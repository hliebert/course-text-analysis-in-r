Econometrics Journal (2007), volume 10, pp. 359–407.
doi: 10.1111/j.1368-423X.2007.00212.x

Propensity score matching without conditional independence
assumption—with an application to the gender wage gap
in the United Kingdom
M ARKUS F R ÖLICH

∗

University of St. Gallen, SIAW, Switzerland
E-mail: markus.froelich@unisg.ch
First version received: October 2003; final version accepted: January 2007

Summary Propensity score matching is frequently used for estimating average treatment
effects. Its applicability, however, is not confined to treatment evaluation. In this paper, it is
shown that propensity score matching does not hinge on a selection on observables assumption
and can be used to estimate not only adjusted means but also their distributions, even with
non-i.i.d. sampling. Propensity score matching is used to analyze the gender wage gap among
graduates in the UK. It is found that subject of degree contributes substantially to explaining
the gender wage gap, particularly at higher quantiles of the wage distribution.
Keywords: Covariate-adjustment, Discrimination,
unobservables, Subject of degree, Wage gap.

Field

of

major,

Selection

on

1. INTRODUCTION
Propensity score matching (PSM) is widely used in evaluation studies to estimate average
treatment effects when selection is on observables. The propensity score plays such a fundamental
role since it allows using one-dimensional non-parametric regression techniques for estimating
treatment effects, even with many confounding variables. Rosenbaum and Rubin (1983) showed
that, if treatment assignment is ignorable, matching on the probability of treatment receipt
estimates the average treatment effect consistently. Hence, instead of matching on all covariates
X, matching on this one-dimensional probability is sufficient, and this dimension reduction has
been used in many evaluation studies.1
This paper extends the results of Rosenbaum and Rubin (1983) in several directions. First,
it is argued that PSM can also be used outside of the realm of treatment evaluation, for
example, to disentangle the effects due to observables and due to unobservables in the analysis of
discrimination as a nonparametric extension of the Blinder (1973)–Oaxaca (1973) decomposition,

∗

Correspondence address: Universität St. Gallen, Bodanstrasse 8, SIAW, 9000 St. Gallen, Switzerland.
Brodaty et al. (2001), Frölich et al. (2004), Frölich (2005), Gerfin and Lechner (2002), Heckman et al. (1998),
Jalan and Ravallion (2003), Larsson (2003), Lechner (1999), Puhani (1999) and Smith and Todd (2005).
1 See e.g.


C Royal Economic Society 2007. Published by Blackwell Publishing Ltd, 9600 Garsington Road, Oxford OX4 2DQ, UK and 350 Main

Street, Malden, MA, 02148, USA.

360

Markus Frölich

or to account for the changing sample composition in a longitudinal survey due to attrition and
non-response. It is shown that consistency of PSM as an estimator of the covariate-distribution
adjusted mean follows from a purely mechanical property of conditional densities and requires
only finite mean assumptions. It does not hinge on any properties of potential outcomes and does
not even need the concept of potential outcomes, which is controversial in the statistical literature
Dawid (2000). It also clarifies that no additional assumptions are needed for PSM other than those
required for justifying matching on covariates.
Second, it is shown that PSM can be used also to estimate adjusted density and distribution
functions, for example, to simulate changes in the wage distribution if the distribution of certain
characteristics in the population (age, education etc) was changed, which has been the focus of Juhn
et al. (1993), DiNardo et al. (1996) and Gosling et al. (2000) in their analyses of the increasing
wage inequality in the USA and UK. Third, PSM under non-random sampling (e.g. stratified
household surveys or oversampling of treatment participants) is analyzed and a weighted PSM
estimator is developed. Also conditions under which standard unweighted PSM is consistent are
given.
These results also help to clarify two common misperceptions in the literature, where it is often
argued (i) that matching on the propensity score required different assumptions than matching on
covariates,2 and (ii) that PSM needed to be modified in the presence of choice-based sampling,
i.e. over- or undersampling of treatment participants as in Heckman et al. (1997) and Heckman
et al. (1998).3 Section 2 of this paper clarifies that PSM is justified under the same assumptions
than matching on covariates, and that choice-based sampling can be ignored.
In Section 3, the finite-sample properties of propensity score and multivariate matching are
examined. In Section 4, PSM is applied to analyze the gender wage gap of college graduates
in the UK. It is examined to which extent the gender wage gap can be explained by observed
characteristics, and, by simulating the entire wage distribution, the gender wage gap can be
examined at different quantiles. Of particular interest is the contribution of ‘subject of degree’
(= field of major) to explain the gender wage differences, a variable that is not available in most
data sets. It turns out that subject of degree contributes substantially to reducing the unexplained
wage gap, particularly in the upper tail of the wage distribution. The huge wage differential
between high-earning men and high-earning women is thus to a large extent the result of men
and women choosing different subjects in university. Section 5 concludes. Additional material is
given in the Appendix.

2. PROPENSITY SCORE MATCHING WITHOUT CIA
Let f x|s be the density of some covariates X in a particular population (denoted source population)
and let f x|t be the density of X in a target population. In many situations, one is interested in the
2 For example, Heckman and Navarro-Lozano (2004, p. 33) state ‘However, if (M-1’) is invoked, the assumption that
one can replace W by P(W) does not follow from the analysis of Rosenbaum and Rubin, and is an additional new
assumption’. [Emphasis added]. Similarly, Nopo (2004) argues that he uses matching on covariates instead of propensity
scores because ‘The “ignorability of treatment” assumption required by Rosenbaum and Rubin (1983) in order to allow
to match by propensity scores instead of characteristics is not likely to be satisfied in the gender setup of this paper’ Nopo
(2004, footnote 6).
3 For example, Heckman et al. (1997, footnote 18) state ‘We use the weighting procedure . . . to account for choice-based
sampling’. Similarly, Smith and Todd (2005, section 3.4) argue that in the presence of choice-based sampling either
weighted estimation of the propensity scores is required or matching should be done on the propensity score odds ratio.


C Royal Economic Society 2007

361

Propensity score matching

mean of an outcome variable Y in the source population if its covariates were distributed as in the
target population

m s (x) · f x|t (x)d x,
(1)
S

where m s (x) = E s [Y |X = x] is the conditional mean of Y in the source population and S is the
support of X in the source population.
A non-parametric matching estimator of this covariate-distribution adjusted mean is
1 
m̂ s (X i ) ,
n St i:Di =t
X i ∈S

where D i ∈ {s, t} indicates whether an observation i is drawn from the source or the target
population, m̂ s (x) is an estimator of E s [Y |X = x] = E[Y |X = x, D = s] and n St is the number
of observations in the target population lying in the support S, i.e. with D i = t and X i ∈ S.
For example, let the source population be women and the target population be men, and let Y
be wages and X describing human capital endowment, then the adjusted mean (1) represents the
mean wage that women would receive if they had the human capital endowment of men.
As another example, let D i ∈ {0, 1} denote whether an individual received a treatment
(e.g. participation in a training programme) or did not. Define Y i0 , Y i1 as the potential outcomes
and the average effect of treatment on the treated as E[Y 1 − Y 0 |D = 1]. If all variables that
influenced treatment assignment and the potential outcomes are observed, then conditional on
these confounding variables X the potential outcomes are stochastically independent of D4
Y0 ⊥
⊥ D |X ,
and the average treatment effect is identified as

(2)


E[Y − Y |D = 1] = E[Y |D = 1] −
1

0

m 0 (x) · f x|D=1 (x)d x,

(3)

where m 0 (x) ≡ E[Y |X = x, D = 0], provided that supp(X |D = 1) ⊆ supp(X |D = 0), or
equivalently, that Pr (D = 1|X ) < 1 a.s.5 The last term in expression (3) is the adjusted mean (1)
where the non-treated are the source population and the treated the target population.
For the treatment evaluation context, Rosenbaum and Rubin (1983) showed that the
independence assumption (2) also implies independence conditional on the propensity score
Y0 ⊥
⊥ D | p(X ),

(4)

where p(x) = Pr(D = 1|X = x), such that the average treatment effect on the treated can also be
estimated by matching on the one-dimensional propensity score.
In this section, the results of Rosenbaum and Rubin (1983) are extended in several directions
and the applicability of PSM outside the treatment evaluation context is illustrated. First,

4 This assumption is known as selection on observables (Barnow et al. 1981), ignorable treatment assignment
(Rosenbaum and Rubin 1983) or conditional independence assumption (Lechner 1999).
5 Otherwise, the definition of the treatment effect has to be restricted to the set supp(X |D = 0) since the expected
counterfactual is not identified for participants who could never have been assigned to non-treatment.


C Royal Economic Society 2007

362

Markus Frölich

Theorem 1 shows that the consistency of PSM follows from a purely mechanical property of
conditional densities. Only the existence of moments is needed to show that


m s (x) · f x|t (x)d x = ms (ρ) · f p|t (ρ)dρ,
S

S

where m s (ρ) = E[Y | p(X ) = ρ, D = s] and f p|t is the distribution of the propensity score
p(x) = Pr(D = t|X = x, D ∈ {s, t}) in the target population. Hence, matching on the propensity
score
1 
m̂s ( pi ) ,
n St i:Di =t
pi <1

where pi = p(X i ), is consistent provided that a consistent estimator m̂ s is used.
The justification of PSM, therefore, is not based on any properties of potential outcomes and
does not even require the controversial concept of potential outcomes (see Dawid 2000). Even if
the concept of potential outcomes is invoked, Theorem 1 implies that no additional assumptions
are needed for PSM other than those required for justifying matching on X. In particular, mean
independence given X suffices:6
E[Y 0 |X , D = 0] = E[Y 0 |X , D = 1].

(5)

Theorem 1 also shows that PSM can be used to estimate not only adjusted means, but also
density and distribution functions. The density function of Y if its covariates X were distributed
as in the target population is given by

f y|x,s (a, x) · f x|t (x)d x
(6)
S

and its adjusted distribution function is

Fy|x,s (a, x) · f x|t (x)d x,

(7)

S

where f y|x,s (a, x) is the conditional density function of Y in the source population evaluated at
the value a and conditional on X = x, and F y|x,s (a, x) is the conditional distribution function.
The corresponding PSM estimators for the adjusted pdf and cdf are
1  ˆ
f y| p,s (a, pi )
n St i:Di =t
pi <1

and

1 
F̂y| p,s (a, pi ) ,
n St i:Di =t
pi <1

6 Heckman and Navarro-Lozano (2004, p. 33) state “However, if (M-1’) is invoked, the assumption that one can replace
W by P(W) does not follow from the analysis of Rosenbaum and Rubin, and is an additional new assumption”, where the
assumption (M-1’) replaces full independence by mean independence given X. Nopo (2004) argues that he uses matching
on covariates instead of propensity scores because “The “ignorability of treatment” assumption required by Rosenbaum
and Rubin (1983) in order to allow to match by propensity scores instead of characteristics is not likely to be satisfied in the
gender setup of this paper” Nopo (2004, footnote 6). As Theorem 1 shows, PSM is justified under the same assumptions
as matching on covariates.


C Royal Economic Society 2007

Propensity score matching

363

respectively, where fˆy| p,s (a, ρ) is a non-parametric estimator of the pdf of Y at a in the source
population given the propensity score, and F̂y| p,s (a, ρ) is a nonparametric estimator of the cdf.
F y| p,s (a, ρ) could be estimated, for example, by nonparametric regression of 1(Y ≤ a) on the
propensity score in the source sample. These estimators are consistent by Theorem 1.
On the other hand, PSM cannot directly be used to estimate the adjusted variance or adjusted
quantiles, e.g. the adjusted median


Var [Y |X = x, D = s] · f x|t (x)d x
or
Median [Y |X = x, D = s] · f x|t (x)d x.
Whereas matching on covariates is consistent for these two objects, propensity score matching
is not. The reason for this is that PSM essentially relies on a type of iterated averaging argument
where averages are taken in two steps: First within subspaces with the same value of the propensity
score and then across these subspaces. Whereas such an iterated expectations property holds for the
mean, pdf and cdf, i.e. E[Y ] = E[E[Y |X ]] and f Y (a) = E[ f Y |X (a, X )] and F Y (a) = E[F Y |X (a,
X )], no such relationship holds for the variance or for quantiles. Obviously, the adjusted quantiles
can be obtained indirectly via inverting the adjusted distribution function, which can be obtained
by PSM. This is the approach used in Section 4.
Taken together, this suggests that PSM can also be used in applications other than treatment
evaluation with ignorable treatment assignment and can be used to estimate not only the mean of
Y in a particular population if its covariates X were distributed as in an other population, but also
its whole distribution. To mention a few examples, it can be used to disentangle the effects due to
observables and unobservables in an analysis of discrimination, where it relaxes the parametric
assumptions of the Blinder–Oaxaca decomposition. Here, it is of interest how much men would
earn if they had the distribution of the human capital characteristics of women.
Similarly, PSM could also be used to simulate changes in the wage distribution if the
distribution of certain characteristics (age, education) in the population were changed, as for
example in the analysis of the increasing wage inequality in the USA and UK of Juhn et al.
(1993), DiNardo et al. (1996) and Gosling et al. (2000).
As another example, PSM could be used to account for survey non-response or attrition
in longitudinal studies, e.g. if interest is in the evolution of a cohorts’ characteristics over time
(e.g. income, employment rate), non-random attrition has to be taken into account. If data are
missing at random conditional on some covariates X observed in the baseline period, the mean
outcome among the attriters can be estimated by adjusting the observed outcomes of the nonattriters for the distribution of X among the attriters. Usually, inverse probability weighting is used
to deal with attrition and non-response (e.g. Horvitz and Thompson 1952; Horowitz and Manski
1998; Robins et al. 1995; Wooldridge 2002), but PSM may have the advantage in small samples
of being less susceptible to weighting by very small denominators. If data are not missing at
random, PSM in the baseline period(s) could be used to estimate and predict the bias for later
periods.
Theorem 1 shows that PSM is justified if some kind of iterated expectations property (8) holds
for a function ξ y|x,d (x, d) of the distribution of Y given X = x and D = d and the corresponding
function ξ y| p,d ( p, d) given the propensity score P = p and D = d. This property is satisfied, e.g.,
for the conditional mean ξ y|x,d (x, d) = E[Y |X = x, D = d], the conditional density function
ξ y|x,d = f Y |X,D=d and the conditional distribution function ξ y|x,d = F Y |X,D=d .7
7 With the corresponding expressions for the conditional mean ξ
y| p,d (ρ, d) = E[Y |P = ρ, D = d], for the conditional
density function ξ y| p,d = f Y |P,D=d , and for the conditional distribution function ξ y| p,d = F Y |P,D=d .

C Royal Economic Society 2007

364

Markus Frölich

Theorem 1: Let (Y , X , D) ∈ × k × be random variables with Pr (D = s) > 0 and
Pr (D = t) > 0. Let ξ y|x,d (x, d) be a function of the distribution of Y given X = x and D = d. Let
ξ y| p,d ( p, d) be the corresponding function given the propensity score P = p and D = d, where
the propensity score is p(x) = Pr (D = t|X = x, D ∈ {s, t}). Denote by f x|s (x) the density of X
given D = s and let S ≡ {x : f x|s (x) > 0} = {x : p(x) < 1} denote the support of X in the source
population. Suppose that ξ y|x,d (x, s) and ξ y| p,d ( p, s) are both finite for all values of x ∈ S and
p < 1. If
E[ξ y|x,d (X , s)| p(X ) = ρ, D = s] = ξ y| p,d (ρ, s)

(8)

then
E
[ξ y|x,d (X , s)|D = t]
S

=

E
[ξ y| p,d (P, s)|D = t],
S

(9)

where the expectation is taken with respect to the support S (proof in Appendix).
Hence, matching on X and matching on the propensity score
1 
1 
and
ξ̂ y|x,d (X i , s)
ξ̂ y| p,d ( pi , s)
S
n t i:Di =t
n St i:Di =t
X i ∈S

pi <1

converge to the same limit, provided ξ̂ y|x,d and ξ̂ y| p,d are consistent estimators.
2.1. Propensity score matching with non-i.i.d. data
Theorem 2 analyzes PSM with non-random sampling and shows that no adjustment for choicebased sampling is necessary, whereas several modifications are required for other kinds of nonrandom sampling. Let f 0yxd = f 0yx|d · f 0d be the joint pdf of Y , X and D in the superpopulation,
containing the source and the target and perhaps other populations. The available data may
often not be representative of the true population proportions, with certain groups such as
treatment participants, foreigners, low-income individuals or residents of particular regions being
oversampled.8 Let f ∗yxd = f ∗yx|d · f ∗d be the sampling distribution corresponding to the sampling
design. In the following, we distinguish between non-random sampling with respect to D (i.e.
f ∗d = f 0d ) and non-random sampling with respect to Y and X given D (i.e. f ∗yx|d = f 0yx|d ).
Non-random sampling with respect to D is particularly frequent in the treatment evaluation
context, where treatment participants are often oversampled. This is referred to as choice-based
sampling in Heckman et al. (1997, footnote 18), Heckman et al. (1998) and Smith and Todd
(2005).9 As we are interested in comparing source and target population, let P 0t = Pr0 (D = t|D ∈
{s, t}) be the true population measure of the target population relative to the source population,10
and P ∗t = Pr∗ (D = t|D ∈ {s, t}) be the corresponding proportion under the sampling design.
We define choice-based sampling as a relative over- or undersampling of the treated population,
i.e. P ∗t = P 0t , which leads to inconsistent estimates of the propensity score (Manski and Lerman
1977).
Non-random sampling with respect to X or Y given D can occur e.g. due to oversampling
of foreigners or low-income individuals. Such non-random sampling could be present only in
8 See

e.g. Imbens and Lancaster (1996) or Wooldridge (1999) for a discussion of various sampling schemes.
may also often occur, when the source and target sample stem from separate surveys or data sources.
10 That is P 0 = f 0 /( f 0 + f 0 ).
t
t
s
t
9 It


C Royal Economic Society 2007

Propensity score matching

365

one of the two populations, for example, if different sampling designs were used for the two
populations. A survey might e.g. oversample pregnant women or women with small children,
while using random sampling for the survey of men.
In the following, it is supposed that no groups are excluded from the survey, i.e. that the
sampling densities are positive wherever the population densities are:
 ∗ 
 0 
supp f yx|d
= supp f yx|d
for d ∈ {s, t} ,
such that the sampling weights wyx|d (y, x|d), assumed to be known, can be defined as11
w yx|d =

0
f yx|d
∗
f yx|d

.

(10)

We are interested in estimating the covariate-distribution adjusted mean


E 0 m 0s (X )|D = t
S

(11)

where the superscript 0 in E0 and in m 0s symbolizes that the expectation and the conditional
mean are with respect to the true population distribution. All the following results can be
obtained analogously for estimating the adjusted pdf and cdf. To make the notation somewhat less
cumbersome, it is assumed that the support of X in the source and target populations coincide.
The required modifications for accommodating different supports are obvious.
Theorem 2 shows that (11) can be estimated by PSM from data sampled under the sampling
distribution, if the matching estimator is redefined to account for the sampling weights. Three
modifications are required to obtain an estimator consistent under the population distribution. The
weighted PSM estimator

wi · m̂0s ( pi )
i:Di =t



(12)

wi

i:Di =t

takes account of the sampling weights wi = w yx|d (Y i , X i |D i ) in the target population. Second,
to take into account the sampling weights in the source population, a weighted estimator m̂0s is
required, for example, weighted kernel regression

 p −ρ 
w j · Y j · K jh
m̂0s (ρ) =

i:D j =s



i:D j =s

wj · K

 p j −ρ  .

(13)

h

Third, the non-random sampling needs to be taken into account in the estimation of the propensity
score, which could be estimated e.g. by weighted non-parametric regression or by weighted
Maximum Likelihood (Manski and Lerman 1977). The weights can be accounted for in different
11 As an example, consider variable probability or Bernoulli sampling (Imbens and Lancaster 1996) in a survey of
women where women with young children are to be oversampled. First, a woman is drawn randomly and some preliminary
characteristics (age of children) are gathered. With a probability depending on these characteristics, the observation is
kept in the sample and further interviewed. Otherwise, it is dropped from the sample. These probabilities are inversely
1
proportional to wyx|d , i.e. Pr0 (in sample|X , Y , D = d) ∝ w yx|d
.

C Royal Economic Society 2007

366

Markus Frölich

ways. On the one hand, one could take account of the sampling weights and of choice-based
sampling. The resulting propensity score p 0 (x) would satisfy
p 0 (x) =

0
(x) · Pt0
f x|t
0
0
f x|t
(x) · Pt0 + f x|s
(x) · Ps0

.

On the other hand, non-random sampling could be ignored in the estimation of the propensity
score, which would yield the propensity score p∗ (x)
p ∗ (x) =

∗
(x) · Pt∗
f x|t
∗
f x|t
(x)

∗
· Pt∗ + f x|s
(x) · Ps∗

.

As a third alternative, one could take account of the sampling weights w yx|d but neglect choicebased sampling, which would give the propensity score p 0∗ (x)
p 0∗ (x) =

0
f x|t
(x) · Pt∗
0
0
f x|t
(x) · Pt∗ + f x|s
(x) · Ps∗

.

Under choice-based sampling, both propensity scores p 0∗ and p ∗ are biased.
Theorem 2 shows under which conditions weighted PSM with p 0 (x), p 0∗ (x) or p ∗ (x) as
propensity score can be used to estimate the adjusted mean. The first part of Theorem 2 shows
that the limit expression of the weighted PSM estimator based on the propensity score p 0 (x)
is identical to the adjusted mean (11). Hence, weighted PSM is consistent. The second part of
Theorem 2 shows that this expression is identical when p 0∗ (x) is used instead of p 0 (x). Therefore,
choice-based sampling is irrelevant for consistency of the matching estimator and can be neglected
in the estimation of the propensity score.
The third part of Theorem 2 shows that in particular situations, also the weighted PSM
estimator with p ∗ (x) as propensity score has the same limit expression. Then, it is irrelevant
whether the propensity score under the population distribution or under the sampling distribution
is used. In this case, the propensity score can be estimated by conventional (unweighted) estimation
methods under the sampling distribution, completely ignoring non-random sampling. The relevant
condition for this equivalence result is (A.4)
wx|t (x) ∝ wx|s (x),
where w x|d = f 0x,d / f ∗x,d is the sampling weight with respect to X.12 This condition requires that
non-random sampling with respect to x from the source population is proportional to non-random
sampling from the target population. This condition is usually satisfied when the same sampling
design was used for the source and the target sample, e.g. both are part of the same survey.13 In
this case, any weights can be neglected in the estimation of the propensity score (e.g. a simple
logit model could be used). The presence of choice-based sampling can be neglected in any case.
Theorem 2 is given in the Appendix.

12 The

sampling weights can be expressed as w yx|d = w y|x,d · w x|d , where w y|x,d = f 0y|x,d / f ∗y|x,d .

the example mentioned above, the relevant condition is Pr0 (in sample|X , D = t) ∝ Pr0 (in sample|X , D = s).
Note that this proportionality condition refers to the marginal sampling probability with respect to X only. Even if the
sampling weights with respect to Y and X are the same in the source and target population, they may differ with respect to
X only, for example if Y is wages, X is education, women are paid less than men and low-wage earners are oversampled.
13 In


C Royal Economic Society 2007

Propensity score matching

367

Figure 1. Distribution of true propensity score in source and target population.
Note: Left-hand graph ε ∼ N (0, 30), middle graph ε ∼ N (0, 100), right-hand graph ε are drawn from χ 2(5)
and scaled to mean 0.5 and variance 67.6.

3. MONTE CARLO STUDY
In this section, a small Monte Carlo simulation is conducted to examine the properties of PSM in
finite samples. Since the propensity score is usually unknown, three different types of estimators
are compared: semi-parametric PSM (with a parametric estimator of the propensity score), nonparametric PSM (with a non-parametric estimator of the propensity score) and non-parametric
matching on covariates. Two simulation experiments are conducted: one with five continuous
and one with 10 binary covariates. The source and target populations are specified indirectly by
first drawing the X covariates and assigning them subsequently to the source (D = 0) and target
(D = 1) population. This process allows to analyze the properties for correctly specified and
misspecified propensity scores conveniently.
In the first experiment, the X covariates consist of five continuous variables. The first three
variables are jointly normal (with variances 2, 1, 1, respectively, and covariances 1, −1, −0.5),
X 4 is uniformly distributed in (−3, 3) and X 5 is χ 2(1) distributed. The source (D = 0) and target
(D = 1) sample are formed by assigning each observation according to
D = 1 (X 1 + 2X 2 − 2X 3 − X 4 − 0.5X 5 + ε > 0) .
Three different designs for the error term ε are considered. In the first two designs, ε is normal
with variance 30 and 100, respectively, and the resulting distributions of the propensity scores in
the source and the target population are shown by the first two graphs in Figure 1. (Tables C.1
to C.3 in the supplementary appendix summarize the distributions of X in the source and target
populations). When the variance of ε is 30, the source and target populations are very different
and matching as well as PSM will be more difficult (left-hand graph of Figure 1). For a variance
of 100 (middle graph), the source and target populations are more similar and the estimators are
expected to be more precise. For the third design (right-hand graph), an asymmetric error term
with higher kurtosis was chosen: ε is drawn from a χ 2(5) and scaled to mean 0.5 and variance
67.6.14 Its variance thus lies between the variance of the other two designs, with a skewness of
1.26 and a kurtosis of 5.40. Note that for this error term, the probit estimator, which will be used
below for estimating the propensity score, is misspecified.
14 This error term was chosen to satisfy the following requirements: to be skewed and leptokurtic, with variance lying
between the variances of the other two designs, and such that the size of the target population P(D = 1) is about 0.5, and
such that there should be only very little point mass of the propensity score at one.


C Royal Economic Society 2007

368

Markus Frölich

For the variable Y (observed only in the D = 0 population), three designs are examined:

Y design 2:

Y = X1 + X2 + X3 − X4 + X5 + u
√
Y = X 1 + X 2 + 0.2X 3 X 4 − X 5 + u

Y design 3:

Y = (X 1 + X 2 + X 5 )2 + u,

Y design 1:

where u ∼ N (0, 1). For these different designs, samples of size 100, 400 and 1600, respectively,15
are drawn and the adjusted mean

m 0 (x) · f x|1 (x)d x
is estimated. Three different types of estimators are considered: nonparametric matching on
covariates, semiparametric PSM and nonparametric PSM. (In the supplementary appendix, also
propensity score weighting is examined.)
Three nonparametric matching estimators are considered, estimating the adjusted mean as
1 
m̂ 0 (X i ),
n 1 i:D=1
where m̂ 0 (x) is an estimator of E[Y |X = x, D = 0] obtained from the D = 0 sample. Mahalanobis
ˆ an estimate of the
matching estimates m̂ 0 (x) by first-nearest neighbour regression, with 
covariance matrix of X and the distance between two observations X 1 and X 2 defined as
ˆ −1 (X 1 − X 2 ).
(X 1 − X 2 ) 
Multivariate kernel matching estimates m̂ 0 (x) by kernel regression with product kernel

wjYj
5
X j,k − xk
j:D=0
m̂ 0 (x) = 
,
and
w(X j , x) =
φ
wj
hk
k=1
j:D=0

where w j = w(X j , x), φ is the Gaussian kernel function,16 x k denotes the kth component of x and
h k is the corresponding bandwidth value. The X data were scaled to mean zero and unit variance
before. The bandwidths are chosen by leave-one-out cross-validation in the D = 0 sample. Two
estimators are examined: with a single and with multiple bandwidths. With a single bandwidth,
h is chosen from a grid of 20 bandwidth values.17 With multiple bandwidths, grid search is not
viable and the vector (h 1 , h 2 , h 3 , h 4 , h 5 ) is chosen by minimization of the cross-validation criterion
using the BFGS descent algorithm.
The nonparametric PSM estimators estimate first the propensity score E[D|X ] for all
observations by kernel regression, either with a single or with multiple bandwidths, as described
above.18 The semiparametric PSM estimators estimate the propensity score by Probit regression

15 This

is the total sample size. About half are in the source and half in the target sample, respectively.
simulations with Epanechnikov kernel led to worse results.
17 The bandwidth search grid is 0.001, 0.001 · 1.7, 0.001 · 1.72 , . . . , 0.001 · 1.718 , ∞.
18 Alternatively, one could have estimated E[D|X ] by local logit as in Frölich (2006).
16 Previous


C Royal Economic Society 2007

Propensity score matching

369

of D on a set of regressors, where three different regressor specifications are examined:
Regressors
Specification 1:

const, X 1 , X 2 , X 3 , X 4 , X 5

Specification 2:

const, X 1 , X 22 , X 3 , X 4 , X 5

Specification 3:

const, X 12 , X 22 , X 3 , X 42 , X 52 .

For normal errors ε, the first specification is correct, whereas the other two are misspecified.
For non-normal errors ε, all three specifications are incorrect. These different specifications will
provide some indication about the value of knowing the correct functional form. Specification 2
is only mildly misspecified, the correlation between the true and estimated propensity score is
about 0.96 (in a sample of 106 observations). Specification 3 is more misspecified, but with a
correlation of 0.80 still highly correlated with the true propensity score.19
With the propensity
 score pi estimated for all observations, the PSM estimators estimate the
adjusted mean as n11 i:Di =1 m̂0 ( p̂i ), and differ in how the conditional mean m0 (ρ) = E[Y | p(X ) =
ρ, D = 0] is estimated from the D = 0 observations. Pair matching estimates m
0 (ρ) by the
outcome Y of the nearest neighbour. Kernel matching estimates m0 (ρ) as m̂0 (ρ) = j:D j =0 Y j ·

p −ρ
p −ρ
K ( jh )/ j:D j =0 K ( jh ), where the Gaussian and the Epanechnikov kernel are examined in
the simulations. The bandwidth h is chosen by leave-one-out cross-validation in the D = 0 sample,
using the same grid as above.
Propensity score ridge matching20 estimates m̂0 (ρ) as
T0
T1 · (ρ − p̄)
,
+
S0
S2 + r h |ρ − p̄|


p −ρ
p −ρ
where Sa (ρ) = j:D j =0 ( p j − p̄)a K ( jh ) and Ta (ρ) = j:D j =0 Y j ( p j − p̄)a K ( jh ) and p̄ =


p j −ρ
p j −ρ
j:D j =0 p j K ( h )/
j:D j =0 K ( h ). The ridge parameter r is set to 5/16 for the Epanechnikov
and 0.3535 for the Gaussian kernel, according to the rule-of-thumb of Seifert and Gasser (2000).
Table 1 shows the mean squared error of the various estimators for the various simulation
designs. (Results for median absolute error are given in Table C.5 in the supplementary appendix.)
The left third column of the table contains the results for sample size n = 100, the middle for
n = 400 and the right for n = 1600. The first rows contain the results for the nonparametric
covariate matching estimators, followed by the semiparametric PSM estimators and finally by the
nonparametric PSM estimators. The underlined bold numbers indicate the minimum number in
each column, while the bold numbers indicate the minimum in each block of estimators.
Among the nonparametric covariate matching estimators, kernel regression with multiple
bandwidths performs better than Mahalanobis or kernel matching with a single bandwidth,
m̂0 (ρ) =

19 Generally, we would expect the bias of PSM to increase with the misspecification of the propensity score (at least for
local departures from the truth). The magnitude of this effect, however, also depends on the data generating process for Y
and its relationship to the propensity score. For Ydesign 3, for example, the correlation of Y with the true propensity score
is only about 0.16 compared to 0.52 and 0.80 in Ydesigns 1 and 2, respectively. Small misspecifications of the propensity
score may therefore affect the estimates of the semiparametric PSM much less for Ydesign 3 than for 1 and 2, which is
indeed observed, e.g. in Table 1 for n = 100.
20 Ridge matching is based on the ridge regression estimator of Seifert and Gasser (1996, 2000) and performed very
well in the simulations of Frölich (2004), who compared different PSM estimators for known propensity score, but did
not examine estimators with estimated propensity score or multivariate covariate matching estimators.


C Royal Economic Society 2007

1

2

3

2

3

1

2

ε ∼ χ 2(5)
3

1

2

3

ε ∼ N(0,30)
1

Semiparametric propensity score matching

7.7

7.2
7.7

55.7 30.9 22.5 30.5 18.8 12.2 46.4 26.1 19.5 12.4

54.0 33.0 22.0 29.8 19.0 11.8 45.2 27.5 19.0 13.0

Ridge Gauss

Ridge Epa

2

3

1

2

ε ∼ χ 2(5)

8.7

8.8

6.6

6.1

17.6 14.3

3.2

425

368

Pair Match

Kernel Gauss

219 22.4 157 91.6 12.6 251

189 33.5 181 84.2 20.4 291
153 18.5 341

136 26.8 360

9.3

10.3
10.2

7.9
8.0

171 15.5 127 64.1

154 16.2 125 55.5

9.2

6.7

7.5

3.3

79.0 51.5 22.6 37.6 25.6 11.6 59.3 41.1 18.5 26.3 22.1

76.2 53.9 22.6 36.5 26.1 11.5 58.0 42.8 18.1 26.9 22.6

Ridge Gauss

2

3

1

2

3

1

2

ε ∼ χ 2(5)
3

7.1

7.3

6.8

7.5

3.48 1.87 2.53 1.47 0.98 0.99 2.53 2.01 2.02

3.28 1.79 2.48 1.45 0.97 0.86 2.41 1.82 1.89

4.58 2.39 2.54 2.38 1.64 0.97 3.80 3.48 2.06

4.72 2.14 2.66 2.47 1.61 0.98 4.16 2.66 2.15

11.7 6.07 2.43 3.98 2.74 1.46 1.40 5.64 2.55 3.74

6.9

7.5

7.6

8.4

220

115 10.8 329

151 11.9 121 55.1 4.20 212 98.9 6.84

144 11.3 117 49.2 3.72 211 89.6 6.06

14.9 12.1 3.43 4.54 4.05 0.83 8.45 8.81 1.95

14.9 12.3 3.51 4.53 4.22 0.81 8.18 8.62 1.89

20.6 15.9 4.74 7.63 6.73 1.58 13.0 13.8 2.85

20.9 15.6 4.90 7.89 6.78 1.60 13.5 11.8 2.93

234 99.5 11.3 342

17.6 15.0

27.4 21.6
26.8 23.8

16.5 13.3

4.2

9.9

93.9 76.3 19.8 44.4 37.6 10.7 68.3 61.3 16.3 39.3 30.7

Kernel Epa

Specification 3

1

n = 1600
ε ∼ N(0,100)

25.1 17.2 10.5 16.2 12.5 4.77 5.80 4.63 1.78 10.4 9.17 4.23

9.8

9.5

13.4 10.4

13.5

17.6

4.2

6.2

3.4

3.2

3.5

3.6

5.8

98.5 73.0 20.3 45.3 35.7 11.1 70.4 57.2 17.2 39.8 29.3 10.0 16.5 12.3

Ridge Epa

3

ε ∼ N(0,30)

23.6 13.9 11.6 10.4 13.1 6.90 4.37 4.43 3.64 7.88 9.28 5.94
17.9 10.1 8.1 10.1 6.86 4.33 5.80 2.32 2.05 8.29 4.37 3.49

94.4 61.9 35.7 55.0 35.6 20.7 77.6 53.4 30.2 31.8 23.2 13.4 15.5 10.9

3.8

3.8

5.9

5.5

5.9

7.6
5.4

Kernel Gauss

6.5

6.6

9.1

9.2

7.8
6.3

Pair Match

7.8

8.0

64.9 44.7 19.0 33.7 25.4 10.4 50.1 38.7 16.6 17.5 10.4

Kernel Epa

Specification 2

8.1

11.7 11.3

9.4

67.5 42.4 19.9 34.9 24.7 11.0 52.9 35.8 17.9 18.2

Kernel Gauss

9.4

77.7 42.6 38.2 48.2 28.6 21.2 66.4 36.9 31.6 21.6

Pair Match

Specification 1

n = 400
ε ∼ N(0,100)

88.5 87.7 33.4 47.1 35.6 21.3 64.1 57.2 28.7 37.1 39.4 18.3 17.1 12.6 10.1 26.0 23.9 15.1 15.5 16.6 9.67 6.57 4.90 4.32 10.8 10.9 7.66

1

ε ∼ N(0,100)

Table 1. MSE with five continuous variables.

K one bandwidth 69.6 55.3 24.7 36.4 24.3 15.6 50.6 37.9 21.6 32.8 20.6 13.5 14.9
K multi band
62.0 37.1 24.6 34.5 19.9 14.8 47.2 28.6 20.3 24.7 16.3 10.1 11.3

Mahalanobis

Nonparametric covariate matching

Y-design

ε ∼ N(0,30)

n = 100

370
Markus Frölich


C Royal Economic Society 2007


C Royal Economic Society 2007

384

383

Kernel Epa

Ridge Gauss

Ridge Epa

2

187

186

219

3

1

23.7 156

23.7 156

22.3 155

77.4

272

262

Kernel Epa

Ridge Gauss

Ridge Epa

112

64.3

32.5

36.9

72.1

30.3

32.8

25.1

3

1

2

3

1

2

3

1

9.0

9.3
337

337

2

3

1

2

3

1

2

3
102 6.90

143 10.1 112 48.9 2.19 206 89.6 4.76

143 10.4 113 48.6 2.44 206 89.3 5.06

152 11.9 121 56.0 4.23 212

8.9

16.3 12.5 17.2 7.8 11.1

9.8

12.9 3.21 2.73 6.33 1.64 2.51 3.06 1.93 1.88 5.34

22.7 13.7 13.1 18.9

8.8

5.9 18.4 11.8 10.0 4.42 2.88 3.86 2.63 2.29 1.34 3.88 2.51 2.79

26.2 16.7 15.5 21.4 14.0 6.1 24.5 17.9 10.9 5.19 4.95 3.77 3.27 4.43 1.24 5.52 3.99 2.69

47.0 29.8 23.3 30.7 25.3 9.9 37.6 27.0 18.1 12.4 8.52 5.22 6.23 7.52 2.04 9.43 6.27 5.80

15.4 15.7 15.5 13.2 22.0 5.5 14.2 23.3 10.7 4.74 4.30 5.12 3.71 7.59 1.22 2.93 3.63 3.38

18.6 18.2 16.1 16.3 24.9 5.8 19.0 27.1 10.7 6.10 5.77 4.73 4.56 8.77 1.15 4.49 4.23 3.08

13.0

17.8 12.7 16.9 11.6 16.1 7.3 15.7 16.6 12.2 4.83 4.75 5.59 2.32 5.00 2.62 3.31 2.61 4.40

29.2 24.3 19.5 22.8 27.9 7.8 27.2 26.4 14.6 8.79 7.75 6.08 5.50 9.12 2.02 6.49 4.96 4.42

151 13.9 119 52.9 4.7 217 98.0

150 14.3 121 52.3 5.0 218 96.6

119 10.7 332

ε ∼ χ 2(5)

Note: All figures multiplied by 100. The minimum in each column is marked bold underlined. The minimum in each block of estimators (nonparametric matching,
semiparametric PSM, nonparametric PSM) is marked in bold. Gauss refers to Gaussian kernel, Epa to the Epanechnikov kernel. Number of Monte Carlo replications: 5000 for
n = 100, 1000 for n = 400 and 500 for n = 1600.

22.1

77.1

102

61.3

65.5

40.0

42.6
27.9

351

349

2
172 15.4 127 65.9 6.7 222

ε ∼ N(0,100)

190 >999 58.2 106 >999 >999 >999 >999 >999 90.0 18.1 14.8 22.9 19.9 6.0 25.0 23.1 10.7 6.40 5.03 3.63 4.77 5.99 1.39 5.84 4.32 2.64

55.4

134

194

65.5

75.8

59.0

58.9
40.8

18.5

18.8

1
342

ε ∼ N(0,30)

Ridge Epa

37.6 85.5

25.2

50.6

20.7

21.7

16.4

97.0
67.2

129

128

3
18.0

ε∼

n = 1600

146

64.5

104

67.5

59.7

36.9

30.8
18.0

258

258

2
155

ε ∼ N(0,100)

χ 2(5)

196 >999 60.9 117 >999 >999 >999 >999 >999 91.4 20.7 15.9 25.3 23.1 6.1 28.7 26.1 11.2 6.90 6.11 3.56 5.34 7.07 1.28 7.02 5.35 2.60

43.6 96.7

81.9 161

41.3 55.6

43.5 61.3

33.2 47.6

65.8

37.7

12.4

12.7

1
249

ε ∼ N(0,30)

n = 400

Kernel Epa

83.3

56.8 89.0

37.0 51.2

3
12.4

ε∼

χ 2(5)

Table 1. (Continued).

Ridge Gauss

96.5

229

165

Kernel Gauss

125

67.4

Pair Match

Multiple
bandwidths

47.9

89.4

Kernel Gauss

73.0

75.1

53.7

One bandwidth
Pair Match
115

76.0

75.4

93.0

2

ε ∼ N(0,100)

Nonparametric propensity score matching

1

366

Y-design

ε ∼ N(0,30)

n = 100

Propensity score matching

371

372

Markus Frölich

in almost all designs. Among the nonparametric PSM estimators, kernel regression with
Epanechnikov kernel is usually more precise than Gaussian kernel or pair or ridge matching.
The relative efficiency of nonparametric matching on covariates to nonparametric PSM
depends on the sample size. For n = 1600, nonparametric PSM with multiple bandwidths (and
with Epanechnikov kernel regression) has an often substantially smaller MSE than direct matching
on X in all nine designs. This also holds for the median absolute error. For n = 400, this is still
the case with respect to median absolute error, but no longer with respect to MSE. For a small
sample size n = 100, nonparametric PSM is clearly worse than matching on covariates and using
multiple bandwidths in the estimation of the propensity score worsens precision (also with respect
to median absolute error). Hence, it seems that the repeated use of nonparametric regression in
the nonparametric PSM estimator (first to estimate the propensity score and second to estimate
the regression line) and thus the need to select bandwidth values twice can add a lot of variation,
compared to direct matching, when the sample size is small. On the other hand, in larger samples,
nonparametric PSM performs better than matching on covariates.
Analyzing the results for semiparametric PSM, we first examine the various estimators for
the same specification of the probit model. Within each specification, ridge matching very often
performs better than kernel matching, whereas the type of kernel function often does not matter
much. Ridge matching with Gauss kernel usually is the most precise estimator in specification 1.
Pair matching is always worse than ridge matching, whereas it can be better than kernel matching
in several of the designs.
Now comparing semiparametric PSM to nonparametric matching, when the parametric model
is correctly specified, not surprisingly, semiparametric PSM is more precise than nonparametric
estimation. For sample size 1600, however, the efficiency loss when using nonparametric PSM
is not very large: The MSE of nonparametric PSM with multiple bandwidths (and Epanechnikov
kernel regression) is about 50 to 60% larger than for semiparametric ridge matching with Gauss
kernel (and probit specification 1). The efficiency loss in terms of median absolute error (Table C.5)
is about 30%. On the other hand, even when the parametric model is only mildly misspecified
(Specification 2), nonparametric PSM with multiple bandwidths can be a lot more precise than
semiparametric PSM (e.g. for Ydesigns 1 and 2); and particularly for the moderately misspecified
model (Specification 3), where semiparametric PSM is always and often substantially worse than
nonparametric PSM (with Epanechnikov kernel regression). Hence, semiparametric PSM can be
quite sensitive even to relatively moderate misspecifications of the parametric component, and
nonparametric PSM appears to be more robust.
In small samples (n = 100), on the other hand, nonparametric PSM can be very variable
and direct matching on covariates becomes relatively more precise. The efficiency loss of
nonparametric covariate matching with multiple bandwidths compared to semiparametric ridge
matching with Gauss kernel (in specification 1) is about 10% in terms of MSE (and 15% in
terms of median absolute error). Even in those designs where ε is normally distributed (and the
probit specification therefore correct), the loss in precision is only about 15%. When the probit
model is slightly or moderately misspecified, semiparametric PSM can sometimes (though not
always) be very imprecise. For n = 400, the results are less clear, though. Semiparametric PSM
with moderate misspecification (specification 3) is still almost always worse than nonparametric
covariate matching and nonparametric PSM in terms of MSE and median absolute error. But for
Specification 1 the efficiency losses of the nonparametric estimators are now often larger.
In the second Monte Carlo experiment, X consists of 10 binary variables, taking the values
−0.5 and 0.5 with equal probability. X 1 . . . X 10 are generated as the sum of a common component
and an individual component (both uniform random variables), taking the value 0.5 if this sum is

C Royal Economic Society 2007

373

Propensity score matching

Figure 2. Distribution of true propensity score in source and target population.
Left ε ∼ N (0, 100), middle ε ∼ N (0, 400), right ε drawn from χ 2(5) and scaled to mean 2.5 and variance
202.5.

greater than 1, and −0.5 otherwise. The correlation between X 1 . . . X 10 is 0.34. The observations
are assigned to the source (D = 0) or the target (D = 1) sample by
D = 1(X  β + ε > 0),
√
√
√
√
where β = ( 0.5, 1.5, 2.5, . . . , 9.5) .21 Again, three different designs of ε are considered:
ε ∼ N (0, 100), ε ∼ N (0, 400) and ε drawn from a χ 2(5) and scaled to mean 2.5 and variance 202.5.
Figure 2 shows the distributions of the propensity score.
For the outcome variable Y three designs are examined, with u ∼ N (0, 1):
Y design 1 :

Y =

10


Xk + u

k=1

Y design 2 :

Y =

5


Xk −

k=1

Y design 3 :

Y = ln

10

k=6

10


Xk +

5


X k X k+5 + u

k=1

(X k + 0.5) + 0.1 + u.

k=1

In addition to the previously described estimators, also exact matching is included. With X
being discrete, it is now possible to match exactly on all covariates, in that m 0 (x) is estimated by
the average of the Y values in the cell defined by X. If the cell is empty in the D = 0 sample, the
estimate is undefined. Then, in the D = 1 sample, the average of m̂ 0 is taken for all values of X i
where the estimate is defined.
The nonparametric covariate matching estimator is also adapted to this design with binary
regressors. A kernel that smoothes over the dummy variables is used,22 with weights
10

w(X j , x) =

1(X j,k =xk )

hk

,

k=1
21 This β vector was chosen to obtain a large cardinality of the support of the propensity score. Since with X discrete,
the propensity score (X  β/σ ε ) is also discrete. Were β chosen, for example, as a vector with identical elements, X  β
could take only 11 different values and the support of the propensity score would thus contain only 11 points; this would
not be a very realistic scenario.
22 Smoothing over discrete and binary variables has recently been suggested in Racine and Li (2004), who find substantial
efficiency gains even when the number of discrete regressors is small.

C Royal Economic Society 2007

374

Markus Frölich

as suggested in Racine and Li (2004), where h k ∈ [0, 1] is the bandwidth value for the kth
regressor. Kernel matching with a single and with multiple bandwidths is considered. With a
single bandwidth, h is chosen by cross-validation in the D = 0 sample from the grid: 0, 0.05,
0.10, . . . , 1. If h were chosen to be zero, no smoothing over the discrete regressors takes place
and multivariate kernel matching is equivalent to exact matching. If h were chosen to be one,
the weights are all equal to one and the estimate corresponds to the sample mean. With multiple
bandwidths, grid search is not possible and the vector of bandwidths (h 1 , . . . , h 10 ) is chosen by
numerical minimization using the BFGS descent algorithm.
The nonparametric PSM estimators are adapted analogously. For semiparametric PSM
estimation, three different regressor specifications of the index function for estimating the
propensity score by probit are examined:
Regressors
Specification 1:

const, X 1 , X 2 , . . . , X 10

Specification 2:

const, X 1 , X 2 , . . . , X 9 , X 9 X 10

Specification 3:

const, X 1 , X 2 , . . . , X 5 , X 1 X 6 , X 2 X 7 , X 3 X 8 , X 4 X 9 , X 5 X 10 .

For normal errors ε, the first specification is correct, whereas the other two are misspecified.
Specification 2 is very mildly misspecified (the correlation between the true and estimated
propensity score is about 0.98), while Specification 3 is moderately misspecified with a still
rather high correlation of about 0.87.23
Table 2 shows the simulated MSE (with results for median absolute error given in Table C.6 in
the supplementary appendix). The overall patterns are roughly similar to those of Table 1. Among
the nonparametric covariate matching estimators, kernel matching with multiple bandwidths
usually performs better than matching with a single bandwidth or Mahalanobis matching
(particularly in larger samples and with respect to median absolute error in Table C.6). Exact
matching, on the other hand, is often very imprecise.24
Among the nonparametric PSM estimators, kernel regression with Epanechnikov kernel
is often the most precise. When comparing nonparametric PSM to nonparametric matching
on covariates, the sample size matters. For small samples, nonparametric PSM with multiple
bandwidths (and with Epanechnikov kernel regression) is often much more noisy than covariate
matching with multiple bandwidths. For n = 1600, on the other hand, nonparametric PSM with
multiple bandwidths is clearly more precise than covariate matching in Y-designs 2 and 3 (also in
median absolute error). Similarly to Table 1, this seems to indicate that the two smoothing steps
in nonparametric PSM require a larger sample size for reliable estimation.
Among the semiparametric PSM estimators, kernel regression with Epanechnikov kernel is
often best in Specification 1, but it can also be a lot worse than ridge matching in the other two
specifications. Generally, the patterns are less clear than in Table 1. In the first two specifications
23 In Specification 2, the interaction term X X instead of the variable X is included in the Probit model. In specification
9 10
10
3, the interaction term X 1 X 6 instead of the variable X 6 is used as regressor, and also X 2 X 7 instead of X 7 and so forth.
The informational content is the same in all three specifications, since X 10 could be recovered from the regressors X 9
and X 9 X 10 in Specification 2 (and analogously in Specification 3). Specification 2 corresponds to a model where two
variables A and B are included in a Probit model, but where the true propensity score is of the type (β1 A + β2 BA ), i.e.
depending on the ratio B/A.
24 Since exact matching discards all observations for which no exact match can be found, in small samples it might occur
that the estimate is undefined as no matches are found at all. The bracketed numbers in Table 2 show the MSE using only
those replications where the estimate was defined.


C Royal Economic Society 2007

1

2

3


C Royal Economic Society 2007

37.9 17.1

Ridge Epa

39.5 16.8

39.2 16.7

Kernel Epa

Ridge Gauss

Ridge Epa

106 30.2

79.3 39.0

82.8 38.8

Ridge Gauss

Ridge Epa

Kernel Gauss

Kernel Epa

76.3 51.7

97.8 31.5

Pair Match

Specification 3

10.2

50.5 13.0

Kernel Gauss

12.2

13.4

13.0

13.7

16.5

10.9

12.4

12.3

54.7 33.3

49.5 13.5

Pair Match

16.6

10.8

8.2

34.5

7.6

7.8

9.2

8.5

9.2

8.0

9.3

7.8

9.2

43.2 17.2

44.9 17.6

48.2 14.0

8.4

9.7

9.1

47.9 14.8 10.1

57.4 29.9 14.4

35.2 10.6

38.9 11.0

35.3

38.9

55.2 23.1 14.3

34.9 10.2

38.7 10.8

10.0

12.4

37.4 17.3

Ridge Gauss

45.7 13.6

Kernel Epa

9.1

55.4 22.8 14.5

8.9

16.8

37.9

Kernel Gauss

12.2

53.6 33.9

43.9 14.0

Pair Match

Specification 2

3

36.7 12.9 14.9
34.9 14.9 13.0

Semiparametric propensity score matching

Specification 1

2

38.7 21.2 16.9

1

ε ∼ N(0,400)

53.9
54.1

56.0

1

56.7

1

2

3

1

2

3

1

2

ε ∼ χ 2(5)
3

1

2

3

ε ∼ N(0,100)
1

n = 1600

2

3

ε ∼ N(0,400)
1

2

ε ∼ χ 2(5)
3

56.7

63.0

60.5

81.9

74.9

66.4

40.1

40.6

49.0

47.7

9.1

8.8

7.90 3.12 2.10 6.53 2.19 1.46 7.87 2.75 1.77 2.24 1.27 0.47 1.38 0.71 0.39 1.84 0.97 0.42

9.3

6.92 4.36 2.14 6.48 2.65 1.37 6.98 3.52 1.74 2.23 1.54 0.47 1.46 0.75 0.37 1.84 1.11 0.42

27.8 10.6 40.3 29.5 3.32 13.2 9.48 1.70 24.3 19.6 2.54 27.8 22.2 1.61 7.54 6.66 0.66 15.9 14.6 1.02

28.1 11.6 35.9 28.9 3.30 11.1 9.53 1.84 21.4 19.4 2.59 17.9 15.3 1.39 4.20 5.07 0.62 9.86 10.4 0.92

22.0 11.1 43.4 27.1 3.71 13.9 9.04 2.09 27.9 19.2 2.97 27.8 23.5 1.93 7.25 7.25 0.86 16.6 15.9 1.28

22.9 12.1 38.0 27.1 3.55 11.4 9.30 2.06 23.7 19.3 2.86 19.2 16.8 1.54 4.52 5.84 0.73 11.0 11.7 1.07

40.7 15.9 22.3 23.4 5.94 12.6 11.1 4.43 17.9 17.5 5.45 8.94 8.67 3.59 4.52 4.32 2.81 6.54 6.91 3.15

12.8

13.0 10.5 6.66 4.18 2.22 6.37 2.65 1.56 6.62 3.51 1.84 2.00 1.47 0.47 1.40 0.73 0.37 1.68 1.10 0.42

10.1

10.5 10.3 7.67 3.05 2.23 6.34 2.27 1.61 7.24 2.74 1.88 2.11 1.36 0.48 1.38 0.76 0.39 1.75 1.06 0.43

27.7 14.9 10.4 9.21 5.32 10.5 6.58 4.32 10.7 7.54 5.05 4.48 4.17 3.30 3.97 2.88 2.76 4.02 3.85 3.04

13.5

5.99 3.75 2.12 6.29 2.33 1.37 6.34 3.20 1.74 1.50 0.86 0.46 1.37 0.61 0.36 1.49 0.75 0.43

6.50 3.32 2.00 6.26 1.91 1.43 6.92 2.80 1.69 1.39 0.75 0.46 1.34 0.49 0.36 1.42 0.60 0.43

39.0

8.3

13.7 10.5 5.97 3.71 2.14 6.60 2.33 1.51 6.24 3.13 1.80 1.38 0.85 0.46 1.38 0.58 0.36 1.42 0.73 0.43

10.6

11.1 10.2 6.37 3.23 2.09 6.42 1.95 1.57 6.77 2.77 1.79 1.38 0.78 0.47 1.39 0.55 0.37 1.42 0.68 0.43

28.6 15.0 10.3 8.58 5.21 10.8 6.16 4.22 10.9 7.14 5.41 4.32 3.91 3.39 3.98 2.80 2.74 4.00 3.62 3.10

120 68.7 32.5 9.43 35.2 23.7 11.1 42.1 28.8 9.76 17.2 9.19 1.03 7.09 6.29 1.66 10.6 7.68 1.21

14.6 16.8 13.3 6.47 3.61 13.6 5.54 4.13 15.9 5.91 3.79 2.53 2.28 1.03 2.54 1.82 1.25 2.59 1.93 1.04
19.8 14.9 11.4 4.63 3.38 12.7 4.01 2.80 13.3 4.11 3.27 2.26 1.49 1.30 4.55 1.49 0.86 2.47 1.36 0.85

39.9

44.3

44.6

3

n = 400
ε ∼ N(0,400)

24.7 18.7 10.6 8.31 5.99 8.97 5.97 4.22 10.4 7.02 5.34 4.53 3.53 3.28 3.91 2.47 2.68 4.09 3.41 2.99

2

ε ∼ N(0,100)

Table 2. MSE with 10 binary variables.
ε ∼ χ 2(5)

(56) (85) (131) 264 63.6 (78) (473) (74)

17.6
16.5

Exact match

21.2

68.3 27.5

Mahalanobis

K one bandwidth 62.5 17.2
K multi band
69.7 23.8

Nonparametric covariate matching

Y-design

ε ∼ N(0,100)

n = 100

Propensity score matching

375

1

2

3

1

2

2

3

1

2

3

ε ∼ N(0,100)
1

n = 400

2

3

ε ∼ N(0,400)
1

2

ε ∼ χ 2(5)
3

1

2

3

ε ∼ N(0,100)
1

n = 1600

2

3

ε ∼ N(0,400)
1

2

ε ∼ χ 2(5)
3

219 55.5 32.0 311 53.8 42.1 225 44.4 29.4 42.5 12.4 7.62 44.2 8.80 6.14 38.2 9.96 6.58 5.93 4.40 3.44 6.73 2.74 2.89 5.40 3.88 3.22

1

ε ∼ χ 2(5)

Table 2: (Continued).

235 31.5 26.1 279 20.3 22.6 236 25.0 23.1 46.8 7.58 3.86 57.6 4.86 4.12 46.2 6.28 3.71 5.49 1.80 0.62 8.47 0.96 0.64 5.40 1.27 0.67

245 30.7 23.9 261 19.9 22.3 229 24.4 21.2 46.4 7.83 3.86 56.9 4.82 4.40 47.4 6.43 3.84 5.51 1.89 0.64 9.05 1.05 0.73 5.66 1.39 0.73

Ridge Gauss

Ridge Epa

237 91.4 46.2 225 73.7 43.2 219 81.7 41.9 37.1 14.6 8.88 31.8 16.0 9.69 29.1 14.1 8.56 5.51 4.13 3.58 5.63 2.84 3.03 4.96 3.74 3.31

207 39.2 26.9 138 24.5 17.3 161 31.2 22.5 33.8 6.34 3.60 22.1 3.97 2.70 27.5 5.41 2.91 3.55 1.04 0.55 5.23 0.71 0.56 3.61 0.84 0.62

Ridge Epa

Note: See note below Table 1. Bracketed numbers indicate that the exact matching estimate was undefined in some replications and the MSE refers only to those replications
where the estimate was defined.

153 30.4 23.0 104 18.9 15.4 131 25.5 20.0 29.5 5.41 3.28 21.1 3.35 2.40 24.8 4.78 2.72 3.19 0.89 0.54 5.48 0.61 0.53 3.41 0.72 0.60

214 44.3 29.4 166 30.0 21.3 179 36.1 24.6 34.6 6.45 3.85 20.3 4.57 2.94 26.6 5.58 2.98 3.45 1.04 0.54 4.79 0.73 0.51 3.41 0.84 0.59

Kernel Epa

Ridge Gauss

Kernel Gauss 186 38.8 28.0 148 26.1 19.6 164 32.1 23.9 32.6 5.73 3.78 20.2 4.16 2.80 25.0 5.16 2.92 3.25 0.93 0.54 5.11 0.66 0.50 3.36 0.76 0.59

Pair Match

Multiple bandwidths

177 22.9 20.2 208 14.6 18.1 180 17.1 18.0 42.9 5.10 3.81 54.7 3.17 4.15 44.7 4.30 3.73 4.96 1.55 0.63 8.92 0.86 0.69 5.21 1.10 0.70

Kernel Epa

Kernel Gauss 207 25.1 25.2 248 16.7 21.6 211 19.3 22.5 44.1 5.27 3.86 56.4 3.37 4.04 44.4 4.37 3.67 4.98 1.63 0.60 8.58 0.90 0.63 5.12 1.15 0.68

Pair Match

One bandwidth

3

ε ∼ N(0,400)

Nonparametric propensity score matching

Y-design

ε ∼ N(0,100)

n = 100

376
Markus Frölich


C Royal Economic Society 2007

Propensity score matching

377

of the probit model, pair matching is always worst, but in Specification 3 it can be even better
than the other semiparametric PSM estimators.
Contrasting semiparametric to nonparametric estimation, for n = 1600 and Specification 1, the
efficiency loss of nonparametric PSM is about 40% in terms of median absolute error compared
to semiparametric Epanechnikov kernel regression, but can be a lot larger in some designs with
respect to MSE. For a moderately misspecified propensity score (Specification 3), semiparametric
PSM with Epanechnikov kernel is always and often substantially worse (in terms of MSE and
median absolute error) than nonparametric PSM with multiple bandwidths (and Epanechnikov
kernel regression) and than nonparametric covariate matching with multiple bandwidths. Also
semiparametric ridge matching is almost always worse.
In small samples (n = 100), nonparametric matching on covariates is often more precise
than nonparametric PSM. The efficiency loss of nonparametric covariate matching with
multiple bandwidths compared to semiparametric Epanechnikov kernel matching under probit
Specification 1 is about 60% in terms of MSE (and 30% in terms of median absolute error), but
the efficiency gains if the parametric propensity score is misspecified (Specification 3) are rather
modest. For sample size n = 400, semiparametric PSM under Specification 3 performs often
quite a lot worse than nonparametric covariate matching and nonparametric PSM with multiple
bandwidths, but the efficiency losses of the nonparametric estimators compared to Specification 1 can also sometimes be rather large.
The results of this limited Monte Carlo study do not allow for very general conclusions as
the observed patterns vary between the designs and sample sizes. Still, some patterns regarding
the ordering among the various estimators can be extracted. Among the PSM estimators, pair
matching is usually inferior to kernel matching and ridge matching. Ridge matching performed
somewhat better than kernel matching in the simulations with five continuous variables, while
this relationship was less clear in the simulations with 10 binary variables.
Among the nonparametric estimators, the estimators based on kernel regression with multiple
bandwidths usually performed best. For relatively large samples (1600 observations and 5 to
10 regressors), nonparametric PSM can often be more precise than nonparametric covariate
matching, whereas nonparametric PSM can be poor in small samples, presumably due to the
two smoothing and bandwidth choice steps.
The performance of semiparametric PSM compared to the nonparametric estimators depends
on the degree of misspecification of the parametric component. Semiparametric PSM often
performs much worse than nonparametric estimation for a moderately misspecified propensity
score (Specification 3). Even when the probit model is only mildly misspecified (Specification 2,
with a correlation of 0.96 with the true propensity score), semiparametric PSM often performs
worse than nonparametric PSM in the design with five continuous regressors and n = 1600.
Hence, nonparametric PSM can be a more robust competitor to semiparametric PSM, provided
the sample size is reasonably large.

4. GENDER WAGE GAP AND PROPENSITY SCORE MATCHING
In this section, PSM is applied to examine the gender wage gap in the UK. The gender wage
gap has been of long-standing political concern as an indicator of discrimination against women.
The fact that women are paid substantially lower wages than men may be the result of wage
discrimination in the labour market. On the other hand, part of this wage gap may be due to
differences in education, experience and other skills, whose distribution differs between men and
women. Machin and Puhani (2003) pointed out that the substantial wage differences between

C Royal Economic Society 2007

378

Markus Frölich

male and female UK university graduates can be explained to a large extent by the observation
that men and women choose to study different subjects. When including subject of degree in a
Blinder–Oaxaca decomposition, the fraction of the wage gap explained increases from less than
a half to two-thirds. In the following analysis it is investigated, whether and how these results
change when the counterfactual is estimated by PSM and at which points in the wage distribution
the subject of degree matters most.
The Blinder (1973) and Oaxaca (1973) decomposition decomposes the average gender wage
gap into an explained and an unexplained part.25 Separate (log) wage regressions are estimated
for men (Y i = β m X i + εi ) and for women (Y i = β w X i + εi ), where X are human capital variables
characterizing productivity. The average wage gap Ȳm − Ȳw can be expressed as the sum of two
components: βm ( X̄ m − X̄ w ) + (βm − βw ) X̄ w . The first part is attributed to differences in average
characteristics between men and women. The second part is due to differences in average returns
to the individual characteristics, which may reflect discrimination.26 βm X̄ w represents the wage
for women if they were paid as men (i.e. if they received the same returns to their human capital
as men do). It also represents the wage for men, if they had the average human capital endowment
of women.
Several recent studies have demonstrated that the functional form assumptions inherent in
the parametric Blinder–Oaxaca decomposition can give misleading results (See e.g. Barsky et al.
2002; Mora 2008; Nopo 2004). Nonparametric approaches differ from the parametric approach
in two aspects: First, the regression function is no longer specified as linear. Second, the adjusted
mean wage is simulated only for the common support subpopulation. Let m w (x) ≡ E[Y |X =
x, D = w] denote the mean wage for women with characteristics x, and let f w (x) denote the
distribution of X among women. Define m m (x) and f m (x) analogously for men. Let S denote
the common support of f w and f m . For the common support subpopulation, the counterfactual
wages can be simulated and the gender wage gap can be decomposed into an explained and an
unexplained part:



E
[Y |D = m] − SE [Y |D = w] = m m (x) · f mS (x) − f wS (x) d x
S

+

S

(m m (x) − m w (x)) · f wS (x)d x,

S

f mS (x)

where
= f m (x)/PS|m and f wS (x) = f w (x)/PS|w are the densities of X in the subpopulations
of men and women belonging to the common support. As in the Blinder–Oaxaca decomposition,
the first term represents the part of the gender wage gap (in the common support subpopulation)
that can be attributed to differences in the distribution of human capital variables between men
and women. The second part is due to differences in returns to these variables, which may (partly)
reflect discrimination. Separating these two components requires an estimate of the wage men
would earn if they had the human capital characteristics of women:

m m (x) · f wS (x)d x,
(14)
S

which corresponds to βm X̄ w in the Blinder–Oaxaca decomposition.
25 For

an overview, see Blau and Kahn (1997) and Altonji and Blank (1999).
a constant term is included in X. The component of β m − β w corresponding to the constant captures the pay
difference that can be attributed neither to different characteristics nor to different rewards.
26 Usually,


C Royal Economic Society 2007

379

Propensity score matching
Table 3. Descriptive statistics and subject of degree.
Full sample
Variable

Men

Women

Gross hourly wage in £
log(hourly wage)
Age in years

14.01

10.90

2.47
39.1

2.26
36.3

Full-time employed

96.3%

76.1%

Employed in private sector

60.2%

40.5%

Medicine

4.5%

8.5%

Biological science
Veterinary science

4.1%
0.1%

6.4%
0.2%

Agricultural science
Physical and mathematical sciences
Engineering/technology
Architecture and planning
Social sciences and business
Language studies
Humanities, creative arts, education
Not classifiable, combined studies

2.5%
16.5%
18.5%
3.4%
28.7%
3.6%
13.4%
4.8%

2.2%
7.8%
1.5%
0.8%
26.1%
11.4%
29.1%
6.0%

Number of observations

2983

2183

Note: UK labour force survey 1996, data coded as in Machin and Puhani (2003).

The data used by Machin and Puhani (2003) are based on the UK labour force survey for 1996,
where observations with missing information on earnings or other key explanatory variables were
deleted. In the survey, university graduates were asked to report the subject of study of their degree,
where they could choose from 124 different subjects, of which 102 subjects are observed in the
data. Descriptive statistics are given in Table 3, where for the purpose of exposition, these 124
subjects are summarized into 11 broader categories. Clear differences in the patterns of degrees
between men and women can be seen. Men are more likely to study physical and mathematical
sciences and engineering, while women are more likely to enrol in humanities, creative arts and
education.
The average wage gap is 3.10 £ (or 0.208 in log units). Machin and Puhani (2003) conducted
various Blinder–Oaxaca decompositions to analyze this wage differential. In their preferred
specification, they control for age, age squared, part-time work, public sector employment,
10 regional dummies and nine industry dummies.27 The estimated male counterfactual

27 Specification 2 in Machin and Puhani (2003). In an alternative specification, they also control for occupation, where
the additional explanatory power of subject of degree nevertheless persists, increasing the fraction of the gap explained
from 53% to 70%. They argue in favour of the specification without occupation because of the endogeneity of occupational
choice.


C Royal Economic Society 2007

380

Markus Frölich

log wage βm X̄ w is 2.37, hence 46% of the wage gap is explained by gender differences in these
characteristics. When accounting additionally for the subject of degree, the male counterfactual
log wage is 2.33, implying that 66% of the wage gap is explained. When the same analysis
is performed with wages instead of log wages, the counterfactual wage is 14.03£ without
subject of degree and 13.30£ when controlling for it. Hence, without controlling for degree
virtually nothing can be explained by the characteristics, while 23% is explained with the
degree.
Now analyzing the gender wage gap by PSM, a nonparametric and a parametric estimate
of the propensity score are examined. In the semiparametric PSM estimation, the propensity
score is estimated by a probit model Pr(D = w|X = x) = (x  β) with age and age squared as
continuous regressors and dummy variables for full-time employment, public sector employment,
nine regional dummies, eight industry dummies and 101 subject of degree dummies (in total 122
regressors). For decomposing the wage gap if the subject of degree were not available, also the
propensity score without the subject of degree dummies is estimated analogously.
For nonparametric PSM, the propensity score is estimated by kernel regression with
multiplicative hybrid kernel weights w(X j ,x) to account for ordered and unordered
regressors:
w(X j , x) = φ

X age, j − xage
h1

6

1(X k, j =xk )

hk

,

k=2

where h1 is the bandwidth for age, and h 2 , . . . , h 6 are the bandwidths for the regressors: full-time
employed (binary), private sector employed (binary), region (coded as 1 to 10), industry (coded
as 1 to 9) and subject of degree (coded as 1 to 106). The bandwidths (h 1 , . . . , h 6 ) minimizing
the cross-validation criterion are: 0.604, 0.012, 0.768, 0.998, 0.445, 0.004. The bandwidths
chosen for the propensity score without subject of degree are: 0.359, 0.001, 0.146, 0.997,
0.013.
For estimating the common support, the trimming approach of Heckman et al. (1997,
appendix C) is used.28 With the estimates of the propensity score P ≡ Pr(D = w|X ) including
subject of degree, the densities of the propensity score f (P|D = m) and f (P|D = w) are estimated
nonparametrically at all sample values of P, using a biweight kernel and bandwidths chosen by
the rule-of-thumb of Silverman (1986).29 In a first instance, all observations with a propensity
score where either fˆ(P|D = m) or fˆ(P|D = w) is zero are deleted, which did not occur for the
chosen bandwidths. Of the remaining observations, another 2% with very low density values are
trimmed. Only observations with min( fˆ(P|D = m), fˆ(P|D = w)) > τ are retained, thus giving
5063 in-support observations.
The mean gender wage gap in the common support population is 3.10£ and thus similar to
the full population. Figure 3 shows the distribution functions for male and female wages and the
implied absolute and relative quantile wage gap. The absolute wage gap at, e.g., the 20% quantile
is the difference between the wage at the 20% quantile in the male distribution and the wage

28 See

also Heckman et al. (1998, 1998) and Smith and Todd (2005, p. 317). The following graphs refer to the
nonparametrically estimated propensity score, but the results are virtually identical when using the parametrically estimated
propensity score.
29 K (u) = 15 (1 − u 2 )2 · 1(|u| < 1), with h
−0.2 min(σ , interquartile range/1.34) by Silverman’s rule for
opt = 2.7768n
16
a bivariate kernel. For the nonparametric propensity score, this gives 0.098 for estimating f (P|D = m) and 0.129 for
estimating f (P|D = w).

C Royal Economic Society 2007

381

Propensity score matching

Figure 3. Distribution functions and quantile wage gap for common support population.
Left graph: cdf of wages for men and women; middle graph: absolute quantile wage gap (Q θ |men − Q θ |women );
right graph: relative quantile wage gap (Q θ|men /Q θ|women ).
Table 4. Decomposition of the mean gender wage gap (2% trimming common support).
With subject of degree
Without subject of degree
Adjusted wage £

% explained

Adjusted wage £

% explained

Semiparametric PSM
Pair matching
Kernel Gauss matching
Kernel Epa matching
Ridge Gauss matching
Ridge Epa matching

11.69 (0.64)
12.15 (0.45)
12.01 (0.38)
11.75 (0.44)
11.70 (0.37)

76.1 (20.0)
61.2 (13.1)
65.7 (11.1)
74.1 (12.7)
75.8 (10.2)

12.13 (0.80)
12.65 (0.53)
12.67 (0.50)
12.56 (0.54)
12.57 (0.50)

61.6 (25.1)
44.7 (13.6)
44.0 (11.9)
47.6 (13.9)
47.2 (11.5)

Nonparametric PSM
Kernel Gauss matching
Kernel Epa matching

12.04 (0.52)
11.78 (0.43)

63.5 (17.3)
71.6 (14.4)

12.35 (0.31)
12.25 (0.27)

53.4 (10.2)
56.7 (9.2)

Note: Bandwidths used for PSM for the various estimators, with subject of degree: 0.119, 0.202, 0.119, 0.202, 0.119,
0.202; without subject of degree: 0.024, 0.070, 0.119, 0.343, 0.070, 0.119. Standard errors are in brackets (simulated with
1000 bootstrap replications).

at the 20% quantile in the female distribution.30 The relative wage gap is the quotient of these
two wages. Figure 3 thus shows that men at the 20% quantile earn about 1.2 £ (or 20%) more
than women at the 20% quantile of their wage distribution. For higher quantiles, the wage gap is
increasing not only in absolute but also in relative magnitude.
To decompose the average wage gap for the common support population, the male
counterfactual wage is estimated by adjusting the male wages for the different distribution of
the propensity score among men and women. Table 4 shows the adjusted wage and the implied
percentage of the gap explained by the explanatory characteristics for various estimators, on the
left when the subject of degree information is included, on the right when it is neglected. The
definition of the common support is always based on the propensity score with the subject of

30 That

is, it is the horizontal distance between the two distribution functions in the leftmost graph in Figure 3.


C Royal Economic Society 2007

382

Markus Frölich

degree information.31 The results are similar for the various estimators and suggest that about
70% of the wage gap can be explained by differences in the explanatory characteristics. Without
the subject of degree information, the percentage explained is about 50%. (In terms of log wages,
the percentage explained is about 80% with the subject of degree information and about 60%
without it, see the supplementary appendix.) Hence, the percentage of the wage gap explained by
all these characteristics is even larger than in the parametric Blinder–Oaxaca decomposition of
Machin and Puhani (2003), whereas the incremental explanatory power of the subject of degree
information is with 20 percentage points of a very similar magnitude. These results are robust to
variations in the trimming level (as can be seen in the Appendix).
Having found that subject of degree contributes substantially to explaining the wage gap, it
is now interesting to examine at which part of the wage distribution it is most relevant. To this
end, the distribution function F Y |D=m (a) is adjusted for differences in the covariates among men
and women. Noting that F Y |D=m (a) can be written as E[1(Y ≤ a)|D = m], the gender gap in the
distribution functions F Y |D=m (a) − F Y |D=w (a) can be decomposed analogously to the average
gap. Let FY |D=m,S (a) denote the distribution function among men with characteristics belonging
to the common support S. The adjusted distribution function for men is

∗
FY |D=m,S (a) =
FY |X ,D=m (a, x) · f wS (x)d x,
S

where F Y |X,D=m is the conditional cdf given X. It represents the wage distribution that would
prevail among men if they had the human capital characteristics of women. A matching estimator
of the adjusted cdf is
F̂Y∗|D=m,S (a) =

1
n Sw



F̂Y |X ,D=m (X i )

i:Di =w,X i ∈S

where F̂Y |X ,D=m (x) is a nonparametric estimate of the conditional cdf F Y |X,D=m (a, x) and n Sw is
the number of female observations with characteristics in the common support. The conditional
cdf can be estimated by nonparametric regression of the binary variable 1(Y ≤ a) on X in the
male subpopulation belonging to the common support. Instead of regressing and matching on
covariates X, matching can also proceed on the propensity score as proven in Theorem 1.
Nonparametric PSM estimates of the quantile wage gap after adjusting for differences
in covariates are shown in Figure 4. The top panel shows the results with the subject of
degree information, the bottom panel without it. The solid lines are identical to Figure 3 and
give the unadjusted wage gap between the observed male and female cdf. The dashed line is the
wage gap after adjustment for the covariate distributions, i.e. the difference between the adjusted
male cdf and the observed female cdf. This line shows which part of the wage gap is not explained.
Without the subject of degree information (lower panel), the unexplained wage gap increases
for higher wages, not only in absolute but also in relative terms. At the 10th percentile, the wage gap
is fully explained by the covariates, whereas at the top end of the wage distribution the explanatory
power of the covariates almost shrinks to zero. Now adding the subject of degree information (top
panel), it helps little to explaining the wage gap at low quantiles. On the other hand, its explanatory
power increases steadily with the wage position and contributes substantially to explaining the
31 That is, the estimates on the left and on the right in each row are based on exactly the same observations (also in the
bootstrap). Further results for alternative trimming levels and for log wages are given in the appendix.


C Royal Economic Society 2007

Propensity score matching

383

Figure 4. Decomposition of the quantile wage gap with PSM.
Absolute and relative quantile wage gap after adjusting for differences in covariates, using the nonparametric propernsity
score. Solid lines are unadjusted and identical to Figure 3. Dashed lines are after adjustment including subject of degree
(top panel) and without subject of degree (bottom panel). Bandwidth h = 0.202.

wage gap for high wage earners (with respect to the absolute and the relative gap). At the top end
of the wage distribution, only about £1 of the 4 to 7£ wage gap remains unexplained. Hence,
differences in the subjects studied between men and women help substantially in explaining wage
differences, particularly for higher wages.

5. CONCLUSIONS
In this paper, the versatility of PSM has been demonstrated. First, it has been shown that the
justification of PSM as an alternative to matching on X does not depend on a conditional
independence assumption or other properties of potential outcomes. PSM can be used to estimate
not only the adjusted mean outcome, but also its density and distribution functions, and these
results extend, with appropriate modifications, to the case of non-random sampling.
PSM was applied to analyze the gender wage gap among college graduates in the UK. It
was found that subject of degree is an important variable to explaining the wage differences
between men and women, and its contribution appeared to be even greater than the parametric
Blinder–Oaxaca decomposition had suggested. This contribution is not uniform across the wage

C Royal Economic Society 2007

384

Markus Frölich

distribution, though: Whereas it helped relatively little to explain wage differences at the lower
end, at the higher end it demonstrated that the large wage differential between high-earning men
and high-earning women is to a large extent the result of men and women choosing different
subjects in university.

ACKNOWLEDGEMENTS
The author is also affiliated with the Swiss Institute for International Economics and Applied Economic
Research (SIAW), the Institute for Labour Market Policy Evaluation (IFAU), Uppsala and the Institute
for the Study of Labor (IZA), Bonn. I am grateful to the UK Data Archive at the University of Essex
for providing the data and to Richard Blundell, Michael Lechner, Stephen Machin, Blaise Melly,
Ruth Miquel, Patrick Puhani, Conny Wunsch, the editor and three anonymous referees for helpful
comments and suggestions. This research was supported by the Swiss National Science Foundation
(project NSF 4043-058311), the Grundlagenforschungsfonds HSG (project G02110112) and the Marie
Curie Individual Fellowship MEIF-CT-2004-006873.

REFERENCES
Altonji, J. and R. Blank (1999). Race and Gender in the Labor Market. In O. Ashenfelter and D. Card (Eds.),
Handbook of Labor Economics, pp. 3143–259. North-Holland, New York.
Barnow, B., G. Cain and A. Goldberger (1981). Selection on observables. Evaluation Studies Review Annual
5, 43–59.
Barsky, R., J. Bound, K. Charles and J. Lupton (2002). Accounting for the black-white wealth gap: A
nonparametric approach. Journal of the American Statistical Association 97, 663–73.
Blau, F. and L. Kahn (1997). Swimming upstream: Trends in the gender wage differential in the 1980s.
Journal of Labor Economics 15, 1–42.
Blinder, A. (1973). Wage discrimination: Reduced form and structural estimates. Journal of Human
Resources 8, 436–55.
Brodaty, T., B. Crpon and D. Fougre (2001). Using matching estimators to evaluate alternative youth
employment programmes: Evidence from France, 1986–1988. In M. Lechner and F. Pfeiffer (Eds.),
Econometric Evaluation of Labour Market Policies, pp. 85–124. Physica/Springer, Heidelberg.
Dawid, A. (2000). Causal inference without counterfactuals. Journal of American Statistical Association
95, 407–48 (with Discussion).
DiNardo, J., N. Fortin and T. Lemieux (1996). Labor market institutions and the distribution of wages,
1973–1992: A semiparametric approach. Econometrica 64, 1001–44.
Frölich, M. (2004). Finite sample properties of propensity-score matching and weighting estimators. The
Review of Economics and Statistics 86, 77–90.
Frölich, M. (2005). Matching estimators and optimal bandwidth choice. Statistics and Computing 15, 197–
215.
Frölich, M. (2006). Nonparametric regression for binary dependent variables. Econometrics Journal 9,
511–40.
Frölich, M., A. Heshmati and M. Lechner (2004). A microeconometric evaluation of rehabilitation of longterm sickness in Sweden. Journal of Applied Econometrics 19, 375–96.
Gerfin, M. and M. Lechner (2002). Microeconometric evaluation of the active labour market policy in
Switzerland. Economic Journal 112, 854–93.

C Royal Economic Society 2007

Propensity score matching

385

Gosling, A., S. Machin and C. Meghir (2000). The changing distribution of male wages in the U.K.. Review
of Economics Studies 67, 635–66.
Heckman, J., H. Ichimura, J. Smith and P. Todd (1998). Characterizing selection bias using experimental
data. Econometrica 66, 1017–98.
Heckman, J., H. Ichimura and P. Todd (1997). Matching as an econometric evaluation estimator: Evidence
from evaluating a job training programme. Review of Economic Studies 64, 605–54.
Heckman, J., H. Ichimura and P. Todd (1998). Matching as an econometric evaluation estimator. Review of
Economic Studies 65, 261–94.
Heckman, J. and S. Navarro-Lozano (2004). Using matching, instrumental variables, and control functions
to estimate economic choice models. The Review of Economics and Statistics 86, 30–57.
Hirano, K., G. Imbens and G. Ridder (2003). Efficient estimation of average treatment effects using the
estimated propensity score. Econometrica 71, 1161–89.
Horowitz, J. and C. Manski (1998). Censoring of outcomes and regressors due to survey nonresponse:
Identification and estimation using weights and imputations. Journal of Econometrics 84, 37–58.
Horvitz, D. and D. Thompson (1952). A generalization of sampling without replacement from a finite
population. Journal of American Statistical Association 47, 663–85.
Imbens, G. and T. Lancaster (1996). Efficient estimation and stratified sampling. Journal of Econometrics
74, 289–318.
Jalan, J. and M. Ravallion (2003). Estimating the benefit incidence of an antipoverty program by propensityscore matching. Journal of Business and Economic Statistics 21, 19–30.
Juhn, C., K. Murphy and B. Pierce (1993). Wage inequality and the rise in returns to skill. Journal of Political
Economy 101, 410–42.
Larsson, L. (2003). Evaluation of Swedish youth labour market programmes. Journal of Human Resources
38, 891–927.
Lechner, M. (1999). Earnings and employment effects of continuous off-the-job training in East Germany
after unification. Journal of Business and Economic Statistics 17, 74–90.
Machin, S. and P. Puhani (2003). Subject of degree and the gender wage differential: Evidence from the UK
and Germany. Economics Letters 79, 393–400.
Manski, C. and S. Lerman (1977). The Estimation of choice probabilities from choice-based samples.
Econometrica 45, 1977–88.
Mora, R. (2008). A nonparametric decomposition of the Mexican American average wage gap. In Journal
of Applied Econometrics (forthcoming).
Nopo, H. (2004). Matching as a tool to decompose wage gaps. IZA Discussion paper 981.
Oaxaca, R. (1973). Male-female wage differences in urban labour markets. International Economic Review
14, 693–709.
Puhani, P. (1999). Evaluating Active Labour Market Policies: Empirical Evidence for Poland during
Transition. Physica, Heidelberg.
Racine, J. and Q. Li (2004). Nonparametric estimation of regression functions with both categorical and
continuous data. Journal of Econometrics 119, 99–130.
Robins, J., A. Rotnitzky and L. Zhao (1995). Analysis of Semiparametric regression models for repeated
outcomes in the presence of pissing data. Journal of American Statistical Association 90, 106–21.
Rosenbaum, P. and D. Rubin (1983). The central role of the propensity score in observational studies for
causal effects. Biometrika 70, 41–55.
Seifert, B. and T. Gasser (1996). Finite-sample variance of local polynomials: Analysis and solutions. Journal
of American Statistical Association 91, 267–75.
Seifert, B. and T. Gasser (2000). Data adaptive ridging in local polynomial regression. Journal of
Computational and Graphical Statistics 9, 338–60.

C Royal Economic Society 2007

386

Markus Frölich

Silverman, B. (1986). Density Estimation for Statistics and Data Analysis. Chapman and Hall, London.
Smith, J. and P. Todd (2005). Does matching overcome LaLonde’s critique of nonexperimental estimators?
Journal of Econometrics 125, 305–53.
Wooldridge, J. (1999). Asymptotic properties of weighted M-estimators for variable probability samples.
Econometrica 67, 1385–1406.
Wooldridge, J. (2002). Econometric Analysis of Cross Section and Panel Data. MIT Press, Cambridge.

A APPENDIX: Theorem 2
Similar to Theorem 1, the first part of Theorem 2 shows that the probability limit of the weighted PSM
estimator (=right-hand side of (A.2)), which is based on the sampling distribution, is identical to the adjusted
mean (11) under the population distribution (=left-hand side of (A.2)).32 To see that the right-hand side
corresponds to the limit of weighted PSM, note that the weighted kernel regression m̂0s (ρ) in (13) converges
to
m0s (ρ) =

E ∗ [Y · W yx|s | p(X ) = ρ, D = s]
E ∗ [W yx|s | p(X ) = ρ, D = s]

under appropriate conditions on the bandwidth sequence. With m̂0s (ρ) converging to m0s (ρ), the limit of the
weighted PSM estimator (12) is

∗
(ρ)dρ.
(A.1)
E ∗ [W yx|t | p(X ) = ρ, D = t] · m0s (ρ) · f p|t
This corresponds to the expressions (A.2), (A.3) and (A.5), respectively, depending on whether p 0 (x), p 0∗ (x)
or p ∗ (x) is used as propensity score.
Theorem 2: Let f 0yx|d be the population density of Y and X in the D = d population. Let f ∗yx|d be the sampling
density and suppose that supp( f ∗yx|d ) = supp( f 0yx|d ). Let w yx|d = f 0yx|d / f ∗yx|d be the known sampling weights.
Let p 0 (x) = Pr0 (D = t|X = x, D ∈ {s, t}) denote the propensity score under the population distribution and let
p ∗ (x) = Pr∗ (D = t|X = x, D ∈ {s, t}) be the propensity score under the sampling distribution. Let p 0∗ (x)
be the propensity score under the population distribution but with choice-based sampling neglected. Let
f p00 , f p00∗ and f p0∗ denote the densities of p 0 , p 0∗ and p ∗ , respectively, under the population distribution, and
let f p∗0 , f p∗0∗ and f p∗∗ denote the corresponding densities under the sampling distribution. The expectation
operator E0 refers to the population distribution and E ∗ to the sampling distribution. Suppose that the
expected values of Y, X and the sampling weights W exist under the population and under the sampling
distribution. The following equivalences hold:
(a) for p 0 (x)
E 0 [E 0 [Y |X , D = s]|D = t]



 E ∗ Y · W yx|s | p 0 (X ) = ρ, D = s

∗
0
· f p∗0 |t (ρ)dρ.
=
E W yx|t | p (X ) = ρ, D = t ·
E ∗ [W yx|s | p 0 (X ) = ρ, D = s]
(A.2)

32 Where for ease of exposition, it has been assumed that the supports of X are identical in source and target population,
such that the conditioning on S is no longer necessary.

C Royal Economic Society 2007

387

Propensity score matching

(b) for p 0∗ (x)




 E ∗ Y · W yx|s | p 0∗ (X ) = ρ, D = s

 · f p∗0∗ |t (ρ)dρ.
= E ∗ W yx|t | p 0∗ (X ) = ρ, D = t ·
E ∗ W yx|s | p 0∗ (X ) = ρ, D = s
(A.3)
(c) and if the sampling design is identical for source and target sample in the sense that
∗
0
f x|t
(x) f x|s
(x)
∗
0
(x)
f x|t
(x) f x|s

=γ

(A.4)

is constant for all x, then for p ∗ (x)



 E ∗ Y · W yx|s | p ∗ (X ) = ρ, D = s

∗
∗

 · f p∗∗ |t (ρ)dρ.
= E W yx|t | p (X ) = ρ, D = t ·
E ∗ W yx|s | p ∗ (X ) = ρ, D = s
(A.5)

B APPENDIX TO SECTION 2
B.1 Proof of Theorem 1
To prove Theorem 1, it is first shown that
{s, t}). By Bayes’ theorem

f p|D=t (ρ)
f p|D=s (ρ)

Pr (D = t| p(X ) = ρ, D ∈ {s, t}) =

=

ρ Ps
1−ρ Pt

for ρ < 1 where P t = Pr(D = t|D ∈

f p|D=t (ρ) · Pr (D = t|D ∈ {s, t})
.
f p|D∈{s,t} (ρ)

By iterated expectations and the definition of the propensity score, it follows also that
Pr (D = t| p(X ) = ρ, D ∈ {s, t}) = E[ Pr (D = t|X , D ∈ {s, t}) | p(X ) = ρ, D ∈ {s, t}]
= E[ p(X ) | p(X ) = ρ, D ∈ {s, t}] = ρ.
Both results together thus imply that
f p|D=t (ρ) · Pt
=ρ
f p|D∈{s,t} (ρ)
and
f p|D=t (ρ)
ρ Ps
=
f p|D=s (ρ)
1 − ρ Pt

for ρ < 1.

With this result, Theorem 1 can be proven. The left-hand side of (9) can be written as
E [ξ y|x,d (X , s) |D = t]

1(x ∈ S)
= ξ y|x,d (x, s) · f x|D=t (x)
dx
Pr(X ∈ S |D = t)

1(x ∈ S)
p(x) Ps
=
ξ y|x,d (x, s) · f x|D=s (x)
dx
1 − p(x) Pt Pr(X ∈ S |D = t)

S


C Royal Economic Society 2007

(B.1)

388

Markus Frölich

since

p(x)
1− p(x)

=

f x|D=t Pt
f x|D=s Ps

for x ∈ S by Bayes’ theorem.


= E ξ y|x,d (X , s)


Ps
p(X )
|D = s
.
1 − p(X )
Pr(X ∈ S |D = t) · Pt

Using iterated expectation gives
 


p(X )
Ps
= E E ξ y|x,d (X , s)
| p(X ) = P, D = s |D = s
1 − p(X )
Pr(X ∈ S |D = t) · Pt




P
Ps
=E
.
E ξ y|x,d (X , s) | p(X ) = P, D = s |D = s
1− P
Pr(X ∈ S |D = t) · Pt
The right-hand side of (9) can be written as
E [ξ y| p,d (P, s) |D = t]

1(ρ < 1)
= ξ y| p,d (ρ, s) · f p|D=t (ρ)
dρ
Pr(P < 1|D = t)

1(ρ < 1)
ρ Ps
= ξ y| p,d (ρ, s) · f p|D=s (ρ)
dρ
1 − ρ Pt Pr(P < 1|D = t)


P
Ps
= SE ξ y| p,d (P, s) ·
|D = s
1− P
Pr(P < 1|D = t) · Pt

S

by (B.1). Noting that Pr(X ∈ S|D = t) = Pr(P < 1|D = t) by the definition of the propensity
score. Hence, the left- and the right-hand side of (9) are identical if condition (8) holds.
B.2 Proof of Theorem 2, Part A
It is to be shown that
E 0 [E 0 [Y |X , D = s] |D = t]



 E ∗ Y · W yx|s | p 0 (X ) = ρ, D = s

∗
0
 · f p∗0 |t (ρ)dρ.

=
E W yx|t | p (X ) = ρ, D = t ·
E ∗ W yx|s | p 0 (X ) = ρ, D = s
The propensity score under the population distribution is p 0 (x) = f 0x|t P 0t / f 0x|D∈{s,t} . The
propensity score under the sampling distribution is p ∗ (x) = f ∗x|t P ∗t / f ∗x|D∈{s,t} . Define the
equivalence classes χ (ρ) as the set of all (y, x) values where a deterministic function of (y,
x) takes the value ρ, such that the union of the equivalence classes corresponds to the support
of (Y , X ). In particular, define χ 0 (ρ) = {(y, x) : p 0 (x) = ρ} as the equivalence classes with
respect to the propensity score p0 . Let χ ∗ (ρ) = {(y, x) : p ∗ (x) = ρ} be the equivalence classes
with respect to p ∗ . The measure of the set χ ∗ (ρ) under the sampling distribution in the D = d
population is

∗
(y, x) d yd x.
f p∗∗ |d (ρ) =
f yx|d
χ ∗ (ρ)

C Royal Economic Society 2007

389

Propensity score matching

The measure of χ ∗ (ρ) under the population distribution is




f p0∗ |d (ρ) =

∗
(y, x) d yd x.
w yx|d (y, x) f yx|d

0
(y, x) d yd x =
f yx|d
χ ∗ (ρ)

χ ∗ (ρ)

The corresponding measures for χ 0 (ρ) are
f p∗0 |d (ρ)





∗
f yx|d

=

(y, x) d yd x

and

∗
(y, x) d yd x.
w yx|d (y, x) f yx|d

=

f p00 |d (ρ)

χ 0 (ρ)

χ 0 (ρ)

Now examine the term
E

∗







∗
w yx|t (y, x) · f yx|t,
p 0 =ρ (y, x)d yd x.

W yx|t | p (X ) = ρ, D = t =
0

χ 0 (ρ)
∗
By noting that f yx|t,
f ∗ for every (y, x) ∈ χ 0 (ρ), it follows
p 0 ∝ρ yx|t


=

χ 0 (ρ)

∗
w yx|t (y, x) f yx|t
(y, x)d yd x


χ 0 (ρ)

=

∗
f yx|t
(y, x)d yd x

f p00 |t (ρ)
f p∗0 |t (ρ)

.

(B.2)

And analogously for the source population:
f p00 |s (ρ)


E ∗ W yx|s | p 0 (X ) = ρ, D = s = ∗
.
f p0 |s (ρ)

(B.3)

Now consider the term
E

∗







∗
y · w yx|s (y, x) · f yx|s,
p 0 =ρ (y, x)d yd x

Y · W yx|s | p (X ) = ρ, D = s =
0


=

χ 0 (ρ)

y · w yx|s (y, x) ·

χ 0 (ρ)


χ 0 (ρ)


=

y·

∗
f yx|s
(y, x)d yd x

0
(y, x)
f yx|s

χ 0 (ρ)

∗
f yx|s
(y, x)d yd x

f p00 |s (ρ)

d yd x ·

= E 0 [Y | p 0 (X ) = ρ, D = s]

C Royal Economic Society 2007

f p00 |s (ρ)
f p∗0 |s (ρ)
f p00 |s (ρ)

f p∗0 |s (ρ)



0
(y, x) d yd x/ f p∗0 |s (ρ)
y · f yx|s

=
χ 0 (ρ)



y·

=
χ 0 (ρ)

0
f yx|s,
p 0 =ρ (y, x)d yd x

f p00 |s (ρ)

f p∗0 |s (ρ)
(B.4)

390

Markus Frölich

Inserting (B.2), (B.3) and (B.4) in (A.2) gives


 E ∗ [Y · W yx|s | p 0 (X ) = ρ, D = s]

E ∗ W yx|t  p 0 (X ) = ρ, D = t ·
· f p∗0 |t (ρ)dρ
E ∗ [W yx|s | p 0 (X ) = ρ, D = s]

=

=

 f 0 (ρ)
p 0 |t
f p∗0 |t (ρ)

·

E 0 [Y | p 0 (X ) = ρ, D = s]
f p00 |s (ρ)/ f p∗0 |s (ρ)

f 00 (ρ)
p |s

f ∗0 (ρ)
p |s

· f p∗0 |t (ρ)dρ

E 0 [Y | p 0 (X ) = ρ, D = s] · f p00 |t (ρ)dρ = E 0 [E 0 [Y | p 0 (X ) = P, D = s] |D = t],

where all expectation operators are now with respect to the population distribution. Hence,
applying Theorem 1 proves the equality:
= E 0 [E 0 [Y |X , D = s] | D = t].

B.3 Proof of Theorem 2, Part B
The equality (A.3) of Theorem 2 shows the equivalence of using p 0∗ (x) instead of p 0 (x):



 0

 E ∗ Y · W yx|s | p 0 (X ) = ρ, D = s
∗


 · f p∗0 |t (ρ)dρ
E W yx|t p (X ) = ρ, D = t ·
E ∗ W yx|s | p 0 (X ) = ρ, D = s



 0∗

 E ∗ Y · W yx|s | p 0∗ (X ) = ρ, D = s
∗

 · f p∗0∗ |t (ρ)dρ.
= E W yx|t  p (X ) = ρ, D = t ·
E ∗ W yx|s | p 0∗ (X ) = ρ, D = s
Since all but the last of the derivations of the proof of Theorem 2 Part A can also be performed
analogously with p 0 (x) replaced by p 0∗ (x), it remains to be shown that


E 0 [Y | p 0∗ (X ) = ρ, D = s] · f p00∗ |t (ρ)dρ = E 0 [Y | p 0 (X ) = ρ, D = s] · f p00 |t (ρ)dρ.
(B.5)
By definition of the propensity scores:
0
(x) Pt0
f x|t
p 0 (x)
=
0
1 − p 0 (x)
f x|s
(x) Ps0

and
0
(x) Pt∗
f x|t
p 0∗ (x)
.
=
0
1 − p 0∗ (x)
f x|s
(x) Ps∗

Taking the ratio of both expressions gives
p 0∗ (x) 1 − p 0 (x)
Pt∗ Ps0
= α + 1,
=
1 − p 0∗ (x) p 0 (x)
Ps∗ Pt0

C Royal Economic Society 2007

391

Propensity score matching
P∗ P0

where α is defined as α = Pt∗ Ps0 − 1. Hence, α > 0 if the target population is oversampled, and
s
t
α = 0 if there is no choice-based sampling. This gives
p 0 (x) =

p 0∗ (x)
.
α + 1 − α p 0∗ (x)

Hence, there is a strictly positively monotonous one-to-one correspondence between the
propensity score p 0 (x) under the population distribution and p 0∗ (x), where choice-based sampling
is neglected.33 It follows that a direct mapping between the distribution functions of p 0 (x) and
p 0∗ (x) exists:
F p00∗ |t (ρ) = F p00 |t

ρ
α + 1 − αρ

0 < ρ < 1,

because the sets of (y, x) values where the indicator function is non-zero is identical in F p00∗ |t (ρ) =


ρ
ρ
0
0
1( p 0∗ (x) ≤ ρ) f yx|t
(y, x)d yd x and in F p00 |t ( α+1−αρ
) = 1( p 0 (x) ≤ α+1−αρ
) f yx|t
(y, x)d yd x.
With these results, the left-hand side of (B.5) can be written as

d F p00∗ |t (ρ)
E 0 [Y | p 0∗ (X ) = ρ, D = s] ·
dρ
dρ


ρ

 d F 00

p |t α+1−αρ
ρ
= E 0 Y | p 0 (x) =
,D =s ·
dρ
α + 1 − αρ
dρ

= E 0 [Y | p 0 (x) = u, D = s] · f p00 |t (u) du,
ρ
where u = α+1−αρ
, which is identical to the right-hand side of (B.5). Hence choice-based sampling
can be neglected for PSM.

B.4 Proof of Theorem 2, Part C
To prove the equality (A.5) of Theorem 2, it must be shown that


0
∗
0
E [Y | p (X ) = ρ, D = s] · f p∗ |t (ρ)dρ = E 0 [Y | p 0 (X ) = ρ, D = s] · f p00 |t (ρ)dρ.
(A.7)
With
∗
(x) Pt∗
f x|t
p ∗ (x)
,
=
∗
1 − p ∗ (x)
f x|s (x) Ps∗

the odds ratio is
∗
0
∗
0
(x) Pt∗ f x|s
(x) Ps0
(x) f x|s
(x)
f x|t
f x|t
p ∗ (x) 1 − p 0 (x)
(α + 1) = γ (α + 1) ,
=
=
∗
∗
0
0
0
1 − p ∗ (x) p 0 (x)
f x|s (x) Ps∗ f x|t (x) Pt
f x|t (x) f x|s (x)

33 The

first derivative is

dp 0 (x)
dp 0∗ (x)


C Royal Economic Society 2007

=

α+1

(α+1−α p0∗ (x))2

which is always positive, because α + 1 is always positive.

392

Markus Frölich
Table C1. Distribution of X in source and target population, ε ∼ N (0, 30).
Source population (D = 0)
Target population (D = 1)

X1
X2
X3
X4
X5

5%

25%

Median

75%

95%

5%

25%

Median

75%

95%

−2.71
−1.91
−1.07
−2.58

−1.45
−1.01
−0.21
−1.10

−0.59
−0.40
0.40
0.45

0.25
0.21
1.01
1.80

1.45
1.08
1.91
2.77

−1.36
−1.02
−1.94
−2.77

−0.17
−0.16
−1.06
−1.82

0.67
0.45
−0.44
−0.50

1.52
1.06
0.16
1.05

2.76
1.95
1.02
2.56

0.00

0.11

0.50

1.46

4.21

0.00

0.09

0.41

1.18

3.41

Note: Percentiles of X in source and target population.

Table C2. Distribution of X in source and target population, ε ∼ N (0, 100).
Source population (D = 0)
Target population (D = 1)

X1
X2
X3
X4
X5

5%

25%

Median

75%

95%

5%

25%

Median

75%

95%

−2.64
−1.86
−1.30
−2.63
0.00

−1.32
−0.92
−0.37
−1.24
0.11

−0.41
−0.27
0.27
0.31
0.49

0.50
0.37
0.92
1.71
1.42

1.80
1.30
1.86
2.75
4.11

−1.77
−1.28
−1.87
−2.75
0.00

−0.47
−0.35
−0.94
−1.72
0.09

0.44
0.29
−0.29
−0.33
0.42

1.35
0.94
0.35
1.23
1.23

2.67
1.87
1.28
2.62
3.54

Table C3. Distribution of X in source and target population, ε ∼ χ 2(5) .
Source population (D = 0)

X1
X2
X3
X4
X5

Target population (D = 1)

5%

25%

Median

75%

95%

5%

25%

Median

75%

95%

−2.63
−1.85
−1.18
−2.61
0.00

−1.33
−0.93
−0.32
−1.20
0.11

−0.45
−0.30
0.30
0.35
0.49

0.42
0.32
0.93
1.73
1.42

1.61
1.18
1.85
2.75
4.12

−1.66
−1.20
−1.95
−2.77
0.00

−0.34
−0.27
−1.03
−1.79
0.09

0.58
0.39
−0.39
−0.43
0.41

1.49
1.03
0.26
1.13
1.20

2.78
1.95
1.20
2.59
3.50

Note: ε ∼ χ 2(5) scaled to mean 0.5 and variance 67.6.

by assumption (A.4). The rest of the proof is identical to the proof of Theorem 2b, starting from
(B.6) with (α + 1) replaced by γ (α + 1).

C APPENDIX TO SECTION 3
This appendix contains additional information about the simulations of Section 3. The Tables C.1
to C.4 show the distributions of X in the source and target populations. Tables C.5 and C.6 contain
the simulated median absolute error to complement the MSE of Tables 1 and 2.
Tables C.7 – C.10 contain additional simulation results for propensity score weighting
estimators, as suggested by Horvitz and Thompson (1952) and Hirano et al. (2003). Propensity

C Royal Economic Society 2007

393

Propensity score matching

Table C4. Means of X in source and target population, Monte Carlo with 10 binary variables.
X1
X2
X3
X4
X5
X6
X7
X8
X9
X 10
ε ∼ N (0, 100)
D=0
D=1

−0.13 −0.14
0.13

0.14

−0.14

−0.15

−0.15

−0.15

−0.15

−0.16

−0.16

−0.16

0.14

0.15

0.15

0.15

0.15

0.16

0.16

0.16

−0.08

−0.08

−0.08

−0.08

−0.08

−0.09

−0.09

−0.09

0.08

0.08

0.08

0.08

0.08

0.09

0.09

0.09

−0.12
0.12

−0.12
0.12

−0.12
0.12

−0.13
0.12

−0.13
0.12

−0.13
0.13

−0.13
0.13

−0.13
0.13

ε ∼ N (0, 400)
D=0
D=1

−0.07 −0.08
0.07

0.08

ε ∼ χ 2(5)
D=0
−0.11 −0.12
D=1
0.11
0.11

Note: ε ∼ χ 2(5) scaled to mean 2.5 and variance 202.5.

score weighting estimates the adjusted mean as
p̂ j
1 
Yj ·
.
n 1 j:D j =0
1 − p̂ j
Since the ratio p̂ j /(1 − p̂ j ) might be very large for some observations with very large estimated
propensity scores, also a trimmed version of the weighting estimator is considered:


p̂ j
1 
Y j · min
,c ,
n 1 j:D j =0
1 − p̂ j
where the constant c provides a ceiling to the ratio. Five different values for c (2, 5, 10, 20, 50)
were examined in the simulations. The Tables C.7 to C.10 show only the results for c = 5 and 20
and for the untrimmed estimator, the results for the other ceiling levels were similar.
In the simulations with five continuous variables, the weighting estimator is often much worse
than PSM, particularly with a nonparametrically estimated propensity score. It also performs
usually worse than semiparametric Gauss ridge matching and never much better. In the simulations
with 10 binary regressors, the relative performance of weighting improves because the largest
propensity score is quite distant from one, as seen in Figure 2. Therefore, only few estimated
propensity scores are close to one and trimming often has little effect anymore.


C Royal Economic Society 2007

1

2

3

2

3

1

2

ε∼
3

1

2

3

ε ∼ N(0,30)
1

2

3

ε ∼ N(0,100)

n = 400

1

2

ε∼

χ 2(5)
3

1

2

3

ε ∼ N(0,30)
1

2

3

ε ∼ N(0,100)

n = 1600

1

2

ε ∼ χ 2(5)
3

82.2 85.0 50.3 53.4 47.3 38.3 67.6 65.5 46.2 57.3 58.3 39.4 34.2 30.4 28.6 45.8 45.6 35.9 37.3 39.5 30.2 22.8 19.5 19.5 30.9 31.3 26.5

1

ε ∼ N(0,100)

χ 2(5)

Table C5. Median absolute error with five continuous variables.

60.4 50.3 33.9 42.8 36.3 23.7 53.4 47.4 31.7 31.0 22.7 22.5 21.7 17.1 14.4 26.2 25.8 20.2 14.0 10.1 11.5 10.2 8.41 7.19 14.2 15.1 10.9

50.6 37.2 33.8 38.2 28.1 23.3 47.0 34.4 31.4 22.6 18.2 19.5 17.3 13.0 11.5 20.5 18.0 17.8 11.8 9.32 10.5 8.40 6.56 5.95 10.2 10.1 8.87

50.6 38.2 34.1 37.8 28.2 23.3 46.9 35.5 31.1 23.4 18.6 19.2 17.0 13.2 11.5 21.2 18.6 17.8 12.1 9.69 10.5 8.41 6.72 6.41 10.6 9.97 9.11

Kernel Gauss

Kernel Epa

Ridge Gauss

Ridge Epa

63.5 54.0 40.1 48.9 39.3 29.7 59.3 49.5 35.9 39.9 38.1 24.4 26.1 22.2 15.9 34.1 32.1 21.7 32.7 31.7 16.9 17.9 17.5 9.11 24.1 26.4 13.3

82.6 70.2 36.2 51.8 44.6 24.5 68.7 62.0 32.5 55.8 48.5 27.5 33.7 28.2 16.5 43.7 41.6 24.7 42.9 37.9 20.1 24.9 23.8 10.4 34.2 32.8 14.8

80.9 73.9 36.0 52.0 47.3 24.5 67.6 66.1 32.5 56.0 50.1 27.2 32.7 29.8 16.3 42.0 43.7 24.0 42.4 37.8 20.1 24.5 23.8 10.3 32.8 35.2 14.3

65.8 52.9 35.9 42.7 33.1 23.8 56.3 47.3 32.2 40.4 40.8 24.2 23.6 21.2 12.3 29.7 31.8 19.7 35.1 32.9 14.8 17.2 17.9 6.14 24.6 27.5 9.73

65.6 54.8 36.0 42.4 33.9 23.6 57.5 48.8 31.7 41.1 41.1 23.7 23.4 21.3 12.5 30.5 32.5 18.9 35.0 32.8 14.4 17.1 17.2 6.16 25.4 27.6 9.82

Pair Match

Kernel Gauss

Kernel Epa

Ridge Gauss

Ridge Epa

Specification 2

56.4 43.0 39.9 45.7 35.2 29.6 52.9 39.5 35.7 29.3 19.9 22.8 22.8 16.7 15.3 28.5 21.1 20.9 16.3 10.8 12.3 11.7 7.26 7.97 16.1 11.2 11.7

61.9 46.6 33.9 43.3 34.6 23.6 54.7 45.0 31.4 31.1 21.0 23.4 22.0 16.4 14.6 25.4 22.5 21.0 15.2 9.89 12.0 10.5 8.46 7.22 13.7 12.4 10.8

Pair Match

Specification 1

Semiparametric propensity score matching

K one bandwidth 70.5 65.1 43.3 46.4 37.6 33.3 59.0 50.9 41.5 53.0 41.0 33.9 33.0 22.7 25.1 44.3 33.8 31.5 29.3 35.0 25.6 18.5 18.4 18.2 25.6 29.4 23.4
K multi band
61.0 46.1 39.8 42.3 30.1 30.1 52.2 39.4 37.0 39.8 29.0 27.7 25.6 16.7 20.3 34.0 24.9 25.2 28.5 20.9 18.9 18.5 10.2 12.9 25.1 18.2 17.2

Mahalanobis

Nonparametric covariate matching

Y-design

ε ∼ N(0,30)

n = 100

394
Markus Frölich


C Royal Economic Society 2007


C Royal Economic Society 2007

185

187

188

Kernel Epa

Ridge Gauss

Ridge Epa

129

127

143

142

122

2

41.0

40.7

40.6

40.5

45.0

3

114

114

116

116

113

1

75.6 27.4

74.7 27.7

87.9 28.5

86.5 28.5

3
187

121

36.2

106

3

31.2

30.9

96.7 26.9

95.8 27.9

107

105

95.4 26.6

2

183

183

181

180

184

1

119

119

123

123

117

2

30.8

31.4

33.7

33.8

31.7

3

106

106

110

110

107

1

3

1

69.3 13.0 143

69.3 13.9 143

74.5 19.7 145

73.5 19.6 145

70.2 16.6 145

2

3

25.6

94.3 20.1

94.4 20.8

101

99.9 25.4

94.0 21.9

2

88.1 57.9 46.8 61.8 47.8 33.9 76.2 52.4 42.4 33.6 26.9 26.7 27.1 29.4 16.2 32.4 28.0 20.9 17.6 15.7 13.3 14.4 19.3 7.59 15.2 14.2 10.9

Ridge Epa

Note: See note below Table 3.1.

83.7 55.2 43.0 60.9 41.9 31.2 74.0 49.8 40.0 31.3 24.1 27.6 25.2 18.6 17.6 28.9 20.6 23.2 14.7 11.7 15.1 10.3 10.0 8.35 12.3 10.6 11.9

91.6 57.9 46.2 64.8 49.2 33.3 81.2 52.8 41.7 34.1 28.7 26.8 28.6 31.3 15.7 34.9 30.3 21.5 17.3 18.2 11.9 16.1 21.8 7.19 18.1 17.5 10.3

Ridge Gauss

Kernel Gauss

Kernel Epa

88.1 63.8 56.2 68.9 53.7 40.8 82.0 55.8 48.3 44.2 35.3 30.8 31.8 31.8 18.3 38.4 30.5 26.2 23.6 21.1 14.7 17.1 20.8 9.09 20.3 16.9 12.9

90.8 56.2 43.3 63.5 43.8 31.6 79.1 49.5 39.7 32.5 26.2 27.4 26.1 21.8 17.6 31.8 23.2 23.3 14.5 15.7 13.5 12.0 14.5 7.51 15.8 13.6 10.6

Pair Match

Multiple
bandwidths

61.4 48.5 47.8 48.6 43.3 31.0 51.0 43.2 40.2 26.1 29.3 31.4 24.5 30.6 15.7 25.1 36.3 25.6 14.3 12.8 18.2 15.2 24.3 7.50 11.9 12.5 14.9

145

146

146

146

147

1

64.3 49.7 47.3 50.7 44.5 31.2 55.4 44.5 40.7 27.8 31.5 30.9 26.8 32.7 15.7 30.0 40.6 24.7 14.9 12.8 16.2 17.3 27.4 7.36 14.7 15.6 13.5

69.1 17.3

68.8 17.9

78.0 23.4

76.9 23.7

69.0 21.3

3

Ridge Epa

107

107

110

110

2

ε ∼ χ 2(5)

Ridge Gauss

34.0

34.6

37.1

37.1

1

n = 1600
ε ∼ N(0,100)

60.3 48.2 45.5 47.3 39.6 30.6 52.1 44.1 40.4 24.8 20.5 35.6 21.6 26.8 23.6 22.6 20.6 32.6 11.7 11.0 22.3 8.64 11.9 15.9 9.48 8.94 21.4

121

119

130

129

3

ε ∼ N(0,30)

Kernel Epa

184

184

182

182

2

ε ∼ χ 2(5)

65.5 52.2 49.1 54.7 47.9 34.5 60.9 45.9 41.5 35.4 35.2 30.8 31.4 32.8 18.9 34.3 37.5 27.0 19.2 17.9 17.1 18.0 27.1 9.84 17.6 16.7 16.2

34.9

35.4

36.1

36.5

1

n = 400
ε ∼ N(0,100)

63.3 47.9 45.7 46.4 37.6 30.5 54.3 39.8 40.0 27.8 23.9 33.4 21.8 24.8 21.8 26.9 28.3 29.5 13.6 12.4 19.9 10.2 18.9 14.1 11.0 11.0 18.1

104

103

119

117

97.9 39.0

2

ε ∼ N(0,30)

Kernel Gauss

152

152

151

151

153

1

ε ∼ χ 2(5)

Table C5. (Continued).

Pair Match

One bandwidth

3

72.1 32.5

2

ε ∼ N(0,100)

Nonparametric propensity score matching

191

184

Kernel Gauss

1

Pair Match

Specification 3

Y-design

ε ∼ N(0,30)

n = 100

Propensity score matching

395

1

2

3

2

3

1

2

ε∼
3

1

2

3

ε ∼ N(0,100)
1

2

3

ε ∼ N(0,400)

n = 400

1

2

ε∼

χ 2(5)
3

1

2

3

ε ∼ N(0,100)
1

2

3

ε ∼ N(0,400)

n = 1600

1

2

ε ∼ χ 2(5)
3

50.8 35.8 29.8 42.7 31.2 27.8 47.5 34.4 29.2 22.0 19.3 15.3 20.4 17.2 14.2 21.9 17.1 15.7 14.7 13.2 11.8 13.6 11.0 11.0 14.1 12.4 11.6

1

ε ∼ N(0,400)

χ 2(5)

Table C6. Median absolute error with 10 binary variables.

159 69.1 62.2 106 65.0 58.4 133 67.5 64.9 67.7 49.1 19.1 42.8 44.3 26.7 45.9 47.8 22.1 37.1 28.4 6.71 20.3 23.8 9.76 27.2 26.0 7.59

39.2 25.3 22.8 40.9 21.0 20.0 40.4 22.6 20.9 16.7 12.3 9.43 17.2 9.75 8.24 16.2 11.5 9.09 7.72 6.00 4.35 7.94 5.02 4.05 8.02 5.85 4.51

Kernel Epa

Ridge Gauss

46.9 22.8 21.3 40.0 19.2 18.5 46.4 20.3 19.8 19.3 11.9 9.36 17.2 9.67 8.20 18.9 11.5 8.67 10.6 8.21 4.46 7.55 5.89 4.12 9.50 7.23 4.85

40.0 25.3 22.7 40.9 21.3 20.1 40.8 22.3 21.1 17.1 14.2 9.56 16.9 11.1 8.35 16.9 12.5 8.83 10.1 9.14 4.38 7.53 6.24 4.05 9.19 7.40 4.62

39.7 25.2 21.6 39.6 21.4 18.6 41.2 22.5 20.1 17.2 13.9 9.41 17.2 11.2 8.08 17.5 12.7 8.65 10.4 9.50 4.48 7.60 6.26 3.97 9.40 7.64 4.63

Kernel Gauss

Kernel Epa

Ridge Gauss

Ridge Epa

55.5 54.5 26.8 50.0 37.6 25.1 53.2 47.2 25.5 34.1 40.4 16.5 24.9 25.1 13.9 30.4 33.5 16.0 22.0 23.7 12.7 14.5 15.2 11.2 18.9 19.3 11.5

73.9 40.3 24.5 46.3 25.7 20.5 62.6 33.1 23.1 54.6 49.5 13.8 24.2 26.3 9.91 41.8 40.9 12.2 41.3 40.1 10.7 17.8 23.2 6.04 30.5 33.1 8.07

Pair Match

Kernel Gauss

Specification 3

46.9 36.8 26.9 49.8 32.1 25.2 48.9 35.3 25.3 21.0 20.1 15.1 21.4 17.2 13.9 21.2 17.8 15.4 14.5 14.8 12.0 13.6 11.9 11.5 14.1 13.2 11.9

46.4 22.8 22.6 41.2 19.5 20.0 46.1 20.0 20.8 18.9 11.8 9.54 16.8 10.2 8.83 17.9 11.2 9.09 10.2 8.61 4.55 7.57 6.37 4.18 9.36 7.50 4.62

Pair Match

Specification 2

39.4 25.5 21.5 40.0 20.7 18.4 39.8 23.0 19.5 16.9 12.9 9.43 16.9 9.73 8.11 16.2 11.7 8.82 7.74 6.16 4.30 7.68 5.16 4.13 8.07 5.87 4.55

44.0 22.7 21.2 39.9 18.9 18.4 43.9 20.9 18.7 17.4 12.0 9.23 16.9 9.07 8.19 17.7 11.4 8.69 7.84 5.78 4.33 7.66 4.52 4.15 8.11 5.40 4.47

Kernel Gauss

Ridge Epa

46.9 37.2 27.1 50.5 31.3 25.5 48.9 34.4 25.5 21.6 20.0 15.0 21.8 16.9 13.7 21.6 16.4 15.7 14.3 13.5 12.2 12.5 11.5 11.1 13.7 12.4 12.1

43.1 23.0 22.6 41.1 19.3 19.9 43.6 20.5 20.4 17.1 11.7 9.23 16.7 9.18 8.39 16.8 11.1 9.10 7.86 5.67 4.40 8.04 4.64 4.20 8.18 5.43 4.56

Pair Match

Specification 1

Semiparametric propensity score matching

Exact match

K one bandwidth 59.5 29.4 32.2 42.6 26.4 29.0 54.1 27.1 32.1 27.4 19.9 13.2 28.5 19.4 15.9 31.5 18.8 13.9 11.5 12.8 7.51 10.5 11.9 9.06 11.6 11.7 8.08
K multi band
54.6 31.5 27.7 39.6 26.4 24.4 49.0 29.2 26.4 25.3 14.8 11.9 26.7 13.9 12.3 26.9 13.7 12.7 10.6 9.13 6.48 16.1 10.3 6.63 11.1 8.83 6.32

Mahalanobis

Nonparametric covariate matching

Y-design

ε ∼ N(0,100)

n = 100

396
Markus Frölich


C Royal Economic Society 2007


C Royal Economic Society 2007

3

1

2

3

1

2

3

1

2

3

1

2

3

1

2

3

ε ∼ N(0,100)
1

2

3

ε ∼ N(0,400)
1

2

ε ∼ χ 2(5)
3

114

Ridge Epa

120

110

42.1 32.3 45.9 24.9 17.6 46.7 18.7 16.2 42.8 19.3 17.1 16.0 14.2 12.3 17.4 10.7 11.2 15.3 13.3 12.3
25.2 28.6 50.2 15.1 13.1 55.2 11.6 13.6 48.2 13.2 13.2 15.6 9.75 4.91 22.8 6.78 5.77 16.4 7.59 5.54

25.4 29.2

25.3 29.0
113

116

28.8 28.2 52.7 20.5 13.6 56.7 15.5 14.0 49.4 18.9 13.7 17.1 10.2 5.08 23.1 7.24 6.08 17.6 8.55 5.85

28.7 29.5 51.9 20.2 13.3 56.9 15.3 13.5 49.9 18.2 13.2 17.2 9.91 5.16 23.2 6.97 5.79 17.5 7.99 5.47

22.0 27.6 96.4 24.9 26.2 49.4 14.9 13.6 55.1 11.7 14.2 47.5 13.7 13.1 15.6 9.24 5.01 22.7 6.79 6.09 16.5 7.49 5.77

107

98.8 62.9 41.3 94.0 53.6 41.6 94.0 58.4 41.7 38.0 25.1 17.8 35.1 25.2 18.7 34.4 23.8 19.4 15.8 14.6 12.3 16.2 11.0 11.1 14.9 13.0 12.2

33.3 29.0

38.9 32.7

22.4 28.6

84.1 35.1 29.0 66.5 28.2 24.9 75.6 30.0 27.2 37.3 16.7 11.7 29.8 13.6 10.8 32.5 14.7 11.3 13.8 6.91 4.71 18.2 5.94 5.39 13.9 6.30 5.55

Ridge Gauss

Ridge Epa

Note: See note below Table 1.

72.8 30.6 27.6 60.1 25.2 23.1 66.6 28.1 26.1 33.7 15.5 11.6 28.3 12.5 10.6 29.8 13.9 10.5 12.9 6.12 4.57 18.9 5.34 5.24 13.4 5.80 5.42

86.4 35.9 30.6 72.1 29.2 26.0 80.7 31.8 28.8 37.0 16.4 12.1 27.9 13.6 11.0 31.9 14.5 11.1 13.6 6.94 4.66 17.1 5.76 5.20 13.7 6.43 5.34

Kernel Epa

Kernel Gauss 81.4 33.3 30.1 67.7 27.3 25.1 75.8 29.7 28.0 34.6 15.4 11.9 27.2 12.9 10.6 29.8 14.4 10.9 13.2 6.42 4.51 18.2 5.22 5.06 13.4 5.82 5.45

Pair Match

Multiple
bandwidths

109

122

116

33.0 31.1

97.8 28.1 27.1

Kernel Epa

119

Ridge Gauss

47.7 34.7

114

Kernel Gauss

28.6 30.3

112

108

Pair Match

One bandwidth

Nonparametric propensity score matching

64.5 48.4 23.6 43.7 28.6 19.0 54.9 39.1 21.4 56.9 52.1 13.5 27.7 27.2 8.58 41.7 41.7 11.4 50.7 46.2 11.1 25.2 25.1 5.73 37.9 37.6 8.27

2

ε∼

62.5 47.4 23.6 44.2 28.6 20.2 53.4 38.6 22.2 52.7 50.9 13.1 24.4 27.1 9.05 38.4 41.6 11.3 39.6 38.0 9.90 16.9 21.3 5.45 28.4 31.1 7.49

1

ε ∼ N(0,400)

n = 1600

Ridge Epa

3

ε ∼ N(0,100)

χ 2(5)

Ridge Gauss

2

ε∼

n = 400

79.7 39.7 25.1 47.8 25.3 20.1 69.3 33.3 22.7 60.2 49.0 14.9 28.6 26.3 10.1 45.7 41.2 13.1 51.0 47.6 12.5 24.4 26.3 6.98 38.9 39.2 9.58

1

ε ∼ N(0,400)

χ 2(5)

Table C6. (Continued).

Kernel Epa

Y-design

ε ∼ N(0,100)

n = 100

Propensity score matching

397

1

2

3

ε ∼ N(0,30)

1

2

2

3

8.8

387

400

W20

167

165

27.5

26.7

29.4

157

157

158

265

67.6 13.5

89.1 44.3 88.6 55.6 20.7

89.1 44.3 88.6 55.6 20.7

89.1 44.3 88.6 55.6 20.7

206

206

206

W

W5

W20

55.4 47.9 99.6 27.3 27.4

55.5 47.9 99.7 27.3 27.4

55.4 47.9 99.6 27.3 27.4

Multiple bandwidths

189

189

W5

W20

189

W

One bandwidth

153

153

153

138

138

138

262

267

67.1 13.1

68.3 13.5

Nonparametric propensity score matching

404

W

W5

169

20.5

19.8

21.0

43.9 39.9

43.9 39.9

43.9 39.9

77.5 34.5

77.5 34.5

77.5 34.5

117

118

117

118

118

118

125

126

125

357

353

357

14.5

16.6

14.5

120

121

120

51.6

52.7

51.6

5.4

5.5

5.4

4.3

3.5

5.3

5.0

3.3

5.6

3

2

226

226

226

105

106

105

28.2 25.8

31.0 28.0

28.7 25.8

16.0 13.2

17.3 14.3

16.0 13.2

1

ε∼

8.1

8.6

8.1

7.8

8.3

7.8

3

10.6

11.1

10.7

χ 2(5)
2

3

1

2

3

ε ∼ N(0,100)
1

2

ε ∼ χ 2(5)
3

339

338

340

141

149

140

11.3

13.9

11.2

114

115

114

47.9 3.19

48.7 3.34

47.9 3.19

216

216

216

102

103

102

7.79

8.31

7.79

18.9 16.5 4.71 4.59 4.47 1.11 21.5 23.2 5.16

45.4 36.0 10.7 5.71 5.61 1.27 24.1 25.5 5.88

76.6 16.7 5.60 4.59 4.54 1.13 21.5 23.2 5.16

6.02 4.38 3.06 2.00 1.54 1.06 9.96 10.4 4.89

25.9 16.7 8.99 1.86 1.48 0.91 11.4 11.7 5.48

37.5 23.2 7.59 2.06 1.66 1.14 9.96 10.4 4.89

1

ε ∼ N(0,30)

n = 1600

49.8 29.5 45.0 19.9 11.4 83.2 38.1 22.2 67.8 36.8 18.8 19.5 13.2 4.97 46.9 30.1 13.0

50.2 29.7 45.0 19.9 11.4 83.4 38.1 22.3 71.6 38.9 19.7 19.6 13.2 4.99 47.5 30.5 13.1

49.8 29.5 45.0 19.9 11.4 83.2 38.1 22.2 67.8 36.8 18.8 19.5 13.2 4.97 46.9 30.1 13.0

56.0 35.3 53.8 35.5 14.4 94.8 46.8 28.3 81.9 51.2 23.8 26.7 16.8 8.64 58.6 40.2 18.5

56.3 35.4 53.9 35.5 14.4 94.9 46.9 28.4 84.4 52.9 24.4 26.8 16.8 8.65 58.7 40.3 18.6

56.0 35.3 53.8 35.5 14.4 94.8 46.8 28.3 81.9 51.2 23.8 26.7 16.8 8.64 58.6 40.2 18.5

148

154

147

8.7

82.3 55.5 29.6 39.9 29.3 15.2 59.2 44.2 21.3 33.5 25.7 10.1 10.5

W20

Specification 3

9.2

148

85.8 54.7 24.8 33.7 24.0 12.1 58.9 43.5 18.5 55.5 40.6 13.7 10.9

W

9.1

6.0

4.5

7.4

2

W5

97.8 47.8 43.6 34.5 15.8 61.0 45.7 22.7 39.8 34.4 19.9 10.9

9.4

72.5 41.9 32.9 40.3 28.4 18.1 45.3 30.7 21.9 20.6 12.9

W20

Specification 2

6.7

186

9.8

1

64.4 33.4 23.8 27.0 17.8 12.4 42.5 28.0 18.4 35.1 20.2 12.3

77.6 48.6 34.9 19.5 47.5 33.7 23.1 77.7 56.2 23.5

1

n = 400
ε ∼ N(0,100)

W

130

3

ε ∼ N(0,30)

W5

Specification 1

1

3

2

ε∼

χ 2(5)

Table C7. MSE with five continuous variables (propensity score weighting).

ε ∼ N(0,100)

Semiparametric propensity score weighting

ε
Y-design

n = 100

398
Markus Frölich


C Royal Economic Society 2007

1

2

3

ε ∼ N(0,30)

1

2


C Royal Economic Society 2007

3

1

2

3

ε ∼ N(0,30)
1

2

3

ε ∼ N(0,100)

n = 400

1

2

ε∼

χ 2(5)
3

1

2

3

ε ∼ N(0,30)
1

2

3

ε ∼ N(0,100)

n = 1600

1

2

ε ∼ χ 2(5)
3

124

191

192

W5

W20

43.9

45.3

44.0

115

115

115

71.6 28.3

71.8 28.4

71.7 28.3

136

136

W20

87.3 66.1 88.2 65.9 40.7

87.3 66.1 88.2 65.9 40.7

87.3 66.1 88.2 65.9 40.7

142

142

142

W

W5

W20

68.4 69.0 92.2 40.6 47.1

68.4 69.0 92.2 40.7 47.1

68.4 69.0 92.2 40.6 47.1

Multiple bandwidths

136

W

W5

One bandwidth

Nonparametric propensity score matching

124

124

192

W

Specification 3

120

120

120

115

115

115

155

156

155

37.3

37.8

37.3

58.9 60.9

58.9 60.9

58.9 60.9

83.0 56.3

83.0 56.3

83.0 56.3

102

102

102

105

106

105

110

111

110

186

186

186

35.0

38.6

34.9

108

108

108

67.9 19.6

68.7 19.9

67.9 19.6

149

149

149

101

101

101

30.6

31.5

30.6

184

184

184

119

122

118

33.1

36.5

33.0

106

106

106

69.1 16.6

69.3 17.1

69.1 16.6

146

146

146

101

102

101

27.1

28.1

27.1

69.1 53.3 62.3 41.5 29.6 88.2 59.4 45.2 81.2 59.8 42.9 42.5 35.3 21.1 67.8 54.2 35.5

69.3 53.4 62.3 41.5 29.7 88.2 59.5 45.2 83.3 61.9 43.9 42.6 35.5 21.1 68.3 54.6 35.7

69.1 53.3 62.3 41.5 29.6 88.2 59.4 45.2 81.2 59.8 42.9 42.5 35.3 21.1 67.8 54.2 35.5

73.7 58.5 71.5 55.5 36.2 96.3 63.8 53.2 88.6 71.7 47.7 50.9 40.5 28.9 76.4 63.1 42.6

74.0 58.7 71.5 55.5 36.2 96.4 63.8 53.2 89.9 73.1 48.3 50.9 40.6 28.9 76.6 63.1 42.7

73.7 58.5 71.5 55.5 36.2 96.3 63.8 53.2 88.6 71.7 47.7 50.9 40.5 28.9 76.4 63.1 42.6

120

122

120

80.7 65.0 42.0 41.9 34.7 25.1 62.6 55.3 35.2 69.7 61.2 34.1 25.3 23.4 13.5 50.0 50.0 26.1 66.1 59.1 31.7 20.8 20.9 8.60 47.8 49.4 23.2

72.0 61.7 40.2 42.7 37.0 25.8 60.9 54.9 34.7 47.1 43.1 25.1 24.3 22.2 13.8 46.5 47.4 24.8 40.2 37.9 19.7 17.8 18.1 7.50 45.2 47.2 21.5

W5

73.7 63.0 40.8 42.8 37.1 25.8 61.0 55.1 34.7 48.6 44.5 25.8 24.4 22.2 13.8 46.5 47.4 24.8 37.5 35.6 18.1 17.8 18.1 7.51 45.2 47.2 21.5

W20

W

Specification 2

66.6 47.5 40.4 36.2 29.2 24.7 49.2 41.0 34.5 53.0 41.0 31.7 18.1 14.6 12.5 34.0 33.5 25.2 49.5 39.7 29.0 9.16 8.24 6.91 32.3 32.5 22.1

62.5 47.6 39.5 39.3 32.6 25.9 49.4 42.3 34.6 32.6 27.8 22.0 19.3 16.0 12.7 31.6 31.2 23.2 17.8 15.2 13.7 9.61 8.40 6.89 30.3 30.5 20.7

W5

63.8 48.8 40.3 39.4 32.6 26.1 49.6 42.5 34.6 37.4 30.1 24.0 19.3 16.0 12.7 31.6 31.2 23.2 19.3 19.0 13.7 9.66 8.40 6.92 30.3 30.5 20.7

χ 2(5)

W20

W

Specification 1

1

3

2

ε∼

ε ∼ N(0,100)

Semiparametric propensity score weighting

ε
Y-design

n = 100

Table C8. Median absolute error with five continuous variables (propensity score weighting).

Propensity score matching

399

1

2

3

ε ∼ N(0,30)

1

58.2 19.9 14.6 32.0 11.3

W20

106

88.8 47.9 15.8 39.6 19.6

W20

5.0

4.9

5.0

72.6 10.2 58.1 31.0

W20

67.2 31.6

89.4

8.3

72.6 10.2 58.1 31.0

W

52.3 52.8

53.8 52.9

52.3 52.8

W5

Multiple bandwidths

102

105

W5

W20

102

W

One bandwidth

7.0

6.7

7.0

4.7

4.7

4.7

Nonparametric propensity score matching

30.8 18.9 38.7 16.8

99.1 54.3 17.1 39.9 19.7

W

W5

1

2

3

1

2

3

ε ∼ N(0,100)
1

2

ε∼

χ 2(5)
3

1

2

3

ε ∼ N(0,30)
1

2

3

ε ∼ N(0,100)

n = 1600

1

2

ε ∼ χ 2(5)
3

9.4

11.8 3.06 3.02 6.47 2.07 1.22 9.23 2.96 1.53 3.84 0.80 0.88 1.41 0.47 0.33 3.22 0.86 0.37

9.8

10.1 14.5 3.06 3.27 6.57 2.29 1.25 10.9 2.65 1.68 5.78 1.02 1.00 1.51 0.68 0.35 4.83 0.63 0.43

30.8 54.6

31.8 63.7

30.8 54.7

22.4 82.2

22.5 83.4

9.2

8.0

9.2

4.8

4.8

4.8

43.1 25.9 2.83 12.4 10.1 1.85 4.65 19.7 2.63 7.42 11.1 0.70 3.28 3.22 0.47 1.09 7.82 0.64 1.29

49.0 30.9 2.83 14.4 10.1 1.85 4.69 21.5 2.60 8.19 11.6 0.72 3.43 3.22 0.47 1.09 7.86 0.65 1.30

43.1 25.9 2.83 12.4 10.1 1.85 4.65 19.7 2.63 7.42 11.1 0.70 3.28 3.22 0.47 1.09 7.82 0.64 1.29

36.3 31.3 1.83 13.7 15.2 1.47 5.81 26.1 1.67 8.29 10.6 0.97 3.49 4.17 0.56 1.42 8.29 0.68 1.45

37.0 33.2 1.82 14.4 15.2 1.47 5.82 26.5 1.66 8.44 10.9 0.94 3.62 4.17 0.56 1.42 8.31 0.68 1.45

36.3 31.3 1.83 13.7 15.2 1.47 5.81 26.1 1.67 8.29 10.6 0.97 3.49 4.17 0.56 1.42 8.29 0.68 1.45

69.2 32.2 11.9 49.6 33.7 4.53 15.8 10.6 2.12 36.9 21.2 3.52 43.5 32.7 3.07 10.8 9.21 1.12 31.8 19.5 2.27

9.0

22.4 82.2

76.7 23.4 13.3 55.6 30.8 5.43 15.8 10.6 2.12 38.2 20.5 3.69 44.0 32.3 3.15 10.8 9.21 1.12 31.8 19.5 2.27

70.7 33.3 13.0 49.6 33.7 4.53 15.8 10.6 2.12 36.9 21.2 3.52 43.5 32.7 3.07 10.8 9.21 1.12 31.8 19.5 2.27

46.3 14.1 10.4 10.3 3.82 2.42 6.58 2.29 1.25 10.4 2.76 1.63 3.17 1.41 0.57 1.51 0.68 0.35 4.79 0.63 0.43

44.8

48.2 15.5 11.5 10.3 3.82 2.42 6.58 2.29 1.25 10.4 2.76 1.63 3.17 1.41 0.57 1.51 0.68 0.35 4.79 0.63 0.43

45.0 14.4 10.0 10.1 3.31 2.37 6.47 2.07 1.22 9.10 2.99 1.53 2.38 0.75 0.52 1.41 0.47 0.33 3.20 0.86 0.37

41.1 10.4

8.5

9.2

7.9

9.4

57.2 11.1 16.2 28.4

Specification 3

7.0

68.0 22.5 17.6 32.4 11.5

W

W5

8.1

7.9

62.2 19.8 14.9 32.7 11.1

W20

Specification 2

6.8

9.4

52.6 11.4 15.9 28.4

8.2

76.2 23.1 19.1 33.0 11.4

W

W5

Specification 1

3

ε ∼ N(0,30)

n = 400

46.6 15.3 10.9 10.1 3.31 2.37 6.47 2.07 1.22 9.10 2.99 1.53 2.38 0.75 0.52 1.41 0.47 0.33 3.20 0.86 0.37

2

1

3

2

ε∼

χ 2(5)

Table C9. MSE with 10 binary variables (propensity score weighting).

ε ∼ N(0,100)

Semiparametric propensity score weighting

ε
Y-design

n = 100

400
Markus Frölich


C Royal Economic Society 2007

1

2

3

ε ∼ N(0,30)

1

2


C Royal Economic Society 2007

1

2

3

1

2

3

ε ∼ N(0,100)
1

2

ε∼

χ 2(5)
3

1

2

3

ε ∼ N(0,30)
1

2

3

ε ∼ N(0,100)

n = 1600

1

2

ε ∼ χ 2(5)
3

92.7 15.0 65.7 58.0 14.3 38.2 80.7 15.1 52.6 53.1 8.94 35.3 31.4 7.87 20.8 46.5 8.82 26.1 30.2 7.11 18.1 16.2 5.32 10.2 25.9 5.66 10.3

90.3 15.1 65.0 57.8 14.3 38.2 79.6 15.2 52.3 51.2 8.99 34.8 31.4 7.87 20.8 45.5 8.83 25.9 29.7 7.29 17.9 16.2 5.32 10.2 25.9 5.67 10.3

W20

65.1 20.1 64.1 38.3 16.4 41.0 54.8 19.5 51.7 45.2 11.1 32.1 23.5 9.16 15.7 36.7 10.9 22.6 31.2 5.45 17.0 13.4 4.21 8.47 25.2 5.24 9.72

78.6 18.9 72.0 38.9 16.2 42.1 63.1 18.2 57.4 49.2 11.0 34.2 23.5 9.13 15.8 39.4 10.8 23.8 31.9 5.51 17.4 13.4 4.21 8.47 25.2 5.26 9.79

65.1 20.1 64.2 38.3 16.4 41.0 54.8 19.5 51.7 45.2 11.1 32.1 23.5 9.16 15.7 36.7 10.9 22.6 31.2 5.45 17.0 13.4 4.21 8.47 25.2 5.24 9.72

W

W5

W20

Multiple bandwidths

90.3 15.1 65.0 57.8 14.3 38.2 79.6 15.2 52.3 51.2 8.99 34.8 31.4 7.87 20.8 45.5 8.83 25.9 29.7 7.29 17.9 16.2 5.32 10.2 25.9 5.67 10.3

W

W5

One bandwidth

Nonparametric propensity score matching

86.9 44.4 32.9 42.9 29.7 19.2 69.6 37.9 26.1 69.3 53.2 19.4 31.6 29.4 10.5 56.9 42.8 15.6 65.0 56.4 15.9 30.9 29.8 8.79 55.2 43.9 13.8

72.4 53.7 27.8 43.2 31.4 19.4 62.0 42.6 24.0 65.0 55.0 16.8 31.6 29.4 10.5 55.4 43.3 14.8 64.5 56.6 15.8 30.9 29.8 8.79 55.2 43.9 13.8

W5

73.4 53.9 28.0 43.2 31.4 19.4 62.2 42.7 24.0 65.0 55.0 16.8 31.6 29.4 10.5 55.4 43.3 14.8 64.5 56.6 15.8 30.9 29.8 8.79 55.2 43.9 13.8

W20

W

Specification 3

55.2 22.1 29.0 35.7 20.6 17.5 48.5 21.3 21.5 27.3 11.8 12.8 17.2 10.5 7.46 23.3 11.2 8.92 19.8 7.04 7.27 8.12 5.79 3.82 18.3 5.34 4.41

50.5 28.0 24.5 37.4 22.1 17.8 46.1 23.9 20.8 22.0 13.4 10.2 17.2 10.5 7.48 22.5 11.2 8.71 12.7 8.91 5.04 8.12 5.79 3.82 18.1 5.37 4.41

W5

51.3 28.3 24.6 37.4 22.2 17.8 46.4 23.9 20.9 22.0 13.4 10.2 17.2 10.5 7.48 22.5 11.2 8.71 12.7 8.91 5.04 8.12 5.79 3.82 18.1 5.37 4.41

W20

W

Specification 2

52.3 22.6 28.7 35.6 19.9 17.3 45.9 21.8 21.1 23.2 11.6 11.9 16.9 9.29 7.49 21.1 11.8 8.52 14.5 6.10 6.50 7.96 4.86 4.02 13.4 6.52 4.18

50.4 27.6 24.8 37.6 21.1 18.2 45.5 24.2 20.4 19.9 12.2 9.80 16.9 9.19 7.50 20.4 11.8 8.55 10.3 5.78 4.80 7.96 4.86 4.02 13.4 6.49 4.18

W5

51.2 28.0 25.1 37.7 21.1 18.2 45.6 24.2 20.5 19.9 12.2 9.80 16.9 9.19 7.50 20.4 11.8 8.55 10.3 5.78 4.80 7.96 4.86 4.02 13.4 6.49 4.18

3

ε ∼ N(0,30)

n = 400

W20

W

Specification 1

1

3

2

ε∼

ε ∼ N(0,100)

Semiparametric propensity score weighting

ε
Y-design

χ 2(5)

Table C10. Median absolute error with 10 binary variables (propensity score weighting)

n = 100

Propensity score matching

401

402

Variable
Const

Markus Frölich
Table D1. Probit estimation of the propensity score with Subject of Degree.
Estimate
Std.error
t-statistic
Variable
Estimate
Std.error

t-statistic

2.10

0.34

6.13

Subject 46

0.78

0.22

3.57

Age/10

−0.23

0.16

−1.44

Subject 47

−0.09

0.21

−0.46

Age2/1000
Full time work

−0.12
−1.24

0.20
0.07

−0.61
−17.42

Subject 48
Subject 49

−0.21
−0.01

0.29
0.15

−0.71
−0.09

Private sector

−0.15

0.06

−2.50

Subject 50

−0.15

0.15

−1.02

Region 1
Region 2
Region 4

0.05
0.05
−0.24

0.12
0.09
0.09

0.44
0.57
−2.53

Subject 51
Subject 52
Subject 53

−0.08
−0.20
−0.39

0.17
0.30
0.15

−0.45
−0.67
−2.54

Region 5
Region 6

−0.07
−0.06

0.09
0.13

−0.80
−0.45

Subject 54
Subject 55

0.80
0.20

0.30
0.45

2.65
0.46

Region 7
Region 8
Region 9
Region 10
Industry 1
Industry 2
Industry 4
Industry 5
Industry 6
Industry 7
Industry 8
Industry 9
Subject 5
Subject 6
Subject 7
Subject 8
Subject 9
Subject 10
Subject 11
Subject 12

−0.03
−0.08
−0.09
−0.02
−0.34
−0.30
−0.27
−0.13
−0.59
−0.19
−0.23
−0.15
−0.02
−0.08
0.36
−0.55
0.42
−0.15
1.60
0.38

0.06
0.10
0.11
0.09
0.43
0.17
0.11
0.11
0.17
0.10
0.12
0.07
0.16
0.50
0.29
0.38
0.25
0.40
0.33
0.20

−0.43
−0.87
−0.83
−0.26
−0.80
−1.79
−2.53
−1.20
−3.48
−1.87
−1.91
−2.17
−0.12
−0.16
1.25
−1.46
1.68
−0.38
4.93
1.96

Subject 56
Subject 57
Subject 58
Subject 59
Subject 60
Subject 61
Subject 62
Subject 63
Subject 64
Subject 65
Subject 66
Subject 67
Subject 68
Subject 69
Subject 70
Subject 71
Subject 72
Subject 73
Subject 74
Subject 75

−0.55
0.34
1.08
0.70
0.49
−0.29
0.92
0.95
1.41
0.13
0.60
0.30
−0.64
−0.01
−0.51
0.55
0.44
0.10
0.59
0.68

0.39
0.29
0.57
0.16
0.60
0.31
0.24
0.30
0.47
0.16
0.39
0.34
0.37
0.24
0.45
0.26
0.20
0.24
0.45
0.14

−1.39
1.19
1.89
4.24
0.82
−0.94
3.87
3.12
2.97
0.83
1.52
0.90
−1.71
−0.03
−1.15
2.10
2.17
0.41
1.31
4.87

D APPENDIX TO SECTION 4
Tables D.1 and D.2 show the coefficients for the parametrically estimated propensity score.
The Tables D.3 and D.4 contain the decomposition of the mean gender wage gap without
trimming and with 5% trimming, respectively. These tables indicate that the decomposition results
of Table 4 are not very sensitive to the trimming level.
Tables D.5 to D.7 give the results if the PSM adjustment proceeds with respect to log wages
instead of wages.

C Royal Economic Society 2007

403

Propensity score matching
Table D1. (Continued).
t-statistic
Variable

Estimate

Std.error

t-statistic

Subject 76

0.54

0.15

3.70

Subject 77

0.66

0.24

2.77

1.33
0.19

Subject 78
Subject 79

0.17
−0.29

0.22
0.36

0.76
−0.80

0.27

1.66

Subject 80

−0.20

0.22

−0.90

0.84
−0.50
0.68

0.43
0.33
0.26

1.93
−1.50
2.65

Subject 81
Subject 82
Subject 83

−0.22
−1.54
0.52

0.25
0.35
0.17

−0.87
−4.46
3.02

Subject 22
Subject 23

−0.47
−1.26

0.16
0.26

−2.94
−4.83

Subject 84
Subject 85

−0.16
0.08

0.17
0.77

−0.94
0.10

Subject 24
Subject 25
Subject 26
Subject 27
Subject 28
Subject 29
Subject 30
Subject 31
Subject 32
Subject 33
Subject 34
Subject 35
Subject 36
Subject 37

0.71
−0.24
0.28
−0.11
0.29
−0.76
−1.03
−1.06
−1.55
−0.93
−1.68
−0.66
−0.67
−0.87

0.55
0.26
0.22
0.16
0.46
0.18
0.40
0.24
0.28
0.24
0.34
0.27
0.68
0.34

1.29
−0.90
1.28
−0.72
0.63
−4.21
−2.54
−4.40
−5.49
−3.87
−4.91
−2.48
−0.99
−2.56

Subject 86
Subject 87
Subject 88
Subject 89
Subject 90
Subject 91
Subject 92
Subject 93
Subject 94
Subject 95
Subject 96
Subject 97
Subject 98
Subject 99

0.94
0.54
0.76
0.60
0.59
0.24
0.51
−0.05
0.08
−0.05
−0.63
−0.84
0.13
−0.23

0.20
0.41
0.25
0.28
0.20
0.32
0.65
0.59
0.29
0.45
0.52
0.44
0.23
0.42

4.62
1.31
3.06
2.11
3.02
0.75
0.79
−0.09
0.28
−0.11
−1.21
−1.91
0.58
−0.54

Subject 38
Subject 39
Subject 40
Subject 41
Subject 42
Subject 43
Subject 44
Subject 45

−0.71
−1.26
−0.24
−0.45
0.74
0.59
0.61
0.05

0.26
0.39
0.31
0.19
0.20
0.26
0.24
0.75

−2.76
−3.23
−0.78
−2.39
3.65
2.25
2.51
0.07

Subject 100
Subject 101
Subject 102
Subject 103
Subject 104
Subject 105
Subject 106

0.01
1.07
0.87
0.34
0.54
1.29
0.55

0.33
0.35
0.21
0.38
0.34
0.64
0.25

0.03
3.05
4.07
0.89
1.56
2.01
2.19

Variable

Estimate

Std.error

Subject 13

0.20

0.32

0.62

Subject 14

−0.54

0.37

−1.45

Subject 16
Subject 17

0.45
0.04

0.34
0.20

Subject 18

0.46

Subject 19
Subject 20
Subject 21

Note: 5166 observations, 5043 degrees of freedom, robust covariance matrix used, adjusted R2 = 0.311.


C Royal Economic Society 2007

404

Markus Frölich
Table D2. Probit estimation of the propensity score without Subject of Degree.
Estimate
Std.error
t-statistic
Const

2.12

0.30

6.96

Age/10

−0.13

0.15

−0.91

Age squared/1000
Full time work

−0.20
−1.30

0.18
0.07

−1.11
−19.29

Private sector

−0.35

0.05

−6.82

Region 1
Region 2
Region 4

0.08
0.06
−0.19

0.11
0.08
0.09

0.72
0.77
−2.12

Region 5
Region 6

−0.03
−0.08

0.09
0.11

−0.29
−0.73

Region 7
Region 8
Region 9
Region 10
Industry 1
Industry 2
Industry 4
Industry 5
Industry 6
Industry 7
Industry 8
Industry 9

0.01
−0.07
0.00
−0.05
−0.50
−0.72
−0.72
−0.06
−1.17
−0.17
−0.46
−0.28

0.06
0.09
0.11
0.08
0.36
0.14
0.09
0.10
0.14
0.09
0.11
0.06

0.10
−0.84
−0.01
−0.60
−1.39
−5.03
−7.99
−0.59
−8.36
−1.86
−4.12
−4.61

Note: 5166 observations, 5144 degrees of freedom, robust covariance matrix used, adjusted
R2 = 0.185.


C Royal Economic Society 2007

405

Propensity score matching
Table D3. Decomposition of the mean gender wage gap (0% trimming).
With subject of degree
Without subject of degree
Adjusted wage £

% explained

Adjusted wage £

% explained

Semiparametric propensity score matching
Pair matching

11.66 (0.43)

75.7 (14.4)

12.07 (0.86)

62.4 (28.0)

Kernel Gauss matching
Kernel Epa matching

12.08 (0.39)
11.95 (0.33)

62.0 (12.1)
66.2 (10.5)

12.61 (0.53)
12.62 (0.50)

45.1 (13.6)
44.7 (12.5)

Ridge Gauss matching

11.77 (0.42)

72.2 (13.0)

12.52 (0.56)

48.0 (13.8)

Ridge Epa matching

11.77 (0.40)

72.1 (12.3)

12.54 (0.48)

47.2 (11.1)

66.4 (23.3)
74.3 (18.8)

12.31 (0.38)
12.21 (0.30)

54.7 (11.5)
57.9 (9.5)

Nonparametric propensity score matching
Kernel Gauss matching
Kernel Epa matching

11.94 (0.71)
11.70 (0.53)

Note: Bandwidths used for PSM for the various estimators, with subject of degree: 0.119, 0.202, 0.119, 0.202, 0.119,
0.202; without subject of degree: 0.024, 0.070, 0.119, 0.343, 0.070, 0.119. Standard errors in brackets (simulated with
1000 bootstrap replications).

Table D4. Decomposition of the mean gender wage gap (5% trimming common support).
With subject of degree
Without subject of degree
Adjusted wage £

% explained

Adjusted wage £

% explained

Semiparametric propensity score matching
Pair matching
11.73 (0.51)
Kernel Gauss matching
12.22 (0.31)
Kernel Epa matching
12.08 (0.27)
Ridge Gauss matching
11.79 (0.32)
Ridge Epa matching
11.80 (0.29)

74.2 (15.9)
58.2 (10.2)
62.6 (8.8)
72.5 (10.5)
72.1 (9.3)

12.21 (0.60)
12.80 (0.44)
12.77 (0.54)
12.64 (0.45)
12.64 (0.53)

58.3 (19.5)
39.0 (11.0)
39.8 (12.4)
44.2 (11.5)
44.0 (12.3)

Nonparametric propensity score matching
Kernel Gauss matching
12.18 (0.40)
Kernel Epa matching
11.94 (0.33)

59.0 (13.9)
67.0 (11.0)

12.43 (0.26)
12.32 (0.24)

50.9 (9.1)
54.5 (8.8)

Note: Bandwidths used for PSM for the various estimators, with subject of degree: 0.119, 0.202, 0.070, 0.202, 0.119,
0.202; without subject of degree: 0.041, 0.070, 0.119, 0.343, 0.070, 0.119. Standard errors in brackets (simulated with
1000 bootstrap replications).


C Royal Economic Society 2007

406

Markus Frölich
Table D5. Decomposition of the mean gender log wage gap (0% trimming).
With subject of degree
Without subject of degree
Adjusted log wage

% explained

Adjusted log wage

% explained

77.8 (17.5)
82.2 (14.9)

2.334 (0.034)
2.331 (0.027)

63.4 (16.1)
64.6 (13.3)

Semiparametric propensity score matching
Pair matching
Kernel Gauss matching

2.304 (0.035)
2.295 (0.029)

Kernel Epa matching

2.298 (0.028)

80.5 (13.6)

2.331 (0.019)

64.6 (9.2)

Ridge Gauss matching

2.295 (0.030)

82.1 (15.2)

2.331 (0.028)

64.6 (13.4)

Ridge Epa matching

2.296 (0.029)

81.6 (14.3)

2.335 (0.022)

62.9 (10.2)

91.0 (28.9)
92.5 (25.7)

2.358 (0.028)
2.341 (0.021)

51.7 (13.3)
60.1 (10.0)

Nonparametric propensity score matching
Kernel Gauss Matching
Kernel Epa matching

2.277 (0.064)
2.273 (0.057)

Note: Outcome variable is log wages. Bandwidths used for PSM for the various estimators, with subject of degree: 0.041,
0.119, 0.041, 0.119, 0.041, 0.070; without subject of degree: 0.024, 0.041, 0.024, 0.041, 0.003, 0.024. Standard errors in
brackets (simulated with 1000 bootstrap replications).

Table D6. Decomposition of the mean gender log wage gap (2% trimming common support).
With subject of degree
Without subject of degree
Adjusted log wage

% explained

Adjusted log wage

% explained

Semiparametric propensity score matching
Pair matching
2.321 (0.034)
Kernel Gauss matching
2.306 (0.028)
Kernel Epa matching
2.310 (0.023)
Ridge Gauss matching
2.302 (0.029)
Ridge Epa matching
2.302 (0.026)

72.6 (16.9)
80.0 (14.2)
78.0 (11.9)
81.8 (14.5)
82.1 (13.2)

2.346 (0.029)
2.342 (0.025)
2.341 (0.020)
2.341 (0.025)
2.340 (0.021)

60.2 (14.0)
62.1 (12.2)
62.4 (9.9)
62.6 (12.3)
63.0 (10.3)

Nonparametric propensity score matching
Kernel Gauss matching
2.290 (0.069)
Kernel Epa matching
2.281 (0.059)

85.4 (32.9)
90.0 (27.9)

2.356 (0.022)
2.342 (0.016)

53.4 (10.1)
60.2 (6.8)

Note: Outcome variable is log wages. Bandwidths used for PSM for the various estimators, with subject of degree: 0.041,
0.119, 0.041, 0.119, 0.041, 0.070; without subject of degree: 0.024, 0.041, 0.024, 0.070, 0.003, 0.024. Standard errors in
brackets (simulated with 1000 bootstrap replications).


C Royal Economic Society 2007

407

Propensity score matching
Table D7. Decomposition of the mean gender log wage gap (5% trimming common support).
With subject of degree
Without subject of degree
Adjusted log wage

% explained

Adjusted log wage

% explained

72.4 (15.1)
76.8 (13.4)

2.358 (0.030)
2.351 (0.022)

53.6 (15.6)
56.8 (10.9)

Semiparametric propensity score matching
Pair matching
Kernel Gauss matching

2.321 (0.031)
2.312 (0.027)

Kernel Epa matching

2.318 (0.021)

74.1 (10.1)

2.351 (0.019)

57.1 (9.5)

Ridge Gauss matching

2.304 (0.028)

81.1 (13.6)

2.350 (0.023)

57.7 (11.3)

Ridge Epa matching

2.302 (0.023)

82.0 (11.4)

2.349 (0.020)

58.2 (10.0)

77.1 (22.1)
80.3 (17.7)

2.361 (0.016)
2.350 (0.014)

53.1 (8.3)
58.6 (7.2)

Nonparametric propensity score matching
Kernel Gauss matching
Kernel Epa matching

2.313 (0.042)
2.307 (0.033)

Note: Outcome variable is log wages. Bandwidths used for PSM for the various estimators, with subject of degree: 0.041,
0.119, 0.041, 0.119, 0.041, 0.070; without subject of degree: 0.024, 0.041, 0.024, 0.041, 0.003, 0.024. Standard errors in
brackets (simulated with 1000 bootstrap replications).


C Royal Economic Society 2007

