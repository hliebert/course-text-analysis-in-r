Journal of Econometrics 156 (2010) 38–67

Contents lists available at ScienceDirect

Journal of Econometrics
journal homepage: www.elsevier.com/locate/jeconom

Dynamic discrete choice structural models: A survey
Victor Aguirregabiria a,∗ , Pedro Mira b
a

University of Toronto, Canada

b

CEMFI, Madrid, Spain

article

info

Article history:
Available online 16 September 2009
JEL classification:
C14
C25
C61

abstract
This paper reviews methods for the estimation of dynamic discrete choice structural models and discusses
related econometric issues. We consider single-agent models, competitive equilibrium models and
dynamic games. The methods are illustrated with descriptions of empirical studies which have applied
these techniques to problems in different areas of economics. Programming codes for some of the
estimation methods are available in a companion web page.
© 2009 Elsevier B.V. All rights reserved.

Keywords:
Dynamic structural models
Discrete choice
Estimation methods

1. Introduction
This paper reviews recent developments in the literature on
the estimation of discrete choice dynamic programming models
of individual behavior. The goal of this paper is to provide an
update of existing surveys of this literature, e.g. Eckstein and
Wolpin (1989) and Rust (1994a).1 In order to avoid repetition,
we emphasize the methodological contributions during the last
decade. Thus, some of the major themes of the survey are: the
extension of methods which avoid repeated full solution of the
structural model in estimation; the development and increased use
of simulation and approximation methods; and the exploration of
techniques that allow researchers to estimate dynamic equilibrium
models, both strategic and competitive. This paper tries to make
the reader familiar with these recent developments. With that
purpose in mind, this survey is complemented with programs that
implement some of the estimation methods we describe. These
programs are available at the journal’s web site.
In dynamic discrete choice structural models, agents are forward looking and maximize expected intertemporal payoffs. The
parameters to be estimated are structural in the sense that they
describe agents’ preferences and beliefs about technological and
institutional constraints. Under the principle of revealed preference, these parameters are estimated using microdata on individuals’ choices and outcomes. Thus an attractive feature of this

∗ Corresponding address: Department of Economics, University of Toronto, 150
St. George Street, Toronto, Ontario M5S 3G7, Canada. Tel.: +1 416 978 4358; fax: +1
416 978 6713.
E-mail address: victor.aguirregabiria@utoronto.ca (V. Aguirregabiria).
1 Other excellent surveys are Rust (1994b), Pakes (1994) and Miller (1997).
0304-4076/$ – see front matter © 2009 Elsevier B.V. All rights reserved.
doi:10.1016/j.jeconom.2009.09.007

literature is that structural parameters have a transparent interpretation within the theoretical model that frames the empirical investigation. Moreover, econometric models in this class are
useful tools for the evaluation of new (counterfactual) policies.2
Seminal papers include Wolpin (1984) on fertility and child mortality, Miller (1984) on job matching and occupational choice,
Pakes (1986) on patent renewal, and Rust (1987) on machine replacement. A well-known impediment to the development of this
literature has been the computational complexity of estimation.
Solving the structural model or evaluating an estimation criterion
such as the likelihood can both be nontrivial numerical tasks, and
estimation in this context typically requires the use of algorithms
in which a dynamic programming solution procedure is nested in
the optimization of the estimation criterion. In spite of this, over
the last twenty years there has been a significant number of interesting applications of these models to different areas in economics.
In this paper, we will select a few of these applications as examples
to illustrate estimation methods and econometric issues. Many of
the problems encountered by applied researchers are the same as
in other discrete choice microeconometric models, e.g., permanent
unobserved heterogeneity, initial conditions, censored outcomes
and sample selection, measurement error, endogeneity, identification, etc. Having to consider explicit solutions to the dynamic
optimization problem that is postulated to describe individual behavior adds another layer of complexity. But such a close link

2 See Wolpin (1996) for a review of some uses of these models for public policy
analysis, and Keane (2010) and Rust (2010) in this issue for more discussion on the
use of empirical structural dynamic models.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

between economic theory and the econometric model can also
provide more insight into the econometric problems.
Our discussion of estimation methods will follow a classification based on two criteria. The first criterion is the type of interactions between agents which the structural model explicitly takes
into account. According to this criterion we distinguish singleagent models, dynamic games, and competitive equilibrium models. The estimation of equilibrium models and dynamic strategic
games involves specific econometric issues which are not present
in single-agent models. In particular, multiple equilibria, the endogeneity of other players’ actions and prices, and the curse of dimensionality associated with the number of heterogeneous players and
the state of the economy.
A second natural classification criterion is the structure of
the unobservables. Different assumptions on the structure of
the unobservables lead to very different estimation methods, as
already noted by Eckstein and Wolpin (1989). Multi-dimensional
numerical integration and the so-called initial conditions problem
are important issues that arise in dynamic discrete choice
models (structural or not) in which unobservables are correlated
across choices or over time. Dealing with these issues can add
considerable complexity to the solution and estimation of dynamic
discrete choice structural models.
Our discussion of estimation methods for single-agent problems proceeds in three steps. First, we review methods for Rust’s
model with additively separable, conditionally independent and
extreme value distributed unobservables. Second, we consider several important departures from Rust’s framework, such as allowing for permanent unobserved heterogeneity, non-additive shocks,
correlation across choices and observable but choice-censored
state variables or payoffs. We group all such models under the label Eckstein–Keane–Wolpin models after the authors who have contributed many applications and methodological advances. Third,
we discuss estimation of models with serially correlated unobservables and continuous state variables. Finally, we briefly review
other issues in the estimation of single-agent models: the problem
of approximation error and inference, Bayesian methods, validation of structural models, and departures from the standard dynamic, rational expectations framework.
For the sake of space, this paper does not cover several topics
in this literature which have received attention in recent years.
Some omissions that we are aware of are nonparametric and
semiparametric identification and estimation (see Rust, 1994a;
Magnac and Thesmar, 2002; Aguirregabiria, 2007; Bajari and Hong,
2005; Heckman and Navarro, 2007), and the application of parallel
computing (see Ferrall, 2005).
Section 2 introduces the notation and basic assumptions,
illustrates the main issues that arise in estimation of dynamic
discrete choice structural models and presents four examples of
applications. Each of these examples deals with one of the four
classes of models that we examine in the survey: single-agent
models under Rust’s framework; single-agent models under the
Eckstein–Keane–Wolpin framework; dynamic general equilibrium
models; and dynamic strategic games. This section is selfcontained and tries to provide an introduction to this literature
for a second year Ph.D. student. Sections 3–5 deal with the details
of methods for the estimation of single-agent models, dynamic
games and general equilibrium models, respectively. The idea
is that, after reading Section 2, the reader can go to either of
these sections to learn about the details of specific methods. Each
subsection includes additional references to applications which
have used the corresponding method—these lists are illustrative
and incomplete. Computer programs implementing some of the
methods are available in a companion web page at the journal’s
website.

39

2. Models and examples
2.1. Single-agent models
Time is discrete and indexed by t. We index agents by i. Agents
have preferences defined over a sequence of states of the world
from period t = 0 until period t = T . The time horizon T can
be either finite or infinite. The state of the world at period t for
individual i has two components: a vector of state variables sit that
is known at period t; and a decision ait chosen at period t that
belongs to the discrete set A = {0, 1, . . . , J }. The time index t
can be a component of the state vector sit , which may also contain
time-invariant individual characteristics. Agents’ preferences over
possible sequences of states of the world can be represented by
PT
j
a utility function
j=0 β U (ai,t +j , si,t +j ), where β ∈ (0, 1) is the

discount factor and U (ait , sit ) is the current utility function.3 The
decision at period t affects the evolution of future values of the
state variables, but the agent faces uncertainty about these future
values. The agent’s beliefs about future states can be represented
by a Markov transition distribution function F (si,t +1 |ait , sit ).4 These
beliefs are rational in the sense that they are the true transition
probabilities of the state variables.5 Every period t the agent
observes the vector of state variables sit and chooses his action
ait ∈ A to maximize the expected utility
E

T −t
X

!
β U (ai,t +j , si,t +j )|ait , sit .
j

(1)

j =0

This is the agent’s dynamic programming (DP) problem. Let α(sit )
and V (sit ) be the optimal decision rule and the value function of the
DP problem, respectively.6 By Bellman’s principle of optimality the
value function can be obtained using the recursive expression:



V (sit ) = max U (a, sit ) + β
a∈A

Z



V (si,t +1 )dF (si,t +1 | a, sit )

(2)

and the optimal decision rule is then α(sit ) = arg maxa∈A {v(a, sit )}
where, for every a ∈ A,

v(a, sit ) ≡ U (a, sit ) + β

Z

V (si,t +1 )dF (si,t +1 | a, sit )

(3)

is a choice-specific value function.
We are interested in the estimation of the structural parameters
in preferences, transition probabilities, and the discount factor β .7
Suppose that a researcher has panel data for N individuals who
behave according to this decision model. For every observation
(i, t ) in this panel dataset, the researcher observes the individual’s

3 We do not consider deviations from this expected utility, time-separable
framework. Note that β is constant over time, e.g., hyperbolic discounting is ruled
out.
4 The utility function and the transition probability functions are not indexed by
time or individual. This is without loss of generality because time and individual
heterogeneity can be arguments in the state vector sit .
5 If the only data available are (longitudinal) data on choices and states, then
preferences, beliefs and the actual transition probabilities cannot be separately
identified in general. In this sense, rational expectations is an identification
assumption. It can be relaxed if the researcher has data on elicited beliefs and is
able to use that data in estimation. See Section 3.3.5 for further discussion and
references.
6 Again, and without loss of generality, we omit time and individual subindexes
from the arguments of these functions because they are implicit in the state vector
sit .
7 The discount factor is assumed constant across agents. In most applications
this parameter is not estimated because it is poorly identified (e.g., see Rust, 1987).
Also note that the decision horizon T is the same for all agents and known by the
econometrician.

40

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

action ait and a subvector xit of the state vector sit . Therefore, from
an econometric point of view, we can distinguish two subsets of
state variables: sit = (xit , εit ), where the subvector εit is observed
by the agent but not by the researcher. Note that εit is a source
of variation in the decisions of agents conditional on the variables
observed by the researcher. It is the model’s ‘econometric error’,
which is given a structural interpretation as an unobserved state
variable.8 In some applications the researcher also observes one
or more payoff variables. We define a payoff variable as a variable
yit which contains information about utility but is not one of the
model’s actions or state variables.9 Payoff variables depend on
current action and state variables. We specify this relationship
as yit = Y (ait , xit , εit ), where Y (.) is the payoff function, e.g., an
earnings function, a production function, etc.10 In summary, the
researcher’s dataset is:
Data = {ait , xit , yit : i = 1, 2, . . . , N ; t = 1, 2, . . . , Ti }

(4)

where Ti is the number of periods over which we observe
individual i.11 In microeconometric applications of single-agent
models, we typically have that N is large and Ti is small.
Let θ be the vector of structural parameters and let gN (θ ) be an
estimation criterion for this model and data, such as a likelihood
or a GMM criterion. For instance, if the data are a random sample
over individuals and the criterion is a log-likelihood, then gN (θ ) =
PN
i=1 li (θ ), where li (θ ) is the contribution to the log-likelihood
function of individual i’s history:
li (θ) = log Pr {ait , yit , xit : t = 1, 2, . . . , Ti | θ}

= log Pr {α (xit , εit , θ) = ait , Y (ait , xit , εit , θ)
= yit , xit : t = 1, 2, . . . , Ti | θ } .

(5)

Whatever the estimation criterion, in order to evaluate it for a
particular value of θ it is necessary to know the optimal decision
rules α(xit , εit , θ ). Therefore, for each trial value of θ the DP
problem needs to be solved exactly, or its solution approximated
in some way.
So far we have not made any assumption on the relationship
between observable and unobservable variables. These are key
modelling decisions in the econometrics of dynamic discrete
structural models. The form of li (θ ) and the choice of the
appropriate solution and estimation methods crucially depend
on these assumptions. We first introduce six assumptions which
define what we call Rust’s model, or also ‘‘dynamic programming
(DP)—conditional logit’’ model. This is the simplest framework for
estimation and it has been used in many applications beginning
with the bus engine replacement model in Rust (1987).

Assumption IID (iid Unobservables). The unobserved state variables in εit are independently and identically distributed over
agents and over time with CDF Gε (εit ) which has finite first moments and is continuous and twice differentiable in εit .12
Assumption CI-X (Conditional Independence of Future x). Conditional on the current values of the decision and the observable state
variables, next period observable state variables do not depend on
current ε : i.e., CDF (xi,t +1 |ait , xit , εit ) = Fx (xi,t +1 |ait , xit ). We use θf
to represent the vector of parameters that describe the transition
probability function Fx .
Assumption CI-Y (Conditional Independence of y). Conditional
on the values of the decision and the observable state variables, the value of the payoff variable y is independent of ε :
i.e., Y (ait , xit , εit ) = Y (ait , xit ). The vector of parameters that describe Y is θY .
Assumption CLOGIT. The unobserved state variables {εit (a) : a =
0, 1, . . . , J } are independent across alternatives and have an
extreme value type 1 distribution.
Assumption DIS (Discrete Support of x). The support of xit is
discrete and finite: xit ∈ X = {x(1) , x(2) , . . . , x(|X |) } with |X | < ∞.
Note that Assumptions CI-X and IID together imply that
F (xi,t +1 , εi,t +1 |ait , xit , εit ) = Gε (εi,t +1 )Fx (xi,t +1 |ait , xit ), which corresponds to the conditional independence assumption in Rust
(1987). It is convenient to distinguish several components in the
vector of structural parameters: θ = {θu , θY , θf }, where θY and θf
have been defined above and θu represents all the parameters in
the utility function which are not in θY as well as the parameters
in the distribution of Gε . In order to illustrate this framework, we
present an example of a model of retirement from the labor force
which is based on the models of Rust and Phelan (1997) and Karlstrom et al. (2004).
Example 1 (Retirement from the Labor Force). Every period the
individual decides whether to continue working (ait = 1) or to
retire and start collecting social security pension benefits (ait = 0).
This is an optimal stopping problem with a finite horizon, where
t = 1 is the earliest age at which the individual can retire and T is
age at death.13 Let rait denote the individual’s retirement status. If
he has not retired yet, rait = 0. If retired, rait is the age at which he
retired. The utility function is additively separable in consumption
and leisure. More specifically,



Assumption AS (Additive Separability). The one-period utility
function is additively separable in the observable and unobservable
components: U (a, xit , εit ) = u(a, xit )+εit (a), where εit (a) is a zero
mean real random variable with unbounded support. That is, there
is one unobservable state variable for each choice alternative, so
the dimension of εit is (J + 1) × 1.

8 See Rust (1994a,b) for a discussion of alternative interpretations of the
econometric error.
9 That is, we can write U (a , s ) as Ũ (y , a , s ). For instance, in a model of firm
it
it
it
it
it
behavior the researcher may observe firms’ output, revenue or the wage bill; or in a
model of individual behavior the econometrician may observe individual earnings.
10 The payoff function can also incorporate stochastic components such as
measurement error in payoff variables or structural innovations which are not state
variables because they are iid over time and unknown to the agent when he makes
his decision.
11 Here the index t sequences each individual’s observations. Strictly speaking,
it is not the same as the time period index in the description of the structural
model, but distinguishing between the two at this stage would make the notation
unnecessarily cumbersome.

θ

U (ait , xit , εit ) = E citu1 |ait , xit




× exp θu2 + θu3 hit + θu4 mit + θu5

tit
1 + tit



− θu6 ait + εit (ait )
(6)

cit is current consumption. θu1 is the coefficient of relative
risk aversion. The expression in the exponential term captures
individual heterogeneity in the marginal utility of consumption.
In particular, hit is an indicator of good health status, mit is an
indicator of marital status, and tit is age. Finally, the last term is
associated with the utility of leisure. θu6 is the disutility of working.
In our notation, θu = (θu1 , θu2 , . . . , θu6 ). The unobservable state

12 Rust (1994a,b) presents a weaker version of this assumption where the second
and higher moments of εit may depend on xit . However, this weaker version of the
assumption is hardly ever used in practice.
13 Rust and Phelan allow for uncertainty about the age at death. In their
specification, the hazard of death varies with age and T is a terminal age at which
the probability of death is 1.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

variables εit (1) and εit (0) enter additively in the utilities of working
and not working, respectively, and they can be interpreted as
transitory and idiosyncratic shocks to the utility from leisure. These
random variables are independently distributed over time and over
individuals with an extreme value distribution.
Consumption is equal to current income (yit ) minus health
care expenditures net of insurance reimbursements (hcit ): cit =
yit − hcit . If the individual works, his income is equal

 to stochastic
θ

labor earnings (wit ), hence the expectation E citu1 |ait , xit . If

the individual decides to retire, then his earnings are equal to
social security pension benefits bit . The econometrician observes
earnings yit and yit = ait wit + (1 − ait )bit . Labor earnings depend
on age, health status, marital status, past earnings history through
pension points and an unobservable shock ξit . In particular,


tit
wit = exp θw1 + θw2 hit + θw3 mit + θw4
+ θw5 ppit + ξit .
(7)
1 + tit
Earnings yit are a payoff variable and θY = (θw1 , θw2 , . . . , θw5 , σξ2 )
is the vector of parameters in the corresponding payoff function,
where σξ2 is the variance of ξit . Retirement benefits depend on
retirement age (rait ) and on pension points or social security wealth
ppit : bit = b(rait , ppit ). The form of the function b(·, ·) depends
on the rules of the pension system, which are known to the
econometrician. Health care expenditures are stochastic, with a
Pareto distribution conditional on health and marital status.
The vector of observable state variables is xit = {hit , hcit , mit ,
tit , rait , ppit }. Age and retirement age have obvious deterministic
transition rules. Pension points are a deterministic function of past
earnings history. However, as argued by Rust and Phelan (1997), for
many pension systems, including the US system, the transition rule
of pension points can be very closely approximated by a Markov
process with transition probability function Fpp (ppi,t +1 |wit , ppit ).
This transition probability is nonparametrically specified. Health
status and marital status follow first order Markov processes
with transition probabilities Fh (hi,t +1 |hit ) and Fm (mi,t +1 |mit ) which
are nonparametrically specified. Though health expenditures and
pension points are continuous variables, Rust and Phelan discretize
these variables. An important feature of this model is that the
shock to wages ξit is assumed serially uncorrelated, independent
of the state variables xit and εit , and unknown to the individual at
the time he makes his period t decision. Therefore, ξit determines
the transition of labor earnings but it is not a state variable
and Assumption CI-Y holds: i.e., conditional of (ait , xit ) observed
earnings are independent of the unobserved state variables in εit .
Rust and Phelan use a richer specification of this model which
allows for part time work and post-retirement work and includes
a detailed description of Social Security and Medicare benefits
to help explain several aspects of retirement behavior in the
US. Counterfactual experiments based on their estimated model
suggest that the peak in retirement behavior at age 65 is largely
due to the fact that Social Security benefits are actuarially unfair
after age 65 and to the fact that ‘health insurance constrained’
individuals have to wait to age 65 in order to apply for Social
Security benefits and qualify for Medicare. Karlstrom et al. (2004)
use their model to simulate the effect of a three year delay in
retirement benefits. 
Imposing additive separability implies that the marginal utility
of observable state variables, today and in future periods, does not
depend on unobservables. For instance, in Example 1 the decision
to retire or to continue working determines the current and
future level of consumption. However, additive separability in the
econometric model implies that observed variation in retirement
age cannot be linked to unobserved heterogeneity in the marginal
utility of consumption. Relatedly, an individual considering early
retirement in this model weighs uncertainty about the value

41

of her marginal utility of consumption in the future. Additive
separability implies that unobserved state variables induce no
uncertainty about the marginal utility of consumption, which
may have an effect on the patterns of behavior the model can
explain and on estimation of structural parameters such as the
coefficient of relative risk aversion. As in the case of Assumption CIX which we discuss next, Assumption AS may not be too restrictive
if the model specification and the data are sufficiently rich in
observable explanatory variables; i.e., observable state variables
which are unconstrained by Assumptions AS, CI-X and IID, vary
across individuals and time and correlate with behavior.
Assumptions CI-X and IID restrict the joint transition probability of state variables. These restrictions have two main implications
which can be illustrated in Example 1. First, the unobserved shocks
to the utility of leisure are serially uncorrelated, i.e., transitory. And
second, the probability that a person’s health or marital status will
change between the current period and the next one could depend
on whether this person is currently working, but once we take this
into account it does not depend on the current value of the shocks
to the utility of leisure.14 Suppose we interpret these unobservable shocks as health shocks not included in the observable hit . The
shocks are important enough because they can explain individuals’
changes in labor supply decisions, but they should be ‘transitory’
since according to CI-X they cannot have any direct impact on next
period’s health.
An important implication of Assumptions CI-X and IID is
that the solution to the DP problem is fully characterized by
the integrated value function or E max function, V̄ (xit ), which is
the expectation of the value function over the distribution of
unobservable state Rvariables, conditional on the observable state
variables: V̄ (xit ) ≡ V (xit , εit )dGε (εit ). This function is the unique
solution to the integrated Bellman equation:
V̄ (xit ) =

(

Z

max u(a, xit ) + εit (a)
a∈A

)
+ β

X

V̄ (xi,t +1 )fx (xi,t +1 |a, xit ) dGε (εit ).

(8)

xi,t +1

Under these assumptions, the size of the state space X is the
relevant measure of computational complexity, and given that
X is discrete and finite the DP problem can be solved exactly.
The choice-specific value function in (3) can be decomposed as
v(a, xit ) + εit (a) as in static random utility models, where:15

X

v(a, xit ) = u(a, xit ) + β

V̄ (xit +1 )fx (xi,t +1 |a, xit ).

(9)

xi,t +1

Another important implication of Assumptions CI-X and IID is
that the observable state vector xit is a sufficient statistic for the
current choice. The contribution of individual i to the log-likelihood
function can be factored as follows:16
li (θ ) =

Ti
X

log P (ait |xit , θ ) +

t =1
Ti −1

+

X

Ti
X

log fY (yit |ait , xit , θY )

t =1

log fx (xi,t +1 |ait , xit , θf ) + log Pr(xi1 |θ )

(10)

t =1

14 In Rust and Phelan’s specification the probability that a person’s health or
marital status will change between the current period and the next one does not
depend on whether this person is currently working.
15 There is a slight abuse of notation here because we use the same v() function
as in equation (3), but the alternative-specific value function here does not depend
on εit (a).
16 To see this, define ã , x̃ and ỹ as the vectors with the histories of the
it

it

it

individual’s decisions, states and outcomes, respectively, from period 1 until t.
Assumptions IID, CI-Y and CI-X together with the Markovian assumption imply
that Pr(ait , yit , xit | ãi,t −1 , ỹi,t −1 , x̃i,t −1 ) = fY (yit | ait , xit ) Pr(ait | xit )fx (xit |
ai,t −1 , xi,t −1 ).

42

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

fY is the density of the payoff variable conditional on (ait , xit ). In
Example 1, under Assumption CI-Y, this density is quite straightt
forward: I {ait = 1}φ([log yit − θw1 − θw2 hit − θw3 mit − θw4 1+itt −
it
θw5 ppit ]/σξ ), where I {.} is the indicator function and φ(.) is the
density of a standard normal. This can greatly simplify the estimation of θY .17 fx is the transition density function associated
with Fx . The term log Pr(xi1 |θ ) is the contribution of initial conditions to the likelihood of individual i. In most applications a
conditional likelihood approach is followed and this term is ignored. No bias is incurred as long as unobservables are serially
independent. Even when there is a loss of efficiency, the conditional likelihood is simpler to compute. Accordingly, hereafter the
term ‘likelihood’ by default refers to the conditional likelihood.
The term P (ait |xit , θ ) is the Conditional Choice Probability (CCP)
obtained by integrating the optimal decision rule over the unobservable state variables. The optimal decision rule is α(xit , εit ) =
arg maxa∈A {v(a, xit ) + εit (a)}. Therefore, for any (a, x) ∈ A × X and
θ ∈ Θ , the conditional choice probability is:
P (a|x, θ) ≡

Z
Z

=

I {α(x, ε; θ ) = a} dGε (ε)
I v(a, xit ) + εit (a) > v(a0 , xit )



+ εit (a0 ) for all a0 dGε (εit ).

(11)

algorithm, a full solution method for this class of models. One line
of research pioneered by Hotz and Miller (1993) has developed estimation methods for Rust’s model which avoid repeated solution
of the DP problem (see Sections 3.1.2–3.1.4). The computational
advantage of Hotz–Miller-type methods is greatest when the utility function is linear-in-parameters, as in Example 4 below, and
this computational advantage has made Rust’s model the framework of choice in recent research on models with strategic interactions (see Sections 2.3 and 4). Finally, note that if the choice is
not binary an important restriction is involved in the CLOGIT assumption, i.e., that the unobservable state variables are independent across alternatives.
Our next example, based on Keane and Wolpin (1997), serves as
an illustration of models which relax some of the assumptions in
Rust’s framework. More specifically, we highlight four departures
from the previous model: (1) unobservables which do not satisfy
Assumption AS; (2) observable payoff variables which are choicecensored and do not satisfy Assumption CI-Y; (3) permanent
unobserved heterogeneity (a departure of Assumption IID); and
(4) unobservables which are correlated across choice alternatives
(i.e., no CLOGIT assumption). Many applications have included at
least one of these four features, and in this survey we group all
of them under the label Eckstein–Keane–Wolpin (EKW) after the
authors who are the main contributors. We review estimation
methods for EKW models in Section 3.2.

When {εit (a)} are iid type 1 extreme value random variables, as in
Example 1, the multi-dimension integrals in the integrated Bellman equation and in the definition of CCPs have closed form
analytical expressions. This is the DP conditional logit model with
Bellman equation18



J


X
X
V̄ (xi,t +1 )fx (xi,t +1 |a, xit )  (12)
V̄ (xit ) = log 
exp u(a, xit ) + β


x
a=0

Example 2 (Occupational Choice and the Career Decisions of Young
Men). Each period (year), starting at age 16 through a maximum
age T , an individual chooses between staying at home (ait = 0),
attending school (ait = 4), or working at one of three occupations: white collar (ait = 1), blue collar (ait = 2), or the military
(ait = 3). The specification of the one-period utility function is:

and choice probabilities:

U (4, sit ) = ωi (4) − θtc1 I (hit ≥ 12) − θtc2 I (hit ≥ 16) + εit (4) (14)

i,t +1

P (a|xit , θ ) =

exp {v(a, xit )}
J
P

U (a, sit ) = Wit (a) for a = 1, 2, 3

.

(13)

exp {v(j, xit )}

j =0

If v(a, xit ) were a linear function of the parameters θ , these expressions would be familiar as the choice probability of binary probit,
logit or multinomial logit models. In general, v(a, xit ) is a complex
nonlinear function of θ which has to be computed from the Bellman equation in (12).
The relative simplicity of dynamic discrete choice models under
Rust’s assumptions and their similarity with static discrete choice
econometric models, has contributed to more extensive development of this framework. The econometric theory is better understood, and some general results on identification are available (see
Rust, 1994a,b; Magnac and Thesmar, 2002; Aguirregabiria, 2007).
Factorization of the likelihood in (10) allows for a computationally
advantageous two-step estimation approach. Our review of estimation methods begins in Section 3.3.1 with the Nested Fixed Point

17 Note that ξ is censored for the econometrician since wages are observed only
it
when the individual works. However, under Assumption CI-Y this censoring does
not introduce any bias in the estimation of the wage equation by OLS. We discuss
this issue in more detail in Section 3.
18 Since X is discrete and finite, we can represent Bellman equation as a system
of equations in the Euclidean space R|X | . Let V̄ be the |X | × 1 vector with the
values
V̄ (x(1) ), V̄ (x(2) ), . . . , V̄(x(|X |) ). Then, V̄ is the unique solution to: V̄ = log


PJ

a=0

exp u(a) + β F(a)V̄



U (0, sit ) = ωi (0) + εit (0)

, where u(a) is the |X | × 1 vector of current utilities

(u(a, x(1) ), u(a, x(2) ), . . . , u(a, x(|X |) ))0 and F(a) is the |X | × |X | matrix with the
transition probabilities fx (xt +1 |a, xt ).

hit is schooling (in years). θtc1 and θtc2 are parameters that represent tuition costs in college and graduate school, respectively.
Wit (a) is the wage of individual i at period t in occupation a. Wages
in occupation a are the product of the skill price in that occupation,
ra , and the individual’s skill level for that occupation, which is an
exponential function of an individual-specific endowment at age
16, schooling, experience and a transitory shock. That is:
Wit (a) = ra exp ωi (a) + θa1 hit + θa2 kit (a) − θa3 (kit (a))2 + εit (a)



(15)

where kit (a) is cumulated work experience (in years) in occupation a. The vector εit = {εit (a) : a ∈ A} contains choice-specific
shocks to skill levels and to the monetary values of a year at school
or at home. They are assumed to be serially uncorrelated with a
joint normal distribution with zero means and unrestricted variance matrix. The vector ωi = {ωi (a) : a ∈ A} contains occupation and individual-specific endowments which are fixed from
age 16. This vector has a discrete support, and its probability distribution is nonparametrically specified. Both εit and ωi are unobservable to the econometrician but observable to the individual
when he makes his decision at period t. The vector of observable
state variables is xit = {hit , tit , kit (a) : a = 1, 2, 3}, where tit
represents age. All the variables in xit have a discrete and finite
support and their transitions conditional on choices are deterministic so fx (xi,t +1 |a, xit ) is degenerate. Labor earnings are observable.
This payoff variable is equal to zero when ait ∈ {0, 4} and equal
to Wit (ait ) when ait ∈ {1, 2, 3}. Therefore, the payoff function is
I {ait ∈ {1, 2, 3}}ra exp{ωi (a) + θa1 hit + θa2 kit (a) − θa3 (kit (a))2 +
εit (a)}. Note that Assumption CI-Y does not hold because the un-

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

observed state variables εit (1), εit (2) and εit (3) have a direct effect
on observed labor earnings.
The opportunity cost of investing in human capital by attending
school is the value of foregone earnings and work experience, or
the utility of staying home. Working also has an investment value
since it increases occupation-specific skills and future earnings. An
individual’s optimal career path is partly determined by comparative advantage embedded in endowments at age 16. Keane and
Wolpin estimated this model on NLSY data.19 They found that unobserved skill endowments at age 16 are a very important source
of inequality in lifetime career paths, earnings and utility. To the
extent that they are the root source of inequality, their counterfactual policy experiments suggest that the impact of (large)
college tuition subsidies on college attainment and income distribution would be rather small. 
We now use Example 2 to illustrate the practical implications
for estimation of relaxing some of Rust’s assumptions. The sum
of the permanent and transitory unobserved skill components,
εit (a) + ωi (a), is a serially correlated state variable. The presence of autocorrelated unobservables has important implications
for the estimation of structural parameters. Individuals self-select
into occupations and schooling classes on the basis of persistent
differences in skills which are unobserved by the researcher. Ignoring this source of self-selection can result into an overestimation of the returns to schooling and occupation-specific experience.
Also, persistence in occupational choices in the data may arise
because there is a disutility of switching occupations (state dependence), or because there are persistent differences in skills (unobserved heterogeneity). Failure to control for the latter, if present,
would lead to biased estimates of switching disutilities.20 With
serially correlated unobservables, the probability of an individual’s sequence of choices cannot be factored into a product of conditional choice probabilities as in (10). The observable state xit
is not a sufficient statistic for ait because lagged choices contain
information about the permanent components ωi . However, conditional on ωi the transitory components {εi (a)} do satisfy Assumption IID. Since ωi has discrete support, each individual’s likelihood
contribution can be obtained as a finite mixture of likelihoods,
each of which has the same form as in (10). If the support of ωi
is Ω = {ω1 , ω2 , . . . , ωL } ⊂ RJL , then we have that
L

li (θ, Ω , π ) = log

X

!
Li (θ , ω` )π`|xi1

(16)

43

structural parameters θ . The reason for this is that the payoff
functions (the earnings equations) do not satisfy Assumption CIY and depend on unobservable state variables εit (a). Conditioning
on the current action ait introduces selection or censoring in
the payoff variable and this selection effect depends on all the
parameters of the model.
Several issues are worth highlighting here. First, in general
permanent unobserved heterogeneity poses an initial conditions
problem because the initial state xi1 is correlated with permanent
unobserved components. This problem is avoided if the structural
model has an initial period in which all the individuals have the
same value of the vector x, and if this initial period is observed
in the sample. Under these conditions xi1 = x1 for every i and
then Pr(ω` |xi1 ) is constant over individuals and equal to π` , i.e., the
unconditional mass probability of type ` individuals which is a
primitive structural parameter. Keane and Wolpin’s model is an
example of this in that all individuals start ‘life’ in the model at
age 16 with zero experience in all occupations and the NLSY data
provide histories as of age 16. If x can take different values in
the behavioral model’s first decision period, then the researcher
needs to specify how the distribution of permanent unobserved
heterogeneity varies with xi1 . In Keane and Wolpin’s data there
is variation in schooling measured at age 16. It seems likely that
initial schooling is correlated with other age 16 endowments, and
Keane and Wolpin allow for this as our mixture likelihood in (16)
suggests. A more difficult case arises if individual histories are
left-censored. We return to this issue in our review of estimation
methods for finite mixture models in Section 3.2.1. The focus
there is on a structure with (discrete) permanent unobserved
heterogeneity and (continuous) iid transitory components, which
is the simplest way of allowing for autocorrelation in unobservable
state variables.
Second, in order to evaluate the mixture of likelihoods the
DP problem needs to be solved as many times as the number of
components in the mixture. This is the reason why permanent
unobserved heterogeneity is almost always introduced with a
discrete and finite support. Third, the integrated value function
or Emax function (conditional on individual’s type) V̄` (xit ) still
fully characterizes the solution to the DP problem. The integrated
Bellman equation for individual type ` is:
V̄` (xit ) =

Z

(
max U (a, xit , ω` , εit )
a∈A

`=1

where π`|x ≡ Pr(ωi = ω` |xi1 = x); π is the vector of parameters
{π`|x : ` = 1, 2, . . . , L; x ∈ X }; and21
Li (θ, ω` ) ≡

Ti
Y

P (ait |xit , θ , ω` )fY (yit |ait , xit , θ , ω` )

t =1
T i −1

×

Y

fx (xi,t +1 |ait , xit , θf , ω` ).

(17)

t =1

Note that the conditional density of the payoff variable yit depends
not only on θY , as in Rust’s model, but on the whole vector of

19 Keane and Wolpin report estimates of two versions of this model. The
first ‘bare bones’ version is the one described here. The second one includes
additional features such as disutilities of switching between choices and permanent
unobserved heterogeneity in preferences, which are introduced in order to help the
model fit the degree of persistence in choices observed in the data.
20 See Heckman (1981) for the first discussion of this issue.
21 In Example 2, the transitions of the observable state variables are all
deterministic and do not depend on any structural parameter. Therefore, in this
example θf is an empty vector and the likelihood Li (θ, ω` ) does not include the
term

QTi −1
t =1

fx (xi,t +1 |ait , xit , ω` , θf ).

)
+ β

X

`

V̄` (xi,t +1 )fx (xi,t +1 |a, xit , ω ) dGε (εit ).

(18)

xi,t +1

The optimal decision rule is α(xit , ω` , εit ) = arg maxa∈A {v(a, xit ,
ω` , εit )}, where v(a, xit , ω` , εit ) is the term in brackets {} in
Eq. (18). When ε ’s are additively separable and extreme value
distributed, then we still have closed form expressions for the
integrated Bellman equation and for CCPs in terms of choicespecific value functions. In the occupational choice model of
Example 2 the transitory shocks to skills are correlated across
choices or occupations. This seems like a realistic (and even
necessary) assumption to make in this application; e.g., if
the transitory component of labor market skills reflects an
unobservable health shock, the shock would likely have an effect
on both white collar and blue collar skills. But correlation across
choices implies that integrated value functions and conditional
choice probabilities do not have the convenient closed forms of
McFadden’s conditional logit. In this case, as well as in models
with more general autocorrelation structures, repeated calculation
of multi-dimensional integrals in the solution and/or estimation
of the model is unavoidable. Section 3.2.2 reviews Keane and
Wolpin’s simulation and interpolation method, developed for

44

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

the occupational choice model. Simulation is used in order to
compute multi-dimensional integrals, interpolation in order to
handle problems with very large state spaces.
Fourth, in Example 2 transitory shocks to wages are observable
to the decision maker and determine the optimal occupational
choice. This feature of the model implies that, in contrast with
Example 1, there is a self-selection bias if we estimate the
wage equation for an occupation by OLS using the subsample
of individuals whose wages are observed because they chose
that occupation. And fifth, in Example 2 the shocks εit (2), εit (3)
and εit (4) do not satisfy Assumption AS. Having one shock per
alternative which is additively separable and has unbounded
support is an expedient way of making sure that the optimal
choice probabilities P (a|x, ω` , θ ) are strictly positive for every
value of (a, x, ω` , θ ). When this property fails the joint probability
distribution over actions may be degenerate and the model is
said to be saturated (Rust, 1994a,b). This leads to well-known
complications in estimation. However, this particular problem
does not arise in Example 2.22
So far, we have maintained the assumption that X is a
discrete and finite set. However, in many applications some state
variables are continuous. DP problems with continuous state
variables cannot be solved exactly and the solution needs to
be approximated using discretization or interpolation methods.
These approximation methods introduce an additional error in
the estimation of the model. The implications of this error for
the properties of estimators is a complicated issue because of
the nonlinearity of the structural model. Section 3.3 discusses
some recent developments in this area. In that section we also
discuss methods for models with (time-variant) serially correlated
unobservables, and Bayesian methods.

into the estimation process the equilibrium restrictions embodied
in the theory.23
Example 3 (Occupational Choice in Equilibrium). In order to make
it more suitable for the analysis of economy-wide aggregate data,
consider the following changes in the model of Example 2: (a) Exclude the ‘military’ occupational choice. (b) Allow the utility parameters to vary with gender and make the utility of the ‘home’
alternative dependent on the number of children of pre-school age
nit : U (0, sit ) = ωi (0) + θc nit + εit (0). The observable state variable nit which is now part of xit follows an exogenous Markov
process conditional on age, gender, education and cohort. In
Example 2, the skill rental prices ra in the wage equations (15) were
assumed constants. In this example the state vector is augmented
to include skill prices and, most important, the law of motion of
skill prices is endogenously determined in the model as an equilibrium outcome. The labor market is assumed to be competitive.
The supply side consists of overlapping generations of individuals
aged 16 through 65, whose behavior corresponds to the occupational choice model. The demand side can be characterized by the
following Cobb–Douglas, constant returns to scale aggregate production function:
α

α

1−α1t −α2t

Yt = zt S1t1t S2t2t Kt

(19)

where Yt is aggregate output, S1t and S2t are the aggregate quantities of white collar and blue collar skills, and zt and Kt are
total factor productivity and the aggregate capital stock, which
follow exogenously determined processes.24 Technical change
is captured (deterministically) in time-varying factor shares
{α1t , α2t } as well as in total factor productivity. Demand side competitive behavior implies that skill rental prices satisfy the valueof-marginal-product conditions:

2.2. Competitive equilibrium models



α

α

1−α1t −α2t

rat = (αat /Sat ) zt S1t1t S2t2t Kt
The single-agent models of Examples 1 and 2 are partial
equilibrium models. They study one side of the market (i.e., labor
supply) taking prices and aggregate quantities as exogenously
given. Though useful for policy evaluation, it is well known that
partial equilibrium analysis can give misleading results if the
assumption that prices are invariant to changes in the policy
variables of interest is not a good approximation. Equilibrium
models are also better suited to improve our understanding
of economy-wide trends. Despite the limitations of partial
equilibrium, there have been very few studies that specify
and estimate dynamic general equilibrium (GE) models with
heterogeneous agents using microdata. An important exception is
the study by Heckman et al. (1998) who estimate and calibrate
a heterogeneous agent dynamic GE model of human capital
accumulation and earnings. They use their estimated model to
study the sources of rising wage inequality in the US economy.
More recently, Lee (2005) and Lee and Wolpin (2006) have
estimated dynamic GE models of human capital accumulation
in the same spirit as the study in Heckman, Lochner and Taber,
relaxing some of their assumptions and more fully incorporating

22 In other words, Assumption AS is sufficient but not necessary to avoid
degeneracy. In order to illustrate how multiplicative errors can lead to degeneracy,
even when their support is unbounded, consider a binary choice model with choice
alternatives 0 and 1 and choice-specific utilities U (0) = W (0) exp (ε(0)) and
U (1) = W (1) exp (ε(1)) where W (0) and W (1) are functions of observable
covariates and parameters. Alternative 1 is chosen iff exp(ε(0)) < [W (1)/W (0)]
exp (ε(1)). If W (1)/W (0) < 0 for some configuration of observable covariates and
parameters, then the right hand side of the inequality is always negative and the
left hand side is always positive for every value of the shocks, and alternative 1 is
never chosen.



for a = 1, 2.

(20)

Let e
Xt denote aggregate state variables relevant to the individual’s
occupational choice problem, i.e. current skill rental prices and
other aggregate variables which agents use to predict future skill
rental prices. The state vector of the occupational choice model is
augmented with e
Xt and individuals are assumed to know its law
of motion. The aggregate supplies of skills are obtained by adding
individual skill supplies over all individuals in the economy:

Z
Sat =

kit (a)I a = α(xit , ωi , εit , e
Xt )



x,ω,

for a = 1, 2

(21)

where kit (a) is individual i’s stock of skill in occupation a, α() is the
optimal decision rule, and the integral represents the appropriately
weighted sum over the distribution of individual state variables.
In a (rational expectations) competitive equilibrium, the sequence of skill rental prices {r1t , r2t : t = 1, 2, . . .} and the law
of motion of e
Xt satisfy the following conditions. First, individuals
solve the occupational choice problem taking the law of motion of
e
Xt as given. Second, labor markets for both white and blue collar

23 This emergent microeconometric literature on estimation of dynamic GE
models is related to literature on GE models with heterogeneous agents. See
Krusell and Smith (1998) and Rios-Rull (1999). There is also an important and
large literature in labor economics on the estimation of equilibrium search models
with heterogeneous workers and firms. See Mortensen and Pissarides (1999) and
Eckstein and van den Berg (2007) for surveys.
24 As in Example 2 (Keane–Wolpin), the model here assumes that non-labor
income does not affect choices. More specifically, capital rental income is not a state
variable in the individual’s occupational choice and therefore its distribution in the
population has no effect on equilibrium prices.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

skills clear, i.e., the resulting aggregate skill supply functions, together with skill prices, satisfy the labor demand conditions (20).
And, third, the actual law of motion of e
Xt is consistent with individual’s beliefs. The equilibrium need not be stationary: besides
dependence on initial conditions e
X1 , there are other sources of
non-stationarity such as time variation in factor shares in the aggregate production function, changes in cohort sizes, cohort effects
in fertility, etc.
An important question the equilibrium model can address is the
extent to which ‘feedback’ effects offset the impact of policies such
as the college tuition subsidy evaluated by Keane and Wolpin in
partial equilibrium. That is, the subsidy may increase the supply of
white collar skills to the extent that it induces higher college enrollment. If the relative price of white collar skills falls as a result,
this reduces the returns to schooling and college enrollment. Lee
(2005) estimates the equilibrium model on CPS data and concludes
that feedback effects in the US were quite small. Lee and Wolpin
(2006) extend this framework, allowing for three occupations in an
economy with two sectors, goods and services. They estimate the
model on CPS and NLSY data and use it to study the determinants
of the large growth of employment in the service sector in the US
over the last 50 years. They conclude that demand factors (technological change and movements in product and capital prices) were
much more important than supply factors such as changes in cohort sizes or the decline in fertility. 
The estimation of this model is considerably more demanding
than that of its partial equilibrium version in Example 2 for two
reasons. First, imposing the equilibrium restrictions increases the
computational burden of estimation by an order of magnitude.
Second, estimation of the equilibrium model requires additional
data which can only be obtained from different sources and having
to combine multiple data sources poses some complications for
estimation and inference.
Recall that the state space of the individual agent’s occupational
et ,
choice problem is augmented with aggregate variables X
e.g. current and past values of skill prices, total factor productivity,
cohort sizes, the distributions of schooling and occupation-specific
experience, and other variables which predict future skill prices.
Note that any such variable omitted by the econometrician is a
potential source of endogeneity bias because it is likely to be
correlated with current skill prices. The dimensionality of e
Xt is
potentially so large as to make solution – let alone estimation –
infeasible without some further simplification. Lee (2005) assumes
that skill price sequences are deterministic and individual agents
have perfect foresight; in this case, the state space is augmented
with the sequence of current and future deterministic skill prices.
Lee and Wolpin (2006) assume that stochastic skill prices are
linear functions of a small number of state variables and search for
equilibria within this class of pricing functions. The equilibria they
consider are thus approximations to the ‘full’ stochastic rational
expectations equilibria implied by the model. For any given values
of the parameters to be estimated, the equilibrium laws of motion
solve a fixed point problem which uses as input the solutions
to the individual DP problems of all agents who interact in the
economy. This implies that a single evaluation of the estimation
criterion nests two layers of fixed point problems.25 The estimation
criterion is based on a set of moment conditions which summarize

25 Multiplicity of equilibria in these models cannot be ruled out in general, but
computing multiple equilibria – if they exist – is a difficult task. Because of this,
this issue tends to be ignored in empirical work. Estimation is carried out under
the assumption that the equilibrium is unique, and the validity of the assumption
is scrutinized at the final parameter estimates. The recent literature on estimation
of dynamic discrete games, which we review in Sections 2.3 and 4, has been more
concerned with the issue of multiple equilibria.

45

occupational choices and wages obtained from microsurvey data.
We review the estimation of these models in more detail in
Section 5.
2.3. Dynamic discrete games
The analysis of many economic and social phenomena requires
the consideration of dynamic strategic interactions between a
relatively small number of agents. The study of the dynamics of
oligopoly industries is perhaps the most notorious example of
these dynamic strategic interactions.26 Competition in oligopoly
industries involves important investment decisions which are
irreversible to a certain extent. Market entry in the presence
of sunk entry costs is a simple example of this type of
investment. Dynamic games are powerful tools for the analysis
of these dynamic strategic interactions. Until very recently,
econometric models of discrete games had been limited to
relatively simple static games. Two main econometric issues
explain this limited range of applications: the computational
burden in the solution of dynamic discrete games, and the
indeterminacy problem associated with the existence of multiple
equilibria. The existence of multiple equilibria is a prevalent
feature in most empirical games where best response functions are
nonlinear in other player’s actions. Models with multiple equilibria
do not have a unique reduced form and this incompleteness
may pose practical and theoretical problems in the estimation
of structural parameters. Furthermore, the computational burden
in the structural estimation of games is especially severe.
The dimension of the state space, and the cost of computing
an equilibrium, increases exponentially with the number of
heterogeneous players. An equilibrium is a fixed point of a system
of best response operators and each player’s best response is itself
the solution to a dynamic programming problem.
In Section 4 we review recent papers which have taken
Rust’s framework for single-agent problems, combined with
Hotz–Miller’s estimation approach, as a starting point in the
development of estimable dynamic discrete games of incomplete
information. Private information state variables are a convenient
way of introducing unobservables in the econometric model.27
Furthermore, under certain regularity conditions dynamic games
of incomplete information have at least one equilibrium while that
is not always the case in the corresponding complete information
versions, e.g. Ericson and Pakes (see Doraszelski and Satterthwaite,
2007). We provide here a description of the basic framework with
no payoff variables, based on suitably extended versions of the AS,
IID and CI-X assumptions (also see Rust (1994a,b) pp. 154–158).
Consider a game that is played by N players that we index
by i ∈ I = {1, 2, . . . , N }. Every period t these players decide
simultaneously a discrete action. Let ait ∈ A = {0, 1, . . . , J } be
the action of player i at period t. At the beginning of period t
a player is characterized by two vectors of state variables which
affect her current utility: xit and εit . Variables in xit are common
knowledge for all players in the game, but the vector εit is
private information of player i. Let xt ≡ (x1t , x2t , . . . , xNt ) be
the vector of common knowledge state variables, and similarly

26 Most of the recent applications of dynamic discrete games have estimated
dynamic oligopoly models within the framework proposed by Ericson and Pakes
(1995), or an extended version of that framework that incorporates incomplete
information.
27 As far as we know, there are no estimable dynamic games of complete information. The estimation of this class of games involves nontrivial complications. For
instance, other player’s current actions are not independent of common knowledge
unobservables. In contrast, unobservables which are private information state variables, independently distributed across players, can explain at least part of the heterogeneity in player’s actions without generating this endogeneity problem.

46

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

define at ≡ (a1t , a2t , . . . , aNt ), and let εt be the vector with all
player’s private information. Let Ui (at , xt , εit ) be player i’s current
payoff function, that depends on the actions of all the players,
the common knowledge state variables, and his own private
information εit . A player chooses his action to maximize expected
PT −t
discounted intertemporal utility Et [ j=0 β j Ui (at +j , xt +j , εi,t +j )],
where β ∈ (0, 1) is the discount factor. Players have uncertainty
about other player’s current and future actions, about future
common knowledge state variables, and about their own future
private information shocks. We assume that {xt , εt } follows a
controlled Markov process with transition probability function
F (xt +1 , εt +1 |at , xt , εt ). This transition probability is common
knowledge.
Let α = {αi (xt , εit ) : i ∈ I } be a set of strategy functions,
one

for each player. Player i’s strategy does not depend on εjt : j 6= i
because the shocks are private information. Taking as given the
strategies of all players other than i, the decision problem of player
i is just a standard single-agent DP problem. Let Viα (xt , εit ) be
the value function ofthis DP problem. The Bellman equation is
Viα (xt , εit ) = maxai ∈A viα (ai , xt , εit ) where, for every ai ∈ A,
α

vi (ai , xt , εit ) ≡ Eε−it {Ui (ai , α−i (xt , ε−it ), xt , εit )} + β Eε−it
Z

α
×
Vi (xt +1 , εt +1 )dF (xt +1 , εt +1 |ai , α−i (xt , ε−it ), xt , εt ) (22)
and Eε−it represents the expectation over other player’s private
information shocks. The best response function of player i is
bi (xt , εit , α−i ) = arg maxai ∈A viα (ai , xt , εit ) . This best response
function gives the optimal strategy of player i if the other players
behave, now and in the future, according to their respective
strategies in α−i . A Markov perfect equilibrium (MPE) in this game
is a set of strategy functions α∗ such that for any player i and for
∗
any (xt , εit ) we have that αi∗ (xt , εit ) = bi (xt , εit , α−
i ).
We now formulate the Assumptions AS, IID and CI-X the context
of this game.
ASSUMPTION AS-Game: The one-period utility function is additively
separable in common knowledge and private information components: Ui (at , xt , εit ) = ui (at , xt ) + εit (ait ), where εit (a) is the ath
component of vector εit . The support of εit (a) is the real line for all
a.
ASSUMPTION IID-Game: Private information shocks εit are independently and identically distributed over agents and over time with
CDF Gε (εit ) which has finite first moments and is continuous and
twice differentiable in εit .
ASSUMPTION CI-X-Game: Conditional on the current values of
player’s actions and common knowledge state variables, next
period common knowledge state variables do not depend on
current private information shocks: i.e., CDF (xt +1 |at , xt , εt ) =
Fx (xt +1 |at , xt ).
As in the case of single-agent models, under Assumpα
tions
R α AS, CI-X and IID the integrated value function V̄i (xt ) ≡
Vi (xt , εit )dGε (εit ) fully characterizes player i’s DP problem. The
R
integrated Bellman equation is V̄iα (xt ) =
maxai ∈A {viα (ai , xt ) +
εit (ai )}dGε (εit ) where



α

vi (ai , xt ) = Eε−it ui (ai , α−i (xt , ε−it ), xt )
+ β

Z


V̄iα (xt +1 )dFx (xt +1 |ai , α−i (xt , ε−it ), xt ) . (23)

Another implication of these assumptions is that a MPE can be described as a fixed point of a mapping in the space of CCPs which
‘integrate out’ player’s private information variables. Given a set of
strategy functions α = {αi (xt , εit ) : i ∈ I } we define a set of conditional choice probabilities Pα = {Piα (ai |x) : (i, ai , x) ∈ I × A × X }

such that,
Piα (ai |x) ≡ Pr (αi (xt , εit ) = ai |xt = x)

Z
=





I ai = arg max{viα (j, xt ) + εit (j)} dGε (εit ).

(24)

j∈A

These probabilities represent the expected behavior of firm i
from the point of view of the rest of the firms when firm i
follows its strategy in α. The value functions viα (ai , xt ) depend
on other player’s strategies only through other player’s choice
probabilities. That is, in Eq. (23)
P we can replace the expectation
Eε−it {. . . α−i (xt , ε−it ) . . .} by
a−i Pr(a−i |xt ; α){. . . a−i . . .} where

P

a−i

represents the sum over all possible values in AN −1 , and

Pr(a−i |xt ; α) =

Q

j6=i

Piα (aj |xt ). To emphasize this point we will use

the notation viP instead viα to represent these value functions. Then,
we can define player i’s best response probability function as:

Λ(ai |viP (·, xt ))

Z 
P
≡ I ai = arg max{vi (j, xt ) + εit (j)} dGε (εit ).

(25)

j∈A

Let α∗ be a set of MPE strategies and let P∗ ≡ {Pi∗ (ai |x) : for every (i, ai , x)} be the corresponding CCPs. Then, it is straightforward
∗
to show that for every (i, ai , x), Pi∗ (ai |x) = Λ(ai |viP (·, xt )). That is,
P∗ is a fixed point of P = Λ(v P ), where Λ(v P ) ≡ {Λ(ai |viP (·, x)) :
for every (i, ai , x)}. Given the assumptions on the distribution of
private information, we can define best response probability functions which are continuous in the compact set of player’s choice
probabilities. By Brower’s theorem, there exists at least one equilibrium. In general, the equilibrium is not unique.28
We now distinguish between observable and unobservable
variables from the point of view of the econometrician. In principle,
we could distinguish observable and unobservable components
both in common knowledge and in private information state
variables. We start with a more restrictive and simpler case.
ASSUMPTION OC : All the common knowledge state variables in
xt are observable to the econometrician, and all the private
information variables in εt are unobservable.
To complete this description of the econometric model we
should comment on the sampling framework. In the case of
single-agent models, we assumed that the econometrician has a
random sample of many agents (e.g., firms, households) behaving
according to the model. That is not the case in applications of
dynamic strategic games where typically the number of players
is quite small, e.g., firms in an oligopoly market, members of a
family, political parties, etc. We assume that the game is played
independently at different locations, indexed by m, and that we
have a random sample of M of these locations. Therefore, taking
into account Assumption OC, the data consist of:
Data = {amt , xmt : m = 1, 2, . . . , M ; t = 1, 2, . . . , Tm } .

(26)

Note that an assumption that is implicit in this description of the
data is that we observe the actions of all the players in the game.
Our next example illustrates models with strategic interactions
and is based on Aguirregabiria and Mira (2007).
Example 4 (An Entry–Exit Game of Incomplete Information). The
players are firms making decisions on whether to enter, continuing
to operate in, or exit from a market. The market is a small local
retail market and each active firm operates at one location or store.
We observe a random sample of markets, m = 1, 2, . . . , M . In

28 See Doraszelski and Satterthwaite (2007) and Aguirregabiria and Mira (2007)
for more details.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

each market there are N potentially active and infinitely lived
firms. Every period all firms decide simultaneously whether to
operate their store or not. If firm i in market m operates its store
at time t (aimt = 1), its variable profits depend on the number of
firms that choose to be active andon market demand
conditions,

as follows: θRS log (Smt ) − θRN log 1 +

P

j6=i ajmt , where θRS , θRN

are parameters. Market demand conditions are represented by
market (population) size, Smt . Market size is common knowledge
to firms and observable to the econometrician, and it follows a first
order Markov process. The parameters θRS and θRN measure the
sensitivity of variable profits to market size and to the number of
active competitors, respectively.29 Total current profits of an active
firm are:

!
Uimt (1) = θRS log (Smt ) − θRN log 1 +

X

ajmt

− θFC ,i

j6=i

− θEC ,i (1 − aim,t −1 ) + εimt (1)

(27)

where θFC ,i − εimt (1) is firm i’s fixed operating cost which has two
components: θFC ,i is time-invariant and common knowledge, and
εimt (1) is private
information of firm i and time-varying. The term

1 − ai,t −1 θEC ,i is an entry cost, where the entry cost parameter


θEC ,i is multiplied by 1 − ai,t −1 since this cost is paid only by
new entrants. If a firm does not operate its store, it can put its
capital to other uses. Current profits of a non-active firm, Uimt (0),
are equal to the value of the best outside opportunity. We assume
that Uimt (0) = εimt (0), which is private information of firm
i. The choice-specific private information variables, εimt (0) and
εimt (1), are transitory normally distributed shocks, iid across firms,
markets and time with zero mean.30
The vector of state variables of the game which are observable
to the researcher is xmt = (Smt , amt −1 ) where amt −1 = {aim,t −1 :
i = 1, 2, . . . , N } are indicators of incumbency status. Incumbency
status matters because incumbent firms do not pay entry costs
and are thus more likely to operate their store than nonincumbents. The unobservable state variables are the private
information shocks εimt . In this game, a firm’s strategy function,
αi (xmt , εimt ), is a binary decision rule. The associated conditional
choice probability, Piα (1|xmt ), is the probability that the firm
operates in the market.
Aguirregabiria and Mira estimate this model using panel data
of Chilean local retail markets. They assume that all potential
entrants in each market are identical and consider symmetric
equilibria.31 They estimate the model separately for five different
retail industries and analyze how fixed costs, the sensitivity of
profits to the number of active firms and the magnitude of sunk
costs contribute to explain differences in the number of active
firms across industries. As we describe in Section 4, Aguirregabiria
and Mira relax Assumption OC by including a time-invariant and
market-specific component of market profitability that is common
knowledge for firms but unobserved to the researcher. They find
that this unobserved market heterogeneity is important. Failure to
account for it may lead to implausible estimates of the parameter
θRN , which measures the sensitivity of profits to the number of
active competitors, because more profitable markets tend to have
a larger number of active firms in equilibrium. 

29 One may interpret variable profits as the equilibrium payoffs of a one-period
static game in which firms with identical products and variable costs compete in
quantities (i.e., Cournot).
30 We might write the value of the best outside opportunity as µ + ε (0), but
i

imt

the parameter µi cannot be identified separately from the average fixed cost θFC ,i
so we normalize it to zero.
31 Therefore, θ
and θ
is the same for all firms. Aguirregabiria et al. (2007a,b)
FC ,i

relax this assumption.

EC ,i

47

In order to illustrate Hotz and Miller’s CCP estimation method
and its extensions for single-agent problems we will use the
following simplified version of Example 4:
Example 4B (Entry–Exit Without Strategic Interactions). In Example 4, suppose that θRN = 0 such that, conditional on market size
St , firms’ variable profits are independent of the number of active
competitors. This assumption corresponds to markets with either
perfect or monopolistic competition. Then, the second term in the
payoff function (27) is zero and strategic interactions become irrelevant. Every period the firm has to decide whether to stay active or not taking into account the sunk costs θEC incurred each
time it decides to re-enter the market and the stochastic fluctuations in its profits brought about by changes in market size St , by
the idiosyncratic shocks to fixed operating costs εit (1), and by the
best outside opportunity εit (0). The state vector for firm i is now
xit = (St , ait −1 ), i.e., only the own incumbent status matters. Furthermore, suppose that εit (1) and εit (0) satisfy assumption CLOGIT
rather than being jointly normal. We are also assuming that structural parameters are identical across markets and firms and we
have dropped the m subscript so the t subscript now stands for
any market-period observation. 
The estimation of dynamic games, relative to single-agent models, poses several specific problems. Simple as Example 4 is, it illustrates how the size of the game’s state space tends to grow
exponentially with the number of players if it includes playerspecific state variables such as incumbency status. As in the competitive equilibrium model of Example 3, solving the model nests
two levels of fixed point problems, i.e., the best response equilibrium condition and the individual player’s dynamic programming problem. In order to alleviate the computational complexity,
one might attempt to estimate structural parameters from each
player’s individual decision problem and actions. But the decision
rule depends on the (lagged) actions of other players, such as their
incumbency status. If some aggregate state variables are unobservable (e.g., the permanent component of market profitability),
other player’s actions are endogenous.32 For given parameter values, multiple equilibria are a (likely) possibility which will make
the empirical model indeterminate and call for some additional
structure.
On a different level, note that Example 4 is different from the
first three in that only choice data are used in estimation. In the
first three examples, data on payoffs (i.e., wages) was also available.
‘Pure choice’ data is a fairly common situation which tends to make
estimation simpler because payoff data are often choice-censored
and corrections for selection can be more difficult to implement in
structural models, as we will see for Example 2. On the other hand,
it is clear that availability of payoff data is an important source
of identification. Furthermore, the basic framework that we have
described for empirical discrete games is easily extended to the
case in which payoff variables satisfy Assumption CI-Y.
3. Estimation methods for single-agent models
3.1. Methods for Rust’s model
We introduced Rust’s model as a single-agent model with the
additive separability, iid, conditional independence and logistic
assumptions. We describe four methods/algorithms which have
been applied to the estimation of this class of models: (1) Rust’s
nested fixed point algorithm; (2) Hotz–Miller’s CCP method;

32 And, furthermore, an initial conditions problem has to be taken into account.

48

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

(3) The NPL algorithm, a recursive CCP method Aguirregabiria and
Mira, 2002; and (4) A simulation-based CCP method Hotz et al.,
1994. The first of these is a full solution method, i.e., the DP
problem is solved for every trial value of the parameters. Methods
(2)–(4) avoid repeated full solutions of the DP problem, taking
advantage of the existence of an invertible mapping between
conditional choice probabilities and differences in choice-specific
value functions, a result due to Hotz and Miller (1993). Almost
all applications in models with more than two choice alternatives
have imposed the CLOGIT assumption on unobservables. Although
the CLOGIT assumption per se is not essential for the statistical
properties of Rust’s model and the methods which we review here,
it leads to closed form expressions for several of the econometric
model’s key objects. This is an advantage which all four of these
methods fully exploit, and CCP methods are specially dependent on
it. Extending the range of applicability of NFXP and CCP methods to
models which do not impose the CLOGIT assumption is a topic for
further research. One step in this direction is the estimation of DPnested logit models and models with generalized extreme value
(GEV) unobservables.33
3.1.1. Rust’s nested fixed point algorithm
The nested fixed point algorithm (NFXP) is a gradient iterative
search method to obtain the maximum likelihood estimator of the
structural parameters. More specifically, this algorithm combines
a BHHH method (outer algorithm), that searches for a root of
the likelihood equations, with a value function or policy iteration
method (inner algorithm), that solves the dynamic programming
problem for each trial value of the structural parameters. The
algorithm is initialized with an arbitrary vector of structural
parameters, say θ̂0 . A BHHH iteration is defined as:

θ̂k+1 = θ̂k +

N
X
∂ li (θ̂k ) ∂ li (θ̂k )
i =1

∂θ

∂θ 0

! −1

N
X
∂ li (θ̂k )
i=1

∂θ

To illustrate this algorithm in more detail, consider a version of
Rust’s DP conditional logit model with infinite horizon and discrete
observable state variables x. Let V̄(θ ) be the column vector of
values {V̄ (x, θ ) : x ∈ X }. Following Eq. (12), this vector of values
can be obtained as the unique fixed point in V̄ of the following
Bellman equation in vector form:
V̄ = log

J
X

!
exp u(a, θ ) + β Fx (a)V̄



(30)

a=0

where u(a, θ ) is the column vector of utilities {u(a, x, θ ) : x ∈
X } and Fx (a) is the transition probability matrix with elements
fx (x0 |a, x) for all x and x0 in X , where x and x0 denote the current
state and next period’s state, respectively. The choice probabilities
P (a|x, θ ) have the conditional logit form:
exp u(a, xit , θ ) + β Fx (a, x)0 V̄(θ )



P (a|x, θ ) =

J
P

exp u(j, xit , θ ) + β Fx



(31)

(j, x)0 V̄(θ )

j =0

where Fx (a, x) is the column vector {fx (x0 |a, x) : x0 ∈ X }. To obtain
∂
the gradient ∂θ
log Pit of this DP conditional logit model, it is useful
to take into account that the denominator in Eq. (31) is equal to the
exponential of V̄ (xit , θ ). It can be shown that this gradient has the
following analytic form:
0

∂ log Pit
∂ u(ait , xit )
∂ V̄
∂ V̄ (xit )
=
+β
Fx (ait , xit ) −
∂θu
∂θu
∂θu
∂θu
!
0
(32)
∂ log Pit
∂ Fx (ait , xit )0
∂ V̄
∂ V̄ (xit )
=β
V̄ +
Fx (ait , xit ) −
.
∂θf
∂θf
∂θf
∂θf
The expression for ∂θ∂ log Pit is equivalent to that of ∂θ∂ log Pit . And

!

u

Y

(28)

where li (θ ) is the log-likelihood function for individual i. Given the
form of the likelihood in Eq. (10), and that θ = (θu0 , θY0 , θf0 )0 , we
have:
∂ li (θ )
∂θ


Ti
X
∂
log P (ait |xit , θ )


∂θu


t =1
 Ti

Ti
X ∂
X ∂


= 
(29)
log P (ait |xit , θ) +
log fY (yit |ait , xit , θY ) 
.
∂θ
∂θ
Y
 t =1 Y

t =1
 T

Ti −1
i
X

X ∂
∂
log P (ait |xit , θ ) +
log fx (xi,t +1 |ait , xit , θf )
∂θf
∂θf
t =1
t =1
The terms ∂θ∂ log fY and ∂θ∂ log fx are standard because the
Y
f
transition probability function and the payoff function are
∂
primitives of the model. However, to obtain ∂θ
log P we need

to solve the DP problem for θ = θ̂k in order to compute the
conditional choice probabilities and their derivatives with respect
to the components of θ̂k . There are different ways to solve the
DP problem. When the model has finite horizon (i.e., T is finite)
the standard approach is to use backward induction. For infinite
horizon models, one can use either value function iterations
(described below) or policy function iterations, or an hybrid of
both.

33 See Arcidiacono (2004, 2005) for dynamic structural models with GEV
unobservables. Arcidiacono and Miller (2008) explore the use of CCP methods for
models with GEV unobservables.

given the Bellman equation in (30), the Jacobian matrix ∂ V̄(θ )/∂θ 0
is:

∂ V̄(θ )
=
∂θu0

I −β

J
X

! −1
P(a|θ ) ∗ Fx (a)

a =0

×

J
X

∂ u(a, θ )
P(a|θ ) ∗
∂θu0
a=0

!

J
X
∂ V̄(θ )
=
β
I
−
β
P(a|θ ) ∗ Fx (a)
∂θf0
a=0

×

! −1

(33)

!
∂ Fx (a)
P(a|θ ) ∗
V̄(θ )
∂θf0
a=0

J
X

where P(a|θ ) is the column vector of choice probabilities
{P (a|x, θ ) : x ∈ X }, and ∗ represents the element-by-element
product. Note that we obtain the gradient of the value functions
in a relatively simple manner as a by-product of the iterative DP
solution method. This is an important additional advantage of the
DP conditional logit specification. Without it, it would be necessary
to ‘perturb’ each element of θ and obtain new solutions of the
DP model for each perturbation in order to compute numerical
derivatives, which is much more costly.34
The NFXP algorithm proceeds as follows. We start with an
arbitrary value of θ , say θ̂0 . Given θ̂0 , in the ‘inner’ algorithm we

34 If policy iteration is used to solve the infinite horizon DP model, the gradient
of the value function can also be obtained as a by-product. The computational cost
of computing numerical derivatives is the main reason why BHHH, which avoids
second derivatives, is particularly useful in the estimation of structural models.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

obtain the vector V̄(θ̂0 ) by successive iterations in the Bellman
equation (30): starting with some guess V̄0 , we iterate in V̄h+1 =
PJ
log( a=0 exp{u(a, θ̂0 ) + β Fx (a)V̄h }) until convergence. Then,

given θ̂0 and V̄(θ̂0 ) we construct the choice probabilities P (a|x, θ̂0 )
using the formula in (31), the matrix ∂ V̄(θ̂0 )/∂θ 0 using (33), and the
gradient ∂ li (θ̂0 )/∂θ using Eq. (32). Finally, in the ‘outer’ algorithm
we use the gradient ∂ li (θ̂0 )/∂θ to make a new BHHH iteration to
obtain θ̂1 . We proceed in this way until the distance between θ̂k+1
and θ̂k or the difference in the likelihoods is smaller than a prespecified convergence constant.
When the model has finite horizon, we can solve for the value
function, its gradient and choice probabilities using backward
induction in the inner algorithm of the NFXP. That is, the sequence
of value vectors at ages T , T − 1, etc., can be obtained starting with
PJ
V̄T (θ̂) = log( a=0 exp{uT (a, θ̂ )}), and then using the recursive

PJ

formula V̄t (θ̂ ) = log( a=0 exp{ut (a, θ̂ ) + β Fx,t (a)V̄t +1 (θ̂ )})
for t ≤ T − 1. At each iteration the choice probabilities are
PJ
Pt (a|θ̂ ) = exp{ut (a, θ̂ ) + β Fx,t (a)0 V̄t +1 (θ̂ )}/[ j=0 exp{ut (j, θ̂ ) +

β Fx,t (j)0 V̄t +1 (θ̂ )}], and the gradients have the following recursive
PJ
0
forms ∂ V̄t (θ̂ )/∂θu0 =
a=0 Pt (a|θ̂ ) ∗ {∂ ut (a, θ̂ )/∂θu + β Fx,t (a)
P
J
∂ V̄t +1 (θ̂ )/∂θu0 } and ∂ V̄t (θ̂ )/∂θf0 = β a=0 Pt (a|θ̂ ) ∗ {∂ Fx,t (a)/
∂θf0 V̄t +1 (θ̂ ) + βb
Fx,t (a)∂ V̄t +1 (θ̂ )/∂θf0 }.
As any other gradient method, the NFXP algorithm returns
a solution to the likelihood equations. In general, the likelihood
function of this class of models is not globally concave. Therefore,
some global search is necessary to check whether the root of the
likelihood equations that has been found is actually the global
maximum and not just a local optimum.
We have described the NFXP algorithm in the context of full
information MLE (FIML). However, most applications of this algorithm have considered a sequential partial likelihood approach
first
P advocated by Rust. In the
Pfirst step, the partial likelihoods
log
f
(
y
|
a
,
x
,
θ
)
and
Y
it
it
it
Y
i ,t
i,t log fx (xi,t +1 |ait , xit , θf ) are separately maximized to obtain estimates of parameters θY and θf ,
respectively. This step does not involve solving the DP problem.
Given these estimators, in the second step the parameters in θu
are estimated using the NFXP algorithm and the partial likelihood
P
i,t log P (ait |xit , θu , θ̂Y , θ̂f ). Multiple-step strategies such as this
are widely used to alleviate the computational burden of estimation of dynamic programming structural models. The two-step
partial likelihood approach for Rust’s model relies on Assumptions CI-Y and CI-X as well as on rational expectations. It can greatly
simplify the estimation problem in models with many parameters in the transition probabilities. It was used by Rust and Phelan (1997) to estimate the model that we described in Example 1.
In that application, the state variables with stochastic transitions
were health status, health expenses, marital status and public pension points. The payoff function is the labor earnings equation.
There are two main reasons why this sequential approach reduces
the cost of estimating these and other models. First, the number of
BHHH iterations needed to reach convergence typically increases
with the number of parameters that are estimated. Note that BHHH
iterations here are particularly costly because they involve the full
solution of the dynamic programming problem. And second, the
computational cost associated with a global search increases as
well with the dimension of the parameter space. Nevertheless, it
should be noted that in the sequential partial likelihood approach
the calculation of standard errors in the second step correcting for
estimation error in the first step is not a trivial task. It is often no
more costly to consider a third estimation step consisting of a single FIML-BHHH iteration which, as it is well known, delivers an
asymptotically efficient estimator as well as the correct standard
errors.

49

There is a long list of applications which have used the NFXP
algorithm to estimate models in Rust’s class in different areas.
For instance: investment models of machine replacement, as in
Rust (1987), Sturm (1991), Das (1992), Kennet (1993, 1994), and
Rust and Rothwell (1995); or models of retirement from the labor
force, as in Rust and Phelan (1997), and Karlstrom et al. (2004).
In health economics, Gilleskie (1998) proposes and estimates a
dynamic model of workers’ decisions to visit a doctor and to miss
work during an episode of acute illness. In economic demography,
Ahn (1995) estimates a model of fertility and the value of children;
and Kennan and Walker (2005) a model of individual migration
decisions.
3.1.2. Hotz–Miller’s CCP method
The main advantages of the NFXP algorithm are its conceptual
simplicity and, more importantly, that it gives the MLE which
is asymptotically efficient under the assumptions of the model.
The main limitation of this algorithm is its computational cost. In
particular, the DP problem has to be solved exactly for each trial
value of the structural parameters. Given the cost of solving some
DP problems, this characteristic of the algorithm limits the range
of applications that are feasible, even in the DP conditional logit
case. Hotz and Miller (1993) observed that, under the assumptions
of Rust model, it is not necessary to solve the DP problem even
once in order to estimate the structural parameters A key idea
in their method is that, using nonparametric estimates of choice
and transition probabilities, it is possible to obtain a simple
representation of the choice-specific value functions v(a, x, θ ) for
values of θ around the true vector of structural parameters (see
also Manski, 1993, for a method that exploits a similar idea). This
representation is particularly simple and useful for estimation
in the DP conditional logit model with linear-in-parameters
utility as in Example 4B. We describe Hotz–Miller’s method in
detail for this case but we also include a brief discussion of
alternative specifications including the nonlinear, infinite horizon
case. Furthermore, we assume that the dataset does not include
payoff variables or, if it does, Assumption CI-Y holds and θY has
been estimated and subsumed into the known z functions.
Suppose that u(a, xit , θu ) = z (a, xit )0 θu where z (a, xit ) is a vector of known ‘basis’ functions. An example of this is the entry/
exit model with no strategic interactions, Example 4B in Section 2. In that model, the decision is binary, the vector of observable state variables is (St , ai,t −1 ), and the one-period payoffs are
u(0, xit , θu ) = 0 and u(1, xit , θu ) = θRS log (St ) − θFC − θEC (1 −
ai,t −1 ). Therefore, we can write these payoffs as u(a, xit , θu ) =
z (a, xit )0 θu , where z (0, xit )0 = (0, 0, 0), z (1, xit )0 = (log (St ) , −1,
−(1 − ai,t −1 )), and θu = (θRS , θFC , θEC )0 . In Hotz and Miller’s representation the choice-specific value functions are written as follows:35

v(a, xt , θ ) = z̃ (a, xt , θ )θu + ẽ(a, xt , θ )

(34)

z̃ (a, xt , θ ) is the expected and discounted sum of current and future z vectors {z (at +j , xt +j ) : j = 0, 1, 2, . . .} which may occur
along all possible histories originating from the choice of a in state
xt , if the individual behaves optimally in the future. More formally,
z̃ (a, xt , θ ) = z (a, xt ) +

T −t
X

β j E(xt +j ,εt +j )|at =a,xt

j =1




× z α xt +j , εt +j , θ , xt +j

35 Hotz–Miller’s representation can be derived either for alternative-specific value
functions or for the integrated value function (Emax function). We have preferred
to use the first version here.

50

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67
T −t
X

= z (a, xt ) +

To emphasize this point we use the notation z̃ P (a, xt ) to reprePT −t j
PJ
sent
P (a0 |xt +j )z (a0 , xt +j )] and ẽP (a, xt )
j=1 β Ext +j |at =a,xt [
a0 =0

β j Ext +j |at =a,xt

j=1


×

J
X

P (at +j |xt +j , θ )z (at +j , xt +j )

(35)

at +j =0

where α(·) is the optimal decision rule as defined in Section 2 and
Ext +j |at =a,xt (·) represents the expectation over the distribution of
xt +j conditional on (at = a, xt ), given that state variables evolve
as a controlled stochastic process defined by the optimal decision
rule and transition probability functions. Likewise, ẽ(a, xt , θ ) is the
expected and discounted sum of the stream {ε(at +j ) : j = 1, 2, . . .}
along the histories originating at (at = a, xt ) if the individual behaves optimally in the future.
ẽ(a, xt , θ ) =

T −t
X



β j E(xt +j ,εt +j )|at =a,xt ε α xt +j , εt +j , θ

j =1

=

T −t
X


β j Ext +j |at =a,xt 

j =1

J
X


P (at +j |xt +j , θ )e(at +j , xt +j ) .

(36)

at +j =0

The function e(a, xt ) is the expectation of εt (a) conditional on
xt and on alternative a being optimal, i.e., e(a, xt ) ≡ E (εt (a)|xt ,
α(xt , εt ) = a). Hotz and Miller showed that the conditional expectation e(a, xt ) is a function of choice probabilities and the distribution Gε only. To see why, first note that the event {α(xt , εt ) = a} is
equivalent to {v(a, xt ) + εt (a) ≥ v(a0 , xt ) + εt (a0 ) for any a0 6= a}.
Therefore,
e(a, xt ) = E εt (a)|xt , v(a, xt ) + εt (a)


≥ v(a0 , xt ) + εt (a0 ) for any a0 6= a
Z

1
=
εt (a)I εt (a0 ) − εt (a)
P (a|xt )
≤ v(a, xt ) − v(a0 , xt )∀a0 6= a dGε (εt ).

(37)

This expression shows that e(a, xt ) depends on the choice probability P (a|xt ), the distribution of εt , and the vector of value differences ṽ(xt ) ≡ {v(a, xt ) − v(0, xt ) : a ∈ A}. Second, choice
probabilities depend on the primitives of the model only through
the probability distribution
Gε and the vector of value differences
R
ṽ(xt ): i.e., P (a|xt ) = I {εt (a0 ) − εt (a) ≤ v(a, xt ) − v(a0 , xt )∀a0 6=
a}dGε (εt ). Hotz and Miller proved that this mapping relating choice
probabilities and value differences is invertible (see Proposition 1,
page 501, in Hotz and Miller (1993)). Thus, solving this inverse
mapping into Eq. (37), we have that e(a, xt ) is a function of choice
probabilities and the distribution Gε only. The particular form of
the mapping that relates CCPs and value differences depends on
the probability distribution Gε . For instance, in the model of Example 4B, v(1, xt ) (or v(0, xt )) is the firm’s expected stream of
profits if it decides to be active (or not active) in state xt and behave optimally thereafter. For this binary choice model, ṽ(xt ) =
v(1, xt ) − v(0, xt ). Under assumption CLOGIT on Gε the probabilexp(ṽ(x ))
ity that the firm will be active is P (1|xt ) = 1+exp(ṽ(tx )) . Inverting
t

this relationship we get ṽ(xt ) = log(P (1|xt )) − log(P (0|xt )). Also,
under the CLOGIT assumption,
the

 conditional expectation e(1, xt )
is equal to γ − log

exp(ṽ(xt ))
1+exp(ṽ(xt ))

similarly e(0, xt ) = γ − log



, where γ is Euler’s constant, and

1
1+exp(ṽ(xt ))



P
β j Ext +j |at =a,xt [ Ja0 =0 P (a0 |xt +j )e(a0 , xt +j )].36
= (θ , θf0 ) be the true value of θ in the population

to represent



. Using the inverse map-

ping above, it turns out that e(a, xt ) = γ − log P (a|xt , θ ).
Note that z̃ (a, xt , θ ) and ẽ(a, xt , θ ) depend on θ only through
the parameters in the transition probabilities, θf , and the vector
of CCPs, P(θ ) = {P (a|x, θ ) : (a, x) ∈ A × X }. In fact, we can
define z̃ and ẽ for an arbitrary vector of CCPs (optimal or not).

Let θ 0

P T −t
j =1
0
u

of individuals under study. And let P0 be the conditional choice
probabilities in the population. If we knew (P0 , θf0 ), we could
0

0

construct the values z̃ P (a, x) and ẽP (a, x) and then use Hotz
and Miller’s representation to approximate the choice-specific
values v(a, x, θ ) as simple linear functions of θu close to its
true value. Although we do not know (P0 , θf0 ), we can estimate
them consistently without having to solve the DP problem.
Consistent estimates of transition probabilities can be obtained
using a (partial) MLE of θf0 that maximizes the (partial) likelihood
P
i,t log fx (xi,t +1 |ait , xit , θf ). Conditional choice probabilities can be
estimated using nonparametric regression methods (i.e., P 0 (a|x) =
E (I {ait = a}|xit = x)) such as a Nadaraya–Watson kernel estimator
or a simple frequency estimator. Let P̂ and θ̂f be the estimators of
P0 and θf0 , respectively. Based on these estimates, Hotz and Miller’s
idea is to approximate v(a, xit , θ ) by z̃ P̂ (a, xit )θu +ẽP̂ (a, xit ) in order
to obtain the CCP’s in Eq. (31). They propose the GMM estimator
that solves in θu the sample moment conditions:
Ti
N X
X

H (xit )

i=1 t =1



n

o

exp z̃ P̂ (1, xit )θu + ẽP̂ (1, xit )

I {ait = 1} −
o
n

J
P

exp z̃ P̂ (a, xit )θu + ẽP̂ (a, xit )


a=0

..
×

.
o
n

P̂

exp z̃ (J , xit )θu + ẽP̂ (J , xit )

 I {ait = J } −
o
n
J

P
exp z̃ P̂ (a, xit )θu + ẽP̂ (a, xit )








=0







a =0

(38)
where H (xit ) is a matrix with dimension dim(θu )× J with functions
of xit which are used as instruments. For instance, in the entry–exit
model of Example 4B the vector θu has three parameters, the decision is binary (J = 1), and the vector of observable state variables
is (St , ai,t −1 ). Therefore, a possible choice for H (xit ) is the vector
(1, St , ai,t −1 )0 .
The main advantage of this estimator is its computational
simplicity. Nonparametric estimation of choice probabilities is a
(relatively) simple task. The main task is the computation of the
values z̃ P̂ (a, xit ) and ẽP̂ (a, xit ), based on a recursive version of
expressions (35) and (36) — more details are provided below.
However, these values are calculated just once and remain fixed
in the search for the Hotz–Miller estimator. In contrast, in a full
solution method such as the NFXP algorithm these values are
recomputed exactly for each trial value of θ . Thus, Hotz–Miller’s
method greatly reduces the computational burden of NFXP’s ‘inner’
algorithm. Another important advantage of Hotz–Miller’s CCP
estimator is that, for the DP conditional logit model with linearin-parameters utility, the system of equations (38) that defines the
estimator has a unique solution. Therefore, a global search is not
needed.
Previous conventional wisdom was that Hotz–Miller’s estimator achieved a significant computational gain at the expense of

36 For notational simplicity we omit θ as an argument, though it should be clear
f
that z̃ P (a, xt ) and ẽP (a, xt ) depend on P and θf .

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

efficiency, both in finite samples and asymptotically. Thus, researchers had the choice between two extremes: a full solution
NFXP-ML estimator with the attendant computational burden, or
the much faster but less efficient Hotz–Miller estimator. However,
Aguirregabiria and Mira (2002) showed that a pseudo-maximum
likelihood version of Hotz–Miller’s estimator is asymptotically
equivalent to partial MLE. The ‘two-step’ pseudo-maximum likelihood (PML) estimator is defined as the value of θu that maximizes
the pseudo-likelihood function37 :

values must satisfy the following recursive expressions:
z̃tP (a, xt ) = z (a, xt ) + β

=

i =1 t =1

×

fx (xt +1 |a, xt )

#
xt +1 )z̃tP+1

Pt +1 (a |
0

X

ẽPt (a, xt ) = β

( a , x t +1 )
0

(40)

fx (xt +1 |a, xt )

xt +1 ∈X

"

J
X

Pt +1 (a |xt +1 ) et +1 (a , xt +1 ) +
0

0

ẽPt +1

#

( a , x t +1 ) .
0

a 0 =0

n

o

exp z̃ P̂ (ait , xit )θu + ẽP̂ (ait , xit )
log

J

P

n

exp z̃ P̂ (a, xit )θu + ẽP̂ (a, xit )

o.

(39)

The asymptotic variance of this two-step PML estimator is just
equal to the variance of the partial MLE of θu described at the
end of Section 3.3.1. That is, the initial nonparametric estimator
of P0 and the PML estimator of θu0 are asymptotically independent
and therefore there is no asymptotic efficiency loss from using an
inefficient initial estimator of P0 . Nevertheless, although the twostep PML estimator is asymptotically equivalent to partial MLE,
Monte Carlo experiments show that its finite sample bias can be
much larger.38 Imprecise initial estimates of choice probabilities
do not affect the asymptotic properties of the estimator, but they
can generate serious small sample biases in the two-step PML
estimator and, more generally, in the whole class of Hotz–Miller’s
CCP estimators.39 The source of this bias is well understood in
two-step methods: P̂ enters nonlinearly in the sample moment
conditions that define the estimator, and the expected value of a
nonlinear function of P̂ is not equal to that function evaluated at the
expected value of P̂. The larger the variance of P̂, the larger the bias
of θ̂u . The variance of the nonparametric estimator of P 0 (a|x) =
E (I {ait = a}|xit = x) increases with the number of cells in the set
X . In applications with millions of cells in X and a few thousand
observations, the variance of P̂ and the bias of θ̂u can be very large.
A recursive extension of the two-step method, which we describe
in the next subsection, deals with this problem.
We now describe in some detail on the computation of the
values z̃ P (a, xt ) and ẽP (a, xt ). As defined in Eqs. (35) and (36), these

37 It is well known that the PML estimator belongs to the class of GMM estimators
defined in Eq. (38). More specifically, the PML estimator is the GMM estimator with
a matrix of instruments H (xit ) equal to the derivatives with respect to θu of the logprobabilities of alternatives 1 to J, i.e.,

∂ log Ψ (1|xit , θ, P̂)
∂ log Ψ (J |xit , θ, P̂)
,...,
∂θu
∂θu

!

where Ψ (a|xit , θ, P̂) represents the probabilities in the pseudo-likelihood function.
For instance, in the DP conditional logit model, the matrix of instruments of the PML
estimator is simply:



J
X

a 0 =0

×

a=0

H (xit ) =

X
xt +1 ∈X

"

Q (θu , P̂, θ̂f )
Ti
N X
X

51



H (xit ) = z̃ P̂ (1, xit ), . . . , z̃ P̂ (J , xit ) .

38 See the Monte Carlo experiments in Aguirregabiria and Mira (2002, 2007),
Pesendorfer and Schmidt-Dengler (2008), and Kasahara and Shimotsu (2007a).
39 As pointed out by Pakes et al. (2007), the bias of CCP estimators can be smaller
when the instruments H (xit ) do not depend on the first step estimator P̂. We discuss
this issue in Section 4.

For a finite horizon model we can obtain the sequence of values
{z̃tP (a, xt ) and ẽPt (a, xt ) : t = 1, 2, . . . , T } using backwards induction. Starting at the last period, we have z̃TP̂ (a, xT ) = z (a, xT ) and
ẽP̂T (a, xT ) = 0. For every t < T we iterate on Eq. (40). The computational burden incurred is equivalent to that of solving the finite
horizon DP problem once.
For stationary infinite horizon models such as Example 4B,
P we
can rewrite Eq. (40) as follows: z̃ P (a, x) = z (a, x) + β x0 ∈X
P
fx (x0 |a, x) WzP (x0 ); and ẽP (a, x) = β x0 ∈X fx (x0 |a, x)WeP (x0 ), where
in turn WzP (x) =

PJ

a0 =0

PJ

P (a|x)z̃ P (a, x) is a 1 × dim(θu ) vector; and


(x) = a0 =0 P (a|x) e(a, x) + ẽP (a0 , x) is a scalar. Both WzP (x)
and WeP (x) are basis functions for a policy valuation operator.40
Define the matrix WP ≡ {[WzP (x), WeP (x)] : x ∈ X }. Then, one
WeP

can show that WP is the unique solution to the following equation:
W=

J
X

P(a) ∗ {[z(a), e(a)] +β Fx (a)W}

(41)

a =0

where P(a) is the column vector of choice probabilities {P (a|x) :
x ∈ X }; z(a) = {z (a, x) : x ∈ X }; and e(a) ≡ {e(a, x) : x ∈ X }.
One can compute WP by successive approximations, iterating on
the right hand side of Eq. (41) which is a contraction mapping. The
computational cost involved in doing this is equivalent to that of
solving the infinite horizon DP problem once. Note that (41) is a
linear system, so there is a closed form expression for WP , i.e.,
P

W =

I −β

J
X

! −1
P(a) ∗ Fx (a)

a =0

J
X

P(a) ∗ [z(a), e(a)] .

(42)

a =0

When the number of cells in X is small enough, matrix inversion
algorithms may be preferable to successive approximations.41
Hotz and Miller derived another representation of choicespecific value functions for problems with ‘‘terminating actions’’,
which are actions leading to an absorbing state. For instance,
in Hotz and Miller (1993)’s model of fertility and contraceptive
choices irreversible sterilization is a terminating action leading
to an absorbing ‘infertile’ state. Hotz and Miller’s alternative
representation for these problems is also based on their inversion
theorem and it is considerably simpler to compute than the general
representation that we have described here because the valuation
step does not go more than one period into the future.42 The CCP

40 W P (x)θ + W P (x) is the expected discounted utility of behaving according to
u
e
z
choice probabilities P from current period t and into the infinite future when xt = x.
See Aguirregabiria and Mira (2002) for more detail.
41 The matrix (I − β F )−1 can also be approximated using the series I + β F +

β 2 F 2 + · · · + β K F K , with K large enough. This can be easier than matrix inversion.
More generally, this inverse matrix can be obtained iterating in A (successive
approximations) in the mapping A = I + β FA.
42 To see how this is achieved, consider the choice-specific value function v(a, x )

= u(a, xit ) + β

it

P

xi,t +1

V̄ (xit +1 )fx (xi,t +1 |a, xit ) where V̄ (xit +1 ) is the integrated

52

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

estimators based on this simpler representation have a different
asymptotic variance and have been used less often. A recent
example is Murphy (2008) who estimates a dynamic model of
housing supply where land owners choose the optimal time of
construction taking into account their expectations about future
prices and costs.
Our description of the CCP method has so far assumed that
the utility function is linear-in-parameters and that there is a
closed form expression for the e() function. We now discuss briefly
the role of these restrictions. First, if the utility is not linear-inparameters, we can represent the choice-specific value v(a, x, θ )
as z̃ P (a, x, θu ) + ẽP (a, x), where θu is now an argument in z̃ P (),
and z̃ P () is now a scalar. The recursive expression for ẽP in Eq. (40)
still applies and the one for z̃ P remains valid if we replace z (a, x)
by u(a, x, θu ) on the right hand side. The valuation matrix WP is
now {[WzP (x, θu ), WeP (x)] : x ∈ X } which uniquely solves the
system W =

PJ

a =0

P(a) ∗ {[u(a, θu ), e(a)] +β Fx (a)W}. For each

PJ

trial value of θu the terms
a=0 P(a) ∗ u(a, θ u ) do have to be
recomputed and pre-multiplied by rows of the ‘weighting’ inverse
matrix. This increases the computational cost relative to a model
with a linear-in-parameters utility. However, the inverse matrix
P
(I − β Ja=0 P(a) ∗ Fx (a))−1 only has to be computed once and
collects a large part of the calculations involved in valuation.43
Second, the e(a, x) function has a straightforward expression when
the ε ’s have independent extreme value distributions, as well
as in binary choice models when unobservables have normal
or exponential distributions (see Aguirregabiria and Mira (2007)
and Pakes et al. (2007) for examples in the context of dynamic
games). However, in multinomial models without extreme value
unobservables, e() does not have a closed form and would have
to be computed numerically or by simulation. Furthermore, in
general e() might depend nonlinearly on unknown parameters
and would have to be recomputed for different trial values of
the parameters. Therefore, relaxing the logistic assumption in the
multinomial case represents an important complication for all
methods which rely on Hotz–Miller’s invertibility result and their
usefulness outside this setting remains an open question.
It should also be noted that all the methods that use
Hotz–Miller’s representation of value functions are based on the
two-step partial likelihood approach and do not estimate the
discount factor β directly. To see why, recall that the valuation
operator relies on previously obtained consistent estimates of the
parameters θf of transition probability functions and on prior
knowledge of β . Without these, the present values z̃ P and ẽP
would have to be recomputed repeatedly for different values of θf
and β in the second step, rather than just once, and most of the
computational advantage of the Hotz–Miller approach would be
lost.
An important limitation perceived in Hotz–Miller’s CCP estimator and most of its extensions until very recently is that it cannot
accommodate permanent unobserved heterogeneity in the econometric model. If there is permanent unobserved heterogeneity, as

value function (or Emax). Hotz and Miller note that each of these one-periodahead Emaxes can be obtained as the value of choosing the terminating action
plus a weighted sum of utility differences. That is, if action 0 is the terminating
PJ
action then V̄ (xit +1 ) =
a=0 P (a|xi,t +1 ) [v(a, xit +1 ) + e(a, xit +1 )] = v(0, xit +1 ) +

PJ

PJ

P (a|xi,t +1 ) [v(a, xit +1 ) − v(0, xit +1 )] +
a=1 P (a|xi,t +1 )e(a, xit +1 ). By the
inversion theorem, the utility differences v(a, xit +1 ) − v(0, xit +1 ) and the
expectations e() are functions of conditional choice probabilities which in turn can
be estimated from the data.
43 This inverse matrix computes the expected number of times each state will be
a=1

in the finite mixture model of Example 2, it does not seem possible
to recover consistent nonparametric estimates of CCP’s (an essential element of Hotz–Miller’s two-step approach) from the mixture
observed in choice data. However, Aguirregabiria and Mira (2007),
Aguirregabiria et al. (2007a) and Arcidiacono and Miller (2008)
have recently proposed and applied recursive versions of the CCP
estimator which can be started with inconsistent estimates of CCP’s
but still obtain consistent estimates of the structural parameters of
finite mixture models. Also, Kasahara and Shimotsu (2007b) have
shown than under certain conditions it is possible to obtain consistent nonparametric estimators of CCPs in finite mixture models,
which can be used to construct a root-N consistent CCP estimator.
Some applications which have used the CCP estimator are:
contraceptive choice, Hotz and Miller (1993); price adjustment and
inventories in retail firms, Slade (1998), Aguirregabiria (1999); and
firms’ investment and labor demand, Sanchez-Mangas (2002) and
Rota (2004).

visited in the future, with each visit weighted by the corresponding discount factor.
Similar matrices could be obtained for the finite horizon, nonlinear-in-parameters
case but we are not aware of any application doing this.

3.1.3. Recursive CCP estimation (NPL algorithm)
Let θ̂u be the two-step PML estimator of θu0 that we have described above. Given this estimator, one can obtain new estimates
P̂1 =
o
n of the choice probabilities,
n {P̂1 (a|x)}, as P̂1 (ao|x) =
exp z̃ P̂ (a, x)θ̂u + ẽP̂ (a, x) /

PJ

j=0

exp z̃ P̂ (j, x)θ̂u + ẽP̂ (j, x) .

Given the new estimates P̂1 we can compute new values z̃ P̂1 (a, xit )
and ẽP̂1 (a, xit ), a new pseudo-likelihood function Q (θu , P̂1 , θ̂f ), and
a new PML estimator that maximizes this function. We can iterate in this way to generate a sequence of estimators of structural
parameters and conditional choice probabilities {θ̂u,K , P̂K : K =
1, 2, . . .} such that for any K ≥ 1:

θ̂u,K = arg max Q (θu , P̂K −1 , θ̂f )

(43)

θu ∈Θ

and

o

n

P̂K (a|x) =

exp z̃ P̂K −1 (a, x)θ̂u,K + ẽP̂K −1 (a, x)
J
P

n

exp z̃

P̂K −1

(j, x)θ̂u,K + ẽ

P̂K −1

o.
(j, x)

(44)

j =0

All the estimators in this sequence are asymptotically equivalent
to partial MLE and to the two-step PML (Aguirregabiria and
Mira, 2002, Proposition 4). Therefore, iterating in this procedure
does not give any asymptotic gain. However, it seems intuitive
that if the pseudo-likelihood is built from estimates of choice
probabilities that exploit the structure of the model one may
get estimates of structural parameters with smaller finite sample
bias an variance. Aguirregabiria and Mira (2002) present Monte
Carlo experiments that illustrate how iterating in this procedure
does in fact produce significant reductions in finite sample bias.
Kasahara and Shimotsu (2007a) provide a proof of this result using
higher order expansions for the bias and variance of the sequence
of PML estimators. Aguirregabiria and Mira also show that upon
convergence the recursive procedure gives, exactly, a root of the
likelihood equations. This result holds regardless of whether the
initial estimator of P0 is consistent or not, and the procedure is
called the nested pseudo-likelihood algorithm (NPL algorithm).
Therefore, the NPL procedure can be seen both as a method to
reduce the finite sample bias of Hotz–Miller’s CCP estimator and as
an algorithm to obtain the MLE. As a bias reduction method, we do
not have to iterate until convergence and the computational cost is
clearly smaller than NFXP. As an algorithm to obtain the MLE, it can
also be computationally much cheaper than NFXP. The example in
Aguirregabiria and Mira (2002) suggests that this is likely to be
the case in infinite horizon models when maximization in θu of
the pseudo-likelihood function is a simple task, such as Rust’s DP

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

53

conditional logit model with a linear-in-parameters utility where
the pseudo-likelihood is globally concave in θu .44
Furthermore, the choice probabilities obtained upon convergence of the NPL procedure are the optimal choice probabilities
corresponding to the parameter estimate. Thus the procedure does
not compute full solutions at every iteration but, unlike other CCP
methods, it delivers a full solution upon convergence. Moreover
the operator in Eq. (44) which updates choice probabilities at every iteration can also be used to compute the exact solution of the
DP problem for counterfactual parameter values.45
Applications of this method for single-agent models include: Aguirregabiria and Alonso-Borrego (2009) on labor demand;
Sanchez-Mangas (2002) and Lorincz (2005) on machine replacement and firms’ investment; and De Pinto and Nelson (2009) who
estimate a dynamic model of land use and apply it to study deforestation in a developing country.

Hotz et al. propose an estimator that is root-N consistent for
any number of simulations, even with R = 1. This property of
simulation-based estimators obtains when, in the system of equations that define the estimator, the unbiased simulator enters linearly and averaged over sample observations. This is not satisfied
by the simulation versions of the GMM estimator in (38) or of the
PML estimator. Hotz et al. consider a GMM estimator that exploits
moment conditions for the choice-specific value functions. Given
that the mapping that relates choice-specific value functions and
choice probabilities is invertible (see Proposition 1 in Hotz and
Miller, 1993), we can represent the value differences v(a, x, θ ) −
v(0, x, θ ) as functions of choice probabilities. For the DP conditional logit model, this inverse function has a very simple closed
form expression: i.e., v(a, x, θ ) − v(0, x, θ ) = log(P (a|x, θ )) −
log(P (0|x, θ )). Based on this representation, we can construct the
following moment conditions:

3.1.4. Simulation-based CCP estimator
Though Hotz–Miller’s CCP estimator is computationally much
cheaper than NFXP, it is still impractical for applications where
the dimension of the state space X is very large, e.g., a discrete
state space with millions of points or a model in which some of
the observable state variables are continuous. To deal with this
problem, Hotz et al. (1994) propose an extension of the Hotz–Miller
estimator that uses simulation techniques to approximate the

E

values z̃ P̂ (a, x) and ẽP̂ (a, x). For every value of xit in the sample and
every choice alternative a ∈ A (in the sample or not), we consider
(a, xit ) as the initial state and generate R simulated paths of future
actions and state variables from period t + 1 to t + T ∗ (i.e., T ∗
periods ahead). We index simulated paths by r ∈ {1, 2, . . . , R}.
The rth simulated path associated with the initial state (a, xit ) is
{a(i,rt,+a)j , xi(,rt,+a)j : j = 1, 2, . . . , T ∗ }. Then, Hotz et al. consider the
following simulators:

" ∗
T
1X X
R

β j z a(i,rt,+a)j , x(i,rt,+a)j
j=1
" ∗
#
T
R
1 X X j  ( r ,a ) ( r ,a ) 
P̂
ẽR (a, xit ) =
β e ai,t +j , xi,t +j .

z̃RP̂ (a, xit ) = z (a, xit )+

R r =1





#
(45)

j =1

(r ,a)

draw from the distribution fx (·|a, xit , θ̂f ). Then, the action ai,t +1 is a
(r ,a)

(r ,a)

(r ,a)

random draw from the distribution P̂ (·|xi,t +1 ). Given (ai,t +1 , xi,t +1 ),
then the state
(r ,a)

is a random draw from
(r ,a)

(r ,a)
(r ,a)
fx (·|ai,t +1 , xi,t +1 , θ̂f ),

and ai,t +2 is drawn from P̂ (·|xi,t +2 ). And so on. Simulations are
independent across the R paths. If the DP problem has finite
horizon, or if T ∗ is large enough such that the approximation error
associated with the truncation of paths is negligible, then these
simulators are unbiased. That is, for any number of simulations
R we have that ER (z̃RP̂ (a, xit )) = z̃ P̂ (a, xit ) and ER (ẽP̂R (a, xit )) =
ẽP̂ (a, xit ), where ER (.) is the expectation over the simulation draws.

44 Computational savings will be larger the smaller the number of NPL iterations
relative to the number of trial values of θu required by NFXP’s outer algorithm. Little
is known about the relative merits of NPL and NFXP in other contexts, e.g., finite
horizon models.
45 Given parameter values, the right hand side of Eq. (44) defines an operator
mapping CCP’s into CCP’s. Aguirregabiria and Mira (2002) show that this is a policy
iteration operator which can be used to compute the solution of the DP problem in
the space of conditional choice probabilities.



h(xit ) log

−

n



P 0 (ait |xit )
P 0 (0|xit )



n 0
o
0
− z̃ P (ait , xit ) − z̃ P (0, xit ) θu0

o 
=0
ẽ (ait , xit ) − ẽ (0, xit )
P0

P0

(46)

where h(xit ) is a vector of instruments with the same dimension as
θu . These moment conditions still hold asymptotically, as N goes
to infinity with R fixed, if we replace the population parameters
(P0 , θf0 ) by consistent estimates and the values z̃ and ẽ by the unbiased simulators z̃R and ẽR . Then, for the DP conditional logit model,
the simulation-based estimator is defined as the value of θu that
solves the sample moment conditions:
Ti
N X
X

"
h(xit ) log

P̂0 (ait |xit )

n

ẽP̂R

(ait , xit ) −

!

P̂0 (0|xit )

i =1 t =1

−

R r =1

Simulated paths are obtained using the initial estimates of choice
and transition probabilities, P̂ and θ̂f . The path is generated
sequentially. Starting at the observed state xit and given the
(r ,a)
hypothetical action a, the state next period, xi,t +1 , is a random

(r ,a)
xi,t +2



ẽP̂R

o
(0, xit )

n
o
− z̃RP̂ (ait , xit ) − z̃RP̂ (0, xit ) θu

#
= 0.

(47)

This estimator has a closed form expression. In fact, the expression
is the one of an IV estimator in a linear regression model. It is clear
that the simulation error averages out over the sample and does
not have any influence on the consistency or the rate of convergence of the estimator. However, the simulation error increases the
variance of the estimator: only as R goes to infinity, the asymptotic
variance of this estimator converges to the variance of the GMM estimator without simulation. The latter is larger than the variance of
the one-step PML estimator (i.e., the variance of MLE) because the
moment conditions in (46) are not the optimal ones.
Hotz et al. present several Mont Carlo experiments that
illustrate that this estimator can have large bias in small samples.
To the finite sample bias of the Hotz–Miller estimator now we
should add the bias due to the simulation error. Despite these
problems, this is a very interesting and useful estimator. The
estimator can be applied to models with continuous state variables
and it can be extended to deal with continuous decision variables
as well. Altug and Miller (1998) applied this method to estimate a
model of female labor supply where the decision variable, hours
of work, is continuous and censored. Other applications include
Miller and Sanders (1997) on welfare participation, and Hollifield
et al. (2004) on limit orders markets.
3.2. Estimation of Eckstein–Keane–Wolpin models
Under the label ‘Eckstein–Keane–Wolpin’ we grouped most
applications which have not used Rust’s DP conditional logit
model. Specifically, we listed the following four departures

54

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

from that framework: (1) Unobservables which do not satisfy Assumption AS; (2) Observable but choice-censored payoff or state variables; (3) Permanent unobserved heterogeneity;
(4) Unobservables which are correlated across choice alternatives.
The prevalent estimation criterion for Eckstein–Keane–Wolpin
models has been full solution FIML because the two-step partial
likelihood approach exploited in Rust’s framework does not give
consistent estimators under (2) and (3). The bulk of this section
will address the estimation of models allowing for (3) and (4),
i.e., methods for finite mixtures of likelihoods (Section 3.2.1) and
Keane and Wolpin’s simulation and interpolation method (Section 3.2.2). In the next two paragraphs we briefly discuss the estimation of models featuring (1) and (2).46
The main consequence of departing from AS is that the
econometric model may not be saturated. A discrete choice model
is saturated if for any value of the observable state variables
and of the structural parameters the model predicts a strictly
positive choice probability for any of the choice alternatives. Nonsaturation causes econometric and computational problems in
maximum likelihood estimation (see Rust, 1994a,b). A natural way
of dealing with this issue is to allow for measurement error in the
state and/or choice variables. For examples of this approach to deal
with non-saturated models see Wolpin (1987), pages 805–806, and
Keane and Wolpin (2001).
The problem with censored payoff or state variables was
illustrated in the occupational choice model of Example 2, where
wages are observed if individuals work but the distribution of
wages across occupations cannot be estimated consistently from
wage data alone because observed wages are a choice-censored
sample. The two-step partial likelihood approach described in
Section 3.3.1, which greatly reduces the computational burden of
estimation in Rust’s model, cannot be used here. The full likelihood
uses the structural behavioral model to correct for sample selection
bias.47
3.2.1. Finite mixture DP models (permanent unobserved heterogeneity)
The finite mixture framework and FIML estimation: Consider a more
general version of the finite mixture model introduced in Section 2,
with permanent unobserved heterogeneity in the utility function,
payoff function, and transition probabilities. Individuals in the population belong to one of L unobserved types indexed by `. The vector ω` represents unobserved heterogeneity, and π`|xi1 denotes the
mass (to be estimated) of type ` individuals conditional on the individual’s initial value of the state variables. We distinguish three
components in ω` , i.e., ω` = (ωu` , ωY` , ωf` ), which correspond to
heterogeneity in utility, payoff and transition rules, respectively.
In Example 2 there is heterogeneity in utility and payoffs but not
in transition probabilities because the laws of motion of schooling
and experience are deterministic. The set of structural parameters
consists of: π = {π`|x : ` = 1, 2, . . . , L; x ∈ X }; the set of values
Ω = {ω` : ` = 1, 2, . . . , L}; and the vector θ = (θu , θY , θf ), that
is invariant across types. As shown in Section 2, the contribution

46 Several of the seminal papers in this literature, such as Miller (1984), Wolpin
(1984, 1987) and Pakes (1986), precede Rust’s contribution and ‘deviated’ from his
framework. All these models considered binary choices and a single unobservable
state variable which resulted in a ‘threshold’ decision rule.
47 There are other approaches to estimate the wage equation consistently
controlling for selection. For instance, the model can provide exclusion restrictions
(i.e., variables that affect occupational choice but not wages) which can be used
to estimate the wage equation using a Heckman-type two-step method. See Vella
(1998) for a survey on sample selection models describing methods that have
extended Heckman’s two-step approach to selection models with multinomial
choices, panel data and nonparametric specification of the unobservables.

of agent i to the conditional log-likelihood in this mixture model
QTi
PL
is li (θ , Ω , π ) = log( `=1 π`|xi1 Li (θ , ω` )), where Li (θ , ω` ) is t =
1

`
i
P (ait |xit , ω` , θ )fY (yit |ait , xit , ωY` , θ ) t =
1 fx (xi,t +1 |ait , xit , ωf , θf ).
Conditional on type, the likelihood factors into conditional choice
probabilities, payoff probabilities, and state transition probabilities as in Rust’s model. However, unlike the log-likelihood in (10),
this log-likelihood is not additively separable because the type proportions appear inside the log.48 Consistent estimates of θY and
θf cannot be obtained separately because agents’ choices, which
appear in the payoff and transition probabilities, are not independent of the individual unobserved types. FIML estimation corrects
the endogeneity bias. This approach to allow for persistent individual heterogeneity is based on the seminal work by Heckman and
Singer (1984).49
The computational cost of estimation may be much larger than
in a similar model without permanent unobserved heterogeneity
because the likelihood of the choice history is maximized in the
full parameter vector and furthermore the number of times the DP
problem needs to be solved is multiplied by the number of types. As
noted before this is the reason why finite mixtures are used and the
number of types is kept small.50 Following Heckman and Singer, if
L is unknown the number of types can be estimated by increasing
L until the likelihood at the FIML estimates ‘does not increase’.
However, this search is expensive and typically L is set a priori. One
should be careful not to choose a large value for L. If the value of L in
the estimated model is larger than its true value in the population,
the model is not identified (e.g., there are multiple combinations of
the π`|xi1 parameters that can explain the data equally well). This
is another reason why most applications have considered a small
number of types.
The simplest estimable DP models with permanent unobserved
heterogeneity are those that combine Rust’s model with the
finite mixture framework. Some examples are: the model of
contraception and sterilization of Carro and Mira (2006); the model
of fertility and learning about child mortality of Mira (2007); the
model of health expenditures and labor supply of older men of Blau
and Gilleskie (2008); and the model of habits and teen age sex of
Arcidiacono et al. (2007a).

Q T −1

Sequential EM algorithm (ESM): Arcidiacono and Jones (2003)
propose a clever algorithm which makes the two-step partial
likelihood approach compatible with the finite mixture model.
Their insight is that additive separability of the log-likelihood,
which is the basis for the two-step partial likelihood strategy,
can be recovered in a ‘multi-cycle’ or ‘sequential’ version of the
well-known Expectation–Maximization (EM) algorithm. A key
element of Arcidiacono and Jones’ ESM algorithm is the ‘posterior’
probability that individual i belongs to unobserved type ` given her
observed history of choices and states. For the sake of simplicity,
ignore for the moment the initial conditions problem and assume
that π`|xi1 = π` . We also assume that conditional on type, Rust’s
Assumption CI-Y holds, i.e., conditional on type the payoff function
yit is independent of the transitory shocks εit . Let e
ai , e
xi and ỹi

48 If there is not permanent unobserved heterogeneity in the transition
probabilities, then we can write the full likelihood as the sum of two partial
likelihoods and θ f can be still estimated consistently by maximizing the partial
likelihood associated with transition data and without solving the DP problem.
49 In the context of discrete choice DP problems the papers by Miller (1984) and
Wolpin (1984) are the earliest example we are aware of.
50 There have been some attempts to estimate DP models with continuously
distributed permanent unobserved heterogeneity. The retirement model of
Berkovec and Stern (1991) is the earliest successful application we are aware
of. More recently, Ackerberg (2001) and Pantano (2008) have proposed methods
based on importance sampling techniques, and Imai et al. (2007) have used MCMC
methods.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

be individual i’s histories of actions, states, and payoff variables,
respectively. From Bayes’ theorem


π` Pr e
ai ,e
xi , ỹi |`; θ

Pr(`|e
ai ,e
xi , ỹi ; θ , Ω , π ) =
ai ,e
xi , ỹi |θ , Ω , π
Pr e
=

π` Li (θ , ω` )
exp {li (θ , Ω , π )}

(48)

where the functions Li (θ , ω` ) and li (θ , Ω , π ) are the likelihoods
that we have defined in (16). It can be shown that the FIML
estimator (θ̂ , Ω̂ , π̂ ) that maximizes the likelihood function (16)
satisfies the following conditions:
N
1 X

(a)

π̂` =

(b)

(θ̂ , Ω̂ ) = arg max

N i=1

Pr(`|e
ai ,e
xi , ỹi ; θ̂ , Ω̂ , π̂ )

{θ ,Ω }

N X
L
X

(49)

i=1 `=1

Pr(`|e
ai ,e
xi , ỹi ; θ̂ , Ω̂ , π̂ ) log Li (θ , ω` ).
Condition (a) is quite intuitive since it states that unconditional
type proportions and individual posterior probabilities have to
be mutually consistent. Condition (b) states that (θ̂ , Ω̂ ) also
maximizes a mixture of log-likelihoods, weighted by posterior
type probabilities. In this maximization the posterior weights are
kept fixed and appear outside the logs, so the mixture of loglikelihoods is once again separable in choice, payoff and state
transition factors.
These properties motivate Arcidiacono and Jones’ sequential
version of the EM algorithm. The algorithm is initialized with
an arbitrary vector {θ̂0 , Ω̂0 , π̂0 } in the space of the structural
parameters. Given {θ̂0 , Ω̂0 , π̂0 } we obtain a new vector {θ̂1 , Ω̂1 , π̂1 }
as follows:
‘‘E’’ step: Compute Pi`0 ≡ Pr(`|e
ai ,e
xi , ỹi ; θ̂0 , Ω̂0 , π̂0 ) as π̂`0 Li (θ̂0 , ω̂0` )

/ exp{li (θ̂0 , Ω̂0 , π̂0 )}.

Sequential ‘‘M’’ step For {Pi`0 } fixed, obtain {θ̂1 , Ω̂1 , π̂1 } using:
(a)
(b1)

π̂`1 =

N
1 X

N i =1

Pi`0

N X
L
X
(θ̂f 1 , ω̂f`1 ) = arg max
Pi`0
{θf ,ωf` } i=1 `=1
"T −1
#
i
X
`
×
log fx (xi,t +1 |ait , xit , ωf , θf )
t =1

(b2)

N X
L
X
(θ̂Y 1 , ω̂Y` 1 ) = arg max
Pi`0
{θY ,ωY` } i=1 `=1
" T
#
i
X
`
×
log fY (yit |ait , xit , ωY , θY )
t =1

(b3)

N X
L
X
`
(θ̂u1 , ω̂u1
) = arg max
Pi`0
{θu ,ωu` } i=1 `=1
" T
#
i
X
`
`
`
×
log P (ait |xit , ωu , ω̂Y 1 , ω̂f 1 , θu , , θ̂Y 1 , θ̂f 1 ) .
t =1

Then, use {θ̂1 , Ω̂1 , π̂1 } as the initial value and apply the ‘‘E’’
step and the sequential ‘‘M’’ step again. We proceed until
convergence in {θ̂ , Ω̂ , π̂ }. Arcidiacono and Jones show that, if
the algorithm converges, it obtains consistent and asymptotically
normal estimators. These estimators are not asymptotically
efficient because the sequential partial likelihood approach is used
in every M-step. The algorithm requires multiple maximization
steps, but each of them may be much less costly than full

55

information maximization. Arcidiacono and Jones illustrate their
method in a Monte Carlo experiment based on a model of schooling
choices. In their experiments, the ESM delivers estimators much
faster than FIML, with a small loss of precision.51
Example applications: Arcidiacono (2004) estimates a model of
the choice of college and major and studies ability sorting by major
and the returns to major; Arcidiacono (2005) extends that model to
include the choice of college applications and the process of college
admissions and uses it to study the impact of affirmative action in
admissions. Also see Arcidiacono et al. (2007b).
Initial conditions: As illustrated in Example 2, if the model has permanent unobserved heterogeneity then the first observation xi1
on which the likelihood is conditioned is potentially an endogenous variable because it is not independent of the individual’s
type: i.e., π`|xi1 ≡ Pr(`|xi1 ) 6= Pr(`). Following Heckman (1981),
there are two standard solutions to this problem. The first solution,
which has been the most common approach in life-cycle models, is
to complement the conditional likelihood derived from the structural DP model with an auxiliary model for the distribution of types
conditional on the initial value of the state variables. A sufficiently
flexible multinomial logit model can approximate arbitrarily well
the distribution of type ` as a function of xi1 . That is, for ` ≤ L − 1:
exp xi1 θπ ,`



π`|xi1 =

L −1

1+

P
`0 =1

exp



(50)

θ

xi1 π ,`0

where θπ ≡ {θπ ,` : ` = 1, 2, . . . , L − 1} is a vector of parameters to estimate, and θπ ,L is normalized to zero. This seems like the
most reasonable approach if the researcher thinks that the structural model does not apply to pre-sample periods. For instance, in
Keane–Wolpin occupational choice model, the authors did not believe that their structural model explained schooling at age 16, but
still treated this variable as endogenous.
In the second approach, it is assumed that the structural behavioral model explains the distribution of the initial values of
the state variables. Consider again Keane–Wolpin’s occupational
choice model. The initial age in their data and model (i.e., t =
1) is 16 years old. For the sake of illustration, suppose that at
some out-of-sample age lower than 16 (i.e., t0 < 1) the state
variables took the same value for all individuals. That is, all the
individuals at age t0 have the same level of formal education
and the same (zero) labor market experience. Therefore, for every individual i, xit0 = x0 where x0 is known to the researcher.
Also, assume that individual’s choice probabilities at ages in the
sample (i.e., t ≥ 1) can be extrapolated to ages younger than
16. Then, given the choice probabilities of the structural model,
we can obtain the probabilities Pr(xi1 |xit0 = x0 , ω` , θ ) for every type ` and every value xi1 in the sample. By Bayes rule,
P
0
π`|xi1 = π` Pr(xi1 |x0 , ω` , θ )/ L`0 =1 π`0 Pr(xi1 |x0 , ω` , θ ). Therefore, given the probabilities Pr(xi1 |x0 , ω` , θ ), we can construct
PL
the conditional log-likelihood function log( `=1 π`|xi1 Li (θ , ω` )),
where now the vector of parameters π contains the unconditional
mass probabilities of each type {π` : ` = 1, 2, . . . , L}, which are
primitive parameters of the structural model and are estimated together with θ . The key assumption for the validity of this approach
is the extrapolation of choice probabilities for periods t < 1. If
this assumption is correct, this ‘‘structural’’ approach to deal with
the initial conditions problem provides more efficient estimates of
the structural parameters than the first, ‘‘reduced form’’ approach.
However, the approach has two important limitations: it is com-

51 Bonhomme (2006) shows how to use the generalized information inequality
to simplify the calculation of the standard errors of this estimator of the mixture
model.

56

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

putationally much more intensive, and it relies on out-of-sample
extrapolations which may be not realistic in some applications.

function. Starting at the last period T , the simulator of Ṽ`T (x) is:53

In some applications some individual’s histories may be leftcensored which implies that individuals have different initial
periods. For instance, in Keane and Wolpin’s occupational choice
model suppose we do not observe all the individuals since age 16
but from very different initial ages, e.g., age 24, 28, etc. If we use
the ‘‘reduced form’’ approach to deal with the initial conditions
problem, we will have to allow the parameters θπ,` to vary in
a flexible way with the individual’s initial age. In this context,
the number of θπ parameters to estimate may be very large
and therefore the estimation of all the parameters can be quite
inefficient. Keane and Wolpin (2001) propose and implement a
simulation estimation method which deals with this problem, and
more generally with the problem of missing state or choice data,
which is in the same spirit as the ‘‘structural approach’’ that we
have described above. They simulate complete outcome histories
and match them to incomplete observed histories in order to
compute the probabilities of the latter. Because degeneracy would
occur even if the number of simulations is very large, they allow for
measurement error in both continuous and discrete variables. They
use this method to estimate a dynamic model of schooling choices
with savings decisions and borrowing constraints. More recently,
an alternative approach to the initial conditions problem has been
explored by Aguirregabiria and Mira (2007) (see Section 4.2).

Ṽ`T (x) =

R
1X

R r =1

n

(r )

o

max UT (a, x, εT , ω` , θ ) .

(51)

a∈A

At period t < T we already know the simulator of next period’s
Emax function, Ṽ`,t +1 (.). Then, the simulator of the Emax function
at period t is:
(
)
R
X
1X
(r )
`
0
0
Ṽ`t (x) =
max Ut (a, x, εt , ω , θ ) + β
Ṽ`,t +1 (x )fx (x |a, x) .
R r =1

a∈A

x 0 ∈X

(52)
Note that these Emax values should be calculated at every point
x in the support X . This can be very costly for DP problems
with large state spaces. In order to alleviate this computational burden the method obtains simulation-based approximations to the Emax function only at a (randomly chosen) subset
X̄t of the state points every period. The Emax at other points
are obtained as the predicted values from a regression function
which is estimated from the points in X̄t . In the model of career decisions, the arguments of the regression function were
{v t (a, x) − max [v t (1, x), . . . , v t (J , x)]}, where:



v t (a, x) ≡ Eεt Ut (a, x, εt , ω` , θ )
+β

X

Ṽ`,t +1 (x0 )fx (x0 |a, x).

(53)

x0 ∈X̄t +1

3.2.2. Keane–Wolpin’s simulation and interpolation method
Keane and Wolpin’s simulation and interpolation method
has been the most widely used for applications with finite
horizon problems, large state spaces and unobservables which are
correlated across choices, beginning with the occupational choice
model (see Keane and Wolpin, 1994). The estimation criterion
is FIML and individual contributions to the likelihood are the
finite mixtures shown in (16). Conditional on an individual’s
unobserved type Assumption CI-X holds so the likelihood factors
into conditional choice probabilities and the solution of the
DP problem is characterized by the Emax function. However,
the choice-specific unobservables do not have extreme value
distributions and are correlated so the CCP’s and Emax functions
do not have closed forms. Computing them involves solving Jdimensional integrals at every point x in the state space. Keane
and Wolpin use Monte Carlo integration to simulate these multiple
integrals. Furthermore the state space is large so at every time
period the Emax integrals are simulated at a subset of the
state space points only, and their value at every other point is
interpolated using a regression function which is fit to the points
in the subset.52
As before, solving the model essentially amounts to obtaining
the Emax function. In a finite horizon model, this is done by backwards induction. Let V̄`t (xt ) be the integrated value function, or
Emax function, at period t and for type `, as defined in Section 2.1.
(r )
Let {εt : r = 1, 2, . . . , R} be R random draws of histories of an
individual’s unobservables. Using these random draws we can construct simulation-based approximations (simulators) for the Emax

52 Other approximations have been used in finite horizon models. For instance,
Blau and Gilleskie (2006) ‘‘truncate’’ the decision horizon at a fixed period T and
approximate the value function at that period by a flexible ‘‘terminal’’ value function
in ‘‘reduced form’’ parameters which are estimated jointly with the structural
parameters. Wolpin (1992) increases the length of decision periods which are in
the distant future and fall outside the sample period; i.e., time aggregation is used
to reduce the number of state points and approximate the value function.

That is, the interpolating function depends on the state through
choice-specific value functions only. This interpolating function
worked very well in this example but the arguments are costly to
compute and the full state space has to be spanned in either simulation or interpolation. Using a polynomial in the state variables is
much cheaper because in order to approximate the Emax at state
x, we do not need to compute {v t (a, x)} and because of this we do
not need to know Emaxes at all states that may visited in the future
from x. Monte Carlo experiments reported in Keane and Wolpin
(1994) show that the method performed less well with a quadraticin-states approximation. In most subsequent applications, polynomial approximations have been used.
Given the Emax functions, the conditional choice probabilities
and the conditional density of the payoff variables can be
obtained using simulation.54 The parameters are estimated by
FIML. As Keane and Wolpin noted, the approximation errors in
the Emax functions enters nonlinearly in the CCP’s. Therefore,
simulated CCP’s are biased and this implies that estimators of
structural parameters are not consistent.55 To put this problem
into perspective, note that approximation error in the Emax is
not the only source of potential inconsistency; e.g., discretization
of continuous variables, approximate convergence of the Bellman
operator in infinite horizon problems, etc. Furthermore, the large
computational gain involved has allowed researchers using this
method to produce many interesting applications, estimating
models with very large state spaces and richer structures than
would otherwise be possible. Besides Keane and Wolpin (1997)’s
occupational choice model of Example 2, other leading examples

53 We describe a version of Keane–Wolpin method that uses a simple frequency
simulator. However, more efficient simulators can be used.
54 Simulation of CCP’s is needed only at sample points; kernel smoothing is used
in this case, in order to avoid empty cells and to enable the use of gradient methods
in the maximization of the likelihood. Note that the same draws of ε ’s are used for
the simulation of CCPs and the conditional density of wages.
55 A bias remains as long as interpolation is used, even if the number of simulation
draws goes to infinity.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

are Eckstein and Wolpin (1999)’s study of the determinants of high
school exit or completion and the model of congressional careers
of Diermeier et al. (2005).
3.3. Other issues in the estimation of single-agent models
3.3.1. Serially correlated unobservables and continuous state variables
We begin this section reviewing methods and applications
for models where unobservable state variables follow stochastic
process with serial correlation. There are two main issues in
the estimation of this class of models. First, the observable state
variable xt is not a sufficient statistic for the current choice and the
probability of an individual’s choice history cannot be factored into
CCP’s conditional on xt alone. Therefore, computing that individual
contribution involves solving an integral over all possible histories
of unobservables which are compatible withe the observed data.
The dimension of this integral is Ti , the number of longitudinal
observations. The earliest examples of this can be found in the job
matching model of Miller (1984) and in the paper by Pakes (1986)
on patent renewal. Pakes’ paper was also one the first econometric
applications that used Monte Carlo simulation techniques to
approximate high-dimensional integrals.56 Since Pakes’s paper,
there have been very important contributions in the areas of
Monte Carlo integration (see Geweke, 1996) and simulationbased estimation methods (see Hajivassiliou and Ruud, 1994;
Stern, 1997). An important contribution was the development
of the Geweke-Hajivassiliou-Keane (GHK) simulator.57 This is a
very efficient importance sampling simulator of multinomial
probabilities in discrete choice models with normally distributed
unobservables. The use of this simulator reduces significantly the
approximation error and thus the bias and variance of simulationbased estimators. An example of the application of this type of
simulators is the paper by Brien et al. (2006) that applies the
GHK simulator in the estimation of a dynamic structural matching
model of cohabitation, marriage and divorce.
A second important issue is that a DP problem with continuous
state variables – observable or unobservable – cannot be solved
exactly and needs to be approximated using interpolation methods
or polynomial approximations.58 To illustrate this issue consider
the occupational choice model in Example 2 where, for every
choice alternative, we omit the random effect ωi (a) but relax
the IID assumption in εit (a). For instance, suppose that εit (a)
follows an AR(1) process, εit (a) = ρa εi,t −1 (a) + ξit (a). The value
function of this DP problem depends on εit , which is a vector
of continuous variables, and cannot be solved exactly. Note that
the problem cannot be solved by considering the integrated value
function,
as in models where εit is iid, because the ‘‘Emax’’ V̄ (xit ) ≡
R
V (xit , εit )dGε (εit ) does not characterize the solution of the DP
problem at t − 1.59 There are two classes of approximation methods
to solve this type of DP problems: interpolation methods, and
polynomial approximations. Stinebrickner (2000) discusses these
methods in the context of a dynamic discrete choice structural

56 See also the seminal work by Lerman and Manski (1981).
57 See Geweke (1991), Keane (1994) and Hajivassiliou and McFadden (1998) for
the original sources.
58 This second issue is not a problem in Pakes’ patent renewal model. A nice
feature of that application is that the particular structure of the model (i.e., optimal
stopping problem and the specification of the stochastic process of εt ) is such that
it is possible to obtain an exact recursive solution of the threshold values that
characterize the optimal decision rule.
R
59 Note that the integrated value function V̄ (x , ε
) ≡
V (x , ρε
+
it

i,t −1

it

it −1

ξit )dGξ (ξit ) fully characterizes the solution of the DP problem. However,
V̄ (xit , εi,t −1 ) has the same dimension as V (xit , εit ).

57

models with serial correlation and he presents some examples
to illustrate the relative strengths of the various approximation
approaches. His experiments suggest that, at least for models with
normally distributed variables, interpolating methods based on
Hermite and Gauss–Legendre quadrature perform very well even
when the degree of serial correlation is high. Stinebrickner (2001)
applied Hermite quadrature interpolation to solve and estimate a
dynamic model of teacher labor supply. More recently, Bound et al.
(2010) have used a similar method in the context of a structural
model of retirement where a component of an individual’s health
is unobserved to the researcher and it is a continuous and serially
correlated random variable. The study in Benitez-Silva et al. (2005)
presents a very extensive comparison of different strategies for
solving dynamic programming problems with continuous, serially
correlated state variables. One of the methods considered in that
paper is the parameterized policy iteration method. This solution
method has been used by Hall and Rust (2005) in the estimation of
a model of inventory investment and price speculation by a durable
commodity intermediary. The simulation–interpolation method
in Keane and Wolpin (1994) could also be used for this class of
models.
The papers by Melnikov (2000) and Hendel and Nevo (2006)
present an interesting and useful approximation method for the
estimation of dynamic demand models with large state spaces.60
Hendel and Nevo estimate a dynamic model for the demand of a
differentiated storable good (laundry detergent) using consumer
scanner data. They use the estimated model to study long-run
and short-run demand responses to temporary price reductions
(i.e., sales promotions). The state space in this model includes
prices and advertising expenditures for all brands in all sizes of
the product: more than one hundred continuous state variables.
Hendel and Nevo show that in their model the probability of
choosing a brand conditional on quantity does not depend on
dynamic considerations, and therefore many of the demand
parameters can be estimated from a static brand-choice model
without solving the DP problem. Once these parameters are
estimated, it is possible to construct a single index (or inclusive
value) for each quantity choice (four quantity choice alternatives).
These four indexes summarize all the relevant information in
prices and advertising expenditures for the current utility of an
individual. Then, Hendel and Nevo assume that these inclusive
values follow a first order Markov process: i.e., all the information
in current prices and advertising that is relevant to predict next
period inclusive values can be summarized in today’s inclusive
values. Under this assumption, more than hundred state variables
can be summarized in just four state variables. This is a very
convenient approach in the estimation of dynamic demand models
of differentiated products.61 Even under these assumptions the
solution of the DP problem in this model is cumbersome: the
vector of state variables consists of the inclusive value, consumer
inventory, and an unobserved shock in the marginal utility of
consumption, which are all continuous variables. Thus, Hendel
and Nevo also use interpolation techniques to approximate the
solution of the DP problem. They use the parameterized policy
iteration method in Benitez-Silva et al. (2005) as the ‘inner
algorithm’ in a nested fixed point algorithm similar to Rust’s.

60 Melnikov’s and Hendel and Nevo’s approaches have clear similarities with the
use of Gittins’ indexes in the estimation of an occupational choice model in Miller
(1984).
61 Nevertheless, under realistic specifications for the stochastic process of prices
and brand-choice parameters, the assumption of a Markov process for inclusive
value can be clearly rejected. On the positive side, this is an assumption that can be
tested empirically and that can be relaxed to a certain extent, e.g., a higher order
Markov process. See Erdem et al. (2003) for a similar application with different
assumptions and estimation method.

58

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

3.3.2. Approximation error and inference
Numerical methods provide only approximations to the solution of dynamic decision models with continuous state variables.
Therefore, the researcher cannot calculate the exact likelihood
function (or other sample criterion function) of the model but only
an approximated likelihood based on his approximated solution to
the model. An important question is what are the implications for
statistical inference of using an approximated likelihood function.
The literature on simulation-based estimation has dealt with the
implications of simulation errors on the asymptotic properties of
estimators. However, much less is known when the approximation error does not come from using Monte Carlo simulators but
from other numerical methods such as interpolation techniques.
The standard practice in applications that use interpolation techniques has been to conduct inference as if the exact solution of
the model were used and to ignore the effects of approximation
errors. In this context, the recent paper by Fernández-Villaverde
et al. (2006) contains some important contributions to this difficult topic. They show that convergence of the approximated policy function to the exact policy function does not necessarily imply
that the approximated likelihood function also converges to the
exact likelihood. Some additional conditions are needed for convergence of the likelihood function. In particular, in addition to regularity conditions to have a well defined likelihood function, the
optimal decision rule and the transition rule of the state variables,
as functions of the vector of structural parameters, should be continuously differentiable and have bounded partial derivatives. They
also propose a likelihood ratio test to check for the importance of
errors in the approximated likelihood. Suppose that a researcher
is using interpolation methods to approximate the solution of a
DP model and that he solves and estimates the model under two
different levels of approximation error, e.g., two different grids of
points in the state space. We can interpret the two different approximations as two competing models. We want to test if the data
significantly support one approximation over the other one. Let l̂(1)
and l̂(2) be the maximum values of the two likelihood functions
under the two levels of approximation error. The likelihood ratio
statistic is LR = l̂(1) − l̂(2) . Vuong (1989) develops the asymptotic
behavior of this statistic for both nested and non-nested models
and his results are general enough to include the case we consider
here. Based on this test, Fernandez-Villaverde et al. suggest to use
an increasing approach to choose the degree of accuracy in the numerical solution of the model. That is, to increase the accuracy of
the numerical solution until the likelihood ratio test cannot reject
that the less accurate solution is statistically equivalent to the more
accurate solution.62
3.3.3. Bayesian methods
The computational cost of evaluating the likelihood in structural dynamic discrete choice models has so far made Bayesian
inference in these models intractable.63 If a Markov Chain Monte
Carlo algorithm (MCMC) is used, the number of likelihood evaluations that is required is typically much larger than in the case of

62 Recently, Geweke (2007) and Ackerberg et al. (forthcoming) have raised
some important concerns about the properties of the likelihood ratio test
proposed by Fernandez-Villaverde et al. They show that it is possible to construct
simple and plausible examples such that the MLE based on the approximated
likelihood is different from the MLE based on the exact likelihood even when the
approximation index (i.e., number of cells in the approximation) goes to infinity. In
those cases, the likelihood ratio test may be seriously biased.
63 An exception is Lancaster (1997) who demonstrates the feasibility of Bayesian
inference in a search model with closed form solutions. Geweke and Keane (2000)
show how to do Bayesian inference when the future component of the value
function is replaced by a flexible approximation in order to avoid the burden of
full solution.

algorithms tailored to classical likelihood-based inference. In a recent paper, Imai et al. (2007) propose an estimation method which
promises to alleviate this problem significantly. At each iteration,
a modified Metropolis–Hastings step is combined with a single iteration in the Bellman equation which updates the value function
and replaces the full solution of the DP problem. Therefore, estimation and solution proceed simultaneously. This is in the same spirit
as Aguirregabiria and Mira’s NPL algorithm, but gradual updating
of the DP solution is carried out in ‘value function space’ rather
than in ‘conditional choice probability space’. Imai et al. show that
the approximate solution converges to the full solution and the approximate posterior converges to the true posterior. They illustrate
their method in Monte Carlo experiments with uninformative priors for models of firm entry and exit which allow for continuously
distributed random effects and continuous state variables.
3.3.4. Validation of dynamic structural models
One of the most attractive features of dynamic structural
models is that they can be used to predict the effects of
counterfactual policy changes (or ex ante policy evaluation). Clearly,
a prerequisite for such an exercise is that the researcher has
enough confidence in the estimated structural model, i.e., the
model needs to be validated. Some of the most commonly used
criteria for validation of dynamic structural models have been:
(a) conformity with the researcher’s priors on ‘‘admissible’’ ranges
of parameter values, based on economic theory and/or previous
empirical work; (b) informal assessment of goodness of fit;
(c) formal specification tests such as goodness of fit and overidentifying restrictions tests (see Andrews, 1988; Rust, 1994a,b).
However, these criteria may seem insufficient for the purpose of
credible policy evaluation. First, many researchers are concerned
about identification. Second, goodness of fit and over-identifying
restrictions tests are of limited usefulness when the estimated
model is the result of pretesting (or ‘‘structural data mining’’, as
referred by Wolpin, 2007). Alternative specifications with very
similar in-sample performance may provide very different outof-sample predictions of the effects of counterfactual policies.
In fact, as pointed out by Wolpin (2007), it can be the case
that some model features that contribute to improve in-sample
goodness-of-fit may have a negative effect on the performance
of the model for the prediction of counterfactual experiments.
Then, how should we choose among these models? First, if the
structural model will be use to predict a counterfactual policy, it
seems reasonable that the model should be judged in terms of its
ability to predict that particular policy. In this sense, the ‘‘best’’
model depends on the type of counterfactual policy one wants to
predict. Social experiments and exogenous regime swifts provide
very useful information for the credible validation of a structural
model. Subject to identification issues, one can estimate the
structural model using the control-group subsample and then use
the experimental group to evaluate how well the model predicts
the effects of the policy intervention which was the object of the
social experiment. Once a model has been selected in this way, it
can be used to predict extrapolations of the policy in the social
experiment. This idea has been used before in dynamic structural
models by Lumsdaine et al. (1992), to predict retirement behavior
under alternative pension plans, and by Todd and Wolpin (2006),
to predict the effect of subsidies on children school attendance in
Mexico.
However, for good or for bad, social experiments and regime
swifts are a rarity. In a recent paper, Keane and Wolpin (2007)
propose an approach for model validation that is in this same
spirit but can be used when non-experimental data is available.
The approach consists in holding out a subsample that is subject
to a policy change along the same dimension as the counterfactual
policy that we want to evaluate. The holdout sample plays the same

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

role as the treatment group sample when a social experiment is
available: it is not used for estimation but it is used to validate the
predictive ability of the model. Keane and Wolpin (2007) explore
the use of variation in welfare policies across states as a validation
tool in a model of welfare participation, work, schooling and
fertility choices of young women. This idea seems very interesting,
although the fact the subsample selection is not random introduces
nontrivial econometric issues.
3.3.5. Relaxing rational expectations
The assumption of rational expectations has been ubiquitous
in this literature. Nevertheless, this is a very strong assumption
in many applications. Information is costly and individuals typically make predictions using different sets of partial information. Though the rational expectations assumption in empirical
structural dynamic programming models is made for identification
reasons (i.e., observed choices may be consistent with many alternative specifications of preferences and expectations), if incorrect
it can induce serious biases in our predictions of counterfactual experiments. Data on expectations can be used to relax or to validate assumptions about expectations, and it can make the predictions of dynamic structural models more credible. Manski (2004)
presents an excellent review on the use of data on subjective expectations in microeconometric decision models (see also Delavande, 2006). In the context of dynamic discrete choice structural
models, two examples are the study of teen fertility and unwanted
births by Walker (2003), and the study by Van der Klaauw and
Wolpin (2005) on Social Security and savings.
The standard framework common to all the work reviewed
in this survey also assumes that agents are forward looking and
that their preferences are time-separable and time-consistent.
A common practice in many applications has been to test the
hypothesis that β = 0, which is a test of forward looking behavior
—conditional on the rest of the model’s structure. In a recent
paper, Arcidiacono et al. (2007b) study whether the patterns of
heavy drinking and smoking of late-middle-age men, observed
in the US Health and Retirement Study, can be explained
better by myopic models than by models of forward looking
behavior. They estimate a sequence of rational-addiction models
which differ by individual’s degree of forward looking behavior.
Interestingly, they find that forward looking models explain
observed individual behavior better than myopic models. Fang
and Silverman (2007) estimate a model of labor supply and
welfare program participation of single mothers with dependent
children which allows for quasi-hyperbolic discounting. They
provide estimates of the degree of time inconsistency and use
their model to explore the behavioral and utility consequences
of welfare reforms which may be interpreted as commitment
mechanisms.
4. Estimation methods for dynamic discrete games
As we did for single-agent models, we distinguish between
the structural parameters in the utility function, θu and in the
transition rules of the state variables, θf . Under assumption CIX-Game, we do not have to deal with the problem of calculating
a MPE of the game in order to estimate θf . We can estimate
θf as the vector that maximizes the partial likelihood function
t =1 log fx (xm,t +1 |amt , xmt ; θf ). We assume hereafter that
β is known and that θf has been estimated in a first step and we
focus on the estimation of the parameters in θu , which requires

PM

m=1

PTm −1

that we exploit the equilibrium structure of the game. In some
applications the data may include ‘‘payoff variables’’ such as sales
or cost data. If payoff variables are ‘‘conditionally independent’’ of
private information shocks then the first step may also include the
estimation of the parameters of the ‘‘payoff functions’’ as in the

59

single-agent problems of Section 3. Following most of the papers
in this literature, we make the assumption that the observations
in the data have been generated by only one Markov Perfect
equilibrium.
ASSUMPTION One-MPE-Data: Define the distribution of amt conditional on xmt in market m at period t as P0mt ≡ {Pr(amt = a|xmt =
x) : (a, x) ∈ AN × X }. (A) For every observation (m, t ), P0mt = P0 .
(B) Players expect P0 to be played in future (out of sample) periods. (C) The observations {amt , xmt } are independent across markets and Pr (xmt = x) > 0 for all x in X .
Assumption (A) establishes that the data has been generated
by only one Markov Perfect equilibrium. Thus even if the model
has multiple equilibria, the researcher does not need to specify
an equilibrium selection mechanism because the equilibrium that
has been selected will be identified from the conditional choice
probabilities in the data. We will discuss in Section 4.2 how this
assumption can be relaxed. Assumption (B) is necessary in order
to accommodate dynamic models. Without it, we cannot compute
the expected future payoffs of within-sample actions unless we
specify the beliefs of players regarding the probability of switching
equilibria in the future.
Following the notation in Section 2.3, let Λ(v P (θ )) ≡ {Λ(ai |
P
vi (·, x, θ )) : (i, ai , x) ∈ I × A × X } be the equilibrium best response
mapping of the dynamic game. Furthermore, let viP (ai , x, θ )
hereafter denote Hotz–Miller’s representation of choice-specific
value functions, adapted to this context (see details below).
Aguirregabiria and Mira (2007) show that, for given θ , a vector
of conditional choice probabilities P is a MPE of the game if and
only if it satisfies the fixed point condition, P = Λ(v P (θ )). For the
description of several estimators in this literature, it is convenient
to define the following pseudo-likelihood function:
Q (θ , P) =

Tm X
M X
N
X

ln Λ(aimt |viP (·, xmt , θ ))

(54)

m=1 t =1 i=1

where P is an arbitrary vector of player’s choice probabilities.
This is a ‘‘pseudo’’ likelihood because the choice probabilities
Λ(aimt |viP (·, xmt , θ )) are not necessarily equilibrium probabilities
associated with θ , but just best responses to arbitrary beliefs P
about other player’s behavior. The MLE can be defined as:

(
θ̂MLE = arg max
θ∈Θ

)
sup

P∈(0,1)N |X |

Q (θ , P) subject to : P = Λ(v (θ )) .
P

(55)
For given θ , the expression P = Λ(v P (θ )) defines the set of vectors
P which are equilibria associated with that value of the structural
parameters. For some values of θ that set may contain more than
one P and therefore to obtain the MLE one should maximize
over the set of equilibria. Under standard regularity conditions,
multiple equilibria does not affect the standard properties of the
MLE which in this model is root-M consistent, asymptotically
normal and efficient. However, in practice, this estimator can be
very difficult to implement. This is particularly the case if we use
an algorithm that for each trial value of θ computes all the vectors
P which are an equilibrium associated with θ and then selects
the one with maximum value for Q (θ , P). Finding all the Markov
Perfect equilibria of a dynamic game can be very difficult even for
relatively simple models.
4.1. Two-step methods
Several recent papers (Jofre-Bonet and Pesendorfer, 2003;
Aguirregabiria and Mira, 2007; Bajari et al., 2006; Pakes et al., 2007;
Pesendorfer and Schmidt-Dengler, 2008) have proposed different

60

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

versions and extensions of Hotz–Miller’s CCP estimator to estimate
dynamic games. An interesting aspect of the application of the
CCP estimator to dynamic games is that this method deals with
the problem of multiple equilibria, i.e., it avoids the optimization
of the (pseudo) likelihood with respect to P. Under assumption
‘One-MPE-Data’, player’s choice probabilities can be interpreted
as player’s beliefs about the behavior of their opponents. Given
these beliefs, one can interpret each player’s problem as a game
against nature with a unique optimal decision rule in probability
space, which is the player’s best response. While equilibrium
probabilities are not unique functions of structural parameters,
the best response mapping is a unique function of structural
parameters and player’s beliefs about the behavior of other players.
These methods use best response functions evaluated at consistent
nonparametric estimates of player’s beliefs.
We now describe different variants of this estimator in the
context of dynamic games. As in the case of single-agent models,
the CCP method is particularly useful in models where the
utility function is linear-in-parameters. Therefore, we assume that
ui (amt , xmt , θu ) = zi (amt , xmt )0 θu , where zi (amt , xmt ) is a vector
of known basis functions. Let P be a vector of conditional choice
probabilities, for every player, state and action. Following the same
approach as in single-agent models, the alternative-specific value
functions can be written as follows:64

viP (ai , xt ) = z̃iP (ai , xt ) θu + ẽPi (ai , xt )

(56)

where (ai , xt ) is the expected and discounted sum of current
and future zi0 s along all histories that originate from (ai , xt ) and
ẽPi (ai , xt ) is the expected and discounted sum of the stream
{εi,t +j (ai,t +j ) : j = 1, 2, . . .}. Both expectations are obtained
under the assumption that all players behave now and in the
future according to the probabilities in P. They can be computed
using recursive expressions similar to those used for single-agent
problems in Eq. (40), the only complication being that the actions
of all other players need to be ‘integrated out’ here. Specifically, we
have:
z̃iP

!
z̃iP (ai , xt ) ≡

X Y
a−i

Pj (aj |xt )

j6=i

"

#

× zi (ai , a−i , xt ) + β

X

(

| ,

, )

fx xt +1 ai a−i xt WziP

(xt +1 )

xt +1

(57)

!
ẽPi (ai , xt ) ≡ β

X Y
a−i

×

"
X

Pj (aj |xt )

j6=i

#
fx (xt +1 |ai , a−i , xt )WeiP (xt +1 )

xt +1

where a−i is the vector with the actions of all players other than i,
aj is player j’s action in a−i , and
WziP (xt +1 ) =

X

Pi (ai |xt +1 )z̃iP (ai , xt +1 )

ai ∈A

WeiP (xt +1 ) =

X

Pi (ai |xt +1 ) e(ai , xt +1 ) + ẽPi (ai , xt +1 )





(58)

ai ∈A

(x) and WeiP (x) are policy valuation operators. Let WPi be the
matrix {(WziP (x), WeiP (x)) : x ∈ X }. Then, this valuation matrix
is the unique solution in W to the fixed point problem: W =
P
QN
a∈AN [
j=1 Pj (aj )] ∗ {[zi (a), ei (a)] +β Fx (a)W}, and ei (a) has the
WziP

same definition as in the single-agent model.

64 In some of the equations which follow we drop the m subscript for notational
simplicity, and t can be interpreted as an index for market-period.

Let P̂ and θ̂f be consistent estimators of P0 and θf0 , respectively.
Based on these initial estimates, we can obtain a two-step
estimator of θu as a GMM estimator that solves the sample moment
conditions:
M X
N TX
m −1
X
m=1 i=1

Hi (xmt )

t =1





I {aimt = 1} − Λ 0|z̃iP̂ (·, xmt )θu + ẽP̂i (·, xmt )



×


I {aimt

 



..
=0
.

 
= J } − Λ J |z̃iP̂ (·, xmt )θu + ẽP̂i (·, xmt )

(59)

where H (xmt ) is a matrix with dimension dim(θu ) × J with
functions of xmt which are used as instruments. The estimator is
root-M consistent and asymptotically normal. This estimator is
used by Jofre-Bonet and Pesendorfer (2003) and Pakes et al. (2007).
Dunne et al. (2006) have also applied this method, and the model
in Pakes, Ostrovsky and Berry, to study the determinants of market
structure in the dentists and chiropractors industries. An attractive
feature of this method of moments estimator, emphasized by
Pakes et al. (2007), is that when the matrix of instruments Hi (xmt )
does not depend on the nonparametric estimator P̂, this estimator
can have lower finite sample bias than the pseudo-maximum
likelihood and the minimum distance estimators that we describe
in the following paragraphs. We return to this issue at the end of
this section.
In the firm entry/exit game of Example 4, recall that market size
and every firms’ incumbency status are the common knowledge
state variables, so we have xt = (St , ait −1 , a−i,t −1 ). Market size is
a first order Markov chain with parameters θf . Since the operating
cost and entry cost parameters are firm-specific, then θu and the
basis functions are the following (2 + 2N )-dimension vectors:



 θRS 
 θRN 


 θFC ,1 


 θEC ,1 


 ··· 

θu = 
 θFC ,i  ;


θ 
 EC ,i 


 ··· 


θFC ,N
θEC ,N

log (St )


!

X

log 1 +
ajt


j6=i

0



0

zi (1, a−it , xt ) = 
·
··


−1

 −(1 − a
i,t −1 )


···


0










;









0

(60)

0
0
 
0
 
0
 
· · ·

zi (0, a−it , xt ) = 
 0 .
 
0
 
 
· · ·
 
0
0

Furthermore, the best response mapping is Λ(1|viP (·, xmt , θ )) =
Φ ((viP (1, xt ) − viP (0, xt ))/σ ) where σ 2 is the variance of the
difference εimt (1) − εimt (0). Finally, given that ε 0 s are jointly
normal, we have that:


v ar (εi (a)) − cov(εi (0), εi (1)) φ Φ −1 (Pi (a|x))
e(a, xt ) =
.
σ
Pi (a|x)

(61)

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

The two-step method in Aguirregabiria and Mira (2007) is a
pseudo-maximum likelihood (PML) estimator that maximizes in
θu the criterion function Q (θu , θ̂f , P̂) defined in Eq. (54). The values z̃iP̂ and ẽP̂i are calculated as described above: i.e., solving for
the matrices WP̂i and then applying the expressions in (57). This
method is a particular case of the class of GMM estimators defined
in Eq. (59). The (pseudo) likelihood equations that define this estimator can be expressed as in (59) with a matrix Hi (xmt ) equal to
{∂ log Λimt (1)/∂θu , ∂ log Λimt (2)/∂θu , . . . , ∂ log Λimt (J )/∂θu }. In
contrast to the case of single-agent models, this estimator is less
efficient asymptotically than the partial MLE. This is because the
initial nonparametric estimator of P0 and the PML estimator of θu0
are not asymptotically independent and therefore there is an efficiency loss from using an inefficient initial estimator of P0 .
Pesendorfer and Schmidt-Dengler (2008) consider the following class of minimum distance estimators:

h

i0
i
θ̂u = arg min P̂ − Λ v (θ ) AM P̂ − Λ v P̂ (θ )
h

θu



P̂

(62)

where AM is a weighting matrix that converges in probability
to a non-stochastic positive definite matrix A0 as M goes to
infinity. Different choices of weighting matrices give rise to distinct
estimators within this class. Under standard regularity conditions,
all the estimators in this class are consistent and asymptotically
normal. Minimum distance estimation theory establishes that the
efficient estimator in this class is the one where the weighting
matrix A0 is:

61

structural models. Bajari, Benkard and Levin (BBL) propose an estimator that minimizes a set of moment inequalities and that can
be applied to a general class of dynamic structural models under Assumptions AS, IID, CI-X, including dynamic games with either discrete or continuous decision and state variables. Define
WiP (x) ≡ (WziP (x), WeiP (x)), and split the vector of choice probabilities P into the subvectors Pi and P−i , where Pi are the probabilities
associated to player i and P−i contains the probabilities of the other
players. The model implies that for any state x ∈ X and any Pi 6= P0i
the following inequality should hold:
P0i ,P0−i

Wi

( x)

 
θu
1

Pi ,P0−i

≥ Wi

(x)

 
θu
1

.

(64)

Let H be a set of values for (i, x, P). If the set H is large enough and
θu0 is identified, then θu0 uniquely minimizes the population criterion function:

X





P0i ,P0−i

min 0; Wi

Pi ,P0−i

(x) − Wi

(x)

  2
θu
1

{i,x,P}∈H

.

(65)

This criterion function penalizes departures from the inequalities
in (64). The BBL estimator of θu0 minimizes a simulation-based sample counterpart of this criterion function. More precisely,

θ̂u = arg min
θu ∈Θ

X 



P̂i ,P̂−i

0; W̃i

Pi ,P̂−i

(x) − W̃i

  2
θu
(x)
1

{i,x,P}∈H

(66)
0

"

!
#0 "
!
#!−1
..
..


I.0 − ∇P,θf Λ v P0 (θ 0 )
Σ
I.0 − ∇P,θf Λ v P0 (θ 0 )
(63)

where Σ is the variance matrix of the initial estimators P̂ and

.
θ̂f ; (I..0) is the identity matrix (with dimension the number of

rows in P) vertically stacked with a matrix of zeros (where
the number of columns is equal to the number of elements in
the vector θf ); and ∇P,θf Λ is the Jacobian matrix of Λ with
respect to P and θf .65 Note that this optimal weighting matrix
depends on θu0 . Therefore, the efficient estimator is obtained in

three steps: estimate P̂ and θ̂f 0 and their variance; obtain an
initial (and inefficient) minimum distance estimator of θu0 using
an arbitrary weighting function, e.g., Σ −1 ; finally, construct a
consistent estimator of the optimal weighting matrix and obtain
the efficient estimator. Pesendorfer and Schmidt-Dengler show
that this efficient estimator is asymptotically equivalent to MLE.
In models with continuous state variables or with large state
spaces, the computation of continuation values z̃iP̂ and ẽP̂i can
be infeasible or extremely burdensome. Bajari, Benkard and
Levin (2008) propose a method that builds on and extends the
simulation-based CCP estimator that we have described in Section 3.1.4. Their method has two important features that distinguish it from the other methods that we review here: it can be
applied to models with continuous decision variables (as long as
the utility function satisfies ∂ 2 u(ai , a−i , x, εi )/∂ ai ∂εi ≥ 0), and
to models where the parameters are not point identified (i.e., set
identification). In fact, these two features of their method also
contribute to the literature on estimation of single-agent dynamic

65 There is some abuse of notation in the use of the Jacobian matrix ∇
P,θf Λ. This is
because P and θf are not direct arguments of the mapping Λ. The direct arguments
of this mapping are the choice-specific values v . Therefore, what the matrix ∇P,θf Λ
represents is the product between the Jacobian of Λ with respect to v and the
Jacobian of v P (θ) with respect to P and θf .

where P̂ is a nonparametric estimator of P (there are also initial
estimators of θY0 and θf0 but we have omitted them for the sake of
notational simplicity), and W̃i is a simulator of Wi which is obtained
in a similar way as described in Section 3.1.4. As both the number
of sample observations and the number of simulations approach
infinity, this estimator of θu converges to its true population value.
In contrast to the simulation-based CCP estimator that we have described in Section 3.1.4, the BBL estimator is consistent and asymptotically normal only as the number of simulations goes to infinity,
and not for a fixed number of simulations. The explanation is that in
the moment conditions that define the simulation-based CCP estimator the simulation error enters additively and averages out over
the sample. However, that is not the case for the simulation error
in the BBL estimator. Furthermore, the asymptotic variance of the
estimator depends not only on the variance of P̂ but also on the
choice of the set of ‘‘deviations’’ with respect to the optimal policy contained in H. The larger the number of alternative policies P
used to construct the sample criterion function, the more precise
the BBL estimator. Nevertheless, the cost of computing the values
W̃iP (x) for a policy P can be large, even when using a simulation
method. Bajari et al. describe a bootstrap procedure to calculate
standard errors (see also Chernozhukov et al., 2007).
Ryan (2006) uses the BBL method to estimate a dynamic
oligopoly model of the US cement industry. In his model, firms
compete in quantities in a static equilibrium, but they are subject
to capacity constraints. Firms invest in future capacity and this
decision is partly irreversible (and therefore dynamic). Note that
the decision variable in this model, investment, is a censored
continuous variable. Ryan estimates the parameters in demand
and marginal costs using data on prices, quantities and the static
equilibrium conditions. In a second step he estimates investment
costs as well as entry and exit costs using BBL’s inequality
estimator. Ryan allows entry costs to vary before and after year
1990 when several amendments were introduced in the Clean Air
Act. He finds that these amendments raised significantly the sunk
costs of entry in the cement industry. Other applications of the BBL
method: Holmes (2008) studies the diffusion of Wal-Mart store

62

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

openings and the existence of economies of density; Beresteanu
and Ellickson (2005) examine competition between supermarket
chains using a dynamic model of strategic investment; Sweeting
(2007) estimates a dynamic game of radio-stations’ decisions of the
format/characteristics of their products.
The main advantage of these two-step estimators is their
computational simplicity. However, they have two important
limitations. The first problem is finite sample bias. The initial
nonparametric estimator can be very imprecise in the small
samples available in actual applications, and this can generate
serious finite sample biases in the two-step estimator of structural
parameters. In dynamic games with heterogeneous players the
number of observable state variables is proportional to the number
of players and therefore the so-called curse of dimensionality in
nonparametric estimation (and the associated bias of the twostep estimator) can be particularly serious. The sources of this
finite sample bias can be illustrated using the moment conditions
in (59): (1) if the matrix of instruments Hi (xmt ) depends on
the nonparametric estimator P̂0 , then there is a finite sample
correlation between these instruments and the ‘‘errors’’ I {aimt =
P̂

P̂

j} − Λ(j|z̃i 0 (·, xmt )θu + ẽi 0 (·, xmt )); and (2) the choice probabilities
P̂

P̂

Λ(j|z̃i 0 (·, xmt )θu + ẽi 0 (·, xmt )) are complicated nonlinear functions
of the nonparametric estimator P̂0 , and the expected value of a
nonlinear function is not equal to the function evaluated at the
expected value. As argued by Pakes et al. (2007), the first source of
bias is present in the pseudo-maximum likelihood estimator and
the minimum distance estimator but not in a method of moments
estimator when the instruments do not depend on P̂0 . However,
the second source of bias appears in all these two steps estimators
and it can be very important as illustrated in the Monte Carlo
experiments of several papers (see the Monte Carlo experiments
in Hotz et al., 1994; Aguirregabiria and Mira, 2002, 2007, or
Pesendorfer and Schmidt-Dengler, 2008).
A second important limitation of these two-step methods is
the restrictions imposed by Assumption IID. Ignoring persistent
unobservables, if present, can generate important biases in the
estimation of structural parameters.

ωm does not enter into the conditional transition probability of xmt ,
i.e., Pr(xm,t +1 |amt , xmt , ωm ) = fx (xm,t +1 |amt , xmt ). This assumption
implies that the transition probability function fx can still be
estimated from transition data without solving the model.
The introduction of unobserved market heterogeneity also
implies that we can relax the assumption of only ‘One MPE in the
data’ to allow for different market types to have different equilibria.
Let P0mt ≡ {Pr(amt = a|xmt = x, m, t ) : (a, x) ∈ AN × X } be
the distributions of amt conditional on xmt in market m at period
t. We assume that P0mt = P0` , where ` is the type of market m.
Each market type has its own MPE. Though we still assume that
only one equilibrium is played in the data conditional on market
type, the data generating process may correspond to multiple
equilibria. Markets which, in terms of exogenous characteristics,
are observationally equivalent to the econometrician may have
different probabilities of entry and exit because the random effect
component of profits ω is different. Furthermore, though, in our
example, market heterogeneity ωm is payoff-relevant, this variable
may also play (in part) the role of a sunspot.
The vector of structural parameters now includes the distribution
 1 of2market Ltypes: π ≡ {π` : ` = 1, 2, . . . , L} and Ω =
ω , ω , . . . , ω . Here we consider a parametric specification of
the distribution of ωm . This specification simplifies significantly
the computation of the estimator with unobserved market heterogeneity (see Aguirregabiria and Mira, 2007, for an empirical appli∗
cation with this model and method). Suppose that ωm = σω ωm
∗
where σω > 0 is a parameter, and ωm is a discrete random variable
with zero mean, unit variance, and a probability distribution that is
known to the econometrician, e.g., a discretized standard normal.
∗
Therefore, the points of support of ωm
and the probabilities π` are
known, and the only parameter to be estimated is σω . The (conditional) pseudo-likelihood function has the following finite mixture
form:
M
X

Q (θu , σω , {P` }) =

ln

m=1

×

"
T Y
N
Y

Λ



P
aimt |z̃i `

t =1 i =1

4.2. Sequential estimation

π`|xm1

`=1

#!

θu
P`
(·, xmt )
+ ẽi (·, xmt )
σω


(68)

P

We have described in Section 3.1.3 how a recursive or
sequential CCP procedure is a bias reduction method that deals
with the problem of finite sample bias of the two-step CCP
estimator. This procedure can be particularly useful in the context
of dynamic games with heterogeneous players because it is in this
context where the finite sample bias of the two-step estimator
can be very serious. The sequential CCP method or NPL algorithm
also deals with the issue of permanent unobserved heterogeneity.
Here we follow Aguirregabiria and Mira (2007) and describe the
NPL method for a model with permanent unobserved market
heterogeneity. Consider the entry–exit model in Example 4 but
extended to include unobserved market heterogeneity. The profit
of an active firm is:

X

where vectors z̃i ` (·, xmt ) are computed as in (57)–(58), noting that
for ` = 1, . . . , L the basis functions zi () need to be augmented
with the value of `th point of support of the (discretized) standard
normal distribution. The mixture weight π`|x is the conditional
probability Pr(ωm = ω` |xm1 = x). It is clear that firms’ incumbent
statuses at period 1, which are components of the vector xm1 , are
not independent of market type, i.e., more profitable markets tend
to have more incumbent firms. Therefore, π`|xm1 is not equal to
the unconditional probability π` . Under the assumption that xm1
is drawn from the stationary distribution induced by the MPE, we
can obtain the form of π`|xm1 . Let p∗ (P` ) ≡ {p∗ (x|P` ) : x ∈ X } be
the stationary distribution of x induced by the equilibrium P` and
the transition fx (·|·, θf ). This stationary distribution can be simply
obtained as the solution to the system of linear equations:
p∗ (x|P` ) =

!
Uimt (1) = θRS log (Smt ) − θRN log 1 +

L
X

ajmt

X

p∗ (x0 |P` ) Pr(x|x0 , P` )

x0 ∈X

j6=i

− θFC ,i − θEC ,i (1 − aim,t −1 ) + ωm + εimt

(67)

where ωm is a random effect interpreted as a time-invariant market
characteristic affecting firms’ profits, which is common knowledge
to the players but unobservable to the econometrician.
We assume

that ωm has a discrete and finite support Ω = ω1 , ω2 , . . . , ωL ,
and it is independently and identically distributed across markets
with probability mass function π` ≡ Pr(ωm = ω` ). Furthermore,

=

X
x0 ∈X

p (x0 |P` )
∗

"
N
X Y
a∈AN

#

!

P`j (aj |x0 ) fx (x|a, x0 ) . (69)

j=1

Then, by Bayes’ rule, we have that:

π`|xm1 =

π` p∗ (xm1 |P` )
.
P
∗
0
0
π` p (xm1 |P` )
L

`0 =1

(70)

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

The NPL estimator of (θu , σω ) is obtained using an iterative
procedure similar to the one we have described in Section 3.1.3
for a model without heterogeneity. The main difference is that
now we have to calculate the steady-state distributions p∗ (P` ) to
deal with the initial conditions problem. However, the pseudolikelihood approach also reduces very significantly the cost of dealing with the initial conditions problem. The reason is that given
P` the steady-state distributions do not depend on the structural parameters in (θu , σω ). Therefore, the distributions p∗ (P` ) remain constant during any pseudo-maximum likelihood estimation
and they are updated only between two pseudo-maximum likelihood estimations when new choice probabilities are obtained. This
implies a very significant reduction in the computational cost
associated with the initial conditions problem. Given that the probabilities {π` } are known, the probabilities π`|xm1 also remain constant during any pseudo-maximum likelihood estimation. The NPL
algorithm proceeds as follows. We start with L arbitrary vectors
of player’s choice probabilities, one for each market type: {P̂`0 :
` = 1, 2, . . . , L}. Then, we perform the following steps. Step 1:
For every market type we obtain the steady-state distribution of
xm1 and the probabilities {π`|xm1 }. Step 2: We obtain the pseudomaximum likelihood estimator of θu and σω as: (θ̂u1 , σ̂ω1 ) =
arg max(θu ,σω ) Q (θu , σω , θ̂f , {P̂`0 }). Step 3: Update the vector of
player’s choice probabilities using the best response probability
mapping. That is, for market type `, P̂`1 = Λ(v P̂`0 (θ̂u1 , σ̂ω1 , ω`∗ ,

θ̂f )). If, for every type `, kP̂`1 − P̂`0 k is smaller than a predetermined small constant, then stop the iterative procedure and keep
(θ̂u1 , σ̂ω1 ) as a candidate estimator. Otherwise, repeat steps 1 to 4
using {P̂`1 }.
This NPL algorithm, upon convergence, finds an ‘‘NPL fixed
point’’ (Aguirregabiria and Mira, 2007).66 An NPL fixed point is
defined as any combination of parameters and conditional choice
probabilities (e
θu , e
σω , {P̃` }) which satisfies the following two conditions: (a) The parameters maximize the pseudo-likelihood given
the probabilities. That is, (e
θu , e
σω ) = arg max(θu ,σω ) Q (θu , σω , θ̂Y , θ̂f ,

{P̃` }); and (b) The probabilities are an equilibrium given the parameters. That is, P̃` = Λ(v P̃` (θ̃u , σ̃ω , ω`∗ , θ̂f )) for all `. In any given

sample there may be more than one NPL fixed point. Aguirregabiria
and Mira define the NPL estimator as the NPL fixed point which
maximizes the pseudo-likelihood and show that it is consistent
(Proposition 2, Aguirregabiria and Mira, 2007). In order to guarantee consistency, the researcher needs to start the NPL algorithm
from different CCP’s in case there are multiple NPL fixed points.
This situation is similar to using a gradient algorithm, designed to
find a local root, in order to obtain an estimator which is defined
as a global root.67
The NPL method, with or without unobserved market heterogeneity, has been applied in several empirical papers in industrial
organization. Collard-Wexler (2006) uses the NPL method to estimate a dynamic oligopoly model of entry and exit in the US readymix concrete industry. Kano (2006) estimates a dynamic oligopoly
game of price competition with menu costs. Aguirregabiria et al.

66 Aguirregabiria and Mira (2002, 2007) do not prove that the algorithm always
converges.
67 See Aguirregabiria and Mira (2007) for further details. Pesendorfer and
Schmidt-Dengler (2008) report poor performance of ‘‘NPL’’ estimators in some of
their examples. This is suggestive of the existence of multiple NPL fixed points. Since
they do not report starting the algorithm from different values we conjecture that
they are finding NPL fixed points which are dominated by another NPL fixed point.
In that case their estimator is not the NPL estimator and it need not be consistent.
Clearly, we do not know much about how prevalent the case of multiple NPL fixed
points is in relevant applications and about how often inconsistent fixed points may
be found, and this is a topic for further research.

63

(2007a,b) propose and estimate a model of entry, exit and investment in retail industries that allows for unobserved market and
firm heterogeneity; Aguirregabiria and Ho (2008) estimate a dynamic game of network competition between US airline companies and use it to measure the contribution of demand, cost and
strategic factors to explain the adoption of hub-spoke networks.
The NPL method has been applied also to estimate static games of
incomplete information: Suzuki (2008) studies the welfare effects
of land use regulation in game of market entry and competition by
hotel chains; and Ellickson and Misra (2008) investigate strategic
interactions in supermarkets’ adoption of pricing schemes.
5. General equilibrium models
In this section we describe the method proposed by Lee and
Wolpin (LW) to estimate competitive equilibrium models. The
model is that of Example 3, which is a simplified version of the
model in LW with only one sector and two occupations as in Lee
(2005). Total factor productivity zt is assumed to follow an AR(1)
process. This is the only source of exogenous aggregate uncertainty
which is explicitly modelled and it implies that individuals solving
the occupational choice model face uncertainty about future skill
prices. Future skill prices depend on future TFP and on future
cross-sectional distributions of schooling and occupation-specific
experience. However, including these distributions in the vector of
state variables e
Xt would make the dimension of the state space so
large as to make solution and estimation infeasible. Lee and Wolpin
assume that current and lagged values of skill prices provide a good
approximation to the information contained in these distributions
that is relevant to predict future skill prices. More specifically,
LW assume that the evolution of skill prices is described by the
following system of difference equations:
ln ra,t +1 − ln ra,t = ηa0 +

2
X

ηak (ln rk,t − ln rk,t −1 )

k=1

+ ηa3 (ln zt +1 − ln zt )

(71)

where η ≡ {ηa0 , ηa1 , ηa2 , ηa3 : a = 1, 2} is a vector of parameters. Under this assumption the vector of aggregate state variables
that individuals use to predict future prices is e
Xt = (zt , r1t , r2t ,
r1,t −1 , r2,t −1 ). Therefore, the equilibria they consider are approximations to the full rational expectations equilibria. This approach
is in the spirit of Krusell and Smith (1998). It is important to note
that the vector η is determined in equilibrium as a function of the
structural parameters, but is not itself one of the structural parameters or primitives of the model.
The vector of structural parameters of the model is θ = (θu , θy ,
θπ , θY , θz , θn ) where: θu and θy represents the parameters in utility
function and wage equations, respectively; θπ is the distribution
of types (by cohort, schooling at age 16 and gender); θY contains
the parameters in the aggregate production function; θz has the
coefficients in the stochastic process of total factor productivity;
and θn represents the parameters in the stochastic process
followed by the number of pre-school children.
A rational expectations equilibrium in this model can be
described as a value of the vector η, say η∗ (θ ), that solves a
fixed point problem. The following description of the equilibrium
mapping also provides an algorithm to compute the fixed point.
Consider an arbitrary value of η, say η0 .
Step 1 (Optimal Individual Behavior): Given η0 individuals use
Eq. (71) to form expectations about future prices, and to solve their
occupational choice problems.
Step 2 (Solve for Market Clearing Skill Prices): Given initial conditions
for TFP, skill prices and the distribution of state variables for all
individuals alive at t = 1 :

64

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

a. Simulate a sequence of values of TFP for t = 1, 2, . . . , T ,
drawing from the AR(1) process defined by θz .
b. Guess skill prices {rat } at t = 1 using the TFP draw and
(71) Draw idiosyncratic shocks for all individuals alive at t = 1
and simulate their choices using the solutions from step 1. Obtain
aggregate skill supplies S1t and S2t for t = 1.
c. Given these skill supplies, use the market clearing conditions
to obtain a new value of skill prices, that is:
0
rat
=

αat 
Sat

α

α

1−α1t −α2t

zt S1t1t S2t2t Kt



for a = 1, 2 for t = 1.

0
d. In general, the new skill prices {rat
} will not be the same as
0
the original guess {rat }. Replace {rat } by {rat
} and repeat steps b-c
until convergence.
e. Repeat steps b-c-d for t = 2, . . . , T . Let {rat (η0 , θ ) : t =
1, 2, . . . , T } be the sequence of skill prices that we obtain upon
convergence.

Step 3 (Update Beliefs): Use this new sequence of skill prices and the
sequence of TFP to obtain a new value of η, say η1 , as the vector of
OLS coefficients for the ‘regression equation’ in (71).
Step 4 (Impose Self-Fulfilling Beliefs): If η1 = η0 , then η0 is a rational
expectations equilibrium associated with θ , i.e., individual’s beliefs
are self-fulfilling. Otherwise, we start again in Step 1 using η1
instead of η0 .
The data used in LW have annual frequency and consist of the
following items from different sources: (1) occupational choice and
wage data (from microsurveys); (2) aggregate output and capital
stock; (3) number of pre-school children, by cohort age and gender;
(4) cohort sizes, by gender; (5) distribution of schooling at age
16, by cohort and gender; and (6) the initial conditions, i.e., the
distribution of state variables xi1 for all cohorts alive at calendar
time t = 1. To make the inference problem more tractable, LW
treat data in items (2) to (6) as population parameters which are
known to the researcher. The parameter θn is obtained directly
from (3) and is not estimated with the rest of the parameters.
Note that data in items (2), (4), (5) and (6) are used in the
solution algorithm we have just described. For the occupational
choice and wage data in item (1), the authors combine two
different microsurveys: the Current Population Survey (CPS) and
the National Longitudinal Survey of the Youth (NLSY). The two
datasets are complementary: on the one hand, the CPS covers a
much longer period and thus provides a much wider coverage
in terms of calendar time, cohorts and ages; on the other hand,
the NLSY has full histories as of age 16, so it adds a true panel
dimension and, furthermore, experience capital can be constructed
for all sampled individuals.
The estimation method that LW use is a Simulated Method
of Moments (SMM). The estimation criterion is a weighted
average distance between sample and simulated moments, where
the weights are the inverses of the estimated variances of the
moments. Moments are selected from CPS and NLSY microdata and
a very large number of moments is considered (see pages 23–24
in their paper). The estimation procedure is a nested solutionestimation algorithm. The ‘outer algorithm’ searches for the value
of θ that minimizes the sample criterion function. An iteration
of this ‘outer algorithm’ is a Newton iteration. For each value
of θ in this gradient search, the ‘inside algorithm’ solves for
an equilibrium of the model using the procedure that we have
described in steps 1 to 4 above. Given that equilibrium, the inside
algorithm simulates data and calculates the simulated moments
associated with a given θ .68

68 Lee and Wolpin do not estimate all the model parameters using this nested
procedure. The parameters in the stochastic process of the number of pre-school
children, θn , are estimated separately in a first step using data item (3).

It is helpful to compare this estimation procedure with the one
for the single-agent occupational choice model in Example 2. In the
single-agent model there was not aggregate uncertainty, structural
parameters consisted of (θu , θπ , θn ) and of constant skill prices r̄1
and r̄2 , and these parameters were estimated using the likelihood
of the microdata in item (1). In LW’s approximation to a stochastic
rational expectations equilibrium, the state vector of an individual
agent’s problem is augmented with the 5 continuous aggregate
variables e
Xt = (zt , r1t , r2t , r1,t −1 , r2,t −1 ) and the parameter vector
is augmented with parameters (θz , η). However, η is not a free
parameter but a function of the structural parameters θ implicitly
defined as a fixed point of the equilibrium mapping described
above. Therefore, the estimation problem is an order of magnitude
more complex than that in Example 2.
There are several details of LW’s method which are worth mentioning. First, note that at step 2 of the solution algorithm (i.e., imposing market clearing condition) we need initial conditions for
TFP and skill prices, {ra1 , z1 : a = 1, 2}, which are unobservable
variables for the researcher. The way that LW deal with this issue
is by choosing an initial period t = 1 which is many periods before
the sample period that is used to construct moments conditions
from the microdata. In this way, the choice of the initial conditions
has negligible influence on the simulated data for the sample period. This amounts to assuming that aggregate initial conditions are
consistent with ‘steady-state’ implications of the model, modified
by the limited information we have about aggregate trends in the
decades that precede the sample period.
A second detail deals with the solution of the individual’s
occupational choice problem. The state space of the DP problem
is very large and the estimation procedure requires that the DP
problem be solved many times, more than once for each cohort,
type and candidate parameter value. LW use Keane–Wolpin’s
simulation–interpolation method to approximate the solution to
individual’s occupational choice problem.
Third, a relevant question is why SMM is used instead of
Simulated Maximum Likelihood. The likelihood function of this
model is particularly complex and costly to evaluate. For instance,
full histories of choices and states are not available for all sampled
individuals and, in particular, the value of occupation-specific
experience capital is not observable. Missing state variables have to
be integrated out for each individual contribution to the likelihood.
Computing the likelihood using simulation methods is therefore
more costly than computing simulated moments.
Fourth, in order to highlight the equilibrium mapping and the
solution of the model we have presented a simplified version
of LW’s solution/estimation algorithm in which no use is made
of the time series of output in data item (2). In LW’s solution
algorithm the sequence of TFP values in step 2 is not simulated.
Instead, they impose that the value of zt which is conjectured to
derive aggregate skill supplies in step 2b should be consistent with
α
α
1−α −α
aggregate production technology, that is Yt = zt S1t1t S2t2t Kt 1t 2t
where S1t and S2t are the derived supplies and Yt and Kt are
the actual time series data. The iterative procedure within step 2
obtains both the market clearing skill rental prices and the TFP
values consistent with the data. In step 3 both η and θz are updated
based on the sequences derived in step 2. In this solution algorithm
θz is not a free parameter. An ‘estimate’ of it is obtained as a byproduct, conditional on the rest of the parameter vector and data
item (2).
Finally, given that LW’s method is computationally very
intensive, an important question is whether there is a simpler
estimation strategy which does not require one to solve for the
equilibrium of the model for each trial value of θ . Consider the
same model and assume that the data have been generated by
a rational expectations equilibrium of this model. It is possible
to obtain an estimator of an augmented parameter vector (θ , η)

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

that does not fully impose the equilibrium restrictions. The
main advantage of this alternative approach, in the spirit of
Heckman et al. (1998), is that it is computationally simpler: its
computational burden is of the same order of magnitude as the one
in the estimation of the single-agent occupational choice model.
However, it has some potential limitations. First, it may be difficult
to identify (θ , η) jointly without fully imposing the equilibrium
restrictions. Relatedly, there is a loss of efficiency. Even if (θ , η)
is identified, imposing the equilibrium restrictions can improve
significantly the precision of our estimates. A third limitation is
that the estimated model, though statistically consistent, is not
internally consistent and one might argue that this detracts from
the credibility of counterfactual exercises.69 There is a trade-off
between the increased efficiency and internal consistency of the
estimates obtained using Lee and Wolpin’s method and the extra
computational burden which is involved.70
Other applications: Lee and Wolpin (2010) also use an extended
version of the model of Example 3 to study the determinants of
several important long-run trends in the US labor market in a
unified framework: the growth of the service sector, increased
wage inequality, the rise of the college premium and the increase
of female employment and the female–male wage ratio. Colussi
(2006) uses a very similar method to estimate a dynamic
equilibrium model of the migration decisions of illegal Mexican
workers. The model allows for return migration and is used to
assess the importance of network effects in migration and to
evaluate the impact of alternative US immigration policies.
6. Conclusions
This paper reviews the econometrics of discrete choice dynamic structural models. Our description of this literature is
organized into four classes of models: single-agent models
under Rust’s framework; single-agent models under the Eckstein–Keane–Wolpin framework; dynamic general equilibrium
models; and dynamic strategic games. For each of these classes
of models we have presented an example based on an important
empirical application. We have used these examples to illustrate
both econometric issues in this literature and recent methodological contributions. Section 2 is self-contained and tries to provide
an introduction to this literature for a second year Ph.D. student.
Sections 3–5 deal with the details of methods. We provide references to many recent and significant empirical applications of the
methods.
Acknowledgements
We want to thank comments from an anonymous referee, Zvi
Eckstein, Allan Collard-Wexler, Chris Ferrall, Donna Gilleskie, Brett
Gordon, Chun-Yu Ho, Michael Keane, Ahmed Khwaja, Donghoon
Lee, Haizhen Li, Arvind Magesan, Bob Miller, Carlos Serrano,
Todd Stinebrickner, and graduate students at the University
of Toronto, CEMFI, Universidad Carlos III, Indiana University,
Universitat de Barcelona, University of Helsinki, and ENSAE-Paris
where this survey was part of a course on microeconometric
dynamic structural models. Pedro Mira acknowledges support

69 That is, the estimate vector η can be very different to the value that we get
using information from skill prices generated from the market clearing conditions.
A possible way of dealing with this internal inconsistency is to include this
discrepancy as one of the moment conditions in the sample criterion function to
minimize.
70 A solution algorithm like Lee and Wolpin’s is still needed to carry out
their empirical analysis of the growth of the service sector which is based on
counterfactuals.

65

from the Spanish Ministerio de Educación y Ciencia through grant
SEJ2005-08880 and through the Consolider-Ingenio 2010 Project
‘‘Consolidating Economics’’.
References
Ackerberg, D., 2001. A new use of importance sampling to reduce computational
burden in simulation estimation. Manuscript. Department of Economics. UCLA.
Ackerberg, D., Geweke, J., Hahn, J., 2009. Comments on ‘‘Convergence Properties of
the Likelihood of Computed Dynamic Models’’. Econometrica (forthcoming).
Aguirregabiria, V., 1999. The dynamics of markups and inventories in retailing firms.
The Review of Economic Studies 66, 275–308.
Aguirregabiria, V., 2007. Another look at the identification of dynamic discrete
decision processes: With an application to retirement behavior. Manuscript.
University of Toronto.
Aguirregabiria, V., Alonso-Borrego, C., 2009. Labor contracts and flexibility:
Evidence from a labor market reform in Spain. Manuscript. Department of
Economics. University of Toronto.
Aguirregabiria, V., Ho, C-Y., 2008. A dynamic oligopoly game of the US airline
industry: Estimation and policy experiments. Manuscript. University of
Toronto.
Aguirregabiria, V., Mira, P., 2002. Swapping the nested fixed point algorithm: A
class of estimators for discrete Markov decision models. Econometrica 70,
1519–1543.
Aguirregabiria, V., Mira, P., 2007. Sequential estimation of dynamic discrete games.
Econometrica 75, 1–53.
Aguirregabiria, V., Mira, P., Roman, H., 2007a. An estimable dynamic model of entry,
exit and growth in oligopoly retail markets. American Economic Review 97,
449–454.
Aguirregabiria, V., Mira, P., Roman, H., 2007b. Inter-industry heterogeneity in
market structure and dynamic oligopoly structural models. Manuscript. The
University of Toronto.
Ahn, N., 1995. Measuring the value of children by sex and age using a dynamic
programming model. Review of Economic Studies 62, 361–379.
Altug, S., Miller, R., 1998. The effect of work experience on female wages and labour
supply. Review of Economic Studies 65, 45–85.
Andrews, D., 1988. Chi-square diagnostic tests for econometric models. Journal of
Econometrics 37, 135–156.
Arcidiacono, P., 2004. Ability sorting and the returns to college major. Journal of
Econometrics 121, 343–375.
Arcidiacono, P., 2005. Affirmative action in higher education: How do admission and
financial aid rules affect future earnings? Econometrica 73, 1477–1524.
Arcidiacono, P., Jones, J., 2003. Finite mixture distributions, sequential likelihood,
and the EM algorithm. Econometrica 71, 933–946.
Arcidiacono, P., Khwaja, A., Ouyang, L., 2007a. Habit persistence and teen sex:
Could increased access to contraception have unintended consequences for
Teen pregnancies? Manuscript. Duke University.
Arcidiacono, P., Miller, R., 2008. CCP Estimation of Dynamic Discrete Choice Models
with Unobserved Heterogeneity. Manuscript. Duke University.
Arcidiacono, P., Sieg, H., Sloan, F., 2007b. Living rationally under the volcano?
An empirical analysis of heavy drinking and smoking. International Economic
Review 48, 37–65.
Bajari, P., Benkard, L., Levin, J., 2006. Estimating dynamic models of imperfect
competition. Econometrica 75, 1331–1370.
Bajari, P., Hong, H., 2005. Semiparametric Estimation of a Dynamic Game of
Incomplete Information. Manuscript. Duke University.
Benitez-Silva, H., Hall, G., Hitsch, G., Rust, J., 2005. A Comparison of Discrete
and Parametric Approximation Methods for Solving Dynamic Programming
Problems in Economics. Manuscript. Department of Economics. University of
Maryland.
Beresteanu, A., Ellickson, P., 2005. The Dynamics of Retail Oligopoly. Manuscript.
Department of Economics. Duke University.
Berkovec, J., Stern, S., 1991. Job exit behavior of older men. Econometrica 59,
189–210.
Blau, D., Gilleskie, D., 2006. Health insurance and retirement of married couples.
Journal of Applied Econometrics 21, 935–953.
Blau, D., Gilleskie, D., 2008. The role of retiree health insurance in the employment
behavior of older males. International Economic Review 49, 475–514.
Bonhomme, S., 2006. Standard errors estimation in mixtures of partial likelihood
models. Manuscript. CEMFI.
Bound, J., Stinebrickner, T., Waidman, T., 2010. Health, Economic Resources, and the
Work Decisions of Older Men. Journal of Econometrics 156, 106–129.
Brien, M, Lillard, L., Stern, S., 2006. Cohabitation, marriage, and divorce in a model
of match quality. International Economic Review 47, 451–494.
Carro, J., Mira, P., 2006. A dynamic model of contraceptive choice of spanish couples.
Journal of Applied Econometrics 21, 955–980.
Chernozhukov, V., Hong, H., Tamer, E., 2007. Estimation and confidence regions for
parameter sets in econometric models. Econometrica 75, 1243–1284.
Collard-Wexler, A., 2006. Productivity Dispersion and Plant Selection in the ReadyMix Concrete Industry. Manuscript. New York University.

66

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67

Colussi, A., 2006. Migrants’ networks: An estimable model of illegal Mexican
migration. Manuscript, University of Western Ontario.
Das, M., 1992. A micro-econometric model of capital utilization and retirement: The
case of the cement industry. Review of Economic Studies 59, 277–297.
Delavande, A., 2006. Pill, Patch or Shot? Subjective Expectations and Birth Control
Choice. Manuscript. Universidade Nova de Lisboa.
De Pinto, A., Nelson, G., 2009. Land use change with spatially explicit data: A
dynamic approach. Environmental and Resource Economics 43, 209–229.
Diermeier, D., Keane, M., Merlo, A., 2005. A political economy model of
congressional careers. American Economic Review 95, 347–373.
Doraszelski, U., Satterthwaite, M., 2007. Computable Markov-Perfect Industry
Dynamics: Existence, Purification, and Multiplicity. Manuscript. Department of
Economics. Harvard University.
Dunne, T., Klimek, S., Roberts, M., Xu, Y., 2006. Entry and Exit in Geographic Markets.
Manuscript. Department of Economics. Pennsylvania State University.
Eckstein, Z., van den Berg, G., 2007. Empirical labor search: A survey. Journal of
Econometrics 136, 531–564.
Eckstein, Z., Wolpin, K., 1989. The specification and estimation of dynamic
stochastic discrete choice models. Journal of Human Resources 24, 562–598.
Eckstein, Z., Wolpin, K., 1999. Why youth drop out of high school: The impact of
preferences, opportunities and abilities. Econometrica 67, 1295–1339.
Ellickson, P., Misra, S., 2008. Supermarket pricing strategies. Marketing science 27,
811–828.
Erdem, T., Imai, S., Keane, M.P., 2003. Brand and quantity choice dynamics under
price uncertainty. Quantitative Marketing and Economics 1, 5–64.
Ericson, R., Pakes, A., 1995. Markov-perfect industry dynamics: A framework for
empirical work. Review of Economic Studies 62, 53–82.
Fang, H., Silverman, D., 2007. Time-inconsistency and welfare program participation: Evidence from the NLSY. Manuscript.
Fernández-Villaverde, J., J Rubio-Ramírez, M., Santos,, 2006. Convergence properties
of the likelihood of computed dynamic models. Econometrica 74, 93–119.
Ferrall, C., 2005. Solving finite mixture models: Efficient computation in economics
under serial and parallel execution. Computational Economics 25, 343–379.
Geweke, J., 1991. Efficient simulation for the multivariate normal ans student-t
distributions subject to linear constraints. In: Computer Science and Statistics:
Proceedings of the Twenty-Third Symposium on the Interface. American
Statistical Association, Alexandria, VA, pp. 571–578.
Geweke, J., 1996. Monte Carlo simulation and numerical integration. In: Amman, H.,
Kendrick, D., Rust, J. (Eds.), Handbook of Computational Economics, chapter 15,
pages 731-800. North-Holland, Amsterdam.
Geweke, J., 2007. Convergence Properties of the Likelihood of Computed Dynamic
Models: Comment. Manuscript, Departments of Economics and Statistics,
University of Iowa.
Geweke, J., Keane, M., 2000. Bayesian inference for dynamic discrete choice
models without the need for dynamic programming. In: Mariano, Schuermann,
Weeks (Eds.), Book Simulation Based Inference and Econometrics: Methods and
Applications. Cambridge University Press, pp. 100–131.
Gilleskie, D., 1998. A dynamic stochastic model of medical care use and work
absence. Econometrica 66, 1–45.
Hajivassiliou, V., McFadden, D., 1998. The method of simulated scores for the
estimation of LDV models. Econometrica 63, 863–896.
Hajivassiliou, V., Ruud, P., 1994. In: McFadden, D., Engle, R. (Eds.), Classical
Estimation Methods for LDV Models Using Simulation. In: The Handbook of
Econometrics, vol. 4. North-Holland, Amsterdam.
Hall, G., Rust, J., 2005. Simulated Minimum Distance Estimation of a Model of
Optimal Commodity Price Speculation with Endogenously Sampled Prices.
Manuscript. Department of Economics. University of Maryland.
Heckman, J., 1981. The incidental parameters problem and the problem of initial
conditions in estimating a discrete time-discrete data stochastic process.
In: Manski, C., McFadden, D. (Eds.), Structural Analysis of Discrete Data with
Econometric Applications. MIT Press.
Heckman, J., Lochner, L., Taber, C., 1998. Explaining rising wage inequality:
Explanations with a dynamic general equilibrium model of labor earnings with
heterogeneous agents. Review of Economic Dynamics 1, 1–58.
Heckman, J., Singer, B., 1984. A method for minimizing the impact of distributional
assumptions in economic models for duration data. Econometrica 52, 271–320.
Heckman, J., Navarro, S., 2007. Dynamic discrete choice and dynamic treatment
effects. Journal of Econometrics 136, 341–396.
Hendel, I., Nevo, A., 2006. Measuring the implications of sales and consumer
inventory behavior. Econometrica 74, 1637–1674.
Hollifield, B.R., Miller, R.A., Sandas, P., 2004. Empirical analysis of limit order
markets. Review of Economic Studies 71, 1027–1063.
Holmes, T., 2008. The Diffusion of Wal-Mart and Economies of Density. NBER
Working Paper No. 13783.
Hotz, J., Miller, R.A., 1993. Conditional choice probabilities and the estimation of
dynamic models. Review of Economic Studies 60, 497–529.
Hotz, J., Miller, R.A., Sanders, S., Smith, J., 1994. A simulation estimator for dynamic
models of discrete choice. Review of Economic Studies 61, 265–289.
Imai, S., Jain, N., Ching, A., 2007. Bayesian Estimation of Dynamic Discrete Choice
Models. Manuscript. University of Toronto.
Jofre-Bonet, M., Pesendorfer, M., 2003. Estimation of a dynamic auction game.
Econometrica 71, 1443–1489.
Kano, K., 2006. Menu Costs, Strategic Interactions and Retail Price Movements.
Manuscript. Queen’s University.

Karlstrom, A., Palme, M., Svensson, I., 2004. A dynamic programming approach to
model the retirement behaviour of blue-collar workers in Sweden. Journal of
Applied Econometrics 19, 795–807.
Kasahara, H., Shimotsu, K., 2007a. Nested Pseudo-likelihood Estimation and
Bootstrap-based Inference for Structural Discrete Markov Decision Models.
Manuscript. Department of Economics. The University of Western Ontario.
Kasahara, H., Shimotsu, K., 2007b. Nonparametric Identification of Finite Mixture
Models of Dynamic Discrete Choices. Manuscript. Department of Economics.
The University of Western Ontario.
Keane, M., 1994. A computationally practical simulation estimator for panel data.
Econometrica 62, 95–116.
Keane, M., 2010. Structural vs. Atheoretic Approaches to Econometrics. Journal of
Econometrics 156, 3–20.
Keane, Michael P., Wolpin,, Kenneth I,, 1994. The solution and estimation of discrete
choice dynamic programming models by simulation and interpolation: Monte
Carlo evidence. The Review of Economics and Statistics 76, 648–672.
Keane, M., Wolpin, K., 1997. The career decisions of young men. Journal of Political
Economy 105, 473–522.
Keane, M., Wolpin, K., 2001. The effect of parental transfers and borrowing
constraints on educational attainment. International Economic Review 42,
1051–1103.
Keane, M., Wolpin, K., 2007. Exploring the usefulness of a non-random holdout
sample for model validation: Welfare effects on female behavior. International
Economic Review 48, 1351–1378.
Kennan, J., Walker, J.R., 2005. The Effect Income on Individual Migration Decisions.
Manuscript, University of Wisconsin-Madison.
Kennet, M., 1993. Did deregulation affect aircraft engine maintenance? An empirical
policy analysis. RAND Journal of Economics 24, 542–558.
Kennet, M., 1994. A structural model of aircraft engine maintenance. Journal of
Applied Econometrics 9, 351–368.
Krusell, P., Smith, A., 1998. Income and wealth heterogeneity in the macroeconomy.
Journal of Political Economy 106, 867–896.
Lancaster, A., 1997. Exact structural inference in optimal job-search models. Journal
of Business and Economic Statistics 15, 165–179.
Lee, D., 2005. An estimable dynamic general equilibrium model of work, schooling
and occupational choice. International Economic Review 46, 1–34.
Lee, D., Wolpin, K., 2006. Intersectoral labor mobility and the growth of the service
sector. Econometrica 74, 1–46.
Lee, D., Wolpin, K., 2010. Accounting for wage and employment changes in the
US from 1968-2000: A dynamic model of labor market equilibrium. Journal of
Econometrics 156, 68–85.
Lerman, S., Manski, C., 1981. On the use of simulated frequencies to approximate
choice probabilities. In: Manski, C., McFadden, D. (Eds.), Structural Analysis of
Discrete Data with Econometric Applications. MIT Press, Cambridge, MA.
Lorincz, S., 2005. Persistence Effects in a Dynamic Discrete Choice Model:
Application to Low-End Computer Servers. Discussion Papers 2005/10. Institute
of Economics Hungarian Academy of Sciences.
Lumsdaine, R., Stock, J., Wise, D., 1992. Three models of retirement: Computational
complexity versus predictive validity. In: Wise, David A. (Ed.), Topics in the
Economics of Aging. University of Chicago Press, Chicago.
Magnac, T., Thesmar, D., 2002. Identifying dynamic discrete decision processes.
Econometrica 70, 801–816.
Manski, C., 1993. Dynamic choice in social settings: Learning from the experience
of others. Journal of Econometrics 58, 121–136.
Manski, C., 2004. Measuring expectations. Econometrica 72, 1329–1376.
Melnikov, O., 2000. Demand for Differentiated Durable Products: The Case of the
U.S. Computer Printer Market. Manuscript. Department of Economics, Yale
University.
Miller, R., 1984. Job matching and occupational choice. Journal of Political Economy
92, 1086–1120.
Miller, R., 1997. Estimating models of dynamic optimization with microeconomic
data. In: Pesaran, H., Smidth, P. (Eds.), Handbook of Applied Econometrics:
Microeconomics. Blackwell.
Miller, R., Sanders, S., 1997. Human Capital Development and Welfare Participation.
In: Carnegie-Rochester Conference Series on Public Policy, vol. 46. pp. 1–44.
Mira, P., 2007. Uncertain infant mortality, learning and life-cycle fertility.
International Economic Review 48, 809–846.
Mortensen, D., Pissarides, C., 1999. New Developments in Models of Search in the
Labor Market. In: Handbook of Labor Economics, vol. 2. pp. 2567–2627 (Chapter
39).
Murphy, A., 2008. A Dynamic Model of Housing Supply Manuscript. Department of
Economics. Duke University.
Pakes, A., 1986. Patents as options: Some estimates of the value of holding european
patent stocks. Econometrica 54, 755–784.
Pakes, A., 1994. Dynamic structural models, problems and prospects. In: Sims, C.
(Ed.), Advances in Econometrics. Sixth World Congress. Cambridge University
Press.
Pakes, A., Ostrovsky, M., Berry, S., 2007. Simple estimators for the parameters of
discrete dynamic games (with entry/exit examples). Rand Journal of Economics
38, 373–399.
Pantano, J., 2008. On Scarlet Letters and Clean Slates; Criminal Records Policy
in a Dynamic Model of Human Capital Accumulation and Criminal Behavior.
Manuscript. Department of Economics. UCLA.
Pesendorfer, M., Schmidt-Dengler,,, 2008. Asymptotic least squares estimators for
dynamic games. The Review of Economic Studies 75, 901–928.
Rota, P., 2004. Estimating labor demand with fixed costs. International Economic
Review 45, 25–48.

V. Aguirregabiria, P. Mira / Journal of Econometrics 156 (2010) 38–67
Rios-Rull, J.V., 1999. In: Marimon, R., Scott, S. (Eds.), Computation of Equilibria
in Heterogeneous Agent Models,in Computational Methods for the Study of
Dynamic Economies: An Introduction. Oxford University Press, Oxford.
Rust, J., 1987. Optimal replacement of GMC bus engines: An empirical model of
Harold Zurcher. Econometrica 55, 999–1033.
Rust, J., 1994a. In: Engle, R.E., McFadden, D. (Eds.), Structural Estimation of Markov
Decision Processes. In: Handbook of Econometrics, vol. 4. North-Holland,
Amsterdam.
Rust, J., 1994b. Estimation of dynamic structural models, problems and prospects:
Discrete decision processes. In: Sims, C. (Ed.), Advances in Econometrics. Sixth
World Congress. Cambridge University Press.
Rust, J., 2010. Comments on: Structural vs. atheoretic approaches to econometrics
by Michael Keane. Journal of Econometrics 156, 21–24.
Rust, J., Rothwell, G., 1995. Optimal response to a shift in regulatory regime: The
case of the US nuclear power industry. Journal of Applied Econometrics 10,
S75–S118.
Rust, J., Phelan, C., 1997. How social security and medicare affect retirement
behavior in a world of incomplete markets. Econometrica 65, 781–832.
Ryan, S., 2006. The Costs of Environmental Regulation in a Concentrated Industry.
Manuscript, MIT Department of Economics.
Sanchez-Mangas, R., 2002. Pseudo Maximum Likelihood Estimation of a Dynamic
Structural Investment Model. Working Paper 02-62, Statistics and Econometrics
Series. Universidad Carlos III de Madrid.
Slade, M., 1998. Optimal pricing with costly adjustment: Evidence from retail
grocery stores. Review of Economic Studies 65, 87–108.
Stern, S., 1997. Simulation-based estimation. Journal of Economic Literature 35,
2006–2039.
Stinebrickner, T., 2000. Serially correlated variables in dynamic discrete choice
models. Journal of Applied Econometrics 15, 595–624.
Stinebrickner, T., 2001. A dynamic model of teacher labor supply. Journal of Labor
Economics 19, 196–230.

67

Suzuki, J., 2008. Land Use Regulation as a Barrier to Entry: Evidence from the
Texas Lodging Industry. Manuscript. Department of Economics. University of
Minnesota.
Sweeting, A., 2007. Dynamic Product Repositioning in Differentiated Product
Markets: The Case of Format Switching in the Commercial Radio Industry. NBER
Working Paper #13522.
Sturm, R., 1991. A Structural Economic Model of Operating Cycle Management in
European Nuclear Power Plants. Manuscript, RAND Corporation.
Todd, P., Wolpin, K., 2006. Assessing the impact of a school subsidy program in
mexico. American Economic Review 96, 1384–1417.
Van der Klaauw, W., Wolpin, K., 2005. Social Security and the Retirement and
Savings Behavior of Low Income Households. PIER Working Paper 05-020.
Department of Economics. University of Pennsylvania.
Vella, F., 1998. Estimating models with sample selection bias: A survey. The Journal
of Human Resources 33, 127–169.
Vuong, Q., 1989. Likelihood ratio test for model selection and non-nested
hypotheses. Econometrica 57, 307–333.
Walker, J., 2003. Pregnancy and Fertility Expectations: Estimates of Bounded
Rationality and Unintended Births. Manuscript, University of Wisconsin.
Wolpin, K., 1984. An estimable dynamic stochastic model of fertility and child
mortality. Journal of Political Economy 92, 852–874.
Wolpin, K., 1987. Estimating a structural search model: The transition from
schooling to work. Econometrica 55, 801–818.
Wolpin, K., 1992. The determinants of black-white differences in early employment
careers: Search, layoffs, quites and endogenous wage growth. Journal of Political
Economy 100, 535–560.
Wolpin, K., 1996. Public-policy uses of discrete-choice dynamic programming
models. American Economic Review 86, 427–432.
Wolpin, K., 2007. Model validation and model comparison ex ante policy evaluation,
structural estimation, and model selection. American Economic Review 97,
48–52.

