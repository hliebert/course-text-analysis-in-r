Journal of Econometrics 200 (2017) 344–362

Contents lists available at ScienceDirect

Journal of Econometrics
journal homepage: www.elsevier.com/locate/jeconom

Counting rotten apples: Student achievement and score manipulation
in Italian elementary Schools✩
Erich Battistin a,b,c,d , Michele De Nadai e, *, Daniela Vuri f,d,g,h
a

Queen Mary University of London, United Kingdom
CEPR, United Kingdom
c
IRVAPP, Italy
d
IZA, Germany
e
University of New South Wales, Australia
f
University of Rome Tor Vergata, Italy
g
CESifo, Germany
h
CEIS, Italy
b

article

info

Article history:
Available online 21 July 2017
JEL classification:
C14
C31
C81
I21
J24

a b s t r a c t
We derive bounds on the distribution of math and language scores of elementary school students in Italy
correcting for pervasive manipulation. A natural experiment that randomly assigns external monitors to
schools is used to deal with endogeneity of manipulation, as well as its mismeasurement in the data.
Bounds are obtained from properties of the statistical model used to detect classes with manipulated
scores, and from restrictions on the relationship between manipulation and true scores. Our results show
that regional rankings by academic performance are reversed once manipulation is taken into account.
© 2017 Elsevier B.V. All rights reserved.

Keywords:
Measurement error
Non-parametric bounds
Partial identification
Score manipulation

1. Introduction
Cross-national comparisons on student achievement are widely
used to gauge the overall performances of a country’s school system. Figures obtained from the Trends in International Mathematics
and Science Study (TIMSS) and the Progress in International Reading
Literacy Study (PIRLS) show Italian primary schools performing
worst than in many European countries, especially in math. These
same tests also show Southern Italy well behind the North, not
✩ We are indebted with the Editor and two anonymous referees for constructive
comments on previous versions of this manuscript. Special thanks go to Patrizia
Falzetti, Roberto Ricci and Paolo Sestito at INVALSI for providing the achievement
data used here and to INVALSI staffers Paola Giangiacomo and Valeria Tortora for
advice and guidance in our work with these data. Our thanks to Joshua Angrist and
Enrico Rettore for helpful discussions and comments and to seminar participants
at the 2015 SOLE meeting, the 2015 Laax Labor Economics Workshop, the 2016
IAAE Conference, the 2016 Australasian Meeting of the Econometric Society, the
University of Florence, the University of Rome Tor Vergata and the University of
Maryland for helpful comments. This research was supported by the Fondazione
Bruno Kessler. The views expressed here are those of the authors alone.
Correspondence to: UNSW Business School UNSW Sydney, NSW 2052, Australia.
E-mail address: m.denadai@unsw.edu.au (M. De Nadai).

*

http://dx.doi.org/10.1016/j.jeconom.2017.06.015
0304-4076/© 2017 Elsevier B.V. All rights reserved.

surprisingly in view of the backwardness characterizing Southern
regions along many economic dimensions (higher unemployment,
lower per-capita income, higher crime rates) but also in terms of
financial development (Guiso et al., 2004), political accountability
(Nannicini et al., 2013) and workplace productivity (Ichino and
Maggi, 2000). At the same time Italy’s own accountability system,
managed by the Istituto Nazionale per la Valutazione del Sistema
dell’Istruzione (INVALSI), points to a very different regional pattern, with primary school students in the South doing better than
Northerners. The marked regional gradient pictured by INVALSI
data can be seen in the left hand side panels of Fig. 1, where
primary school math and language scores are considered. Moreover, the correlation of raw scores with proxies of school and family inputs unveils patterns in contrast with empirical regularities
usually found in the literature. For example we show in Fig. 2
that lower per-capita income is associated with higher scores in
math, and that public spending is inversely related to achievement. The implications of these results to guide public policy in
funding and accountability contradict the need for conspicuous EU
investments to support modernization of education in Southern

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

345

Fig. 1. Raw scores and manipulation rates. Note. These figures are obtained from INVALSI data pooling second and fifth grade students for the school years 2009-2011.

Italy through the Italian National Operative Programme (PON)
scheme.1
How can these two sets of statistics be reconciled? A key difference between INVALSI tests and TIMSS and PIRLS tests emerges in
their administration. INVALSI tests are proctored by local administrators and teachers, whereas in TIMSS and PIRLS scorers are organized into teams and a team leader ensures scoring reliability. We
argue here that local administration opens the door to cheating and
misreporting, and that it is this sort of manipulation that explains
surprising patterns in INVALSI data. Using a statistical model to
detect manipulation, INVALSI identifies about 6% of classes in the
country with compromised scores. In the South the proportion of
compromised exams averages about 13%, uncovering the substantial regional gradient shown in the right hand side panels of Fig. 1.
For example, about 16% of classes in Sicily are suspected to have
manipulated scores in math compared to less than 1% in Veneto,
1 See http://www.invalsi.it/invalsi/index.php for a list of PON projects in Italy.

the Northern region with the most reliable figures according to
INVALSI publications.
Angrist et al. (forthcoming) discuss at large the origin of this
phenomenon. They argue that local teachers manipulate results
by dishonest transcription of students hand-written answer sheets
onto machine-readable score report forms. INVALSI itself has acknowledged the problem, and now down-weights schools with
suspiciously large results in the derivation of aggregate figures.2
Score manipulation on the part of teachers is far from unique to
Italy. In an early empirical contribution, Jacob and Levitt (2003)
documented substantial cheating from teachers in Chicago public
schools. More recently, Dee et al. (2016) have shown that scores
on New York’s Regents exams are manipulated by school staff who
grade them in an effort to move marginal students over the performance thresholds. Concerns regarding score manipulation have
2 Their correction implicitly assumes that manipulated and honest scores are
representative of the same population (INVALSI, 2013), a restriction that we do not
impose here.

346

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

Fig. 2. Raw and adjusted scores against school and family inputs. Note. The figure plots regional math and language scores against regional per-capita income (left panel)
and pupil to teacher ratio (right panel). Points with · refer to raw scores and points with x refer to adjusted scores. Labeled in the figure are regions with the lowest (Veneto)
and highest (Sicily) incidence of presumed manipulation. Data on per-capita income are obtained from Istat, Conti economici regionali 2012. Data on the pupil to teacher ratio
are from the Ministry of Education, La scuola statale - sintesi dei dati 2009-2010.

also been raised in Sweden (Böhlmark and Lindahl, 2015; Diamond
and Persson, 2016) and in the United Kingdom, where Key Stage
1 tests at primary school are locally marked.3 A recent systemwide cheating scandal in Atlanta has raised much interest from the
media and several educators have been convicted (Severson 2011;
Aviv 2014; Blinder, 2015).
3 See https://www.gov.uk/government/collections/national-curriculum-assess
ments-key-stage-1-tests.

The contamination of INVALSI data raises the problem of uncovering true patterns across Italian regions, which is the objective
of this paper. Our analysis develops considering features of the
true score distribution, its average being an example. Two main
problems challenge identification. As classes with manipulated
scores are arguably not representative of the population, selection
precludes identification of the counterfactual score for manipulators. Moreover, the manipulation status from the statistical model
employed by INVALSI can be misclassified as we do not have direct
evidence on who manipulates.

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

We deal with these two problems using a policy that randomly
assigns external monitors to 20% of institutions in the country.4
Monitors supervise test administration and are responsible for
score sheet transcription, as we discuss below. We use the presence
of monitors at institution to instrument for manipulation, and
show that this is sufficient to bound the distribution of true scores.
Allowing for misclassified manipulation widens these bounds.
However, if misclassification is independent of the sampling process that assigns monitors to classes and if monitoring prevents
manipulation, monitored classes classified as manipulators reveal
part of the error. We show how this result, coupled with standard
assumptions on the misclassification error (Mahajan 2006; Lewbel
2007; Hu 2008), yields bounds on the distribution of true scores
that allow for endogenous and mismeasured manipulation.5 Central to the development of our strategy are additional assumptions
on the relationship between true scores and the incentives to manipulate. We show that a simple Roy model motivates restrictions
on the true underlying achievement patterns and on the extent of
misclassification.
The resulting bounds are sufficiently tight to reverse regional
differences in raw scores: after correcting for manipulation, students in the North outperform students in the South in both math
and language. Looking at a finer geographic disaggregation, we see
that bounds in the most problematic regions of the South are dominated by scores in most regions of the North. For example Sicily
– the region with the highest presumed incidence of manipulation
– is ranked 3rd among the 20 Italian regions using raw math scores,
and 15th at best after our correction. Our conclusions reconcile
INVALSI data with evidence from international surveys, both in
terms of the regional gradient in achievement and of its relationship with family and school inputs (as shown in Fig. 2). We also
show that score manipulation in the South is largely independent
of the threat of having external monitors at institution, suggesting
that dishonesty is widespread.
The remainder of the paper is organized as follows. Section 2
presents the institutional background and data, describes the monitoring experiment and explains the statistical procedure used
by INVALSI to detect manipulation. Section 3 shows how to get
identification of the parameters of interest when manipulation is
measured without error. Section 4 derives the conditions for identification when manipulation is instead misclassified. Section 5
presents conclusions on the extent of manipulation in INVALSI
data that are robust to measurement error. In addition, we discuss
how manipulation affects scores. Section 6 presents bounds on true
achievement obtained by imposing restrictions on the behavior of
manipulators. Section 7 derives policy implications and concludes.
2. Background and data
Institutional background and sample selection criteria
We use administrative data collected by the INVALSI on testing
program in Italian elementary schools in the 2009/10, 2010/11, and
2011/12 academic years. Elementary school lasts 5 years starting
from 6 years of age and covers grade 1 to 5. Standardized testing
for evaluation purposes is mandatory in Italy since 2009 for all
schools and students. INVALSI assessments considered in what
follows cover math and language skills of pupils in second and fifth
grade in a national administration lasting two days in the Spring,
usually in May.6 Scores in language and math are computed as
4 Institutions consist of affiliated schools, not at the same location.
5 Identification under endogenous and misclassified ‘treatment’ is also considered in Nicoletti et al. (2011), Kreider et al. (2012), and Battistin et al. (2014).
6 The testing procedure and its implementation are described in the annual
reports of INVALSI (see http://www.invalsi.it).

347

percentage of correct answers, measured by grade and year of test
administration. Our statistical unit of analysis is the class since our
manipulation variable varies at class level, as explained below. The
working sample includes only public schools (over 90% of primary
school students) and consists of about 70,000 classes in each of the
two grades covered by three years of data.
The monitoring experiment
In an effort to increase test reliability, INVALSI randomly selects institutions to be observed by an external monitor. Every
year about 7% of classes and 20% of institutions in the country
are mandated to external control on the test day. Compliance of
institutions is enforced by the Italian law. Monitors are selected
from a pool of retired teachers and principals who did not have
direct contacts with the schools or worked in town in the two years
preceding the test. The daily salary offered is about 200 euros per
class monitored. Monitors supervise test administration and are
responsible for score sheet transcription in a limited number of
classes which are selected following a two-stage design. First, a
sample of institutions stratified by region is drawn with probability
proportional to grade enrollment; then, in sampled institutions,
one or two classes by grade (depending on grade enrollment) are
assigned an external monitor. Although within-institution monitoring is supposed to preserve randomness, in practice it appears
to be contaminated by negotiation between school principals and
INVALSI (as evident from descriptives in Bertoni et al., (2013) and
discussed in Angrist et al. (forthcoming)).
In the absence of external monitoring, tests are proctored by
local school staff. Proctors are expected to copy students’ original
responses onto machine-readable answer sheets (called scheda
risposta), which are then sent to INVALSI. The transcription procedure is needed because this task is not mechanical. Questions come
in the form of multiple choice and open-ended items. Answers
to open questions have to be judged by transcribers as correct,
wrong or missing, thus making transcription a form of grading.
This transcription procedure opens the door to score manipulation,
as does the fact that no further checks are enforced to ensure
that students’ original responses coincide with information on
scheda risposta sent to INVALSI. Importantly, the transcription is
performed outside official school hours without any monetary
incentives for teachers.
Measuring manipulation
The possibility of score manipulation is acknowledged by INVALSI in their official publications. We build on Angrist et al. (forthcoming), who show that manipulation reflects teacher behavior.
Specifically, it follows from dishonest transcription of students
hand-written answer sheets onto machine-readable score report
forms.
To identify classes with compromised scores, INVALSI adopts a
procedure that takes as input within-class information on average
and standard deviation of test scores, proportion of missing items,
and variability in response patterns (as measured by a Gini index of
homogeneity). The 4 × 4 correlation matrix determined by these
indicators is used to extract two principal components, explaining
over 90% of total variance for the years considered in our analysis.
Cluster analysis is then used to form eight groups of classes from
values of their principal components. Fuzzy clustering is adopted,
yielding a matrix whose elements are, for each class, eight group
membership probabilities. Classes with manipulated scores are
identified as those in the group with ‘‘extreme’’ values of the principal components. In practice, these are classes with abnormally high
performance, small dispersion of scores, low proportion of missing
items, and high concentration in response patterns relative to the

348

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

Table 1
Compliance types.

M0 = 1
M0 = 0

M1 = 1

M1 = 0

Dishonest (D)
Non-complying dishonest (N)

Complying (C)
Honest (H)

Note. This table defines the four compliance types implied by the monitoring
experiment. Types refer to teacher behavior. See Section 3 for details.

population averages of these indicators. The indicator adopted by
INVALSI is the probability of membership to the extreme group
resulting from fuzzy clustering. This indicator is subject-specific
(math and language), and clustering is stratified by grade and
year.7
The manipulation indicator used in this paper is obtained replicating the same statistical procedure. However, hard clustering is
used instead of fuzzy clustering: only classes in the extreme cluster
identified by INVALSI are deemed to have compromised scores. The
continuous indicator used by INVALSI is replaced here by a dummy
variable aimed at outlier detection. The binary indicator eases
interpretation, facilitates the discussion of measurement error in
Section 4 and is in the spirit of Jacob and Levitt (2003). The right
hand side panels of Fig. 1 report the fraction of classes with compromised scores resulting from our indicator. The regional pattern
depicted is qualitatively identical to that reported by INVALSI in
official reports (e.g., INVALSI, 2010).
Descriptive statistics for the estimation sample are presented in
Table A.1.8

of the two potential outcomes (M0 , M1 ). The notation for potential
scores is also adjusted and indexed to the presence of monitors.
The variable Ymz represents class scores when M = m and Z = z,
where m = 0, 1 and z = 0, 1. The following assumption will be
maintained throughout.
Assumption 1 (Independence, Monitoring Effects, Exclusion and
Monotonicity). (a) (Ym1 , Ym0 , M0 , M1 ) ⊥Z ; (b) E [M1 − M0 ] ̸ = 0;
(c) Ym1 = Ym0 for m = 0, 1; (d) φN = 0.
Assumption 1a is implied in our setting by random assignment
of monitors to institutions. Assumption 1b states that institution monitoring is effective in reducing manipulation. Assumption 1c is an exclusion restriction implying that monitoring lowers
scores only by lowering manipulation.9 Assumption 1.d rules out
the presence of non-complying dishonest teachers, imposing that
monitoring does not cause manipulation. Given these assumptions,
we can identify four functionals of score distributions by adapting
expressions in Abadie (2002):
E [g(Y1 )|D] =

E [g(Y1 )|C ] =

E [g(Y0 )|C ] =

3. Identification when manipulation is observed
E [g(Y0 )|H ] =
Let Y1 and Y0 be scores with and without manipulation, respectively. The observed score is Y = Y0 (1 − M ) + Y1 M, where
M is an indicator for manipulation (the ‘treatment’). Class is the
unit of analysis. The random variable Z takes value one if the class
belongs to a monitored institution, while Q denotes monitored
classes; hence Q = 0 if Z = 0 by design. Class and school level
demographics X are also available, the conditioning on which is
left implicit.
The monitoring experiment is used to learn about scores for
different, latent types of teachers in the population. Types are
defined by indexing manipulation to Z = z, Mz , to express the
idea that monitoring should lower manipulation. Combinations
of (M0 , M1 ) define the four, mutually exclusive groups reported
in Table 1. Honest (H) teachers are those who never manipulate.
The remaining teachers are classified depending on their behavior
in the presence of external monitoring. Complying (C) teachers
are those who manipulate only when the threat is low (without
monitors). Dishonest (D) teachers are those with positive expected
benefit from manipulation even when the threat is high (with
monitors). Finally, non-complying dishonest (N) teachers are those
who would manipulate only with external monitors.
The incidence of the four groups in the population is φH , φC , φD
and φN , respectively. The monitoring experiment reveals only one
7 For additional details, see Quintano et al. (2009). Classes suspected of manipulation are not sanctioned, although from school year 2011/12 INVALSI has used the
manipulation indicator to adjust class scores. In classes with values of the indicator
above a threshold set by INVALSI, results are not returned to the school. Below this
threshold and within a range of values decided by INVALSI, scores are weighted
by the value of the manipulation indicator. This procedure was unknown at the
time of the test, making it unlikely that score manipulation anticipates the future
adjustment.
8 We will conventionally label as ‘North’ regions in Northern and Central Italy
(Piedmont and Valle d’Aosta, Liguria, Trentino Alto Adige, Veneto, Friuli Venezia
Giulia, Emilia Romagna, Tuscany, Umbria, Lazio). These will be contrasted to regions
in the South (Abruzzo and Molise, Campania, Pulia, Basilicata, Calabria, Sicily and
Sardinia).

E [g(Y )M |Z = 1]
E [M |Z = 1]

,

(1)

E [g(Y )M |Z = 1] − E [g(Y )M |Z = 0]
E [M |Z = 1] − E [M |Z = 0]

,

E [g(Y )(1 − M)|Z = 1] − E [g(Y )(1 − M)|Z = 0]
E [(1 − M)|Z = 1] − E [(1 − M)|Z = 0]
E [g(Y )(1 − M)|Z = 0]
E [(1 − M)|Z = 0]

,

(2)

, (3)

(4)

where g(Y ) is any real function of the observed variable Y such that
the moments above are finite. In the empirical analysis the function
g(Y ) will be assumed non-decreasing in its argument. Since:
E [M |Z = z ] = φD + (1 − z)φC ,
we have φD = E [M |Z = 1], φC = E [M |Z = 0] − E [M |Z = 1] and
φH = 1 − φD − φC . Fig. 1 motivates the investigation of conditional
versions of this parameter by area (e.g., North versus South).
The difference between Eqs. (2) and (3) identifies the effect of
manipulation for C teachers. We are interested, however, in the
following quantity that includes H and D teachers as well:
E [g(Y0 )] = E [g(Y0 )|D]φD + E [g(Y0 )|C ]φC + E [g(Y0 )|H ]φH .

(5)

We will use g(Y0 ) = Y0 when considering average scores, and
g(Y0 ) = 1(Y0 ≥ θ ) to learn about classes scoring above a cutoff
θ ∈ [0, 100]. Even if M is not mismeasured, Assumption 1 is not
sufficient for point identification as E [g(Y0 )|D] is not identified in
general. By varying the latter quantity over the space of its possible
values, we obtain the identification region for E [g(Y0 )]. As we shall
see in Section 4, lack of identification is exacerbated when the
indicator M is mismeasured.
The identification region for the quantity of interest is narrowed
by assuming that manipulation boosts scores, as seems likely.
Assumption 2 (Scores and Manipulation). 0 ≤ Y0 ≤ Y1 .
9 Using survey data on exam day experiences and perceptions, Bertoni et al.,
(2013) find no direct effects of monitors on fifth graders’ feelings and motivation.
This rules out a possible effect of monitoring on scores over and above the effect
on manipulation. Assumption 1c is violated if the extent of manipulation depends
on the presence of monitors at institution, for example because Y11 < Y10 . Assumptions would be needed to sign the role of unobservables that cause such violation, in
the spirit of Nevo and Rosen (2012). Point identification of the quantities in (1)–(4)
would be lost in this case.

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

This assumption implies g(0) ≤ E [g(Y0 )|D] ≤ E [g(Y1 )|D],
which narrows the width of the identification region for (5) to
(E [g(Y1 )|D] − g(0)) φD . Importantly for what follows, φD = 0
implies point identification. We will refer to naive bounds for (5)
as those obtained under Assumption 2.
Finally, we are interested in counting ‘rotten apples’. The quantities 1 − φH (i.e., the fraction of non-honest teachers, consisting
of C and D groups) and φD (i.e., the fraction of D teachers) are
considered to this end. These quantities are always point identified
if manipulation is not mismeasured. The quantity φC is of independent interest, as it measures the size of teachers whose behavior
is changed by the monitoring experiment. Using the instrumental
variables jargon, this is the first stage effect when M is considered
as ‘treatment’.
Table A.2 in Appendix A reports estimates of the quantities
above obtained from raw data when g(Y ) = Y . The counterfactual
terms (1)–(4), are estimated from 2SLS regressions which follow
from those described in Section 4 imposing no measurement error.
The average effect of manipulation for C teachers, E [Y1 − Y0 |C ], is
positive and large — see columns (1) and (4). Classes with H teachers appear to have comparable scores everywhere in the country,
well above those for classes with C teachers. Since E [M |Z = 1] −
E [M |Z = 0] = −φC , the table also shows that monitoring reduces
manipulation, particularly in the South. Moreover, the size of the
complying population among non-honest teachers is below 10% in
the South. In the North φD is negligible and set to zero in estimation
for practical purposes, implying that the presence of monitors at
institution is sufficient to offset dishonest transcription of scores in
all classes. We will soon come back to differences in the prevalence
of latent types across areas.
4. Identification with misclassified manipulation
Monitoring and misclassification
In practice, we do not know for sure who manipulates. Rather,
we observe only a proxy for M, denoted by W , which corresponds
to the manipulation indicator described in Section 2.10 We therefore turn to an analysis that takes misclassification into account.
We first assume that class monitoring (that is, monitoring of
classes within sampled institutions) prevents manipulation. Here
and below the notation employed uses the fact that monitored
classes are only in monitored institutions.
Assumption 3 (No Manipulation in Monitored Classes). E [M1 |Q =
1] = 0.
The potential outcome notation is employed here to stress that
class monitoring constrains behavior of teachers. The assumption
is weaker than assuming that monitoring eliminates manipulation
in all classes at institution, and implies:
M = M(1 − Q ).

Assumption 4 (Misclassification Independent of Monitoring).
E [W |M1 = m, Z = 1] = E [W |M0 = m, Z = 0] for m = 0, 1.
Assumption 4 is an exclusion restriction implying that the correlation between monitoring and W reflects only the correlation
between monitoring and M. The relationship between observed
manipulation, W , and latent manipulation, M, can therefore be
written as:
W = (1 − π0 ) + (π0 + π1 − 1)M + η,

10 As previously discussed, W is aimed at detecting outliers along multiple dimensions. However, this indicator is not deterministically related to large class scores.
For example, 39% and 67% of classes with scores in the top 10% and 20% of the math
distribution, respectively, have W = 0.

(7)

the terms π1 and π0 denoting probabilities of correct detection of
manipulated and honest scores, respectively:11

πm ≡ Pr [W = m|M = m],

m = 0, 1.

Our characterization is completed by assuming non-differential
misclassification, which is a standard assumption in the measurement error literature (see Carroll et al. (2006), and Chen et al.
(2011)). It qualifies W as a surrogate of M, in the sense that the
latter variable is finer than the former in the relationship between
manipulation, outcomes and Q .
Assumption 5 (Non-Differential Misclassification). For z = 0, 1 and
m = 0, 1:

(Y0 , Y1 , Q ) ⊥ W |Mz = m, Z = z .
This again is an exclusion restriction, implying that W does
not have any residual correlation with (Y0 , Y1 , Q ) when the manipulation status M is revealed. Importantly, it does not rule out
the likely correlation between manipulation, Y and Q , and can
be stated conditional on X . Also, Assumption 5 lends itself to an
interpretation that stems from the definition of latent types. It says
that errors in detection of misconduct (of D and C teachers) or of
honest behavior (of H and C teachers) are independent of outcomes
and class monitoring.
We can now derive the quantities (1)–(4), which are functionals
of (Y , Q , M , Z ), as functionals of (Y , Q , W , Z ). This allows us to
establish an identifying map between quantities of interest and
their analogues computed from raw data. Define:

Λ ≡ [W − (1 − π0 )] (1 − Q ),

Ψ (π1 ) ≡ (π0 + π1 − 1) − Λ.

The dependence on π0 is left implicit here, as this parameter will
not be relevant for the derivation of bounds in what follows. The
main results are presented in propositions, whose proof follows
from calculations reported in Appendix A.
Proposition 1 (Potential Distributions Under Misclassification). Under Assumptions 1, 3, 4 and 5:
E [g(Y1 )|D] =
E [g(Y1 )|C ] =

(6)

We further assume that the properties of the manipulation indicator do not change across populations for which it is computed. If
one maintains φN = 0, the probability of detecting manipulation
must be the same for D and C teachers. Similarly, detection of
honest reporting should be the same for H and C teachers. This
is equivalent to assuming classification errors independent of the
monitoring experiment.

349

E [g(Y0 )|C ] =
E [g(Y0 )|H ] =

E [g(Y )Λ|Z = 1]

,

E [Λ|Z = 1]
E [g(Y )Λ|Z = 1] − E [g(Y )Λ|Z = 0]

(8)

,

E [Λ|Z = 1] − E [Λ|Z = 0]
E [g(Y )Ψ (π1 )|Z = 1] − E [g(Y )Ψ (π1 )|Z = 0]
E [Ψ (π1 )|Z = 1] − E [Ψ (π1 )|Z = 0]
E [g(Y )Ψ (π1 )|Z = 0]
E [Ψ (π1 )|Z = 0]

.

(9)

,

(10)
(11)

The quantities above are partially identified by letting the
probabilities of correct classifications, π0 and π1 , vary over their
support. Importantly, quantities involving outcomes under manipulation depend only on π0 . The equations presented are derived
11 Since by definition of (M , M ) we have E [W |M = m, Z = z ] = E [W |M =
0
1
z
m, Z = z ], Assumption 4 is equivalent to E [W |M = m, Z = 1] = E [W |M = m, Z =
0] for m = 0, 1.

350

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

imposing the constrain in (6). When Q = 0 for all classes, Proposition 1 provides expressions for functionals of potential outcomes
in an instrumental variable setting when the treatment status is
misclassified.

probability π1 (for an application of the same method see Angrist
et al. 2013). For C teachers, the following equations are considered:

Proposition 2 (Rotten Apples Under Misclassification). Under Assumptions 1, 3, 4 and 5:

g(Y )Ψ (π1 ) = α0C + β0C Ψ (π1 ) + ζ0C ,

1 − φH =

E [Λ|Z = 0]
(π0 + π1 − 1)

,

φD =

E [Λ|Z = 1]
(π0 + π1 − 1)

.

Note that the ratio of these two quantities depends only on π0 :

φD
E [Λ|Z = 1]
=
,
1 − φH
E [Λ|Z = 0]

(12)

and represents the share of D teachers among the pool of nonhonest (D or C) teachers. It also follows that:

φC =

E [Λ|Z = 1] − E [Λ|Z = 0]
(π0 + π1 − 1)

.

Proposition 3 (Identification of π0 ). Under Assumptions 3–5 the
misclassification probability π0 is identified from the monitoring experiment:
(1 − π0 ) = E [W |Q = 1].
The last result is central for what follows, implying that the
quantities (8), (9) and (12) are point identified from the data. It
follows that identification region for the parameter in (5) becomes
wider when W ̸ = M because π1 is unknown. At the same time,
point identification of φD , φC and φH is lost.12
The difference between (9) and (10) identifies the causal effect
of manipulation for C teachers. Using the expression for (1 − π0 ) in
Proposition 3, it follows that:
E [g(Y1 ) − g(Y0 )|C ] = (π1 − E [W |Q = 1])

×

E [g(Y )|Z = 1] − E [g(Y )|Z = 0]
E [W |Z = 1] − E [W |Z = 0]

,

the last term on the right hand side representing the causal effect
obtained from raw data (Table A.2 in Appendix A reports the
effect when g(Y ) = Y ). A sufficient condition to ensure that
misclassification preserves the sign of this causal effect is π1 >
E [W |Q = 1]. The latter assumption also implies that manipulation
biases upward causal effects for complying teachers estimated
from raw data (Aigner, 1973).13
Finally the following assumption is also imposed. It is convenient in our setting, and is not rejected in the data when combined
with Assumption 8. This is more than the minimum requirement
to maintain positive correlation between M and W, and imposes a
lower bound on the correlation between W and M.
Assumption 6 (Informational Content of W ). π1 ≥ 0.5.
Estimation
The quantities in Proposition 1 are estimated from a sequence
of 2SLS regressions using Z as instrument at selected values of the

g(Y )Λ = α1C + β1C Λ + ζ1C ,
(13)

and the coefficients β and β are used to estimate (9) and (10),
respectively. For D teachers, the quantity (8) is obtained by considering the coefficient β1D from:
C
1

C
0

g(Y )ΛZ = α1D + β1D ΛZ + ζ1D .

(14)

Finally, the coefficient β from:
N
0

g(Y )Ψ (π1 ) (1 − Z ) = α0N + β0N Ψ (π1 ) (1 − Z ) + ζ0N ,
is used to estimate the quantity (11). We estimate separate regressions by area (Northern versus Southern regions), controlling
for grade and year effects and using sampling probability weights
constructed from the stratification variables in the monitoring
experiment (region, grade enrollment at institution and their interactions).14 Standard errors are obtained using 100 bootstrap
replications clustering on institution. We will use these as pointwise standard errors (i.e., standard errors computed for a fixed
value of π1 ) in presenting some of the results. The quantities in
Proposition 2 are estimated from their sample analogues, using
sampling probability weights, and their standard errors computed
via bootstrap.15
Finally, the value (1 − π0 ) is estimated by taking the empirical
analogue of E [W |Q = 1] using all monitored classes in the sample.
In particular, we impose the same value of (1 − π0 ) across areas,
as the regression of W on X for monitored classes (Q = 1) did
not yield important differences over time, grades and areas. The
resulting estimate of π0 is 98%, implying that 2% of classes are
erroneously classified as manipulators.
5. Counting rotten apples
Using raw INVALSI data we compute the fraction of honest (φH ),
complying (φC ) and dishonest teachers (φD ) from Proposition 2.
Results are presented in Fig. 3 by varying π1 over the interval
[0.5, 1], separately for Northern and Southern regions. Shaded areas represent 95% confidence intervals obtained at each value of π1 .
The left hand side panels show that the fraction of honest teachers
is almost 100% in the North, and that it uniformly dominates,
at all values of π1 , the fraction of honest teachers in the South.
Manipulation appears to be more pronounced for math.
The fraction of C teachers is reported on the right hand side
panels of Fig. 3. The incidence of D teachers can be mechanically
obtained as a residual term φD = 1 − φH − φC , and is not
presented. The striking feature about manipulation in the North
is that all dishonest teachers are compliers, implying φD ≃ 0. The
important policy conclusion to draw is that institution monitoring
in the North annihilates manipulation. Complying teachers in the
South are roughly half the pool of non-honest (C or D) teachers.
Depending on the value of π1 , the size of the non-honest group

as the sets of values taken by (10) and (11), respectively, when π1 ≥ a. Calculations
available on request show that, for δ > 0 and a + δ < 1, we have SC (a + δ ) ⊂ SC (a)
and SH (a + δ ) ⊂ SH (a). This implies that the identification regions for (10) and (11)
shrink as π1 increases to one.
13 Under Assumption 6, Assumption 2 does not restrict the range of values of the

14 All control variables here are categorical. To ease the computational burden,
and since the identification result abstracts from parametric restrictions, we impose
that covariates enter linearly the various conditional expectations. We checked the
sensitivity of our conclusions to this restriction by implementing the estimator
proposed by Frölich (2007), which uses non-parametric estimates over cells defined
by the cross-tabulation of X and Z . In our data, the average sample size across 240
cells is 583 classes. Results from this alternative estimation strategy are reported
in Figures B1–B4 of the on-line Appendix B, and are qualitatively similar to those
presented below.
15 See Arcones and Giné (1992) and Hahn (1996) for the validity of bootstrap for

probability π1 .

just identified 2SLS models with an i.i.d. sample from (Y, W, Z).

12 Define:
SC (a) ≡ {E [g(Y0 )|C ] : π1 ≥ a} ,

SH (a) ≡ {E [g(Y0 )|H ] : π1 ≥ a} ,

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

351

Fig. 3. Percentages of honest and complying teachers. Note. This figure reports the percentage of honest (φH ) and complying (φC ) teachers. Results are presented for the
interval π1 ≥ 0.5, separately for the North (continuous line) and the South (dashed line). Shaded areas are 95% bootstrap confidence intervals obtained at each value of π1 .

varies between 11% and 23% for language and between 15% and
30% for math. All D teachers are located in the South, suggesting
that manipulation is an area-specific phenomenon. The veil of
ignorance about the probability π1 limits our ability to count rotten
apples. However, our conclusions on peculiarities of the two areas
are not precluded by this limitation.
The evidence documented poses the question of how score distributions are affected by such pervasive manipulation. The issue
is addressed in Fig. 4, where densities of Y1 for D and C teachers
are reported. In light of the information conveyed by Fig. 3, only
results for the South are presented. For a grid of values θ in the
support of the outcome variable, we estimate Eqs. (13) and (14)

using g(Y ) = 1(Y ≥ θ ). The resulting estimates of β0C and β0D represent cumulative distributions for C and D teachers, respectively,
at all values θ . These are combined using the isotonic regression
smoother (Brunk, 1958) to impose non-decreasing curves, which
we then use to plot densities in Fig. 4. Shaded areas represent 95%
confidence intervals constructed from bootstrap standard errors
using 100 replications.16

16 Density estimation may be carried out using:
g(Y ) =

1
h

(
K

a−Y
h

)

,

352

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

Fig. 4. Manipulated score distributions by compliance type. Note. This figure shows the score distribution for math and language under manipulation for dishonest (left hand
side panels) and complying (right hand side panels) teachers. Only classes in the South are considered. Shaded areas are bootstrap 95% confidence intervals (see Section 4
for details).

Teachers manipulate scores to obtain almost perfect results
(i.e., 100% correct). This is consistent with manipulation boosting
scores on all items regardless of their difficulty. Wholesale curbstoning, a strategy that minimizes transcription or grading effort
while maintaining high levels of achievement, has been identified
as the primary force behind score manipulation in Angrist et al.

(forthcoming). The distributions presented for math and language
are substantially identical across latent types.

where the term on the right hand side is a kernel function with bandwidth h (see
Angrist et al., 2013 for a similar idea). The resulting estimates of β0C and β0D represent
densities at a for C and D teachers, respectively. The approach taken in this section
ensures some symmetry with density estimation at the end of Section 6, and yields
qualitatively identical results.

Bounds on E [g(Y0 )] are obtained by varying π1 over the range
implied by Assumption 6. For all admissible values of this probability, we compute (5) by retrieving the relevant quantities from
Propositions 1 and 2. Imposing Assumption 2, the counterfactual

6. Bounds on true scores
Naive bounds

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

term E [g(Y0 )|D] is bounded from above by (8), yielding the following bounds for a known value of π1 :
E [g(Y0 )] ≤ E [g(Y1 )|D]φD + E [g(Y0 )|C ]φC + E [g(Y0 )|H ]φH ,

}
φC
φH
+ E [g(Y0 )|H ]
, E [g(Y0 )|H ] ,
1 − φD
1 − φD
φC
φD
+ E [g(Y0 )|C ]
.
E [g(Y0 )] ≥ g(0)
1 − φH
1 − φH
{
≤ min E [g(Y0 )|C ]

where g(0) is the value of g(Y0 ) at the lowest possible value of the
score (Y0 = 0).17 Consistently with the evidence presented in the
previous section, we impose φD = 0 in the North implying that in
this area E [g(Y0 )] is point identified at all values of π1 . Shaded areas, here and in what follows, represent point-wise 95% confidence
intervals (i.e., confidence intervals computed for a known value of
π1 ) constructed using the bootstrap procedure by Horowitz and
Manski (2000) with 100 replications.
Bounds for average math and language scores are presented
in Fig. 5, separately for the two areas, using g(Y0 ) = Y0 . The
discussion of results for other functionals of the score distribution
is deferred to the final part of this section. Math scores in the North
are centered at about 61% of correct answers, a value included
in the corresponding bounds computed for the South. Confidence
intervals in the South shrink as π1 grows to one, ranging from
[51, 64] for π1 = 0.5 to [56, 63] for π1 = 1. Results are not
conclusive about the ranking of areas with respect to performance
in math. However, the bottom panel of Fig. 5 tells a different story
for language scores. Scores in the North virtually bound from above
the range of admissible values for scores in the South. The average
difference between areas computed from raw data is reversed
once manipulation is taken into account. Confidence intervals for
average scores in the South shrink from [60, 71] when π1 = 0.5 to
[65, 71] when π1 = 1.
Behavioral restrictions
Restrictions on the origin of manipulation can be used to tighten
naive bounds. The following assumption is reasonable for the case
at hand, implying that dishonest teachers have the lowest scores.
This is in the spirit of Kreider and Pepper (2011), although random
assignment of monitors to institutions adds to the informational
content of this assumption as we discuss further below.
Assumption 7 (Origin of Manipulation). The following inequality
holds for z = 0, 1:
E [g(Y0 )|Mz = 0] ≥ E [g(Y0 )|Mz = 1].
In potential outcome notation, the assumption is equivalent to
stating that D teachers have the worst scores:
(15)

and that H teachers have better scores than do D and C teachers:
E [g(Y0 )|H ] ≥ E [g(Y0 )|H̄ ],

Proposition 4 (Bounds Under Behavioral Restrictions). Under Assumptions 1, 3, 4, 5 and 7, the following bounds are defined for a
known value of π1 :
E [g(Y0 )]

E [g(Y0 )] ≥ g(0)φD + E [g(Y0 )|C ]φC + E [g(Y0 )|H ]φH ,

E [g(Y0 )|D̄] ≥ E [g(Y0 )|D],

353

(16)

where the notation D̄ and H̄ denote non-D and non-H teachers,
respectively. As we show in Appendix A, these assumptions are
expected to tighten the naive upper bound in our application. However, they do not necessarily make the naive lower bound more
informative. To ease presentation, we state the bounds implied by
Assumption 7 in the following proposition.

Fig. 6 shows how naive bounds for average scores are refined
by imposing Assumption 7. Results are obtained by taking the
intersection with bounds in the previous section. We find that (15)
and (16) unveil geographic differences in math scores and reinforce
the ranking in language scores already pictured by naive bounds.
Math scores in the North now bound from above admissible values
for scores in the South. Confidence intervals in the South change
from [51, 58] for π1 = 0.5 to [56, 61] for π1 = 1. Assumption 7
implies a sizable improvement for the width of bounds compared
to the naive case discussed above: about 46% at π1 = 0.5 and 38%
at π1 = 1. Confidence intervals for language scores in the South
are now [60, 68] when π1 = 0.5, and [65, 70] when π1 = 1 (with
a 17% and 27% width improvement, respectively), strengthening
geographic differences already evident with naive bounds.
A Roy model for manipulation
Assumption 7 yields a partial ordering of E [g(Y0 )] across latent
groups, and can be motivated using a Roy model for the decision
to manipulate. Write potential outcomes as Y1 = µ1 + ε1 and
Y0 = µ0 + ε0 , and let γ1 Z + τ be the manipulation cost. The
latter varies across classes and areas through the random term τ ,
and increases for everyone in the presence of external monitors
(γ1 > 0). By letting V ≡ −ε1 + ε0 + τ and γ0 ≡ µ1 − µ0 , the
decision to manipulate is modeled as:
M = 1(Y1 − Y0 − γ1 Z − τ > 0) = 1 (γ0 − γ1 Z ≥ V ) ,

(17)

where V is unobservable and assumed continuous with a strictly
increasing distribution function. In this setting, manipulation occurs if the expected benefit is positive. The assumption that Z is
independent of the triple (ε0 , ε1 , V ), which in our setting follows
from the monitoring experiment, together with the latent index
equation (17) imply, and are implied, by Assumption 1 (Vytlacil,
2002). Additive separability between Z and V plays an essential
role in this result. It follows that latent groups in the population
are identified from the value of V :
D : γ0 − γ1 ≥ V ,

C : γ0 ≥ V ≥ γ0 − γ1 ,

H : γ0 ≤ V .

This representation implies that scores for D, C and H teachers are
stochastically ordered if E [ε0 |V = v] is not decreasing in v .18 It
therefore follows that Assumption 7 is implied by non-decreasing
class performance in manipulation cost.
The same Roy model also implies the full ordering of E [g(Y0 )]
across latent groups for any non-decreasing function g(Y0 ). In
general this is neither implied by, or implies, Assumption 7. This
paves the way for the following additional assumption used in the
derivation of bounds.
Assumption 8 (Ranking of Scores Across Latent Types). The following inequality holds:
E [g(Y0 )|H ] ≥ E [g(Y0 )|C ] ≥ E [g(Y0 )|D].

17 This choice is rather conservative. The lowest scores are 22% and 30% for math
and language, respectively, in monitored institutions in Sicily, which is the Italian
region with the highest presumed manipulation rate.

18 Joint normality of (ε , V ) with positive correlation of the two components is
0
also sufficient for the result.

354

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

Fig. 5. Naive bounds on E [Y0 ]. Note. This figure shows naive bounds for average math and language scores, separately for North and South, for π1 ≥ 0.5. We impose φD = 0
in the North. Shaded areas are 95% confidence intervals at each value of π1 using the procedure by Horowitz and Manski (2000).

This requirement refines the identification region of the parameter of interest by changing the upper bound and by restricting the
parameter space for π1 . To see this, notice that the first inequality
in Assumption 8 implies:
E [g(Y0 )|H ] − E [g(Y0 )|C ] ≥ 0,

(18)

for all values of π1 . Given that both E [g (Y0 |H )] and E [g (Y0 |C )] are
identified from Eqs. (10) and (11) up to knowledge of π1 , we could
use Eq. (18) to rule out values of π1 yielding a negative difference.
Conditional on values of π1 for which (18) is not violated, the
following proposition presents the lower and upper bounds from
imposing that scores are ranked across latent types of teachers. We
show in Appendix A that the new upper bound is more informative
than the upper bound derived in Proposition 4.
Proposition 5 (Bounds Under Ranking of Scores). Under Assumptions 1, 3, 4, 5 and 8, the following bounds are defined for a known
value of π1 when E [g(Y0 )|H ] ≥ E [g(Y0 )|C ]:
E [g(Y0 )] ≤ E [g(Y0 )|C ](1 − φH ) + E [g(Y0 )|H ]φH ,

(19)

E [g(Y0 )] ≥ g(0)φD + E [g(Y0 )|C ](1 − φD ).

(20)

Bounds for average math and language scores obtained by imposing Assumptions 7 and 8 are shown in Fig. 7. We set π1 ≥ 0.56
and π1 ≥ 0.55 for math and language, respectively, as these are
the critical values ensuring the validity of (18).19 Classes in the
North outperform classes in the South in both math and language.
For math, scores in the South range from [52, 59] when π1 is at
its minimum to [56, 60] for π1 = 1 (implying a 20% improvement
on the width of bounds in Proposition 4 when π1 = 1). Similar
results are obtained for language, the width of confidence interval
at π1 = 1 now being [65, 68], with an improvement of about 40%.
The discussion so far has addressed the problem of bounding
average scores. The same methodology can be used to provide
bounds for distributions, by replicating the same analysis using
g(Y0 ) = 1(Y0 ≥ θ ). Bounds (19) and (20) define mixtures
bracketing the true, unknown distribution of Y0 for a known value
of π1 . For a grid of values θ in the support of the outcome variable,
we compute the complement to the cumulative distributions for
19 Fig. B5 in the on-line Appendix B presents the profile of this difference with
respect to π1 , together with confidence intervals obtained by bootstrapping the
difference between (10) and (11) which we estimate from 2SLS regressions as
explained above.

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

355

Fig. 6. Bounds on E [Y0 ] using behavioral restrictions. Note. This figure shows bounds for average math and language scores when Assumption 7 is imposed, separately for
North and South, for π1 ≥ 0.5. We impose φD = 0 in the North. Shaded areas are 95% confidence intervals at each value of π1 using the procedure by Horowitz and Manski
(2000).

complying teachers, E [1(Y0 ≥ θ )|C ], and honest teachers, E [1(Y0 ≥
θ )|H ]. The isotonic regression smoother is then applied as in Fig. 4,

Regional rankings

and bounds are computed by combining smoothed distributions
using mixture weights φH and φD . Results are presented in Fig. 8
for scenarios corresponding to ‘small’ (π1 = 0.95), ‘moderate’
(π1 = 0.90) and ‘large’ (π1 = 0.80) misclassification of true
manipulators.
Results show that the ranking of average scores does not follow
from stochastic dominance across areas. The lower tail of the math
distribution is thicker in the South, implying a larger number of
classes with problematic performance compared to the North.
However, the fraction of classes scoring above 60% (approximately
the average score for Northerners, as shown in Fig. 7) is comparable
across areas, and the upper tail in the South is significantly thicker
than in the North for scores between 70% and 90%. A similar
comment applies to language scores: the fraction of classes scoring
above 70%, the average score for Northerners, is comparable across
areas, but the lower tail of the distribution is much thicker in the
South. This conclusion holds up at all values of π1 considered,
implying that poor performance in the South is driven by a large
number of classes lagging behind academic standards of the best
classes in the area, which are instead comparable to the North.

The same analysis can be carried out at a finer geographic level
considering the 20 Italian administrative regions. This disaggregation is important as reflects political divisions responsible for
the administration of local resources, including those assigned
to schools. We start by deriving, for each region, bounds on the
incidence of manipulation E [M ]. These are obtained from (7) by
varying π1 over its support. Pragmatically, we impose E [M ] = 0
in those regions (6 for math and 5 for language, all in the North)
where the upper bound is below 1%. It follows that in these regions
raw scores can be treated as true scores (Y = Y0 ). Maintaining
the assumption that all manipulators in the North are compliers,
we compute bounds on regional scores as in Fig. 7. Our correction
heavily affects the national ranking because the effects of manipulation on scores are large, as it is shown in Fig. 9. Here bounds are
presented for π1 = 0.9, as the general conclusions are not sensitive
to this choice (see Figs. B6 and B7 in the on-line Appendix B which
report results for π1 = 0.80 and π1 = 0.95, respectively). Dots
in the figure represent average scores computed from raw data.
Continuous lines are confidence intervals for bounds on true scores
obtained from our correction. The vertical axis reports names of all

356

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

Fig. 7. Bounds on E [Y0 ] using full ranking of types. Note. This figure shows bounds for average math and language scores when Assumption 7 and Assumption 8 are imposed,
separately for North and South, for π1 ≥ 0.5. We impose φD = 0 in the North. Shaded areas are 95% confidence intervals at each value of π1 using the procedure by Horowitz
and Manski (2000).

regions, which are ranked clockwise from North to South (Lazio is
the last Northern region considered in the main analysis). Upper
bounds in the South are dominated by scores for most regions in
the North. For example, Sicily is ranked 3rd according to raw math
scores, and at best 15th after our correction. Moreover, the figure
allows to establish at least a partial ordering of Southern regions.
Not only our correction changes the regional gradient in scores,
but also affects its relationship with family and school inputs. Fig. 2
presents the association between scores and per-capita income
(left panel) and pupil-to-teacher ratio (right panel) across the 20
administrative regions of the peninsula. Dots in the figure are
average scores obtained from raw data, which are interpolated
to obtain the downward-sloping line for per-capita income and
the upward-sloping line for pupil-to-teacher ratio, respectively.
Superimposed are labels for the regions with lowest (Veneto) and
highest (Sicily) incidence of presumed manipulation according to
the indicator W . Results show that regions with low per-capita
income and high pupil-to-teacher ratio have the highest scores, a
fact hard to reconcile with evidence from the international literature. The figure also presents linear fits once manipulation is taken
into account. Adjusted scores, represented with crosses, coincide
with regional upper bounds in Fig. 9, thus considering the most

conservative scenario for the relationship with the socio-economic
indicators considered.
We find that score manipulation reverses the sign of the correlation. This finding has important implications for empirical
analyses using INVALSI data, as the effects of manipulation when
true scores, Y0 , are used as dependent variable in the relationship
with inputs, X , is not innocuous as it is in the case of classical measurement error. Although our discussion was not centered around
differences between ∂∂x E [Y0 |X = x] and ∂∂x E [Y |X = x], Appendix A
presents a simple setup showing under which conditions the latter
term can be wrongly signed because of score manipulation.
7. Conclusions and policy implications
Our findings have important policy implications. The first result
is that manipulation is widespread only in some areas of the
country (see Fig. 3). Scores in the North are reported correctly
for at least 98% of classes. The fraction of classes with compromised math scores in the South is instead at least 15%, but can
be almost 30% depending on the assumptions made on the extent
of misclassification. Manipulation reflects dishonesty of teachers
(Angrist et al. forthcoming) which, in the South, is a widespread

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

357

Fig. 8. Bounds on score distributions. Note. This figure shows bounds on math and language scores distributions when Assumption 7 and Assumption 8 are imposed,
separately for North and South, at selected values of π1 . We impose φD = 0 in the North. Shaded areas are 95% confidence intervals using the preocedure by Horowitz and
Manski (2000).

attitude rather than an opportunity to cut corners: approximately
half of dishonest teachers manipulate scores regardless of the
threat of having an external monitor at institution. Italian teachers
work in a highly regulated public sector, with virtually no risk of
termination, and are subject to a pay and promotion structure that
are largely independent of performance. As the available resources
are inadequate to increase the number of monitored classes or to
provide sensible monetary incentives to teachers, INVALSI should
improve reliability of the information collected either by sanctioning dishonest behavior or by enforcing high quality standards in
the transcription process. From 2013/14 multiple versions of the
same test are employed with items randomly ordered, making the

mechanical transcription of correct answers into scheda risposta
more difficult. Whether or not this measure has been successful
in limiting manipulation is still an open issue.
Measuring manipulation and purging data from its distortive
effects is of primary interest for the redistribution of resources
and the design of education policies. All indicators of score
manipulation are error prone, and the procedure followed by
INVALSI is no exception. We have shown that the INVALSI
monitoring experiment can be used to unveil part of the error. If the
properties of the manipulation indicator are independent of how
monitors are assigned to classes, the fraction of monitored classes
classified as honest must equal π0 . This probability in our data is

358

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

Fig. 9. Regional rankings using raw and adjusted scores. Note. This figure shows average scores from raw data and bounds on the average of true scores, the latter being
obtained under Assumption 7 and Assumption 8 when π1 = 0.9 (see Section 6 for details).

approximately 98%, with little variability across grades, areas and
time. As INVALSI flags as suspicious classes with a distribution of
answers unusually concentrated around high scores, 2% of truly
exceptional classes may be erroneously deemed to have manipulated results. The possibility of misclassification should be acknowledged in the publication of official reports.
Our approach offers an alternative to the correction used by
INVALSI until 2013 (Falzetti, 2013). Their method employed the
class-level probability of manipulation derived from fuzzy clustering (as described in Section 2). Average figures in the country
were obtained by down-weighting classes with abnormally high
values of the indicator with respect to Veneto, a region in the North
where scores are viewed as the most accurate. Classes with a probability value below the median for Veneto were given weight one;
all remaining classes were weighted one minus this probability.
This adjustment affected marginally the regional gradient obtained
from raw data, as can be seen from official reports published by

INVALSI.20 Starting from 2013, this procedure was refined by
INVALSI using weights constructed with a different methodology.
Both corrections are not uncontroversial, as they implicitly assume
that manipulators are a random sample from the population (as
well as that they can be detected for sure). Our approach overcomes such limitations.
Learning about the incidence of score manipulation allows to
rank Italian regions in terms of performance at national tests (see
Fig. 9). If the propensity to manipulate decreases with true scores,
an assumption consistent with the implications of a simple Roy
model, bounds on true scores are tight enough to reverse the
evidence from raw data. Classes in the South under-perform with
20 We document this in Fig. B8 of the on-line Appendix B. The correlation between
regional ranks before and after the correction is 99% and 66% for math and language
scores, respectively. A variant to this procedure is also considered by INVALSI, and
assigns weight zero to classes with a probability value above 50%. The resulting
regional ranking is comparable to that in Fig. B8 (results are available upon request).

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

respect to the rest of Italy, and differences are particularly pronounced in the most problematic regions. This conclusion aligns
well with that from international surveys like TIMMS and PIRLS.
Interestingly, a closer look at score distributions reveals higher
inequality in the South and thick tails at the lower end. Besides, the
best classes in the South have scores comparable to the best classes
in the North. It follows that differences in score distributions between areas do not result from a location shift, and poor average
achievement in the South can be ascribed to a disproportionally
large number of low performing classes. These are the learning
environments that should be primary target of policy interventions
in Southern Italy, for example through the National Operative
Programme (PON) scheme.
Why is the fact that score manipulation distorts regional rankings of general interest? Micro-data on student achievement are
employed in empirical research to learn about the most effective
determinants in the education production function. Manipulation
explains the puzzling, negative relationship between scores and
family and school inputs that researchers would measure from
raw data, as we have shown in Fig. 2. The association between
achievement and inputs is reversed by the correction, as better
endowed regions are now characterized by higher scores. Ignoring
manipulation, at least for the case of primary schools considered
here, would heavily bias results of empirical analyses using micro
data on scores. This finding has important implications for public
policy in funding and accountability.
Our findings raise a number of additional questions, including
why teacher manipulation is so much more prevalent in the South,
and what can be done to enhance accurate assessment in Italy
and elsewhere. Similar concerns have been raised in regard to the
consequences of local proctoring and grading of tests in Britain
and New York. For example, local teachers mark the UK’s Key
Stage 1 assessments (given in year 2, usually at age 7). Key Stage 2
assessments given at the end of elementary school (usually at age
11) are locally proctored with unannounced external monitoring
and external marking (grading).21 It is also worth asking what
are the determinants of low performance of students in the South
of Italy, in light of the ongoing education policies in those areas
(Objective 1 regions) eligible to receive EU Regional Development
Funds and EU Social Funds (see, for example Battistin and Meroni,
2013) and the positive trend in PISA scores of some regions. We
hope to answer these questions in future work.
Appendix A
A.1. Relationship between scores and socio-economic characteristics
We use a simple model in an effort to explain how manipulation
may reverse the relationship between scores and socio-economic
indicators (see the discussion at the end of Section 6). This is
motivated by results in Fig. 2. Assume the following relationship
between true scores, Y0 , and school inputs, X :
E [Y0 |X = x, g ] = α0g + β0 x,
where E [X ] = 0 and g = C , D, H. Assume β0 ≥ 0 without loss
of generality, so that inputs above the average are associated with
better scores. Assume also:

α0D ≃ α0C ≡ α0H̄ < α0H ,
implying that, at common values X = x, scores for D and C teachers
are approximately equal and below scores for H teachers. This
21 See documents and links at http://www.education.gov.uk/sta/assessment, and
the evidence of manipulation in Battistin and Neri (2015).

359

Table A.1
Descriptive statistics.
Italy
(1)

North
(2)

South
(3)

64.042
(13.027)
0.066
(0.248)
0.069
(0.253)

62.419
(10.628)
0.020
(0.141)
0.069
(0.253)

66.747
(15.892)
0.142
(0.349)
0.069
(0.253)

72.077
(10.172)
0.056
(0.231)
0.069
(0.253)

71.784
(8.730)
0.023
(0.150)
0.069
(0.253)

72.565
(12.187)
0.112
(0.316)
0.069
(0.253)

0.238
(0.426)
0.482
(0.500)
0.343
(0.475)
0.329
(0.470)
0.327
(0.469)

0.247
(0.431)
0.489
(0.500)
0.341
(0.474)
0.330
(0.470)
0.329
(0.470)

0.222
(0.416)
0.471
(0.499)
0.347
(0.476)
0.329
(0.470)
0.324
(0.468)

140,010

87,498

52,512

Panel A. Math
Raw score
Presumed manipulators
Monitored classes
Panel B. Language
Raw score
Presumed manipulators
Monitored classes
Panel C. Other covariates
Monitored institutions
Second grade
2009 survey
2010 survey
2011 survey
Number of classes

Note. This table presents descriptive statistics from INVALSI data pooling second
and fifth grade students for the years 2009–2011. Standard deviations in parentheses.

setting is consistent with Assumption 8. Manipulation takes the
form:
E [Y1 |X = x, g ] = α1 ≃ 100,
and follows from nearly perfect curbstoning (see Fig. 4; for a
discussion on the anatomy of manipulation see Angrist et al. (forthcoming)).
Consider institutions without monitors (Z = 0), where all complying teachers manipulate. The following quantities are defined
(the conditioning on Z = 0 is left implicit throughout):
E [Y0 |X = x] = (α0H + β0 x)φH (x) + (α0H̄ + β0 x)[1 − φH (x)],
E [Y |X = x] = (α0H + β0 x)φH (x) + α1 [1 − φH (x)],
where φH (x) is the fraction of H teachers at X = x. The expressions
above imply:
E [Y |X = x] = E [Y0 |X = x] + α1 [1 − φH (x)]

− (α0H̄ + β0 x)[1 − φH (x)]
and the following expression for the covariance between Y and X :
Cov[Y , X ] = Cov[Y0 , X ] − (α1 − α0H̄ )Cov[φ (X ), X ]

{
}
− β0 Var [X ] − E [X 2 φH (X )] .
Dividing both sides by Var(X ) we obtain:
Cov[Y , X ]
Var [X ]

=

Cov[Y0 , X ]
Var [X ]

− (α1 − α0H̄ )δH − β0 {1 − κH } ,

where κH = E [X 2 φH (X )]/Var(X ) ∈ (0, 1) and δH = Cov (φH (X ),
X )/Var(X ). This expression relates the slope of the linear regression
of Y on X , on the left hand side (see Fig. 2), to the slope of the linear
regression of Y0 on X , on the right hand side. Manipulation boosts
scores, implying α1 −α0H̄ ≥ 0. Notice that, if manipulation is nearly
perfect curbstoning, the term α1 −α0H̄ can be fairly large. If δH ≥ 0,

360

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362
Table A.2
Estimates of average counterfactual scores by compliance types and percentages of honest, complying and dishonest
teachers.
North

South

Complying
(1)

Dishonest
(2)

Honest
(3)

Complying
(4)

Dishonest
(5)

Honest
(6)

90.469
(0.210)
27.226
(3.895)
0.020
(0.000)

–
–
–
–
–
–

–
–
62.156
(0.071)
0.980
(0.000)

91.866
(0.483)
24.194
(4.194)
0.072
(0.004)

90.423
(0.090)
–
–
0.085
(0.003)

–
–
63.133
(0.140)
0.842
(0.002)

–
–
–
–
–
–

–
–
71.480
(0.056)
0.977
(0.001)

92.373
(0.417)
39.176
(4.087)
0.051
(0.003)

91.201
(0.073)
–
–
0.072
(0.003)

–
–
70.429
(0.106)
0.876
(0.002)

Panel A. Math
E [Y1 ]
E [Y0 ]

φ

Panel B. Language
E [Y1 ]

91.249
(0.149)
57.846
(2.424)
0.023
(0.001)

E [Y0 ]

φ

Note. This table shows estimates of average counterfactual scores by compliance types and percentages of honest,
complying and dishonest teachers. All terms are obtained from 2SLS regressions similar to those described in Section 3,
assuming that classes with manipulated scores are correctly classified. Standard errors in parentheses.

an assumption likely to hold in our data, we have Cov[Y0 , X ] ≥ 0
and that the second and third terms on the right hand side of
the last expression are negative. This may yield sign reversion, for
example if the gradient of φH (X ), amplified by (α1 − α0H̄ ), exceeds
the gradient of Y0 .
Now consider institutions with monitors (Z = 1), where
all complying teachers transcribe scores honestly. The quantity
E [Y0 |X = x] coincides with that for unmonitored (Z = 0) institutions. By denoting with φC (x) the fraction of C teachers at X = x,
we have (the conditioning on Z = 1 is left implicit throughout):

The ratio of the quantities:

E [Y |X = x] = α1 + (α0H − α1 ) φH (x)

E [g(Y1 )|C ] =

+ α0H̄ − α1 φC (x) + β0 x [φH (x) + φC (x)] ,

)

(

E [M |Z = 1] − E [M |Z = 0] =

Var [X ]

=

Cov[Y0 , X ]
Var [X ]

(π0 + π1 − 1)

=

E [g(Y )Λ|Z = 1] − E [g(Y )Λ|Z = 0]
(π0 + π1 − 1)

E [g(Y )Λ|Z = 1] − E [g(Y )Λ|Z = 0]
E [Λ|Z = 1] − E [Λ|Z = 0]

.

Now consider:

[

{

(
)
− α1 − α0H̄ δ̃H − β0 {1 − κ̃H } ,

[

,

implies:

E [g(Y )(1 − M)|Z = z ] = E g(Y ) 1 −

where κ̃H = E X 2 {φH (X ) + φC (X )} /Var(X ) ∈ (0, 1) and δ̃H =
Cov [{φH (X ) + φC (X )} , X ] /Var(X ). If δ̃H ≥ 0, sign reversion can
follow from arguments similar to those discussed above.

,

E [g(Y )M |Z = 1] − E [g(Y )M |Z = 0]

which, by re-arranging terms, implies:
Cov[Y , X ]

E [Λ|Z = 1] − E [Λ|Z = 0]

}
]
Λ
|Z = z ,
(π0 + π1 − 1)

and:

]

[
E [(1 − M)|Z = z ] = E 1 −

]
Λ
|Z = z .
(π0 + π1 − 1)

Since we can write:
A.2. Proofs of propositions
1−
Proposition 1
Assumption 5 implies:

+ (π0 + π1 − 1)E [M |Z = z ],
E [g(Y )W (1 − Q )|Z = z ] = (1 − π0 )E [g(Y )(1 − Q )|Z = z ]
+ (π0 + π1 − 1)E [g(Y )M |Z = z ].
These expressions can be solved for the unknowns (i.e., quantities
that depend on M) and substituted into Eqs. (1)–(4). Start from:
E [Λ|Z = z ]
(π0 + π1 − 1)

E [g(Y )M |Z = z ] =

=

Ψ ( π1 )
(π0 + π1 − 1)

E [g(Y0 )|C ] =

E [g(Y )Ψ (π1 )|Z = 1] − E [g(Y )Ψ (π1 )|Z = 0]
E [Ψ (π1 )|Z = 1] − E [Ψ (π1 )|Z = 0]

E [g(Y0 )|H ] =

E [g(Y )Ψ (π1 )|Z = 0]
E [Ψ (π1 )|Z = 0]

E [g(Y )Λ|Z = z ]
(π0 + π1 − 1)

E [Λ|Z = 1]

.

Proposition 2
Using the representations in the proof of Proposition 1 we can
write:

,

E [g(Y )Λ|Z = 1]

.

The same calculations also imply:

.

φD = E [M |Z = 1] =

E [Λ|Z = 1]
(π0 + π1 − 1)

It follows that:
E [g(Y1 )|D] =

,

it is:

E [W (1 − Q )|Z = z ] = (1 − π0 )E [1 − Q |Z = z ]

E [M |Z = z ] =

Λ
(π0 + π1 − 1)

.

1 − φH = E [M | Z = 0 ] =

,

E [Λ|Z = 0]
(π0 + π1 − 1)

.

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

Proposition 3
Under Assumptions 3–5 we have:

This defines a new lower bound on (5). Remember that the naive
lower bound is: g(0)φD + E [g(Y0 )|C ]φC + E [g(Y0 )|H ]φH . Therefore
the difference between the latter and the one obtained imposing
Assumption 8 is:

E [W |Q = 1, Z = 1] = (1 − π0 ) + (π0 + π1 − 1)

× E [M |Q = 1, Z = 1] = 1 − π0 .

E [g(Y0 )|C ](φC − φC − φH )

+ E [g(Y0 )|H ]φH = (E [g(Y0 )|H ] − E [g(Y0 )|C ])φH

Proposition 4
Assume that π1 is known. Inequality (15) implies:
E [g(Y0 )|D] ≤ E [g(Y0 )|C ]

which is always positive.

φC
φH
+ E [g(Y0 )|H ]
,
1 − φD
1 − φD

Appendix B. Supplementary data

which when substituted into (5) yields:
E [g(Y0 )] ≤ E [g(Y0 )|C ]

Supplementary material related to this article can be found
online at http://dx.doi.org/10.1016/j.jeconom.2017.06.015.

φC
φH
+ E [g(Y0 )|H ]
.
1 − φD
1 − φD

References

Inequality (16) implies:
E [g(Y0 )|D] ≤ E [g(Y0 )|H ]

(1 − φH )

φD

− E [g(Y0 )|C ]

φC
.
φD

Substituting into (5) we have:
E [g(Y0 )] ≤ E [g(Y0 )|H ](1 − φH ) + E [g(Y0 )|H ]φH = E [g(Y0 )|H ].
The two inequalities derived, taken jointly, imply:
E [g(Y0 )]

{
≤ min E [g(Y0 )|C ]

}
φC
φH
+ E [g(Y0 )|H ]
, E [g(Y0 )|H ] ,
1 − φD
1 − φD

which is the expression for the upper bound. The naive upper
bound can be written as:
E [g(Y1 )|D]φD + E [g(Y0 )|C ]φC + E [g(Y0 }|H ]φH .

(21)

If E [g(Y1 )|D] is larger than E [g(Y0 )|C ] and E [g(Y0 )|H ], as it is likely
to be the case in our application, the new upper bound is more
informative than the naive upper bound.
Inequality (16) acts on the lower bound by imposing the following restriction:
E [g(Y0 )] ≥ E [g(Y0 )|D]

φD
1 − φH

+ E [g(Y0 )|C ]

φC
1 − φH

.

The expression for the lower bound follows by bounding E [g(Y0 )|D]
from below:
E [g(Y0 )] ≥ g(0)

φD
1 − φH

361

+ E [g(Y0 )|C ]

φC
1 − φH

.

The naive lower bound can be written as:
g(0)φD + E [g(Y0 )|C ]φC + E [g(Y0 )|H ]φH ,
which can be smaller or larger than the bound in this proposition.
Proposition 5
Assume that π1 is known. The second inequality in Assumption 8 bounds from above the counterfactual term E [g(Y0 )|D]. If
substituted into (5), this yields:
E [g(Y0 )] ≤ E [g(Y0 )|C ](1 − φH ) + E [g(Y0 )|H ]φH ,
which is the expression for the upper bound. Notice that the
ranking across types implies that the difference between upper
bounds from Propositions 5 and 4 is equal to:

{E [g(Y0 )|H ] − E [g(Y0 )|C ]}

φH φD
1 − φD

≥ 0,

implying that the upper bound here is tighter than the upper bound
in Proposition 4.
As for the lower bound, the first inequality in Assumption 8
implies:
E [g(Y0 )] ≥ E [g(Y0 )|D]φD + E [g(Y0 )|C ](1 − φD )

≥ g(0)φD + E [g(Y0 )|C ](1 − φD ).

Abadie, A., 2002. Bootstrap tests for distributional treatment effects in instrumental
variable models. Rev. Econom. Stud. 97, 284–292.
Aigner, D., 1973. Regression with a binary independent variable subject to errors of
observation. J. Econometrics 1, 49–60.
Angrist, J.D., Battistin, E., Vuri, D., 2017. In a small moment: Class size and moral
hazard in the Italian Mezzogiorno. Amer. Econ. J. Appl. Econ. (forthcoming).
Angrist, J.D., Pathak, P., Walters, C.R., 2013. Explaining charter school effectiveness.
Amer. Econ. J. Appl. Econ. 5 (4), 1–27.
Arcones, M., Giné, E., 1992. On the bootstrap of M-estimators and other statistical
functionals. In: LePage, R., Billard, L. (Eds.), Exploring the Limits of Bootstrap.
Wiley, New York.
Aviv, R., 2014. Wrong Answer: In an era of high-stakes testing, a struggling school
made a shocking choice. The New Yorker, Annals of Education, July 21. Accessed
at: http://www.newyorker.com/magazine/2014/07/21/wrong-answer.
Battistin, E., De Nadai, M., Sianesi, B., 2014. Misreported schooling, multiple
measures and returns to educational qualifications. J. Econometrics 181 (2),
136–150.
Battistin, E., Meroni, E.C., 2013. Should We Increase Instruction Time in Low Achieving Schools? Evidence from Southern Italy, IZA Discussion Papers 7437. Institute
for the Study of Labor.
Battistin, E., Neri, L., 2015. Manipulation of Internally and Externally Assessed
Evaluations of Students: Evidence from the UK. Queen Mary University of
London, Unpublished mimeo.
Bertoni, M., Brunello, G., Rocco, L., 2013. When the cat is near, the mice won’t play:
The effect of external examiners in Italian schools. J. Publ. Econ. 104, 65–77.
Blinder, A., 2015. Atlanta Educators Convicted in School Cheating Scandal. New York
Times, April 1. Accessed at: https://www.nytimes.com/2015/04/02/us/verdictreached-in-atlanta-school-testing-trial.html.
Böhlmark, A., Lindahl, M., 2015. Independent schools and long-run educational
outcomes - evidence from Sweden’s large scale voucher reform. Economica
82 (327), 508–551.
Brunk, H.D., 1958. On the estimation of parameters restricted by inequalities. Ann.
Math. Stat. 29 (2), 437–454.
Carroll, R., Ruppert, D., Stefanski, L., Crainiceanu, C., 2006. Measurement Error in
Nonlinear Models, A Modern Perspective, second ed. Chapman & Hall.
Chen, X., Hong, X., Nekipelov, D., 2011. Nonlinear models of measurement errors.
J. Econ. Lit. 49, 901–937.
Dee, T.S., Dobbie, W., Jacob, B., Rockoff, J., 2016. The Causes and Consequences of
Test Score Manipulation: Evidence from the New York Regents Examinations.
NBER Working Paper, 22165.
Diamond, R., Persson, P., 2016. The Long-term Consequences of Teacher Discretion
in Grading of High-Stakes Tests. NBER Working Paper, 22207.
Falzetti, P., 2013. L’esperienza di restituzione dei dati al netto del cheating. Presentation at the Workshop ‘‘etodi di identificazione, analisi e trattamento del cheating’’, 8 February, available at: http://www.invalsi.it/invalsi/ri/sis/documenti/
022013/falzetti.pdff.
Frölich, M., 2007. Nonparametric IV estimation of local average treatment effects
with covariates. J. Econometrics 139 (1), 35–75.
Guiso, L., Sapienza, P., Zingales, L., 2004. The role of social capital in financial
development. Amer. Econ. Rev. 94 (3), 526–556.
Hahn, J., 1996. A note on bootstrapping generalized method of moments estimators.
Econometric Theory 12, 187–197.
Horowitz, J.L., Manski, C.F., 2000. Nonparametric analysis of randomized experiments with missing covariate and outcome data. J. Amer. Statist. Assoc. 95,
77–84.
Hu, Y., 2008. Identification and estimation of nonlinear models with misclassification error using instrumental variables: a general solution. J. Econometrics
144 (1), 27–61.
Ichino, A., Maggi, G., 2000. Work environment and individual background: explaining regional shirking differentials in a large italian firm. Quart. J. Econ. 115 (3),
933–959.

362

E. Battistin et al. / Journal of Econometrics 200 (2017) 344–362

INVALSI, 2010. Sistema Nazionale di Valutazione - A.S. 2009/2010, La Rilevazione
degli Apprendimenti. Technical Report.
INVALSI, 2013. Sistema Nazionale di Valutazione - A.S. 2012/2013, La Rilevazione
degli Apprendimenti. Technical Report.
Jacob, B., Levitt, S., 2003. Rotten apples: An investigation of the prevalence and
predictors of teacher cheating. Quart. J. Econ. 118 (3), 843–877.
Kreider, B., Pepper, J.V., 2011. Identification of expected outcomes in a data error
mixing model with multiplicative mean independence. J. Bus. Econ. Stat. 29 (1),
49–60.
Kreider, B., Pepper, J.V., Gundersen, C., Jolliffe, D., 2012. Identifying the effects of
SNAP (food stamps) on child health outcomes when participation is endogenous
and misreported. J. Amer. Statist. Assoc. 107 (499), 958–975.
Lewbel, A., 2007. Estimation of average treatment effects with misclassification.
Econometrica 2 (3), 537–551.
Mahajan, A., 2006. Identification and estimation of regression models with misclassification. Econometrica 74 (3), 631–665.

Nannicini, T., Stella, A., Tabellini, G., Troiano, U., 2013. Social capital and political
accountability. Amer. Econ. J. Econ. Policy 5, 222–250.
Nevo, A., Rosen, A.M., 2012. Identification with imperfect instruments. Rev. Econ.
Stat. 97(3), 659–671.
Nicoletti, C., Peracchi, F., Foliano, F., 2011. Estimating income poverty in the presence of missing data and measurement error. J. Bus. Econom. Statist. 29 (1),
61–72.
Quintano, C., Castellano, R., Longobardi, S., 2009. A fuzzy clustering approach to
improve the accuracy of Italian student data. An experimental procedure to
correct the impact of the outliers on assessment test scores. Statist. Appl. VII (2),
149–171.
Severson, K., (2011) Systematic Cheating Is Found in Atlanta’s School System.
New York Times, July 11. Accessed at: http://www.nytimes.com/2011/07/06/
education/06atlanta.html.
Vytlacil, E.J., 2002. Independence, monotonicity, and latent index models: An equivalence result. Econometrica 70 (1), 331–341.

