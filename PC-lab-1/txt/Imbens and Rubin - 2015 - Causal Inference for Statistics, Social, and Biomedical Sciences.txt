CAUSAL INFERENCE
for Statistics, Social, and Biomedical Sciences An Introduction
Most questions in social and biomedical sciences are causal in nature: what would happen to individuals, or to groups, if part of their environment were changed? In this groundbreaking text, two world-renowned experts present statistical methods for studying such questions.
This book starts with the notion of potential outcomes, each corresponding to the outcome that would be realized if a subject were exposed to a particular treatment or regime. In this approach, causal effects are comparisons of such potential outcomes. The fundamental problem of causal inference is that we can observe only one of the potential outcomes for a particular subject. The authors discuss how randomized experiments allow us to assess causal effects and then turn to observational studies. They lay out the assumptions needed for causal inference and describe the leading analysis methods, including matching, propensity-score methods, and instrumental variables. Many detailed applications are included, with special focus on practical aspects for the empirical researcher.
Guido W. Imbens is Applied Econometrics Professor and Professor of Economics at the Graduate School of Business at Stanford University. He has previoulsy held tenured positions at the University of California at Los Angeles, the University of California at Berkeley, and Harvard University. He is a Fellow of the Econometric Society and the American Academy of Arts and Sciences. He holds an honorary doctorate from the University of St. Gallen, Switzerland. Imbens has done extensive research in econometrics and statistics, specializing in causal inference. He has published widely in leading economics and statistics journals, including the American Economic Review, Econometrica, the Review of Economic Studies, the Journal of the American Statistical Association, the Annals of Statistics, Biometrika, and the Journal of the Royal Statistical Society, Series A.
Donald B. Rubin is John L. Loeb Professor of Statistics at Harvard University, where he has been professor since 1983 and Department chair for 13 of those years. He has been elected to be a Fellow/Member/Honorary Member of the Woodrow Wilson Society, the Guggenheim Memorial Foundation, the Alexander von Humboldt Foundation, the American Statistical Association, the Institute of Mathematical Statistics, the International Statistical Institute, the American Association for the Advancement of Science, the American Academy of Arts and Sciences, the European Association of Methodology, the British Academy, and the U.S. National Academy of Sciences. As of 2014, he has authored/coauthored nearly 400 publications (including ten books), has five joint patents, and for many years has been one of the most highly cited authors in the world, with currently over 150,000 citations (Google Scholar). He is also the recipient of honorary doctorates from Otto Friedrich University, Bamberg, Germany; the University of Ljubljana, Slovenia; and Universidad Santa To´mas, Bogota´, Colombia, and has been named an honorary professor at four universities.

Advance Praise for Causal Inference for Statistics, Social, and Biomedical Sciences
"This thorough and comprehensive book uses the `potential outcomes' approach to connect the breadth of theory of causal inference to the real-world analyses that are the foundation of evidence-based decision making in medicine, public policy, and many other fields. Imbens and Rubin provide unprecedented guidance for designing research on causal relationships, and for interpreting the results of that research appropriately."
­ Dr. Mark McClellan, Director of the Health Care Innovation and Value Initiative, the Brookings Institution
"Clarity of thinking about causality is of central importance in financial decision making. Imbens and Rubin provide a rigorous foundation allowing practitioners to learn from the pioneers in the field."
­ Dr Stephen Blyth, Managing Director, Head of Public Markets, Harvard Management Company
"A masterful account of the potential outcomes approach to causal inference from observational studies that Rubin has been developing since he pioneered it 40 years ago."
­ Adrian Raftery, Blumstein-Jordan Professor of Statistics and Sociology, University of Washington
"Correctly drawing causal inferences is critical in many important applications. Congratulations to Professors Imbens and Rubin, who have drawn on their decades of research in this area, along with the work of several others, to produce this impressive book covering concepts, theory, methods, and applications. I especially appreciate their clear exposition of conceptual issues, which are important to understand in the context of either a designed experiment or an observational study, and their use of real applications to motivate the methods described."
­ Nathaniel Schenker, Former President of the American Statistical Association

CAUSAL INFERENCE
for Statistics, Social, and Biomedical Sciences An Introduction
Guido W. Imbens
Stanford University
Donald B. Rubin
Harvard University

32 Avenue of the Americas, New York, NY 10013-2473, USA

Cambridge University Press is part of the University of Cambridge.
It furthers the University's mission by disseminating knowledge in the pursuit of education, learning, and research at the highest international levels of excellence.

www.cambridge.org Information on this title: www.cambridge.org/9780521885881

c Guido W. Imbens and Donald B. Rubin 2015

This publication is in copyright. Subject to statutory exception and to the provisions of relevant collective licensing agreements, no reproduction of any part may take place without the written permission of Cambridge University Press.

First published 2015

Printed in the United States of America

A catalog record for this publication is available from the British Library.

Library of Congress Cataloging in Publication Data

Imbens, Guido.

Causal inference for statistics, social, and biomedical sciences :

an introduction / Guido W. Imbens & Donald B. Rubin.

pages cm

1. Social sciences­Research. 2. Causation. 3. Inference. I. Rubin, Donald B.

H62.I537 2014

519.5 4­dc23

2014020988

II. Title.

ISBN 978-0-521-88588-1 Hardback

Cambridge University Press has no responsibility for the persistence or accuracy of URLs for external or third-party Internet Web sites referred to in this publication and does not guarantee that any content on such Web sites is, or will remain, accurate or appropriate.

To my parents, Annie Imbens-Fransen and Gerard Imbens, for all their support and encouragement over the years; to my children, Carleton, Annalise and Sylvia, who have provided so much joy in recent years; and to my wife and best friend, Susan Athey.
Guido W. Imbens
To my family, colleagues, and students Donald B. Rubin

Contents

Preface

page xvii

PART I INTRODUCTION

1 Causality: The Basic Framework

3

1.1 Introduction

3

1.2 Potential Outcomes

3

1.3 Definition of Causal Effects

5

1.4 Causal Effects in Common Usage

7

1.5 Learning about Causal Effects: Multiple Units

8

1.6 The Stable Unit Treatment Value Assumption

9

1.7 The Assignment Mechanism: An Introduction

13

1.8 Attributes, Pre-Treatment Variables, or Covariates

15

1.9 Potential Outcomes and Lord's Paradox

16

1.10 Causal Estimands

18

1.11 Structure of the Book

20

1.12 Samples, Populations, and Super-Populations

20

1.13 Conclusion

21

Notes

21

2 A Brief History of the Potential Outcomes Approach to

Causal Inference

23

2.1 Introduction

23

2.2 Potential Outcomes and the Assignment Mechanism

before Neyman

24

2.3 Neyman's (1923) Potential Outcome Notation in Randomized

Experiments

25

2.4 Earlier Hints for Physical Randomizing

26

2.5 Fisher's (1925) Proposal to Randomize Treatments to Units

26

2.6 The Observed Outcome Notation in Observational Studies for

Causal Effects

27

2.7 Early Uses of Potential Outcomes in Observational Studies in

Social Sciences

28

vii

viii
2.8 Potential Outcomes and the Assignment Mechanism in Observational Studies: Rubin (1974) Notes
3 A Classification of Assignment Mechanisms 3.1 Introduction 3.2 Notation 3.3 Assignment Probabilities 3.4 Restrictions on the Assignment Mechanism 3.5 Assignment Mechanisms and Super-Populations 3.6 Randomized Experiments 3.7 Observational Studies: Regular Assignment Mechanisms 3.8 Observational Studies: Irregular Assignment Mechanisms 3.9 Conclusion Notes

Contents
29 30
31 31 33 34 37 39 40 41 42 43 43

PART II CLASSICAL RANDOMIZED EXPERIMENTS

4 A Taxonomy of Classical Randomized Experiments

47

4.1 Introduction

47

4.2 Notation

48

4.3 Bernoulli Trials

48

4.4 Completely Randomized Experiments

50

4.5 Stratified Randomized Experiments

51

4.6 Paired Randomized Experiments

52

4.7 Discussion

53

4.8 Conclusion

55

Notes

56

5 Fisher's Exact P-Values for Completely Randomized Experiments

57

5.1 Introduction

57

5.2 The Paul et al. Honey Experiment Data

59

5.3 A Simple Example with Six Units

59

5.4 The Choice of Null Hypothesis

63

5.5 The Choice of Statistic

64

5.6 A Small Simulation Study

72

5.7 Interval Estimates Based on Fisher P-Value Calculations

74

5.8 Computation of P-Values

75

5.9 Fisher Exact P-Values with Covariates

78

5.10 Fisher Exact P-Values for the Honey Data

80

5.11 Conclusion

81

Notes

81

6 Neyman's Repeated Sampling Approach to Completely

Randomized Experiments

83

6.1 Introduction

83

6.2 The Duflo-Hanna-Ryan Teacher-Incentive Experiment Data

84

6.3 Unbiased Estimation of the Average Treatment Effect

85

Contents

ix

6.4 The Sampling Variance of the Neyman Estimator

87

6.5 Estimating the Sampling Variance

92

6.6 Confidence Intervals and Testing

95

6.7 Inference for Population Average Treatment Effects

98

6.8 Neyman's Approach with Covariates

101

6.9 Results for the Duflo-Hanna-Ryan Teacher-Incentive Data

102

6.10 Conclusion

104

Notes

104

Appendix A Sampling Variance Calculations

105

Appendix B Random Sampling from a Super-Population

109

7 Regression Methods for Completely Randomized Experiments

113

7.1 Introduction

113

7.2 The LRC-CPPT Cholesterol Data

115

7.3 The Super-Population Average Treatment Effects

116

7.4 Linear Regression with No Covariates

118

7.5 Linear Regression with Additional Covariates

122

7.6 Linear Regression with Covariates and Interactions

125

7.7 Transformations of the Outcome Variable

127

7.8 The Limits on Increases in Precision Due to Covariates

128

7.9 Testing for the Presence of Treatment Effects

129

7.10 Estimates for LRC-CPPT Cholesterol Data

131

7.11 Conclusion

133

Notes

134

Appendix

135

8 Model-Based Inference for Completely Randomized Experiments

141

8.1 Introduction

141

8.2 The Lalonde NSW Experimental Job-Training Data

144

8.3 A Simple Example: Naive and More Sophisticated Approaches

to Imputation

146

8.4 Bayesian Model-Based Imputation in the Absence of Covariates 150

8.5 Simulation Methods in the Model-Based Approach

163

8.6 Dependence between Potential Outcomes

165

8.7 Model-Based Imputation with Covariates

169

8.8 Super-Population Average Treatment Effects

171

8.9 A Frequentist Perspective

172

8.10 Model-Based Estimates of the Effect of the NSW Program

174

8.11 Conclusion

177

Notes

177

Appendix A Posterior Distributions for Normal Models

178

Appendix B Analytic Derivations with Known Covariance

Matrix

181

9 Stratified Randomized Experiments

187

9.1 Introduction

187

9.2 The Tennesee Project Star Data

188

x

Contents

9.3 The Structure of Stratified Randomized Experiments

189

9.4 Fisher's Exact P-Values in Stratified Randomized Experiments

192

9.5 The Analysis of Stratified Randomized Experiments from

Neyman's Repeated Sampling Perspective

201

9.6 Regression Analysis of Stratified Randomized Experiments

205

9.7 Model-Based Analysis of Stratified Randomized Experiments

207

9.8 Design Issues: Stratified versus Completely Randomized

Experiments

211

9.9 Conclusion

212

Notes

212

Appendix A: Student-Level Analyses

213

Appendix B: Proofs of Theorems 9.1 and 9.2

214

10 Pairwise Randomized Experiments

219

10.1 Introduction

219

10.2 The Children's Television Workshop Experiment Data

220

10.3 Pairwise Randomized Experiments

220

10.4 Fisher's Exact P-Values in Pairwise Randomized Experiments

222

10.5 The Analysis of Pairwise Randomized Experiments from

Neyman's Repeated Sampling Perspective

224

10.6 Regression-Based Analysis of Pairwise Randomized

Experiments

229

10.7 Model-Based Analysis of Pairwise Randomized Experiments

231

10.8 Conclusion

233

Notes

234

Appendix: Proofs

234

11 Case Study: An Experimental Evaluation of a Labor Market

Program

240

11.1 Introduction

240

11.2 The San Diego SWIM Program Data

240

11.3 Fisher's Exact P-Values

242

11.4 Neyman's Repeated Sampling-Based Point Estimates and

Large-Sample Confidence Intervals

245

11.5 Regression-Based Estimates

247

11.6 Model-Based Point Estimates

250

11.7 Conclusion

253

Notes

253

PART III REGULAR ASSIGNMENT MECHANISMS: DESIGN

12 Unconfounded Treatment Assignment

257

12.1 Introduction

257

12.2 Regular Assignment Mechanisms

258

12.3 Balancing Scores and the Propensity Score

266

12.4 Estimation and Inference

268

12.5 Design Phase

276

Contents

xi

12.6 Assessing Unconfoundedness

278

12.7 Conclusion

279

Notes

279

13 Estimating the Propensity Score

281

13.1 Introduction

281

13.2 The Reinisch et al. Barbituate Exposure Data

284

13.3 Selecting the Covariates and Interactions

285

13.4 Choosing the Specification of the Propensity Score for

the Barbituate Data

288

13.5 Constructing Propensity-Score Strata

290

13.6 Choosing Strata for the Barbituate Data

294

13.7 Assessing Balance Conditional on the Estimated

Propensity Score

296

13.8 Assessing Covariate Balance for the Barbituate Data

300

13.9 Conclusion

306

Notes

306

Appendix: Logistic Regression

307

14 Assessing Overlap in Covariate Distributions

309

14.1 Introduction

309

14.2 Assessing Balance in Univariate Distributions

310

14.3 Direct Assessment of Balance in Multivariate Distributions

313

14.4 Assessing Balance in Multivariate Distributions Using the

Propensity Score

314

14.5 Assessing the Ability to Adjust for Differences in Covariates

by Treatment Status

317

14.6 Assessing Balance: Four Illustrations

318

14.7 Sensitivity of Regression Estimates to Lack of Overlap

332

14.8 Conclusion

336

Notes

336

15 Matching to Improve Balance in Covariate Distributions

337

15.1 Introduction

337

15.2 The Reinisch et al. Barbituate Exposure Data

339

15.3 Selecting a Subsample of Controls through Matching to

Improve Balance

339

15.4 An Illustration of Propensity Score Matching with Six

Observations

344

15.5 Theoretical Properties of Matching Procedures

345

15.6 Creating Matched Samples for the Barbituate Data

349

15.7 Conclusion

358

Notes

358

16 Trimming to Improve Balance in Covariate Distributions

359

16.1 Introduction

359

16.2 The Right Heart Catheterization Data

360

16.3 An Example with a Single Binary Covariate

362

xii
16.4 Selecting a Subsample Based on the Propensity Score 16.5 The Optimal Subsample for the Right Heart
Catheterization Data 16.6 Conclusion
Notes

Contents
366
368 373 374

PART I V RE GUL AR ASSI GNM E NT M E CHANI SM S: ANALYSI S

17 Subclassification on the Propensity Score

377

17.1 Introduction

377

17.2 The Imbens-Rubin-Sacerdote Lottery Data

378

17.3 Subclassification on the Propensity Score and Bias Reduction

380

17.4 Subclassification and the Lottery Data

385

17.5 Estimation Based on Subclassification with Additional

Bias Reduction

386

17.6 Neymanian Inference

388

17.7 Average Treatment Effects for the Lottery Data

390

17.8 Weighting Estimators and Subclassification

392

17.9 Conclusion

399

Notes

399

18 Matching Estimators

401

18.1 Introduction

401

18.2 The Card-Krueger New Jersey and Pennsylvania Minimum

Wage Data

404

18.3 Exact Matching without Replacement

405

18.4 Inexact Matching without Replacement

407

18.5 Distance Measures

410

18.6 Matching and the Card-Krueger Data

412

18.7 The Bias of Matching Estimators

415

18.8 Bias-Corrected Matching Estimators

416

18.9 Matching with Replacement

424

18.10 The Number of Matches

425

18.11 Matching Estimators for the Average Treatment Effect for the

Controls and for the Full Sample

427

18.12 Matching Estimates of the Effect of the Minimum Wage

Increase

428

18.13 Conclusion

430

Notes

431

19 A General Method for Estimating Sampling Variances for

Standard Estimators for Average Causal Effects

433

19.1 Introduction

433

19.2 The Imbens-Rubin-Sacerdote Lottery Data

435

19.3 Estimands

436

Contents

xiii

19.4 The Common Structure of Standard Estimators for Average

Treatment Effects

441

19.5 A General Formula for the Conditional Sampling Variance

445

19.6 A Simple Estimator for the Unit-Level Conditional Sampling

Variance

446

19.7 An Estimator for the Sampling Variance of ^ Conditional on

Covariates

452

19.8 An Estimator for the Sampling Variance for the Estimator for the

Average Effect for the Treated

452

19.9 An Estimator for the Sampling Variance for the Population

Average Treatment Effect

454

19.10 Alternative Estimators for the Sampling Variance

456

19.11 Conclusion

460

Notes

460

20 Inference for General Causal Estimands

461

20.1 Introduction

461

20.2 The Lalonde NSW Observational Job-Training Data

462

20.3 Causal Estimands

465

20.4 A Model for the Conditional Potential Outcome

Distributions

468

20.5 Implementation

472

20.6 Results for the Lalonde Data

473

20.7 Conclusion

474

Notes

474

PART V REGULAR ASSIGNMENT MECHANISMS: SUPPLEMENTARY

ANALYSE S

21 Assessing Unconfoundedness

479

21.1 Introduction

479

21.2 Setup

482

21.3 Estimating Effects on Pseudo-Outcomes

482

21.4 Estimating Effects of Pseudo-Treatments

485

21.5 Robustness to the Set of Pre-Treatment Variables

487

21.6 The Imbens-Rubin-Sacerdote Lottery Data

490

21.7 Conclusion

495

Notes

495

22 Sensitivity Analysis and Bounds

496

22.1 Introduction

496

22.2 The Imbens-Rubin-Sacerdote Lottery Data

497

22.3 Bounds

497

22.4 Binary Outcomes: The Rosenbaum-Rubin

Sensitivity Analysis

500

xiv
22.5 Binary Outcomes: The Rosenbaum Sensitivity Analysis for P-Values
22.6 Conclusion Notes

Contents
506 509 509

PART VI REGULAR ASSIGNMENT MECHANISMS WITH

NONCOM PL I ANCE: ANALYSI S

23 Instrumental Variables Analysis of Randomized Experiments with

One-Sided Noncompliance

513

23.1 Introduction

513

23.2 The Sommer-Zeger Vitamin A Supplement Data

516

23.3 Setup

517

23.4 Intention-to-Treat Effects

519

23.5 Compliance Status

522

23.6 Instrumental Variables

526

23.7 Moment-Based Instrumental Variables Estimators

530

23.8 Linear Models and Instrumental Variables

531

23.9 Naive Analyses: "As-Treated," "Per Protocol,"

and Unconfoundedness

535

23.10 Conclusion

539

Notes

539

Appendix

541

24 Instrumental Variables Analysis of Randomized Experiments

with Two-Sided Noncompliance

542

24.1 Introduction

542

24.2 The Angrist Draft Lottery Data

543

24.3 Compliance Status

544

24.4 Intention-to-Treat Effects

546

24.5 Instrumental Variables

548

24.6 Traditional Econometric Methods for Instrumental

Variables

556

24.7 Conclusion

559

Notes

559

25 Model-Based Analysis in Instrumental Variable Settings:

Randomized Experiments with Two-Sided Noncompliance

560

25.1 Introduction

560

25.2 The McDonald-Hiu-Tierney Influenza Vaccination Data

561

25.3 Covariates

567

25.4 Model-Based Instrumental Variables Analyses for Randomized

Experiments with Two-Sided Noncompliance

568

25.5 Simulation Methods for Obtaining Draws from the Posterior

Distribution of the Estimand Given the Data

574

25.6 Models for the Influenza Vaccination Data

578

Contents

xv

25.7 Results for the Influenza Vaccination Data

581

25.8 Conclusion

584

Notes

584

PART VII CONCLUSION

26 Conclusions and Extensions

589

Notes

590

References

591

Author Index

605

Subject Index

609

Preface
In many applications of statistics, a large proportion of the questions of interest are fundamentally questions of causality rather than simply questions of description or association. For example, a medical researcher may wish to find out whether a new drug is effective against a disease. An economist may be interested in uncovering the effects of a job-training program on an individual's employment prospects, or the effects of a new tax or regulation on economic activity. A sociologist may be concerned about the effects of divorce on children's subsequent education. In this text we discuss statistical methods for studying such questions.
The book arose out of a conversation we had in 1992 while we were both on the faculty at Harvard University. We found that although we were both interested in questions of causality, we had difficulty communicating our ideas because, coming from different disciplines, we were used to different terminology and conventions. However, the excitement about the ideas in these different areas motivated us to capitalize on these difficulties, which led to a long collaboration, including research projects, graduate and undergraduate teaching, and thesis advising. The book is a reflection of this collaboration.
The book is based directly on many semester and quarter-length courses we, initially jointly, and later separately, taught for a number of years, starting in 1995 at Harvard University, followed by the University of California at Los Angeles, the University of California at Berkeley, and Stanford University, to audiences of graduate and undergraduate students from statistics, economics, business, and other disciplines using applied statistics. In addition we have taught shorter versions of such courses in Barcelona, Beijing, Berlin, Bern, Geneva, Maastricht, Mexico City, Miami, Montevideo, Santiago, Stockholm, Uppsala, Wuppertal, Zurich, and at the World Bank as well as other associations and agencies.
There are a number of key features of the approach taken in this book. First of all, the perspective we take is that all causal questions are tied to specific interventions or treatments. Second, causal questions are viewed as comparisons of potential outcomes, with each potential outcome corresponding to a level of the treatment. Each of these potential outcomes could have been observed had the treatment taken on the corresponding level. After the treatment has taken on a specific level, only the potential
xvii

xviii

Preface

outcome corresponding to that level is realized and can be actually observed. Causal effects involve the comparison of the outcome actually observed with other potential outcomes that could have been observed had the treatment taken on a different level, but that are not, in fact, observed. Causal inference is therefore fundamentally a missing data problem and, as in all missing data problems, a key role is played by the mechanism that determines which data values are observed and which are missing. In causal inference, this mechanism is referred to as the assignment mechanism, the mechanism that determines levels of the treatment taken by the units studied.
The book is organized in seven parts. In the first part we set out the basic philosophy underlying our approach to causal inference and describe the potential outcomes framework. The next three parts of the book are distinguished by the assumptions maintained about the assignment mechanism. In Part II we assume that the assignment mechanism corresponds to a classical randomized experiment.
In Part III we assume that the assignment mechanism is "regular" in a well-defined sense, which generalizes randomized experiments. In this part of the book we discuss what we call the "design" phase of an observational study, which we view as extremely important for credible conclusions. In the next part, Part IV, we discuss data analysis for studies with regular assignment mechanisms. Here we consider matching and subclassification procedures, as well as model-based and weighting methods.
In Part V we relax this regularity assumption and discuss more general assignment mechanisms. First we assess the key assumption required for regularity, unconfoundedness. We also explore in this part of the text sensitivity analyses where we relax some of the key features of a regular assignment mechanism.
Next, in Part VI of the text, we consider settings where the assignment mechanism is regular, but compliance with the assignment is imperfect. As a result, the probability of receipt of treatment may depend on both observed and unobserved characteristics and outcomes of the units. To address these complications, we turn to instrumental variables methods. Part VII of the book concludes.
As with all books, ours has limitations. Foremost is our focus on binary treatments. Although many of the results can easily be extended to multi-valued treatments, we focus on the binary treatment case because many critical conceptual issues arise already in that setting. Second, throughout most of the book we make the "stability" assumption that treatments applied to one unit do not affect outcomes for other units and that there are no unrepresented versions of the treatments. There is a growing literature on interactions through networks and peer effects that builds on the notions of causality discussed in this book. Finally, although we designed the book to be theoretically tight and principled, we focus on practical rather than mathematical results, including detailed applications with real data sets, consistent with our target audience of researchers in applied fields.

ACKNOWLEDGMENTS
We are deeply indebted to many collaborators, colleagues, and students from whom we have learned much about the topics discussed in this book over the years. These include Alberto Abadie, Nikola Andric, Joshua Angrist, Susan Athey, Thomas Barrios, David Card, Matias Cattaneo, Gary Chamberlain, Raj Chetty, Rajeev Dehejia, Mike Dickstein,

Preface

xix

Peng Ding, David Drukker, Valeria Espinosa, Avi Feller, Sergio Firpo, Andrew Gelman, Paul Gift, Paul Goldsmith-Pinkham, Bryan Graham, Roee Gutman, Jane Herr, Kei Hirano, Joe Hotz, Wilbert van der Klaauw, Jacob Klerman, Alan Krueger, Tony Lancaster, Joseph Lee, Victoria Liublinska, Chuck Manski, Eric Maskin, Fabrizia Mealli, Kari Lock Morgan, Eduardo Morales, Julie Mortimer, Eleanor Murray, Whitney Newey, Cassandra Wolos Pattanayak, Jack Porter, Geert Ridder, Paul Rosenbaum, Bruce Sacerdote, Hal Stern, Elizabeth Stuart, Neal Thomas, Sadek Wahba, David Watson, Jeff Wooldridge, and Alan Zaslavsky.
We are grateful for stimulating discussions over the years with David Freedman, Sander Greenland, James Heckman, Nick Jewell, Mark van der Laan, Judea Pearl, Jamie Robins, Jasjeet Sekhon, Jeffrey Smith, and Edward Vytlacil.
We are also grateful to Joshua Angrist, David Card, Raj Chetty, Rajeev Dehejia, Esther Duflo, Brad Efron, Alan Krueger, Robert Lalonde, June Reinisch, Bruce Sacerdote, Sadek Wahba, and Scott Zeger for making their data available.

PART I
Introduction

CHAPTER 1
Causality: The Basic Framework
1.1 INTRODUCTION
In this introductory chapter we set out our basic framework for causal inference. We discuss three key notions underlying our approach. The first notion is that of potential outcomes, each corresponding to one of the levels of a treatment or manipulation, following the dictum "no causation without manipulation" (Rubin, 1975, p. 238). Each of these potential outcomes is a priori observable, in the sense that it could be observed if the unit were to receive the corresponding treatment level. But, a posteriori, that is, once a treatment is applied, at most one potential outcome can be observed. Second, we discuss the necessity, when drawing causal inferences, of observing multiple units, and the utility of the related stability assumption, which we use throughout most of this book to exploit the presence of multiple units. Finally, we discuss the central role of the assignment mechanism, which is crucial for inferring causal effects, and which serves as the organizing principle for this book.
1.2 POTENTIAL OUTCOMES
In everyday life, causal language is widely used in an informal way. One might say: "My headache went away because I took an aspirin," or "She got a good job last year because she went to college," or "She has long hair because she is a girl." Such comments are typically informed by observations on past exposures, for example, of headache outcomes after taking aspirin or not, or of characteristics of jobs of people with or without college educations, or the typical hair length of boys and girls. As such, these observations generally involve informal statistical analyses, drawing conclusions from associations between measurements of different quantities that vary from individual to individual, commonly called variables or random variables ­ language apparently first used by Yule (1897). Nevertheless, statistical theory has been relatively silent on questions of causality. Many, especially older, textbooks avoid any mention of the term other than in settings of randomized experiments. Some mention it mainly to stress that correlation or association is not the same as causation, and some even caution their readers to avoid
3

4

Causality: The Basic Framework

using causal language in statistics. Nevertheless, for many users of statistical methods, causal statements are exactly what they seek.
The fundamental notion underlying our approach is that causality is tied to an action (or manipulation, treatment, or intervention), applied to a unit. A unit here can be a physical object, a firm, an individual person, or collection of objects or persons, such as a classroom or a market, at a particular point in time. For our purposes, the same physical object or person at a different time is a different unit. From this perspective, a causal statement presumes that, although a unit was (at a particular point in time) subject to, or exposed to, a particular action, treatment, or regime, the same unit could have been exposed to an alternative action, treatment, or regime (at the same point in time). For instance, when deciding to take an aspirin to relieve your headache, you could also have choosen not to take the aspirin, or you could have chosen to take an alternative medicine. In this framework, articulating with precision the nature and timing of the action sometimes requires a certain amount of imagination. For example, if we define race solely in terms of skin color, the action might be a pill that alters only skin color. Such a pill may not currently exist (but, then, neither did surgical procedures for heart transplants hundreds of years ago), but we can still imagine such an action.
This book primarily considers settings with two actions, although many of the extensions to multi-valued treatments are conceptually straightforward. Often one of these actions corresponds to a more active treatment (e.g., taking an aspirin) in contrast to a more passive action (e.g., not taking the aspirin). In such cases we sometimes refer to the first action as the active treatment as opposed to the control treatment, but these are merely labels and formally the two treatments are viewed symmetrically. In some cases, when it is clear from the context, we refer to the more active treatment simply as the "treatment" and the other treatment as the "control."
Given a unit and a set of actions, we associate each action-unit pair with a potential outcome. We refer to these outcomes as potential outcomes because only one will ultimately be realized and therefore possibly observed: the potential outcome corresponding to the action actually taken. Ex post, the other potential outcomes cannot be observed because the corresponding actions that would lead to them being realized were not taken. The causal effect of one action or treatment relative to another involves the comparison of these potential outcomes, one realized (and perhaps, though not necessarily, observed), and the others not realized and therefore not observable. Any treatment must occur temporally before the observation of any associated potential outcome is possible.
Although the preceding argument may appear obvious, its force is revealed by its ability to clarify otherwise murky concepts, as can be demonstrated by considering the three examples of informal "because" statements presented in the first paragraph of this section. In the first example, it is clear what the action is: I took an aspirin, but at the time that I took the aspirin, I could have followed the alternate course of not taking an aspirin. In that case, a different outcome might have resulted, and the "because" statement is causal in the perspective taken in this book as it reflects the comparison of those two potential outcomes. In the second example, it is less clear what the treatment and its alternative are: she went to college, and at the point in time when she decided to go to college, she could have decided not to go to college. In that case, she might have had a different job a year ago, and the implied causal statement compares the quality of the job she actually had then to the quality of the job she would have had a year ago, had she not

1.3 Definition of Causal Effects

5

gone to college. However, in this example, the alternative treatment is somewhat murky: had she not enrolled in college, would she have enrolled in the military, or would she have joined an artist's colony? As a result, the potential outcome under the alternative action, the job obtained a year ago without enrolling in college, is not as well defined as in the first example.
In the third example, the alternative action is not at all clear. The informal statement is "she has long hair because she is a girl." In some sense the implicit treatment is being a girl, and the implicit alternative is being a boy, but there is no action articulated that would have made her a boy and allowed us to observe the alternate potential outcome of hair length for this person as a boy. We could clarify the causal effect by defining such an action in terms of surgical procedures, or hormone treatments, all with various ages at which the action to be taken is specified, but clearly the causal effect is likely to depend on the particular alternative action and timing being specified. As stated, however, there is no clear action described that would have allowed us to observe the unit exposed to the alternative treatment. Hence, in our approach, this "because" statement is ill-defined as a causal statement.
It may seem restrictive to exclude from consideration such causal questions. However, the reason to do so in our framework is that without further explication of the intervention being considered, the causal question is not well defined. One can make many of these questions well posed in our framework by explicitly articulating the alternative intervention. For example, if the question concerns the causal effect of "race," then an ethnicity change on a curriculum vitae (or its perception, as in Bertrand and Mullainathan, 2004) defines one causal effect being contemplated, whereas if the question concerns a futuristic "at conception change of chromosomes determining skin color," there is a different causal effect being contemplated. With either manipulation, the explicit description of the intervention makes the question a plausible causal one in our framework.
A closely related way of interpreting the qualitative difference between the three "causal" statements is to consider, after application of the actual treatment, the counterfactual value of the potential outcome corresponding to the treatment not applied. In the first statement, the treatment applied is "aspirin taken," and the counterfactual potential outcome is the state of your headache under "aspirin not taken"; here it appears unambiguous to consider the counterfactual outcome. In the second example, the counterfactual outcome is her job a year ago had she decided not to go to college, which is not as well defined. In the last example, the counterfactual outcome ­ the person's hair length if she were a boy rather than a girl (note the lack of an action in this statement) ­ is not at all well defined, and therefore the causal statement is correspondingly poorly defined. In practice, the distinction between well and poorly defined causal statements is one of degree. The important point is, however, that causal statements become more clearly defined by more precisely articulating the intervention that would have made the alternative potential outcome the realized one.

1.3 DEFINITION OF CAUSAL EFFECTS
Let us consider the case of a single unit, I, at a particular point in time, contemplating whether or not to take an aspirin for my headache. That is, there are two treatment levels,

6

Causality: The Basic Framework

Table 1.1. Example of Potential Outcomes and Causal Effect with One Unit

Unit

Potential Outcomes

Causal Effect

Y (Aspirin)

Y(No Aspirin)

You

No Headache

Headache

Improvement due to Aspirin

taking an aspirin, and not taking an aspirin. If I take the aspirin, my headache may be gone, or it may remain, say, an hour later; we denote this outcome, which can be either "Headache" or "No Headache," by Y(Aspirin). (We could use a finer measure of the status of my headache an hour later, for example, rating my headache on a ten-point scale, but that does not alter the fundamental issues involved here.) Similarly, if I do not take the aspirin, my headache may remain an hour later, or it may not; we denote this potential outcome by Y(No Aspirin), which also can be either "Headache," or "No Headache." There are therefore two potential outcomes, Y(Aspirin) and Y(No Aspirin), one for each level of the treatment. The causal effect of the treatment involves the comparison of these two potential outcomes.
Because in this example each potential outcome can take on only two values, the unitlevel causal effect ­ the comparison of these two outcomes for the same unit ­ involves one of four (two by two) possibilities:
1. Headache gone only with aspirin: Y(Aspirin) = No Headache, Y(No Aspirin) = Headache
2. No effect of aspirin, with a headache in both cases: Y(Aspirin) = Headache, Y(No Aspirin) = Headache
3. No effect of aspirin, with the headache gone in both cases: Y(Aspirin) = No Headache, Y(No Aspirin) = No Headache
4. Headache gone only without aspirin: Y(Aspirin) = Headache, Y(No Aspirin) = No Headache
Table 1.1 illustrates this situation assuming the values Y(Aspirin) = No Headache, Y(No Aspirin) = Headache. There is a zero causal effect of taking aspirin in the second and third possibilities. In the other two cases the aspirin has a causal effect, making the headache go away in one case and not allowing it to go away in the other.
There are two important aspects of this definition of a causal effect. First, the definition of the causal effect depends on the potential outcomes, but it does not depend on which outcome is actually observed. Specifically, whether I take an aspirin (and am therefore unable to observe the state of my headache with no aspirin) or do not take an aspirin (and am thus unable to observe the outcome with an aspirin) does not affect the definition of the causal effect. Second, the causal effect is the comparison of potential outcomes, for the same unit, at the same moment in time post-treatment. In particular, the causal effect is not defined in terms of comparisons of outcomes at different times, as in a before-and-after comparison of my headache before and after deciding to take or not to take the aspirin. "The fundamental problem of causal inference" (Holland, 1986, p. 947) is therefore the problem that at most one of the potential outcomes can be realized and thus observed. If the action you take is Aspirin, you observe Y(Aspirin) and

1.4 Causal Effects in Common Usage

7

Table 1.2. Example of Potential Outcomes, Causal Effect, Actual Treatment, and Observed Outcome with One Unit

Unit Not Observable

Known

Potential Outcomes

Causal Effect

Y(Aspirin) Y(No Aspirin)

Actual Observed Treatment Outcome

You No Headache Headache

Improvement due to Aspirin Aspirin No Headache

will never know the value of Y(No Aspirin) because you cannot go back in time. Similarly, if your action is No Aspirin, you observe Y(No Aspirin) but cannot know the value of Y(Aspirin). Likewise, for the college example, we know the outcome given college attendance because the woman actually went to college, but we will never know what job she would have had if she had not gone to college. In general, therefore, even though the unit-level causal effect (the comparison of the two potential outcomes) may be well defined, by definition we cannot learn its value from just the single realized potential outcome. Table 1.2 illustrates this concept for the aspirin example, assuming the action taken was that you took the aspirin.
For the estimation of causal effects, as opposed to the definition of causal effects, we will need to make different comparisons from the comparisons made for their definitions. For estimation and inference, we need to compare observed outcomes, that is, observed realizations of potential outcomes, and because there is only one realized potential outcome per unit, we will need to consider multiple units. For example, a before-and-after comparison of the same physical object involves distinct units in our framework, and also the comparison of two different physical objects at the same time involves distinct units. Such comparisons are critical for estimating causal effects, but they do not define causal effects in our approach. For estimation it will also be critical to know about, or make assumptions about, the reason why certain potential outcomes were realized and not others. That is, we will need to think about the assignment mechanism, which we introduce in Section 1.7. However, we do not need to think about the assignment mechanism for defining causal effects: we merely need to do the thought experiment of the manipulations leading to the definition of the potential outcomes.

1.4 CAUSAL EFFECTS IN COMMON USAGE
The definition of a causal effect given in the previous section may appear a bit formal, and the discussion a bit ponderous, but the presentation is simply intended to capture the way we use the concept in everyday life. Also, implicitly this definition of causal effect as the comparison of potential outcomes is frequently used in contemporary culture, for example, in the movies. Many of us have seen the movie It's a Wonderful Life, with Jimmy Stewart as George Bailey. In this movie George Bailey becomes very depressed and states that the world would have been a better place had he never been born. At the appropriate moment an angel appears and shows him what the world would have been like had he not been born. The actual world is the real, observed outcome, but the

8

Causality: The Basic Framework

angel shows George the other potential outcome, had George not been born. Not only are there obvious consequences, like his own children not existing, but there are many other untoward events. For example, his younger brother, who was in actual life a World War II hero, in the counterfactual world drowns in a skating accident at age eight because George was not there to save him. In the counterfactual world a pharmacist fills in a wrong prescription and is convicted of manslaughter because George was not there to catch the error as he did in the actual world. The causal effect of George not being born is the comparison of the entire stream of events in the actual world with George in it, with the entire stream of events in the counterfactual world without George in it. In reality we would never be able to see both worlds, but in the movie George gets to observe both.
Another interesting comparison is to the "but-for" concept in legal settings. Suppose someone committed an action that is harmful, and a second person suffered damages. From a legal perspective, the damage that the second person is entitled to collect is the difference between the economic position of the plaintiff had the harmful event not occurred (the economic position "but-for" the harmful action) and the actual economic position of the plaintiff. Clearly, this is a comparison of the potential outcome that was not realized and the realized potential outcome, this difference being the causal effect of the harmful action.

1.5 LEARNING ABOUT CAUSAL EFFECTS: MULTIPLE UNITS
Although the definition of causal effects does not require more than one unit, learning about causal effects typically requires multiple units. Because with a single unit we can at most observe a single potential outcome, we must rely on multiple units to make causal inferences. More specifically, we must observe multiple units, some exposed to the active treatment, some exposed to the alternative (control) treatment.
One option is to observe the same physical object under different treatment levels at different points in time. This type of data set is a common source for personal, informal assessments of causal effects. For example, I might feel confident that an aspirin is going to relieve my headache within an hour, based on previous experiences, including episodes when my headache went away when I took an aspirin, and episodes when my headache did not go away when I did not take aspirin. In that situation, my views are shaped by comparisons of multiple units: myself at different times, taking and not taking aspirin. There is sometimes a tendency to view the same physical object at different times as the same unit. We view this as a fundamental mistake. The same physical unit, "myself at different times," is not the same unit in our approach to causality. Time matters for many reasons. For example, I may become more or less sensitive to aspirin, evenings may differ from mornings, or the initial intensity of my headache may affect the result. It is often reasonable to assume that time makes little difference for inanimate objects ­ we may feel confident, from past experience, that turning on a faucet will cause water to flow from that tap ­ but this assumption is typically less reasonable with human subjects, and it is never correct to confuse assumptions (e.g., about similarities between different units), with definitions (e.g., of a unit, or of a causal effect).
As an alternative to observing the same physical object repeatedly, one might observe different physical objects at approximately the same time. This situation is another common source for informal assessments of causal effects. For example, if both you

1.6 The Stable Unit Treatment Value Assumption

9

and I have headaches, but only one of us takes an aspirin, we may attempt to infer the

efficacy of taking aspirin by comparing our subsequent headaches. It is more obvious

here that "you" and "I" at the same point in time are different units. Your headache

status after taking an aspirin can obviously differ from what my headache status would

have been had I taken an aspirin. I may be more or less sensitive to aspirin, or I may have

started with a more or less severe headache. This type of comparison, often involving

many different individuals, is widely used in informal assessments of causal effects, but

it is also the basis for many formal studies of causal effects in the social and biomedical

sciences. For example, many people view a college education as economically beneficial

to future career outcomes based on comparisons of the careers of individuals with, and

individuals without, college educations.

By itself, however, the presence of multiple units does not solve the problem of causal

inference. Consider the aspirin example with two units, You and I, and two possible

treatments for each unit, aspirin or no aspirin. For simplicity, assume that the two avail-

able aspirin tablets are equally effective. There are now a total of four treatment levels:

you take an aspirin and I do not, I take an aspirin and you do not, we both take an aspirin,

or neither of us does. There are therefore four potential outcomes for each of us. For "I"

these four potential outcomes are the state of my headache (i) if neither of us takes an

aspirin, (ii) if I take an aspirin and you do not, (iii) if you take an aspirin and I do not,

and (iv) if both of us take an aspirin. "You," of course, have the corresponding set of

four potential outcomes. We can still only observe at most one of these four potential

outcomes for each unit, namely the one realized corresponding to whether you and I

took, or did not take, an aspirin. Thus each level of the treatment now indicates both

whether you take an aspirin and whether I do. In this situation, there are six different

comparisons defining causal effects for each of us, depending on which two of the four

potential outcomes for each unit are conceptually compared

6=

4 2

. For example,

we can compare the status of my headache if we both take aspirin with the status of my

headache if neither of us takes an aspirin, or we can compare the status of my headache

if only you take an aspirin to the status of my headache if we both do.

Although we typically make the assumption that whether you take an aspirin does not

affect my headache status, it is important to understand the force of such an assumption.

One should not lose sight of the fact that it is an assumption, often a strong and con-

troversial one, not a fact, and therefore may be false. Consider a setting where I take

aspirin, and I will have a headache if you do not take an aspirin, whereas I will not

have a headache if you do take an aspirin: we are in the same room, and unless you

take an aspirin to ease your own headache, your incessant complaining will maintain

my headache! Such interactions or spillover effects are an important feature of many

educational programs, and often motivate changing the unit of analysis from individual

children to schools or other groups of individuals.

1.6 THE STABLE UNIT TREATMENT VALUE ASSUMPTION
In many situations it may be reasonable to assume that treatments applied to one unit do not affect the outcome for another unit. For example, if we are in different locations and have no contact with each other, it would appear reasonable to assume that whether

10

Causality: The Basic Framework

you take an aspirin has no effect on the status of my headache. (But, as the example in the previous section illustrates, this assumption need not hold if we are in the same location, and your behavior, itself affected by whether you take an aspirin, may affect the status of my headache, or if we communicate by extrasensory perception.) The stable unit treatment value assumption, or SUTVA (Rubin, 1980a) incorporates both this idea that units do not interfere with one another and the concept that for each unit there is only a single version of each treatment level (ruling out, in this case, that a particular individual could take aspirin tablets of varying efficacy):
Assumption 1.1 (SUTVA) The potential outcomes for any unit do not vary with the treatments assigned to other units, and, for each unit, there are no different forms or versions of each treatment level, which lead to different potential outcomes.
These two elements of the stability assumption enable us to exploit the presence of multiple units for estimating causal effects.
SUTVA is the first of a number of assumptions discussed in this book that are referred to generally as exclusion restrictions: assumptions that rely on external, substantive, information to rule out the existence of a causal effect of a particular treatment relative to an alternative. For instance, in the aspirin example, in order to help make an assessment of the causal effect of aspirin on headaches, we could exclude the possibility that your taking or not taking aspirin has any effect on my headache. Similarly, we could exclude the possibility that the aspirin tablets available to me are of different strengths. Note, however, that these assumptions, and other restrictions discussed later, are not directly informed by observations ­ they are assumptions. That is, they rely on previously acquired knowledge of the subject matter for their justification. Causal inference is generally impossible without such assumptions, and thus it is critical to be explicit about their content and their justifications.

1.6.1 SUTVA: No Interference
Consider, first, the no-interference component of SUTVA ­ the assumption that the treatment applied to one unit does not affect the outcome for other units. Researchers have long been aware of the importance of this concept. For example, when studying the effect of different types of fertilizers in agricultural experiments on plot yields, traditionally researchers have taken care to separate plots using "guard rows," unfertilized strips of land between fertilized areas. By controlling the leaching of different fertilizers across experimental plots, these guard rows make SUTVA more credible; without them we might suspect that the fertilizer applied to one plot affected the yields in contiguous plots.
In our headache example, in order to address the no-interference assumption, one has to argue, on the basis of a prior knowledge of medicine and physiology, that someone else taking an aspirin in a different location cannot have an effect on my headache. You might think that we could learn about the magnitude of such interference from a separate experiment. Suppose people are paired, with each pair placed in a separate room. In each pair one randomly choosen individual is selected to be the "designated treated" individual and the other the "designated control" individual. Half the pairs are then randomly

1.6 The Stable Unit Treatment Value Assumption

11

selected to be the "treatment pairs" and the other half selected to be "control pairs," with the "designated treated" individual in the treatment pairs given aspirin and the "designated treated" individual in the control pairs given a placebo. The outcome would then be the status of the headache of the "control" person in each pair. Although such an experiment could shed some light on the plausibility of our no-interference assumption, this experiment relies itself on a more distant version of SUTVA ­ that treatments assigned to one pair do not affect the results for other pairs. As this example reveals, in order to make any assessment of causal effects, the researcher has to rely on assumed existing knowledge of the current subject matter to assert that some treatments do not affect outcomes for some units.
There exist settings, moreover, in which the no-interference part of SUTVA is controversial. In large-scale job training programs, for example, the outcomes for one individual may well be affected by the number of people trained when that number is sufficiently large to create increased competition for certain jobs. In an extreme example, the effect on your future earnings of going to a graduate program in statistics would surely be very different if everybody your age also went to a graduate program in statistics. Economists refer to this concept as a general equilibrium effect, in contrast to a partial equilibrium effect, which is the effect on your earnings of a statistics graduate degree under the ceteris paribus assumption that "everything else" stayed equal. Another classic example of interference between units arises in settings with immunizations against infectious diseases. The causal effect of your immunization versus no immunization will surely depend on the immunization of others: if everybody else is already immunized with a perfect vaccine, and others can therefore neither get the disease nor transmit it, your immunization is superfluous. However, if no one else is immunized, your treatment (immunization with a perfect vaccine) would be effective relative to no immunization. In such cases, sometimes a more restrictive form of SUTVA can be considered by defining the unit to be the community within which individuals interact, for example, schools in educational settings, or specifically limiting the number of units assigned to a particular treatment.

1.6.2 SUTVA: No Hidden Variations of Treatments
The second component of SUTVA requires that an individual receiving a specific treatment level cannot receive different forms of that treatment. Consider again our assessment of the causal effect of aspirin on headaches. For the potential outcome with both of us taking aspirin, we obviously need more than one aspirin tablet. Suppose, however, that one of the tablets is old and no longer contains a fully effective dose, whereas the other is new and at full strength. In that case, each of us may have three treatments available: no aspirin, the ineffective tablet, and the effective tablet. There are thus two forms of the active treatment, both nominally labeled "aspirin": aspirin+ and aspirin-. Even with no interference we can now think of there being three potential outcomes for each of us, the no aspirin outcome Yi(No Aspirin), the weak aspirin outcome Yi(Aspirin-) and the strong aspirin outcome Yi(Aspirin+), with i indexing "I" or "You." The second part of SUTVA either requires that the two aspirin outcomes are identical: Yi(Aspirin+) = Yi(Aspirin-), or that I can only get Aspirin+ and you can only get Aspirin- (or vice versa). Alternatively we can redefine the treatment as taking

12

Causality: The Basic Framework

a randomly selected aspirin (either Aspirin- or Aspirin+). In that case SUTVA might be satisfied for the redefined stochastic treatment.
Another example of variation in the treatment that is ruled out by SUTVA occurs when differences in the method of administering the treatment matter. The effect of taking a drug for a particular individual may differ depending on whether the individual was assigned to receive it or chose to take it. For example, taking it after being given the choice may lead the individual to take actions that differ from those that would be taken if the individual had no choice in the taking of the drug.
Fundamentally, the second component of SUTVA is again an exclusion restriction. The requirement is that the label of the aspirin tablet, or the nature of the administration of the treatment, cannot alter the potential outcome for any unit. This assumption does not require that all forms of each level of the treatment are identical across all units, but only that unit i exposed to treatment level w specifies a well-defined potential outcome, Yi(w), for all i and w. One strategy to make SUTVA more plausible relies on redefining the represented treatment levels to comprise a larger set of treatments, for example, Aspirin-, Aspirin+, and no-aspirin instead of only Aspirin and no-aspirin. A second strategy involves coarsening the outcome; for example, SUTVA may be more plausible if the outcome is defined to be dead or alive rather than to be a detailed measurement of health status. The point is that SUTVA implies that the potential outcomes for each unit and each treatment are well-defined functions (possibly with stochastic images) of the unit index and the treatment.

1.6.3 Alternatives to SUTVA
To summarize the previous discussion, assessing the causal effect of a binary treatment requires observing more than a single unit, because we must have observations of potential outcomes under both treatments: those associated with the receipt of the treatment on some units and those associated with no receipt of it on some other units. However, with more than one unit, we face two immediate complications. First, there exists the possibility that the units interfere with one another, such that one unit's potential outcome when exposed to a specific treatment level, may also depend on the treatment received by another unit. Second, because in multi-unit settings, we must have available more than one copy of each treatment, we may face circumstances in which a unit's potential outcome when receiving the same nominal level of a treatment could vary with different versions of that treatment. These are serious complications, serious in the sense that unless we restrict them by assumptions, combined with careful study design to make these assumptions more realistic, any causal inference will have only limited credibility.
Throughout most of this book, we shall maintain SUTVA. In some cases, however, specific information may suggest that alternative assumptions are more appropriate. For example, in some early AIDS drug trial settings, many patients took some of their assigned drug and shared the remainder with other patients in hopes of avoiding placebos. Given this knowledge, it is clearly no longer appropriate to assert the nointerference element of SUTVA ­ that treatments assigned to one unit do not affect the outcomes for others. We can, however, use this specific information to model how treatments are received across patients in the study, making alternative ­ and in this case, more appropriate ­ assumptions that allow some inference. For example, SUTVA may

1.7 The Assignment Mechanism: An Introduction

13

be more appropriate using subgroups of people as units in such AIDS drug trials. Similarly, in educational settings, SUTVA may be more plausible with classrooms or schools as the units of analysis than with students as the units of analysis. In many economic examples, interactions between units are often modeled through assumptions on market structure, again avoiding the no-interference element of SUTVA. Consequently, SUTVA is only one candidate exclusion restriction for modeling the potentially complex interactions between units and the entire set of treatment levels in a particular experiment. In many settings, however, it appears that SUTVA is the leading choice.

1.7 THE ASSIGNMENT MECHANISM: AN INTRODUCTION

If we are willing to accept SUTVA, our complicated "You" and "I" aspirin example simplifies to the situation depicted in Table 1.3. Now You and I each face only two treatment levels (e.g., for "You" whether or not "You" take an aspirin), and the accompanying potential outcomes are a function of only our individual actions. This extends readily to many units. To accommodate this generalization, and also the discussion of other examples beyond that of taking or not taking aspirin, as introduced in Section 1.6, let us index the units in the population of size N by i, taking on values 1, . . . , N, and let the treatment indicator Wi take on the values 0 (the control treatment, e.g., no aspirin) and 1 (the active treatment, e.g., aspirin). We have one realized (and possibly observed) potential outcome for each unit. For unit i, now i  {1, . . . , N}, let Yiobs denote this realized (and possibly observed) outcome:

Yiobs = Yi(Wi) =

Yi(0) Yi(1)

if Wi = 0, if Wi = 1.

For each unit we also have one missing potential outcome, for unit i denoted by Yimis:

Yimis = Yi(1 - Wi) =

Yi(1) Yi(0)

if Wi = 0, if Wi = 1.

Many writers replace the potential outcomes and treatment indicator with simply the treatment indicator, Wi, and the observed outcome Yiobs. This "observed-value" notation confuses the objects of inference and the assignment mechanism and can lead to mistakes as we see in Section 1.9.
This information alone, still, does not allow us to infer the causal effect of taking an aspirin on headaches. Suppose, in the two-person headache example, that the person who chose not to take the aspirin did so because he had only a minor headache. Suppose then that an hour later both headaches have faded: the headache for the first person possibly faded because of the aspirin (it would still be there without the aspirin), and the headache of the second person faded simply because it was not a serious headache (it would be gone even without the aspirin). When comparing these two observed potential outcomes, we might conclude that the aspirin had no effect, whereas in fact it may have been the cause of easing the more serious headache. The key piece of information that

14

Causality: The Basic Framework

Table 1.3. Example of Potential Outcomes and Causal Effects under SUTVA with Two Units

Unit Unknown

Known

Potential Outcomes

Causal Effect

Actual

Observed

Y(Aspirin) Y(No Aspirin)

Treatment Outcome

Wi

Yiobs

You No Headache Headache

Improvement due to Aspirin Aspirin No Headache

I No Headache No Headache None

No Aspirin No Headache

Table 1.4. Medical Example with Two Treatments, Four Units, and SUTVA: Surgery (S) and Drug Treatment (D)

Unit
Patient #1 Patient #2 Patient #3 Patient #4 Average

Potential Outcomes

Yi(0)
1 6 1 8

Yi(1)
7 5 5 7

4

6

Causal Effect
Yi(1) - Yi(0)
6 -1
4 -1
2

we lack is how each individual came to receive the treatment level actually received: in our language of causation, the assignment mechanism.
Because causal effects are defined by comparing potential outcomes (only one of which can ever be observed), they are well defined irrespective of the actions actually taken. But, because we observe at most half of all potential outcomes, and none of the unit-level causal effects, there is an inferential problem associated with assessing causal effects. In this sense, the problem of causal inference is, as pointed out in Rubin (1974), a missing data problem: given any treatment assigned to an individual unit, the potential outcome associated with any alternate treatment is missing. A key role is therefore played by the missing data mechanism, or, as we refer to it in the causal inference context, the assignment mechanism. How is it determined which units get which treatments or, equivalently, which potential outcomes are realized and which are not? This mechanism is, in fact, so crucial to the problem of causal inference that Parts II through VI of this book are organized by varying assumptions concerning this mechanism.
To illustrate the critical role of the assignment mechanism, consider the simple hypothetical example in Table 1.4. This example involves four units, in this case patients, and two possible medical procedures labeled 0 (Drug) and 1 (Surgery). Assuming SUTVA, Table 1.4 displays each patient's potential outcomes, in terms of years of post-treatment survival, under each treatment. From Table 1.4, it is clear that on average, Surgery is better than Drug by two years' life expectancy, that is, the average causal effect of Surgery versus Drug is two years for these four individuals.
Suppose now that the doctor, through expertise or magic, knows enough about these potential outcomes and so assigns each patient to the treatment that is more beneficial to that patient. In this scenario, Patients 1 and 3 will receive surgery, and Patients 2 and

1.8 Attributes, Pre-treatment Variables, or Covariates

15

Table 1.5. Ideal Medical Practice: Patients Assigned to the Individually Optimal Treatment; Example from Table 1.4

Unit i
Patient #1 Patient #2 Patient #3 Patient #4

Treatment Wi
1 0 1 0

Observed Outcome Yiobs
7 6 5 8

4 will receive the drug treatment. The observed treatments and outcomes will then be as displayed in Table 1.5, where the average observed outcome with surgery is one year less than the average observed outcome with the drug treatment. Thus, a casual observer might be led to believe that, on average, the drug treatment is superior to surgery. In fact, the opposite is true: as shown in Table 1.4, if the drug treatment were uniformly applied to a population like these four patients, the average survival would be four years, as can be seen from the "Y(0)" column in Table 1.4, as opposed to six years if all patients were treated with surgery, as can be seen from the "Y(1)" column in the same table. Based on this example, we can see that we cannot simply look at the observed values of potential outcomes under different treatments, that is, {Yiobs|i : s. t. Wi = 0} and {Yiobs|i : s. t. Wi = 1}, and reach valid causal conclusions irrespective of the assignment mechanism. In order to draw valid causal inferences, we must consider why some units received one treatment rather than another. In Parts II through VI of this text, we will discuss in greater detail various assignment mechanisms and the accompanying analyses for drawing valid causal inferences.

1.8 ATTRIBUTES, PRE-TREATMENT VARIABLES, OR COVARIATES
Consider a study of causal effects involving many units, which we assume satisfies the stability assumption, SUTVA. At least half of all potential outcomes will be unobserved or missing, because only one potential outcome can be observed for each unit, namely the potential outcome corresponding to the realized level of the treatment or action. To estimate the causal effect for any particular unit, we will generally need to predict, or impute, the missing potential outcome. Comparing the imputed missing outcome to the realized and observed outcome for this unit allows us to estimate the unit-level causal effect. In general, creating such predictions is difficult. They involve assumptions about the assignment mechanism and about comparisons between different units, each exposed to only one of the treatments. Often the presence of unit-specific background attributes, also referred to as pre-treatment variables, or covariates, and denoted in this text by the K-component row vector Xi for unit i, can assist in making these predictions. For instance, in our headache example, such variables could include the intensity of the headache before making the decision to take aspirin or not. Similarly, in an evaluation of the effect of job training on future earnings, these attributes may include age, previous educational achievement, family, and socio-economic status, or pre­training earnings.

16

Causality: The Basic Framework

As these examples illustrate, sometimes a covariate (e.g., pre-training earnings) differs from the potential outcome (post-training earnings) solely in the timing of measurement, in which case the covariates can be highly predictive of the potential outcomes.
The key characteristic of these covariates is that they are a priori known to be unaffected by the treatment assignment. This knowledge often comes from the fact that they are permanent characteristics of units, or that they took on their values prior to the treatment being assigned, as reflected in the label "pre-treatment" variables.
The information available in these covariates can be used in three ways. First, covariates commonly serve to make estimates more precise by explaining some of the variation in outcomes. For instance, in the headache example, holding constant the intensity of the headache before receiving the treatment by studying units with the same initial headache intensity should give more precise estimates of the effect of aspirin, at least for units with that level of headache intensity. Second, for substantive reasons, the researcher may be interested in the typical (e.g., average) causal effect of the treatment on subgroups (as defined by a covariate) in the population of interest. For example, we may want to evaluate the effects of a job-training program separately for people with different education levels, or the effect of a medical drug separately for women and men. The final and most important role for covariates in our context, however, concerns their effect on the assignment mechanism. Young unemployed individuals may be more interested in training programs aimed at acquiring new skills, or high-risk groups may be more likely to take flu shots. As a result, those taking the active treatment may differ in the values of their background characteristics from those taking the control treatment. At the same time, these characteristics may be associated with the potential outcomes. As a result, assumptions about the assignment mechanism and its possible freedom from dependence on potential outcomes are typically more plausible within subpopulations that are homogeneous with respect to some covariates, that is, conditionally given the covariates, rather than unconditionally.

1.9 POTENTIAL OUTCOMES AND LORD'S PARADOX
To illustrate the clarity that comes with the potential outcomes interpretation of causality, we consider a problem from the literature that is known as Lord's paradox:
A large university is interested in investigating the effects on the students of the diet provided in the university dining halls and any sex differences in these effects. Various types of data are gathered. In particular, the weight of each student at the time of his arrival in September and his weight the following June are recorded. (Lord, 1967, p. 304)
The results of the hypothetical study described in Lord's paper include the finding that for the males the average weight is identical at the end of the school year to what it was at the beginning; in fact, the whole distribution of weights is unchanged, although some males lost weight and some males gained weight ­ the gains and losses exactly balance. The same thing is true for the females. The only difference is that the females started and ended the year lighter on average than the males. On average, there is no weight gain or weight loss for either males or females. From Lord's quoted description of the problem, the object of interest, what we will generally call the estimand, is the difference between

1.9 Potential Outcomes and Lord's Paradox

17

the causal effect of the university diet on males and the causal effect of the university diet on females. That is, the causal estimand is the difference between the causal effects for males and females, the "differential" causal effect.
The paradox is generated by considering the contradictory conclusions of two statisticians asked to comment on the data. Statistician 1 observes that there are no differences between the September and June weight distributions for either males or females. Thus, Statistician 1 concludes that
as far as these data are concerned, there is no evidence of any interesting effect of diet (or of anything else) on student weight. In particular, there is no evidence of any differential effect on the two sexes, since neither group shows any systematic change. (Lord, 1967, p. 305)
Statistician 2 looks at the data in a more "sophisticated" way. Effectively, he examines males and females with the same initial weight in September, say a subgroup of "overweight" females (meaning simply above-average-weight females) and a subgroup of "underweight" males (analogously defined). He notices that these males tended to gain weight on average and these females tended to lose weight on average. He also notices that this result is true no matter what the value of initial weight he focuses on. (Actually, Lord's Statistician 2 used a technique known as covariance adjustment or regression adjustment described in Chapter 7.) His conclusion, therefore, is that after "controlling for" initial weight, the diet has a differential positive effect on males relative to females because for males and females with the same initial weight, on average the males gain more than the females.
Who's right? Statistician 1 or Statistician 2? Notice the focus of both statisticians on before-after or gain scores and recall that such gain scores are not causal effects because they do not compare potential outcomes at the same time post-treatment; rather, they compare changes over time. If both statisticians confined their comments to describing the data, both would be correct, but for causal inference, both are wrong because these data cannot support any conclusions about the causal effect of the diet without making some very strong, and arguably implausible, assumptions.
Back to the basics. The units are obviously the students, and the time of application of active treatment (the university diet) is clearly September and the time of the recording of the outcome Y is clearly June. Let us accept the stability assumption. Now, what are the potential outcomes, and what is the assignment mechanism? Notice that Lord's statement of the problem uses the already criticized notation with a treatment indicator and the observed variable, Yiobs, rather than the potential outcome notation being advocated. The potential outcomes are June weight under the university diet Yi(1) and under the "control" diet Yi(0). The covariates are sex of students, male versus female, and September weight. But the assignment mechanism has assigned everyone to the new treatment! There is no one, male or female, who is assigned to the control treatment. Hence, there is absolutely no purely empirical basis on which to compare the effects, either raw or differential, of the university diet with the control diet. By making the problem complicated with the introduction of the covariates "male/female" and "initial weight," Lord has created partial confusion. But the point here is that the "paradox" is immediately resolved through the explicit use of potential outcomes. Either answer could be correct for causal inference depending on what we are willing to assume about

18

Causality: The Basic Framework

the (never-observed) potential outcome under the control diet and its relation to the (observed) potential outcome given the university diet.

1.10 CAUSAL ESTIMANDS

Let us now be a little more formal when describing causal estimands, the ultimate object of interest in our analyses. We start with a population of units, indexed by i = 1, . . . , N, which is our focus. Each unit in this population can be exposed to one of a set of treatments. In the most general case, let Ti denote the set of treatments to which unit i can be exposed. In most cases, this set will be identical for all units. Exceptions include settings where the treatment is defined as the peer group for each individual. In the current text, the set Ti consists of the same two treatments for each unit (e.g., taking or not taking a drug),

Ti = T = 0, 1 ,

for all i = 1, . . . , N. Generalizations of most of the discussion in this text to finite sets of treatments are conceptually straightforward.
For each unit i, and for each treatment in the common set of treatments, T = {0, 1}, there are corresponding potential outcome, Yi(0) and Yi(1). Comparisons of Yi(1) and Yi(0) are unit-level causal effects. Often these are simple differences,

Yi(1) - Yi(0),

or ratios Yi(1)/Yi(0),

but in general the comparisons can take different forms. There are many such unit-level causal effects, and we often wish to summarize them for the finite sample or for subpopulations. A leading example of what we in general refer to as a causal estimand is the average difference of the pair of potential outcomes, averaged over the entire population,

fs

=

1 N

N i=1

Yi(1) - Yi(0)

,

where the subscript "fs" indicates that we average over the finite sample. We can generalize this example in a number of ways. Here we discuss two of these
generalizations, maintaining in each case the setting with T = {0, 1} for all units. First, we can average over subpopulations rather than over the full population. The subpopulation that we average over may be defined in terms of different sets of variables. First, it can be defined in terms of pre-treatment variables, or covariates, denoted by Xi. Recall these are variables measured on the units that, unlike outcomes, are a priori known to be unaffected by the treatment. For example, we may be interested in the average effect of a new drug only for females:

fs(f

)

=

1 N(f

)

i:Xi=f

Yi(1) - Yi(0)

.

1.10 Causal Estimands

19

Here Xi  {f , m} is an indicator for being female, and N(f ) =

N i=1

1Xi

=f

is the

number

of females in the finite population, where 1A is the indicator function for the event A,

equal to 1 if A is true and zero otherwise. Second, one can focus on the average effect of

the treatment for those who were exposed to it:

fs,t

=

1 Nt

i:Wi=1

Yi(1) - Yi(0)

,

where Nt is the number of units exposed to the active treatment. For example, we may be interested in the average effect of serving in the military on subsequent earnings in the civilian labor market for those who served in the military, or the average effect of exposure to asbestos on health for those exposed to it. In both examples, there is less interest in the average effect for units not exposed to the treatment. A third way of defining the relevant subpopulation is to do so partly in terms of potential outcomes. As an example, one may be interested in the average effect of a job-training program on hourly wages, averaged only over those individuals who would have been employed (with positive hourly wages) irrespective of the level of the treatment:

1 fs,pos = Npos i:Yi(0)>0,Yi(1)>0 Yi(1) - Yi(0) ,

where Npos =

N i=1

1Yi(0)>0,Yi(1)>0.

Because

the

conditioning

variable

(being

employed

irrespective of the treatment level) is a function of potential outcomes, the conditioning

is (partly) on potential outcomes.

As a second generalization of the average treatment effect, we can focus on more gen-

eral functions of potential outcomes. For example, we may be interested in the median

(over the entire population or over a subpopulation) of Yi(1) versus the median of Yi(0). One may also be interested in the median of the difference Yi(1) - Yi(0), which generally differs from the difference in medians.

In all cases with T = {0, 1}, we can write the causal estimand as a row-exchangeable

function of all potential outcomes for all units, all treatment assignments, and pre-

treatment variables:

 =  (Y(0), Y(1), X, W).

In this expression Y(0) and Y(1) are the N-component column vectors of potential outcomes with ith elements equal to Yi(0) and Yi(1), W is the N-component column vector of treatment assignments, with ith element equal to Wi, and X is the N × K matrix of covariates with ith row equal to Xi. Not all such functions necessarily have a causal interpretation, but the converse is true: all the causal estimands we consider in this book can be written in this form, and all such estimands are comparisons of Yi(0) and Yi(1) for all units in a common set whose definition, as the previous examples illustrate, may depend on Y(0), Y(1), X, and W.

20

Causality: The Basic Framework

1.11 STRUCTURE OF THE BOOK

The remainder of Part I of this text includes a brief historical overview of the development of our framework for causal inference (Chapter 2) and some mathematical definitions that characterize assignment mechanisms (Chapter 3).
Parts II through V of this text cover different situations corresponding to different assumptions concerning the assignment mechanism. Part II deals with the inferentially simplest setting of randomized assignment, specifically what we call classical randomized experiments. In these settings, the assignment mechanism is under the control of the experimenter, and the probability of any assignment of treatments across the units in the experiment is entirely knowable before the experiment begins.
In Parts III and IV we discuss regular assignment mechanisms, where the assignment mechanism is not necessarily under the control of the experimenter, and the knowledge of the probabilities of assignment is incomplete in a very specific and limited way: within subpopulations of units defined by fixed values of the covariates, the assignment probabilities are known to be identical for all these units and known to be strictly between zero and one; the probabilities themselves need not be known. Moreover, in practice, we typically have few units with the same values for the covariates, so that the methods discussed in the chapters on classical randomized experiments are not directly applicable.
Finally, Parts V and VI concern irregular assignment mechanisms, which allow the assignment to depend on covariates and on potential outcomes, both observed and unobserved, or which allow the unit-level assignment probabilities to be equal to zero or one. Such assignment mechanisms present special challenges, and without further assumptions, only limited progress can be made. In this part of the text, we discuss several strategies for addressing these complications in specific settings. For example, we discuss investigating the sensitivity of the inferential results to violations of the critical "unconfoundedness" assumption on the assignment mechanism. We also discuss some specific cases where this unconfoundedness assumption is supplemented by, or replaced by, assumptions linking various potential outcomes. These assumptions are again exclusion restrictions, where specific treatments are assumed a priori not to have any, or limited, effects on outcomes. Because of the complications arising from these irregular assignment mechanisms, and the many forms such assignment mechanisms can take in practice, this area remains a fertile field for methodological research.

1.12 SAMPLES, POPULATIONS, AND SUPER-POPULATIONS
In much of the discussion in this text, the finite set of units for which we observe covariates, treatments, and realized outcomes is the set of units we are interested in, and we will refer to this as the population. It does not matter how this population was selected, or where it came from. All conclusions are conditional on this population, and we do not attempt to draw inferences for other populations. For part of the discussion, however, it is useful to view the set of units for which we observe values as drawn randomly from a larger population. In that case we typically take the population that the units were drawn from as infinite. When it is important to make this distinction, we will refer to the

Notes

21

set of units for which we observe values as the finite sample (often using the subscript "fs"), and the infinite population that these were drawn from as the super-population (using subscript "sp") to distinguish between this case and the previous case where we observed values for all units in the population.

1.13 CONCLUSION
In this chapter we present the three basic concepts in our framework for causal inference. The first concept is that of potential outcomes, one for each unit for each level of the treatment. Causal estimands are defined in terms of these potential outcomes, possibly also involving the treatment assignments and pre-treatment variables. We discussed that, because at most only one of the potential outcomes can be observed, there is a need for observing multiple units to be able to conduct causal inference. In order to exploit the presence of multiple units, we use the stability assumption, SUTVA, which is the second basic concept in our framework. The third fundamental concept is that of the assignment mechanism, which determines which units receive which treatment. In Chapter 3 we provide a classification of assignment mechanisms that will serve as the organizing principle of the text.

NOTES
Note that the manipulation underlying our view of causality does not have to take place, merely that one has to be able to do the thought experiment in order for the causal effects to be well defined. Rubin (1978, p. 38) writes: "The fundamental problem facing inference for causal effects is that if treatment t is assigned to the ith experimental unit (i.e., Wi = t), only values in Yt can be observed, Yj for j = t being unobservable (or missing)." Holland (1986, p. 947) puts it similarly when he describes the causal inference problem as arising from the fact that "It is impossible to observe the value of Yt(u) and Yc(u) on the same unit and, therefore, it is impossible to observe the effect of t on u" (emphasis in original). In Holland's notation, u denotes the unit, and Yt(u) and Yc(u) denote the two potential outcomes for unit u under the two levels of the treatment. See also Rubin (1977, 2004, 2012).
Following Holland (1986), we refer to the general potential outcomes approach taken in this book as the Rubin Causal Model, although it has precursors in the work by Neyman (1923). Their work explicitly uses potential outcomes ("potential yields" in Neyman, 1990, translation of the 1923 original, p. 467), although Neyman focused exclusively on what we call here completely randomized experiments. In Chapter 2 we discuss in more detail the historical background to the potential outcomes framework.
The Stable Unit Treatment Value Assumption (SUTVA) was formally introduced in Rubin (1980a). See also the discussions in Rubin (1986a, 1990b, 2010). It is implicit in the notation used by Neyman (1923, 1990) where the potential outcomes are indexed only by the treatment assigned to that unit. Cox (1958, p. 19) is explicit about the need for the no-interference part of SUTVA but does not address the part of SUTVA that requires a single version of each treatment for each unit. Fisher does not explicitly address the

22

Causality: The Basic Framework

issue, but under the null hypothesis of no effect of the treatment whatsoever, SUTVA automatically holds.
For more statistical details of the resolution of Lord's paradox, see Lord (1967) and Holland and Rubin (1983), and for earlier related discussion, see, for example, Lindley and Novick (1981).
There is an extensive econometric literature concerned with causality and methods for inferring causal effects, often in settings with complex selection. For recent reviews, see Angrist and Krueger (2000), Leamer (1988), Heckman and Robb (1984), Heckman, Ichimura, Smith, and Todd, (1998), Heckman, Lalonde, and Smith (2000), and Angrist and Pischke (2008).
Recent textbooks discussing causal inference in various detail and from various points of view include Rosenbaum (1995, 2002, 2009), Shadish, Campbell, and Cook (2002), Van Der Laan and Robins (2003), Lee (2005), Caliendo (2006), Gelman and Hill (2006), Morgan and Winship (2007), Angrist and Pischke (2008), Guo and Fraser (2010), Morton and Williams (2010), Murnane and Willett (2011); and for collected papers, see Rubin (2006) and Freedman (2009). For a more philosophical perspective, see Beebee, Hitchcock, and Menzies (2009). The Rosenbaum books are closest to the current text in terms of the perspective on causality.
There are some approaches to causality that take conceptually different perspectives. In the analysis of time series, economists have found it useful to consider "Granger-Sims causality," which essentially views causality as a prediction property. Suppose we have two time series, one measuring the money supply ("money"), and one measuring gross domestic product (GDP). Money "causes" GDP in the Granger sense if, conditional on the past values of GDP, and possibly conditional on other variables, past values of money predict future values of GDP. Money does not "cause" GDP in the Sims sense if, when predicting money from past, present, and future values of GDP, the future values have no predictive power. See Granger (1969) and Sims (1972). For a recent analysis of the causal links between the money supply (or, more specifically, actions by the Federal Reserve Bank), and GDP, from a perspective that is, at least in spirit, closer to the potential outcome approach taken in this text, see Romer and Romer (2004). Angrist and Kuersteiner (2011) provide some discussion on the link with the potential outcome approach.
Dawid (2000) develops an interesting approach to causality that avoids potential outcomes, and which focuses primarily on a decision-oriented perspective. There has not been much experience with this approach in applications so far.
Pearl (1995, 2000, 2009) advocates a different approach to causality. Pearl combines aspects of structural equations models and path diagrams. In this approach, assumptions underlying causal statements are coded as missing links in the path diagrams. Mathematical methods are then used to infer, from these path diagrams, which causal effects can be inferred from the data, and which cannot. See Pearl (2000, 2009) for details and many examples. Pearl's work is interesting, and many researchers find his arguments that path diagrams are a natural and convenient way to express assumptions about causal structures appealing. In our own work, perhaps influenced by the type of examples arising in social and medical sciences, we have not found this approach to aid drawing of causal inferences, and we do not discuss it further in this text.

CHAPTER 2
A Brief History of the Potential Outcomes Approach to Causal Inference
2.1 INTRODUCTION
The approach to causal inference outlined in the first chapter has important antecedents in the literature. In this chapter we review some of these antecedents to put the potential outcomes approach in perspective. The two most important early developments, in quick succession in the 1920s, are the introduction of potential outcomes in randomized experiments by Neyman (Neyman, 1923, translated and reprinted in Neyman, 1990), and the introduction of randomization as the "reasoned basis" for inference by Fisher (Fisher 1935, p. 14).
Once introduced, the basic idea that causal effects are the comparisons of potential outcomes may seem so obvious that one might expect it to be a long-established tenet of scientific thought. Yet, although the seeds of the idea can be traced back at least to the eighteenth century, the formal notation for potential outcomes was not introduced until 1923 by Neyman. Even then, however, the concept of potential outcomes was used exclusively in the context of randomized experiments, not in observational studies. The same statisticians, analyzing both experimental and observational data with the goal of inferring causal effects, would regularly use the notation of potential outcomes in experimental studies but switch to a notation purely in terms of realized and observed outcomes for observational studies. It is only more recently, starting in the early seventies with the work of Donald Rubin (1974), that the language and reasoning of potential outcomes was put front and center in observational study settings, and it took another quarter century before it found widespread acceptance as a natural way to define and assess causal effects, irrespective of the setting.
Moreover, before the twentieth century there appears to have been only limited awareness of the concept of the assignment mechanism. Although by the 1930s randomized experiments were firmly established in some areas of scientific investigation, notably in agricultural experiments, there was no formal statement for a general assignment mechanism and, moreover, not even formal arguments in favor of randomization until Fisher (1925).
23

24

A Brief History of the Potential Outcomes Approach to Causal Inference

2.2 POTENTIAL OUTCOMES AND THE ASSIGNMENT MECHANISM BEFORE NEYMAN

Before the twentieth century we can find seeds of the potential outcomes definition of causal effects among both experimenters and philosophers. For example, one can see some idea of potential outcomes, although as yet unlabeled as such, in discussions by the philosopher and economist Mill (1973, p. 327), who offers:

If a person eats of a particular dish, and dies in consequence, that is, would not have died if he had not eaten of it, people would be apt to say that eating of that dish was the source of his death.

Applying the potential outcomes notation to this quotation, Mill appears to be considering the two potential outcomes, Y(eat dish) and Y(not eat dish) for the same person. In this case the observed outcome, Y(eat dish), is "death," and Mill appears to posit that if the alternative potential outcome, Y(not eat dish), is "not death," then one could infer that eating the dish was the source (cause) of the death.
Similarly, in the early twentieth century, the father of much of modern statistics, Fisher (1918, p. 214), argued:
If we say, "This boy has grown tall because he has been well fed," . . . we are suggesting that he might quite probably have been worse fed, and that in this case he would have been shorter.

Here again we see a, somewhat implicit, reference to two potential outcomes, Y(well fed) = tall and Y(not well fed) = shorter, associated with a single unit, a boy.
Despite the insights we may perceive in these quotations, their authors may or may not have intended their words to mean as we choose to interpret them. For instance, in his argument, Mill goes on to require "constant conjunction" in order to assign causality ­ that is, for the dish to be the cause of death, this outcome must occur every time it is consumed, by this person, or perhaps by any person. Curiously, an early tobacco industry argument used a similar notion of causality: not everyone who smokes two or more packs of cigarettes a day gets lung cancer, therefore smoking does not cause lung cancer. Jerome Cornfield, the well-known American epidemiologist who studied smoking and lung cancer also struggled with this: "If cigarettes are carcinogenic, why don't all smokers get lung cancer?" (Cornfield, 1959, p. 242) without the benefits of the potential outcomes framework. See also Rubin (2012).
No matter how interpreted, however, we have found no early writer who formally pursued these intuitive insights about potential outcomes defining causal effects; in particular, until Neyman did so in 1923, no one developed a formal notation for the idea of potential outcomes. Nor did anyone discuss the importance of the assignment mechanism, which is necessary for the evaluation of causal effects. The first such formal mathematical use of the idea of potential outcomes was introduced by Jerzey Neyman (1923), and then only in the context of an urn model for assigning treatments to plots. The general formal definition of causal effects in terms of potential outcomes, as well as the formal definition of the assignment mechanism, was still another half century away.

2.3 Neyman's (1923) Potential Outcome Notation in Randomized Experiments

25

2.3 NEYMAN'S (1923) POTENTIAL OUTCOME NOTATION IN RANDOMIZED EXPERIMENTS

Neyman (in the translated 1990 version) begins with a description of a field experiment with m plots on which v varieties might be applied. Neyman introduces what he calls "potential yield" Uik, where i indexes the variety, i = 1, . . . , v, and k indexes the plot, k = 1, . . . , m. The potential yields are not equal to the actual or observed yield because i indexes all varieties and k indexes all plots, and each plot is exposed to only one variety. Throughout, the collection of potential outcomes, U = {Uik : i = 1, . . . , v; k = 1, . . . , m} is considered a priori fixed but unknown. The "best estimate" (Neyman's term) of the yield of the ith variety in the field is the average potential outcomes for that variety over all m plots,

ai

=

1 N

m k=1

Uik.

Neyman calls ai the "best estimate" because of his concern with the definition of "true yield," something that he struggled with again in Neyman (1935). As we define potential outcomes, they are the "true" values under SUTVA, not estimates of them.
Neyman then goes on to describe an urn model for determining which variety each plot receives; this model is stochastically identical to the completely randomized experiment with n = m/v plots exposed to each variety. He notes the lack of independence between assignments for different plots implied by this restricted sampling of treatments without replacement (i.e., if plot k receives variety i, then plot l is less likely to receive variety i), and he goes on to note that certain formulas for this situation that have been justified on the basis of independence (i.e., treating the Uik as independent normal random variables given some parameters) need more careful consideration.
Now, still using Neyman's notation, let xi be the sample average of the n plots actually exposed to the ith variety, as opposed to ai, the average of the potential outcomes over all m plots. Neyman shows that the expectation of xi - xj, that is, the average value of xi - xj over all assignments that are possible under his urn drawings, is ai - aj. Thus, the standard estimate of the effect of variety i versus variety j, the difference in observed means, xi - xj, is unbiased (over repeated randomizations on the m plots) for the causal estimand, ai - aj, the average effect of variety i versus variety j across all m plots.
Neyman's formalism made three contributions: (i) explicit notation for potential outcomes, (ii) implicit consideration of something like the stability assumption, and (iii) implicit consideration of a model for the assignment of treatments to units that corresponds to the completely randomized experiment. But as Speed (1990, p. 464) writes in his introduction to the translation of Neyman (1923): "Implicit is not explicit; randomization as a physical act, and later as a basis for analysis, was yet to be introduced by Fisher." Nevertheless, the explicit provision of mathematical notation for potential outcomes was a great advance, and after Fisher's introduction of randomized experiments in 1925, Neyman's notation quickly became standard for defining average causal effects in randomized experiments. See, for example, Pitman (1937), Welch (1937), McCarthy (1939), Anscombe (1948), Kempthorne (1952, 1955), Brillinger, Jones, and Tukey (1978), Hedges and Lehman (1970, sec. 9.4), and dozens of other places, often

26

A Brief History of the Potential Outcomes Approach to Causal Inference

assuming additivity as in Cox (1956, 1958), and even in introductory texts (Freedman, Pisani, and Purves, 1978, pp. 456­458). Neyman himself, in hindsight, felt that the mathematical model was an advance:
Neyman has always depreciated the statistical works which he produced in Bydogszcz [which is where Neyman (1923) was done], saying that if there is any merit in them, it is not in the few formulas giving various mathematical expectations but in the construction of a probabilistic model of agricultural trials which, at that time, was a novelty. (Reid, 1982, p. 45)

2.4 EARLIER HINTS FOR PHYSICAL RANDOMIZING
The notion of the central role of randomization, even if not actual randomized experiments, seems to have been "in the air" in the 1920s before it was explicitly introduced by Fisher. For example, "Student" (Gossett, 1923, pp. 281­282) writes: "If now the plots had been randomly placed . . . ," and Fisher and MacKenzie (1923, p. 473) write "Furthermore, if all the plots were undifferentiated, as if the numbers had been mixed up and written down in random order" (see Rubin, 1990, p. 477). Somewhat remarkably, however, an American psychologist and philosopher, Charles Sanders Peirce, appears to have proposed physical randomization decades earlier, although not as a basis for inference, as in Fisher (1925). Specifically, Peirce and Jastrow (1885, reprinted in Stigler, 1980, pp. 75­83) used physical randomization to create sequences of binary treatment conditions (heavier versus lighter weights) in a repeated-measures psychological experiment. The purpose of the randomization was to create sequences such that "any possible psychological guessing of what changes the operator [experimenter] was likely to select was avoided" (Stigler, pp. 79­80).1 Peirce also appears to have anticipated, in the late nineteenth century, Neyman's concept of unbiased estimation when using simple random samples and appears to have even thought of randomization as a physical process to be implemented in practice (Peirce, 1931).2 But we can find no suggestion for the physical randomizing of treatments to units as a basis for inference under Fisher (1925).

2.5 FISHER'S (1925) PROPOSAL TO RANDOMIZE TREATMENTS TO UNITS
An interesting aspect of Neyman's analysis was that, as just mentioned, although he developed his notation to treat data as if they arose from what was later called a completely randomly assigned experiment, he did not take the further step of proposing the necessity of physical randomization for credibly assessing causal effects. It was instead Ronald Fisher, in 1925, who first grasped this. Although the distinction may seem trivial in hindsight, Neyman did not see it as such:
1 Thanks to Stephen Stigler for noting this, possibly first, use of randomization in formal experiments, in correspondence with the second author.
2 Thanks to Keith O'Rourke and Stephen Stigler for pointing this out.

2.6 The Observed Outcome Notation in Observational Studies for Causal Effects

27

On one occasion, when someone perceived him as anticipating the English statistician R. A. Fisher in the use of randomization, he objected strenuously:
"I treated theoretically an unrestrictedly randomized agricultural experiment and the randomization was considered a prerequisite to probabilistic treatment of the results. This is not the same as the recognition that without randomization an experiment has little value irrespective of the subsequent treatment. The latter point is due to Fisher, and I consider it as one of the most valuable of Fisher's achievements" (Reid, 1982, p. 45)
Also,
Owing to the work of R. A. Fisher, "Student" and their followers, it is hardly possible to add anything essential to the present knowledge concerning local experiments . . . . One of the most important achievements of the English School is their method of planning field experiments known as the method of Randomized Blocks and Latin Squares. (Neyman, 1935, p. 109)
Thus, independent of Neyman's work, Fisher (1925) proposed the physical randomization of units and furthermore developed a distinct method of inference based for this special class of assignment mechanisms, that is, randomized experiments. The random assignments can be made, for instance, by choosing balls from an urn, as described by Neyman (1923). Fisher's "significance levels" (i.e., p-values), in the current text introduced and discussed in Chapter 5, remain the accepted rigorous standard for the analysis of randomized clinical trials at the start of the twenty-first century and validate so-called intent-to-treat analyses, as discussed in Chapters 5 and 23.

2.6 THE OBSERVED OUTCOME NOTATION IN OBSERVATIONAL STUDIES FOR CAUSAL EFFECTS
Despite the almost immediate acceptance of randomized experiments, Fisher's p-values, and Neyman's notation for potential outcomes in agricultural work and mathematical statistics by 1930 within such experiments, these same elements were not used for causal inference in observational studies. Among social scientists, who were using almost exclusively observational data, the work on randomized experiments by Fisher, Neyman, and others, received little or no attention, and researchers continued building models for observed outcomes rather than thinking in terms of potential outcomes. Even among statisticians involved in the analysis of both randomized and non-randomized data for causal effects, the ideas and mathematical language used for causal inference in the setting of randomized experiments were completely excluded from causal inference in the non-randomized settings. The approach in the latter continued to involve building statistical models relating the observed value of the outcome variable to covariates and indicator variables for treatment levels, with the causal effects defined in terms of the parameters of these models, a tradition that appears to originate with Yule (1897).
This approach estimated associations, for example, correlations, between observed variables, and then attempted, using various external arguments about temporal ordering of the variables, to infer causation, that is, to assess which of these associations might be reflecting a causal mechanism. In particular, the pair of the potential outcomes

28

A Brief History of the Potential Outcomes Approach to Causal Inference

(Yi(1), Yi(0)), which in our approach is fundamental for defining causal effects, was replaced by the observed value of Y for unit i, introduced in Section 1.7.

Yiobs = Yi(Wi) = Wi · Yi(1) + (1 - Wi) · Yi(0) =

Yi(0) Yi(1)

if Wi = 0, if Wi = 1.

The observed outcome Yiobs was then typically regressed, using ordinary least squares methods, as in Yule (1897), on covariates Xi and the indicator for treatment exposure, Wi. The regression coefficient of Wi in this regression was then interpreted as estimating the causal effect of Wi = 1 versus Wi = 0. Somewhat remarkably, under very specific conditions, this approach works as outlined in Chapter 7. But in broad generality it does not. This tradition dominated economics, sociology, psychology, education, and other social sciences, as well as the biomedical sciences, such as epidemiology, for most of a century.
In fact, for the half century following Neyman (1923), statisticians who wrote with great clarity and insight on randomized experiments using the potential outcomes notation did not use it when discussing non-randomized studies for causal effects. For example, contrast the discussion in Cochran and Cox (1956) on experiments with that in Cochran (1965) on observational studies, and the discussion in Cox (1958) on randomized experiments with that in Cox and McCullagh (1982) on Lord's paradox (which we discussed using the potential outcome framework in Chapter 1).

2.7 EARLY USES OF POTENTIAL OUTCOMES IN OBSERVATIONAL STUDIES IN SOCIAL SCIENCES
Although the potential outcome notation did not find widespread adoption in observational studies until recently, in some specific settings researchers used frameworks for causal inference that are similar. One of the most interesting examples is the use of potential outcomes in the analysis of demand and supply functions specifically, and the analysis of simultaneous equations models in economics in general. In the 1930s and 1940s, economists Tinbergen (1930) and Haavelmo (1944) formulated causal questions in such settings in terms that now appear very modern. Tinbergen writes:
Let  be any imaginable price; and call total demand at this price n( ), and total supply a( ). Then the actual price p is determined by the equation a(p) = n(p), so that the actual quantity demanded, or supplied, obeys the condition u = a(p) = n(p), where u is this actual quantity. . . . The problem of determining demand and supply curves . . . may generally be put as follows: Given p and u as functions of time, what are the functions n( ) and a( )? (Tinbergen, 1930, translated in Hendry and Morgan, 1994, p. 233)
This quotation clearly describes the potential outcomes and the specific assignment mechanism corresponding to market clearing, closely following the treatment of such questions in economic theory. Note the clear distinction in notation between the price as an argument in the demand-and-supply functon ("any imaginable price ") and the actual price p.

2.8 Potential Outcomes Assignment Mechanism in Observational Studies

29

Similarly, Haavelmo (1934) writes:
If the group of all consumers in society were repeatedly furnished with the total income, or purchasing power r per year, they would, on average or "normally" spend a total amount u¯ for consumption per year, equal to u¯ = r+. (Haavelmo, 1943, p. 3, reprinted in Hendry and Morgan, 1994, p. 456)
Although more ambiguous than the Tinbergen quote, this certainly suggests that Haavelmo viewed laws or structural equations in terms of potential outcomes that could have been observed by arranging an experiment.
There are two interesting aspects of the Haavelmo work and the link with potential outcomes. First, it appears that Haavelmo was directly influenced by Neyman (see Hendry and Morgan, 1994, p. 67) and in fact studied with him for a couple of months at Berkeley: "I then had the privilege of studying with the world famous statistician Jerzey Neyman for a couple of months in California. . . . When I met him for that second talk I had lost most of my illusions regarding my understanding of how to do econometrics" (Haavelmo, 1989). Second, the close connection between the Tinbergen and Haavelmo work and potential outcomes disappeared in later work. In the work by Koopmans and others associated with the Cowles Commission (e.g., the papers in Koopmans, 1950, and Hood and Koopmans, 1953), statistical models are formulated for observed outcomes in terms of observed explanatory variables. No distinction is made between variables that Cox describes as "treatments . . . potentially causal" and "intrinsic properties of the [units] under study" (Cox, 1992, p. 296) that are characteristics or attributes of the units. This observed outcome framework for analyzing causal questions dominated economics and other social sciences and continues to dominate the textbooks in econometrics, with few exceptions, until very recently.

2.8 POTENTIAL OUTCOMES AND THE ASSIGNMENT MECHANISM IN OBSERVATIONAL STUDIES: RUBIN (1974)
Rubin (1974, 1975, 1978) makes two key contributions. First, Rubin (1974) puts the potential outcomes center stage in the analysis of causal effects, irrespective of whether the study is an experimental one or an observational one. Second, he discusses the assignment mechanism in terms of the potential outcomes.
Rubin starts by defining the causal effect at the unit level in terms of the pair of potential outcomes:
. . . define the causal effect of the E versus C treatment on Y for a particular trial (i.e., a particular unit . . .) as follows: Let y(E) be the value of Y measured at t2 on the unit, given that the unit received the experimental Treatment E initiated at t1; Let y(C) be the value of Y measured at t2 on the unit given that the unit recieved the control Treatment C initiated at t1. Then y(E) - y(C) is the causal effect of the E versus C treatment on Y . . . for that particular unit. (Rubin, 1974, p. 639)
This definition fits perfectly with Neyman's framework for analyzing randomized experiments but shows that the definition has nothing to do with the assignment mechanism: it applies equally to observational studies as well as to randomized experiments.
Rubin (1975, 1978) then discusses the benefits of randomization in terms of eliminating systematic differences between treated and control units and formulates the

30

A Brief History of the Potential Outcomes Approach to Causal Inference

assignment mechanism in general mathematical terms as possibly depending on the potential outcomes. Our formal consideration of the assignment mechanism begins in Chapter 3.

NOTES
When one of us (Rubin) was visiting the Department of Statistics at Berkeley in the mid1970s, where Neyman was Professor Emeritus, he asked Neyman why no one ever used the potential outcomes notation from randomized experiments to define causal effects more generally. This meeting was fifteen years before the (re-)publication of Neyman (1923, 1990). Somewhat remarkably in hindsight, at this meeting, Neyman never mentioned that he invented the notation; his reply to the question as to why it was not used outside experiments was to the effect that defining causal effects in non-randomized settings was too speculative, and in such settings, statisticians should stick with statements concerning descriptions and associations (see Rubin, 2010, p. 42). This fits in with the Neyman quote given in Section 2.5: "without randomization, an experiment has little value irrespective of the subsequent treatment" (Reid, 1982, p. 45). The term "assignment mechanism," and its formal definition, including possible dependence on the potential outcomes, was introduced in Rubin (1975).
For discussions on the intention-to-treat principle, see Davies (1954), Fisher et al. (1990), Meier (1992), Cook and DeMets (2008), Wu and Hamada (2009), Altman (1991), Sheiner and Rubin (1995), and Lui (2011).

CHAPTER 3
A Classification of Assignment Mechanisms
3.1 INTRODUCTION
As discussed in Chapter 1, the fundamental problem of causal inference is the presence of missing data ­ for each unit we can observe at most one of the potential outcomes. A key component in a causal analysis is, therefore, what we call the assignment mechanism: the process that determines which units receive which treatments, hence which potential outcomes are realized and thus can be observed, and, conversely, which potential outcomes are missing. In this chapter we introduce a taxonomy of assignment mechanisms that will serve as the organizing principle for this text. Formally, the assignment mechanism describes, as a function of all covariates and of all potential outcomes, the probability of any vector of assignments. We consider three basic restrictions on assignment mechanisms: 1. Individualistic assignment: This limits the dependence of a particular unit's assign-
ment probability on the values of covariates and potential outcomes for other units. 2. Probabilistic assignment: This requires the assignment mechanism to imply a nonzero probability for each treatment value, for every unit. 3. Unconfounded assignment: This disallows dependence of the assignment mechanism on the potential outcomes. Following Cochran (1965), we also make a distinction between experiments, where the assignment mechanism is both known and controlled by the researcher, and observational studies, where the assignment mechanism is not known to, or not under the control of, the researcher. We consider three classes of assignment mechanisms, covered in Parts II, III, IV, V, and VI of this book. The first class, studied in Part II, corresponds to what we call classical randomized experiments. Here the assignment mechanism satisfies all three restrictions on the assignment process, and, moreover, the researcher knows and controls the functional form of the assignment mechanism. Such designs are well understood, and in such settings causal effects are often relatively straightforward to estimate, and, moreover, it is often possible to do finite sample inference. We refer to the second class of assignment mechanisms, studied in Parts III and IV of this text, as regular assignment mechanisms. This class comprises assignment
31

32

A Classification of Assignment Mechanisms

mechanisms that, like classical randomized experiments, are individualistic, probabilistic, and unconfounded, but, in contrast to classical randomized experiments, the assignment mechanism need not be under the control of, or known by, the researcher. When the assignment mechanism is not under the control of the researcher, the restrictions on the assignment mechanism that make it regular are now usually assumptions, and they are typically not satisfied by design, as they are in classical randomized experiments. In general, we will not be sure whether these assumptions hold in any specific application, and in later chapters we will discuss methods for assessing their plausibility, as well as investigating the sensitivity to violations of them.
In practice, the regular observational study is a setting of great importance. It has been studied extensively from a theoretical perspective and is widely used in empirical work. Many, but not all, of the methods applicable to randomized experiments can be used, but often modifications to the specific methods are critical to enhance the credibility of the results. The simple methods that suffice in the context of randomized experiments tend to be more controversial when applied with regular assignment mechanisms. The concerns these simple methods raise are particularly serious if the covariate distributions under the various treatment regimes are substantially different, or unbalanced in our terminology. In that case, it can be very important, for the purpose of making credible causal inferences, to have an initial, what we call design stage of the study. In this design stage, the data on covariate values and treatment assignment (but, importantly, not the final outcome data) are analyzed in order to assemble samples with improved balance in covariate distributions, somewhat in parallel with the design stage of randomized experiments. Often in this setting, the number of pre-treatment variables is substantial, typically because, conditional on a large number of pre-treatment variables, unconfoundedness is more plausible. Although this creates no conceptual problems, it makes the practical problem of drawing credible causal inferences more challenging.
In Part V of the book we discuss methods for assessing the plausibility of the unconfoundedness assumption, and sensitivity analyses for assessing the implications of violations of it. In Part VI we analyze a number of assignment mechanisms where the assignment itself is regular, but the treatment received is not equal to the treatment assigned for all units. Thus, although the treatment assigned is unconfounded, the treatment received is not unconfounded, because the probability of receiving the active versus control treatment depends on potential outcomes. Such settings have arisen in the econometric literature to account for settings where individuals choose the treatment regime, at least partly based on expected benefits associated with the two treatment regimes. Although, as a general matter, such optimizing behavior is not inconsistent with regular assignment mechanisms, in some cases it suggests assignment mechanisms associated with so-called instrumental variable methods.
The rest of this chapter is organized as follows. In the next section we introduce additional notation. In Section 3.3 we define the assignment mechanism, unit-level assignment probabilities, and the propensity score. In Section 3.4 we formally introduce the three general restrictions we consider imposing on assignment mechanisms. We then use those restrictions to define classical randomized experiments in Section 3.6. In Section 3.7 we define regular assignment mechanisms as a special class of observational studies. The next section, Section 3.8, discusses some non-regular assignment mechanisms. Section 3.9 concludes.

3.2 Notation

33

3.2 NOTATION

Continuing the potential outcomes discussion in Chapter 1, let us consider a population of N units, indexed by i = 1, . . . , N. The ith unit in this population is characterized by

a K-component row vector of covariates (also referred to as pre-treatment variables or attributes), Xi, with X the N × K matrix of covariates in the population with ith row equal

to Xi. In social science applications, the elements of Xi may include an individual's

age, education, socio-economic status, labor market history, pre-test scores, sex, and

marital status. In biomedical applications, the covariates may also include measures of

an individual's medical history, and family background information. Most important is

that covariates are known a priori to be unaffected by the assignment of treatment.

For each unit there is also a pair of potential outcomes, Yi(0) and Yi(1), denoting

its outcome values under the two values of the treatment: Yi(0) denotes the outcome

under the control treatment, and Yi(1) denotes the outcome under the active treatment.

Notice that when using this notation, we tacitly accept the Stable Unit Treatment Value

Assumption (SUTVA) that treatment assignments for other units do not affect the out-

comes for unit i, and that each treatment defines a unique outcome for each unit. The

latter requirement implies that there is only a single version of the active and control

treatments for each unit. Let Y(0) and Y(1) denote the N-component vectors (or the

N-vectors for short) of the potential outcomes. More generally, the potential outcomes

could themselves be multi-component row vectors, in which case Y(0) and Y(1) would be matrices with the ith rows equal to Yi(0) and Yi(1), respectively. Here, we largely

focus on the situation where the potential outcomes are scalars, although in most cases

extensions to vector-valued outcomes are conceptually straightforward.

Next, the N-component columns vector of treatment assignments is denoted by

W, with ith element Wi  {0, 1}, with Wi = 0 if unit i received the control treatment,

and Wi = 1 if this unit received the active treatment. Let Nc =

N i=1

(1

-

Wi)

and

Nt =

N i=1

Wi

be

the

number

of

units

assigned

to

the

control

and

active

treatment

respectively, with Nc + Nt = N.

In Chapter 1 we defined the realized and possibly observed outcomes

Yiobs = Yi(Wi) =

Yi(0) Yi(1)

if Wi = 0, if Wi = 1,

(3.1)

and the missing outcomes:

Yimis = Yi(1 - Wi) =

Yi(1) Yi(0)

if Wi = 0, if Wi = 1.

(3.2)

Yobs and Ymis are the corresponding N-vectors (or matrices in the case with multiple outcomes). We can invert these relations and characterize the potential outcomes in terms of the observed and missing outcomes:

Yi(0) =

Yimis if Wi = 1, Yiobs if Wi = 0,

and

Yi(1) =

Yimis Yiobs

if Wi = 0, if Wi = 1.

(3.3)

34

A Classification of Assignment Mechanisms

This characterization illustrates that the causal inference problem is fundamentally a missing data problem: if we impute the missing outcomes, we "know" all the potential outcomes and thus the value of any causal estimand in the population of N units.

3.3 ASSIGNMENT PROBABILITIES

To introduce the taxonomy of assignment mechanisms used in this text requires some formal mathematical terms. First, we define the assignment mechanism to be the function that assigns probabilities to all 2N possible values for the N-vector of assignments W (each unit can be assigned to treatment or control), given the N-vectors of potential outcomes Y(0) and Y(1), and given the N × K matrix of covariates X:
Definition 3.1 (Assignment Mechanism) Given a population of N units, the assignment mechanism is a row-exchangeable function Pr(W|X, Y(0), Y(1)), taking on values in [0, 1], satisfying

Pr(W|X, Y(0), Y(1)) = 1,
W{0,1}N

for all X, Y(0), and Y(1).

The set W = {0, 1}N is the set of all N-vectors with all elements equal to 0 or 1. By

the assumption that the function Pr( · ) is row exchangeable, we mean that the order

in which we list the N units within the vectors or matrices is irrelevant. Note that this

probability Pr(W|X, Y(0), Y(1)) is not the probability of a particular unit receiving the

treatment. Instead, it is the probability that a particular value for the full assignment ­

first two units treated, third a control, fourth treated, etc. ­ will occur. The definition requires that the probabilities across the full set of 2N possible assignment vectors W

sum to one. Note also that some assignment vectors W may have zero probability. For

example, if we were to design a study to evaluate a new drug, it is likely that we would

want to rule out the possibility that all subjects received the control drug. We could do

so by assigning zero probability to the vector of assignments W with Wi = 0 for all i, or

perhaps even assign zero probability to all vectors of assignments other than those with

N i=1

Wi

=

N/2,

for

even

values

of

the

population

size

N.

In addition to the probability of joint assignment for the entire population, we are often

interested in the probability of an individual unit being assigned to the active treatment:

Definition 3.2 (Unit Assignment Probability) The unit-level assignment probability for unit i is

pi(X, Y(0), Y(1)) =

Pr(W|X, Y(0), Y(1)).

W:Wi=1

Here we sum the probabilities across all possible assignment vectors W for which Wi = 1. Out of the set of 2N different assignment vectors, half (that is 2N-1) have the property that Wi = 1. The probability that unit i is assigned to the control treatment is 1 - pi(X, Y(0), Y(1)). Note that according to this definition, the probability that unit i

3.3 Assignment Probabilities

35

receives the treatment can be a function of its own covariates Xi and potential outcomes Yi(0) and Yi(1), and it generally is also a function of the covariate values, and potential outcomes, and treatment assignments of the other units in the population.
We are also often interested in the average of the unit-level assignment probabilities for subpopulations with a common value of the covariates, for example, Xi = x. We label this function the propensity score at x. In the finite population case the definition of the propensity score follows.

Definition 3.3 (Finite Population Propensity Score) The propensity score at x is the average unit assignment probability for units with Xi = x,

e(x)

=

1 N(x)

pi(X, Y(0), Y(1))
i:Xi=x

where N(x) = #{i = 1, . . . , N|Xi = x} is the number of units with Xi = x. For values x with N(x) = 0, the propensity score is defined to be zero.

To illustrate these definitions more concretely, consider four examples, the first three with with two units, and the last one with three units.
EXAMPLE 1 Suppose we have two units. Then there are four (22) possible values for W,

W

0 0

,

0 1

,

1 0

,

1 1

.

We conduct a randomized experiment where all treatment assignments have equal probability. Then the assignment mechanism is equal to

Pr(W|X, Y(0), Y(1)) = 1/4, for W 

0 0

,

0 1

,

1 0

,

1 1

.

(3.4)

In this case the unit assignment probability pi(X, Y(0), Y(1)) is equal to 1/2 for both units i = 1, 2. In a randomized experiment with no covariates, the propensity score is equal to the unit assignment probabilities, here all equal to 1/2.

EXAMPLE 2 We conduct a randomized experiment with two units where only those

assignments with exactly one treated and one control unit are allowed. Then the

assignment mechanism is



1/2 if W 

0 1

,

1 0

,

Pr(W|X, Y(0), Y(1)) = 0

if W 

0 0

,

1 1

.

(3.5)

This does not change the unit-level assignment probabilities, which remains equal to 1/2 for both units, and so does the propensity score.
EXAMPLE 3 A third, more complicated, assignment mechanism with two units is the following. The unit with more to gain from the active treatment (using a coin toss in the

36

A Classification of Assignment Mechanisms

case of a tie) is assigned to the treatment group, and the other to the control group. This leads to

 111/2 Pr(W|X, Y(0), Y(1)) = 000

if Y2(1) - Y2(0) > Y1(1) - Y1(0) and W =

if Y2(1) - Y2(0) < Y1(1) - Y1(0) and W =

if Y2(1) - Y2(0) = Y1(1) - Y1(0) and W 

if W 

0 0

,

1 1

,

if Y2(1) - Y2(0) < Y1(1) - Y1(0) and W =

if Y2(1) - Y2(0) > Y1(1) - Y1(0) and W =

0 1

,

1 0

,

0 1

,

0 1

,

1 0

.

1 0

,

(3.6)

In this example the unit-level treatment probabilities pi(X, Y(0), Y(1)) are equal to zero, one, or a half, depending whether the gain for unit i is smaller or larger than for the other unit, or equal. Given that there are no covariates, the propensity score remains a constant, equal to 1/2 in this case. This is a type of assignment mechanism that we often rule out when attempting to infer causal effects.

EXAMPLE 4 A sequential randomized experiment allows for dependence of the assignment mechanism on the potential outcomes, thus violating some of the assumptions we consider later. In this example, there are three units, and thus eight possible values for W:

               

0 0 0 0 1 1 1 1

W



00

,

0 1

,

1 0

,

1 1

,

0 0

,

0 1

,

1 0

,

1 1

.

Suppose there is a covariate Xi measuring the order in which the units entered the experiment, Xi  {1, 2, 3}. Without loss of generality, let us assume that Xi = i. For the first unit, with Xi = 1, a fair coin toss determines the treatment. The second unit, with Xi = 2,
is assigned to the alternative treatment. Let the observed outcomes for the first and second unit be Y1obs and Y2obs. The third unit, with Xi = 3, is assigned to the active or control treatment that appears better, based on a comparison of observed outcomes by treatment
status for the first two units. If both treatments appear equally beneficial, the third unit is assigned to the active treatment. For example, if W1 = 0, W2 = 1, and Y1obs > Y2obs, then the third unit gets assigned to the control group; if W1 = 0, W2 = 1, and Y1obs  Y2obs, the third units gets assigned to the treatment group; and similarly given the alternative

3.4 Restrictions on the Assignment Mechanism

37

assignments for the first two units. Formally:

 11//22

 

if Y1(0) > Y2(1), if Y1(1)  Y2(0),

and and

W W

= =

0 1
0
 1
0 1

,,

Pr(W|X, Y(0), Y(1), X) = 11//22

if Y1(0)  Y2(1), if Y1(1) < Y2(0),

and and

W W

= =

 0
1 1
 1
0

,.

(3.7)

0

In this case the unit assignment probability is equal to 1/2 for the first two units,

p2(X, Y(0), Y(1)) = p2(X, Y(0), Y(1)) = 1/2,

and, for unit 3, equal to

 0 p3(X, Y(0), Y(1)) = 11/2

if Y1(0) > Y2(1) and Y1(1) < Y2(0), if Y1(1)  Y2(0) and Y1(0)  Y2(1), otherwise.

Because the covariates identify the unit, the propensity score is equal to the unit assignment probabilities. Thus, for x = 1 and x = 2 the propensity score is equal to 1/2. If x = 3, the propensity score is equal to p3(X, Y(0), Y(1)).

3.4 RESTRICTIONS ON THE ASSIGNMENT MECHANISM
Before classifying the various types of assignment mechanisms that are the basis of the organization of this text, we present three general properties that assignment mechanisms may satisfy. These properties restrict the dependence of the unit-level assignment probabilities on values of covariates and potential outcomes for other units, or restrict the range of values of the unit-level assignment probabilities, or restrict the dependence of the assignment mechanism on potential outcomes.
The first property we consider is individualistic assignment, which limits the dependence of the treatment assignment for unit i on the outcomes and assignments for other units:

38

A Classification of Assignment Mechanisms

Definition 3.4 (Individualistic Assignment) An assignment mechanism Pr(W|X, Y(0), Y(1)) is individualistic if, for some function q( · )  [0, 1],

pi(X, Y(0), Y(1)) = q(Xi, Yi(0), Yi(1)), for all i = 1, . . . , N,

and
N
Pr(W|X, Y(0), Y(1)) = c · q(Xi, Yi(0), Yi(1))Wi (1 - q(Xi, Yi(0), Yi(1)))1-Wi ,
i=1
for (W, X, Y(0), Y(1))  A, for some set A, and zero elsewhere (c is the constant that ensures that the probabilities sum to unity).

Individualistic assignment is violated in sequential experiments such as Example 4. Given individualistic assignment, the propensity score simplifies to:

1

e(x)

=

Nx

q(Xi, Yi(0), Yi(1)).
i:Xi=x

Next, we define probabilistic assignment, which requires every unit to have positive probability of being assigned to treatment level 0 and to treatment level 1:

Definition 3.5 (Probabilistic Assignment) An assignment mechanism Pr(W|X, Y(0), Y(1)) is probabilistic if the probability of assignment to treatment for unit i is strictly between zero and one:

0 < pi(X, Y(0), Y(1)) < 1, for each possible X, Y(0), Y(1),
for all i = 1, . . . , N.
Note that this merely requires that every unit has the possibility of being assigned to the active treatment and the possibility of being assigned to the control treatment.
The third property is a restriction on the dependence of the assignment mechanism on potential outcomes:
Definition 3.6 (Unconfounded Assignment) An assignment mechanism is unconfounded if it does not depend on the potential outcomes:

Pr(W|X, Y(0), Y(1)) = Pr(W|X, Y (0), Y (1)),

for all W, X, Y(0), Y(1), Y (0), and Y (1).
If an assignment mechanism is unconfounded, we can drop the two potential outcomes as arguments and write the assignment mechanism as Pr(W|X). The assignment mechanisms in Examples 1 and 2 are, but those in in Examples 3 and 4 are not, unconfounded.

3.5 Assignment Mechanisms and Super-Populations

39

The combination of unconfoundedness and individualistic assignment plays a very important role. In that case,

N
Pr(W|X, Y(0), Y(1)) = c · q(Xi)Wi · (1 - e(Xi))1-Wi .
i=1

(3.8)

so that

e(x) = q(x),

so that the assignment mechanism is the product of the propensity scores. Note that, under unconfoundedness, the propensity score is no longer just the average assignment probability for units with covariate value Xi = x; it can also be interpreted as the unitlevel assignment probability for such units.
Given individualistic assignment, the combination of probabilistic and unconfounded assignment is referred to as strongly ignorable treatment assignment (Rosenbaum and Rubin, 1983a). More generally, ignorable treatment assignment refers to the weaker restriction where the assignment mechanism can be written in terms of W, X, and Yobs only, without dependence on Ymis (Rubin, 1978).

3.5 ASSIGNMENT MECHANISMS AND SUPER-POPULATIONS
In part of this text we view our sample of size N as a random sample from an infinite super-population. In that case we employ slightly different formulations of the restrictions on the assignment mechanism. Sampling from the super-population generates a joint sampling distribution on the quadruple of unit-level variables (Yi(0), Yi(1), Wi, Xi), i = 1, . . . , N. More explicitly, we assume the (Yi(0), Yi(1), Wi, Xi) are independently and identically distributed draws from a distribution indexed by a global parameter. We write this in factored form as
fW|Y(0),Y(1),X(Wi|Yi(0), Yi(1), Xi, ) · fY(0),Y(1)|X(Yi(0), Yi(1)|Xi,  ) · fX(Xi|), (3.9)
where the parameters are in their respective parameter spaces, and the full parameter vector is (, , ), where each of these components is generally a function of the global parameter.
In this setting we define the propensity score as
Definition 3.7 (Super-Population Propensity Score) The propensity score at x is the population average unit assignment probability for units with Xi = x,
e(x) = ESP fW|Y(0),Y(1),X(1|Yi(0), Yi(1), Xi, )fY(0),Y(1)|X(Yi(0), Yi(1)|Xi,  ) Xi = x ,
for all x in the support of Xi; e(x) is here a function of , a dependence that we usually suppress notationally.

40

A Classification of Assignment Mechanisms

The "SP" subscript on the expectations operator indicates that the expectation is taken over the distribution generated by random sampling. In this case the expectation is taken over the potential outcomes (Yi(0), Yi(1)). By iterated expectations the propensity score in the super-population setting is also equal to Pr(Wi = 1|Xi = x, , ) where the probability is taken both over the assignment mechanism and over the random sampling.
Note that with our definition of super-populations the assignment mechanism is automatically individualistic (of course, given (, )).
Definition 3.8 (Super-Population Probabilistic Assignment) An assignment mechanism is super-population probabilistic if the probability of assignment to treatment for unit i is strictly between zero and one:
0 < fW|Y(0),Y(1),X(1|Yi(0), Yi(1), Xi, ) < 1, for each possible Xi, Yi(0), Yi(1).

Definition 3.9 (Super-Population Unconfounded Assignment) An assignment mechanism is super-population unconfounded if it does not depend on the potential outcomes:
fW|Y(0),Y(1),X(w|y0, y1, x, ) = fW|Y(0),Y(1),X(w|y0, y1, x, ),
for all y0, y1, x, y0, y1, , and for w = 0, 1.

3.6 RANDOMIZED EXPERIMENTS
Part II of this text deals with the inferentially most straightforward class of assignment mechanisms, randomized assignment. Randomized experimental designs have traditionally been viewed as the most credible basis for causal inference, as reflected in the typical reliance of the U.S. Food and Drug Administration on such experiments in its approval process for pharmaceutical treatments.
Definition 3.10 (Randomized Experiment) A randomized experiment is an assignment mechanism that
(i) is probabilistic, and (ii) has a known functional form that is controlled by the researcher.
In Part II of this text we will be concerned with a special case ­ what we call classical randomized experiments:
Definition 3.11 (Classical Randomized Experiment) A classical randomized experiment is a randomized experiment with an assignment mechanism that is
(i) individualistic, and (ii) unconfounded.
The definition of a classical randomized experiment rules out sequential experiments as in Example 4. In sequential experiments, the assignment for units assigned in a later

3.7 Observational Studies: Regular Assignment Mechanisms

41

stage of the experiment generally depends on observed outcomes for units assigned

earlier in the experiment.

A leading case of a classical randomized experiment is a completely randomized

experiment, where, a priori, the number of treated units, Nt, is fixed (and thus the number of control units Nc = N - Nt is fixed as well). In such a design, Nt units are randomly

selected, from a population of N units, to receive the active treatment, with the remaining

Nc assigned to the control group. In this case, each unit has unit assignment probability

q = Nt/N, and the assignment mechanism equals



1 Pr(W|X, Y(0), Y(1)) = 0

N Nt

if

N i=1

Wi

=

Nt,

otherwise,

where the number of distinct values of the assignment vector with Nt units out of N assigned to the active treatment is

N Nt

=

Nt!

·

N! (N -

, Nt)!

with J! = J(J - 1) . . . 1.

Other prominent examples of classical randomized experiments include stratified randomized experiments and paired randomized experiments, discussed in Chapters 9 and 10.

3.7 OBSERVATIONAL STUDIES: REGULAR ASSIGNMENT MECHANISMS
In Parts III and IV of this text, we discuss cases where the exact assignment probabilities may be unknown to the researcher, but the researcher still has substantial information concerning the assignment mechanism. For instance, a leading case is where the researcher knows the set of variables that enters into the assignment mechanism but does not know the functional form of the dependence. Such information will generally come from subject-matter knowledge. For example, medical decisions in some situations are made solely using patients' medical records, but precisely how may be unknown. In general we refer to designs with unknown assignment mechanisms as observational studies:
Definition 3.12 (Observational Study) An assignment mechanism corresponds to an observational study if the functional form of the assignment mechanism is unknown.
The special case of an assignment mechanism that is the focus of Part III of the book is a regular assignment mechanism:
Definition 3.13 (Regular Assignment Mechanism) An assignment mechanism is regular if
(i) the assignment mechanism is individualistic, (ii) the assignment mechanism is probabilistic, and (iii) the assignment mechanism is unconfounded.

42

A Classification of Assignment Mechanisms

If, in addition, the functional form of a regular assignment mechanism is known, the assignment mechanism corresponds to a classical randomized experiment. If the functional form is not known, the assignment mechanism corresponds to an observational study with a regular assignment mechanism.
In Part III of this book we focus on the design stage of studies where the assumption of a regular assignment mechanism is viewed as plausible. In this design stage we focus on the data on treatment assignment and pre-treatment variables only, without seeing the outcome data. The concern at this stage is balance in the covariate distributions between treated and control groups. In completely and stratified randomized experiments, balance is guaranteed by design, but in observational studies this needs to be done by special analyses. We assess balance, and in cases where initially there is insufficient balance, we develop methods for improving balance.
In Part IV we discuss methods of analysis for causal inference with regular assignment mechanisms in some detail. Even if in many cases it may appear too strong to assume that an assignment mechanism is regular, we will argue that, in practice, it is a very important starting point for many studies. There are two main reasons for this. The first is that in many well-designed observational studies, researchers have attempted to record all the relevant covariates, that is, all the variables that may be associated with both outcomes and assignment to treatment. If they have been successful in this endeavor, or at least approximately so, a regular assignment mechanism may be a reasonable approximation to the true assignment mechanism. The second reason is that specific alternatives to regular assignment mechanisms are typically even less credible. Under a regular assignment mechanism, it will be sufficient to adjust appropriately for differences between treated and control units' covariate values to draw valid causal inferences. Any alternative method involves causal interpretations of comparisons of units with different treatments who also are observed to differ systematically in their values for covariates. It is relatively uncommon to find a convincing argument in support of such alternatives, although there are some notable exceptions, such as instrumental variables analyses discussed in Part VI of the book. More details of these arguments are presented in Chapter 12.

3.8 OBSERVATIONAL STUDIES: IRREGULAR ASSIGNMENT MECHANISMS
In Part VI of this book, we discuss another class of assignment mechanisms. We focus on settings where assignment to treatment may differ for some units from the receipt of treatment. We assume that assignment to treatment itself is unconfounded, but allow receipt of treatment to be confounded. This class of assignment mechanisms includes noncompliance in randomized experiments and sometimes utilizes instrumental variables analyses. Often in these designs, the receipt of treatment can be viewed as "latently regular" ­ that is, it would be regular given some additional covariates that are not fully observed. To conduct inference in such settings, it is often useful to invoke additional conditions, in particular exclusion restrictions, which rule out the presence of particular causal effects.

Notes

43

The remainder of this text provides more detailed discussion of methods of causal inference given each of these types of assignment mechanisms. In the next part of the book, Chapters 4­11, we start with classical randomized experiments.

3.9 CONCLUSION
This chapter presented the taxonomy of assignment mechanisms that serves as the organizing principle for this text. Using three restrictions on the assignment mechanism ­ individualistic assignment, probabilistic assignment, and unconfoundedness ­ we define regular assignment mechanisms and the special case of classical randomized experiments. In the next part of the book, we study classical randomized experiments, followed in Parts III and IV by the study of observational studies with regular assignment mechanisms. In Parts V and VI of the text we analyze some additional assignment mechanisms where receipt of treatment is confounded.

NOTES
Of the restrictions on assignment mechanisms we discuss in the current chapter, the first one, individualistic assignment, is often made implicitly, but the term is new. The notion of probabilistic assignment is often stated formally, although it is rarely given a formal label. The term unconfoundedness was coined by Rubin (1990a). It is sometimes referred to as the conditional independence assumption (Lechner, 2001; Angrist and Pischke, 2009). In the econometrics literature it is also closely related to the notion of exogeneity (Manski, Sandefur, McLanahan, and Powers, 1992), although formal definitions of exogeneity do not coincide with unconfoundedness (see Imbens, 2004, for some discussion). The combination of probabilistic assignment and unconfoundedness is referred to as Strong Ignorability or Strongly Ignorable Treatment Assignment by Rosenbaum and Rubin (1984). There is a close link between some of the assumptions used in the context of causal inference and the terminology in missing data problems. In the missing data literature, strong ignorability is closely linked with Missing at Random missingness mechanisms (Rubin, 1976c; Little and Rubin, 2002; Frumento, Mealli, Pacini, and Rubin, 2012).
Instrumental variables methods originate in the econometrics literature and go back to the 1920s and 1940s (P. Wright, 1928; S. Wright 1921, 1923; Tinbergen, 1928; Haavelmo, 1943). For a historical perspective, see Stock and Trebbi (2003) and Imbens (2014). For modern approaches see Imbens and Angrist (1994), and Angrist, Imbens, and Rubin (1996). For textbook discussions, see Wooldridge (2010) and Angrist and Pischke (2008).
Some methods for assignment mechanisms not covered in this edition of the book include Principal Stratification, Regression Discontinuity Designs, Difference In Differences methods, and case-control designs. The notion of Principal Stratification generalizes the binary-treatment version of instrumental variables. It was introduced by Frangakis and Rubin (2002). Regression discontinuity designs originate in the

44

A Classification of Assignment Mechanisms

psychology literature (Thistlewaite and Campbell, 1960). See for a historical overview Cook (2008), and for recent surveys Imbens and Lemieux (2008) and Lee and Lemieux (2010). Difference in Differences (DID) methods are another set of methods intended for irregular designs. DID methods are widely used in the econometric literature. See Angrist and Pischke (2008) for a general discussion and references. Case-control designs, more accurately called case-noncase designs, are commonly used in epidemiology, especially when looking for exposures that lead to rare diseases (i.e., the cases).

PART II
Classical Randomized Experiments

CHAPTER 4
A Taxonomy of Classical Randomized Experiments
4.1 INTRODUCTION
In this chapter we introduce four specific examples of classical randomized assignment mechanisms, and we relate these examples to the general taxonomy of assignment mechanisms described in the previous chapter. The four examples, Bernoulli trials, completely randomized experiments, stratified randomized experiments (randomized blocks), and paired randomized experiments, all satisfy the four criteria necessary for assignment mechanisms to be classified as classical randomized experiments. These criteria, as discussed in more detail in Chapter 3, require that the assignment mechanism (i) is individualistic, with the dependence on values of covariates and potential outcomes for other units limited; (ii) is probabilistic ­ each experimental unit has a positive probability of being assigned to the active treatment and a positive probability of being assigned to the control treatment; (iii) is unconfounded ­ that is, given covariates, does not depend on potential outcomes; and (iv) has a known functional form that is controlled by the researcher.
The key difference between the four types of classical randomized experiments we consider in this chapter is in the set of assignment vectors W (the N-dimensional vector with elements Wi  {0, 1}) with positive probability. Let the set of all possible values be denoted by W = {0, 1}N, with cardinality 2N, and let the subset of values for W with positive probability be denoted by W+. In the first example of randomized experiments, Bernoulli trials, each of the 2N possible vectors W defining the treatment assignments of the full population of size N has positive probability. However, such trials put positive probability on assignments in which all units receive the same treatment, thereby compromising our ability to draw credible and precise inferences regarding the causal effect of one treatment versus another from the resulting data. The remaining three types of classical randomized experiments impose increasingly restrictive sets of conditions on the set W+ of values of W with positive probability. If imposed judiciously, these restrictions can lead to more precise inferences by reducing the possibility of unhelpful assignment vectors (i.e., assignment vectors that a priori are unlikely to lead to useful inferences regarding the causal effects of interest).
47

48
4.2 NOTATION

A Taxonomy of Classical Randomized Experiments

In this section we briefly review the definition of, and notation for, classical randomized experiments, introduced in Chapter 3. The requirements for classical randomized experiments are that the assignment mechanism must be individualistic, probabilistic, and unconfounded and that the assignment mechanism is known to and controlled by the researcher. As a result of the first and third conditions, by Theorem 3.1, the assignment mechanism in a classical randomized experiment can be written as

N
Pr(W|X, Y(0), Y(1)) = c · e(Xi)Wi · (1 - e(Xi))1-Wi ,
i=1
for W  W+, and zero elsewhere. Here W+  W is the subset of the set of possible values for W with positive probability, and e(x) is the propensity score, which, by probabilistic assignment, is strictly between zero and one. The constant c ensures that the probabilities add to unity:

N

-1

c=

e(Xi)Wi · (1 - e(Xi))1-Wi .

WW+ i=1

Because of the fourth condition, the propensity score e(x) is a known function of the covariates. In this chapter we discuss four common classes of assignment mechanisms that fit into this framework: Bernoulli trials, completely randomized experiments, stratified randomized experiments, and pairwise randomized experiments.

4.3 BERNOULLI TRIALS

The simplest Bernoulli experiment tosses a fair coin for each unit: if the coin is heads, the unit is assigned the active treatment, and if it is tails, the unit is assigned the control treatment. Because the coin is fair, the unit-level probabilities and the propensity scores are all 0.5. Because the tosses are independent, the probability of any W for the N units in the study is the product of the individual probabilities; thus

Pr(W|X, Y(0), Y(1)) = 0. 5N,

(4.1)

for all W  W+. Here W+ = {0, 1}N = W. Slightly more generally, we allow the probability of assignment to the treatment ­ that
is, the propensity score ­ to be different from 1/2, say q  (0, 1). Then Equation (4.1) becomes

Pr(W|X, Y(0), Y(1)) = qNt · (1 - q)Nc ,

(4.2)

where Nt =

N i=1

Wi,

and

Nc

=

N

- Nt

=

N i=1

(1

-

Wi)

are

the

number

of

treated

and control units, respectively. Here, the probabilities of the different W vectors depend

4.3 Bernoulli Trials

49

solely on the number of treated and control units, but still W+ = {0, 1}N. Such an assignment mechanism, where say, q  (0. 5, 1), may be attractive, for example, when trying to induce people with a serious disease to enroll in a placebo-controlled experiment of a promising new drug for that disease. When the probability of assignment to the treatment group is higher than the probability of assignment to the control group, it would be more attractive for individuals to enroll in this trial than in one where the placebo or control treatment is as likely to be assigned as the active treatment.
Our final generalization of Bernoulli trials allows the unit probabilities to vary with the unit's covariate values. This situation can occur, for example, when certain types of patients are thought to do better on one treatment than another, and the strength of this belief about the better treatment varies with characteristics of the person (e.g., age, sex, race). Here, each unit has a special coin tossed, with the probability that the coin comes up heads equal to the probability that the unit is treated: the unit's propensity score. Consequently,

N
Pr(W|X, Y(0), Y(1)) = e(Xi)Wi · (1 - e(Xi))1-Wi .
i=1

(4.3)

Here again W+ = W. Our formal definition of a Bernoulli trial requires that assignments to treatment are independent across all units in the population:

Definition 4.1 (Bernoulli Trial) A Bernoulli trial is a classical randomized experiment with an assignment mechanism such that the assignments for all units are independent.

Theorem 4.1 (Assignment Mechanism for a Bernoulli Trial) If the assignment mechanism is a Bernoulli trial, then

N
Pr(W|X, Y(0), Y(1)) = e(Xi)Wi · (1 - e(Xi))1-Wi ,
i=1
where e(x) is the propensity score, which must be strictly between zero and one for all i, implying W+ = {0, 1}N.

Proof. If assignment to treatment is independent across all observations in the population, then the probability of observing a specific assignment vector W, Pr(W|X, Y(0), Y(1)), will simply equal the product of each unit's probability of assignment:

N
Pr(W|X, Y(0), Y(1)) = pi(X, Y(0), Y(1))Wi · (1 - pi(X, Y(0), Y(1)))1-Wi .
i=1
Combined with the fact that pi(X, Y(0), Y(1)) = e(Xi) for all i, implied by the fact that a Bernoulli trial is a classical randomized experiment, it follows that the normalizing constant is c = 1 and that the general form of the assignment mechanism for this type of

50

A Taxonomy of Classical Randomized Experiments

randomized experiment is

N
Pr(W|X, Y(0), Y(1)) = e(Xi)Wi · (1 - e(Xi))1-Wi ,
i=1

as in Equation (4.3).

2

One common disadvantage of Bernoulli trials is that, because of the independence of the assignment across all units, there is always a positive probability (although small even in modest samples, and essentially zero in large samples) that all units will receive the same treatment. In that case, there will be no evidence in the data about the potential outcome values under the treatment that is not represented in the data. Even when there is a single unit being assigned one treatment and many assigned the other treatment, there will be limited evidence about the potential outcomes under the former treatment. Next, we therefore consider alternative classical randomized experiments that ensure that there are "enough" treated and control units under each assignment, beginning with the completely randomized experiment.

4.4 COMPLETELY RANDOMIZED EXPERIMENTS

In the second design we consider, the completely randomized experiment, a fixed number

of subjects is assigned to receive the active treatment. The simplest completely random-

ized experiment takes an even number of units and divides them at random in two groups,

with exactly one-half of the sample receiving the active treatment and the remaining units

receiving the control treatment. This is accomplished, for example, by putting labels for

the N units in an urn and drawing Nt = N/2 at random to be treated. The assignment

mechanism is:

 

N

-1

Pr(W|X, Y(0), Y(1)) = 0 Nt

if

N i=1

Wi

=

Nt,

otherwise,

(4.4)

where

N=

N! .

Nt Nt!(N - Nt)!

The notation in (4.4) reveals that Nt does not have to equal N/2, but can be any positive integer less than N, fixed in advance. These designs are common in many applied settings, both because they assure that some units will be assigned each treatment, and because analyses using such designs are particularly straightforward in many circumstances. One reason for this simplicity is that the propensity scores are equal for all units, namely Nt/N.

Definition 4.2 (Completely Randomized Experiment) A completely randomized experiment is a classical randomized experiment with an assignment mechanism satisfying

4.5 Stratified Randomized Experiments

51

N
W+ = W  W Wi = Nt ,
i=1

for some preset Nt  {1, 2, . . . , N - 1}.

In other words, given a population of size N, we fix the number of units assigned to

the treatment, Nt such that 1  Nt  N - 1. Out of the population of N, we draw Nt units at random to receive the treatment. Each unit therefore has probability q = Nt/N

of receiving the treatment. The number of possible assignment vectors, the cardinal-

ity of the set W+, is under this design

N . All Nt

N Nt

assignment vectors in

W+ are equally likely; thus, the probability for any one is equal to

N -1 , whence

Nt

in completely randomized experiments, the assignment mechanism is given by

Equation (4.4).

Although often very sensible, completely randomized experiments are not without

drawbacks, especially when important covariates are available. Important covariates here

means covariates a priori thought to be possibly highly associated with the potential out-

comes. Consider, for example, a study with N = 20 units, ten men and ten women, where

the potential treatment and control outcomes are a priori thought to vary substantially

by sex. Then, although a completely randomized design with Nt = 10 would ensure that

ten units get treated, there is the possibility that all ten of them are men (or women). In

that case, average differences in the potential outcomes for active and control treatments

could be due to sex differences rather than treatment effects. Related complications with

relatively unhelpful (in the sense of being uninformative) experiments occur when only

a single man is treated and nine men are in the control group, and so forth. The design

studied in the next section addresses this issue in some circumstances.

4.5 STRATIFIED RANDOMIZED EXPERIMENTS
With the stratified randomized experiment, the population of units in the study is first partitioned into blocks or strata so that the units within each block are similar with respect to some (functions of) covariates thought to be predictive of potential outcomes. Then, within each block, we conduct a completely randomized experiment, with assignments independent across blocks.
The simplest randomized block experiment involves two blocks, say males and females, where independent completely randomized experiments are conducted for each group. There is no requirement that the numbers of males and females are the same. Thus, the assignment mechanism is the product of one expression like (4.4) for males, with N(m) and Nt(m) replacing N and Nt, and one expression like (4.4) for women, with N(f ) and Nt(f ) replacing N and Nt, with the experiment having a total of Nt(m) + Nt(f ) units assigned to the active treatment and has a total of N(m) + N(f ) - Nt(m) - Nt(f ) units assigned to the control treatment.
In general, more strata can be used. Let Bi  {1, . . . , J} indicate the block or stratum of the ith unit, with Bi = B(Xi) a function of the pre-treatment variables Xi, with a total

52

A Taxonomy of Classical Randomized Experiments

of J blocks or strata, and let Bi(j) be the binary indicator for the event Bi = j. Then the assignment mechanism is the product of J versions of expression (4.4), each version having N and Nt indexed by the J distinct values of Bi  {1, . . . , J}. The unit-level probabilities are common for all units within a block but can vary across blocks. The main reason for generally preferring randomized blocks designs to completely randomized designs is that the former designs control balance in the covariates used to define blocks in treatment and control groups.
Formally, our definition of stratified randomized experiments is as follows:

Definition 4.3 (Stratified Randomized Experiment)

A stratified randomized experiment with J blocks is a classical randomized experiment

with an assignment mechanism satisfying







N



W+ = W  W

Wi = Nt(j), for j = 1, 2, . . . , J  ,

i:Bi=j

and





J j=1

Pr(W|X, Y(0), Y(1)) =  0

N(j) Nt(j)

-1
if W  W+,
otherwise,

for some preset Nt(j) such that Nj > Nt(j) > 0, for j = 1, . . . , J.
In this setting, the unit-level assignment probability or, equivalently in our situation with a classical randomized experiment, the propensity score, e(Xi), is equal to Nt(j)/N(j) for all units with Bi = j. As this representation makes explicit, this probability can vary with the stratum indicator. Often, however, the unit-level assignment probabilities are identical across the strata so that e(x) = q for all x. In this case, the only difference between the stratified and completely randomized experiment is that in the former the relative sample size for treatment and control groups is constant across strata, whereas in the latter it may vary. If the covariates defining Bi corresponds to substantive information about the units, in the sense that Bi is predictive of the potential outcomes, (Yi(0), Yi(1)), randomizing within the strata will lead to more precise inferences by eliminating the possibility that all or most units of a certain type, as defined by the blocks, are assigned to the same level of the treatment. Furthermore, even if there is no predictive power of the blocking indicator Bi, stratification does not reduce actual precision, though it reduces the number of allowable values of the assignment vector; see the notes to this chapter for some additional comments on this issue.

4.6 PAIRED RANDOMIZED EXPERIMENTS
The paired comparison, or randomized paired design, is an extreme version of the randomized block experiment in which there are exactly two units within each block, and a fair coin is tossed to decide which member of the pair gets the active treatment and

4.7 Discussion

53

which gets the control treatment. As an example, consider an educational experiment with a covariate, a pre-test score, and the students are ranked from high to low on their scores on this pre-test. The top two form the first pair, the next two form the next pair, and so forth. Within each pair, one of the two units is randomly assigned to the treatment, with the probability of assignment equal to 1/2.

Definition 4.4 (Paired Randomized Experiment)

A paired randomized experiment is a stratified randomized experiment with N(j) = 2

and Nt(j) = 1 for j = 1, . . . , N/2, so that







N



W+ = W  W

Wi = 1, for j = 1, 2, . . . , N/2  ,

i:Bi=j

and

 

2-N/2

Pr(W|X, Y(0), Y(1)) =  0

if W  W+, otherwise.

In this design, each unit has probability 1/2 of being assigned to the treatment group.

4.7 DISCUSSION

All four types of designs described in this chapter satisfy the four conditions for classi-

cal randomized experiments. In each case the assignment mechanism is individualistic,

probabilistic, unconfounded, and known to the researcher. The way in which these four designs differ is in the set of values allowed for the vector of treatment indicators, W+.

Reducing this set can be of great importance for the precision of estimated treatment

effects. To illustrate this, consider the following example. Let N be even, and let the

single pre-treatment variable Xi take on N/2 different values, with the number of units with Xi = x equal to 2 for all x  {1, . . . , N/2}. Also assume identical unit-level assignment probabilities, that is, a constant propensity score, e(x) = 1/2 for all x. In Table 4.1

we report the number of values for the assignment vector that have positive probability

under the various types of randomized experiments, for different sample sizes. First, consider a Bernoulli trial. In this case, there are 2N different values for the

assignment vector. The first row in Table 4.1 shows that with N = 4 units, this cor-

responds to 16 assignment vectors. With N = 16, the number of possible treatment

assignment combinations increases to more than 65,000.

Next consider a completely randomized experiment with Nt = N/2 units assigned

to treatment and Nc = N/2 assigned to control. The number of allowed values for the

assignment vector is now

N N/2

,

which

is

strictly

less

than

the

2N

values

allowed

under

the Bernoulli design. With N = 4 units, we now have only six possible assignment vec-

tors; with a sample of N = 16, we have 12,870 possible assignment vectors, or roughly

one-fifth the number possible with the Bernoulli trial.

54

A Taxonomy of Classical Randomized Experiments

Table 4.1. Number of Possible Values for the Assignment Vector by Design and Sample Size

Type of Experiment and Design
Bernoulli trial Completely randomized experiment Stratified randomized experiment Paired randomized experiment

Number of Possible
Assignments Cardinality of W+

Number of Units (N) in Sample

4

8

16

32

2N

16 256 65,536 4.2 × 109

N N/2

6 70 12,870 0.6 × 109

2
N/2 N/4

4 36

4,900 0.2 × 109

2N/2

4 16

256 65,536

Third, consider a randomized block design, with two blocks, each consisting of N/2 units. Given our data set of N observations with the number of units with Xi = x equal to 2 for all x = 1, . . . , N/2, let the first block consist of all units with Xi  N/4, and the second block consist of the remainder. In terms of the notation introduced in
Section 4.5,

Bi =

1 2

if Xi  N/4, if Xi > N/4.

Suppose that within each block, the number of units assigned to the treatment group is

equal to the number of units assigned to the control group, N/4. Now the number of val-

ues for the assignment vector within the first block is

N/2 N/4

, where this assignment vector

W(1) has N/2 components. In the second block the number of units is the same, N/2,

so that the assignment vector for this block is also an N/2 component vector, W(2), and

the number of possible assignment vectors is again

N/2 N/4

.

Therefore,

the

total

number

of values for the full assignment vector, W = (W(1), W(2)), possible under this design is

the product of the within-block number of possibilities,

N/2 N/4

2
. Note that this

is

a strict

subset of the set of possible values under the previous two designs. With N = 4 units,

we now have only 4 possible assignment vectors; with a sample of 16, the number of

possible assignment vectors is 4,900.

Fourth, consider the paired randomized experiment where units with the same value of Xi are paired, so Bi = Xi. Now there will be 2N/2 different possible values of the assign-

ment vector with positive probability. This design is a randomized block experiment in

which each stratum (block, or subclass) contains only two units. This assignment mech-

anism is also a paired randomized experiment. Note also that in a paired randomized

experiment, using the same argument as above, any value of the assignment vector with

positive probability under this design also has positive probability under the stratified

randomized design. With only 4 units, the number of assignment vectors with positive

probability under a paired randomized experiment is, in fact, identical to that with pos-

sible probability under a stratified randomized experiment. With only N = 4 units, in the

4.8 Conclusion

55

stratified design there can be at most 2 strata, each with the 2 units of a pair, and within each, only one observation assigned to the treatment. With 16 units, however, under a paired randomized experiment there are 256 assignment vectors with positive probability, compared to the 4,900 with positive probability under a randomized block design with two blocks, or a total of 65,536 values for the assignment vector with positive probability under the Bernoulli design.
In this particular sequence of designs with fixed N, the number of distinct values of the assignment vector with positive probability, that is, the cardinality of the set W+, gradually decreases. The argument for choosing successively more restrictive designs is to eliminate "unhelpful" assignment vectors that are a priori unlikely to lead to precise causal inferences. Imposing the first restriction ­ from Bernoulli trials to completely randomized experiments ­ is obvious. An assignment vector with all, or almost all, units assigned to one of the treatment levels is typically not as informative as an assignment vector with more balance between the number of treated and control units. Hence, a completely randomized design will tend to be more informative than a Bernoulli trial. The further restrictions to stratified and paired randomized experiments have similar advantages, when the grouping into strata or pairs is based on covariates that are related to the potential outcomes. Formally, if the information used in defining the blocks or pairs is relevant for predicting the potential outcomes, (Yi(0), Yi(1)), then these designs can improve on completely randomized experiments in terms of the precision of the estimates obtained, often considerably so. In an extreme case, if the pre-treatment variable, Xi, upon which the stratification or pairing is based, perfectly predicts both potential outcomes, there will be no uncertainty remaining regarding the treatment effect across the N units or within the subgroups defined by the covariate. On the other hand, if the blocks or pairs are formed in a way unrelated to the potential outcomes (e.g., by randomly drawing units to assign block labels Bi), the eliminated assignment vectors are just as likely to be helpful as the retained ones, and in such cases, the precision of estimators for treatment effects in stratified or paired randomized experiments is usually no greater than that for the corresponding estimators under completely randomized experiments.
In the next chapters, we discuss analyzing results from the various types of classical randomized experiments in more detail and illustrate these analyses with real data. The methods for analyzing these randomized experiments are useful for two major reasons. First, they are valuable in their own right for analyzing randomized experiments. For many questions in the biomedical and social sciences, however, we must rely on data from observational studies. The second use of these methods, as templates for the analysis of data from observational studies, are therefore even more important for us. In Parts III through VI of this text, we extend these methods for analyzing specific types of classical randomized experiments to assessing data from observational studies and show that observational data can often be analyzed as if they fit the assumptions of one of the randomized experiments discussed here.

4.8 CONCLUSION
In this chapter we discuss four special cases of classical randomized experiments: Bernoulli trials, completely randomized experiments, stratified randomized experiments,

56

A Taxonomy of Classical Randomized Experiments

and paired randomized experiments. In the next seven chapters we discuss and illustrate methods for estimation and inference in these settings. This is important for substantive reasons but also because understanding the analysis of such relatively simple cases is important for analyzing the more complex observational studies that are the subject of Parts III through VI of this text.

NOTES
There is a large classical literature on experimental design and the analyses of randomized experiments, including Cochran and Cox (1957), Cox (1958), Kempthorne (1952), and Box, Hunter, and Hunter (2005). Much of the design literature focuses on the optimal design of more complex studies with multiple treatments. Such questions are beyond the scope of the current text. Rosenbaum (2000) discusses the structure of the set of assignment vectors using results for finite distributive lattices. Morgan and Rubin (2012) discuss an additional class of designs for randomized experiments. The idea is to start with a completely randomized design. Then, given the assignments, balance of the covariates is assessed according to some well-defined criterion, articulated prior to the randomization. If the balance is deemed inadequate, the assignment is rejected and a new vector of assignments is drawn. This is repeated until an assignment vector is drawn that is deemed adequately balanced. Such designs can lead to more precise inferences than completely randomized designs, and they can be more attractive than stratification in settings with many covariates. A similar but different design is described by Morris (1979).
For general discussions of the literature on analyses of randomized experiments, see Altman (1991), Wu and Hamada (2009), Cook and DeMets (2008), Davies (1954), Cox (1958), Cochran and Cox (1957), Kempthorne (1957), and Box, Hunter, and Hunter (2005).
Imbens (2011) analyzes the gains from the stratification and shows that even in the absence of any dependence between the potential outcomes and the stratum indicators, stratification, in expectation, in settings with random draws from large strata, does not increase the actual sampling variance of simple estimators of the average treatment effect, thus showing that there is no cost in expected precision of estimation when using stratification even when the samples drawn from the strata are small. There are, however, fewer "degrees of freedom" to estimate that precision, and so the resulting inference is somewhat less precise, an issue studied first in Fisher (1935, pp. 248­250) from a fiducial-likelihood perspective. Specifically, Fisher suggests using the expected information, that is, the expected second derivative of the log-likelihood to adjust for this effect by multiplying the estimated sampling variances by (K + 3)/(K + 1), where K is the number of degrees of freedom used to estimate each sampling variance. It is important here that the strata are large. If the strata are small in the population, it is possible that outcomes within strata are negatively correlated. Snedecor and Cochran (1967, p. 294) discuss examples where this may be relevant (e.g., rats' weights within a litter).

CHAPTER 5
Fisher's Exact P-Values for Completely Randomized Experiments
5.1 INTRODUCTION
As discussed in Chapter 2, Fisher appears to have been the first to grasp fully the importance of physical randomization for credibly assessing causal effects (1925, 1936). A few years earlier, Neyman (1923) had introduced the language and the notation of potential outcomes, using this notation to define causal effects as if the assignments were determined by random draws from an urn, but he did not take the next logical step of appreciating the importance of actually randomizing. It was instead Fisher who made this leap.
Given data from a completely randomized experiment, Fisher was intent on assessing the sharp null hypothesis (or exact null hypothesis, Fisher, 1935) of no effect of the active versus control treatment, that is, the null hypothesis under which, for each unit in the experiment, both values of the potential outcomes are identical. In this setting, Fisher developed methods for calculating "p-values." We refer to them as Fisher Exact P-values (FEPs), although we use them more generally than Fisher originally proposed. Note that Fisher's null hypothesis of no effect of the treatment versus control whatsoever is distinct from the possibly more practical question of whether the typical (e.g., average) treatment effect across all units is zero. The latter is a weaker hypothesis, because the average treatment effect may be zero even when for some units the treatment effect is positive, as long as for some others the effect is negative. We discuss the testing of hypotheses on, and inference for, average treatment effects in Chapter 6. Under Fisher's null hypothesis, and under sharp null hypotheses more generally, for units with either potential outcome observed, the other potential outcome is known; and so, under such a sharp null hypothesis, both potential outcomes are "known" for each unit in the sample ­ being either directly observed or inferred through the sharp null hypothesis.
Consider any test statistic T: a function of the stochastic assignment vector, W; the observed outcomes, Yobs; and any pre-treatment variables, X. As we discuss in more detail shortly, the fact that the null hypothesis is sharp allows us to determine the distribution of T, generated by the complete randomization of units across treatments. The test statistic is stochastic solely through the stochastic nature of the assignment vector. We refer to the distribution of the statistic determined by the randomization as the randomization distribution of the test statistic T. Using this distribution, we can compare
57

58

Fisher's Exact P-Values for Completely Randomized Experiments

the actually observed value of the test statistic, Tobs, against the distribution of T under the null hypothesis. An observed value that is "very unlikely," given the null hypothesis and the induced distribution for the test statistic, will be taken as evidence against the null hypothesis in what is, essentially, a stochastic version of the mathematician's "proof by contradiction."
How unusual the observed value is under the null hypothesis will be measured by the probability that a value as extreme or more extreme (in practice, as large or larger) would have been observed ­ the significance level or p-value. Hence, the FEP approach entails two steps: (i) the choice of a sharp null hypothesis (in Fisher's original version, always the null hypothesis of no effect whatsoever, but easily generalized to any sharp null hypothesis, that is, a null hypothesis that allows us to infer all the missing potential outcomes from the observed potential outcomes), and (ii) the choice of test statistic. The scientific nature of the problem should govern these choices. In particular, although in Fisher's analysis the null hypothesis was always the one with no treatment effect whatsoever, in general the null hypothesis should follow from the substantive question of interest. The statistic should then be chosen to be sensitive to the difference between the null and some alternative hypothesis that the researcher wants to assess for its scientific interest. That is, the statistic should be chosen to have, what is now commonly referred to as, statistical power against a scientifically interesting alternative hypothesis.
An important characteristic of this approach is that it is truly nonparametric, in the sense that it does not rely on a model specified in terms of a set of unknown parameters. In particular, we do not model the distribution of the outcomes: the vectors of potential outcomes Y(0) and Y(1) are regarded as fixed but a priori unknown quantities. The only reason that the observed outcomes, Yobs, and thus the statistic, Tobs, are random is that a stochastic assignment mechanism determines which of the two potential outcomes we observe for each unit. This assignment mechanism is, by definition, known for a classical randomized experiment. In addition, given the null hypothesis, all potential outcomes are known. Thus, we do not need modeling assumptions to calculate the randomization distribution of any test statistic; instead, the assignment mechanism completely determines the randomization distribution of the test statistic. The validity of any resulting p-value is therefore not dependent on assumptions concerning the distribution of the potential outcomes. This freedom from reliance on modeling assumptions does not mean, of course, that the values of the potential outcomes do not affect the properties of the test. These values will certainly affect the distribution of the p-value when the null hypothesis is false (i.e., the statistical power of the test). They will not, however, affect the validity of the test, which depends solely on the randomized assignment mechanism.
The remainder of this chapter begins with a brief description of the data that we will use to illustrate this approach. The data set is from a completely randomized evaluation of the effect of honey on nocturnal cough and resulting sleep quality for coughing children. Next, in Section 5.3, we start with a simple example using data from only six of the seventy-two children in the experiment. After that follows a detailed discussion of the two choices necessary for calculating FEPs: in Section 5.4 we discuss the choice of the null hypothesis, and in Section 5.5 we discuss the choice of the test statistic. In Section 5.6 we carry out a small simulation study to illustrate the properties of the method. Next, in Section 5.7 we discuss how the FEP approach can be extended to construct interval estimates. We then continue in Section 5.8 with a discussion of how to estimate,

5.3 A Simple Example with Six Units

59

Table 5.1. Summary Statistics for Observed Honey Data

Variable
Cough frequency prior to treatment (cfp) Cough frequency after treatment (cfa) Cough severity prior to treatment (csp) Cough severity after treatment (csa)

Mean
3.86 2.47 3.99 2.54

(S.D.)
(0.92) (1.61) (1.03) (1.74)

Mean Controls
3.73 2.81 3.97 2.86

Mean Treated
4.00 2.11 4.00 2.20

rather than calculate exactly, the p-value ­ the level of significance associated with a given observed value of the test statistic ­ when N is so large that such exact calculations are tedious at best and possibly infeasible. Next, in Section 5.9, we discuss how to use covariates to refine the choice of statistic. In Section 5.10, we expand the analysis to apply this approach to the full sample in which a random subset of the group of seventy-two children was given honey as a cough treatment. Section 5.11 concludes.
5.2 THE PAUL ET AL. HONEY EXPERIMENT DATA
The data used in this chapter are from a randomized experiment by Paul et al. (2007) on the evaluation of the effect of three treatments on nocturnal cough and sleep difficulties associated with childhood upper respiratory tract infections. The three treatments are (i) a single dose of buckwheat honey; (ii) a single dose of honey-flavored dextromethorphan, an over-the-counter drug; and (iii) no active treatment. The subjects were 105 children between two and eighteen years of age. Here we only use data on the N = 72 children receiving buckweat honey (Nt = 35) or no active treatment (Nc = 37). The authors measure six different outcomes. We focus on two of them, cough frequency afterwards (cfa), and cough severity afterwards (csa), referring to measures of cough frequency and severity the night after being randomly assigned or not to the administration of the treatment. Both outcomes are measured on a scale from zero ("not at all frequent/severe") to six ("extremely frequent/severe"). We also use two covariates, measured on the night prior to the randomized assignment: cough frequency prior (cfp) and cough severity prior (cfp), both measured on the same scale as the outcomes.
Table 5.1 presents some summary statistics (means and standard deviations, and means by treatment status) for the four observed variables (cfp, cfa, csp, csa), for the 72 children receiving honey or no active treatment in this study. In Table 5.2 we also present cumulative frequencies for the two outcomes variables (cfa and csa) by treatment group for the seven levels of the outcome scale.
5.3 A SIMPLE EXAMPLE WITH SIX UNITS
Initially let us consider, for relative ease of exposition and data display, a subsample from the honey data set, with six children. Table 5.3 gives the observed data on cough frequency for these six children in the potential outcome form. A key part of the table is the pair of columns listing the potential outcomes, observed and missing. The first child (unit 1) was assigned to the (buckwheat honey) treatment group (W1 = 1). Hence we

60

Fisher's Exact P-Values for Completely Randomized Experiments

Table 5.2. Cumulative Distribution Functions for Cough Frequency and Severity after Treatment Assignment for the Honey Study

Value
0 1 2 3 4 5 6

cfa

Controls

Treated

0.14

0.14

0.19

0.40

0.32

0.63

0.73

0.83

0.89

0.91

0.92

0.97

1.00

1.00

csa

Controls

Treated

0.16

0.17

0.22

0.46

0.35

0.54

0.59

0.77

0.86

0.91

0.95

0.94

1.00

1.00

Table 5.3. Cough Frequency for the First Six Units from the Honey Study

Unit

Potential Outcomes

Cough Frequency (cfa)

Yi(0)

Yi(1)

Observed Variables

Wi

Xi

Yiobs

(cfp)

(cfa)

1

?

2

?

3

?

4

4

5

0

6

1

3

1

4

3

5

1

6

5

0

1

4

0

?

0

4

4

?

0

1

0

?

0

5

1

observe Y1obs = Y1(1) (equal to 3 for this child). We do not observe Y1(0), and in the table this missing potential outcome is represented by a question mark. The second child was also assigned to the treatment (W2 = 1), and again we observe Y2obs = Y2(1) (equal to 5), and we do not observe Y2(0) (represented again by a question mark). Table 5.3 directly shows the fundamental problem of causal inference: many of the potential outcomes (in this particular case exactly half) are missing.
Using this subset of the honey data, we first calculate the p-value for the sharp null hypothesis that the treatment had absolutely no effect on coughing outcomes, that is:
H0 : Yi(0) = Yi(1) for i = 1, . . . , 6.
Under this null hypothesis, for each child, the missing potential outcomes, Yimis are identical to the observed outcomes for the same child, Yiobs, or Yimis = Yiobs for all i = 1, . . . , N. Thus, we can fill in all six of the missing entries in Table 5.3 using the observed data; Table 5.4 lists the fully expanded data set under Fisher's sharp null hypothesis. This step is the first key insight of the FEP approach; under the sharp null hypothesis, all the missing values can be inferred from the observed ones.

5.3 A Simple Example with Six Units

61

Table 5.4. Cough Frequency for the First Six Units from Honey Study with Missing Potential Outcomes in Parentheses Filled in under the Null Hypothesis of No Effect of the Treatment

Unit

Potential Outcomes

Cough Frequency (cfa)

Observed Variables

Yi(0)

Yi(1)

Treatment Xi Yiobs rank(Yiobs)

1

(3)

3

2

(5)

5

3

(0)

0

4

4

(4)

5

0

(0)

6

1

(1)

1

43

4

1

65

6

1

40

1.5

0

44

5

0

10

1.5

0

51

3

We use the absolute value of the difference in average outcomes by treatment status as our test statistic:

T(W, Yobs) = Tdif =

Y

obs t

-

Y

obs c

,

where

Y

obs t

=

i:Wi=1 Yiobs/Nt

and

Y

obs c

=

i:Wi=0 Yiobs/Nc are the average of

the observed outcomes in the treatment and control groups, respectively, and

Nc =

N i=1

(1

-

Wi)

and

Nt

=

N i=1

Wi

are

the

number

of

units

in

the

control

and

treat-

ment groups respectively. This test statistic is likely to be sensitive to deviations from

the null hypothesis corresponding to a constant additive effect of the treatment. For the

observed data in Table 5.3, the value of the test statistic is

T obs

=

T (W,

Yobs)

=

|Y

obs t

-

Y cobs |

= |(Y1obs + Y2obs + Y3obs)/3 - (Y4obs + Y5obs + Y6obs)/3| = |8/3 - 5/3| = 1.00.

Under the null hypothesis, we can calculate the value of this statistic under each vector

of treatment assignments, W. Suppose for example, that instead of the observed assignment vector Wobs = (1, 1, 1, 0, 0, 0), the assignment vector had been W~ = (0, 1, 1, 0, 0, 1).

That would not have changed any of the values of the observed outcomes Yiobs, because under the null hypothesis, for each unit, Yi(0) = Yi(1) = Yiobs, but it could have changed

the value of the test statistic because different units would have been assigned to

the treatment and control groups. For example, under the assignment vector, W~ =

(0, 1, 1, 0, 1, 0), the test statistic would have been T(W~ , Yobs) = |(Y2obs +Y3obs +Y5obs)/3- (Y1obs + Y4obs + Y6obs)/3| = |6/3 - 7/3| = 0. 33, different from Tobs = 1. 00. We

can repeat this calculation for each possible assignment vector. Given that we have a

population of six children with three assigned to treatment, there are

6 3

= 20 differ-

ent possible assignment vectors. Table 5.5 lists all twenty possible assignment vectors

for these six children. For the moment, focus on the first unit, i = 1. For all assign-

ment vectors, Y1obs remains the same, but given our null hypothesis of no effect, Y1obs is associated with Y1(0) for those assignment vectors with W1 = 0, and is associated

62

Fisher's Exact P-Values for Completely Randomized Experiments

Table 5.5. Randomization Distribution for Two Statistics for the Honey Data from Table 5.3

Statistic: Absolute Value of Difference in Average

W1 W2 W3 W4 W5 W6 Levels (Yi)

0

0

0

1

1

1

-1.00

0

0

1

0

1

1

-3.67

0

0

1

1

0

1

-1.00

0

0

1

1

1

0

-1.67

0

1

0

0

1

1

-0.33

0

1

0

1

0

1

2.33

0

1

0

1

1

0

1.67

0

1

1

0

0

1

-0.33

0

1

1

0

1

0

-1.00

0

1

1

1

0

0

1.67

1

0

0

0

1

1

-1.67

1

0

0

1

0

1

1.00

1

0

0

1

1

0

0.33

1

0

1

0

0

1

-1.67

1

0

1

0

1

0

-2.33

1

0

1

1

0

0

0.33

1

1

0

0

0

1

1.67

1

1

0

0

1

0

1.00

1

1

0

1

0

0

3.67

1

1

1

0

0

0

1.00

Ranks (Ri)
-0.67 -3.00 -0.67 -1.67
0.00 2.33 1.33 0.00 -1.00 1.33 -1.33 1.00 0.00 -1.33 -2.33 0.00 1.67 0.67 3.00 0.67

Note: Observed values in boldface (Ri is rank(Yi)). Data based on cough frequency for first six units from honey study.

with Y1(1) for those assignment vectors with W1 = 1; likewise for the other units. Thus the value of the corresponding statistics T(W, Yobs) varies with W.
For each vector of assignments, we calculate the corresponding value of the statistic. The last row of Table 5.5 lists the actual assignment vector, corresponding to the data in Table 5.4. In this case, Tobs = 1. 00; in the sample of six children, the measure of the average cough frequencey for the three children who had been given honey differs by one unit of measurement from the average for the three children who had not been given any active treatment for their coughing. The other rows list the value of the statistic under the alternative values of the assignment vector for the expanded data of Table 5.4. Under random assignment, each assignment vector has prior probability 1/20. Thus we can derive the prior probabilities for each of the twenty values of the test statistic under Fisher's null hypothesis.
Given the distribution of the test statistic, we can ask the following question: How unusual or extreme is the observed absolute average difference between children who had been given honey versus nothing (the number 1.00) assuming the null hypothesis is true? That is, how unusual is this observed difference, assuming that there is, in fact, absolutely no causal effect of giving honey on cough frequency? One way to implement

5.4 The Choice of Null Hypothesis

63

this calculation is to ask how likely it is, according to the randomization distribution, to observe a value of the test statistic that is as large as the one actually observed, or even larger. This calculation clearly underestimates the likelihood of the observed result because it bundles it with all rarer events. Simply counting from Table 5.5 we see that there are sixteen assignment vectors with at least a difference in absolute value of 1.00 between children in the treated and control groups, out of a set of twenty possible assignment vectors. This corresponds to a p-value of 16/20 = 0. 80 for the given combination of the sharp null hypothesis and the test statistic. Under the null hypothesis of absolutely no effect of administering honey, the observed difference could, therefore, well be due to chance. If there were no effect of giving honey at all, we could have seen an effect as large as, or larger than, the one we actually observed for eighty out of every hundred times that we randomly assigned the honey. Note that, with three children out of six receiving the treatment, the most extreme p-value that we could have for this statistic for any values of the data is 2/20 = 0. 10; if T = t is a possible value for the test statistic, then t will also be the value of the test statistic obtained by using the opposite assignment vector. Hence the sample of size six is generally too small to be able to assess, with any reasonable certainty, the existence of some effect of honey versus nothing ­ the sample size is not sufficient to have adequate statistical power to reach any firm conclusion.
In the next three sections we go over these three steps, specifying the null hypothesis, choosing the statistic, and measuring the extremeness, in more detail and generality.

5.4 THE CHOICE OF NULL HYPOTHESIS

The first choice that arises when calculating the FEP is the choice of null hypothesis. Fisher himself only focused on what is arguably the most obvious sharp null hypothesis, that of no effect whatsoever of the active treatment:

H0 : Yi(0) = Yi(1), for i = 1, . . . , N.

(5.1)

We need not necessarily believe such a null hypothesis, but we may wish to see how strongly the data can speak against it. Note again that this sharp null hypothesis of no effect whatsoever is very different from the null hypothesis that the average effect of the treatment in the sample of N units is zero. This "average null" hypothesis is not a sharp null hypothesis, because it does not allow the researcher to infer values for all potential outcomes in the sample. The "average null" therefore does not fit into the framework that originates with Fisher, or its direct extensions. This does not imply that the average null hypothesis is less relevant than the hypothesis that the treatment effect is zero for all units. As we will see in Chapter 6, Neyman, whose approach focused on estimating the average effect of the treatment, was critized, perhaps unfairly, by Fisher for his (Neyman's) questioning of the relative importance of the sharp null of absolutely no effect that was the focus of Fisher's analysis, compared to the null hypothesis of no average effect.
Although Fisher's approach cannot accommodate a null hypothesis of an average treatment effect of zero, it can accommodate sharp null hypotheses other than the null

64

Fisher's Exact P-Values for Completely Randomized Experiments

hypothesis of no effect whatsoever. Fisher did not actually take this step, but it is a natural one. An obvious alternative to the null hypothesis of no effect whatsoever, is the hypothesis that there is a constant additive treatment effect, Yi(1) = Yi(0) + C, possibly after some transformation of the outcomes, (e.g., by taking logarithms, so that the null hypothesis is that Yi(1)/Yi(0) = C for all units) for some pre-specified value C. Once we depart from the world of no effect, however, we encounter several possible complications, among them, why the treatment effect should be additive in levels rather than in logarithms, or after some other transformation of the basic outcome.
The most general case that fits into the FEP framework is the null hypothesis that Yi(1) = Yi(0) + Ci for some set of pre-specified treatment effects Ci for i = 1, . . . , N. In practice, however, it is rare to have a meaningful and interesting null hypothesis precise enough to specify individual treatment effects for each unit, without these treatment effects being identical for all units (again, possibly after some transformation).
Although the FEP approach can allow for general sharp null hypotheses, we focus in the following discussion on the implementation of the case where the null hypothesis is that of no effect whatsoever, Yi(1) = Yi(0) for all i = 1, . . . , N, thereby implying that Yimis = Yiobs. This limitation is without essential loss of generality.

5.5 THE CHOICE OF STATISTIC
The second decision in the FEP approach, the choice of test statistic, is typically more difficult than the choice of the null hypothesis. First let us formally define a statistic:
Definition 5.1 (Statistic) A statistic T is a known, real-valued function T(W, Yobs, X) of: the vector of assignments, W; the vector of observed outcomes, Yobs (itself a function of W and the potential outcomes Y(0) and Y(1)); and the matrix of pre-treatment variables, X.
Any statistic that satisfies this definition can be used in the FEP approach in the sense that we can calculate its exact distribution under the null hypothesis. When such a statistic is scalar and used to find a p-value, we call it a "test statistic." However, not all statistics are sensible. We also want the test statistic to have the ability to distinguish between the null hypothesis and an interesting alternative hypothesis. Using the statistical term already introduced, we want the resulting test statistic to have power against alternatives, that is, to be likely to have a value, when the null hypothesis is false, that would be unusually large if the null hypothesis were true. Our desire for statistical power is complicated by the fact that there may be many alternative hypotheses of interest, and it is typically difficult, or even impossible, to specify a single test statistic that has substantial power against all interesting alternatives. We therefore look for statistics that lead to tests that have power against those alternative hypotheses that are viewed as the most interesting from a substantive point of view. Let us now introduce some test statistics and then return to the question of choosing among them.
The most popular choice of test statistic, although not necessarily the most highly recommended, is the one we also used in Section 5.3, the absolute value of the difference

5.5 The Choice of Statistic

65

in average outcomes by treatment status:

Tdif =

Y

obs t

-

Y

obs c

=

i:Wi=1 Yiobs - Nt

i:Wi=0 Yiobs . Nc

(5.2)

This test statistic is relatively attractive if the most interesting alternative hypothesis corresponds to an additive treatment effect, and the frequency distibutions of Yi(0) and Yi(1) have few outliers.
This particular test statistic, without the absolute value, also has an interpretation as an "unbiased" estimator for the average effect of the treatment under any alternative hypothesis, as we shall discuss in detail in the next chapter. However, this is somewhat coincidental and largely irrelevant here. In general, the test statistic need not have a direct interpretation in terms of estimating causal effects. Such an interpretation may be an attractive property, but it is not essential, and in this FEP approach, focusing only on such statistics can at times divert attention from generally more powerful test statistics.
Before discussing alternative statistics, we should add one note of caution. Although there are many choices for the statistic, the validity of the FEP approach and its p-value hinges on using one statistic and its p-value only. If one calculates multiple statistics and their corresponding p-values, the probability of observing at least one p-value less than a fixed value of p, say p, is larger than p. We return to this issue of multiple comparisons in Section 5.5.7.

5.5.1 Transformations
An obvious alternative to the simple difference in average outcomes by treatment status in (5.2) is to transform the outcomes before comparing average differences between treatment levels. This procedure would be an attractive option if a plausible alternative hypothesis corresponds to an additive treatment effect after such a transformation. For example, it may be interesting to consider a constant multiplicative effect of the treatment. In that case, the treatment effect would be an additive constant after taking logarithms, and so we might compare the average difference on a logarithmic scale by treatment status using the following test statistic:

Tlog =

i:Wi=1 ln (Yiobs) - Nt

i:Wi=0 ln (Yiobs) . Nc

(5.3)

Such a transformation could also be sensible if the raw data have skewed distributions, which is typically the case for positive variables such as earnings or wealth, or levels of a pathogen, and treatment effects are more likely to be multiplicative than additive, although one needs to take care in case there are units with zero values. In such a case, the test statistic based on taking the average difference, after transforming to logarithms, would likely be more powerful than the test based on the simple average difference, as we illustrate later.

Downloaded from https:/www.cambridge.org/core. Helsinki University Library, on 18 Mar 2017 at 07:26:49, subject to the Cambridge Core terms of use, available at https:/www.cambridge.org/core/terms. https://doi.org/10.1017/CBO9781139025751.006

66

Fisher's Exact P-Values for Completely Randomized Experiments

5.5.2 Quantiles
Motivated by the same concerns that led to test statistics based on logarithms, one may be led to test statistics based on trimmed means or other "robust" estimates of location, which are not sensitive to outliers. For example, one could use the absolute value of the difference in medians in the two samples,

Tmedian = medt(Yiobs) - medc(Yiobs) ,

(5.4)

where medt(Yiobs) and medc(Yiobs) are the observed sample medians of the subsamples with Wi = 0, {Yiobs : Wi = 0}, and Wi = 1, {Yiobs : Wi = 1}, respectively. Other test statistics based on robust estimates of location include the average in each subsample after trimming (i.e., deleting) the lower and upper 5% or 25% of the two subsamples. Another way of generalizing the statistic based on the difference in medians is to use differences in other quantiles:

Tquant = q,t(Yiobs) - q,c(Yiobs) ,

(5.5)

where q,t(Yiobs) and q,c(Yiobs), for   (0, 1), are the  quantiles of the empirical distribution of Yiobs in the subsample with Wi = 0 and Wi = 1 respectively, so that, i:Wi = 0 1Yiobsq,c(Yiobs)/Nc  , and i:Wi=0 1Yiobs<q,t(Yiobs)/Nc < . Here 1E is the indicator function, equal to 1 if the event E is true and equal to 0 otherwise.

5.5.3 T-Statistics
Another choice for the test statistic is the conventional t-statistic for the test of the null hypothesis of equal means, with unequal variances in the two groups,

Tt-stat =

Y

obs t

-

Y

obs c

,

s2c /Nc + st2/Nt

(5.6)

where sc2 =

i:Wi=0

(Yiobs

-

Y

obs c

)2

/(Nc

-

1)

and

st2

=

i:Wi=1 (Yiobs - Ytobs)2/(Nt - 1).

Note that, in the approach of this chapter, we do not compare this test statistic to a

student-t or normal distribution. Rather, we use the randomization distribution to obtain the exact distribution of the test statistic Tt-stat under the null hypothesis given the poten-

tial outcomes. In many cases, the conventional normal or student-t approximation may

be excellent in moderate to large samples, but in small samples, and with thick-tailed or

skewed distributions for the potential outcomes, these approximations can be poor, and

generally there is no need to rely on them in our era of fast computing, as we illustrate

in Section 5.8.

5.5.4 Rank Statistics
An important class of test statistics involves transforming the outcomes to ranks before considering differences by treatment status. Such a transformation is particularly attractive when the raw outcomes have a distribution with a substantial number of outliers.

5.5 The Choice of Statistic

67

Assuming no ties, the rank of unit i, for i = 1, . . . , N, is defined as the number of units, out of the sample of size N, with an observed outcome less than or equal to Yiobs. Without ties, the rank will take on all integer values from 1 to N, with a discrete uniform distri-
bution, irrespective of the observed potential outcomes. This transformation leads to
inferences that are insensitive to outliers, without requiring consideration of which con-
tinuous transformation would lead to a well-behaved distribution of potential outcomes.
Formally the basic definition of rank in the absence of ties is

N

R~ i = R~ i(Y1obs, . . . , YNobs) =

1YjobsYiobs .

j=1

We often subtract (N + 1)/2 from each rank to obtain a normalized rank that has average value equal to zero in the sample:

R i

=

R~ i(Y1obs, . . . , YNobs)

-

N

+ 2

1

=

N

N+1

1YjobsYiobs -

. 2

j=1

When there are ties in outcomes within the sample, the definition is typically modified,

for instance, by averaging all possible ranks across the tied observations. Suppose we

have two units with outcomes both equal to y; if there are L units with outcomes smaller

than y, the two possible ranks for these two units are L + 1 and L + 2. Hence we assign

each of these units the average rank (L + 1)/2 + (L + 2)/2 = L + 3/2. More generally,

if there are M observations with the same outcome value, and L observations with a

strictly smaller value, the rank for the M observations with the same outcome value is

L + (1 + M)/2. Formally, after again subtracting the mean rank, we use the following

definition for the normalized rank:





Ri

=

Ri(Y1obs, . . . , YNobs)

=

N j=1

1Yjobs <Yiobs

+

1 2

1 +

N j=1

1Yjobs=Yiobs  -

N

+1 .
2

Given the N ranks Ri, i = 1, . . . , N, an obvious test statistic is the absolute value of the difference in average ranks for treated and control units:

Trank = Rt - Rc =

i:Wi=1 Ri - Nt

i:Wi=0 Ri , Nc

(5.7)

where Rt and Rc are the average rank in the treatment and control group respectively. In

the absence of ties, the p-value for this test statistic is closely related to that based on the

Wilcoxon rank sum test statistic, which is defined as Twilcoxon =

N i=1

R~ i,

because

T rank

is a simple transformation of Twilcoxon:

Trank = Twilcoxon - N(N + 1)/2 - N(N - 1)/2 - Twilcoxon .

Nt

Nc

Let us return to the first six units from the honey data in Table 5.3. The observed cough frequency for the first child is 3. There are three units with a smaller value for the outcome, so the rank for the first child's value of the outcome is 4. The second child

68

Fisher's Exact P-Values for Completely Randomized Experiments

has an observed outcome equal to 5, which is the largest observed value, so the rank for this child's value is 6. The cough frequency for the third child is zero, tied for the smallest value with one other child, so that the non-normalized rank is (1 + 2)/2 = 1. 5. The ranks for all six units are reported in Table 5.4. We then calculate the test statistic as the average difference in rank between the three treated and the three control units, which leads to a test statistic of 0.67. To obtain the FEP for this test statistic, we count the number of times we get a test statistic equal to, or larger than, 0.67, across all randomized allocations. With all values reported in Table 5.5, this number is 16, so that the p-value is 16/20 = 0. 80.
Unlike the simple difference in means, or the difference in logarithms, the rank-based statistics do not have a direct interpretation as a meaningful treatment effect. Nevertheless, rank-based statistics can in practice lead to more powerful tests than statistics that have an interpretation as an estimated causal effect, due to their insensitivity to thicktailed or skewed distributions. We will illustrate this feature when we look at an example with real data.

5.5.5 Model-Based Statistics
A rich class of possible test statistics with a form very different from a simple difference
of averages outcomes, possibly after some transformation, is motivated by parametric
models of the potential outcomes. Other uses of such models will be discussed in greater
detail in Chapter 8. Here we briefly discuss their role in motivating statistics in the FEP
approach.
Suppose we have two models, one for the distribution of the potential control out-
comes Yi(0) and the other for the distribution of the potential treated outcomes Yi(1), governed by unknown parameters c and t respectively, where both c and t generally are vectors. For ease of exposition, let us assume that both models have a common functional form so that c and t have the same number of components. Let us estimate c using the observed outcomes from the units assigned to the control group and denote the estimator by ^c. We can use a variety of methods for estimation here, for example, method of moments, least squares, or maximum likelihood estimation. Similarly, let us estimate the parameter t using outcomes from the units assigned to the treatment group, with estimator ^t. Now, take any scalar function of the resulting estimates, say the difference in one of the components of the two vectors ^c and ^t, or the sum of the squared differences between elements of the vectors ^c and ^t. Because ^c and ^t are functions of the observed data (W, Yobs, X), they are statistics according to Definition 5.1. Hence any scalar function of the estimated parameters ^c and ^t is a test statistic that can be used to obtain a p-value for a sharp null hypothesis.
Although these test statistics are motivated by statistical models, the validity of an FEP
based on any one of them does not rely on the validity of these models. In fact, these
models are purely descriptive given that the potential outcomes are considered fixed
quantities. The reason such models may be useful, however, is that they may provide
good descriptive approximations to the sample distribution of the potential outcomes
under some alternative hypothesis. If so, the models can suggest a test statistic that is
relatively powerful against such alternatives.

5.5 The Choice of Statistic

69

Let us consider two examples. First, suppose the model for Yi(0) is normal with mean

c and variance c2. Similarly, suppose the model for Yi(1) is also normal but with

a generally different mean t and variance t2. Thus, c = (c, c2), and t = (t, t2).

The natural estimates for c and t are the two subsample means by treatment status

^ c

=

Y

obs c

and

^ t

=

Y

obs t

.

Hence,

if

we

use

the

statistic

Tmodel =

^ t - ^ c

=

Y

obs t

-

Y

obs c

= Tdif,

we return to the familiar territory of using the difference in averages by treatment status
for the test statistic.
Second, suppose that the model for Yi(0) is a normal distribution with mean c and variance c2, censored from above at C, and similarly that Yi(1) has a normal distribution with mean t and variance t2, also censored from above at a known value C, so that again, c = (c, c2), and t = (t, t2). We can estimate the parameters c, t, c2, and t2 by maximum likelihood as ^ ml,c, ^ ml,t, ^m2l,c, and ^m2l,t respectively, or by the method of moments. There are no analytic solutions for the maximum likelihood estimates in this case, but the FEP based on a test statistic using such estimates, for example, Tmodel = ^ ml,t - ^ ml,c , is still valid.

5.5.6 The Kolmogorov-Smirnov Statistic
The test statistics discussed so far focus on difference in particular features of the outcome distributions between treated and control units. Initially this was the difference in averages, and later we considered differences in averages after taking transformations of outcomes, including ranks. Focusing on a single, or even multiple, features of these distributions may lead the researcher to miss differences in other aspects. For example, suppose we focus on the difference in average outcomes by treatment status. If the true distribution for the potential outcomes given treatment is normal with mean zero and unit variance, and the true distribution for the potential outcome given no treatment is normal with the same mean, zero, but a different variance, say, two, focusing solely on the average difference will not generate extreme p-values very often, even in large samples, despite the null hypothesis not holding. Formally, the test based on the difference in averages will have little power against an alternative hypothesis with different variances. We may, therefore, be interested in test statistics that would be able to detect, given sufficiently large samples, any differences in distributions between treated and control units. An example of such a test statistic is the Kolmogorov-Smirnov statistic.
Let F^ c(y) and F^ t(y) be the empirical distribution functions based on units with treatment Wi = 0 and Wi = 1, respectively:

F^ c(y)

=

1 Nc

1Yiobsy,
i:Wi=0

and

F^ t(y)

=

1 Nt

1Yiobsy,
i:Wi=1

for all - < y < . Then the Kolmogorov-Smirnov test statistic is

Tks = sup F^ t(y) - F^ c(y) = maxi=1,...,N F^ t Yiobs - F^ c Yiobs .
y

(5.8)

70

Fisher's Exact P-Values for Completely Randomized Experiments

This is a more complicated test statistic than, say, the average Tdif. Nevertheless, because it is a scalar function of the vector of assignments and the vector of observed outcomes, it is a valid test statistic. Therefore, we use exactly the same procedure as with the simpler statistics: calculate its exact finite-sample distribution generated by the randomization and then calculate the associated exact p-value.

5.5.7 Statistics with Multiple Components
The validity of the FEP approach depends on an a priori (i.e., before seeing the data) commitment to a specific pair: a null hypothesis and a test statistic. The corresponding p-values are valid for each pair considered in isolation, but the p-values are not independent across pairs. Specifically, consider two possible test statistics, T1(W, Yobs, X) and T2(W, Yobs, X), with realized values T1,obs and T2,obs. This situation may arise in a number of ways. First, it may be that there are multiple alternative hypotheses of interest. For example, under one alternative hypothesis the mean of the outcome distribution may shift (suggesting a test statistic based on the difference in means by treatment status), whereas under another alternative hypothesis the dispersion may change (suggesting a test statistic based on the ratio of sample variances by treatment status). Second, it may be that the researcher has two outcomes for each unit. In the honey study, there are, for example, measures on both cough frequency and cough severity. In that case, one statistic could be the difference in average cough frequency by treatment status and the other difference in average cough severity by treatment status. Under any sharp null hypothesis, one can calculate p-values for each of the tests, for example,
p1 = Pr(T1  T1,obs|X, Y(0), Y(1), H0) and p2 = Pr(T2  T2,obs|X, Y(0), Y(1), H0).
These p-values are valid for each test in isolation, but using the minimum of p1 and p2 as an overall p-value for the null hypothesis is not valid, nor is using the average of p1 and p2 for this purpose.
The simplest way to obtain a valid p-value with multiple test statistics is to combine the two (or more) test statistics into a single test statistic. One can do this directly, by defining the test statistic as a function of the two original test statistics,
Tcomb = g(T1, T2),
for some scalar function g(·, ·). Choices for Tcomb could include a (weighted) average of the two statistics, or the minimum or maximum of the two statistics. Alternatively, Tcomb could be a function of the two p-values, for example, the minimum or the average. Because T1 and T2 (or p1 and p2) are functions of (W, Y, X), it follows that Tcomb is a function of these vectors and thus a valid scalar test statistic according to our definition. Hence, its randomization distribution can be calculated, and the corresponding p-value would equal
pg = Pr(g(T1, T2)  g(T1,obs, T2,obs)|X, Y(0), Y(1), H0).
As an example, suppose we have for, each unit, two outcome measures, Yio1bs and Yio2bs. These may be distinct measurements (e.g., in the honey study, the cough frequency and

5.5 The Choice of Statistic

71

cough severity, both post-treatment), or one could be a transformation of the other. For each outcome we could calculate the statistics based on the t-statistic:

Tt-stat,1 =

Y

obs t1

-

Y

obs c1

,

s2c1/Nc + s2t1/Nt

and Tt-stat,2 =

Y

obs t2

-

Y

obs c2

.

sc22/Nc + st22/Nt

Then we could choose for our test statistic Tcomb = max (Tt-stat,1, Tt-stat,2).

In this case, a slightly more natural test statistic is based on Hotelling's T2 statis-

tic

for

the

difference

in

vector

of

means.

For

j = 1, 2

let

Y

obs c,j

=

i:Wi=0 Yio,jbs/Nc and

Y

obs t,j

=

i:Wi=1 Yio,jbs/Nt. Then let V^ c/Nc + V^ t/Nt be an estimator for the covariance

matrix of (Yt,1 - Yc,1, Yt,2 - Yc,2) , where

V^ c

=

1 Nc -

1

i:Wi=0

Yio,1bs

-

Y

obs c,1

Yio,2bs

-

Y

obs c,2

·

Yio,1bs

-

Y

obs c,1

Yio,2bs

-

Y

obs c,2

,

and

V^ t

=

1 Nt -

1

i:Wi=1

Yio,1bs

-

Y

obs t,1

Yio,2bs

-

Y

obs t,2

·

Yio,1bs

-

Y

obs t,1

Yio,2bs

-

Y

obs t,2

.

Then a natural test statistic is

THotelling =

Y

obs t,1

-

Y

obs c,1

Y

obs t,2

-

Y

obs c,2

V^ c/Nc + V^ t/Nt -1

Y

obs t,1

-

Y

obs c,1

Y

obs t,2

-

Y

obs c,2

,

(5.9)

which measures the Mahalanobis squared distance between the averages in the treatment group and the control group.

5.5.8 Choosing a Test Statistic
Given the wide variety of test statistics introduced here, let us now return to the question of how to choose one among them to calculate the one valid p-value. In principle, the choice should be governed by considering both plausible alternative hypotheses and the approximate distribution of the potential outcomes under both null and alternative hypotheses. Suppose one suspects the effect of the treatment to be multiplicative; in that case, a natural test statistic for assessing the null hypothesis of no effect would be the differences in the average logarithms of the outcomes between the treatment groups. If the null hypothesis does not hold because the effect is in fact multiplicative, such a test statistic will be more sensitive to this alternative hypothesis than the simple difference in averages, thus leading to greater power in the FEP. Similarly, if we expect the treatment to increase the dispersion of the outcomes but to leave the location unchanged, we can use the difference in or ratio of estimates of measures of dispersion, such as the sample variances or the interquartile ranges, for our test statistic. If the treatment does

72

Fisher's Exact P-Values for Completely Randomized Experiments

increase the dispersion but does not alter the location, such a test statistic will lead to more power when using the FEP than would a test statistic based on the difference in average outcomes by treatment status.
A second consideration concerns the distribution of the values of the observed potential outcomes. If the empirical distributions of the observed potential outcomes have some outliers, calculating average differences by treatment status may lead to an FEP with low power against an alternative that corresponds to a constant and additive treatment effect. In that case it may be possible to use a test statistic that measures the difference in the centers of the two observed potential outcome distributions, not affected by a few extreme values, such as the medians, trimmed means, ranks, or even maximum likelihood estimates of locations based on long-tailed distributions, such as the family of t-distributions. In practice, using the average difference in ranks is an attractive test statistic that has decent power in a wide range of settings.

5.6 A SMALL SIMULATION STUDY
To illustrate how the different statistics perform in a known setting, we conducted a small simulation study. The study was designed to see how much power various statistics had against different (e.g., additive versus multiplicative) alternatives under various distributions of the outcomes. Although we look here at multiple statistics, one must remember that the p-value retains its properties only for a single statistic: one cannot look at multiple p-values and choose the "best," as we discussed in Section 5.5.7.
In the basic simulation setting, the population distribution for Yi(0) is normal with mean zero and unit variance, N (0, 1). The treatment effect is  for all units, so that Yi(1) = Yi(0) +   N ( , 1). In each replication, we draw a random sample of size N = 2000 with Nc = 1000 assigned to the control group and Nt = 1000 assigned to the treatment group. We calculate p-values for the sharp null hypothesis that Yi(1) = Yi(0) for all units. We carry out the calculations using three different test statistics. First, the absolute value of the simple difference in means for treated and controls, Tave given in Equation (5.2). Second, we take the absolute value of the difference in medians Tmed given in (5.4). Third, we take the absolute value of the difference in average ranks, Trank given in (5.7). In all three cases, we calculate the p-value as the probability under the null hypothesis of getting a test statistic as large as the observed test statistic, or larger.
We repeat this process by repeatedly drawing random samples and calculating the corresponding p-values. We then compute the power of the tests for each test statistic as the proportion of p-values less than or equal to 0.10. We do this simulation for a range of values of  > 0. Figure 5.1 reports the proportions for the three different test statistics that generate p-values less than 0.1, as a function of  . The solid line corresponds to the mean, the dashed line to the median, and the dotted line corresponds to the rank statistic. We see that the FEP-based rank and mean test statistics have similar performances, whereas the FEP based on the median has less power in this situation.
We then modify the basic data-generating process by changing the distribution of Yi(0). We add a binary random variable Ui to the normal components with Pr(Ui = 0) = 0.8 and Pr(Ui = 5) = 0.2, which leads to a distribution with 20% outliers. We again consider additive alternatives where Yi(1) = Yi(0) +  . In Figure 5.2 we present the

5.6 A Small Simulation Study

73

1

0.9

0.8

0.7

Power

0.6

0.5

0.4

0.3

0.2

0.1 0

0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 

Figure 5.1. Additive model with normal outcomes Tdif(-), Tmedian(--), Trank( . . . )

Power

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0

0.05

0.1

0.15

0.2

0.25



Figure 5.2. Additive model with outliers Tdif(-), Tmedian(--), Trank( . . . )

power functions for the same three statistics. The rank-based and the median-based FEP's are superior here. The mean-based FEP has substantially worse power due to the presence of outliers.
In the third part, we change the distribution of Yi(0) so that the logarithm of Yi(0) has a normal distribution with mean zero and unit variance, and make the treatment effect multiplicative: Yi(1) = Yi(0) · exp ( ) for a range of values of  . Exploiting the fact that the outcomes are positive in this case, we include a test statistic based on the difference

74

Fisher's Exact P-Values for Completely Randomized Experiments

1

0.9

0.8

0.7

Power

0.6

0.5

0.4

0.3

0.2

0.1 0

0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 0.2 

Figure 5.3. Multiplicative model Tdif(-), Tmedian(--), Trank( . . . )

in average logarithms of the basic outcome, Tlog given in (5.3). Figure 5.3 presents the results. Again the solid line corresponds to the mean, the dashed line to the median, and the dotted line corresponds to the rank statistic, and now the dash-dot line corresponds to the statistic based on the difference in average logarithms. The logarithm-based FEP and rank-based FEP both have superior power in this case compared to the mean-based FEP and median-based FEP.
Overall, these simulations suggest that the rank-based statistic is an attractive choice in a range of settings. It has relatively good power in all three settings considered, whereas the other choices for the test statistics performed well only in settings that play to their advantages, at the expense of relatively poor power in other settings.

5.7 INTERVAL ESTIMATES BASED ON FISHER P-VALUE CALCULATIONS
Earlier we discussed how we can use FEP calculations for null hypotheses other than that of absolutely no effect of the treatment, even if this was never considered in the original proposals by Fisher. Suppose, for example, we wish to assess the null hypothesis that for all units the effect of the treatment is an increase in test score equal to C = 0.5: Yi(1) = Yi(0) + 0.5. This assumption is itself a sharp null hypothesis and allows us to fill in all of the missing outcomes; Table 5.6 lists the full set of potential outcomes for the first six observations in the honey data set based on this null hypothesis. Given this complete knowledge, we can again calculate the randomization distribution of any test statistic and the corresponding p-value of any observed test statistic.
Let us now do this for a range of values of a postulated effect  . The second column of Table 5.7 lists, for the full honey data set, the FEPs associated with a constant treatment

5.8 Computation of P-Values

75

Table 5.6. First Six Observations from Data from Honey Study with Missing Data in Parentheses under the Null Hypothesis of a Constant Effect of Size 0.5. Missing Potential Outcomes in Parentheses

Unit

Potential Outcomes

Yi(0)

Yi(1)

1

(2.5)

3.0

2

(4.5)

5.0

3

(-0.5)

0.0

4

4.0

(4.5)

5

0.0

(0.5)

6

1.0

(1.5)

Actual Treatment
1 1 1 0 0 0

Observed Outcome
3.0 5.0 0.0 4.0 0.0 1.0

Note: Data based on cough frequency for first six units from honey study.

effect, C, for C  {-3, -2.75, -2.50, . . . , 1. 00}. Here the test statistic is the absolute value of the difference in average outcomes for treated and control units minus C, and the p-value is the proportion of draws of the assignment vector leading to a test statistic at least as large as the observed value of that test statistic. From Table 5.7 we see that, for very negative values of C (C < - 1.50) or very positive values (C > 0.25), the pvalue is more extreme (smaller) than 0.05. Between these values there is a region where the C-based null hypothesis leads to p-values larger than 0.05. At the lower end of the range, we find that we obtain p-values less than 0.05 with a null hypothesis of a constant additive effect of -1.5, but not a constant additive effect of -1.25. The set of values where we get p-values larger than 0.05 is [-1. 44, 0. 06], which provides a 95% "Fisher" interval for a common additive treatment effect, in the spirit of Fisher's exact p-values.
In the third column of Table 5.7, we do the same for a rank-based test. To be clear here, let us be explicit about the calculation of the statistic and the p-value. If the null hypothesis is that the treatment effect is Yi(1) - Yi(0) = C, then we first calculate for each unit the implied value of Yi(0). For units with Wi = 0, we have Yi(0) = Yiobs, and for units with Wi = 1, we have Yi(0) = Yiobs - C under the null hypothesis. Then we convert these Yi(0) to ranks Ri. Note that this rank is not the rank of Yiobs; rather it is, under the null hypothesis, the rank of Yi(0) (or, equivalently, under the null hypothesis, the rank of Yi(1)). Next, we calculate the statistic as the average rank for the treated minus the average rank for the controls, T = |Rt - Rc|. Finally, we calculate the p-value for this test statistic, under the randomization distribution, as the proportion of values of the test statistic under the randomization distribution that are larger than or equal to the realized value of the test statistic. The set of values where we get p-values equal to or larger than 0.05 is [-2. 00, -0. 00], which provides a 95% "Fisher" interval for the treatment effect.

5.8 COMPUTATION OF P-VALUES
The p-value calculations presented so far have been exact; we have been able to calculate precisely in how many randomizations the test statistic T would be more extreme than

76

Fisher's Exact P-Values for Completely Randomized Experiments

Table 5.7. P-Values for Tests of Constant Treatment Effects (Full Honey Data Set from Table 5.1, with Cough Frequency as Outcome)

Hypothesized Treatment Effect
-3.00 -2.75 -2.50 -2.25 -2.00 -1.75 -1.50 -1.44 -1.25 -1.00 -0.75 -0.50 -0.25
0.00 0.06 0.25 0.50 0.75 1.00

P-Value (level)
0.000 0.000 0.000 0.000 0.001 0.006 0.037 0.050 0.146 0.459 0.897 0.604 0.237 0.067 0.050 0.014 0.003 0.000 0.000

P-Value (rank)
0.000 0.000 0.000 0.000 0.000 0.078 0.078 0.078 0.078 0.628 0.428 0.428 0.429 0.043 0.043 0.001 0.000 0.001 0.000

Note: The level statistic is the absolute value of the difference in treated and control averages minus the hypothesized value, and the p-value is based on the proportion of statistics at least as large as the observed value. The rank-based statistic is the difference in average ranks for the treated and control units, of the value of the potential outcome under the null treatment.

our observed value of T. We could do these calculations exactly because the samples

were small. In general, however, with Nt units assigned to the treatment group and Nc

units assigned to the control group, the number of distinct values of the assignment

vector is

Nc +Nt Nt

,

which,

as

we saw

in Table

4.1

in

Chapter

4,

can

grow

very

quickly

with Nc and Nt. With both Nc and Nt sufficiently large, it may be infeasible to calculate

the test statistic for every value of the assignment vector, even with current advances

in computing. This does not mean, however, that it is difficult to calculate an accurate

p-value associated with a test statistic, because we can rely on numerical approximations

to the p-value.

It is typically very easy to obtain an accurate approximation of the p-value associated

with a specific test statistic and null hypothesis. To do this, instead of calculating the statistic for every single value of the assignment vector W  W+, we calculate it for only a randomly chosen subset of possible assignment vectors. Let Tdif,obs be the observed

value of the test statistic. Then, randomly draw an N-dimensional vector with Nc zeros and Nt ones from the set of possible assignment vectors. For each draw from this set,

5.8 Computation of P-Values

77

Table 5.8. P-Values Estimated through Simulation for Honey Data from Table 5.1 for Null Hypothesis of Zero Effects

Number of Simulations
100 1,000 10,000 100,000 1,000,000

P-Value
0.010 0.044 0.044 0.042 0.043

(s. e. )
(0.010) (0.006) (0.002) (0.001) (0.000)

Note: Statistic is absolute value of difference in average ranks of treated and control cough frequencies. P-value is proportion of draws at least as large as observed statistic.

the probability of being drawn is 1

Nc+Nt Nt

. Calculate the statistic for the first draw, say

Tdif,1 = Yt,1 - Yc,1. Repeat this process K - 1 times, in each instance drawing a new vector of assignments and calculating the statistic Tdif,k = Yt,k - Yc,k, for k = 2, . . . , K.

We then approximate the p-value for our test statistic by the fraction of these K statistics

that are as extreme as, or more extreme than, the observed value Tdif,obs,

1N

p^ = K

1Tdif,kTdif,obs .

k=1

If we were to draw the assignment vectors without replacement, and we sampled

Nc +Nt Nt

assignment vectors, we would have calculated the statistic for all assignment vectors,

and we would obtain the exact p-value. In practice, if K is large, the p-value based

on a random sample will be quite accurate. For this approximation, it does not matter

whether we sample with or without replacement. The latter will lead to slighly more

precise p-values for modest values of K, but both will lead to accurate p-values with K

large enough because each assignment vector has the same probability of being drawn

with or without replacement. The accuracy of this approximation is, therefore, entirely

within the researcher's control. One can determine the number of independent draws required for a given degree of accuracy. Given a true p-value of p, and K draws from

theps(e1t

of -

possible assignment vectors, the large-sample standard error of the p)/K. The maximum value for the standard error is achieved at p

p-value = 1/2,

is in

which case the standard error of the estimated p-value is 1/(2 K). Hence, if we want

to estimate the p-value accurately enough that its standard error is less than 0.001, it

suffices to use K = 250, 000 draws, which is computationally entirely feasible unless the

calculation of the test statistic is itself tedious (which it rarely is, although it can be, for

example, when the test statistic is based on a model without closed-form estimates).

To illustrate this approach, we now analyze the full data set from the Honey Study for

which the summary statistics are presented in Table 5.1. Table 5.8 reports the p-value

for the null hypothesis of no effect, and using for our approximated p-values, K = 100,

K = 1,000, K = 10,000, K = 100,000, and K = 1,000,000. The statistic used is the abso-

lute value of the difference between average ranks for treated and control, and the p-value

78

Fisher's Exact P-Values for Completely Randomized Experiments

reported is the proportion of assignment vectors that leads to a value for the test statistic at least as large as the observed value of the test statistic.

5.9 FISHER EXACT P-VALUES WITH COVARIATES

Thus far, all of the statistics considered have ignored the presence of any pre-treatment variables. Their presence greatly expands the set of possible test statistics. Here we discuss a few additional statistics that are feasible exploiting the presence of covariates.
First, one can use the pre-treatment variables to transform the observed outcome. For instance, if the pre-treatment variable is analogous to the outcome but measured prior to assignment to treatment or control (for instance, a pre-test score), it can be useful to subtract this variable from the potential outcomes and then carry out the test on the transformed outcomes, commonly referred to as gain scores. Thus, define

Yi (w) = Yi(w) - Xi,

for each level of the treatment w, and define the realized transformed outcome as

Yi,obs = Yiobs - Xi =

Yi (0) Yi (1)

if Wi = 0, if Wi = 1.

Such gain scores are often used in educational research. One should resist the temptation, though, to interpret the gain Yi,obs as a causal effect of the program for a treated unit i. Such an interpretation requires that Yi(0) is equal to Xi, which is generally not warranted.
The unit-level causal effect on the modified outcome Y is Yi (1) - Yi (0). Substituting Yi (w) = Yi(w) - Xi shows that this causal effect is identical to the unit-level causal effect on the original outcome Yi, Yi(1)-Yi(0). Hence the null hypothesis that Yi(0) = Yi(1) for
all units is identical to the null hypothesis that Yi (1) = Yi (0) for all units. However, the FEP based on Yi,obs generally differs from the FEP based on Yiobs. A natural test statistic, based on average differences between treated and control units, measured in terms of the
transformed outcome is

Tgain =

i:Wi=1 Yi,obs - Nt

i:Wi=0 Yi,obs Nc

(5.10)

= i:Wi=1 Yiobs - Xi - i:Wi=0 Yiobs - Xi

Nt

Nc

=

Y

obs t

-

Y

obs c

-

(Xt

-

Xc),

where Xc = i:Wi = 0 Xi/Nc and Xt = i:Wi=1 Xi/Nt are the average value of the covari-

ate in the control and treatment group respectively. Compare this test statistic with

the

statistic

based

on

the

simple

difference

in

average

outcomes,

T

ave

=

Y

obs t

-

Y

obs c

.

The difference between the two statistics is equal to the difference in pre-treatment

averages by treatment group, Xt - Xc. This difference is, on average (i.e., averaged

over all assignment vectors), equal to zero by the randomization, but typically it

is different from zero for any particular assignment vector. The distribution of the

5.9 Fisher Exact P-Values with Covariates

79

test

statistic

T gain

=

Y

obs t

-

Y

obs c

-

(Xt

-

Xc)

will

therefore

generally

differ

from

that

of

T

dif

=

Y

obs t

-

Y

cobs,

and

thus

so

will

be

the

associated

p-value.

An alternative transformation involving the pre-test score is to use the proportional

change from baseline, so that

Yi

(w)

=

Yi(w) - Xi

Xi ,

for w = 0, 1,

and

Yi

,obs

=

Yiobs - Xi

Xi .

Here the implicit causal effect being estimated for unit i is

Yi(1) - Xi - Yi(0) - Xi = Yi(1) - Yi(0) .

Xi

Xi

Xi

A natural test statistic is now

Tprop-change = Y

t-Y

c=

1

Yiobs - Xi

Nt i:Wi=1

Xi

-1

Yiobs - Xi .

Nc i:Wi=0

Xi

(5.11)

Both the gain score and the proportional change from baseline statistics are likely to lead
to more powerful tests if the covariate Xi is a good proxy for Yi(0). Such a situation often arises if the covariate is a lagged value of the outcome, for example, a pre-test score in
an educational testing example, or lagged earnings in a job-training example. Both Tgain and Tprop-change use the covariates in a very specific way: transforming
the original outcome using a known, pre-specified function. Such transformations make
sense if one has a clear prior notion about the relationship between the potential out-
comes and the covariate. Often, however, one may think that the covariate is highly
correlated with the potential outcomes, but their scales may be different, for example, if
Xi is a health index and Yi is post-randomization medical complications for unit i. In that case, it is useful to consider a more general way to exploit the presence of covariates.
Recall that any scalar function T = T(W, Yobs, X) can be used in the FEP framework. One possibility is to calculate a more complicated transformation that involves the values of both outcomes and pre-treatment variables for all units. For instance, let (^0, ^X, ^W ) be the least squares coefficients in a regression of Yiobs on a constant, Xi, and Wi:

^0, ^X, ^W

N
= arg min
0,X ,W i=1

Yiobs - 0 - X · Xi - W · Wi

2
.

These least squares coefficients are obviously functions of (W, Yobs, X). An alternative choice for the test statistic is then

Treg-coef = ^W .

(5.12)

80

Fisher's Exact P-Values for Completely Randomized Experiments

Table 5.9. P-Values for Honey Data from Table 5.1, for Null Hypothesis of Zero Effects Using Various Statistics

Test Statistic
T dif Tquant ( = 0. 25) Tquant ( = 0. 50) Tquant ( = 0. 75) T t-stat T rank T ks T F-stat T gain T reg-coef

Statistic
-0.697 -1.000 -1.000 -1.000 -1.869 -9.785
0.304 3.499 -0.967 -0.911

P-Value
0.067 0.440 0.637 0.576 0.065 0.043 0.021 0.182 0.006 0.008

Note: Outcome is cough frequencey (cfa) with the exception of TF-stat, which is based on cough frequency and cough severity (cfa and csa). The p-value is proportion of draws at least as large as observed statistic.

This statistic is likely to be more powerful than those based on simple differences in observed outcomes if the covariates are powerful predictors of the potential outcomes.
As before, the validity of a test based on only one such statistic does not rely on the regression model being correctly specified. However, the increases in power will be especially realized when the model provides a reasonable approximation to the distribution of values of the potential outcomes in both treatment conditions.

5.10 FISHER EXACT P-VALUES FOR THE HONEY DATA

Now we return to the full honey data set with all seventy-two observations. Table 5.9

lists ten test statistics and corresponding p-values, with the p-values estimated using

1,000,000 draws from the randomization distribution. The p-values are based on the post-

treatment cough frequency (cfa) and the post-treatment cough severity (csa). Again,

here we report multiple p-values, although, in theory, only one is valid, the one specified

a priori, and in practice, one should do only one, or adjust the p-values as discussed in

Section 5.5.7.

First we report the p-values when the statistic is the absolute value of the simple dif-

ference

in

average

cough

frequency

by

treatment

status,

T dif

=

|Y

obs t

-

Y

obs c

|.

This

leads

to a p-value of 0.067. Next we report three quantile-based statistics, Tquant given in (5.5),

for the quartiles  = 0.25,  = 0.5, and  = 0.75. Note that, due to the discrete nature of

the outcome variable used here, cough frequency after the treatment, the observed val-

ues of the statistic are the same for all three choices of , although the implied p-values

differ. The quantile-based p-values are considerably higher compared to those based on

the difference-in-means statistic, illustrating that with discrete outcomes, quantile-based statistics can have low statistical power. Fifth, we use the conventional t-statistic, Tt-stat

given in (5.6). The p-value for this test is similar to that for the simple difference in

Notes

81

means. Note that the p-value based on the normal approximation to the distribution of this statistic is 0.062, fairly close to the p-value based on the randomization distribution because the sample size is reasonably large. Next, we use the difference in average ranks, taking account of ties, using the statistic Trank given in (5.7). This leads to a smaller p-value, equal to 0.042. Then we use the Kolmogorov-Smirnov-based test statistic, given in (5.8). The maximum difference observed between the cumulative distribution functions is 0.304. As can be seen from Table 5.2, this maximum difference occurs at y = 2, where F^ Y(1)(2) = 0.63 and F^ Y(0)(2) = 0.32. The p-value using the Kolmogorov-Smirnov-based statistic is 0.021.
The eighth p-value uses both outcomes, cough frequency and cough severity. The test statistic is based on Hotelling's T2 statistic, THotelling in (5.9). The last two p-values involve the pre-treatment variable cfp. First we calculate the statistic based on the absolute value of the difference in gains scores, Tgain, as given in (5.10). The last test uses the estimated regression coefficient as the test statistic, Treg-coef, as given in (5.12). Both lead to substantially lower p-values than the statistics that do not exploit the pre-treatment variables. This reflects the strong correlation between the prior cough frequency and ex post cough frequency (the unconditional correlation is 0.41 in the full sample).

5.11 CONCLUSION
The FEP approach is an excellent one for simple situations when one is willing to assess the premise of a sharp null hypothesis. It is also a very useful starting point, prior to any more sophisticated analysis, to investigate whether a treatment does indeed have some effect on outcomes of interest. For this purpose, an attractive approach is to use the test statistic equal to the absolute value of the difference in average ranks by treatment status, and to calculate the p-value as the probability, under the null hypothesis of absolutely no effect of the treatment, of the test statistic being as large as, or larger than, the realized value of the test statistic. In most situations, however, researchers are not solely interested in obtaining p-values for sharp null hypotheses. Simply being confident that there is some effect of the treatment for some units is not sufficient to inform policy decisions. Instead researchers often wish to obtain estimates of the average treatment effect without being concerned about variation in the effects. In such settings the FEP approach does not immediately apply. In the next chapter, we discuss a framework for inference developed by Neyman (1923) that does directly apply in such settings, at least asymptotically, while maintaining a randomization perspective.

NOTES
As stated here, what we call "Fisher interval" was not actually proposed by Fisher, but may be close to what Fisher would have called a "fiducial interval."
Extensive work on exact inference using the randomization distribution, considerably extending Fisher's work in this area, has been done by Kempthorne and in

82

Fisher's Exact P-Values for Completely Randomized Experiments

the recent literature by Rosenbaum. See among others, Kempthorne (1952, 1955), Rosenbaum (1984a, 1988, 1989b, 2002), and Imbens and Rosenbaum (2004). Rosenbaum's work also focuses on interval estimation using randomization inference. Surveys of this work include Rosenbaum (2002, 2009). Randomization tests based on residuals from regression analyses are discussed in Gail, Tian, and Piantadosi (1988). An interesting application of randomization inference to the California recall election is presented in Ho and Imai (2006).
A Bayesian approach to the analysis of randomized experiments is developed in Rubin (1978). We will discuss a closely related model-based approach in Chapter 8. Rubin (1990a) provides a general discussion of modes of inference for causal effects, relating randomization-based inference to other modes of inference, such as those discussed in Chapters 6, 7, and 8.
The Wilcoxon rank sum test was originally developed for equal-sized treatment and control groups in Wilcoxon (1945). Generalizations were developed in Mann and Whitney (1947); see also Lehman (1975) and Rosenbaum (2000).

CHAPTER 6
Neyman's Repeated Sampling Approach to Completely Randomized Experiments

6.1 INTRODUCTION

In the last chapter we introduced the Fisher Exact P-value (FEP) approach for assessing

sharp null hypotheses. As we saw, a sharp null hypothesis allowed us to fill in the values

for all missing potential outcomes in the experiment. This was the basis for deriving the

randomization distributions of various statistics, that is, the distributions induced by the

random assignment of the treatments given fixed potential outcomes under that sharp

null hypothesis. During the same period in which Fisher was developing this method,

Neyman (1923, 1990) was focused on methods for the estimation of, and inference for,

average treatment effects, also using the distribution induced by randomization, some-

times in combination with repeated sampling of the units in the experiment from a larger

population of units. At a general level, he was interested in the long-run operating char-

acteristics of statistical procedures under both repeated sampling from the population

and randomized assignment of treatments to the units in the sample. Specifically, he

attempted to find point estimators that were unbiased, and also interval estimators that

had the specified nominal coverage in large samples. As noted before, his focus on aver-

age effects was different from the focus of Fisher; the average effect across a population

may be equal to zero even when some, or even all, unit-level treatment effects differ

from zero.

Neyman's basic questions were the following. What would the average outcome be if

all units were exposed to the active treatment, Y(1) in our notation? How did that com-

pare to the average outcome if all units were exposed to the control treatment, Y(0) in our

notation? Most importantly, what is the difference between these averages, the average

treatment effect fs = Y(1)-Y(0) =

N i=1

(Yi

(1)

-

Yi(0))/N?

(Here

we

use

the

subscript

fs to be explicit about the fact that the estimand is the finite-sample average treatment

effect. Later we use the notation sp to denote the super-population average treat-

ment effect.) Neyman's approach was to develop an estimator of the average treatment

effect and derive its mean and variance under repeated sampling. By repeated sam-

pling we refer to the sampling generated by drawing from both the population of units,

and from the randomization distribution (the assignment vector W), although Neyman

never described his analysis this way. His approach is similar to Fisher's, in that both consider the distribution of statistics (functions of the observed W and Yobs) under the

83

84

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

randomization distribution, with all potential outcomes regarded as fixed. The similarity ends there. In Neyman's analysis, we do not start with an assumption that allows us to fill in all values of the missing potential outcomes, and so we cannot derive the exact randomization distribution of statistics of interest. However, without such an assumption we can often still obtain good estimators of aspects of this distribution, for example, first and second moments. Neyman's primary concern was whether an estimator was unbiased for the average treatment effect fs. A secondary goal was to construct an interval estimator for the causal estimand, which he hoped to base on an unbiased estimator for the sampling variance of the average treatment effect estimator. Confidence intervals, as they were called later by Neyman (1934), are stochastic intervals that are constructed in such a way that they include the true value of the estimand with probability, over repeated draws, at least equal to some fixed value, the confidence coefficient.
The remainder of this chapter is organized as follows. In Section 6.2 we begin by describing the data that will be used to illustrate the concepts discussed in this chapter. These data are from a randomized experiment conducted by Duflo, Hanna, and Ryan (2012) to assess the effect of a teacher-incentive program on teacher performance. Next, in Section 6.3, we introduce Neyman's estimator for the average treatment effect and show that it is unbiased for the average treatment effect, given a completely randomized experiment. We then calculate, in Section 6.4, the sampling variance of this estimator and propose an estimator of this variance in Section 6.5. There are several approaches one can take in this latter step, depending on whether one assumes a constant additive treatment effect. In Section 6.6 we discuss the construction of confidence intervals. Throughout the first part of this discussion, we assume that our interest is in a finite population of size N. Because we do not attempt to infer anything about units outside this population, it does not matter how this population was selected; the entire analysis is conditional on the population itself. In Section 6.7 we relax this assumption and instead consider, as did Neyman (1923, 1990), a population of units so that we can view the sample of N units as a random sample drawn from this population. Given this shift in perspective, we reinterpret the original results, especially with respect to the choice of estimator for the sampling variance, and the associated large sample confidence interval for the average effect. In Section 6.8 we discuss the role of covariates in Neyman's approach. In the current chapter we allow only for discrete covariates. With continuous covariates the analysis is more complicated, and we discuss various methods in Chapters 7 and 8. Next, in Section 6.9, we apply Neyman's approach to the data from the Duflo-HannaRyan teacher-incentive experiment. Section 6.10 concludes. Throughout the chapter we maintain the stability assumption, SUTVA.

6.2 THE DUFLO-HANNA-RYAN TEACHER-INCENTIVE EXPERIMENT DATA
To illustrate the methods discussed in this chapter, we use data from a randomized experiment conducted in rural India by Duflo, Hanna, and Ryan (2012), designed to study the effect of financial incentives on teacher performance, measured both directly by teacher absences and indirectly by educational output measures, such as average class test scores. A sample of 113 single-teacher schools was selected, and in a randomly selected subset

6.3 Unbiased Estimation of the Average Treatment Effect

85

Table 6.1. Summary Statistics for Duflo-Hanna-Ryan Teacher-Incentive Observed Data

Variable

Control (Nc = 54) Treated (Nt = 53)

Average (S.D.) Average (S.D.) Min Max

Pre-treatment pctprewritten

0.19 (0.19) 0.16 (0.17) 0.00 0.67

Post-treatment open

0.58 (0.19) 0.80 (0.13) 0.00 1.00

pctpostwritten 0.47 (0.19) 0.52 (0.23) 0.05 0.92

written

0.92 (0.45) 1.09 (0.42) 0.07 2.22

written all

0.46 (0.32) 0.60 (0.39) 0.04 1.43

of 57 schools, the salary structure was changed so that teachers were given a salary that was tied to their (i.e., the teachers') attendance over a month-long period, whereas in the remaining 56 schools, the salary structure was unchanged. In both treatment and control schools, the teachers were given cameras with time stamps and asked to have students take pictures of the class with the teacher, both at the beginning and at the end of every school day. In addition, there were random unannounced visits to the schools by program officials to see whether the school was open or not.
In the current chapter, to focus on Neyman's approach, we avoid complicating issues of unintended missing data, and we drop six schools with missing data and use the N = 107 schools with recorded values for all five key variables, in addition to the treatment indicator: four outcomes and one covariate. Out of these 107 schools/teachers, Nt = 53 were in the treatment group with a salary schedule tied to teacher attendance, and Nc = 54 were in the control sample. In our analyses, we use four outcome variables. The first is the proportion of times the school was open during a random visit (open). The second outcome is the percentage of students who completed a writing test (pctpostwritten). The third is the value of the writing test score (written), averaged over all the students in each school who took the test. Even though not all students took the test, in each class at least some students took the writing test at the end of the study. The fourth outcome variable is the average writing test score with zeros imputed for the students who did not take the test (written all). We use one covariate in the analysis, the percentage of students who completed the written test prior to the study (pctprewritten).
Table 6.1 presents summary statistics for the data set. For all five variables (the pretreatment variables pctprewritten, and the four outcome variables open, pctpostwritten, written, and written all), we present averages and standard deviations by treatment status, and the minimum and maximum values over the full sample.
6.3 UNBIASED ESTIMATION OF THE AVERAGE TREATMENT EFFECT
Suppose we have a population consisting of N units. As before, for each unit there exist two potential outcomes, Yi(0) and Yi(1), corresponding to the outcome under control and treatment respectively. As with the Fisher Exact P-value (FEP) approach discussed

86

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

in the previous chapter, the potential outcomes are considered fixed. As a result, the only random component is the vector of treatment assignments, W, with ith element Wi, which by definition has a known distribution in a completely randomized experiment.
Neyman was interested in the population average treatment effect:

fs

=

1 N

N i=1

Yi(1) - Yi(0)

= Y(1) - Y(0),

where Y(0) and Y(1) are the averages of the potential control and treated outcomes respectively:

Y(0) = 1 N

N

Yi(0),

and

Y(1) = 1 N

N

Yi(1).

i=1

i=1

Suppose that we observe data from a completely randomized experiment in which Nt =

N i=1

Wi

units

are

randomly

selected

to

be

assigned

to

treatment

and

the

remaining

Nc

=

N i=1

(1

-

Wi)

are

assigned

to

control.

Because

of

the

randomization,

a

natural

estimator

for the average treatment effect is the difference in the average outcomes between those

assigned to treatment and those assigned to control:

^ dif

=

Y

obs t

-

Y

obs c

,

where

Y

obs c

=

1 Nc

Yiobs
i:Wi=0

and

Y

obs t

=

1 Nt

Yiobs.
i:Wi=1

Theorem 6.1 The estimator ^ dif is unbiased for fs. Proof of Theorem 6.1. Using the fact that Yiobs = Yi(1) if Wi = 1, and Yiobs = Yi(0) if Wi = 0, we can write the estimator ^ dif as:

^ dif = 1 N N
i=1

Wi · Yi(1) Nt/N

-

(1

-

Wi) · Yi(0) Nc/N

.

Because we view the potential outcomes as fixed, the only component in this statistic that is random is the treatment assignment, Wi. Given the setup of a completely randomized experiment (N units, with Nt randomly assigned to the treatment), by Section 3.5, PrW (Wi = 1|Y(0), Y(1)) = EW [Wi|Y(0), Y(1)] = Nt/N. (Here we index the probability and expectation, and later the variance, operators by W to stress that the probability, expectation, or variance, is taken solely over the randomization distribution, keeping fixed the potential outcomes Y(0) and Y(1), and keeping fixed the population.) Thus,

6.4 The Sampling Variance of the Neyman Estimator

87

^ dif is unbiased for the average treatment effect fs:

EW

^ dif Y(0), Y(1)

=1 N N i=1

EW [Wi] · Yi(1) - EW [1 - Wi]) · Yi(0)

Nt/N

Nc/N

=1 N N i=1

Yi(1) - Yi(0)

= fs.

Note that the estimator is unbiased, irrespective of the share of treated and control units in the randomized experiment. This does not imply, however, that this share is irrelevant for inference; it can greatly affect the precision of the estimator, as we see in the next section.
For the teacher-incentive experiment, taking the proportion of days that the school was open (open) as the outcome of interest, this estimator for the average effect is

^ dif

=

Y

obs t

-

Y

obs c

=

0.80

-

0.58

=

0.22,

as can be seen from the numbers in Table 6.1.

6.4 THE SAMPLING VARIANCE OF THE NEYMAN ESTIMATOR

Neyman was also interested in constructing interval estimates for the average treatment

effect, which he later (Neyman, 1934) termed confidence intervals. This construction

involves three steps. First, derive the sampling variance of the estimator for the average

treatment effect. Second, develop estimators for this sampling variance. Third, appeal

to a central limit argument for the large sample normality of ^ over its randomization

distribution and use its estimated sampling variance from step 2 to create a large-sample

confidence interval for the average treatment effect fs.

In this section we focus on the first step, deriving the sampling variance of the pro-

posed

estimator

^ dif

=

Y

obs t

- Y cobs .

This

derivation

is

relatively

cumbersome

because

the

assignments for different units are not independent in a completely randomized experi-

ment. With the number of treated units fixed at Nt, the fact that unit i is assigned to the

active treatment lowers the probability that unit i will receive active treatment. To show

how to derive the sampling variance, we start with a simple example of only two units

with one unit assigned to each treatment group. We then expand our discussion to the

general case with N units and Nt randomly assigned to active treatment.

6.4.1 The Sampling Variance of the Neyman Estimator with Two Units
Consider the simple case with one treated and one control unit. The estimand, the finite sample average treatment effect, in this case is

fs

=

1 2

·

(Y1(1) - Y1(0)) + (Y2(1) - Y2(0)) .

(6.1)

88

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

In a completely randomized experiment, both units cannot receive the same treatment; it follows that W1 = 1 - W2. The estimator for the average treatment effect is therefore:
^ dif = W1 · Y1obs - Y2obs + (1 - W1) · Y2obs - Y1obs .
If unit 1 receives the treatment (W1 = 1), our estimate of the average treatment effect will be ^ dif = Y1obs - Y2obs = Y1(1) - Y2(0). If on the other hand, W1 = 0, the estimate will be ^ = Y2obs - Y1obs = Y2(1) - Y1(0), so that we can also write:
^ dif = W1 · Y1(1) - Y2(0) + (1 - W1) · Y2(1) - Y1(0) .

To simplify the following calculations of the sampling variance of this estimator,
define the binary variable D = 2 · W1 - 1, so that D  {-1, 1}, W1 = (1 + D)/2 and W2 = 1 - W1 = (1 - D)/2. Because the expected value of the random variable W1 is equal to 1/2, the expected value of D, over the randomization distribution, is EW [D] = 0, and the variance is VW (D) = EW [D2] = D2 = 1. In terms of D and the potential outcomes, we can write the estimator ^ as:

^ dif = D + 1 · 2

Y1(1) - Y2(0)

+ 1-D · 2

Y2(1) - Y1(0) ,

which can be rewritten as:

^ dif = 1 · 2

Y1(1) - Y1(0) + Y2(1) - Y2(0)

+D· 2

Y1(1) + Y1(0) - Y2(1) + Y2(0)

=

fs

+

D 2

·

Y1(1) + Y1(0) - Y2(1) + Y2(0) .

Because EW [D] = 0, we can see immediately that ^ dif is unbiased for fs (which we already established in Section 6.3 for the general case). However, the representation in terms of D also makes the calculation of its sampling variance straightforward:

VW (^ dif) = VW

fs

+

D 2

·

Y1(1) + Y1(0) - Y2(1) + Y2(0)

=

1 4

·

VW (D)

·

Y1(1) + Y1(0) - Y2(1) + Y2(0) 2,

because  and the potential outcomes are fixed. Given that VW (D) = 1, it follows that the sampling variance of our estimator ^ dif is equal to:

VW (^ dif)

=

1 4

·

Y1(1) + Y1(0) - Y2(1) + Y2(0) 2.

(6.2)

This representation of the sampling variance shows that this will be an awkward object to estimate, because it depends on all four potential outcomes, including products of the different potential outcomes for the same unit that are never jointly observed.

6.4 The Sampling Variance of the Neyman Estimator

89

6.4.2 The Sampling Variance of the Neyman Estimator with N Units

Next, we look at the general case with N > 2 units, of which Nt are randomly assigned to

treatment.

To

calculate

the

sampling

variance

of

^ dif

=

Y

obs t

-

Y oc bs ,

we

need

the

expec-

tations of the second and cross moments of the treatment indicators Wi for i = 1, . . . , N.

Because Wi  {0, 1}, Wi2 = Wi, and thus

EW

Wi2

=

EW

[Wi]

=

Nt , N

and

VW (Wi)

=

Nt N

·

1 - Nt N

.

To calculate the cross moment in a completely randomized experiment, recall that
with the number of treated units fixed at Nt, the two events ­ unit i being treated and unit i being treated ­ are not independent. Therefore EW [Wi · Wi ] = EW [Wi] · EW [Wi ] = (Nt/N)2. Rather:

EW [Wi · Wi ] = PrW (Wi = 1) · PrW (Wi

=

1|Wi

=

1)

=

Nt N

·

Nt N

- -

1 1

,

for i = j,

because conditional on Wi = 1 there are Nt - 1 treated units remaining, out of a total of N - 1 units remaining. Given the sampling moments derived, we can infer the sampling

variance and covariance of Wi and Wi .

Theorem

6.2

The

sampling

variance

of

^ dif

=

Y

obs t

-

Y

obs c

is

VW

Y

obs t

-

Y

obs c

= Sc2 + St2 - St2c , Nc Nt N

(6.3)

where Sc2 and St2 are the variances of Yi(0) and Yi(1) in the sample, defined as:

Sc2

=

N

1 -1

N

Yi(0) - Y(0) 2,

and

St2

=

N

1 -1

N

Yi(1) - Y(1) 2,

i=1

i=1

and St2c is the sample variance of the unit-level treatment effects, defined as:

St2c

=

N

1 -

1

N i=1

Yi(1) - Yi(0) - (Y(1) - Y(0))

2

=1 N-1

N i=1

Yi(1) - Yi(0) - fs

2.

Proof of Theorem 6.2. See Appendix A.
Let us consider the interpretation of the three components of this variance in turn.
The first two are related to sample variances for averages of random samples. Recall
that the finite-sample average treatment effect is the difference in average potential outcomes: fs = Y(1) - Y(0). To estimate fs, we first estimate Y(1), the population average potential outcome under treatment, by the average outcome for the Nt treated units, Ytobs. This estimator is unbiased for Y(1). The population variance of Yi(1) is St2 = i (Yi(1) - Y(1))2/(N - 1). Given this population variance for Yi(1), the sampling variance for an average of a random sample of size Nt would be (St2/Nt) · (1 - Nt/N),

90

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

where the last factor is the finite sample correction. The first term has this form, except

for the finite sample correction. Similarly, the average outcome for the Nc units assigned to control, Yocbs, is unbiased for the population average outcome under the control treatment, Y(0), and its sampling variance, ignoring the finite population correction, is Sc2/Nc.
These results follow by direct calculation, or by using standard results from the analysis

of simple random samples: given a completely randomized experiment, the Nt treated

units provide a simple random sample of the N values of Yi(1), and the Nc control units

provide a simple random sample of the N values of Yi(0).

The third component of this sampling variance, St2c/N, is the sample variance of the

unit-level treatment effects, Yi(1)-Yi(0). If the treatment effect is constant in the popula-

tion, this third term is equal to zero. If the treatment effect is not constant, St2c is positive.

Because it is subtracted from the sum of the first two elements in the expression for the

sampling

variance

of

Y

obs t

-

Y oc bs ,

Equation

(6.3),

the

positive

value

for

St2c

reduces

the

sampling variance of this estimator for the average treatment effect.

There is an alternative representation of the sampling variance of ^ dif that is useful.

First we write the variance of the unit-level treatment effect as a function of tc, the

population correlation coefficient between the potential outcomes Yi(1) and Yi(0):

St2c = Sc2 + St2 - 2 · tc · Sc · St,

where

tc =

1 (N - 1) · Sc · St

N i=1

Yi(1) - Y(1)

·

Yi(0)) - Y(0)

.

(6.4)

By definition, tc is a correlation coefficient and so lies in the interval [-1, 1]. Substituting this representation of St2c into Equation (6.3), the alternative expression for the sampling variance of ^ dif (alternative to (6.3)) is:

VW

Y

obs t

-

Y

obs c

=

Nt N · Nc

· Sc2

+

Nc N · Nt

· St2

+

2 N

· tc

· Sc

· St.

(6.5)

The sampling variance of our estimator is smallest when the potential outcomes are perfectly negatively correlated (tc = -1), so that

St2c = Sc2 + St2 + 2 · Sc · St,

and

VW

Y

obs t

-

Y

obs c

tc = -1

=

Nt N · Nc

· Sc2

+

Nc N · Nt

· St2

-

2 N

· Sc

· St,

and largest when the two potential outcomes are perfectly positively correlated (tc = +1), so that

St2c = Sc2 + St2 - 2 · Sc · St,

6.4 The Sampling Variance of the Neyman Estimator

91

and

VW

Y

obs t

-

Y

obs c

tc = 1

=

Nt N · Nc

· Sc2

+

Nc N · Nt

· St2

+

2 N

· Sc

· St

= Sc2 + St2 - (Sc - St)2 .

Nc Nt

N

(6.6)

The most notable special case of perfect correlation arises when the treatment effect is constant and additive, Yi(1) - Yi(0) =  for all i = 1, . . . , N. In that case,

Vconst = VW

Y

obs t

-

Y

obs c

tc = 1, Sc2 = St2

= Sc2 + St2 . Nc Nt

(6.7)

The

fact

that

the

sampling

variance

of

Y

obs t

-

Y

obs c

is

largest

when

the

treatment

effect

is constant (i.e., not varying) across units may appear somewhat counterintuitive. Let

us therefore return to the two-unit case and consider the form of the sampling variance

there in more detail. In the two-unit case, the sampling variance, presented in Equa-

tion (6.2), is a function of the sum of the two potential outcomes for each of the two

units. Consider two numerical examples. In the first example, Yi(0) = Yi(1) = 10, and Y2(0) = Y2(1) = -10, corresponding to a zero treatment effect for both units. To calculate the correlation between the two potential outcomes, we use expression (6.4) for tc and find the numerator of tc equals

1N N - 1 i=1

Yi(1) - Y(1)

·

Yi(0) - Y(0)

= (Y1(1) - 0) · (Y1(0) - 0) + (Y2(1) - 0) · (Y2(0) - 0) = 200,

and the two components of the denominator of tc equal

Sc2

=

N

1 -1

N i=1

Yi(0) - Y(0)

2=

(10 - 0)2 + (-10 - 0)2

= 200,

and

St2

=

N

1 -1

N

Yi(1) - Y(1) 2 = (10 - 0)2 + ( - 10 - 0)2

= 200,

i=1

so that the correlation between the two potential outcomes is 1. In the second example, suppose that Y1(0) = Y2(1) = -10, and Y1(1) = Y2(0) = 10. A similar calculation shows that the correlation between the two potential outcomes is now -1. In both
examples the average treatment effect is zero, but in the first case the treatment effect is
constant and thus equal to 0 for each unit, whereas in the second case the treatment effect for unit 1 is equal to 20, and for unit 2 the treatment effect is equal to -20. As a result,
when estimating the average treatment effect, in the first case the two possible values of the estimator are Y1obs - Y2obs = 20 (if W1 = 1 and W2 = 0) and Y2obs - Y1obs = - 20 (if W1 = 0 and W2 = 1). In contrast, in the second case the two values of the estimator

92

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

are both equal to 0. Hence, the sampling variance of the estimator in the first case, with tc = +1, is positive (in fact, equal to 202), whereas in the second case, with tc = -1, the sampling variance is 0.

6.5 ESTIMATING THE SAMPLING VARIANCE

Now

that

we

have

derived

the

sampling

variance

of

our

estimator,

^ dif

=

Y

obs t

-

Y

obs c

,

the next step is to develop an estimator for this sampling variance. To do this, we

consider separately each of the three elements of the sampling variance given in

Equation (6.3).

The numerator of the first term, the sample variance of the potential control outcome vector, Y(0), is equal to Sc2. As shown in Appendix A, or from standard results on simple random samples, an unbiased estimator for Sc2 is

sc2

=

1 Nc - 1

i:Wi=0

Yi

(0)

-

Y

obs c

2

1

=

Nc - 1 i:Wi=0

Yiobs

-

Y

obs c

2
.

Analogously, we can estimate St2, the population variance of Yi(1), by

s2t

=

1 Nt - 1

i:Wi=1

Yi(1)

-

Y

obs t

2
=

1

Nt - 1 i:Wi=1

Yiobs

-

Y

obs t

2
.

The third term, St2c (the population variance of the unit-level treatment effects), is generally impossible to estimate empirically because we never observe both Yi(1) and
Yi(0) for the same unit. We therefore have no direct observations on the variation in the treatment effects across the population and therefore cannot directly estimate St2c. As noted previously, if the treatment effects are constant and additive (Yi(1) - Yi(0) = fs
for all units), then this component of the sampling variance is equal to zero and the third
term vanishes. Thus we have proved:

Theorem 6.3 If the treatment effect Yi(1) - Yi(0) is constant, then an unbiased estimator for the sampling variance is

V^ neyman = s2c + st2 . Nc Nt

(6.8)

This estimator for the sampling variance is widely used, even when the assumption of

an additive treatment effect may be known to be inaccurate. There are two main reasons

for the popularity of this estimator for the sampling variance. First, by implicitly setting

the third element of the estimated sampling variance equal to zero, the expected value of

V^ neyman

is

at

least

as

large

as

the

true

sampling

variance

of

Y

obs t

-

Y

obs c

,

irrespective

of

the heterogeneity in the treatment effect, because the third term is non-negative. Hence,

in large samples, confidence intervals generated using this estimator of the sampling

variance will have coverage at least as large, but not necessarily equal to, their nominal

6.5 Estimating the Sampling Variance

93

coverage.1 (Note that this statement still needs to be qualified by the clause "in large

samples," because we rely on the central limit theorem to construct normal-distribution-

based confidence intervals.) It is interesting to return to the discussion between Fisher

and Neyman regarding the general interest in average treatment effects and sharp null

hypotheses. Neyman's proposed estimator for the sampling variance is unbiased only

in the case of a constant additive treatment effect, which is satisfied under the sharp

null hypothesis of no treatment effects whatsoever, which was the case considered by

Fisher. In other cases the proposed estimator of the sampling variance generally over-

estimates

the

true

sampling

variance

of

Y

obs t

-

Y

obs c

.

As

a

result,

Neyman's

interval

is generally statistically conservative in large samples. The second reason for using

V^ neyman

as

an

estimator

for

the

sampling

variance

of

Y

obs t

-

Y

obs c

is

that

it

is

always

unbi-

ased for the sampling variance of ^ dif as an estimator of the infinite super-population

average treatment effect; we discuss this population interpretation at greater length in

Section 6.7.

In the remainder of this section, we consider two alternative estimators for the sampling variance of ^ dif. The first explicitly allows for treatment effect heterogeneity.

Under treatment effect heterogeneity, the estimator for the sampling variance in Equation (6.8), V^ neyman, provides an upwardly biased estimate: the third term, which vanishes

if the treatment effect is constant, is now negative. The question arises whether we can

improve upon the Neyman variance estimator without risking under coverage in large

samples.

To see that there is indeed information to do so, recall our argument that an implica-

tion of constant treatment effects is that the variances Sc2 and St2 are equal. A difference

between these variances, which would in large samples lead to a difference in the cor-

responding estimates sc2 and st2, indicates variation in the treatment effects. To use this

information

to

create

a

better

estimator

for

the

sampling

variance

of

Y

obs t

-

Y oc bs ,

let

us

turn to the representation of the sampling variance in Equation (6.5), which incorporates

tc, the population correlation coefficient between the potential outcomes:

VW

Y

obs t

-

Y

obs c

=

Sc2

·

Nt N · Nc

+

Sc2

·

Nc N · Nt

+

tc

·

Sc

·

St

·

2 .
N

Conditional on a value for the correlation coefficient, tc, we can estimate this sampling variance as

V^ tc

=

s2c

·

Nt N · Nc

+

st2

·

Nc N · Nt

+

tc

·

sc

·

st

·

2 .
N

(6.9)

This variance is again largest if the two potential outcomes are perfectly correlated, that is, 01 = 1. An alternative conservative estimator of the sampling variance that exploits

1 This potential difference between actual and nominal coverage of confidence intervals in randomized experiments concerned Neyman, and probably with this in mind, he formally defined confidence intervals in 1934 to allow for the possibility that the actual coverage could be greater than the nominal coverage. Thus the proposed "conservative" intervals are still valid in large samples. Fisher (1934) in his discussion did not agree with the propriety of this definition.

94

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

this bound is

V^ tc=1

=

sc2

·

Nt N · Nc

+ s12

·

Nc N · Nt

+

sc

·

st

·

2 N

= sc2 + s2t - (st - sc)2 .

Nc Nt

N

(6.10)

If s2c and st2 are unequal, then V^ tc=1 will be smaller than V^ neyman. Using V^ tc=1 to construct confidence intervals will result in tighter confidence intervals than using V^ neyman, without compromising their large-sample validity. The intervals based on V^ tc=1 will still be conservative in large samples, because V^ tc=1 is still upwardly biased when the true correlation is smaller than one, although less so than V^ neyman. Note, however, that with no information beyond the fact that s2c = st2, all choices for tc smaller than unity raise the possibility that we will underestimate the sampling variance and construct invalid
confidence intervals.
Next consider an alternative sampling variance estimator under the additional assump-
tion that the treatment effect is constant, Yi(1) - Yi(0) =  for all i. This alternative
estimator exploits the fact that under the constant treatment assumption, the population variances of the two potential outcomes, Sc2 and St2, must be equal. We can therefore define S2  Sc2 = St2 and pool the outcomes for the the treated and control units to estimate this common variance:

s2

=

N

1 -

2

·

s2c 

·

(Nc

-

1)

+

st2

· (Nt

-

1)



=

N

1 -

2

·



Yiobs

-

Y

obs c

2
+

Yiobs

-

Y

obs t

2 .

i:Wi=0

i:Wi=1

(6.11)

The larger sample size for this estimator (from Nc and Nt for s2c and s2t respectively, to N

for

s2),

leads

to

a

more

precise

estimator

for

the

sampling

variance

of

Y

obs t

-

Y

obs c

if

the

treatment effect is constant, namely

V^ const = s2 · 1 + 1 . Nc Nt

(6.12)

When the treatment effects are constant this estimator is preferable to either V^ neyman or V^ tc=1, but if not, it need not be valid. Both V^ neyman and V^ tc=1 are valid generally and therefore may be preferred.
Let us return to the Duflo-Hanna-Ryan teacher-incentive data. The estimate for the
average effect of assignment to the incentives-based salary rather than the conventional
salary structure, on the probability that the school is open, is, as discussed in the previous
section, equal to 0.22. Now let us consider estimators for the sampling variance. First we estimate the sample variances Sc2, St2, and the combined variance S2; the estimates are

sc2 = 0. 192, s2t = 0. 132, and s2 = 0. 162.

6.6 Confidence Intervals and Testing

95

The two sample variances sc2 and st2 are quite different, with their ratio being larger than two. Next we use the sample variances of the potential outcomes to estimate the sampling variance for the average treatment effect estimator. The first estimate for the sampling variance, which is, in general, conservative but allows for unrestricted treatment effect heterogeneity, is

V^ neyman = s2c + st2 = 0. 03112. Nc Nt
(We report four digits after the decimal point to make explicit the small differences between the various estimators for the sampling variance, although in practice one would probably only report two or three digits.) The second estimate, still conservative, but exploiting differences in the variances of the outcome by treatment group, and again allowing for unrestricted treatment effect heterogeneity, is

V^ tc=1

=

sc2 ·

Nt N · Nc

+ st2 ·

Nc N · Nt

+ sc · st

·

2 N

= 0. 03052.

By construction this estimator is smaller than V^ neyman. However, even though the variances sc2 and st2 differ by more than a factor of two, the difference in the estimated sampling variances V^ tc=1 and V^ neyman is very small in this example, less than 1%. In general, the standard variance V^ neyman is unlikely to be substantially larger than V^ tc=1,
as suggested by this example. The third and final estimate of the sampling variance,
which relies on a constant treatment effect for its validity, is

V^ const = s2 · 1 + 1 = 0. 03122, Nc Nt
slightly larger than the other estimates, but essentially the same for practical purposes.

6.6 CONFIDENCE INTERVALS AND TESTING
In the introduction to this chapter, we noted that Neyman's interest in estimating the precision of the estimator for the average treatment effect was largely driven by an interest in constructing confidence intervals. By a confidence interval with confidence coefficient 1 - , here we mean a pair of functions CL(Yobs, W) and CU(Yobs, W), defining an interval [CL(Yobs, W), CU(Yobs, W)], such that
PrW (CL(Yobs, W)    CU(Yobs, W))  1 - .
The only reason the lower and upper bounds in this interval are random is through their dependence on W. The distribution of the confidence limits is therefore generated by the randomization. Note that, in this expression, the probability of including the true value  may exceed 1-, in which case the interval is considered valid but conservative. Here we discuss a number of ways to construct such confidence intervals and to conduct tests for hypotheses concerning the average treatment effect. We will use the Duflo-Hanna-Ryan data to illustrate the steps of Neyman's approach.

96

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

6.6.1 Confidence Intervals Let V^ be an estimate of the sampling variance of ^ dif over its randomization distribution (in practice we recommend using V^ neyman). Suppose we wish to construct a 90% confidence interval. We base the interval on a normal approximation to the randomization distribution of ^ dif. This approximation is somewhat intellectually inconsistent with our stress on finite-sample properties of the estimator for  and its sampling variance, but it is driven by the common lack of empirical a priori information about the joint distribution of the potential outcomes. As we will see, normality is often a good approximation to the randomization distribution of standard estimates, even in fairly small samples. To further improve on this approximation, we could approximate the distribution of V^ neyman by a chi-squared distribution, and then use that to approximate the distribution of ^ dif/ V^ neyman by a t-distribution. For simplicity here, we use the 5th and 95th percentile of the standard normal distribution, -1.645 and 1.645, to calculate a nominal central 90% confidence interval as:
CI0.90(fs) = ^ dif - 1.645 · V^ , ^ dif + 1.645 · V^ .

More generally, if we wish to construct a central confidence interval with nominal confidence level (1 - ) × 100%, as usual we look up the /2 and 1 - /2 quantiles of the standard normal distribution, denoted by z/2, and construct the confidence interval:
CI1-(fs) = ^ dif + z/2 · V^ , ^ dif + z1-/2 · V^ .

This approximation applies when using any estimate of the sampling variance, and, in large samples, the resulting intervals are valid confidence intervals under the same assumptions that make the corresponding estimator for the sampling variance an unbiased or upwardly biased estimator of the true sampling variance.
Based on the three sampling variance estimates reported in the previous section for the outcome that the school is open, we obtain the three following 90% confidence intervals. First, based on V^ neyman = 0.03112, we find
CIn0.e9y0man(fs) = ^ dif + z0.10/2 · V^ neyman, ^ dif + z1-0.10/2 · V^ neyman
= (0.2154 - 1.645 · 0.0311, 0.2154 + 1.645 · 0.0311) = (0.1642, 0.2667).

Second, based on the sampling variance estimator assuming a constant treatment effect, V^ const = 0.03122, we obtain a very similar interval,
CI0co.9n0st(fs) = (0.1640, 0.2668).
Finally, based on the third sampling variance estimator, V^ tc=1 = 0.03052, we obtain again a fairly similar interval,
CI0.t9c=0 1(fs) = (0.1652, 0.2657).
With the estimates for the sampling variances so similar, the three 90% large-sample confidence intervals are also very similar.

6.6 Confidence Intervals and Testing

97

6.6.2 Testing
We can also use the sampling variance estimates to carry out tests of hypotheses concerning the average treatment effect. Suppose we wish to test the null hypothesis that the average treatment effect is zero against the alternative hypothesis that the average effect differs from zero:

H0neyman : Haneyman :

1 N

N i=1

(Yi(1) - Yi(0))

= 0,

and

1 N

N

(Yi(1) - Yi(0)) = 0.

i=1

A natural test statistic to use for Neyman's "average null" is the ratio of the point estimate

to

the

estimated

standard

error.

For

the

teacher-incentive

data,

the

point

estimate

is

Y

obs t

-

Y

obs c

=

0.2154.

The

estimated

standard

error

is,

using

the

conservative

estimator

for

the

sampling variance, V^ neyman, equal to 0.0311. The resulting t-statistic is therefore

t

=

Y

obs t

-

Y

obs c

=

- 0.2154

=

6.9.

V^ neyman

0.0311

The associated p-value for a two-sided test, based on the normal approximation to the distribution of the t-statistic, is 2 · (1 - (6.9)) < 0.001. At conventional significance levels, we clearly reject the (Neyman) null hypothesis that the average treatment effect is zero.
It is interesting to compare this test, based on Neyman's approach, to the FEP approach. There are two important differences between the two approaches. First, and most important, they assess different null hypotheses, for example, a zero average effect for Neyman versus a zero effect for all units for Fisher (although Fisher's null hypothesis implies Neyman's). Second, the Neyman test relies on a large-sample normal approximation for its validity, whereas the p-values based on the FEP approach are exact.
Let us discuss both differences in more detail. First consider the difference in hypotheses. The Neyman test assesses whether the average treatment effect is zero, whereas the FEP assesses whether the treatment effect is zero for all units in the experiment. Formally, in the Fisher approach the null hypothesis is

H0fisher : Yi(1) - Yi(0) = 0 for all i = 1, . . . , N,

and the (implicit) alternative hypothesis is

Hafisher : Yi(1) - Yi(0) = 0 for some i = 1, . . . , N.

Depending on the implementation of the FEP approach, this difference in null hypotheses may be unimportant. If we choose to use a test statistic proportional to the average difference, we end up with a test that has virtually no power against alternatives with heterogeneous treatment effects that average out to zero. We would have power against at least some of those alternatives if we choose a different statistic. Consider as an example a population where for all units Yi(0) = 2. For 1/3 of the units the treatment effect is

98

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

2. For 2/3 of the units the treatment effect is -1. In this case the Neyman null hypothesis

of a zero average effect is true. The Fisher null hypothesis of no effect whatsoever is not

true. Whether we can detect this violation depends on the choice of statistic. The FEP

approach, with the statistic equal to the average difference in outcomes by treatment sta-

tus, has no power against this alternative. However, the FEP approach, with a different

statistic, based on the average difference in outcomes after transforming the outcomes by

taking logarithms, does have power in this setting. In this artificial example, the expected

difference in logarithms by treatment status is -0.23. The FEP based on the difference

in average logarithms will detect this difference in large samples.

The second difference between the two procedures is in the approximate nature of the

Neyman test, compared to the exact results for the FEP approach. We use two approx-

imations in the Neyman approach. First, we use the estimated variance (e.g., V^ neyman)

instead

of

the

actual

variance

(VW

(Y

obs t

-

Y

obs c

)).

Second,

we

use

a

normal

approxima-

tion

for

the

repeated

sampling

distribution

of

the

difference

in

averages

Y

obs t

-

Y

obs c

.

Both

approximations are justified in large samples. If the sample is reasonably large, and if

there are few or no outliers, as in the application in this chapter, these approximations

will likely be accurate.

6.7 INFERENCE FOR POPULATION AVERAGE TREATMENT EFFECTS

In the introduction to this chapter, we commented on the distinction between a finite population interpretation, in which the sample of size N is considered the population of interest, and a super-population perspective, in which the N observed units are viewed as a random sample from an essentially infinite population. The second argument in favor of using the sampling variance estimator V^ neyman in Equation (6.8) is that, regardless of the level of heterogeneity in the unit-level treatment effect, V^ neyman is unbiased for the sampling variance of the estimator ^ dif for the super-population, as opposed to the finite sample, average treatment effect. Here we further explore this argument, address how it affects our interpretation of the estimator of the average treatment effect, and discuss the various choices of estimators for its sampling variance.
Suppose that the population of N subjects taking part in the completely randomized experiment is itself a simple random sample from a larger population, which, for simplicity, we assume is infinite. This is a slight departure from Neyman's explicit focus on the average treatment effect for a finite population. In many cases, however, this change of focus is immaterial. Although in some agricultural experiments, farmers may be genuinely interested in which fertilizer was best for their specific fields in the year of the experiment, in most social and medical science settings, experiments are, explicitly or implicitly, conducted with a view to inform policies for a larger population of units, often assumed to have generated the N units in our sample by random sampling. However, without additional information, we cannot hope to obtain more precise estimates for the treatment effects in the super-population than for the treatment effects in the sample. In fact, the estimates for the population estimands are typically strictly less precise. Ironically it is exactly this loss in precision that enables us to obtain unbiased estimates of the sampling variance of the traditional estimator for the average treatment effect in the super-population.

6.7 Inference for Population Average Treatment Effects

99

Viewing our N units as a random sample of the target super-population, rather than viewing them as the population itself, induces a distribution on the two potential outcomes for each unit. The pair of potential outcome values for an observed unit i is simply one draw from the distribution in the population and is, therefore, itself stochastic. The distribution of the pair of two potential outcomes in turn induces a distribution on the unit-level treatment effects and on the average of the unit-level treatment effects within the drawn sample. To be clear about this super-population perspective, we use the subscript fs to denote the finite-sample average treatment effect and sp to denote the super-population average treatment effect:

fs

=

1 N

N
(Yi(1) - Yi(0))
i=1

and sp = Esp [Yi(1) - Yi(0)] .

Analogously, the subscript sp on the expectations operator indicates that the expectation is taken over the distribution generated by random sampling from the super-population and not solely over the randomization distribution. Thus sp = Esp[Yi(1) - Yi(0)] is the expected value of the unit-level treatment effect, under the distribution induced by sampling from the super-population or, equivalently, the average treatment effect in the super-population. Because of the random sampling, sp is also equal to the expected value of the finite-sample average treatment effect,

Esp [fs] = Esp

Y(1) - Y(0)

=

1 N

N i=1

Esp [Yi(1) - Yi(0)] = sp.

(6.13)

See Appendix B for details on the super-population perspective. Let t2c be the variance of the unit-level treatment effect in this super-population, t2c = Vsp(Yi(1) - Yi(0)) = Esp[(Yi(1) - Yi(0) - sp)2], and let c2 and t2 denote the population variances of the two potential outcomes, or the super-population expectations of Sc2 and St2:

c2 = Vsp(Yi(0)) = Esp (Yi(0) - Esp[Yi(0))2 ,

and

t2 = Vsp(Yi(1)) = Esp (Yi(1) - Esp[Yi(1))2 .

The definition of the variance of the unit-level treatment effect within the superpopulation, t2c, implies that the variance of fs across repeated random samples is equal to

Vsp(fs) = Vsp Y(1) - Y(0) = t2c/N.

(6.14)

Now let us consider the sampling variance of the standard estimator for the average

treatment

effect,

^ dif

=

Y

obs t

-

Y oc bs ,

given

this

sampling

from

the

super-population.

The

expectation and variance operators without subscripts denote expectations and variances

taken over both the randomization distribution and the random sampling from the super-

population.

100

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

We have

V ^ dif = E

Y

obs t

-

Y

obs c

-

E

Y

obs t

-

Y

obs c

2

=E

Y

obs t

-

Y

obs c

-

Esp

Y(1) - Y(0)

2
,

where the second equality holds because E

Y

obs t

-

Y

obs c

= Esp[Y(1) - Y(0)] = sp, as

shown above. Adding and subtracting Y(1) - Y(0) within the expectation, this sampling

variance, over both randomization and random sampling, is equal to:

V ^ dif

=E

Y

obs t

-

Y

obs c

-

Y(1) - Y(0)

+

Y(1) - Y(0)

- Esp

Y(1) - Y(0)

2

=E

Y

obs t

-

Y

obs c

-

(Y (1)

-

Y (0))

2

+ Esp Y(1) - Y(0) - Esp Y(1) - Y(0) 2

+2·E

Y

obs t

-

Y

obs c

-

Y(1) - Y(0)

· Y(1) - Y(0) - Esp Y(1) - Y(0)

.

The third term of this last expression, the covariance term, is equal to zero because the

expectation

of

the

first

factor,

Y

obs t

-

Y

obs c

-

(Y

(1)

-

Y

(0)),

conditional

on

the

N

-vectors

Y(0) and Y(1) (taking the expectation just over the randomization distribution), is zero.

Hence the sampling variance reduces to:

V

Y

obs t

-

Y

obs c

=E

Y

obs t

-

Y

obs c

-

Y (1)

-

Y (0)

2

+ Esp Y(1) - Y(0) - Esp [Y(1) - Y(0)] 2 .

(6.15)

Earlier we showed that EW

Y

obs t

-

Y

obs c

Y(0), Y(1)

= fs = Y(1) - Y(0); hence by

iterated expectations, the first term on the right side is equal to the expectation of the

conditional

(randomization-based)

variance

of

Y

obs t

-

Y

obs c

(conditional

on

the

N-vector

of potential outcomes Y(0) and Y(1)). This conditional variance is equal to

EW

Y

obs t

-

Y

obs c

-

Y (1)

-

Y (0)

2

Y(0), Y(1)

= Sc2 + St2 - St2c , Nc Nt N

(6.16)

as in Equation (6.3). Recall that these earlier calculations were made when assuming that the sample N was the population of interest and thus were conditional on Y(0) and Y(1). The expectation of (6.16) over the distribution of Y(0) and Y(1) generated by sampling

6.8 Neyman's Approach with Covariates

101

from the super-population is

E

Y

obs t

-

Y

obs c

-

Y (1)

-

Y (0)

2

= Esp EW

Y

obs t

-

Y

obs c

-

Y (1)

-

Y (0)

2

Y(0), Y(1)

= Esp

Sc2 + St2 - St2c Nc Nt N

= c2 + t2 - t2c . Nc Nt N

The expectation of the second term on the right side of Equation (6.15) is equal to t2c/N, as we saw in Equation (6.14). Thus the sampling variance of ^ dif over sampling from the super-population equals:

Vsp = Vsp

^ dif

= c2 + t2 , Nc Nt

(6.17)

which we can estimate without bias by substituting sc2 and st2 for c2 and t2, respectively:

V^ sp = s2c + st2 . Nc Nt

The estimator V^ sp is identical to the previously introduced conservative estimator of the sampling variance for the finite population average treatment effect estimator, V^ neyman,
presented in Equation 6.8. Under simple random sampling from the super-population, the expected value of the estimator V^ neyman equals Vsp. Hence, considering the N
observed units as a simple random sample from an infinite super-population, the esti-
mator in (6.8) is an unbiased estimate of the sampling variance of the estimator of the super-population average treatment effect. Neither of the alternative estimators ­ V^ const
in Equation (6.12), which exploits the assumption of a constant treatment effect, nor V^ tc=1 in Equation (6.10), derived through bounds on the correlation coefficient ­ has this attractive quality. Thus, despite the fact that V^ const may be a better estimator of
the sampling variance in the finite population when the treatment effect is constant, and V^ tc=1 may be a better estimator of Vfs, V^ neyman is used almost uniformly in practice in
our experience, although the logic for it appears to be rarely explicitly discussed.

6.8 NEYMAN'S APPROACH WITH COVARIATES
One can easily extend Neyman's approach for estimating average treatment effects to settings with discrete covariates. In this case, one would partition the sample into subsamples defined by the values of the covariate and then conduct the analysis separately within these subsamples. The resulting within-subsample estimators would be unbiased for the within-subsample average treatment effect. Taking an average of these estimates, weighted by subsample sizes, gives an unbiased estimate of the overall average treatment effect. As we see in Chapter 9, we consider this method in the discussion on stratified random experiments.

102

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

It is impossible, however, in general to derive estimators that are exactly unbiased under the randomization distribution, conditional on the covariates, when there are covariate values for which we have only treated or only control units, which is likely to happen with great frequency in settings with covariates that take on many values. In such settings, building a model for the potential outcomes, and using this model to create an estimator of the average treatment effect, is a more appealing option. We turn to this topic in the next two chapters.

6.9 RESULTS FOR THE DUFLO-HANNA-RYAN TEACHER-INCENTIVE DATA
Now let us return to the teacher-incentive data and systematically look at the results based on the methods discussed in the current chapter. We analyze four outcomes in turn, plus one "pseudo-outcome." For illustrative purposes, we report here a number of point, sampling variance, and interval estimates. The first variable we analyze, as if it were an outcome, is a pre-treatment variable, and so we know a priori that the causal effect of the treatment on this variable is zero, both at the unit level and on average. In general, it can be useful to carry out such analyses as a check on the success of the randomization: that is, we know here that the Fisher null hypothesis of no effect whatsoever is true. The pretreatment variable is pctprewritten, the percentage of students in a school that took the pre-program writing test. For this variable, we estimate, as anticipated, the average effect to be small, -0.03, with a 95% confidence interval that comfortably includes zero, (-0.10, 0.04).
Now we turn to the four "real" outcomes. In Table 6.2 we report estimates of the components of the variance, and in Table 6.3 we present estimates of and confidence intervals for the average treatment effects. First we focus on the causal effect of the attendance-related salary incentives on the proportion of days that the school was open during the days it was subject to a random check. The estimated effect is 0.22, with a 95% confidence interval of [0.15, 0.28]. It is clear that the attendance-related salary incentives appeared to lead to a higher proportion of days with the school open. We also look at the effect on the percentage of students in the school who took the written test, pctpostwritten. Here the estimated treatment effect is 0.05, with a 95% confidence interval of [- 0.03, 0.13]. The effect is not statistically significant at the 5% level, but it is at the 10% level. Next, we look at the average score on the writing test, which leads to a point estimate of 0.17, with a 95% confidence interval of [0.00, 0.34]. Finally, we examine the average test score, assigning zeros to students not taking the test. Now we estimate an average effect of 0.14, with a 95% confidence interval of [0.00, 0.28]. As with the Fisher exact p-value approach, the interpretation of nominal levels for tests and interval estimates formally holds for only one such interval. In the final analysis, we look at estimates separately for two subsamples, defined by whether the proportion of students taking the initial writing test was zero or positive, to illustrate the application of the methods developed in this chapter to subpopulations defined by covariates. Again, these analyses are for illustrative purposes only, and we do not take account of the fact that we do multiple tests. The first subpopulation (pctprewritten= 0) comprises 40 schools (37%) and the second (pctprewritten>0) 67 schools (63%). We analyze

6.9 Results for the Duflo-Hanna-Ryan Teacher-Incentive Data

103

Table 6.2. Estimates of Components of Variance of Estimator for the Effect of Teacher Incentives on the Proportion of Days that the School is Open; Nc = 54, Nt = 53, Duflo-HannaRyan Data

Estimated means Estimated variance components Sampling variance estimates

Y

obs c

Y

obs t

^

sc2 s2t s2

V^ neyman

=

s2c Nc

+

st2 Nt

V^ const = s2 ·

1 Nc

+

1 Nt

V^ tc=1

=

sc2

·

Nt N·Nc

+ s2t

·

Nc N·Nt

+ sc

·

st

·

2 N

0.58
0.80 0.22 0. 192 0. 132 0. 162
0. 032 0. 032 0. 032

Table 6.3. Estimates of, and Confidence Intervals for, Average Treatment Effects for Duflo-Hanna-Ryan Teacher-Incentive Data

ATE

(s. e. )

95% C.I.

0.22

(0.03)

(0.15,0.28)

0.05

(0.04)

(-0.03,0.13)

0.17

(0.08)

(0.00,0.34)

0.14

(0.07)

(0.00,0.28)

Table 6.4. Estimates of, and Confidence Intervals for, Average Treatment Effects for Duflo-Hanna-Ryan Teacher-Incentive Data

Variable

pctpre = 0 (N = 40)

pctprewritten > 0 (N = 67)

Difference

^ (s. e. ) 95% C.I. ^ (s. e. ) 95% C.I. EST (s. e. ) 95% C.I.

open

0.23 (0.05) (0.14,0.32) 0.21 (0.04) (0.13,0.29) 0.02 (0.06) (-0.10,0.14)

pctpost -0.004 (0.06) (-0.16,0.07) 0.11 (0.05) (0.01,0.21) -0.15 (0.08) (-0.31,0.00)

written

written 0.20 (0.10) (0.00,0.40) 0.18 (0.10) (-0.03,0.38) 0.03 (0.15) (-0.26,0.31)

written 0.04 (0.07) (-0.10,0.19) 0.22 (0.09) (0.04,0.40) -0.18 (0.12) (-0.41,0.05)

all

separately the effect of assignment to attendance-based teacher incentives on all four outcomes. The descriptive results are reported in Table 6.4. The main substantive finding is that the effect of the incentive scheme on writing skills (written) appears lower for schools where many students entered with insufficient writing skills to take the initial test. The 95% confidence interval comfortably includes zero (-0.41, 0.05), and the 90% confidence interval is (-0.37, 0.01).

104

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

6.10 CONCLUSION

In this chapter we discussed Neyman's approach to estimation and inference in completely randomized experiments. He was interested in assessing the operating characteristics of statistical procedures under repeated sampling and random assignment of treatments. Neyman focused on the average effect of the treatment. He proposed an estimator for the average treatment effect in the finite sample, and showed that it was unbiased under repeated sampling. He also derived the sampling variance for this estimator. Finding an estimator for this sampling variance that itself is unbiased turned out to be impossible in general. Instead Neyman showed that the standard estimator for the sampling variance of this estimator is positively biased, unless the treatment effects are constant and additive, in which case it is unbiased. Like Fisher's approach, Neyman's methods have great appeal in the settings where they apply. However, again like Fisher's methods, there are many situations where we are interested in questions beyond those answered by their approaches. For example, we may want to estimate average treatment effects adjusting for differences in covariates in settings where some covariate values appear only in treatment or control groups. In the next two chapters we discuss methods that do not have the exact (finite sample) statistical properties that make the Neyman and Fisher approaches so elegant in their simplicity but that do address more complicated questions, albeit under additional assumptions or approximations.

NOTES
There was disagreement between Fisher and Neyman regarding the importance of the null hypothesis of a zero average effect versus zero effects for all units. In the reading of Neyman's 1935 paper in the Journal of the Royal Statistical Society on the interpretations of data from a set of agricultural experiments, the discussion became very heated:
(Neyman) "So long as the average (emphasis in original) yields of any treatments are identical, the question as to whether these treatments affect separate yields on single plots seems to be uninteresting and academic. ..."
(Fisher) "... It may be foolish, but that is what the z [FEP] test was designed for, and the only purpose for which it has been used. ..."
(Neyman) "... I believe Professor Fisher himself described the problem of agricultural experimentation formerly not in the same manner as he does now. ..."
(Fisher) "... Dr. Neyman thinks another test would be more important. I am not going to argue that point. It may be that the question which Dr. Neyman thinks should be answered is more important than the one I have proposed and attempted to answer. I suggest that before criticizing previous work it is always wise to give enough study to the subject to understand its purpose. Failing that it is surely quite unusual to claim to understand the purpose of previous work better than its author."
Given the tone of Fisher's remarks, it is all the more suprising how gracious Neyman is in later discussions, for example, the quotations in Chapter 5.
Much of the material in this chapter draws on Neyman (1923), translated as Neyman (1990). Also see Neyman (1934, 1935), with discussions, as well as the comments in Rubin (1990b) on Neyman's work in this area.

Appendix A Sampling Variance Calculations

105

APPENDIX A SAMPLING VARIANCE CALCULATIONS

First

we

calculate

the

sampling

variance

of

the

estimator

^ dif

=

Y

obs t

-

Y oc bs .

As

before,

we have N units, Nt receiving the treatment and Nc receiving the control. The average

treatment effect is:

fs

= Y(1) - Y(0) =

1 N

N
(Yi(1) - Yi(0)) .
i=1

The standard estimator of fs is:

^ dif

=

Y

obs t

-

Y

obs c

=

1 Nt

N
Wi · Yiobs -
i=1

1 Nc

N
(1 - Wi) · Yiobs
i=1

=1 N N i=1

N Nt

·

Wi

·

Yi(1)

-

N Nc

·

(1

-

Wi)

·

Yi(0)

.

For the variance calculations, it is useful to work with a centered treatment indicator Di, defined as



Di

= Wi -

Nt N

 Nc

=

N - Nt

N

if Wi = 1 if Wi = 0.

The expectation of Di is zero, and its variance is V(Di) = E[D2i ] = NcNt/N2. Later we also need its cross moment, E[Di · Dj]. For i = j the distribution of this cross product is

2NN·t

· ·

(Nt - 1) (N - 1)
Nt · Nc

PrW

Di · Dj = d

=



Nc N

N · (N - 1) · (Nc - 1) · (N - 1)

0

if d = Nc2/N2 if d = -NtNc/N2 if d = Nt2/N2 otherwise,

thereby leading to

 

Nc

·

Nt

EW

Di · Dj

=

-

N2 Nt

·

Nc

N2 · (N -

1)

if i = j
. if i = j

106

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

In terms of Di, our estimate of the average treatment effect is:

Y

obs t

-

Y

obs c

=

1 N

N

i=1

N· Nt

Di

+

Nt N

·

Yi(1)

-

N Nc

·

Nc N

-

Di

· Yi(0)

=

1 N

N
(Yi(1) - Yi(0)) +
i=1

1 N

N
Di ·
i=1

N Nt

·

Yi(1)

+

N Nc

·

Yi(0)

= fs +

1 N

N
Di ·
i=1

N Nt

· Yi(1) +

N Nc

· Yi(0)

.

(A.1)

Because

EW [Di]

=

0

and

all

potential

outcomes

are

fixed,

the

estimator

Y

obs t

-

Y

obs c

is

unbiased for the average treatment effect, fs = Y(1) - Y(0).

Next, because the only random element in Equation (A.1) is Di, the variance of ^ =

Y

obs t

-

Y

obs c

is

equal

to

the

variance

of

the

second

term

in

Equation

(A.1).

Defining

Yi+ = (N/Nt)Yi(1) + (N/Nc)Yi(0), the latter is equal to:

VW

Y

obs t

-

Y

obs c

= VW

1 N

N

Di · Yi+

i=1



=

1 N2

·

EW



N
Di · Yi+
i=1

2 .
(A.2)

Expanding Equation (A.2), we get:





VW

Y

obs t

-

Y

obs c

=

EW



1 N2

N i=1

N
DiDjYi+Yj+
j=1

1N = N2
i=1

Yi+ 2 · EW

D2i

1N + N2 i=1 j=i EW

Di · Dj

· Yi+ · Yj+

=

Nc · Nt N4

N

i=1

Yi+

2

-

Nc · Nt N4 · (N -

1)

N i=1

j=i

Yi+ · Yj+

=

Nc · Nt N3 · (N - 1)

N i=1

Yi+

2-

Nc · Nt N4 · (N - 1)

N i=1

N
Yi+ · Yj+
j=1

=

Nc · Nt N3 · (N - 1)

N i=1

Yi+ - Y+ 2

=

Nc · Nt N3 · (N -

1)

N

i=1

N Nt

·

Yi(1)

+

N Nc

·

Yi(0)

-

N · Y(1) + N · Y(0)

Nt

Nc

2

Appendix A Sampling Variance Calculations

107

=

Nc · Nt N3 · (N - 1)

N i=1

N

N

2

Nt · Yi(1) - Nt · Y(1)

+

Nc · Nt N3 · (N - 1)

N i=1

N Nc

·

Yi(0)

-

N Nc

·

Y (0)

2

+

2 N3

· Nc · (N

· Nt - 1)

N

i=1

N Nt

·

Yi(1)

-

N Nt

·

Y (1)

·

N Nc

· Yi(0) -

N Nc

·

Y (0)

=

N

· Nt

Nc · (N

- 1)

N i=1

Yi(1) - Y(1)

2+

N

Nt · Nc · (N - 1)

N i=1

Yi(0) - Y(0) 2

+

2

N

N · (N - 1) i=1

Yi(1) - Y(1)

·

Yi(0) - Y(0)

.

(A.3)

Recall the definition of St2c, which implies that

St2c

=

N

1 -

1

N

Yi(1) - Y(1) - Yi(0) - Y(0) 2

i=1

=

N

1 -1

N i=1

Yi(1) - Y(1)

2+

1 N-1

N i=1

Yi(0) - Y(0) 2

-2 N N - 1 i=1

Yi(1) - Y(1)

·

Yi(0) - Y(0)

=

St2

+

Sc2

-

N

2 -

1

N

Yi(1) - Y(1) · Yi(0) - Y(0) .

i=1

Hence, the expression in (A.3) is equal to

VW

Y

obs t

-

Y

obs c

=

Nc N · Nt

·

St2

+

Nt N · Nc

·

Sc2

+1· N

St2 + Sc2 - St2c

= St2 + Sc2 - St2c . Nt Nc N

Now we investigate the bias of the Neyman estimator for the sampling variance, Vneyman,

under the assumption of a constant treatment effect. Assuming a constant treatment

effect, St2c is equal to zero, so we need only find unbiased estimators for Sc2 and St2 to

provide

an

unbiased

estimator

of

the

variance

of

Y

obs t

-

Y

ocbs.

Consider

the

estimator

st2

=

1 Nt -

1

i:Wi=1

Yiobs

-

Y

obs t

2
.

108

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

The goal is to show that the expectation of s2t is equal to

St2

=

N

1 -1

N i=1

Yi(1) - Y(1)

2

=

N N-1

Y2(1) - Y(1) 2

.

First,

s2t

=

1 Nt - 1

N i=1

1{Wi

=

1} ·

Yiobs

-

Y

obs t

2

=

1 Nt - 1

N i=1

1{Wi

=

1} ·

Yi(1)

-

Y

obs t

2

=

1 Nt - 1

N i=1

1{Wi

=

1} · Yi2(1) -

Nt Nt - 1

Y

obs t

2
.

(A.4)

Consider the expectation of the two terms in (A.4) in turn. Using again Di = 1Wi=1 - Nt/N, with E[Di] = 0, we have

E

1 Nt - 1

N i=1

1Wi=1

· Yi2(1)

=

1 Nt - 1

N i=1

E

Di

+

Nt N

=

Nt Nt -

1

·

Y 2 (1).

· Yi2(1)

Next, the expectation of the second factor in the second term in (A.4):





EW

Y

obs t

2

=

EW



1 Nt2

N i=1

N j=1

Wi · Wj

· Yiobs · Yjobs





=

EW

1 Nt2

N i=1

N
Wi · Wj · Yi(1) · Yj(1)
j=1

1NN

=

Nt2

i=1

EW
j=1

Di

+

Nt N

·

Dj

+

Nt N

· Yi(1) · Yj(1)

=

1 Nt2

N i=1

N
Yi(1) · Yj(1) ·
j=1

E

Di · Dj

+

Nt2 N2

=

1 Nt2

N
Yi2(1) ·
i=1

EW

Di2

+

Nt2 N2

+

1 Nt2

N i=1

j=i

Yi(1) · Yj(1) ·

EW

Di · Dj

+

Nt2 N2

Appendix B Random Sampling from a Super-Population

109

=

1 Nt2

N i=1

Yi2(1) ·

Nc · Nt N2

+

Nt2 N2

+

1 Nt2

N i=1

j=i

Yi(1) · Yj(1) ·

-

Nc · Nt N2 · (N -

1)

+

Nt2 N2

=

1 Nt

· Y2(1) +

Nt - 1 N · (N - 1) · Nt

N i=1

j=i

Yi(1) · Yj(1)

=

1 Nt

· Y2(1) -

Nt - 1 N · (N - 1) · Nt

N i=1

Yi2(1) +

N

Nt - 1 · (N - 1) · Nt

N i=1

N
Yi(1) · Yj(1)
j=1

= 1 · Y2(1) - Nt - 1 · Y2(1) + (Nt - 1) · N Y(1) 2

Nt

(N - 1) · Nt

(N - 1) · Nt

=

Nt

·

Nc (N -

1)

·

Y 2 (1)

+

(Nt - 1) · N (N - 1) · Nt

Y(1) 2 .

Hence, the expectation of the second term in (A.4) equals

- (Nt

-

Nc 1) · (N

-

1)

·

Y 2 (1)

+

(N

N -

1)

·

Y (1)

2,

and adding up the expectations of both terms in in (A.4) leads to

EW

st2

=

Nt Nt -

1

·

Y 2 (1)

-

(Nt

-

Nc 1) · (N

-

1)

·

Y 2 (1)

-

(N

N -

1)

·

Y(1) 2

=

N

N -

1

·

Y 2 (1)

-

(N

N -

1)

·

Y(1) 2 = St2.

Following the same argument,

EW s2c

=

1 Nc -

1

· EW

N
(1 - Wi) ·
i=1

Yiobs

-

Y

obs c

2

= Sc2.

Hence, the estimators s2c and s2t are unbiased for Sc2 and St2, and can be used to create an

unbiased

estimator

for

the

variance

of

Y

obs t

-

Y

cobs,

our

estimator

of

the

average

treatment

effect under the constant treatment effect assumption.

APPENDIX B RANDOM SAMPLING FROM A SUPER-POPULATION
In this chapter we introduced the super-population perspective. In this appendix we provide more details of this approach and its differences from the finite population perspective. Let Nsp be the size of the super-population, with Nsp large, but countable. Each unit in this population is characterized by the pair (Yi(0), Yi(1)), for i = 1, . . . , Nsp. Let Ysp(0) and Ysp(1) denote the Nsp-component vectors with ith element equal to Yi(0) and Yi(1) respectively. We continue to view these potential outcomes as fixed. Our finite

110

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

sample is a Simple Random Sample (SRS) of size N from this large super-population.

We take N as fixed. Let Ri denote the sampling indicator, so that Ri = 1 if unit i is

sampled, and Ri = 0 if unit i is not sampled, with

Nsp i=1

Ri

=

N.

The

sampling

indicator

is a binomial random variable with mean N/Nsp and variance (N/Nsp) · (1 - N/Nsp). The

covariance between Ri and Rj, for i = j, is -(N/Nsp)2. Within the finite sample of size

N, we carry out a completely randomized experiment, with Nt units randomly selected to

receive the active treatment, and the remaining Nc = N - Nt units assigned to receive the

control treatment. For the units in the finite sample, we have Wi = 1 for units assigned

to the treatment group, and Wi = 0 for units assigned to the control group. To simplify

the exposition, let us assign Wi = 0 to all units not sampled (with Ri = 0).

The super-population average treatment effect is

1 Nsp sp = Nsp i=1 (Yi(1) - Yi(0)) , and the variance of the treatment effect in the super-population is

t2c

=

1 Nsp

Nsp i=1

Yi(1) - Yi(0) - sp 2 .

Now consider the finite-population average treatment effect:

fs

=

1 N

Nsp i=1

Ri · (Yi(1) - Yi(0)) .

Viewing Ri as random, but keeping (Yi(0), Yi(1)), for i = 1, . . . , Nsp fixed, we can take the expectation of fs over the distribution generated by the random sampling. Indexing the expectations operator by subscript "sp" to be explicit about the fact that the expectation is taken over the distribution generated by the random sampling, and thus over Ri, i = 1, . . . , N, we have

Esp

fs| Ysp(0), Ysp(1)

1 Nsp

= N

Esp [Ri] · (Yi(1) - Yi(0))

i=1

1 Nsp N = N i=1 Nsp · (Yi(1) - Yi(0)) = sp.

The variance of the finite sample average treatment effect is

Vsp =

fs| Ysp(0),

Esp





1 N

Ysp
Nsp
i=1

(1) Ri

·

(Yi

(1)

-

Yi

(0))

-

2 sp

 Ysp(0), Ysp(1)

Appendix B Random Sampling from a Super-Population

111



=

Esp





1 N

Nsp

i=1

Ri

-

N Nsp

2



· Yi(1) - Yi(0) - sp  Ysp(0), Ysp(1)

=

1 N2

Nsp

Nsp
Esp

i=1 j=1

Ri

-

N Nsp

·

Rj

-

N Nsp



· Yi(1) - Yi(0) - sp · Yj(1) - Yj(0) - sp Ysp(0), Ysp(1)

= 1 - N/Nsp Nsp N · Nsp i=1

Yi(1) - Yi(0) - sp 2

1 Nsp - Ns2p i=1 j=i Yi(1) - Yi(0) - sp · Yj(1) - Yj(0) - sp

=

t2c N

- t2c Nsp

-

1 Ns2p

Nsp i=1

j=i

Yi(1) - Yi(0) - sp

·

Yj(1) - Yj(0) - sp

.

If Nsp is large relative to N, the last two terms are small relative to the first one, and the variance of fs over the super-population is approximately equal to

Vsp

fs| Ysp(0), Ysp(1)

 s2p . N

Now

let

us

consider

the

estimator

^ dif

=

Y

obs t

-

Y cobs .

We

can

write

this

in

terms

of

the super-population as

^ dif

=

1 Nt

Nsp i=1

Ri · Wi · Yiobs -

1 Nc

Nsp i=1

Ri · (1 - Wi) · Yiobs.

We can take the expectation of this estimator, first conditional on R (and always conditional on Ysp(1) and Ysp(0)), so the expectation is over the randomization distribution:

EW

^ dif R, Ysp(1), Ysp(0)

=

1 Nt

Nsp
Ri · EW [Wi] · Yiobs
i=1

-

1 Nc

Nsp
Ri · EW [1 - Wi] · Yiobs
i=1

1 Nsp

= N

Ri · (Yi(1) - Yi(0)) = fs.

i=1

112

Neyman's Repeated Sampling Approach to Completely Randomized Experiments

Thus, the sampling variance of ^ dif, over both the randomization distribution and the sampling distribution, is

E ^ dif Ysp(1), Ysp(0) = Esp EW ^ dif R, Ysp(1), Ysp(0) Ysp(1), Ysp(0) = Esp fs| Ysp(1), Ysp(0) = sp.

Next we calculate the sampling variance of  dif, over both the randomization distribution and the sampling distribution. By iterated expectations,

Vsp = V ^ dif Ysp(1), Ysp(0)

= Esp VW ^ dif R, Ysp(1), Ysp(0) Ysp(1), Ysp(0)

+ Vsp EW ^ dif R, Ysp(1), Ysp(0) Ysp(1), Ysp(0)

= Esp

Sc2 + St2 - St2c Nc Nt N

Ysp(1), Ysp(0)

+ Vsp

fs| Ysp(1), Ysp(0)

=

c2 Nc

+ t2 Nt

- t2c N

+

t2c N

- t2c Nsp

-

1 Ns2p

Nsp i=1

j=i

Yi(1) - Yi(0) - sp

· Yj(1) - Yj(0) - sp  c2 + t2 ,
Nc Nt

when Nsp is large relative to N.

CHAPTER 7
Regression Methods for Completely Randomized Experiments
7.1 INTRODUCTION
One of the more common ways of estimating causal effects with experimental, as well as observational, data in many disciplines is based on regression methods. Typically an additive linear regression function is specified for the observed outcome as a function of a set of predictor variables. This set of predictor variables includes the indicator variable for the receipt of treatment and usually additional pre-treatment variables. The parameters of the regression equation are estimated by least squares, with the primary focus on the coefficient for the treatment indicator. Inferences, including point estimates, standard errors, tests, and confidence intervals, are based on standard least squares methods. Although popular, the use of these methods in this context is not without controversy, with some researchers arguing that experimental data should be analyzed based on randomization inference. As Freedman writes bluntly, "Experiments should be analyzed as experiments, not as observational studies" (Freedman, 2006, p. 691). It has also been pointed out that the justification for least squares methods does not follow from randomization. Again Freedman: "randomization does not justify the assumptions behind the ols [ordinary least squares] model" (Freedman, 2008a, p. 181). In this chapter we discuss in some detail the rationale for, and the interpretation and implementation of, regression methods in the setting with completely randomized experiments. This chapter can be viewed as providing a bridge between the previous chapter, which was largely focused on exact finite-sample results based on randomization, and the next chapter, which is based on fully parametric models for imputation of the unobserved potential outcomes.
The most important difference between the methods discussed in Chapters 5 and 6 and the ones discussed here is that they rely on different sampling perspectives. Both the Fisher approach discussed in Chapter 5 and the Neyman methods discussed in Chapter 6 view the potential outcomes as fixed and the treatment assignments as the sole source of randomness. In the regression analysis discussed in this chapter, the starting point is an infinite super-population of units. Properties of the estimators are assessed by resampling from that population, sometimes conditional on the predictor variables including the treatment indicator. From that perspective, the potential outcomes in the sample are random, and we can derive the bias and sampling variance of estimators over the distribution induced by this random sampling. The sampling variance of estimators derived in
113

114

Regression Methods for Completely Randomized Experiments

this approach will be seen to be very similar to the Neyman sampling variance for  dif derived in Chapter 6, although its interpretation will be different.
There are four key features of the models considered in this chapter. First, we consider models for the observed outcomes rather than for the potential outcomes. Second, we consider models only for the conditional mean rather than for the full distribution. Third, the estimand, here always an average treatment effect, is a parameter of the statistical model. The latter implies that inferential questions can be viewed as questions of inference for parameters of a statistical model. Fourth, in the current context of completely randomized experiments, the validity of these models, that is, whether the models provide accurate descriptions of the conditional mean, is immaterial for the large-sample unbiasedness of the least squares estimator of the average treatment effect.
As the Freedman quote illustrates, the conventional justification for linear regression models, that the regression function represents the conditional expectation of the observed outcome given the predictor variables, does not follow from the randomization if there are predictors beyond the treatment indicator. Nevertheless, in the setting of a completely randomized experiment, the least squares point estimates and associated inferences can be given a causal interpretation. There is an important difference with the causal interpretation in the previous chapter, however. With the exception of the setting without additional covariates beyond the treatment indicator, where the main results are essentially identical to those discussed in the previous chapter from the Neyman approach, all results are now asymptotic (large sample) results. Specifically, exact unbiasedness no longer holds in finite samples with covariates beyond the treatment indicator because of the need to estimate additional nuisance parameters, that is, the associated regression coefficients. The possible benefit of the regression methods over the exact methods from the previous chapter is that they provide a straightforward and, for many researchers, familiar way to incorporate covariates. If these covariates are predictive of the potential outcomes, their inclusion in the regression model can result in causal inferences that are more precise than differences in observed means. This gain in precision can be substantial if the covariates are highly predictive of the potential outcomes, although in practice the gains are often modest. The disadvantage of regression models relative to the fully model-based methods that will be discussed in the next chapter is that the use of standard linear regression models often restricts the set of models considerably, and thereby restricts the set of questions that can be addressed. Thus, when using these regression models, there is often a somewhat unnatural tension between, on the one hand, models that provide a good statistical fit and have good statistical properties and, on the other hand, models that answer the substantive question of interest. This tension is not present in the full, model-based methods discussed in the next chapter.
This chapter is organized as follows. In the next section, Section 7.2, we describe the data that will be used to illustrate the techniques discussed in this chapter. The data come from a completely randomized experiment previously analyzed by Efron and Feldman (1991). Section 7.3 reviews and adds notation regarding the super-population perspective. In Section 7.4 we discuss the case with no predictor variables beyond the treatment indicator. In that case, most of the results are closely related to those from the previous chapter. In Section 7.5 we generalize the results to allow for the presence of additional predictor variables. Next, in Section 7.6, we include interactions between the predictor variables and the treatment indicator. In Section 7.7 we discuss the role of

7.2 The LRC-CPPT Cholesterol Data

115

transformations of the outcome variable. The following section, Section 7.8, discusses the limits on the increases in precision that can be obtained by including covariates. In Section 7.9 we discuss testing for the presence of treatment effects. Then, in Section 7.10, we apply the methods to the Efron-Feldman data. Section 7.11 concludes.

7.2 THE LRC-CPPT CHOLESTEROL DATA
We illustrate the concepts discussed in this chapter using data from a randomized experiment, the Lipid Research Clinics Coronary Primary Prevention Trial (LRC-CPPT), designed to evaluate the effect of the drug cholestyramine on cholesterol levels. The data were previously analyzed in Efron and Feldman (1991). The data set analyzed here contains information on N = 337 individuals. Of these 337 individuals, Nt = 165 were randomly assigned to receive cholestyramine and the remaining Nc = 172 were assigned to the control group, which received a placebo.
For each individual, we observe two cholesterol measures recorded prior to the random assignment. The two measures differ in their timing. The first, chol1, was taken prior to a communication, sent to all 337 individuals in the study, about the benefits of a low-cholesterol diet, and the second, chol2, was taken after this suggestion, but prior to the random assignment to cholestyramine or placebo. We observe two outcomes. The primary outcome is an average of post-randomization cholesterol readings, cholf, averaged over two-month readings for a period of time averaging 7.3 years for all the individuals in the study. Efron and Feldman's primary outcome is the change in cholesterol level, relative to a weighted average of the two pre-treatment cholesterol levels, cholp= 0. 25 · chol1 + 0. 75 · chol2. We denote this change in cholesterol levels by chold=cholf-cholp. The secondary outcome is a compliance measure, denoted by comp, the percentage of the nominally assigned dose of either cholestyramine or placebo that the individual actually took. Although individuals did not know whether they were assigned to cholestyramine or to the placebo, later we shall see that differences in side effects between the active drug and the placebo induced systematic differences in compliance behavior by treatment status. Note that all individuals, whether assigned to the treatment or the control group, were assigned the same nominal dose of the drug or placebo, for the same time period.
The availability of compliance data raises many interesting issues regarding differences between the effect of being assigned to the taking of cholestyramine and the effect of actually taking cholestyramine. We discuss some of these issues in detail in later chapters on noncompliance and instrumental variables (Chapters 23­25). Here we analyze the compliance measure solely as a secondary outcome. Note, however, that in general it is not appropriate to interpret either the difference in final cholesterol levels by assignment, conditional on observed compliance levels, or the difference in final cholesterol levels by actual dosage taken, as estimates of average causal effects. Such causal interpretations would require strong additional assumptions beyond randomization. For example, to validate conditioning on observed compliance levels would require that observed compliance is a proper pre-treatment variable unaffected by the assignment to treatment versus placebo. Because observed compliance reflects behavior subsequent to the assignment, it may be affected by the treatment assigned, which is an assumption. This is an assumption

116

Regression Methods for Completely Randomized Experiments

Table 7.1. Summary Statistics for PRC-CPPT Cholesterol Data

Variable Control (Nc =172)

Treatment (Nt =165)

Average Sample (S.D.) Average Sample (S.D.) Min Max

Pre-treatment Post-treatment

chol1 chol2 cholp cholf chold comp

297.1 289.2 291.2 282.7 -8.5 74.5

(23.1) (24.1) (23.2) (24.9) (10.8) (21.0)

297.0 287.4 289.9 256.5 -33.4 59.9

(20.4) (21.4) (20.4) (26.2) (21.3) (24.4)

247.0 224.0 233.0 167.0 -113.3
0

442.0 435.0 436.8 427.0
29.5 101.0

that can be assessed, and in the current study we can reject, at conventional significance levels, the assumption that observed compliance is a proper pretreatment variable.
In Table 7.1 we present summary statistics for the Efron-Feldman data. For the two initial cholesterol levels (chol1 and chol2), as well as the composite pre-treatment cholesterol level (cholp), the averages do not vary much by treatment status, consistent with the randomized assignment. We do see that the second pre-treatment cholesterollevel measurement, chol2, is, on average, lower than the first one, chol1. This is consistent with the fact that in between the two measurements, the individuals in the study received information about the benefits of a low cholesterol diet that may have induced them to improve their diets. For the subsequent cholesterol-level measures (cholf and chold), the averages do vary considerably by treatment status. In addition, the average level of compliance (comp) is much higher in the control group than in the treatment group. Later in this chapter we investigate the statistical precision of this difference, but here we just comment that this is consistent with relatively severe side effects of the actual drug, which are not present in the placebo. This difference signals the potential dangers of using a post-treatment variable, such as observed compliance, as a covariate.

7.3 THE SUPER-POPULATION AVERAGE TREATMENT EFFECTS
As in Section 6.7 in the previous chapter, we focus in this chapter on the average effect in the super-population, rather than in the sample. We assume that the sample of size N for which we have information can be considered a simple random sample drawn from an infinite super-population. Considering the N units in our sample as a random sample from the super-population induces a distribution on the pair of potential outcomes. The observed potential outcome and covariate values for a drawn unit are simply one draw from the joint distribution in the population and are therefore themselves stochastic. We assume that we have no information about this distribution beyond the values of the observed outcomes and covariates in our sample.
The distribution of the two potential outcomes in turn induces a distribution on the unit-level treatment effects, and thereby on the average of the unit-level treatment effect within the experimental sample. To be clear about this super-population perspective, let us, as we did in the previous chapter, index the average treatment effect  by fs to denote

7.3 The Super-Population Average Treatment Effects

117

the finite-sample average treatment effect and by sp to denote the super-population average treatment effect. Thus

fs

=

1 N

N
(Yi(1) - Yi(0))
i=1

is the average effect of the treatment in the finite sample, and

sp = Esp [Yi(1) - Yi(0)]
is the expected value of the unit-level treatment effect under the distribution induced by sampling from the super-population, or, equivalently, the average treatment effect in the super-population. (We index the expectations operator by "sp" to make explicit that the expectation is taken over the random sampling, not over the randomization distribution, as in the previous chapter.) For the discussion in this chapter, it is useful to introduce some additional notation. Define the super-population average and variance of the two potential outcomes conditional on the covariates or pre-treatment variables, e.g., Xi = x,
c(x) = Esp [Yi(0)|Xi = x] , t(x) = Esp [Yi(1)|Xi = x] , c2(x) = Vsp (Yi(0)|Xi = x) , and t2 = Vsp (Yi(1)|Xi = x) ,
and let the mean and variance of the unit-level treatment effects at Xi = x be denoted by
 (x) = Esp(Yi(1) - Yi(0)|Xi = x], and c2t(x) = Vsp (Yi(1) - Yi(0)|Xi = x) ,
respectively. In addition, denote the marginal means and variances

c = Esp [Yi(0)] , t = Esp [Yi(1)] , c2 = Vsp (Yi(0)) , and t2 = Vsp (Yi(1)) .
Note that the two marginal means are equal to the expectation of the corresponding conditional means:

c = Esp [c(Xi)] , and t = Esp [t(Xi)] ,
but, by the law of iterated expectations, the marginal variance differs from the average of the conditional variance by the variance of the conditional mean:

c2 = Esp c2(Xi) + Vsp (c(Xi)) , and t2 = Esp t2(Xi) + Vsp (t(Xi)) .
Finally, let X = Esp [Xi] , and X = Vsp(Xi) = Esp (Xi - X)T (Xi - X) ,
denote the super-population mean and covariance matrix of the row vector of covariates Xi, respectively.

118

Regression Methods for Completely Randomized Experiments

7.4 LINEAR REGRESSION WITH NO COVARIATES

In this section we focus on the case without covariates, that is, no predictor variables beyond the indicator Wi for the receipt of treatment. We maintain the assumption of a completely randomized experiment. We specify a linear regression function for the observed outcome Yiobs as
Yiobs =  +  · Wi + i,

where the unobserved residual i captures unobserved determinants of the outcome. The ordinary least squares (or ols for short) estimator for  is based on minimizing the sum of squared residuals over  and  ,

N
(^ ols, ^ ols) = arg min
 ,

Yiobs -  -  · Wi

2
,

i=1

with solutions

^ ols =

N i=1

Wi -
N i=1

W · (Yiobs Wi - W

-
2

Y

obs)

,

and

^ ols = Yobs - ^ ols · W,

where

Y obs

=

1 N

N
Yiobs
i=1

and

W

=

1 N

N i=1

Wi

=

Nt . N

Simple algebra shows that in this case the ols estimator ^ ols is identical to the difference in average outcomes by treatment status:

^ ols

=

Y

obs t

-

Y

obs c

=

^ dif,

where,

as

before,

Y

obs t

=

i:Wi=1

Yiobs/Nt

and

Y

obs c

=

i:Wi=0 Yiobs/Nc are the averages

of the observed outcomes in the treatment and control groups respectively.

The least squares estimate of  is often interpreted as an estimate of the causal effect of

the treatment, explicitly in randomized experiments, and sometimes implicitly in obser-

vational studies. The assumptions traditionally used in the least squares approach are that

the residuals i are independent of, or at least uncorrelated with, the treatment indicator

Wi. This assumption is difficult to evaluate directly, as the interpretation of these resid-

uals is rarely made explicit beyond a somewhat vague notion of capturing unobserved

factors affecting the outcomes of interest. Statistical textbooks, therefore, often stress

that in observational studies the regression estimate ^ ols measures only the association

between the two random variables Wi and Yiobs and that a causal interpretation is gener-

ally not warranted. In the current context, however, we already have a formal justification

for

the

causal

interpretation

of

^

ols

because

it

is

identical

to

Y

obs t

-

Y

cobs,

which

itself

was

shown in Chapter 6 to be unbiased for the finite-sample average treatment effect, fs, as

well as for the super-population average treatment effect, sp. Nevertheless, it is useful to

7.4 Linear Regression with No Covariates

119

justify the causal interpretation of ^ ols more directly in terms of the standard justification for regression methods, using the assumptions that random sampling created the sample
and a completely randomized experiment generated the observed data from that sample. Let  be the population average outcome under the control,  = c = Esp [Yi(0)],
and recall that sp is the super-population average treatment effect, sp = t - c = Esp [Yi(1) - Yi(0)]. Now define the residual i in terms of the population parameters, treatment indicator, and the potential outcomes as

i = Yi(0) -  + Wi · Yi(1) - Yi(0) - sp =

Yiobs -  Yiobs -  - sp

if Wi = 0, if Wi = 1.

Then we can write

i = Yiobs - ( + sp · Wi),

and thus we can write the observed outcome as

Yiobs =  + sp · Wi + i.

Random sampling allows us to view the potential outcomes as random variables. In combination with random assignment this implies that assignment is independent of the potential outcomes,

Pr( Wi = 1| Yi(0), Yi(1)) = Pr(Wi = 1) , or in Dawid's (1979) "" independence notation,

Wi  (Yi(0), Yi(1)) .

The definition of the residual, in combination with random assignment and random sampling from a super-population, implies that the residual has mean zero conditional on the treatment indicator in the population:

Esp[i|Wi = 0] = Esp [Yi(0) - |Wi = 0] = Esp [Yi(0)] - ] = 0,

and

Esp[i|Wi = 1] = Esp Yi(1) -  - sp|Wi = 1 = Esp Yi(1) -  - sp|Wi = 1 = 0,

so that

Esp[i|Wi = w] = 0,

for w = 0, 1.

The fact that the conditional mean of i given Wi is zero in turn implies unbiasedness of the least squares estimator, ^ ols for sp = Esp [Yi(1) - Yi(0)], over the distribution induced by random sampling. The above derivation shows how properties of residuals
commonly asserted as assumptions in least squares analyses actually follow from random

120

Regression Methods for Completely Randomized Experiments

sampling and random assignment, and thus have a scientific basis in the context of a completely randomized experiment.
Another way of deriving this result, which is closer to the way we will do this for the general case with pre-treatment variables, is to consider the super-population limits of the estimators. The estimators are defined as

N
(^ ols, ^ ols) = arg min
,

Yiobs -  -  · Wi

2
.

i=1

Under some regularity conditions, these estimators converge, as the sample size goes to infinity, to the population limits (,  ) that minimize the expected value of the sum of
squares:

(,

 )

=

arg

min
,

Esp

=

arg

min
,

Esp

1N N i=1

Yiobs -  -  · Wi 2

Yiobs -  -  · Wi 2 .

This implies that the population limit is   = Esp[Yiobs|Wi = 1] - Esp[Yiobs|Wi = 0]. Random assignment of Wi implies Esp[Yiobs|Wi = 1] - Esp[Yiobs|Wi = 0] = Esp[Yi(1) - Yi(0)] = sp, so that the population limit of the least squares estimator is equal to the population average treatment effect,   = sp.
Now let us analyze the least squares approach to inference (i.e., sampling variance and
confidence intervals) applied to the setting of a completely randomized experiment. Let us initially assume homoskedasticity (Y2|W = c2 = t2). Using least squares methods, the variance of the residuals would be estimated as

^Y2|W

=

N

1 -2

N i=1

^i2

=

N

1 -2

N i=1

Yiobs - Y^iobs

2
,

where the estimated residual is ^i = Yiobs - Y^iobs, and the predicted value Y^iobs is

Y^iobs =

^ ols ^ ols + ^ ols

if Wi = 0, if Wi = 1.

The ols variance estimate can be rewritten as





^Y2|W

=

N

1 -2



Yiobs

-

Y

obs c

2
+

Yiobs

-

Y

obs t

2 ,

i:Wi=0

i:Wi=1

which is equivalent to our calculation of s2, the common variance across the two potential outcome distributions, as seen in Equation (6.11) in Chapter 6. The conventional

7.4 Linear Regression with No Covariates

121

estimator for the sampling variance of ^ols is then

V^ homosk =

^Y2|W

N i=1

Wi - W

2

= s2 ·

1+1 Nc Nt

.

This expression is equal to V^ const in Equation (6.12) in Chapter 6. This result is not surprising, because the assumption of homoskedasticity in the linear model setting is implied by the assumption of a constant treatment effect.
For comparison with subsequent results, it is also useful to have the limit of the estimated sampling variance, normalized by the sample size N. Let p be the probability limit of the ratio of the number of treated units to the total number of units, p = plim(Nt/N). Then, as the sample size increases, the normalized sampling variance estimator converges in probability to

N

· V^ homosk

- p

Y2|W . p · (1 - p)

(7.1)

Note, however, that the random assignment assumption we used for the causal interpretation of ^ ols, although it implies independence between assignments and potential outcomes, implies only zero correlation between the assignment and the residual, not necessarily full independence. Yet we rely on this independence to conclude that the variance is homoskedastic. In many cases, the homoskedasticity assumption will not be warranted, and one may wish to use an estimator for the sampling variance of ^ ols that allows for heteroskedasticity. The standard robust sampling variance estimator for least squares estimators is

V^ hetero =

N i=1

^i2

·

Wi - W

N i=1

Wi - W

2

2
2.

Defining, as the previous chapter,

sc2

=

1 Nc -

1

i:Wi=0

Yiobs

-

Y

obs c

2
,

and

st2

=

1 Nt -

1

i:Wi=1

Yiobs

-

Y

obs t

2
,

we can write the variance estimator under heteroskedasticity as

V^ hetero = s2c + st2 . Nc Nt
This is exactly the same estimator for the sampling variance derived from Neyman's perspective in Chapter 6 (V^ neyman in Equation (6.8)). So, in the case without additional predictors, the regression approach leads to sampling variance estimators that are familiar from the discussion in the previous chapter. It does, however, provide a different perspective on these results. First of all, it is based on a random sampling perspective. Second, this perspective allows for a natural and simple extension to the case with additional predictors.

122

Regression Methods for Completely Randomized Experiments

7.5 LINEAR REGRESSION WITH ADDITIONAL COVARIATES

Now let us consider the case with additional covariates. In this section these additional covariates are included in the regression function additively. The regression function is specified as:

Yiobs =  +  · Wi + Xi + i,

(7.2)

where Xi is a row vector of covariates (i.e., pre-treatment variables). We estimate the regression coefficients again using least squares:

N
(^ ols, ^ ols, ^ ols) = arg min
 ,,

Yiobs -  -  · Wi - Xi

2
.

i=1

The first question we address in this section concerns the causal interpretation of the least squares estimate ^ ols in the presence of these covariates and the associated parameters. We are not interested per se in the value of the "nuisance" parameters,  and . In partic-
ular, we are not interested in a causal interpretation of those parameters. Moreover, we
will not make the assumption that the regression function in (7.2) is correctly specified or that the conditional expectation of Yiobs is actually linear in Xi and Wi. However, in order to be precise about the causal interpretation of ^ ols, it is useful, as in Section 7.4,
to define the limiting values to which the least squares estimators converge as the sample
gets large. We will refer to these limiting values as the super-population values corresponding to the estimators and denote them with a superscript , as in Section 7.4. Using this notation, under some regularity conditions, (^ ols, ^ ols, ^ ols) converge to (,  , ),
defined as

(,  , ) = arg min E
,,

Yiobs -  -  · Wi - Xi 2 .

These population values are generally well defined (subject, essentially, only to finite-
moment conditions and positive definiteness of X, the population covariance matrix of
Xi), even if the conditional expectation of the observed outcome given covariates is not
linear in the covariates. In this case with additional predictors, it is no longer true that ^ ols is unbiased for sp
in finite samples. However, irrespective of whether the regression function is truly linear in the covariates in the population, the least squares estimate ^ ols is unbiased in large samples for the population average treatment effect, sp. Moreover,  , the probability limit of the estimator, is equal to the population average treatment effect sp. Finally, in large samples ^ ols will be distributed approximately normally around sp. To be precise,
we state the result formally.

Theorem 7.1 Suppose we conduct a completely randomized experiment in a sample drawn at random from an infinite population. Then, (i)

  = sp,

7.5 Linear Regression with Additional Covariates

123

and (ii),

 N·

^ ols - sp

 - d N 0, E

(Wi - p)2 ·

Yiobs -  - sp · Wi - Xi 2 p2 · (1 - p)2

 .

We will prove the first part of the result here in the body of the text. The proof of the second part, and of subsequent results, is given in the Appendix to this chapter.
Proof of Theorem 7.1(i). Consider the limiting objective function:
Q(,  , ) = E[(Yiobs -  -  · Wi - Xi)2] = E Yiobs - ~ -  · Wi - (Xi - X) 2 ,

where ~ =  + X, with X = E[Xi]. Minimizing the right-hand side over ~ ,  , and 
leads to the same values for  and  as minimizing the left-hand side over ,  , and , with the least squares estimate of ~ equal ^ + ^ X. Next,

Q(~ ,  , ) = Esp Yiobs - ~ -  · Wi - (Xi - X) 2

= Esp Yiobs - ~ -  · Wi 2 + Esp ((Xi - X))2

- 2 · Esp Yiobs - ~ -  · Wi · (Xi - X) = Esp Yiobs - ~ -  · Wi 2 + Esp ((Xi - X))2

- 2 · Esp Yiobs · (Xi - X) ,

(7.3)

because

Esp [(Xi - X)] = 0, and Esp [ · Wi · (Xi - X)] = 0,

the first by definition, and the second because of the random sampling and the random assignment. Because the last two terms in (7.3) do not depend on ~ or  , minimizing (7.3) over  and  is equivalent to minizing the objective function without the additional covariates,

Esp Yiobs - ~ -  · Wi 2 ,

which leads to the solutions ~  = Esp[Yiobs|Wi = 0] = Esp [Yi(0)|Wi = 0] = Esp [Yi(0)] = c,

124

Regression Methods for Completely Randomized Experiments

and
  = Esp[Yiobs|Wi = 1] - Esp[Yiobs|Wi = 0] = Esp[Yi(1)|Wi = 1] - Esp[Yi(0)|Wi = 0] = sp.

Thus, the least squares estimator is consistent for the population average treatment effect sp.
What is important in the first part of the result is that the consistency (large-sample unbiasedness) of the least squares estimator for sp does not depend on the correctness of the specification of the regression function in a completely randomized experiment. No matter how non-linear the conditional expectations of the potential outcomes given the covariates are in the super-population, simple least square regression is consistent for estimating the population average treatment effect. The key insight into this result is that, by randomizing treatment assignment, the super-population correlation between the treatment indicator and the covariates is zero. Even though in finite samples the actual correlation may differ from zero, in large samples this correlation will vanish, and as a result the inclusion of the covariates does not matter for the limiting values of the estimator. The fact that in finite samples the correlation may differ from zero is what leads to the possibility of finite-sample bias.
Although the inclusion of the additional covariates does not matter for the limit of the corresponding estimator, it does matter for the sampling variance of the estimators. Let us interpret the sampling variance in some special cases. Suppose that, in fact, the conditional expectation of the two potential outcomes is linear in the covariates, with the same slope coefficients but different intercepts in the two treatment arms, or

Esp[Yi(0)|Xi = x] = c + x, and Esp[Yi(1)|Xi = x] = t + x,

so that, in combination with random assignment, we have

Esp Yiobs Xi = x, Wi = t = c + sp · t +  x,

where sp = t-c. Suppose that, in addition, the variance of the two potential outcomes does not vary by treatment or covariates:

Vsp(Yi(w)|Xi = x) = Y2|W,X,

for w = 0, 1, and all x. Then the normalized sampling variance for the least squares estimator for sp, given for the general case in Theorem 7.1, simplifies to

N

· Vshpomosk

=

p

Y2|W,X · (1 - p)

.

(7.4)

This expression reveals the gain in precision from including the covariates. Instead of the unconditional variance of the potential outcomes, as in the expression for the sampling variance in the case without covariates in (7.1), we now have the conditional variance of the outcome given the covariates. If the covariates explain much of the variation in the potential outcomes, so that the conditional variance Y2|W,X is substantially smaller than

7.6 Linear Regression with Covariates and Interactions

125

the marginal variance Y2|W , then including the covariates in the regression model will lead to a considerable increase in precision. The price paid for the increase in precision from including covariates is relatively minor. Instead of having (exact) unbiasedness of the estimator in finite samples, unbiasedness now only holds approximately, that is, in large samples.
The sampling variance for the average treatment effect can be estimated easily using standard least squares methods. Substituting averages for the expectations, and least squares estimates for the unknown parameters, we estimate the sampling variance as

V^ shpetero

=

N (N

1 - 1 - dim(Xi))

N i=1

Wi - W 2 ·

Yiobs - ^ ols - ^ ols - Xi^ ols 2

·

W · (1 - W) 2

.

If one wishes to impose homoskedasticity, one can still use the heteroskedasticityconsistent sampling variance estimator, but a more precise estimator of the sampling variance imposes homoskedasticity, leading to the form:

V^ shpomo

=

N

(N

-

1

1 - dim(Xi))

·

N i=1

Yiobs - ^ ols - ^ ols - Xi^ ols

2

.

W · (1 - W)

7.6 LINEAR REGRESSION WITH COVARIATES AND INTERACTIONS

In this section we take the analysis of Section 7.5 one step further. In addition to including the covariates linearly, one may wish to interact the covariates with the indicator for the receipt of treatment if we expect that the association between the covariates and the outcome varies by treatment status. The motivation for this is twofold. First, adding additional covariates of any form, including those based on interactions, may further improve the precision of the estimator. Second, by interacting all such predictors with the treatment indicators, we achieve a particular form of robustness to model misspecification that we discuss in more detail later. This robustness is not particularly important in the current setting of a completely randomized experiment, but it will be important in observational studies discussed in Parts III and IV of this text. We specify the regression function as

Yiobs =  +  · Wi + Xi + Wi · (Xi - X) + i.

We include the interaction of the treatment indicator with the covariates in deviations
from their sample means to simplify the relationship between the population limits of
the estimators for the parameters of the regression function and sp. Let ^ ols, ^ ols, ^ ols, and ^ ols denote the least squares estimates,

N
(^ ols, ^ ols, ^ ols, ^ ols) = arg min
 ,,,

Yiobs -  -  · Wi - Xi - Wi · (Xi - X)

2
,

i=1

126

Regression Methods for Completely Randomized Experiments

and let ,  , , and   denote the corresponding population values:

(,

 ,

,



)

=

arg

min
,, ,

Esp

Yiobs -  -  · Wi - Xi - Wi · (Xi - X) 2 .

Results similar to Theorem 7.1 can be obtained for this case. The least squares estimator ^ ols is consistent for the average treatment effect sp, and inference can be based on least squares methods.

Theorem 7.2 Suppose we conduct a completely randomized experiment in a random sample from a super-population. Then (i)

  = sp,

and (ii),

 N·

^ ols - sp

- d N

 0, Esp

(Wi - p)2 ·

Yiobs -  - sp · Wi - Xi - Wi · (Xi - X)  2 p2 · (1 - p)2

 .

The proof for this theorem is provided in the Appendix. A slightly different interpretation of this result connects it to the imputation-based methods that are the topic of the next chapter. Suppose we take the model at face value and assume that the regression function represents the conditional expectation:

Esp Yiobs Xi = x, Wi = w =  +  · t +  x + w · (x - X) .

(7.5)

In combination with the random assignment, this implies that

Esp [ Yi(0)| Xi = x] = Esp [ Yi(0)| Xi = x, Wi = 0] = Esp Yiobs Xi = x, Wi = 0 =  + x,

and

Esp [ Yi(1)| Xi = x] =  +  + x + (x - X) .
Suppose that unit i was exposed to the treatment (Wi = 1), so Yi(1) is observed and Yi(0) is missing. Under the model in (7.5), the predicted value for the missing potential outcome Yi(0) is
Y^i(0) = ^ ols + Xi^ ols,

so that for this treated unit the predicted value for the unit-level causal effect is

^i = Yi(1) - Y^i(0) = Yiobs - ^ ols + Xi^ ols .

7.7 Transformations of the Outcome Variable

127

For a control unit i (with Wi = 0) the predicted value for the missing potential outcome Yi(1) is
Y^i(1) = ^ ols + ^ ols + Xi^ ols + (Xi - X)^ ols,

and the predicted value for the unit-level causal effect for this control unit i is

^i = Y^i(1) - Yi(0) = ^ ols + ^ ols + Xi^ ols + (Xi - X)^ ols - Yiobs.

Now we can estimate the overall average treatment effect fs by averaging the estimates of the unit-level causal effects ^i. Simple algebra shows that this leads to the ols estimator:

1 N

N
^i
i=1

=

1 N

N i=1

Wi ·

Yi(1) - Y^i(0)

+ (1 - Wi) ·

Y^i(1) - Yi(0)

= ^ ols.

Thus, the least squares estimator ^ ols can be interpreted as averaging estimated unitlevel causal effects in the sample, based on imputing the missing potential outcomes through a linear regression model. However, as has been stressed repeatedly, thanks to the randomization, the consistency of the ols estimator does not rely on the validity of the regression model as an approximation to the conditional expectation.
There is another important feature of the estimator based on linear regression with a full set of interactions that was alluded to at the beginning of this chapter. As the above derivation shows, the estimator essentially imputes the missing potential outcomes. The regression model with a full set of interactions does so separately for the treated and control units. When imputing the value of Yi(0) for the treated units, this procedure uses only the observed outcomes, Yiobs, for control units, without any dependence on observations on Yi(1) (and vice versa). This gives the estimator attractive robustness properties, clearly separating imputation of control and treated outcomes. This will be important in the context of observational studies.

7.7 TRANSFORMATIONS OF THE OUTCOME VARIABLE
If one is interested in the average effect of the treatment on a transformation of the outcome, one can first transform the outcome and then apply the methods discussed so far. For example, in order to estimate the average effect on the logarithm of the outcome, we can first take logarithms and then estimate the regression function
ln Yiobs =  +  · Wi + Xi + i.
Irrespective of the form of the association between outcomes and covariates, in a completely randomized experiment, least squares estimates of  are consistent for the average effect E[ ln (Yi(1))-ln (Yi(0))]. This follows directly from the previous discussion. There is an important issue, though, involving such transformations that relates to the correctness of the specification of the regression function. Suppose one is interested in the average effect E[Yi(1) - Yi(0)], but suppose that one actually suspects that a model

128

Regression Methods for Completely Randomized Experiments

linear in logarithms provides a better fit to the distribution of Yiobs given Xi and Wi. Estimating a model linear in logarithms and transforming the estimates back to an esti-

mate of the average effect in levels requires assumptions beyond those on the conditional

expectation of the logarithm of the potential outcomes: one needs to make distributional

assumptions on the unobserved component. We discuss such modeling strategies in the

next chapter.

As an extreme example of this issue, consider the case where the researcher is inter-

ested in the average effect of the treatment on a binary outcome. Estimating a linear

regression function by least squares will lead to a consistent estimator for the average

treatment effect. However, such a linear probability model is unlikely to provide an accu-

rate approximation of the conditional expectation of the outcome given covariates and

treatment indicator. Logistic models (where Pr(Yiobs = 1|Wi = w, Xi = x) is modeled as

exp ( + · w, Xi = x)

w+ =

x)/(1+exp ( + ( +  · w + x),

·w+x with

))), (z)

or =

pr-zobit(2mo)d-e1l/s2(ewxhpe(re-Pzr2(Y/2iob)sth=e

1|Wi = normal

cumulative distribution function) are more likely to lead to an accurate approximation of

the conditional expectation of the outcome given the covariates and the treatment indi-

cator. However, such a model will not generally lead to a consistent estimator for the

average effect unless the model is correctly specified. Moreover, the average treatment

effect cannot be expressed directly in terms of the parameters of the logistic or probit

regression model.

The issue is that in the regression approach, the specification of the statistical model is

closely tied to the estimand of interest. In the next chapter we separate these two issues.

This separation is attractive for a number of reasons discussed in more detail in the next

chapter, but it also carries a price, namely that consistency of the estimators will be tied

more closely to the correct specification of the model. We do not view this as a major

issue. In the setting of completely randomized experiments, the bias is unlikely to be sub-

stantial with moderate-sized samples, as flexible models are likely to have minimal bias.

Moreoever, this consistency property despite possible misspecification of the regression

function holds only with completely randomized experiments. In observational studies,

even regression models rely heavily on the correct specification for consistency of the

estimator. Furthermore, large-sample results, such as consistency, are only guidelines for

finite-sample properties, and as such not always reliable.

7.8 THE LIMITS ON INCREASES IN PRECISION DUE TO COVARIATES
In large samples, including covariates in the regression function will not lower, and generally will increase, the precision of the estimator for the average treatment effect. However, beyond the first few covariates, more covariates are unlikely to improve the precision substantially in modest-sized samples. Here we briefly discuss some limits to the gains in precision from including covariates in settings where the randomized assignment ensures that the covariates are not needed for bias removal.
Suppose we do not include any predictor variables in the regression beyond the indicator variable for the treatment, Wi, that is, we include no covariates. Normalized by the sample size, the sampling variance of the least squares estimator, in this case equal to

7.9 Testing for the Presence of Treatment Effects

129

the simple difference in means, is equal to

N

· Vnocov

=

c2 1-p

+

t2 , p

familiar in various forms from this and the previous chapter. Now suppose we have available a vector of covariates, Xi. Including these covariates, their interactions with the treatment indicator, and possibly higher-order moments of these covariates, leads to a normalized sampling variance that is bounded from below by

N

· Vbound

=

Esp[c2(Xi)] 1-p

+

Esp[t2(Xi)] . p

Instead of the marginal variances c2 and t2 in the two terms, we now take the expectation of the conditional variances c2(Xi) and t2(Xi). The difference between the two expressions for the sampling variance, and thus the gain from including the covariates in
a flexible manner, is the sum of the sampling variances of the conditional means of Yi(w) given Xi:

Vnocov - Vbound =

c2 + t2 1-p p

-

Esp[c2(Xi)] + Esp t2(Xi)

1-p

p

=

Vsp(c(Xi)) 1-p

+

Vsp(t(Xi)) . p

The more the covariates Xi help in explaining the potential outcomes, and thus the bigger the variation in w(x), the bigger the gain from including them in the specification of the regression function. In the extreme case, where neither c(x) nor t(x) varies with the predictor variables, there is no gain from using the covariates, even in large sam-
ples. Moreoever, in small samples there will actually be a loss of precision due to the
estimation of coefficients, that are, in fact, zero.

7.9 TESTING FOR THE PRESENCE OF TREATMENT EFFECTS
In addition to estimating average treatment effects, the regression models discussed in this chapter have been used to test for the presence of treatment effects. In the current setting of completely randomized experiments, tests for the presence of any treatment effects are not necessarily as attractive as the Fisher exact p-value calculations discussed in Chapter 5, but their extensions to observational studies are relevant. In addition, we may be interested in testing hypotheses concerning the heterogeneity in the treatment effects that do not fit into the FEP framework because the associated null hypotheses are not sharp. As in the discussion of estimation, we focus on procedures that are valid in large samples, irrespective of the correctness of the specification of the regression model.
The most interesting setting is the one where we allow for a full set of first-order interactions with the treatment indicator and specify the regression function as
Yiobs =  + sp · Wi + Xi + Wi · (Xi - X) + i.

130

Regression Methods for Completely Randomized Experiments

In that case we can test the null hypothesis of a zero average treatment effect by testing the null hypothesis that sp = 0. However, we can construct a different test by focusing on the deviation of either ^sp or ^ from zero. If the regression model were correctly specified, that is, if the conditional expectation of the outcome in the population given
covariates and treatment indicator were equal to

Esp Yiobs Xi = x, Wi = w =  +  · w + x + w · (x - X) ,
this would test the null hypothesis that the average treatment effect conditional on each value of the covariates is equal to zero, or

H0 : Esp[Yi(1) - Yi(0)|Xi = x] = 0,  x,

against the alternative hypothesis

Ha : Esp[Yi(1) - Yi(0)|Xi = x] = 0, for some x.

Without making the assumption that the regression model is correctly specified, it is still
true that, if the null hypothesis that E[Yi(1) - Yi(0)|Xi = x] = 0 for all x were correct, then the population values sp and   would be equal to zero. However, it is no longer true that for all deviations of this null hypothesis the limiting values of either sp or  
differ from zero. It is possible that E[Yi(1) - Yi(0)|Xi = x] differs from zero for some values of x even though sp and   are both equal to zero.
In order to implement these tests, one can again use standard least squares methods. The normalized covariance matrix of the vector (^ ols, ^ ols) is

V , =

V CT,

C , V

.

The precise form of the components of the covariance matrix, as well as consistent estimators for these components, is given in the Appendix. In order to test the null hypothesis that the average effect of the treatment given the covariates is zero for all values of the covariates, we then use the quadratic form

Qzero =

^ ols ^ ols

T
V^ - ,1

^ ols ^ ols

.

(7.6)

Note that this is not a test that fits into the Fisher exact p-value approach because it does not specify all missing potential outcomes under the null hypothesis.
The second null hypothesis we consider is that the average treatment effect is constant as a function of the covariates:

H0 : Esp[Yi(1) - Yi(0)|Xi = x] = sp, for all x, against the alternative hypothesis

Ha :  x0, x1, such that Esp[Yi(1) - Yi(0)|Xi = x0] = Esp[Yi(1) - Yi(0)|Xi = x1].

7.10 Estimates for LRC-CPPT Cholesterol Data

131

This null hypothesis may be of some importance in practice. If there is evidence of heterogeneity in the effect of the treatment as a function of the covariates, one has to be more careful in extrapolating to different subpopulations. On the other hand, if there is no evidence of heterogeneity by observed characteristics, and if the distribution of these characteristics in the sample is sufficiently varied, it may be more credible to extrapolate estimates to different subpopulations. (Of course, lack of positive evidence for heterogeneity does not imply a constant treatment effect, but in cases with sufficient variation in the covariates, it does suggest that treatment-effect heterogeneity may be a a second-order problem.) In order to test this null hypothesis, we can use the quadratic form

Qconst = (^ ols)T V^ -1^ ols.

(7.7)

Theorem 7.3 Suppose we conduct a completely randomized experiment in a random
sample from a large population. If Yi(1) - Yi(0) =  for some value  and all units, then (i):   = 0,
and (ii)

Qconst - d X (dim(Xi)).

If Yi(1) - Yi(0) = 0 for all units, then (iii),

Qzero - d X (dim(Xi) + 1).

7.10 ESTIMATES FOR LRC-CPPT CHOLESTEROL DATA
Now let us return to the LRC-CPPT cholesterol data. We look at estimates for two average effects. First, the effect on post-treatment cholesterol levels, the primary outcome of interest, denoted by cholf. Second, partly anticipating some of the analyses in Chapters 23­25, we estimate the effect of assignment to treatment on the level of compliance, comp. Because compliance was far from perfect (on average, individuals assigned to the control group took 75% of the nominal dose, and individuals in the group assigned to the active treatment, on average, took 60% of the nominal dose), the estimates of the effect on post-assignment cholesterol levels should be interpreted as estimates of intention-totreat (ITT) effects, that is, average effects of assignment to the drug versus assignment to the placebo, rather than as estimates of the effects of the efficacy of the drug.
For each outcome, we present four regression estimates of the average effects. First, we use a simple linear regression with only the indicator for assignment. Second, we include the composite prior cholesterol level cholp as a linear predictor. Third, we include both prior cholesterol-level measurements, chol1 and chol2, as linear predictors. Fourth, we add interactions of the two prior cholesterol-level measurements with the assigment indicator.
Table 7.2 presents the results for these regressions. For the cholesterol-level outcome, the average effect is estimated in all cases reported to be a reduction of approximately 25­26 units, approximately an 8% reduction. Including predictors beyond the treatment

132

Regression Methods for Completely Randomized Experiments

Table 7.2. Regression Estimates for Average Treatment Effects for the PRC-CPPT Cholesterol Data from Table 7.1

Covariates
No covariates cholp chol1, chol2 chol1, chol2, interacted with W

Effect of Assignment to Treatment on

Post-Cholesterol Level

Compliance

Est
-26.22 -25.01 -25.02 -25.04

(s. e. )
(3.93) (2.60) (2.59) (2.56)

Est
-14.64 -14.68 -14.95 -14.94

(s. e. )
(3.51) (3.51) (3.50) (3.49)

Table 7.3. Regression Estimates for Average Treatment Effects on Post-Cholesterol Levels for the PRC-CPPT Cholesterol Data from Table 7.1

Covariates

Model for Levels

Model for Logs

Assignment Intercept
chol1 chol2-chol1 chol1 × Assignment (chol2-chol1) × Assignment R-squared

Est

(s. e. )

-25.04

(2.56)

-3.28 (12.05)

0.98

(0.04)

0.61

(0.08)

-0.22

(0.09)

0.07

(0.14)

0.63

Est

(s. e. )

-0.098 (0.010) -0.133 (0.233) -0.133 (0.233)
0.602 (0.073) -0.154 (0.107)
0.184 (0.159) 0.57

indicator improves the precision considerably, reducing the estimated standard error by a third. Including predictors beyond the simple composite prior cholesterol level cholp does not affect the estimated precision appreciably. For the effect of the assignment on receipt of the drug, the estimated effect is also stable across the different specifications of the regression function. For this outcome the estimated precision does not change with the inclusion of additional predictors.
The left panel of Table 7.3 presents more detailed results for the regression of the outcome on the covariates and the interaction of covariates with the treatment indicator. Although substantively the coefficients of the covariates are not of interest in the current setting, we can see from these results that the covariates do add considerable predictive power to the regression function. This predictive power is what leads to the increased precision of the estimator for the average treatment effect based on the regression with covariates relative to the regression without covariates. For the purpose of assessing the relative predictive power of different specifications, we also report, in the right panel of Table 7.3, the results for a regression after transforming all cholesterol levels to logarithms. As stressed before, this changes the estimand, and so the results are not directly comparable. It is useful to note, though, that in this case the transformation does not improve the predictive power, in the sense that the squared correlation between the observed outcomes and the covariates decreases as a result of this transformation.

7.11 Conclusion

133

Table 7.4. P-Values for Tests for Constant and Zero Treatment Effects, Using chol1 and chol2-chol1 as Covariates for the PRC-CPPT Cholesterol Data from Table 7.1

Zero treatment effect Constant treatment effect

X 2(3) approximation
Fisher exact p-value X 2(2) approximation

Post-Cholesterol Level
<0.001 <0.001
0.029

Compliance
<0.001 0.001 0.270

In Table 7.4 we report p-values for some of the tests discussed in Section 7.9. First we consider the null hypothesis that the effect of the treatment on the final cholesterol level is zero. We use the statistic Qzero given in Equation (7.6), based on the regression with the two prior cholesterol levels and their interactions with the treatment as covariates. Under this null hypothesis, this statistic has, in large samples, a chi-squared distribution with three degrees of freedom. The value of the statistic in the sample is 100.48, which leads to an approximate p-value based on the chi-squared distribution with three degrees of freedom less than 0.001. We perform the same calculations using the compliance variable as the outcome of interest. Now the value of the test statistic is 19.27, again leading to an approximate p-value less than 0.001. Because under the null hypothesis of no effect whatsoever, we can apply the FEP approach, we also calculate the exact p-values. For the post-cholesterol level, the FEP calculations lead to a p-value less than 0.001. For the compliance outcome, the p-value based on the FEP approach is 0.001. The p-values under the FEP approach are similar to those based on large-sample approximations because, with the sample size used in this example, a total of 337 units, 172 in the control group and 165 in the treatment group, and the data values, the normal approximations that underlie the large-sample properties of the tests are accurate.
Next, we test the null hypothesis that the treatment effect is constant against the alternative that it varies between units, using the statistic Qconst given in (7.7). For the final cholesterol-level outcome, the value of the test statistic is 7.05, leading to a p-value based on the chi-squared approximation with two degrees of freedom equal to 0.029. For the compliance outcome, the value of the statistic is 2.62, leading to an approximate p-value of 0.269. Note that in this case, because of the presence of nuisance parameters (we do not restrict the level of the treatment effect, only its variance), the FEP approach is not applicable. Together the tests suggest that the evidence for the presence of treatment effects is very strong but that the evidence for heterogeneity in the treatment effect is weak.
Overall, with the caveat of the multiple testing, the message from this application supports the conclusion that including some covariates can substantially improve the estimated precision of the inferences, although including many covariates is unlikely to be helpful beyond the inclusion of the most important ones.
7.11 CONCLUSION
In this chapter we discussed regression methods for estimating causal effects in the context of a completely randomized experiment. Regression models are typically motivated by assumptions on conditional mean functions. Such assumptions are difficult to justify

134

Regression Methods for Completely Randomized Experiments

other than as approximations. In the context of a completely randomized experiment, however, we can use the randomization to help justify the key assumptions necessary for consistency of the least squares estimator. In contrast to the methods discussed in previous chapters, most of these results are only approximate, relying on large samples. In that sense, the regression methods can be viewed as providing a bridge from the exact results based on randomization inference to the model-based methods that will be discussed in the next chapter.
Regression methods can easily incorporate covariates into estimands and, in that sense lead to an attractive extension of Neyman's basic approach discussed in Chapter 6. In settings with completely randomized experiments, they offer a simple and widely used framework for estimating and constructing confidence intervals for average treatment effects. The main disadvantage is that they are closely tied to linearity. In completely randomized experiments, this linearity is not a particularly important concern, because the methods still lead to consistent estimators for average treatment effects. In observational studies, however, this reliance on linearity can make regression methods sensitive to minor changes in specification. In those settings, discussed in detail in Parts III and IV of this text, simple regression methods are not recommended.

NOTES
The Efron-Feldman data were also analyzed in Jin and Rubin (2008) using a principal stratification approach. In their analysis, the focus is on the causal effect of the actual dose of the drug taken, rather than on the (intention-to-treat) effect of the assignment to the drug.
Cochran (1977) and Goldberger (1991) have extensive discussions on the properties of least squares estimators in settings where the conditional expectation is not necessarily linear, and on the notion of the "best linear predictor" (Goldberger, 1991, p. 52). Gail, Wieand, and Piantadosi (1984) discuss biases in estimated treatment effects in the context of non-linear regression models with experimental data. See also Lin (2012) and Miratrix, Sekhon, and Yu (2013). Lesaffre and Senn (2003) discuss the properties of alternative covariance adjustment methods. Koch, Tangen, Jung, and Amara (1998) discuss regression methods in settings with binary and ordered discrete outcome data. Victora, Habicht, and Bryce (2004) discuss regression methods in health applications.
The discussion in Section 7.8 on the limits of the gains in precision from incorporating pre-treatment variables draws on the results in Hahn (1998). See also Robins and Rotnitzky (1995) and Hirano, Imbens, and Ridder (2003).
Freedman (2008ab) discusses the role of regression analyses in the context of randomized experiments. He suggests, as evidenced by the quotes in the introduction to this chapter, that the use of regression analysis is not always warranted, a view to which we also subscribe. Angrist and Pischke (2008) and Lin (2012) present a less critical view of the use of regression methods for causal inference.
Senn (1994) and Imai, King, and Stuart (2008) discuss the motivation for testing or not testing for baseline balance in randomized experiments.

Appendix

135

APPENDIX

Proof of Theorem 7.1
It is convenient to reparametrize the model. Instead of (,  , ), we parametrize the model using (~ ,  , ), where ~ =  - p ·  - Esp[Xi]. The reparametrization does not change the ols estimates for  and , nor their limiting values. The limiting value of the new parameter is ~  =  - p · sp - Esp[Xi]. In terms of these parameters, the
objective function is

N Yiobs - ~ - p ·  - Esp[Xi] -  · Wi - Xi 2
i=1

N
=

Yiobs - ~ -  · (Wi - p) -

Xi - Esp[Xi]



2
.

i=1

The first-order conditions for the estimators (^~ ols, ^ ols, ^ ols) are

N
 (Yiobs, Wi, Xi, ^~ ols, ^ ols, ^ ols) = 0,
i=1

where ( · ) is a three-component column vector:





y -  -  · (w - p) - x - Esp[Xi] 

(y, w, x, ,  , ) =  (w - p) · y -  -  · (w - p) - x - Esp[Xi]   .

x - Esp[Xi] · y -  -  · (w - p) - x - Esp[Xi] 

Given the population values of the parameters, , sp, and , standard M-estimation (or generalized method of moments) results imply that under standard regularity conditions the estimator is consistent and asymptotically normally distributed:

 N

·

~^ ols ^ ols

-  - sp

- d

N

  0
0 ,

-1

(

 T )-1 ,

^ ols - 

0

where the two components of the covariance matrix are

= Esp



 (, 

,



)



(Yiobs

,

Wi

,

Xi,

,



,



)

(~ ,sp,)

 -1

-(Wi - p)

= Esp  -(Wi - p)

-(Wi - p)2

-(Xi - Esp[Xi])T -(Wi - p) · (Xi - Esp[Xi])T

 -(Xi - Esp[Xi])

-(Wi - p) · (Xi - Esp[Xi]) 

-(Xi - Esp[Xi])T · (Xi - Esp[Xi])

136

Regression Methods for Completely Randomized Experiments

 -1
= Esp  0
0

0 -p(1 - p)
0

 0

0

 ,

-Esp (Xi - Esp[Xi])T · (Xi - Esp[Xi])

and

= Esp (Yiobs, Wi, Xi, ~ , sp, ) · (Yiobs, Wi, Xi, ~ , sp, )T





= Esp  Yiobs -  - sp - Xi 2 · 

1 Wi - p

 

1 Wi - p

T   .

(Xi - Esp[Xi])T (Xi - Esp[Xi])T

The variance of ^ is the (2, 2) element of the covariance matrix. Because is block diagonal, the (2, 2) element of -1 ( T )-1 is equal to the (2, 2) element of divided
by (p(1 - p))2, which is equal to

Esp Yiobs -  - sp - Xi 2 · (Wi - p)2 .

Hence the variance of ^ , normalized by the sample size N, is equal to

Esp Yiobs -  - sp - Xi 2 · (Wi - p)2

p2 · (1 - p)2

.

Proof of Theorem 7.2 First we show that in this case   the population value of ^ , equal to

(,

 ,

,



)

=

arg

min
,, ,

Esp

Yiobs -  -  · Wi - Xi - Wi · (Xi - X) 2 ,

is equal to sp. Again it is useful to reparametrize. The new vector of parameters is

 



~ c

 + X

~ct 

=



+



 +

X



,

t

 +

with inverse

 ~ c - Xc

  = 

c ~ t - ~ c

 .



t - c

Appendix

137

In terms of this parameter vector the minimization problem is

(~ c, ~ t, c, t)

=

arg

min
c ,t ,c ,t

Esp

Yiobs - c - (t - c) · Wi - Xic

-Wi · (Xi - X)(t - c))2

=

arg

min
c ,t ,c ,t

Esp

(1 - Wi) ·

Yiobs - c - (Xi - X)c 2

+Wi · Yiobs - t - (Xi - X)t 2 .

Hence, we can solve separately

(~ c,

c)

=

arg

min
c ,c

Esp

(1 - Wi) ·

Yiobs - c - (Xi - X)c 2

,

and

(~ t,

t)

=

arg

min
t ,t

Esp

Wi ·

Yiobs - t - (Xi - X)t 2

.

Because Esp[Xi|Wi = w] = X for w = 0, 1 by the randomization, this leads to the solutions

~ c = Esp[Yi(0)],

and ~ t = Esp[Yi(1)].

Hence

  = ~ t - ~ c = Esp[Yi(1)] - Esp[Yi(0)] = sp,

proving part (i). For part (ii) we use a different reparametrization. Let ~ =  -  · p - X, with the
other parameters unchanged, so that the minimization problem becomes

(^~ ols, ^ ols, ^ ols, ^ ols) = arg min 1 N , ,, N
i=1

×

Yiobs -  -  · (Wi - p) -  (Xi - X) -  (Xi - X) · Wi

2
.

The first-order conditions for the estimators (~^ ols, ^ ols, ^ ols, ^ ols) are

N
 (Yiobs, Wi, Xi, ~^ ols, ^ ols, ^ ols, ^ ols) = 0,
i=1

138

Regression Methods for Completely Randomized Experiments

where





y -  -  · (w - p) - x - Esp[Xi]  -  x - Esp[Xi] · t

(y, w, x, ,  , ,  ) = 

(w - p) · y -  -  · (w - p) - x - Esp[Xi]  - w · x - Esp[Xi] 
x - Esp[Xi] T · y -  -  · (w - p) - x - Esp[Xi]  - w · x - Esp[Xi] 
x - Esp[Xi] T · w · y -  -  · (w - p) - x - Esp[Xi]

.

 - w · x - Esp[Xi] 

In large samples we have, by standard M-estimation methods,

~^ ols -  

  0



 N

·

^^ oollss

- -

sp 



- d

N

00 ,

-1

(

T )-1 ,

^ ols -  

0

(A.1)

where the two components of the covariance matrix are now

= Esp



(,



 ,

T

,



T

)



(Yiobs

,

Wi,

Xi,

,



,

,



)

(~ ,sp,, )



-1

-(Wi - p)

=

Esp



-(Wi - p) -(Xi - X)T

-(Wi - p)2 -(Wi - p)(Xi - X)T

Wi (Xi - X)T (Wi - p)Wi (Xi - X)T

-(Xi - X)
-(Wi - p)(Xi - X) -(Xi - X)T (Xi - X)

Wi (Xi - X)



(Wi - p)Wi (Xi - X) Wi (Xi - X)T (Xi - X

)



 -1

Wi (Xi - X)T (Xi - X) Wi2 (Xi - X)T (Xi - X)



0

0

0

=

Esp



0 0

-p(1 - p) 0

0

-X

0 0

 ,

0

00

-p · X

and

= Esp (Yiobs, Wi, Xi, ~ , sp, ,  ) · (Yiobs, Wi, Xi, ~ , sp, ,  )T





1



1

T 

= Esp Yiobs -  - sp -  Xi 2 ·

Wi - p (Xi - X)T



Wi - p (Xi - X)T

 .

Wi · (Xi - X)T Wi · (Xi - X)T

Appendix

139

The normalized variance of ^ ols - sp is the (2, 2) element of the matrix -1 ( T )-1, which is equal to

Esp Yiobs -  - sp - Xi 2 · (Wi - p)2

p2 · (1 - p)2

.

Proof of Theorem 7.3

We use the same reparametrization as in the first part of the proof of Theorem 7.2:

~ c   + X 

~ct 

=



+



 +

X  

.

t

 +

In terms of the new parameters,   = t - c. In the proof of Theorem 7.2 it was shown that the population values for (~ c, c) solve

(~ c,

c)

=

arg

min
c ,c

Esp

(1 - Wi) ·

Yiobs - c - (Xi - X)c 2

=

arg

min
c ,c

Esp

(1 - Wi) · (Yi(0) - c - (Xi - X)c)2

.

Because of the randomization, Wi is independent of Yi(0) and Xi, and so

(~ c,

c)

=

arg

min
c ,c

(1

-

p)

·

Esp

(Yi(0) - c - (Xi - X)c)2

.

A similar argument shows that (~t, t) solve the same optimization problem:

(~ t,

t)

=

arg

min
t ,t

p

·

Esp

(Yi(1) - c - (Xi - X)t)2

=

arg

min
t ,t

(1

-

p)

·

Esp

(Yi(0) +  - c - (Xi - X)t)2

(because by the null hypothesis of zero effects Yi(1) = Yi(0) +  ) and so   = t -

c = 0. This Under the

finishes the proof of part (i) of the null hypothesis (Yi(1) = Yi(0) +

theorem.  ),   =

0.

Then

 N^ ols

will

in

large

samples have a normal distribution with variance V , and the quadratic form Qconst will

have a Chi-squared distribution with degrees of freedom equal to the dimension of Xi.

This concludes the proof of part (ii) of the theorem.

Under the null hypothesis (Yi(1) = Yi(0) for all units) it also follows that sp = 0. In that case N(^ ols, ^ ols) are in large samples normally distributed with covariance

matrix V, . Hence the quadratic form Qzero will in large samples have a chi-squared distribution with degrees of freedom equal to the dimension of  and  , which is equal

to the dimension of Xi plus one. The covariance matrix for (^ ols, ^ ols) is most easily obtained from the parametrization

in part (ii) of the proof of Theorem 7.2, in terms of (~ ,  , ,  ). The point estimates

140

Regression Methods for Completely Randomized Experiments

for  and  under this parametrization are identical to those under the parametrization (Tofo,obN, ta(,i^~nolt)sh.-eUc~noodlvsea,rr^tiohalnes -cpeamr,aam^torelistxr-ifzoar,tio^ onNlsi-(n^toels)rmi-ssgoi,vfe^(no~ls,by-, -,)1p)at(rhtietTifo)u-nl1l)c-aos1vgariv(iaennTc)ie-nm1()Aaat.r1si)x.

V=

V~ ,~ -1 ( T )-1) = VV ,,~~
V ,~

V~ , V , V, V ,

V~ ,T V ,T V,T V ,T



V~ , T

V , V,

T T



.

V , T

 The covariance matrix for N(^ ols -  , ^ ols -  ) is then

V , =

V , V ,

V , T V , T

.

 The covariance matrix for N(^ ols -  ) is simply V , T .

CHAPTER 8
Model-Based Inference for Completely Randomized Experiments
8.1 INTRODUCTION
As discussed in Chapters 5 and 6, both Fisher's and Neyman's approaches for assessing treatment effects in completely randomized experiments viewed the potential outcomes as fixed quantities, some observed and some missing. The randomness in the observed outcomes was generated primarily through the assignment mechanism, and sometimes also through random sampling from a population. In this chapter, as in the preceding chapter on regression methods, we consider a different approach to inference, where the potential outcomes themselves are also viewed as random variables, even in the finite sample. Because all of the potential outcomes are considered random variables, any functions of them will also be random variables. This includes any causal estimand of interest ­ for example, the average treatment effect or the median causal effect.
We begin by building a stochastic model for all potential outcomes that generally depends on some unknown parameters. Using the observed data to learn about these parameters, we stochastically draw the unknown parameters and use the postulated model to impute the missing potential outcomes given the observed data, and use this in turn to conduct inference for the estimand of interest. At some level, all methods for causal inference can be viewed as imputation methods, although some more explicitly than others. Because any causal estimand depends on missing potential outcomes, any estimate for such an estimand is, implicitly or explicitly, based on estimates of these missing potential outcomes. The discussion in the current chapter puts this imputation perspective front and center. Because the imputations and resulting inferences are especially straightforward from a Bayesian perspective, we primarily focus on the Bayesian approach, but we also discuss the implementation of frequentist approaches, as well as how the two differ.
This model-based approach is very flexible compared to the Fisher's exact p-value approach, Neyman's repeated sampling approach, or regression methods. For instance, this method can easily accommodate a wide variety of estimands ­ we may be interested not only in average treatment effects but also in quantiles, or in measures of dispersion of the distributions of potential outcomes. In general we can conduct inference in this model-based approach for any causal estimand  =  (Y(0), Y(1)), or even
141

142

Model-Based Inference for Completely Randomized Experiments

more generally

 =  (Y(0), Y(1), X, W),

(8.1)

allowing the estimand to depend on the pre-treatment variables and the vector of treatment indicators: we do restrict  to be a row-exchangeable comparison of Y(0), Y(1), X, and W on a common set of units. In addition, although we focus primarily on the finite population, the model-based approach can easily accommodate super-population estimands. And lastly, unlike Fisher's and Neyman's methods, the model-based approach can be extended readily to observational studies, where the assignment mechanism is (partially) unknown, which we study in Parts III, IV, V, and VI of this text. In such settings, although fundamentally the resulting inference may be more sensitive to the modeling assumptions, and thus less credible than in randomized experiments, the basic approach, as well as its implementation, is the same as in classical randomized experiments.
One of the practical issues in the model-based approach is the choice of a credible model for imputing the missing potential outcomes. It is important to keep in mind here that the estimand of interest need not be a particular parameter of the statistical model. In many traditional statistical analyses, the parameters themselves are taken to be the primary objects of interest. For example, in linear regression analyses for causal effects discussed in the previous chapter, the primary focus of attention was one of the slope coefficients in the regression model. In the current setting, there is no reason why the parameters should coincide with the estimands. As stressed in the introduction to this book, the estimands  are functions of the ex ante observable vectors of potential outcomes Y(0) and Y(1) (and possibly X and W). These potential outcomes, and thus the causal estimands, are well defined irrespective of the stochastic model for either the treatment assignment or the potential outcomes. In some cases ­ for example, a linear model with identical slope coefficients in treatment and control groups ­ the estimand of interest may happen to be equal to one of the parameters of the model. Although this can simplify matters, especially when conducting a frequentist analysis of the data, it is important to understand that any such coincidence is not of any intrinsic importance, and it should not influence the choice of estimands or models, except for pedagogical purposes; rather, the choice should be based on substantive grounds. In the current setting of a completely randomized experiment, the inferences for the estimand of interest are often relatively robust to the parametric model chosen, as long as the specification is reasonably flexible. In fact, in many cases, at least in large samples, estimates for the average treatment effect are unbiased from Neyman's repeated sampling perspective, and the resulting interval estimates have the properties of Neyman's confidence intervals. Yet in other settings, for instance in observational studies with many covariates, the specification of the model may be an inherently difficult task, and the substantive conclusions are generally sensitive to the model-specification choices made. We will return to this issue in more detail in subsequent chapters.
A final comment is that, in contrast to the discussion in the previous chapter, we focus our discussion here on simulation-based computational methods rather than on analytical methods. In principle, either can be used. We focus on computational methods in large part because they often simplify the analyses given recent advances in computational power and in computational methods, such as Markov-Chain-Monte-Carlo (MCMC)

8.1 Introduction

143

techniques. Focusing on computational methods allows us to separate the problem of drawing inferences into smaller steps, with each step often conceptually straightforward. In addition, in contrast to analytical approaches, computational methods maintain the conceptual distinction between parameters in the parametric model and the estimands of interest.
The remainder of this chapter is structured as follows. In Section 8.2 we describe the data from a randomized evaluation of a labor market training program, originally analyzed by Lalonde (1986) and subsequently by Dehejia and Wahba (1999), as well as many others. In Section 8.3, as an introduction to the ideas underlying the model-based approach, we begin with a simple example with a population of only six units and discuss two naive methods to impute the missing potential outcomes given the observed data. The first naive method ignores uncertainty altogether. The second naive method incorporates uncertainty in the value to impute but ignores uncertainty in the estimated model. In addition, both naive methods jump directly to a model of the missing potential outcomes given the observed data, rather than deriving it. But this conditional distribution is inherently a function of the two underlying primitives, the assignment mechanism and the joint distribution of the two potential outcomes, and conceptually it is attractive first to specify these primitives and then to derive the conditional distribution of missing potential outcomes given observed values from these primitives. In order to incorporate uncertainty into the model, the model-based approach starts directly from these more fundamental distributions and then derives the conditional distribution of the missing potential outcomes.
Section 8.4 is the central section in this chapter. In this section we introduce the various steps of the general structure of the model-based approach in the setting without covariates. The goal is to calculate the conditional distribution of the full vector of missing potential outcomes given observed data:

f (Ymis|Yobs, W).

(8.2)

Once we have this conditional distribution, we can infer the distribution for any estimand of interest of the form  =  (Y(0), Y(1), W) by rewriting the estimand as a function of observed and missing outcomes, and assignments,  =  (Ymis, Yobs, W). The Bayesian approach for deriving the conditional distribution in (8.2) is implemented
using two inputs. The first input is a model for the joint distribution of (Y(0), Y(1)) given a hypothetical vector of parameters ,

f (Y(0), Y(1)| ).

(8.3)

By specifying this distribution in terms of a vector of unknown parameters , we allow for a flexible model, with essentially no loss of generality. The second input is a prior distribution for , representing prior beliefs about the parameter vector:

p( ).

(8.4)

In Section 8.4 we analyze the four steps taking us from the two inputs, (8.3) and (8.4), to the output, (8.2), in detail. We also discuss the choices for the model and

144

Model-Based Inference for Completely Randomized Experiments

prior distribution. To illustrate these ideas, we return to the same six units studied in Section 8.3.
In the subsequent five sections we discuss extensions of the model-based approach. First, in Section 8.5 we discuss simulation methods for approximating the distribution of  given Yobs and W, that is, the posterior distribution. Then, in Section 8.6, we discuss the issues concerning dependence between the two potential outcomes (Yi(0), Yi(1)) for a given unit, including the inability of the data to provide information regarding any such dependence, and the implications of that for posterior distributions. In Section 8.7 we incorporate covariates Xi into the model-based approach. Next, in Section 8.8, we discuss a super-population interpretation of the data. Up to this point, including Section 8.8, the discussion takes a Bayesian perspective, although the methods discussed in this chapter can also accommodate a frequentist (repeated sampling) approach.1 In Section 8.9 we discuss the model-based approach from this chapter from a frequentist perspective. In contrast to the Bayesian approach, the standard frequentist approach interprets the unknown hypothetical parameters as fixed quantities and assumes that the potential outcomes (missing or observed) are random variables given these fixed parameters. In Section 8.10 we present estimates based on the Lalonde-Dehejia-Wahba data, illustrating the various methods introduced in this chapter.

8.2 THE LALONDE NSW EXPERIMENTAL JOB-TRAINING DATA
The data we use in this chapter, to illustrate the methods developed here, come from a randomized evaluation of a job training program, the National Supported Work (NSW) program, first analyzed by Lalonde (1986) and subsequently widely used in the literature on program evaluation in econometrics. The specific data set we use here is the one discussed by Dehejia and Wabha (1999), which is a subset of the Lalonde data. The population that was eligible for this program consisted of men who were substantially disadvantaged in the labor market. Most of them had very poor labor market histories with few instances of long-term employment. For each man in this subset we have data on background characteristics, including age (age), years of education (education), whether they were now or ever before married (married), whether they were high school dropouts (nodegree), and ethnicity (black). We also have two measures of pre-training earnings; the first is earnings in 1975 (earn'75), and the second is earnings thirteen to twenty-four months prior to the training, denoted by (earn'74) because this primarily corresponds to earnings in the calendar year 1974. We also use an indicator for zero earnings in 1975 (earn'75= 0) and an indicator for zero earnings in the months thirteen to twenty-four prior to being randomized to training or not
1 A Bayesian perspective refers to statistical analyses based on viewing all a priori unobserved quantities as random variables and deriving the joint conditional distribution of estimands given all observed quantities using Bayes Rule. A frequentist perspective refers to analyses of procedures in terms of their properties in repeated samples. Interestingly, Fisher's (FEP) approach is arguably closer conceptually to the Bayesian approach than to the Neyman approach (Rubin, 1984). See Appendix A for more details and references.

8.2 The Lalonde NSW Experimental Job-Training Data

145

Table 8.1. Summary Statistics: National Supported Work (NSW) Program Data

Covariate
age education married nodegree black earn'74 earn'74=0 earn'75 earn'75=0
earn'78 earn'78=0

Mean
25.37 10.20
0.17 0.78 0.83 2.10 0.73 1.38 0.65
5.30 0.31

(S.D.)
(7.10) (1.79) (0.37) (0.41) (0.37) (5.36) (0.44) (3.15) (0.48)
(6.63) (0.46)

Average Controls (Nc = 260)
25.05 10.09 0.15 0.83 0.83 2.11 0.75 1.27 0.68
4.56 0.35

Average Treated (Nt = 185)
25.82 10.35 0.19 0.71 0.84 2.10 0.71 1.53 0.60
6.35 0.24

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

0

10

20

30

40

50

60

70

80

Figure 8.1. Histogram of earnings for control group ­ NSW job-training data

(earn'74= 0). The outcome of interest is post-program labor market experiences, earnings in 1978 (earn'78).
Table 8.1 presents some summary statistics for the sample of N = 445 men, of whom Nt = 185 were assigned to the job training program and Nc = 260 were assigned to the control group. All earnings variables are in thousands of dollars. Note that annual earnings for these men are very low, even for those years; when we average only over those with positive earnings, average annual earnings in 1978 are on the order of only approximately $8,000 after the program. Prior to the program, earnings are even lower, partly because low earnings in 1978 were a component for determining eligibility. Most preprogram characteristics are reasonably well balanced between the two groups, although the higher proportion of men with zero earnings in 1975 in the treatment group might raise concerns. Figures 8.1 and 8.2 present histograms of the distribution of the outcome, earnings in 1978 in the control and treatment groups, respectively.

146

Model-Based Inference for Completely Randomized Experiments

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

0

10

20

30

40

50

60

70

80

Figure 8.2. Histogram of earnings for trainee group ­ NSW job-training data

8.3 A SIMPLE EXAMPLE: NAIVE AND MORE SOPHISTICATED APPROACHES TO IMPUTATION

Before we introduce the formal representation of the model-based imputation approach, we begin by working through a very simple example that introduces the key ideas underlying this approach. To illustrate this example, we use a subset of the data from the NSW evaluation. Table 8.2 lists information on six men from this data set. The first man did not go through the training program. He did not have a job in 1978, and his 1978 earnings were zero. The second man did go through the training program. He subsequently did find a job, and received earnings in 1978 equal to approximately $9,900. There are a total of three treated and three control individuals, and thus twelve potential outcomes, six of them observed and six of them missing.
In the illustration in this section, we focus on the average treatment effect as the estimand. More general estimands can easily be accommodated in this approach, and we discuss some later. We can write the average treatment effect for this population of six men as

fs

=

 (Y(0), Y(1))

=

1 6

·

6 i=1

Yi(1) - Yi(0)

.

(8.5)

We rely heavily on an alternative representation of the average treatment effect, in terms of observed and missing potential outcomes. To derive this representation, we use the characterization of the two potential outcomes Yi(0) and Yi(1) in terms of the missing and observed values:

Yi(0) =

Yimis Yiobs

if Wi = 1, if Wi = 0,

and

Yi(1) =

Yimis Yiobs

if Wi = 0, if Wi = 1.

(8.6)

8.3 A Simple Example: Naive and More Sophisticated Approaches to Imputation

147

Table 8.2. First Six Observations from NSW Program Data

Unit

Potential Outcomes

Yi(0)

Yi(1)

1

0

?

2

?

9.9

3

12.4

?

4

?

3.6

5

0

?

6

?

24.9

Treatment Wi
0 1 0 1 0 1

Observed Outcome Yiobs
0 9.9 12.4 3.6 0 24.9

Note: Question marks represent missing potential outcomes.

Then we can write fs in terms of observed and missing potential outcomes and treatment indicators as

fs = ~ (Yobs, Ymis, W)

=1· N 6
i

(Wi · Yiobs + (1 - Wi) · Yimis) - ((1 - Wi) · Yiobs + Wi · Yimis)

=1· N 6 i=1

(2 · Wi - 1) ·

Yiobs - Yimis

.

(8.7)

We know the value of the causal estimand up to the missing potential outcome values. In
the model-based approach, we estimate the average treatment effect by explicitly imput-
ing the six missing potential outcomes, initially once, and then repeatedly to account for the uncertainty in the imputation. Let Y^imis be the imputed value for Yimis, leading to the following estimator for the average treatment effect:

^ = ~ (Yobs, Y^ mis, W) = 1 · N 6 i=1

(2 · Wi - 1) · (Yiobs - Y^imis)

.

(8.8)

The key question is how to impute the missing potential outcomes Y^imis, given the observed values Yobs and the treatment assignments W.

Let us first discuss a very simple, and naive, approach, where we impute each missing

potential outcome by the average of the observed potential outcomes with that treatment

level. Consider the first unit. Unit 1 received the control treatment, so we observe its

potential outcome under control (Y1(0)) but not its potential outcome given treatment

(Y1(1)). Thus Y1obs = Y1(0) and Y1mis = Y1(1). The average outcome for the three units

randomly

assigned

to

the

treatment,

that

is,

units

2,

4,

and

6,

is

Y

obs t

=

(Y2(1)

+

Y4(1)

+

Y6(1))/3 = (9. 9 + 3. 6 + 24. 9)/3 = 12. 8. In this illustrative example, we would there-

fore impute Y^1mis = 12. 8. In contrast, Unit 2 received the treatment, thus Y2mis = Y2(0).

The average observed outcome for the three randomly chosen units who did receive the

control

treatment

is

Y

obs c

=

(Y1(0) + Y3(0) + Y5(0))/3

=

(0 + 12. 4 + 0)/3

=

4. 1,

so

we

impute

Y^ 2mis

=

Y

obs c

=

4. 1.

Following

the

same

approach

for

the

remaining

148

Model-Based Inference for Completely Randomized Experiments

Table 8.3. The Average Treatment Effect Using Imputation of Average Observed Outcome Values within Treatment and Control Groups for the NSW Program Data

Unit
1 2 3 4 5 6 Average Diff (ATE):

Potential Outcomes

Yi(0)
0 (4.13) 12.4 (4.13) 0 (4.13)
4.13

Yi(1)
(12.8) 9.9
(12.8) 3.6
(12.8) 24.9
12.8 8.67

Treatment Wi
0 1 0 1 0 1

Observed Outcome Yiobs
0 9.9 12.4 3.6 0 24.9

four units, Table 8.3 presents the observed and imputed potential outcomes ­ the latter

in parentheses ­ for all six units. Substituting these values in Equation (8.8) gives an

average treatment effect of ^ = 12.8 - 4.1 = 8.7. Notice that this is equal to the differ-

ence

between

the

two

average

observed

outcomes

by

treatment

status,

^

dif

=

Y

obs t

-

Y

obs c

.

Given the imputation method, the value for the causal estimand should not be surprising,

but the overall result is unsatisfying. Because we imputed the missing potential outcomes

as if there were no uncertainty about their values, this method provides only a point esti-

mate, with no sense of its precision. Yet it is clear that we are not at all certain that the

missing potential outcomes Y1(1), Y3(1), and Y5(1) are all exactly equal to 12.8. In fact, for the three units with Yi(1) observed, we see that there is a fair amount of variation in

the Yi(1). Even if we assume that units 1, 3, and 5 are "on average" just like the others ­

as we should expect, given the completely randomized experiment ­ we should still cre-

ate imputations that reflect this variability. At most, the randomization would allow us

to deduce the distribution of the missing potential outcomes, but almost never the exact

values of the missing potential outcomes.

Let us therefore consider a second, less naive approach to imputing the missing poten-

tial outcomes. Let us again consider a unit with Wi = w, so that Yimis = Yi(1 - w).

Instead of setting Y^imis for such a unit equal to the corresponding average observed value

Y

obs c

if

w

=

1

or

Y

obs t

if

w

=

0,

as

we

did

in

the

first

approach,

let

us

draw

Yimis

for

such a unit at random from the distribution of Yjobs for those units for whom we observe

Yj(1 - w), that is, units with Wj = 1 - w. Specifically, for Unit 1, with Y1mis = Y1(1),

let us draw at random from the trinomial distribution that puts mass 1/3 on each of

the three observed Yi(1) values, the observed Yiobs values for Units 2, 4, and 6, namely Y2(1) = 9.9, Y4(1) = 3.6, and Y6(1) = 24.9. Similarly for Unit 2, impute Y2mis by draw-

ing from the trinomial distribution with values Y1(0) = 0, Y3(0) = 12. 4, and Y5(0) = 0,

each with probability equal to 1/3; because two of the values are equal, this amounts

to a binomial distribution with support points 0 and 12.4, with probabilities 2/3 and

1/3, respectively. Suppose we draw 3.6 for Unit 1 and 12.4 for Unit 2, thereby imputing Y^1mis = 3.6 and Y^2mis = 12.4. For the third unit, we again draw from the distribution with values 9.9, 3.6, and 24.9; suppose we draw Y^3mis = 9.9. For the fourth unit, suppose we

8.3 A Simple Example: Naive and More Sophisticated Approaches to Imputation

149

Table 8.4. The Average Treatment Effect Using Imputed Draws from the Empirical Distributions within Treatment and Control Groups for the First Six Units from the NSW Program Data

Unit

Potential Outcomes

Yi(0)

Panel A: First draw

1

0

2

(12.4)

3

12.4

4

(12.4)

5

0

6

(0)

Yi(1)
(3.6) 9.9 (9.9) 3.6 (9.9) 24.9

Average Diff (ATE):

6.2

10.3

4.1

Panel B: Second draw

1

0

2

(0)

3

12.4

4

(0)

5

0

6

(0)

(9.9) 9.9 (24.9) 3.6 (3.6) 24.9

Average Diff (ATE):

2.1

12.8

10.7

Treatment Wi

Observed Outcome Yiobs

0

0

1

9.9

0

12.4

1

3.6

0

0

1

24.9

0

0

1

9.9

0

12.4

1

3.6

0

0

1

24.9

again draw 12.4; hence Y^4mis = Y^2mis = 12.4. Note that because we draw with replacement, it is possible to draw the same value for more than one unit. Panel A of Table 8.4 gives these six observations with the missing values imputed in this fashion. Given the imputed and observed data, this gives an estimated average treatment effect of 4.1.
Up to this point, this process has been fairly similar to the first method: for each of the six units, we imputed the missing potential outcome and, via Equation (8.8), used those imputations to estimate the average treatment effect. Now, however, there is a crucial difference. With the current method, we can repeat this process to give a new value for the average treatment effect. Again drawing from the same assumed distributions for the missing Y(0) and Y(1), we expect to draw different values, thereby giving a different estimate for the average treatment effect. Panel B of Table 8.4 presents such a result, this time giving an estimated average treatment effect equal to 10.7.
We can repeat this procedure as many times as we wish, although at some point we will generate sets of draws identical to the ones already obtained. With six missing potential outcomes, each one drawn from a set of three possible values, there are 36 = 729 different ways of imputing the data, all equally likely. Calculating the corresponding average treatment effect for each set of draws, we can then calculate the average and standard deviation of these 729 estimates. Note that not all of these will be different; the order in which the individual outcomes are imputed does not matter. Over the 729 possible vectors of imputed missing data, this leads to an average treatment effect of

150

Model-Based Inference for Completely Randomized Experiments

8.7 and a standard deviation of 3.1. Notice that this average is again identical to the

difference

in

average

outcomes

by

treatment

level,

^ dif

=

Y

obs t

-

Y cobs .

As

before,

this

should seem intuitive, because we have calculated this value from the full set of 729

possible, equally likely, permutations. What this approach adds to the previous analysis,

however, is an estimate of the entire distribution of the average treatment effect and,

in particular, an estimate of the variability of the estimated average treatment effect, as

reflected, for instance, in the standard deviation of this distribution.

Although this example focuses on the average treatment effect, the same procedure

could be applied to any other function of the six pairs of potential outcomes. For exam-

ple, one may be interested in the ratio of variances of the potential outcomes at each

treatment level, or in other measures of central tendency or dispersion.

With more than six units, it quickly becomes expensive to calculate all possible impu-

tations of the missing data. In practice one may, therefore, prefer to use a randomly

selected subset of these imputations and estimate the distribution of a treatment effect as

reflected by these values. Such an approach will give an accurate approximation to the

distribution based on drawing all possible imputations if enough replications are made.

The use of this randomization for imputing the missing potential outcomes is purely a

computational device, albeit a very convenient one.

This second method for imputing the missing potential outcomes is substantially more

sophisticated than the first. Nevertheless, it still does not address fully the uncertainty we

face in estimating the average treatment effect. In particular, we impute the missing data

as if we knew the exact distribution of each of the potential outcomes. Yet, in practice,

we have only limited information; in this example based on six units, our information

for the distributions of treatment and control outcomes comes entirely from three obser-

vations for each. For instance, we assume the distribution of Yi(1), based on the three

observed values (9.9, 3.6, and 24.9), is trinomial for those three values with equal proba-

bility. If we actually observed three additional units exposed to the treatment, it is likely

that their observed outcomes would differ from the first three. If we study the set of

all 445 observations in the NSW data set, we see that the other treated units do have

different potential outcomes from the three in Table 8.2. To take into account this addi-

tional source of uncertainty essentially requires a model for the potential outcomes ­

observed as well as missing ­ which formally addresses the uncertainty about possible

values of missing potential outcomes. We turn to this next.

8.4 BAYESIAN MODEL-BASED IMPUTATION IN THE ABSENCE OF COVARIATES
Let us now formally describe the Bayesian model-based approach for inference in completely randomized experiments when no covariates are observed. The primary goal of this approach is to build a model for the missing potential outcomes, given the observed data,

f (Ymis|Yobs, W).

(8.9)

8.4 Bayesian Model-Based Imputation in the Absence of Covariates

151

Once we have such a model, we can derive the distribution for the estimand of interest,  =  (Y(0), Y(1), W), using the fact that we can also represent the estimand in terms of observed and missing potential outcomes as  =  (Ymis, Yobs, W).
Throughout this chapter, we are slightly informal in our use of notation, and use f ( · | · ) to denote generic conditional distributions, without indexing the distribution f ( · | · ) by the random variables. In each case it should be clear from the context to which random variables the distributions refer.
The previous naive approaches also build models for the missing potential outcomes but in partially unsatisfactory ways. In the first approach in Section 8.3, we specified a degenerate distribution of the missing potential outcomes for unit i as
 1 if y = 12.8, and Wi = 0, Pr Yimis = y Yobs, W = 1 if y = 4.1, and Wi = 1,
0 otherwise.

In the second approach in Section 8.3, we specified a non-degenerate distribution of the

missing potential outcomes for unit i, namely



Pr

Yimis = y Yobs, W

=

11//33 2/3

if y  {3.6, 9.9, 24.9}, and Wi = 0,

if y = 12.4, Wi = 1, if y = 0, Wi = 1,

.

0 otherwise.

Using these models, for each unit i, we predicted Yimis, the outcome we would have observed if i had been exposed to the alternative treatment. Given these imputed missing potential outcomes, we calculated the corresponding estimand, in the specific example, the average treatment effect. These models for the missing potential outcomes were straightforward, but too simplistic, in that neither model allowed for uncertainty in the estimation of the distribution of the missing potential outcomes. In this section we consider more sophisticated methods for imputing the missing potential outcomes that allow for such uncertainty.
Although what we are ultimately interested in is simply a model for the conditional distribution of Ymis given (Yobs, W), this is not our initial focus. The reason is that it is conceptually difficult to specify directly a model for the conditional distribution of Ymis given Yobs and W, and still formally conform to the distributional assumptions on the science and the assignment mechanism. The conditional distribution of Ymis given (Yobs, W) depends intricately on the the joint distribution of the potential outcomes, (Y(0), Y(1)), and on the assignment mechanism. These are very different objects. Specification of the former requires scientific (e.g., subject-matter) knowledge, be it economics, biology, or some other science. In contrast, in the context of this chapter, the assignment mechanism is known by the assumption of a completely randomized experiment. In the model-based approach, we therefore step back and consider specification of the two components separately.
In the remainder of this section, we describe, at a more abstract level, the general approach for obtaining the distribution of the missing data given the observed data in settings without covariates. We separate the derivation of the posterior distribution of the causal effect of interest into four steps, laying out in detail the procedure that takes

152

Model-Based Inference for Completely Randomized Experiments

us from the specification of the joint distribution of the potential outcomes to the conditional distribution of the causal estimand given the observed data, called the posterior (meaning post-observed data) distribution of the estimand. Following the description of the general approach, we return to the six-unit example and show, in detail, how this can be implemented analytically in a very simple setting with Gaussian distributions for the potential outcomes. However, in practice there are few situations where one can derive the posterior distribution of interest analytically, and in Section 8.5 we show how simulation methods can be used to obtain draws from the posterior distribution in the same simple example. This simulation approach is much more widely applicable and often easy to implement.

8.4.1 Inputs into the Model-Based Approach
The first input for the model-based approach is a model for the joint distribution of the two potential outcomes (Y(0), Y(1)):

f (Y(0), Y(1)).

(8.10)

Under row (unit) exchangeability of the matrix (Y(0), Y(1)), and by an appeal to de Finetti's theorem, we can, with no essential loss of generality, model this joint distribution (Y(0), Y(1)) as the integral over the product of iid (independent and identically distributed) unit-level distributions,

f (Y(0), Y(1)) =

N
f (Yi(0), Yi(1)| ) · p( )d ,
i=1

where  is an unknown, finite-dimensional parameter of f (Yi(0), Yi(1)| ), which lies in a parameter space , and p() is its marginal (or prior) distribution.
Specifying the joint distribution of (Yi(0), Yi(1)) conditional on  can be a difficult task. The joint density can involve many unknown parameters. Its specification requires subject-matter (scientific) knowledge. Although in the current setting of completely randomized experiments, inferences are often robust to different specifications, this is not necessarily true in observational studies. In the example in the next section, we use a bivariate normal distribution, but in other cases, binomial distributions or log normal distributions, or mixtures of more complicated distributions may be more appropriate.
Specifying the second input, the prior distribution of ,

p( ),

(8.11)

can also be difficult. In many cases, however, the substantive conclusions are not particularly sensitive to this choice. In the application in this chapter we investigate this issue in more detail.
In observational studies there would be a third input into the model-based calculations: the conditional distribution of W given the potential outcomes, or in other words, the assignment mechanism, f (W|Y(0), Y(1)). In the current setting of a completely

8.4 Bayesian Model-Based Imputation in the Absence of Covariates

153

randomized experiment with no covariate, the assignment mechanism is by definition equal to

Pr(W|Y(0), Y(1)) =

N -1 ,

Nt

N
for all W such that Wi = Nt,
i=1

so this is an input that needs no further specification here.

8.4.2 The Four Steps of the Bayesian Approach to Model-Based Inference for Causal Effects in Completely Randomized Experiments with No Covariates
There are four steps involved in going from the two inputs to the distribution of the
estimand given the observed data. The first step of the model-based approach involves deriving f (Ymis|Yobs, W,  ). The second step involves deriving the posterior distribution for the parameter  , that is, f ( |Yobs, W). The third step involves combining the conditional distribution f (Ymis|Yobs, W,  ) and the posterior distribution f ( |Yobs, W) to obtain the conditional distribution of the missing data given the observed data, but without conditioning on the parameters, f (Ymis|Yobs, W), that is, integrating their product over . Finally, in the fourth step we use the definition of the estimand,  =  (Y(0), Y(1)), and the conditional distribution f (Ymis|Yobs, W) to obtain the conditional distribution of the estimand given the observed values, f ( |Yobs, W). We now examine these four steps in somewhat excruciating detail.

Step 1: Derivation of f (Ymis|Yobs, W,  ) First we combine the conditional distribution, the conditional distribution of the vector of assignments given the potential outcomes, Pr(W|Y(0), Y(1)), with the model for the joint distribution of the potential outcomes given, , f (Y(0), Y(1)| ), to get the joint distribution of (W, Y(0), Y(1)) given , as the product of these two vectors:

f (Y(0), Y(1), W| ) = Pr(W|Y(0), Y(1), ) · f (Y(0), Y(1)| ).

(8.12)

Using the joint distribution in (8.12), we derive the conditional distribution of the potential outcomes given the vector of assignments and the parameter, , f (Y(0), Y(1)|W, ), for the general case as

f (Y(0),

Y(1)|W, )

=

f (Y(0), Y(1), W| ) Pr(W| )

=

f (Y(0), Y(1), W|) f (Y(0), Y(1), W|)dY(0)dY(1) .

The assumption of a completely randomized experiment implies that W is independent of (Y(0), Y(1)), and so that this conditional distribution is in fact equal to the marginal distribution:

f (Y(0), Y(1)|W, ) = f (Y(0), Y(1)| ).

This simplification more generally applies to all regular assignment mechanisms.

154

Model-Based Inference for Completely Randomized Experiments

Next, we transform the distribution for Y(0) and Y(1) given W and  into the distribution for Ymis given Yobs, W, and  . Recall that we can express the pair (Yimis, Yiobs) as functions of (Yi(0), Yi(1), Wi):

Yiobs =

Yi(0) Yi(1)

if Wi = 0, if Wi = 1,

Yimis =

Yi(0) Yi(1)

if Wi = 1, if Wi = 0.

(8.13)

Hence (Ymis, Yobs) can be written as a transformation of (Y(0), Y(1), W), or

(Ymis, Yobs) = g(Y(0), Y(1), W).

We can use this transformation to obtain the distribution of (Ymis, Yobs) given W and  ,

f (Ymis, Yobs|W,  ).

(8.14)

This, in turn, allows us to derive:

f (Ymis|Yobs, W,  )

=

f (Ymis, Yobs|W,  ) f (Yobs|W,  )

=

f (Ymis, Yobs|W,  ) ymis f (ymis, Yobs|W,  )dymis .

(8.15)

This is the conditional distribution of the missing potential outcomes given the observed values, also called the posterior predictive distribution of Ymis.

Step 2: Derivation of the Posterior Distribution of the Parameter , p( |Yobs, W) Here we combine the prior distribution on , p(), with the distribution of the observed data given  to derive the posterior distribution of , p(|Yobs, W). In order to derive
the likelihood function, which is proportional to the distribution of the observed data regarded as a function of the unknown , we return to our previously established
joint distribution of the missing and observed potential outcomes given the parameter  , f (Ymis, Yobs|W,  ). From this, we can derive the marginal distribution of the observed outcomes given , that is, the likelihood function, by integrating out the
missing potential outcomes,

L( |Yobs, W)  f (Yobs, W| ) =

f (ymis, Yobs, W| ) dymis.

ymis

Combining the likelihood function with the prior distribution p(), we obtain the posterior (that is, conditional given the observed data) distribution of the parameters:

p( |Yobs, W)

=

p( ) · L( |Yobs, W) f (Yobs, W) ,

(8.16)

where f (Yobs, W) is the marginal distribution of (Y, W) obtained by integrating over :

f (Yobs, W) = p( ) · L( |Yobs, W) d .


8.4 Bayesian Model-Based Imputation in the Absence of Covariates

155

Step 3: Derivation of Posterior Distribution of Missing Outcomes f (Ymis|Yobs, W) Now we combine the conditional distribution of Ymis given (Yobs, W,  ), given in (8.15), and the posterior distribution for , given in (8.16), to derive the joint distribution of (Ymis, ) given (Yobs, W):
f (Ymis,  |Yobs, W) = f (Ymis|Yobs, W,  ) · p( |Yobs, W).
Then we integrate over  to derive the conditional distribution of Ymis given (Yobs, W):

f (Ymis|Yobs, W) = f (Ymis,  |Yobs, W) d ,

which gives us the conditional distribution of the missing data given the observed data.

Step 4: Derivation of Posterior Distribution of Estimand f ( |Yobs, W) Finally, we use the conditional distribution of the missing data given the observed data f (Ymis|Yobs, W) and the observed data (Yobs, W) to obtain the distribution of the estimand of interest given the observed data. This is the first, and only, time the procedure uses the specific choice of estimand.
The general form of the estimand is  =  (Y(0), Y(1), W). We can rewrite  in terms of observed and missing potential outcomes and the treatment assignment, using (8.6):
(Y(0), Y(1)) = h(Ymis, Yobs, W).
Thus we can write ~ (Ymis, Yobs, W). Combined with the conditional distribution of Ymis given (Yobs, W), we derive the conditional distribution of  given the observed data (Yobs, W), that is, the posterior distribution of  :
f ( |Yobs, W).

Once we have this distribution, we can derive the posterior mean, standard deviation, and any other feature of the posterior distribution of the causal estimand.

We conclude this section with a general comment concerning the key differences between the formal model-based approach and the simplistic examples that opened this chapter. First, the researcher must specify a complete model for the joint distribution of the potential outcomes Y(0) and Y(1) by specifying a unit-level joint distribution, f (Yi(0), Yi(1)| ), given a generally unknown parameter . Although this model depends on an unknown parameter, , and thus need not be very restrictive, at first glance this approach may seem more restrictive than the initial examples where no such model was necessary. Yet this is not necessarily correct. The earlier, naive approaches assumed that the distribution of the missing data given the observed data was known with certainty, an assumption that is more restrictive than any parametric specification. The second difference is that the model-based approach requires the researcher to choose a prior distribution for the unknown parameter  in order to derive its posterior distribution. In practice, given a completely randomized experiment, this choice is often not critical. At least in this setting, as long as the model is reasonably flexible, the prior distribution is not too dogmatic, and the data are sufficiently informative, the substantive conclusions

156

Model-Based Inference for Completely Randomized Experiments

are typically robust. In observational studies, however, the sensitivity of conclusions to the model choice and the choice of prior distribution are typically more severe, as we see in later chapters.

8.4.3 An Analytic Example with Six Units
To illustrate the four different steps in the model-based approach, consider again the first six observations of the National Supported Work Experiment. In Appendix B we provide a more detailed derivation of the distribution of the average treatment effect in a slightly more general setting where we assume Gaussianity for both the joint distribution of the potential outcomes and a conjugate prior distribution for , allowing for unknown covariance matrices with non-zero correlations.
The two inputs are a model for the joint distribution of the potential outcomes, and a prior distribution for the unknown parameters of this distribution. Here, for illustrative purposes, we specify a simple normal distribution for the pair of potential outcomes with unknown means but known covariance matrix:

Yi(0)   N Yi(1)

c t

,

100 0

0 64

,

(8.17)

where the parameter vector  consists of two elements,  = (c, t), implying

f (Yi(0), Yi(1)| )

=

2

·

1 64

·

100

· exp

- 2

1 · 100

(Yi(0)

-

c)2

-

2

1 · 64

(Yi(1)

-

t )2

.

More generally, we may wish to relax the assumption that the covariance matrix is known; for instance, see the examples in Section 8.6 and Appendix B. We may also want to consider more flexible distributions, such as mixtures of normal distributions.
The second input is the prior distribution for the vector parameter  = (c, t). We use here the following prior distribution:

c t

N

0 , 10,000 0

0

0 10,000

.

(8.18)

This prior distribution is relatively agnostic about the values of c and t over a wide range of values, relative to the data values, displayed in Table 8.2. In Appendix B we provide some calculations for a more general specification of the prior distribution, allowing for non-zero means, and a non-diagonal covariance matrix. In practice, with a reasonably sized data set and a completely randomized experiment, we would expect the results to be fairly insensitive to the choice of prior distribution.
In an observational study we would also have to specify the assignment mechanism, but here this is known to be

Pr(W = w|Y(0), Y(1), c, t) =

N

-1
,

Nt

for all w with wi  {0, 1} for all i = 1, . . . , N, and

N i=1

wi

=

Nt,

and

zero

elsewhere.

8.4 Bayesian Model-Based Imputation in the Absence of Covariates

157

Step 1: Derivation of f (Ymis|Yobs, W, c, t) Because the potential outcomes are independent across units conditional on (c, t), the specification of the joint distribution of the pair (Yi(0), Yi(1)) given  allows us to derive the joint distribution of Y(0) and Y(1) given  = (c, t).

N
f (Y(0), Y(1)|c, t) = f (Yi(0), Yi(1)|c, t).
i=1
Let N denote the N-dimensional vector with all elements equal to one, and let IN denote the N × N dimensional identity matrix. Then the 2N-component vector constructed by stacking Y(0) and Y(1) is distributed, given , as

Y(0) Y(1)

c, t  N

c · N t · N

,

100 · IN 0 · IN

0 · IN 64 · IN

.

(8.19)

Next we exploit the assumption that the data come from a completely randomized experiment. Therefore the distribution of W conditional on the potential outcomes and  is

Pr(W = w|Y(0), Y(1), c, t) =

N Nt

-1
,

for all w such that i Wi = Nt, and zero elsewhere. Deriving the conditional distribution of the potential outcomes given the assignment vector is straightforward because of the independence of W and (Y(0), Y(1)) given , so that the conditional distribution is the
same as the marginal distribution given in (8.19):

Y(0) Y(1)

W, c, t  N

c · N t · N

,

100 · IN 0 · IN

0 · IN 64 · IN

.

(8.20)

Now we transform this conditional distribution to the conditional distribution of
(Ymis, Yobs) given (W, c, t), using the representations of Yimis and Yiobs in terms of Yi(0), Yi(1), and Wi given in Equations (8.13). Because conditional on (W, c, t) the
pairs (Yi(0), Yi(1)) and (Yi (0), Yi (1)) are independent if i = i , it follows that the pairs (Yimis, Yiobs) and (Yimis, Yiobs) are also independent given (W, c, t) if i = i . Hence

N
f (Ymis, Yobs)|W, c, t) = f (Yimis, Yiobs|W, c, t),
i=1

where the joint distribution of (Yimis, Yiobs) given (W, c, t) is

Yimis Yiobs

c, t, W  N

Wi · c + (1 - Wi) · t (1 - Wi) · c + Wi · t

,

Wi · 100 + (1 - Wi) · 64

0

0

(1 - Wi) · 100 + Wi · 64

.

(8.21)

Because in this example Yimis and Yiobs are uncorrelated given (c, t) ­ the off-diagonal elements of the covariance matrix in (8.21) are equal to zero ­ the conditional distribution

158

Model-Based Inference for Completely Randomized Experiments

of Yimis given (Yiobs, c, t) is simply equal to the marginal distribution of Yimis given (c, t):

Yimis|Yobs, W, c, t  N Wi · c + (1 - Wi) · t, Wi · 100 + (1 - Wi) · 64 . (8.22)

Thus the joint distribution of the full N-vector Ymis given (Yobs, W, c, t), is





W1 · c + (1 - W1) · t

Ymis|Yobs,

W,

c, t



N

 W2

·

c

+

(1 ...

-

W2)

·

t

 ,

WN · c + (1 - WN ) · t



W1 · 100 + (1 - W1) · 64

0

...



0 ...

W2 · 100 + (1 - W2) · 64 . . .

...

...

 0

0 ...

.

0

0

. . . WN · 100 + (1 - WN) · 64

(8.23)

For the six units in our illustrative data set, this leads to

Y1mis

t  64 0 0 0 0 0 

YYYY4325mmmmiiiissss

Yobs, W, c, t



N

cctt 

,



0 0 0 0

100 0 0 0 0 64 0 0 0 0 100 0 0 0 0 64

0 0 0 0

 .

Y6mis

c

0 0 0 0 0 100

(8.24)

Step 2: Derivation of the Posterior Distribution of the Parameter p(c, t|Yobs, W) The second step consists of deriving the posterior distribution of the parameter given the observed data. The posterior distribution is proportional to the product of the prior distribution and the likelihood function:

p(c, t|Yobs, W)  p(c, t) · L(c, t|Yobs, W).

The prior distribution is given in (8.18), so all we need to do is derive the likelihood function. Conditional on (W, c, t), the distribution of the observed outcome Yiobs is

Yiobs|W, c, t  N (1 - Wi) · c + Wi · t, (1 - Wi) · 100 + Wi · 64 .

(8.25)

Because Yiobs is independent of Yiobs conditional on (W, c, t) if i = i , the contribution of unit i to the likelihood function is proportional to ("")

8.4 Bayesian Model-Based Imputation in the Absence of Covariates

159

Li



 2

·

((1

-

1 Wi) ·

100

+

Wi

·

64)

× exp - 1 2

1 (1 - Wi) · 100 + Wi · 64

Yiobs - (1 - Wi) · c - Wi · t

2

,

and the likelihood function is proportional to the product of these N factors and the probability of the assignment vector. Because the latter is a known constant, it can be ignored, and the likelihood function is proportional to

L(c, t|Yobs, W)

6





1

i=1 2 · ((1 - Wi) · 100 + Wi · 64)

× exp - 1 2

1 (1 - Wi) · 100 + Wi · 64

Yiobs - (1 - Wi) · c - Wi · t

2



 1 exp - 1

i:Wi=0 2 · 100

2

1 100

Yiobs - c

2

×

 1 exp - 1

i:Wi=1 2 · 64

2

1 64

Yiobs - t

2

.

To derive the posterior distribution, we exploit the fact that both the prior distribution of c and t, and the likelihood function factor into a function of c and a function of t. This factorization leads to the following posterior distribution of (c, t) given the observed data:

p(c, t|Yobs, W) 

exp - 1 2c 2 10,000

·

1

exp - 1 (Yiobs - c)2

i:Wi=0 2 · 100

2

100

× exp - 1

2t

·

1

exp - 1 (Yiobs - t)2 .

2 10,000

i:Wi=1 2 · 64

2

64

This expression implies that

c t

Yobs, W



N



Y

obs c

·

Nc

Y

obs t

·

Nt

Nc · 10,000 · 10,000 + 100 Nt · 10,000 · 10,000 + 64

 ,Nc/100

1
+ 1/10,000 0

 1 Nt/64 + 1/10,000 .
(8.26)

Substituting

the

appropriate

values

from

the

six-unit

data

set

in

Table

8.2,

with

Y

obs c

=

4.1 and Nc = 3, we find that c has a Gaussian posterior distribution with meanequal

160

Model-Based Inference for Completely Randomized Experiments

to 4.1 and variance equal to 33.2 = 5.82. Following the same argument for t, with

Y

obs t

=

12.8

and

Nt

=

3,

we

find

that

t

has

a

Gaussian

posterior

distribution

with

mean

12.8 and variance 21.3 = 4.62, so that:

c t

Yobs, W  N

4.1 5.82 0 12.8 , 0 4.62

.

(8.27)

Recall our previous comment that, given a completely randomized experiment, the

resulting posterior distribution is fairly insensitive to the choice of the prior distribu-

tion for c, t. We can see this here, where the choice of prior distribution has had

little effect on any of the moments of the posterior distribution of (c, t). In particular,

notice in (8.27) that the mean values for c and t are equal, up to the first significant

digit,

to

the

observed

average

values,

Y

obs c

and

Yot bs.

The

posterior

distribution,

propor-

tional to the product of the prior distribution for (c, t) and the marginal distribution

of Yobs given (c, t), regarded as a function of (c, t), puts weight on each factor

proportional to their precisions, that is, the inverse of their variances. Our choice of prior

distribution ­ with such large posited variances ­ implies giving almost all of the weight

to

the

observed

data,

Y

obs c

and

Y tobs .

This

choice

was

made

specifically

to

impose

little

structure through our assumptions, instead allowing the observed data to be the primary

voice for the ultimate posterior distribution of  .

Step 3: Derivation of Posterior Distribution of Missing Potential Outcomes f (Ymis|Yobs, W) Now we combine the conditional distribution of Ymis given (Yobs, W, c, t), given in (8.23), and the posterior distribution of (c, t) given (Yobs, W), given in (8.26), to obtain the conditional distribution of Ymis given (Yobs, W). Because the distribution of Ymis given (Yobs, W, c, t), and the distribution of (c, t) given (Yobs, W) are Gaussian, it follows that the joint distribution of (Ymis, c, t) given (Yobs, W) is Gaussian, and thus the marginal distribution of Ymis given (Yobs, W) is
Gaussian. Hence, all we need to do is derive the first two moments of this distribution in
order to characterize it fully. First consider the mean of Yimis given (Yobs, W). Conditional on (Yobs, W, c, t), we
have, using (8.24):

E Yimis Yobs, W, c, t = Wi · c + (1 - Wi) · t.

In addition, from (8.26), we have

E

c t

Yobs, W

=

 YYcootbbss··NNct

Nc · 10,000 · 10,000 + 100 Nt · 10,000 · 10,000 + 64

 

.

Hence

E Yimis|Yobs, W = Wi ·

Y

obs c

·

Nc

Nc · 10,000 · 10,000 + 100

+ (1 - Wi) ·

Y

obs t

·

Nt

Nt · 10,000 · 10,000 + 64

.

(8.28)

8.4 Bayesian Model-Based Imputation in the Absence of Covariates

161

Next, consider the variance. By the law of iterated expectations,

V Yimis Yobs, W = E V Yimis Yobs, W, c, t Yobs, W

+ V E Yimis Yobs, W, c, t Yobs, W

= E Wi · 100 + (1 - Wi) · 64 Yobs, W + V Wi · c + (1 - Wi) · t Yobs, W

=

Wi

·

100

+

(1

-

Wi)

·

64

+

Wi

·

Nc/100

1 + 1/10,000

+

(1

-

Wi)

·

Nt/64

1 + 1/10,000

= Wi ·

100

+

Nc/100

1 + 1/10,000

+ (1 - Wi) ·

64

+

Nt/64

1 + 1/10,000

.

(8.29)

We also need to consider the covariance between Yimis and Yimis, for i = i :

C Yimis, Yimis Yobs, W = E C Yimis, Yimis Yobs, W, c, t Yobs, W

+ C E Yimis Yobs, W, c, t , E Yimis Yobs, W, c, t Yobs, W

= 0 + C Wi · c + (1 - Wi) · t, Wi · c + (1 - Wi ) · t Yobs, W

=

Wi

·

Wj

·

Nc/100

1 + 1/10,000

+

(1

-

Wi)

·

(1

-

Wj)

·

Nt/64

1 + 1/10,000 .

(8.30)

Putting this all together for the six-unit data set, we find

Y1mis YYYY5432mmmmiiiissss Yobs, W 
Y6mis    12. 8 85. 3

N

114422....1188

,

221100..

3 3

4. 1

0

0 133. 2
0 0 0 33. 2

21. 3 0
85. 3 0
21. 3 0

0 33. 2
0 133. 2
0 33. 2

21. 3 0
21. 3 0
85. 3 0

0 

33. 0
33. 0

2 2



.

133. 2

(8.31)

Note that the missing outcomes are no longer independent. Conditional on the parameters (c, t) they were independent, but the fact that they depend on common parameters introduces some dependence.

162

Model-Based Inference for Completely Randomized Experiments

Step 4: Derivation of Posterior Distribution of Estimand, f ( |Yobs, W) In this example, we are interested in the sample average effect of the treatment:

fs

=

 (Y(0), Y(1))

=

1 N

N

(Yi(1) - Yi(0)) .

i=1

Using (8.6) we can write this in terms of the missing and observed outcomes as

fs

=

 (Ymis, Yobs, W)

=

1 N

N

(1

-

2

·

Wi)

·

Yimis

+

1 N

N

(2 · Wi - 1) · Yiobs.

i=1

i=1

Conditional on (Yobs, W) the only stochastic components of this expression are the Yimis. Because fs is a linear function of Y1mis, . . . , Y6mis, the fact that the Yimis are jointly normally distributed implies that fs has a normal distribution. We use the results from Step
3 to derive the first two moments of fs given (Yobs, W). The conditional mean is

E fs Yobs, W

=

1 N

N
(2 · Wi - 1) · Yiobs +
i=1

1 N

N
(1 - 2 · Wi) · E
i=1

Yimis Yobs, W

=

Nt N

·

Y

obs t

-

Nc N

·

Y

obs c

+1 N

N

(1 - 2 · Wi) ·

i=1

Wi ·

Y

obs c

·

Nc

Nc · 10,000 · 10,000 + 100

+ (1 - Wi) ·

Y

obs t

·

Nt

Nt · 10,000 · 10,000 + 64

=

Y

obs t

·

Nt

· 10,000 + 64 · Nt/N Nt · 10,000 + 64

-

Y

obs c

·

Nc

· 10,000 + 100 · Nc/N . Nc · 10,000 + 100

Next, consider the conditional variance of fs. Because fs is a linear function of the Yimis, the variance is a linear combination of the variances and covariances:

V

fs Yobs, W

=

1 N2

N
V
i=1

1 - 2 · Wi · Yimis Yobs, W

+

1 N2

N

C

i=1 i =i

1 - 2 · Wi · Yimis, 1 - 2 · Wi · Yimis Yobs, W

=

1 N2

Nt ·

100

+

Nc/100

1 + 1/10,000

+ Nc ·

64

+

Nt/64

1 + 1/10,000

+

1 N2

Nt

·

(Nt

-

1)

·

Nc/100

1 + 1/10,000

+

Nc

·

(Nc

-

1)

·

Nt/64

1 + 1/10,000

.

Substituting in the values for the six-unit data set (N = 6, Nc = Nt = 3), we find

fs|Yobs, W  N 8.7, 5.22 .

(8.32)

8.5 Simulation Methods in the Model-Based Approach

163

Thus, combining our assumptions on the joint distribution of (Y(0), Y(1)) given (c, t) and on the prior distribution of (c, t) with the observed data, we find that the posterior distribution of fs given (Yobs, W) is normal, with the posterior mean of the average treatment effect equal to 8.7, and the posterior standard deviation equal to 5.2. Note that our point estimate of fs is very similar to the value we found previously in the two imputation methods in Section 8.3, namely 8.7. In contrast, the standard error
estimated under the second method (the first method essentially gave a standard error
of zero for the estimate) was only 2.8, much smaller than what we find using the fully
model-based approach. This difference is driven by the fact that with the second method we still assumed we knew the model of Ymis given Yobs with certainty, whereas here we allow uncertainty via the estimation of the parameter  = (c, t).

8.5 SIMULATION METHODS IN THE MODEL-BASED APPROACH
So far in this chapter, our calculations have all been analytical; we have derived the exact distribution of the average treatment effect, given the observed data, and given our choice of prior distribution. Unfortunately, in many settings this approach is infeasible, or at least impractical. Depending on the model for the joint distribution of the potential outcomes, the calculations required to derive the conditional distribution of the estimand  given the observed data ­ in particular, the integration across the parameter space ­ can be quite complicated. We therefore generally rely on simulation methods for evaluating the distribution of the estimand of interest. These simulation methods intuitively link the full model-based approach back to the starting point of the chapter: the explicit imputation of the missing components of the causal estimand, that is, the missing potential outcomes.
To use simulation methods, the two key elements are the conditional distribution of the missing data given the observed data and parameters, f (Ymis|Yobs, W, c, t), derived in Step 1, and the posterior distribution of the parameters given the observed data, p(c, t|Yobs, W), derived in Step 2. Using these distributions, we can distributionally impute the missing data ­ that is, we repeatedly (or multiply) impute the missing potential outcomes. In this section, we continue with the example with six individuals to illustrate these ideas. See Appendix B for a description of the simulation method with a more general example.
First, recall the posterior distribution of the parameters given data for the six units in our illustrative sample, derived in Step 2:

c t

Yobs, W  N

4.1 5.82 0

, 12.8

0

4.62

.

We draw a pair of random values (c, t) from this distribution. Suppose the first pair of draws is ((c1), t(1)) = (1.63, 5.09). Given this draw for the parameters (c, t), we can substitute these values into the conditional distribution of Ymis, that is, f (Ymis|Yobs, W, c, t) to impute, independently, all of the missing potential outcomes.

164

Model-Based Inference for Completely Randomized Experiments

Table 8.5. The Average Treatment Effect Using Full Model-Based Imputations for the NSW Program Data

Unit

Potential Outcomes

Treatment

Yi(0)

Yi(1)

Wi

Panel A: First Parameter Draw (c(1), t(1)) = (1. 63, 5. 09)

1

0

(6.1)

0

2

(13.5)

9.9

1

3

12.4

(7.4)

0

4

(13.5)

3.6

1

5

0

(-4.1)

0

6

(1.3)

24.9

1

Average f(s1)

6.8

8.0

1.2

Panel B: Second Parameter Draw ((c2), t(2)) = (6. 01, 13. 58)

1

0

(12.1)

0

2

(27.8)

9.9

1

3

12.4

(19.4)

0

4

(4.6)

3.6

1

5

0

(8.9)

0

6

(7.1)

24.9

1

Average f(s2)

8.7

13.1

4.5

Observed Outcome Yiobs
0 9.9 12.4 3.6 0 24.9
0 9.9 12.4 3.6 0 24.9

Specifically, we draw Ymis from the normal distribution

Y1mis

  



5. 09 64 0 0 0 0 0

YYYY2435mmmmiiiissss

Yobs, W, 



N

1515....

06603939

,



0 0 0 0

100 0 0 0 0 64 0 0 0 0 100 0 0 0 0 64

0 0 0 0

 ,

Y6mis

1. 63 0 0 0 0 0 100

obtained by substituting 1.63 for c and 5.09 for t in Equation (8.24). Thus, the missing Yi(0) values for units 2, 4, and 6 will be drawn independently from a N (1. 63, 102)
distribution, and the missing Yi(1) values for units 1, 3, and 5 independently from a N (5. 09, 82) distribution. Panel A of Table 8.5 shows the data with the missing potential
outcomes drawn from this posterior predictive distribution. Substituting the observed
and imputed missing potential outcomes into Equation (8.8) leads to an estimate for the average treatment effect of ^ (1) = 1. 2. Notice that in this step, we impute a complete
set of missing data without redrawing the unknown parameters. This is important. The alternative, drawing say Y1mis given one draw from the parameter vector and drawing Y2mis from a second draw from the parameter vector, would, in general, be incorrect.
Next we draw a new pair of parameter values. Suppose this time we draw ((c2), t(2)) = (6. 01, 13. 58). Given this draw, we again impute the full vector of

8.6 Dependence between Potential Outcomes

165

missing outcomes, Ymis. The missing Yi(0) values are now drawn independently from a N (6.01, 100) distribution, and the missing Yi(1) values independently from a N (13.58, 64) distribution. Panel B of Table 8.5 shows the data with the missing outcomes
drawn from these distributions, leading to a second estimate for the average treatment effect of ^ (2) = 4.5. To derive the full distribution for our estimate of the average treat-
ment effect, we repeat this a number of times and calculate the average and standard deviation of the imputed estimators ^ (1), ^ (2), . . . . Our result, based on NR = 10,000 draws of the pair  = (c, t) , is an average, over these 10,000 draws for ^fs(r), for r = 1, . . . , NR, of 8.6 and a standard deviation of 5.3:

1 NR

NR r=1

f(sr)

=



=

8.6,

1 NR NR - 1 r=1

f(sr) - 

2 = 5.32.

Notice that the simulated mean and standard deviation are quite close to the analytically calculated mean and variance given in Equation (8.32). Hence we lose little precision by using simulation in place of the usually more complicated analytical calculation.

8.6 DEPENDENCE BETWEEN POTENTIAL OUTCOMES

As discussed in Section 8.4, usually the most critical decision in the model-based approach is the specification of the model of the joint distribution of the unit-level potential outcomes, f (Yi(0), Yi(1)| ). In the six-unit example in Section 8.4, we used a joint normal distribution, where we assumed a known covariance matrix. For simplicity, we assumed no dependence between the two potential outcomes ­ the cross-terms of the covariance matrix were equal to zero. Typically it is more appropriate to choose a model in which the elements of the covariance matrix are also unknown. In this case, one parameter that requires special consideration is the correlation coefficient  or, more generally, the parameters reflecting the degree of dependence between the two potential outcomes.
Suppose, in contrast to the model we used in Section 8.4, we assume a joint distribution for the potential outcomes with unknown covariance matrix, including an unknown correlation coefficient :

f (Yi(0), Yi(1)| )  N

c t

,

c2 ct

ct t2

,

where now the parameter vector is  = (c, t, c2, t2, ) . In this setting, the conditional distribution of Yiobs given (W,  ) is

f (Yiobs|W,  ) =

1 2 · ((1 - Wi) · c2 + Wi · t2)

× exp - 1 2

Yiobs - (1 - Wi) · c - Wi · t 2 (1 - Wi) · c2 + Wi · t2

,

(8.33)

166

Model-Based Inference for Completely Randomized Experiments

and the corresponding likelihood function is

6
L(c, t, c2, t2, |Yobs, W) =
i=1

1 2 · ((1 - Wi) · c2 + Wi · t2)

× exp - 1 2

1 (1 - Wi) · c2 + Wi · t2

Yiobs - (1 - Wi) · c - Wi · t

2

.

Note that the likelihood function does not depend on the correlation coefficient ; it is,
in fact, completely unchanged from the corresponding expression in Section 8.4, other than that it replaces 100 with c2 and 64 with t2. In other words, the data contain no information about the correlation between the potential outcomes.
Suppose, in addition, that the prior distribution of the parameters  can be factored into
a function of the correlation coefficient times a function of the remaining parameters:

p( ) = p() · p(c, t, c2, t2).
In combination with the fact that the likelihood function is free of , this implies that the posterior distribution of the correlation coefficient will be identical to its prior distribution. Considering similar discussions in earlier chapters ­ for example, the difficulty in estimating the variance of the unit-level treatment effects in Chapter 6 ­ this result should not be surprising. We never simultaneously observe both potential outcomes for any unit, and thus we have no empirical information on their dependence.
To understand the implications of this change in assumptions, let us estimate the average treatment effect under the same model, except now assuming a correlation coefficient equal to 1. With the variances still known, t2 = 100 and t2 = 64, the parameter vector is again  = (c, t). The distribution of the potential outcomes is now

Yi(0)   N Yi(1)

c t

,

100 80

80 64

.

Using the same steps as in Section 8.4, we can derive the joint distribution of (Ymis, Yobs) given (W, c, t):

Yimis Yiobs

W, c, t  N

Wi · c + (1 - Wi) · t (1 - Wi) · c + Wi · t

,

Wi · 100 + (1 - Wi) · 64

80

80

(1 - Wi) · 100 + Wi · 64

.

This distribution is almost equal to the previously calculated joint distribution for (Ymis, Yobs), seen in Equation (8.21), except that the cross-terms in the covariance matrix
are now also non-zero.

8.6 Dependence between Potential Outcomes

167

Using this joint distribution, we can derive the conditional distribution of Ymis given (Yobs, W, c, t):

Yimis|Yobs, W, c, t 

(8.34)

N

Wi ·

c

+

80 64

·

(Yiobs

-

t)

+ (1 - Wi) ·

t

+

80 100

·

(Yiobs

-

c)

,0

.

This conditional distribution is quite different from the one derived for the case with
 = 0, given in (8.22). Here the conditional variance is zero; because we assume a perfect correlation between Yi(0) and Yi(1), it follows that, given (Yiobs, c, t), we know the exact value of Yimis.
However, our interest is not in this conditional distribution. Rather, we need the distribution of Ymis given (Yobs, W) only, that is, without conditioning on (c, t). To derive this distribution, we need the posterior distribution of (c, t). Here it is key that the
conditional distribution of the observed outcomes, given the assignment W and parameter  , f (Yobs|W,  ), is unaffected by our assumption on  ­ compare Equation (8.33), with t2 = 102 and t2 = 82, to Equation (8.25). Thus the likelihood function remains the same, and this is in fact true irrespective of the value of the correlation coefficient. If
we assume the same prior distribution for , the posterior distributions for (c, t) will
be the same as that derived before and given in (8.26). Because Yimis is a linear function of (c, t), normality of (c, t) implies normality
of Yimis. The mean and variance of Yimis given (Yobs, W) are

E Yimis Yobs, W = Wi ·

Y

obs c

·

Nc

Nc · 10,000 · 10,000 + 100

+

80 64

·

Yiobs

-

Y

obs t

·

Nt

Nt · 10,000 · 10,000 + 64

+ (1 - Wi) ·

Y

obs t

·

Nt

Nt · 10,000 · 10,000 + 64

+

80 100

·

Yiobs

-

Y

obs c

·

Nc

Nc · 10,000 · 10,000 + 100

,

V Yimis Yobs, W = Wi ·

V(c) +

80 64

2
· V(t)

+ (1 - Wi) ·

V(t) +

80 100

2
· V(c)

= Wi ·

1

+

Nc/100 + 1/10,000

80

2
·

1

64 Nt/64 + 1/10,000

+ (1 - Wi) ·

Nt/64

1 + 1/10,000

+

80 100

2

·

Nc/100

1 + 1/10,000

.

168

Model-Based Inference for Completely Randomized Experiments

Finally, the covariance between Yimis and Yimis, for i = i , is

C Yimis, Yimis Yobs, W = Wi · Wi

1

80 2

1

· Nc/100 + 1/10,000 + 64 · Nt/64 + 1/10,000

- Wi · (1 - Wi ) ·

80 ·

1

+ 80 ·

1

100 Nc/100 + 1/10,000 64 Nt/64 + 1/10,000

80

1

80

1

- (1 - Wi) · Wi · 100 · Nc/100 + 1/10,000 + 64 · Nt/64 + 1/10,000

+ (1 - Wi) · (1 - Wi ) ·

1

+

Nt/64 + 1/10,000

80 100

2
·

1

Nc/100 + 1/10,000

.

Again, our ultimate interest is not in this conditional distribution, but in the conditional distribution of the estimand given (Yobs, W). Using the average treatment effect as our
estimand, we have

fs

=

1 N

N i=1

(2 · Wi - 1) ·

Yiobs - Yimis

=1 N

N

(2

·

Wi

-

1)

·

Yiobs

-

1 N

N

(2 · Wi - 1) · Yimis.

i=1

i=1

Thus fs|Yobs, W has a Gaussian (normal) distribution with mean

E

fs Yobs, W

=

1 N

N i=1

(2 ·

Wi

-

1)

·

Yiobs

+

1 N

N i=1

(1

-

2

· Wi)

·

E

Yimis Yobs, W

=

Y

obs t

·

Nt

· 1000 - 16 · Nt/N Nt · 1000 + 64

-

Y

obs c

·

Nc

· 1000 + 20 Nc · 1000 +

· Nc/N 100

.

and variance

V

fs Yobs, W

1N

=

N2

V
i=1

Yimis Yobs, W

1N + N2 i=1 i =i C

Yimis, Yimis Yobs, W

=

Nt N2

·

Nc/100

1 + 1/10,000

+

80 64

2

·

Nt/64

1 + 1/10,000

+

Nc N2

·

1

+

Nt/64 + 1/10,000

80

2
·

1

100 Nc/100 + 1/10,000

+

Nt

·

(Nt - N2

1)

·

1 Nc/100 + 1/10,000 +

80 2

1

64 · Nt/64 + 1/10,000

8.7 Model-Based Imputation with Covariates

169

-

2

·

Nc · N2

Nt

·

80 ·

1

+ 80 ·

1

100 Nc/100 + 1/10,000 64 Nt/64 + 1/10,000

+

Nc

·

(Nc N2

-

1)

·

1 Nt/64 + 1/10,000 +

80 2

1

100 · Nc/100 + 1/10,000

.

Substituting the values for the six-unit illustrative data set, we find

fs|Yobs, W  N 8.7, 7.72 .

Thus, using the same model in Section 8.4, with the sole modification of assuming a correlation coefficient fixed at one rather than zero, leads to an estimated average treatment effect with approximately the same mean, 8.7, but a standard deviation now equal to 7.7, somewhat larger than the standard deviation of 5.2 calculated assuming independent potential outcomes.
The main point to take from this section is that the correlation coefficient between the two potential outcomes is somewhat different from other parameters of the model because the data generally do not contain empirical information about it (more generally, about the parameters governing the conditional association between Y(0) and Y(1) given X). This leaves us with the question of how they should be modeled. Sometimes we choose to be "conservative" about this dependence and therefore assume the worst case. In terms of the posterior variance, the worst case is often the situation of perfect correlation between the two potential outcomes. Note that this mirrors our approach in Chapter 6 in the discussion of Neyman's repeated sampling approach. On the other hand, researchers often wish to avoid contamination of the imputation of the potential outcomes under the active treatment by imputed values of the potential outcomes under the control treatment, and vice versa, thus choosing to model the two potential outcome distributions as conditionally independent in an approach that is conservative in a different sense.

8.7 MODEL-BASED IMPUTATION WITH COVARIATES
The presence of covariates does not fundamentally change the underlying method for imputing the missing potential outcomes in the model-based approach. In this sense, the model-based imputation approach has a substantial advantage over Neyman's approach that was discussed in the previous chapter. In the current setting, the presence of covariates in principle allows for improved imputations of the missing outcomes because the covariates provide information to help predict the missing potential outcomes.
Given covariates, the first step now consists of specifying a model for the joint distribution of the two potential outcomes conditional on these covariates, f (Y(0), Y(1)|X, ). Suppose, by appealing to de Finetti's theorem, that the triples (Yi(0), Yi(1), Xi) are modeled as independent and identically distributed conditional on a vector-valued parameter . We can always factor this distribution into two components, the joint distribution of the potential outcomes given the covariates and the marginal distribution of

170

Model-Based Inference for Completely Randomized Experiments

the covariates:

f (Yi(0), Yi(1), X|Y|X, X) = f (Yi(0), Yi(1)|X, Y|X) · f (X|X),

(8.35)

where Y|X and X are functions of  governing the respective distributions. Often we assume that the parameters entering the marginal distribution of the covariates are dis-
tinct from those entering the conditional distribution of the potential outcomes given the covariates, and specify the prior distribution so that it factors into a function of Y|X and a function of X:

p(Y|X, X) = p(Y|X) · p(X).

(8.36)

Although this assumption is often made in practice, it is not always innocuous. For example, when the covariates include a time series of previous measurements (prior to the intervention of the active treatment) of the same quantity as measured by the outcome, the parameters governing the distribution of the covariates could have important information about the parameters governing the outcome distribution under the control treatment. However, if (8.36) holds, the analysis simplifies. In that case we need to model only the conditional distribution of the potential outcomes given the covariates, f (Yi(0), Yi(1)|Xi, ). (We drop the indexing of  by Y|X because there is only one parameter vector left.) The remaining steps are essentially unchanged. We derive the conditional distribution of the causal estimand given the observed data and parameters, now also conditional on the covariates. We also derive the posterior distribution of the parameters given the observed potential outcomes and covariates.
Let us consider an example with a scalar covariate. The models that we have studied so far have had bivariate normal distributions:

Yi(0)  N Yi(1)

c t

,

c2 0

0 t2

.

(8.37)

One way to extend the previous model to allow for covariates is to instead model the conditional distribution of the potential outcomes conditional on the covariates as

Yi(0) Yi(1)

Xi,   N

Xic Xit

,

c2 0

0 t2

,

(8.38)

where we include the intercept in the vector of covariates. Thus  now consists of the four components c, t, c2, and t2, where c and t are vectors. An alternative is to assume that the slope coefficients (the elements of c and t other than those corresponding to the intercept) are the same for both potential outcomes, although in many situations such
restrictions are not supported by the data. Notice that, in model (8.38), the covariates
affect only the location of the distribution, not its dispersion. This modeling assumption
too can be relaxed.
Given model (8.38), the remainder of the steps in the model-based approach with
covariates are very similar to those in the situation without covariates. We can derive
the distribution of the average treatment effect given observed variables and parameters  = (c, t, c2, t2). For unit i with covariate value Xi, the missing potential outcome

8.8 Super-Population Average Treatment Effects

171

has, given the parameter values, the distribution
Yimis|Yobs, W, X,   N Wi · Xic + (1 - Wi) · Xit, Wi · t2 + (1 - Wi) · t2 .
We combine this distribution with the posterior distribution of  given (Y, W, X) to obtain the joint posterior distribution of  and , which we then use to get the marginal posterior distribution of . If the prior distribution for  factors into a function of (c, c, c2) and a function of (t, t, t2), then we can factor the posterior distribution into a function of (c, c, t2) and a function of (t, t, t2), with the former depending only on the units with Wi = 0, and the latter depending only on units with Wi = 1.
In situations with covariates, analytic solutions are difficult to obtain. In practice, we use simulation methods to obtain draws from the posterior distribution of the causal estimand.

8.8 SUPER-POPULATION AVERAGE TREATMENT EFFECTS

In the discussion so far, we have focused on the average treatment effect for the sample

at hand, fs =

N i=1

(Yi(1)

-

Yi(0))/N

.

Suppose

instead

that

we

view

these

observations

as a random sample from an infinite super-population, and that our interest lies in the

average treatment effect for that super-population:

sp = Esp[Yi(1) - Yi(0)].

This discussion mirrors that in Chapter 6 where we used Neyman's approach with a super-population. As in that setting, we can modify the model-based approach discussed in Sections 8.1­8.6 to estimate and conduct inference for this different estimand.
Given a fully specified model for the potential outcomes, the new estimand of interest, sp, can sometimes be expressed solely as a function of the parameters. For example, in the normal linear model we can write:

sp =  ( ) = Esp [ Yi(1) - Yi(0)|  ] = t - c.

In general, the population average treatment effect can be defined through the model for the joint distribution of the potential outcomes as

 () =

(y(1) - y(0)) f (y(1), y(0)| ) dy(1) dy(0).

If there are covariates, the estimand may depend on both the parameters and the distribution of covariates, for example,

sp = Esp [ ( , X)] ,

where  ( , X) = Esp [ Yi(1) - Yi(0)| X,  ] .

The representation in the linear model makes inference for the population average treat-
ment effect conceptually straightforward. As before, we draw randomly from the derived posterior distribution for . Then, instead of using this draw  (1) to draw from the conditional distribution of Ymis, that is, f (Ymis|Yobs, W,  (1)), we simply use the draw to

172

Model-Based Inference for Completely Randomized Experiments

calculate the average treatment effect directly:  (1) =  ( (1)). Using NR draws from the posterior distribution of  (given the observed data) gives us {^s(pr), r = 1, . . . , NR}. The average and sample variance of these NR draws give us estimates of the posterior mean and variance of the population average treatment effect.
Using the same six observations, let us see how the results for the super-population average treatment effect differ from those for the sample average treatment effect. As derived in Section 8.4.3, the joint posterior distribution for  = (c, t) is equal to

c t

Yobs, W  N

4.1 12.8

,

33.2 0

0 21.3

.

The posterior distribution for sp = t - c is therefore

t - c|Yobs, W  N (12.8 - 4.1), (33.2 + 21.3 + 2 · 0)  N 8.7, 7.42 .

Hence the posterior mean of sp is 8.7, identical to the posterior mean of the sample average treatment effect fs. The posterior standard deviation for the population aver-

age treatment effect is now 7.4. For comparison, recall that when we calculated the

sample average treatment effect assuming independence across the two potential out-

comes (Section 8.4.3), the standard deviation was equal to 5.2; when we assumed perfect

correlation (Section 8.6), it was instead 7.7. Thus the posterior standard deviation is

substantially different from that derived for the sample average treatment effect under

independence of the potential outcomes but close to that for the sample average treat-

ment effect under perfect correlation. This result should not be surprising. Compared

to the first task, estimating the population average treatment effect is more demanding.

Even if we could observe all elements of the vectors of potential outcomes Y(0) and Y(1)

in our experiment ­ allowing us to calculate the finite-sample average treatment effect,

fs =

N i=1

(Yi(1)

-

Yi(0))/N

with

certainty

­

we

would

still

be

uncertain

about

the

average treatment effect in the super-population from which our sample was taken. This

result mirrors the discussion in Chapter 6, where we showed that using the worst-case

scenario assumption of perfect correlation not only gave a "conservative" estimate of the

sampling variance in a finite-population setting but also provided an unbiased estimate

of the sampling variance of the point estimate in the super-population.

It is also important to note that when we are interested in the super-population average

treatment effect, the value of the correlation coefficient  becomes unimportant: the

estimand sp = t - c does not depend on  at all. Because the likelihood function of the observed data does not depend on  either, the posterior distribution for  will not

depend on the prior distribution for , when the prior distribution of  has  and (c, t) marginally independent.

8.9 A FREQUENTIST PERSPECTIVE
In this section we consider the frequentist perspective for calculating average treatment effects via the model-based approach. So far this discussion has taken an exclusively Bayesian perspective because this is particularly convenient for the problem at hand; it

8.9 A Frequentist Perspective

173

treats the uncertainty in the missing potential outcomes in the same way that it treats the
uncertainty in the unknown parameters. In contrast, from the standard frequentist per-
spective, the unknown parameters are taken as fixed quantities, always to be conditioned
on, whereas the potential outcomes, missing and observed, are considered unobserved
and observed random variables given parameters, respectively. Nevertheless, as in many
other instances, inferences based on Bayesian and frequentist perspectives are often
close in substantive terms, with Bayesian posterior intervals often having good repeated
sampling coverage rates, and it is instructive to understand both perspectives. Here we
therefore outline the frequentist perspective in greater detail, focusing on the case where the estimand of interest is the population average treatment effect, sp( ).
Suppose, as before, we specify the joint distributions of Yi(0) and Yi(1) in terms of a parameter vector . As we saw in Section 8.8, the average treatment effect sp is the difference in the two expected values, sp = E[Yi(1) - Yi(0)| ]. This expectation is a function of the parameters, sp( ).
Consider first the situation without covariates, where the joint distribution of the two potential outcomes is bivariate normal with means c and t, with both variances equal to  2, and the correlation coefficient equal to zero. In this case the function sp( ) is simply the difference: sp = t - c. In fact, given that we are interested in the average treatment effect, we can reparameterize  as ~ = (c, sp,  2), where sp = t - c. The estimand of interest now equals one of the elements of our parameter vector, and the inferential problem is now simply one of estimating ~ and its associated precision.
Taking this approach, we can make a direct connection to linear regression. The
conditional distribution of the observed potential outcomes given the assignment and
parameter vectors is now independent and identically distributed as

Yiobs|W, ~  N (c + Wi · sp,  2).

Hence we can simply estimate the population average treatment effect, sp, by ordinary least squares (OLS), with the OLS standard errors providing the appropriate measure of uncertainty for ^sp.
Although the preceding result seems appealing, it is somewhat misleading in its simplicity. Often, statistical models that are convenient for modeling the joint distribution of the potential outcomes cannot be parameterized easily in terms of the average treatment effect. In that case, sp will generally be a more complex function of the parameter vector. Nevertheless, in general we can still obtain maximum likelihood estimates of , and thus of sp( ), as well as estimates of the large sample precision of sp( ).
To see how this works, in a slight modification of the linear model, suppose, for example, that the model is specified on the logarithm of the potential outcomes:

ln (Yi(0))   N ln (Yi(1))

c t

,

c2 0

0 t2

.

The population average treatment effect is now equal to

sp =  ( ) = exp

t

+

1 2

·

t2

- exp

c

+

1 2

·

c2

.

(8.39)

174

Model-Based Inference for Completely Randomized Experiments

Using this model to estimate sp, we would first obtain maximum likelihood estimates of the parameters,  = (c, t, c2, t2). Next we would substitute these values into the transformation sp( · ) to obtain point estimates ^sp = g(^ ), where g( · ) is defined by (8.39). The potentially more complicated step is the calculation of the asymptotic precision of our estimator. This calculation requires, for example, that we first calculate the full large-sample sampling covariance matrix for the parameter vector  (e.g., using the Fisher information matrix), followed by the application of the delta method (i.e., Taylor series approximations) to derive the asymptotic sampling variance for ^sp.
In this example, the frequentist approach has been only slightly more complicated than in the simple linear model. Often when there are covariates, however, these transformations of the original parameters become quite complex. The temptation is thus to choose models for the joint distribution f (Y(0), Y(1)|X, ) that make this transformation as simple as possible, as in the preceding linear examples. We stress, however, that the role of the statistical model is solely to provide a good description of the joint distribution of the potential outcomes. This is conceptually different from being parameterized conveniently in terms of the estimand of interest.
The possible advantage of the frequentist approach is that it avoids the need to specify the prior distribution p() for the parameters governing the joint distribution of the two potential outcomes. However, this does not come without cost. Nearly always one has to rely on large sample approximations to justify the derived frequentist confidence intervals. But in large samples, by the Bernstein­Von Mises Theorem (e.g., Van Der Vaart, 1998), the practical implications of the choice of prior distribution is limited, and the alleged benefits of the frequentist approach vanish.

8.10 MODEL-BASED ESTIMATES OF THE EFFECT OF THE NSW PROGRAM
To illustrate the methods discussed in this chapter, we return to the full data set for the National Supported Work (NSW) program introduced in Section 8.2. We focus on a couple of aspects of the modeling approach and, in particular, the sensitivity to the choice for the joint distribution of the potential outcomes. We will not discuss in detail the choice of prior distribution for the Bayesian approach. For the simple models we use here, standard diffuse prior distributions are available. They perform well and the results are not sensitive to modest deviations from them.
For each model, we report in Table 8.6 the posterior mean and posterior standard deviation for the average effect fs, and the treatment minus control differences in quantiles by treatment status for the 0.25, 0.50, and 0.75 quantiles, quant,0.25, quant,0.50, and quant,0.75. To be precise for, say the 0.25 quantile, we report the difference between the 0.25 quantile of the N values of Yi(1), some observed and some imputed, and the 0.25 quantile of the N values of Yi(0), some observed and some imputed. This generally differs from the 0.25 quantile of the N values of the unit-level treatment effects Yi(1)-Yi(0). The latter quantile is more difficult to estimate, because results for such an estimand are sensitive to choices for the prior distribution of the dependence structure between the two potential outcomes.

8.10 Model-Based Estimates of the Effect of the NSW Program

175

Table 8.6. Posterior Means and Standard Deviations for Treatment Effects under Four Models for NSW Program Data

Effect on Quantiles

Mean

Variance Potential Two- Mean Effect 0.25 quant 0.50 quant 0.75 quant

Covariate Treatment Outcome Part

Dependent Specific Independent Model Mean (S.D.) Mean (S.D.) Mean (S.D.) Mean (S.D.)

No

No

No

No 1.79 (0.63) 1.79 (0.63) 1.79 (0.63) 1.79 (0.63)

No

Yes

Yes

No 1.78 (0.49) 0.63 (0.35) 1.63 (0.55) 3.07 (0.64)

Yes

Yes

Yes

No 1.57 (0.50) 0.42 (0.34) 1.40 (0.55) 2.89 (0.63)

Yes

Yes

Yes

Yes 1.57 (0.74) 0.25 (0.30) 1.03 (0.53) 1.69 (0.72)

To put the model-based results in perspective, we first estimated the average effect using the simple difference in means, using Neyman's approach. The average effect of the training program on annual earnings in thousands of dollars was estimated to be ^fs = 1.79, with an estimated standard error of 0.63 based on V^ neyman. Adjusting for all ten covariates from Table 8.1 using the linear regression methods from the previous chapter, with the regression including an intercept, an indicator for the treatment, and the ten covariates, changes the estimate to 1.67 (with an estimated error equal to 0.64).
We consider four specifications for the joint distribution of the potential outcomes given covariates. The first is a joint normal distribution with the potential outcomes perfectly correlated, free from dependence on the covariates, and with identical variances in the two treatment arms:

Yi(0) Yi(1)

Xi,   N

c t

,

2 2

2 2

.

(8.40)

To implement this model, we need to make one more decision, namely the prior distribution for the unknown parameter  = (c, t,  2). We take the parameters to be independent a priori. The prior distributions for the two mean parameters, c and t, are normal with zero means and variances equal to 1002, the standard deviations of 100
being large relative to the scale of the data (the earnings variables are measured in thousands of dollars and range from 0 to 60.3). The prior distribution for  2 is inverse gamma with parameters 1 and 0.01, respectively. The posterior mean and standard deviation for
the treatment effects of interest are reported in the first row of Table 8.6. Note that, for
this specification, the effect of the treatment is constant, and so the estimates of the quantile effects are all identical to that for the mean. The posterior mean of fs is equal to 1.80, with a posterior standard deviation of 0.63.
For the results reported in the second row of Table 8.6, again we assume prior inde-
pendence between the potential outcomes and allow for treatment-control differences in
the conditional variances:

Yi(0) Yi(1)

Xi,   N

c t

,

c2 0

0 t2

,

(8.41)

176

Model-Based Inference for Completely Randomized Experiments

The prior distributions for the two mean parameters, c and t, are, as before, normal with zero means and variances equal to 1002. The prior distributions for c2 and t2 are inverse gamma with parameters 1 and 0. 01 respectively. The posterior mean for the average effect, fs, is now 1.78, very similar to the 1.80 from before. However, the posterior standard deviation for the average effect fs is substantially lower, 0.44. The posterior means for the quantile effects are fairly different from those reported in the first
row of the table, ranging from 1.38 for the 0.25 quantile to 2.19 for the 0.75 quantile.
In the third row of Table 8.6, we allow for linear dependence of the conditional means
of the potential outcomes in nine covariates:

Yi(0) Yi(1)

Xi,   N

Xic Xit

,

c2 0

0 t2

.

(8.42)

For the parameters c and t, we assume prior independence from the other parameters, as well as independence from each other. The prior distributions are specified to be normal with zero means and variance equal to 1002. The prior distributions for c2 and t2 are the same as before. The posterior mean for the average effect is now 1.60 with a posterior standard deviation equal to 0.47. The posterior means for the quantile effects range from 1.03 for the 0.25 quantile to 2.15 for the 0.75 quantile.
All three of these models implicitly assume continuity of the potential outcome distributions. These models are therefore implausible as descriptions of the distribution of the potential outcomes, considering the high proportion of zeros in the observed outcomes (equal to 31%). The fourth model is a more serious attempt to fit this conditional distribution. We model two parts of the conditional distribution. First, the probability of a positive value for Yi(0) is

Pr(Yi(0)

>

0|Xi, Wi,  )

=

1

exp (Xic) + exp (Xic)

,

(8.43)

and similarly for Yi(1):

Pr(Yi(1)

>

0|Xi, Wi,  )

=

1

exp (Xit) + exp (Xit)

.

Second, conditional on a positive outcome, the logarithm of the potential outcome is assumed to have a normal distribution:

ln (Yi(0)) |Yi(0) > 0, Xi, Wi,   N Xic, c2 ,

(8.44)

and

ln (Yi(1)) |Yi(1) > 0, Xi, Wi,   N Xit, t2 .

The simulation-based results for this model are displayed in the fourth row of Table 8.6. The posterior mean for the average effect is now 1.57, with a posterior standard deviation of 0.75. The posterior mean for the 0.25 quantile is much lower in this model, equal to 0.26. These posterior distributions, especially the posterior mean for the 0.25

Notes

177

Table 8.7. Posterior Distributions for Parameters for Normal/Logistic Two-Part Model ­ NSW Program Data

Covariate
intercept age education married nodegree black earn'74 earn'74=0 earn'75 earn'75=0
ln (c) ln (t)

c

Mean (S.D.)

1.38 0.02 0.01 -0.23 -0.01 -0.44 -0.01 0.19 0.02 -0.05

(0.84) (0.01) (0.06) (0.25) (0.27) (0.20) (0.02) (0.31) (0.04) (0.29)

0.02 (0.06) 0.03 (0.06)

t - c

Mean (S.D.)

0.40 -0.02
0.01 0.35 -0.24 0.37 0.01 -0.58 0.01 0.17

(1.26) (0.02) (0.09) (0.35) (0.39) (0.30) (0.03) (0.46) (0.05) (0.40)

0

Mean (S.D.)

2.54 -0.01 -0.05 -0.18 -0.28 -1.09
0.01 1.00 0.00 -0.61

(1.49) (0.02) (0.11) (0.40) (0.47) (0.44) (0.04) (0.56) (0.08) (0.46)

1 - 0

Mean (S.D.)

0.68 0.02 0.02 0.91 -0.26 -0.77 -0.02 -3.06 0.20 2.13

(2.49) (0.03) (0.17) (0.73) (0.74) (0.97) (0.08) (1.12) (0.17) (1.05)

quantile, are much more plausible given the substantial fraction of individuals who are not working in any period in the study.
In Table 8.7 we report posterior means and standard deviations for all parameter estimates in the last model. These estimates shed some light on the amount of heterogeneity in the treatment effects. We report the estimates for the parameters of the control outcomes, (c and c), and for the differences in the parameters for the treated outcome and the control outcomes, t - c, and t - c.

8.11 CONCLUSION
In this chapter we outline a model-based imputation approach to estimation of and inference for causal effects. The causal effects of interest are viewed as functions of observed and missing potential outcomes. The missing potential outcomes are imputed through a statistical model for the joint distribution of the potential outcomes and a model for the assignment mechanism, which is known in the randomized experiment setting. The model for the potential outcomes is, in principle, informed by subject-matter knowledge, although in the randomized experiment setting, results tend to be relatively insensitive to modest changes in its specification. The context in this chapter is that of a completely randomized experiment, but, in principle, the general framework easily extends naturally to non-experimental settings.

NOTES
The data used in this chapter to illustrate the concepts introduced were first analyzed by Lalonde (1986) and used subsequently by many others, including Heckman and Hotz (1989), Dehejia and Wahba (1999), Smith and Todd (2001), Abadie and Imbens (2009),

178

Model-Based Inference for Completely Randomized Experiments

as well as others. The Lalonde study has been very influential for its conclusion that non-experimental evaluations were unable to recover experimental estimates. The data are available on Rajeev Dehejia's website, http://www.nber.org/~ rdehejia/nswdata.html.
The Bayesian approach to the analysis of randomized experiments presented here was first discussed in detail in Rubin (1978). For Bayesian analyses of more complicated (non-ignorable treatment assignment) models, see Imbens and Rubin (1997b), Hirano, Imbens, Rubin, and Zhou (2000), and Zhang, Rubin, and Mealli (2009).
De Finetti's Theorem originates in de Finetti (1964, 1992). See also Hewitt and Savage (1955), Feller (1965, pp. 225­226), Rubin (1978), and for extensions to the finite N case see Diaconis (1976).
For general discussions of Bayesian methods see Box and Tiao (1973), Gelman, Carlin, Stern, and Rubin (1995), Hartigan (1983), Lancaster (2004), and Robert (1994). To implement the Bayesian analysis discussed in this chapter, it is useful to use modern numerical methods, in particular Markov-Chain-Monte-Carlo methods. For textbook discussions, in addition to the aforementioned texts on Bayesian methods, see Tanner (1996), Robert and Casella (2004), and Brooks, Gelman, Jones, and Meng (2011).

APPENDIX A POSTERIOR DISTRIBUTIONS FOR NORMAL MODELS
In this appendix, we briefly review the basic results in Bayesian inference used in the current chapter. For a fuller discussion of general Bayesian methods, see Gelman, Carlin, Stern, and Rubin (1995) and Lancaster (2004). For a discussion of the role of Bayesian methods for inference for causal effects, see Rubin (1978, 2004) and Imbens and Rubin (1997).

A.1 Prior Distributions, Likelihood Functions, and Posterior Distributions
A Bayesian formulation has two components. First we specify a "sampling" model (conditional distribution) for the data given unknown parameters. The data are denoted by Z. Often Z is a matrix of dimension N × K, with typical row Zi. The parameter will be denoted by . The parameter lies in the set . The sampling model will be denoted by fZ(Z| ). As a function of  with fixed data Z, it is known as the likelihood function: L( |Z). The second component of a Bayesian formulation is the prior distribution on , denoted by p(), which is a (proper) probability (density) function, integrating to one over the parameter space .
The posterior distribution of  given the observed data Z is then

p(|Z) =

L( |Z) · p() .

 L( |Z) · p( )d

Often we write

p(|Z)  L( |Z) · p(),

because the constant can be recovered using the fact that the posterior distribution integrates to one.

Appendix A Posterior Distributions for Normal Models

179

A.2 The Normal Distribution with Unknown Mean and Known Variance
The first special case is the normal distribution with unknown mean and known variance. Suppose Z is an N-vector with ith component Zi|  N (,  2), with  2 known, and all the Zi independent given . We use a normal prior distribution for , with mean  and variance 2. Then the posterior distribution for  is

Z · N/ 2 + /2

1

p(|Z)  N N/ 2 + 1/2 , N/ 2 + 1/2 ,

where Z =

N i=1

Zi/N

.

A.3 The Normal Distribution with Known Mean and Unknown Variance
Now suppose the distribution of Zi is N (,  2) with  known and  2 unknown. We use a prior distribution for  2 such that, for specified S02 and M, the random variable  -2S02/M has a gamma distribution with parameters M/2 and 1/2 (or, equivalently, a chi-squared distribution with M degrees of freedom). Then the posterior distribution of  2 given Z is such that the distribution of  -2 · (S02 + i (Zi - )2/(M + N) has a gamma distribution with parameters (M + N)/2 and 1/2. Repeatedly sampling  and  2, this leads to a sequence whose draws converge to a draw of (,  2) from its actual posterior
distribution.

A.4 Simulation Methods for the Normal Linear Regression Model
Here we present the details for a simulation-based inference for the parameters of a normal linear regression model:

Yi|,  2  N Xi,  2 ,

(A.1)

with unknown  and  . We use a normal prior distribution for , N (, ), and prior distribution for  2 such that for specified S02 and M,  -2 · S02/M has a Gamma distribution with parameters M/2 and 1/2.
To draw from the posterior distribution of  and  2, we use Markov-Chain-MonteCarlo (MCMC) methods where we draw sequentially from the posterior distribution of  given  2 and from the posterior distribution of  2 given , and iterate. We initialize the chain by using the least squares estimate for  and  2 as the starting value.
The first step is drawing from the posterior distribution of  given  2. This posterior distribution is
p(|Y, X,  2) N  -2X X + -1 -1  -2X Y + -1 ,  -2X X + -1 -1 .

It is straightforward to draw from.

180

Model-Based Inference for Completely Randomized Experiments

The second step is drawing from a posterior distribution of  2 given . This posterior distribution is such that the distribution of

N
 -2 · (Yi - Xi)2 /(N + M),
i=1

has a Gamma distribution with parameters (N + M)/2 and 1/2. Repeatedly drawing  and  2 this way leads to a sequence whose draws converge to draws of (,  2) from its
actual posterior distribution.

A.5 Simulation Methods for the Logistic Regression Model
Here we discuss methods for drawing from the posterior distribution of the parameters in a logistic regression model. The model is

Pr(Yi

=

1|Xi,  )

=

1

exp (Xi ) + exp (Xi

)

.

With a sample of size N the likelihood function is

L( |Y, X) = N exp (Yi · Xi ) . i=1 1 + exp (Xi )

We use a normal prior distribution for  , with mean  and covariance matrix . To
sample from the posterior distribution, we use the Metropolis Hastings algorithm (e.g.,
Gelman, Carlin, Stern, and Rubin, 2000). For the starting value we use the maximum likelihood estimates ^ml for  , although this may not be the best choice for assessing convergence of the chain. We can construct a chain 0, 1, . . . , K, where 0 = ^ml. Given a value k we proceed as follows. We draw a candidate value  from a normal distribution centered at ^ml with covariance matrix 2 · I^ -1, where I^ is the estimated Fisher information matrix. Let N ( |, ) denote the density function for a multivariate normal random variable with mean , covariance matrix , evaluated at  .
Given the candidate value  , we move to this new value or stay at the current value k, with probabilities

Pr(k+1 =  ) = min

L( ) · N ( |, 1,
L(k) · N (k|,

) · N (k|^ml, 2 · I^ -1) ) · N ( |^ml, 2 · I^ -1)

Pr(k+1 = k) = 1 - Pr(k+1 =  ).

As with the previous method in Appendix A.3, the sequence converges to a draw from the correct posterior distribution of  .

Appendix B Analytic Derivations with Known Covariance Matrix

181

APPENDIX B ANALYTIC DERIVATIONS WITH KNOWN COVARIANCE MATRIX

In this appendix we derive the distribution of the average treatment effect for the case where the potential outcomes are jointly normally distributed with known covariance matrix, and the prior distribution for the parameters is also jointly normal. In this case, analytic solutions exist for the distribution of the average treatment effect, conditional on the observed data. These analytic results allow us to compare answers for various special cases, such as when the two potential outcomes are uncorrelated versus answers when they are perfectly correlated, and the finite sample versus super-population average treatment effect.
Assume N exchangeable units, indexed by i = 1, . . . , N. Conditional on the parameter vector , we assume the potential outcomes are normally distributed:

Yi(0) Yi(1)

 i.i.d. N

c t

,

t2 ct

ct t2

.

(B.1)

In this example the covariance matrix parameters t2, t2, and  are assumed known, and  = (c, t) is the vector of unknown parameters. The distribution of the assignment vector W is p(W), known by the assumption of a completely randomized experiment.
Conditional on W and the parameters, the observed potential outcomes are independent
of one another, with distribution

Yiobs|W,   N (Wi · t + (1 - Wi) · c, Wi · t2 + (1 - Wi) · t2).

Thus, the likelihood function is

N
L(c, t|Yobs, W) = p(W) ·
i=1

1 2 · ((1 - Wi) · t2 + Wi · t2)

× exp - 1 2

(1

-

Wi)

·

1 t2

+

Wi

·

t2

(Yi

-

(1

-

Wi)

·

c

-

Wi

·

t )2

(B.2) .

As we saw in Section 8.6, this likelihood is free of the correlation coefficient . Note that, because of the assumed normal distribution of the two potential outcomes,
the average of the observed outcomes per treatment level have sampling distributions

Y

obs c

Y

obs t

 N

c t

,

t2/Nc 0

0 t2/Nt

,

(B.3)

where N1 is the number of treated and N0 is the number of control units. Because (Yocbs, Ytobs, Nc, Nt) is a sufficient statistic, the likelihood function based on (B.3) is

proportional to that of the likelihood function based on the full set of observed data

(Yobs,

W).

Note

also

that

the

conditional

covariance

(given

)

between

Y

obs c

and

Y

obs t

is

zero, which is true irrespective of the correlation between the two potential outcomes for

the

same

unit,

because

the

two

averages,

Y

obs c

and

Y tobs ,

are

based

on

different

units.

182

Model-Based Inference for Completely Randomized Experiments

To derive the conditional distribution of the missing potential outcomes given the data and the unknown parameters, first let us consider the conditional distribution of one potential outcome given the other:

Yi(1)|Yi(0), W,   N

t

+



·

t c

·

(Yi(0) -

c) , (1

- 2)

·

t2

,

and

Yi(0)|Yi(1), W,   N

c

+



·

c t

·

(Yi(1) -

t) , (1

- 2)

·

t2

.

Then, if we use Equations (8.13), the representations of Yiobs and Yimis as functions of Yi(0) and Yi(1), the conditional distribution of Yimis is

Yimis|Yiobs, W,   N Wi ·

c

+



·

c t

·

(Yiobs

-

t)

+ (1 - Wi) ·

t

+



·

t c

·

(Yiobs

-

c)

,

(1 - 2) · ((Wi · t2 + (1 - Wi) · t2) .

Because of the exchangeability of the potential outcomes, Yimis is independent of Yimis if i = i , conditional on W and .
Next we use the representation of the average treatment effect in terms of the observed
and missing potential outcomes,

fs

=

1 N

N

Yi(1) - Yi(0)

=1 N

N

(2Wi - 1) · Yiobs - Yimis

i=1

i=1

=

1 N

N i=1

(2Wi - 1) · Yiobs

-

1 N

N i=1

(2Wi

- 1) · Yimis,

to derive the conditional distribution of fs given Yobs, W, and  . The first sum is observed, and the second sum consists of N unobserved terms. Because, given (Yobs, W)
and  , fs is a linear function of normal random variables, fs is normally distributed with
mean

E fs Yobs, W, 

=

1 N

N
Wi ·
i=1

Yiobs

-

c

-



·

c t

·

Yiobs - t

+ (1 - Wi) ·

t

-

Yiobs

+



·

t c

·

Yiobs - c

=

t

·

Y

obs t

+

(1

-

t)

·

t

-

c

·

Y

obs c

+

(1

-

c)

·

c

,

(B.4)

Appendix B Analytic Derivations with Known Covariance Matrix

183

where

t

=

Nt N

·

1 -  · c t

,

and

c

=

Nc N

·

1 -  · t c

,

and conditional variance

V fs Yobs, W, 

= 1 - 2 N

Nt N

·

t2

+

Nc N

·

t2

.

(B.5)

Now consider inference for . We use a joint normal prior distribution for (c, t):

c t

N

c t

,

c2 0

0 t2

,

(B.6)

where c, t, c, and t are specified constants. Combining the prior distribution in (B.6) with the (normal) likelihood function for the observed data given (c, t) from (B.2), leads to a conditional posterior distribution for fs given  that is normal with mean

|Yobs,W = E

c t

Yobs, W, 

=

c

·

Y

obs c

+

(1

-

c)

·

c

t

·

Y

obs t

+

(1

-

t)

·

t

,

(B.7)

where

c

=

Nc/t2 Nc/t2 + 1/c2

and

t

=

Nt/t2 Nt/t2 + 1/t2

,

and covariance matrix

|Yobs,W = V

c t

Yobs, W, 

=

1 Nc /t2 +1/c2
0

0
1 Nt /t2 +1/t2

.

(B.8)

Next we combine the posterior distribution for  with the conditional posterior distribution of the average treatment effect fs given  to obtain the distribution of the average treatment effect conditional on only the observed data, its posterior distribu-
tion. Because both of the distributions used here are normal, with the latter linear
in the parameters, the posterior distribution of fs (i.e., marginalized over ) will also be normal. Specifically, because ( |Yobs, W)  N (|Yobs,W, |Yobs,W), and (fs|Yobs, W,  )  N (c + t  , 2fs|Yobs,W, ) (with 2|Yobs,W, free of  ), it follows that (fs|Yobs, W)  N (c + t |Yobs,W, 2fs|Yobs,W, + t |Yobs,Wt). Straightforward algebra then shows that (fs|Yobs, W) is normal with mean

fs|Yobs,W

=

t

·

Y

obs t

+

(1

-

t)

·

t

-

c

·

Y

obs c

+

(1

-

c)

·

c)

,

(B.9)

184

Model-Based Inference for Completely Randomized Experiments

where

c

=

c

+

(1

-

c) ·

c

=

Nc N

·

= (1 - q) ·

1

-



·

t c

+

1 -  · t c

+

Nt + Nc ·  · t

NN

c

·

Nc/t2 Nc/t2 + 1/c2

q

+

(1

-

q)

·



·

t c

·

(1

(1 - - q) ·

q) · N/t2 N/t2 + 1/c2

,

and

t

=

t

+ (1 - t) · t

=

Nt N

·

1

-



·

c t

+

Nc N

+

Nt N

·

·

c t

·

Nt/t2 Nt/t2 + 1/t2

=p·

1

-



·

c t

+

1

-

p

+

p

·



·

c t

·

q

·

p·N N/t2

/t2 + 1/t2

,

where p = Nt/N, and with posterior variance

2fs|Yobs,W

=

1 - 2 N

Nt N

·

t2

+

Nc N

·

t2

+

Nt + Nc ·  · t

NN

c

2

·

Nc/t2

1 +

1/c2

+

Nc + Nt ·  · c

NN

t

2

·

Nt/t2

1 +

1/t2

= 1 - 2 N

q · t2 + (1 - p) · t2

+

(p + (1 - p) ·  (1 - p) · N/t2

· t/c)2 + 1/c2

+

(1

- p

p+p· · N/t2

 +

· c/t 1/t2

)2

.

Now let us look at some special cases. First, the large sample approximation. With Nc and Nt large, we ignore terms that are of order o(1/Nc) or o(1/Nt). In this case, c  1, t  1, and the mean and scaled variance simplify to

2fs|Yobs,W,Nc,Nt

large

-

Y

obs t

-

Y cobs ,

and

N · 2fs|Yobs,W,Nc,Nt large - 1 - 2 · p · t2 + (1 - p) · t2

+

p

+

(1

-

p)

·



·

t c

2

·

t2 1-p

+

(1

-

p)

+

p

·



·

c t

2 · t2 . p

For the variance, it is useful to consider the special cases with  = 0 and  = 1. In large samples,

N

·

2fs|Yobs,W,Nc,Nt

large,=0

-

t2

·

1

p -

p

+

t2

·

1

- p

p ,

Appendix B Analytic Derivations with Known Covariance Matrix

185

and

N · 2fs|Yobs,W,Nc,Nt large,=1 -

+

(1

-

p)

+

p

·

c t

2 · t2 . p

p

+

(1

-

p)

·

t c

2
·

t2

1-p

It is also useful to compare this to the posterior distribution for the population average treatment effect sp. For the general prior distribution, the posterior distribution is

sp|Yobs, W 

N

t

·

Y

obs t

+

(1

-

t)

·

t

-

c

·

Y

obs c

+

(1

-

c)

·

c

,

(1

-

p)

·

1 N/t2

+

1/c2

+

p

·

1 N/t2 +

1/t2

.

Even in finite samples, the posterior distribution of sp does not depend on the correlation between the potential outcomes, . In large samples this simplifies to

sp  N

Y

obs t

- Ycobs,

(1

t2 - p)

·

N

+

t2 p·N

.

Note that the difference between the normalized posterior precisions for the average effect in the sample and the population average effect does not vanish as the sample size gets large.
Finally, it is useful to derive the conditional distribution of the missing potential outcomes given the observed data, integrating out the unknown parameters . For this we use the conditional distribution of the missing data given the observed data and parameters, and the posterior distribution of the parameters. Again, the normality of both components ensures that the distribution of the missing data are Gaussian (normal). The mean and variance of Yimis given Yobs and W are thus

Yimis|Yobs,W = Wi ·

c

·

Y

obs c

+ (1 - c)

· c + 

·

t c

·

Yiobs

-

t

·

Y

obs t

+

(1

-

t)

·

t

+ (1 - Wi) ·

t

·

Y

obs t

+

(1

-

t)

· t

+



·

c t

·

Yiobs

-

c

·

Y

obs c

+

(1

-

c)

·

c

,

and

Y2imis|Yobs,W = Wi ·

(1

-

2) ·

t2

+

(1 -

p)

·

1 N/t2

+

1/c2

+

2

·

·

p

·

1 N/t2

+

1/t2

c 2 t

186

Model-Based Inference for Completely Randomized Experiments

+ (1 - Wi) ·

(1 - 2) · t2

+

1 p · N/t2 + 1/t2

+ 2

·

·

((1

-

p)

·

1 N/t2

+

1/c2

.

t 2 c

In this case there is also a covariance across units, through the dependence on the

parameters:

Cov(Yimis,

Yimis|Yobs,

W)

=

-NcN+c2+·· t2tt/2t·2/c2c c+2 -NtN/t +t2· 1+t t2·1//c t2t2

-NcN/c+t2· 1+t t·21//cc2c2

- +

 Nt
Nt

· t · c + t2/t2
2 · t2 + t2/t2

if Wi = 0, Wi = 0
if Wi = 0, Wi = 1 .
if Wi = 1, Wi = 0
if Wi = 1, Wi = 1.

In large samples, these can be approximated by

Yimis|Yobs,W = Wi ·

Y

obs c

+

·

t c

·

Yiobs

-

Y

obs t

+ (1 - Wi) ·

Y

obs t

+



·

c t

·

Yiobs

-

Y

obs c

,

Y2imis|Yobs,W = Wi · t2 ·

1

-

2

+

(1

1 - p)

·

N

+

2 p·N

+ (1 - Wi) · t2 ·

1

-

2

+

p

1 ·N

+

((1

2 - p)

·

N

,

and

Cov(Yimis,

Yimis|Yobs,

W)

=

-(1(-12 -··p)ptt·2)·N·Nc+-p·t2N·p·tN· c

-

 · t · (1 - p)
t2

c ·N

-



+ 2 ·

· t · c p·N
t2

(1 - p) · N p · N

if Wi = 0, Wi = 0,
if Wi = 0, Wi = 1, .
if Wi = 1, Wi = 0,
if Wi = 1, Wi = 1.

CHAPTER 9
Stratified Randomized Experiments
9.1 INTRODUCTION
The focus in the previous chapters in Part II was on completely randomized experiments, where, in a fixed sample with N units, Nt are randomly choosen to receive the active treatment and the remaining Nc = N - Nt are assigned to receive the control treatment. We considered four modes of inference: Fisher's exact p-values and associated intervals, Neyman's unbiased estimates and repeated sampling-based large-N confidence intervals, regression methods, and model-based imputation. In addition, we considered the benefits of observing covariates, that is, measurements on the units unaffected by the treatments, such as pre-treatment characteristics. In this chapter we consider the same issues for a different class of randomized experiments, stratified randomized experiments, also referred to as randomized blocks experiments to use the terminology of classical experimental design. In stratified randomized experiments, units are stratified (or grouped or blocked) according to the values of (a function of) the covariates. Within the strata, independent completely randomized experiments are conducted but possibly with different relative sizes of treatment and control groups.
Part of the motivation for considering alternative structures for randomized experiments is interest in such experiments per se. But there are other, arguably equally important reasons. In the discussion of observational studies in Parts III, IV, V, and VI of this text, we consider methods for (non-randomized) observational data that can be viewed in some way as analyzing the data as if they arose from hypothetical stratified randomized experiments. Understanding these methods in the context of randomized experiments will aid their interpretation and implementation in observational studies.
The main part of this chapter describes how the methods developed in the previous four chapters can be modified to apply in the context of stratified randomized experiments. In most cases these modifications are conceptually straightforward. We also discuss some design issues in relation to stratification. Specifically, we assess the benefits of stratification relative to complete randomization.
In the next section we describe the data used to illustrate the concepts discussed in this chapter. These data are from a randomized experiment designed to evaluate the effect of class size on academic achievement, known as Project Star. In Section 9.3 we discuss the general structure of stratified randomized experiments. In the next four sections
187

188

Stratified Randomized Experiments

we discuss the four approaches we described previously for completely randomized experiments: in Section 9.4 the Fisher exact p-value approach; in Section 9.5 the Neyman approach; in Section 9.6 the regression approach; and in 9.7 the model-based imputation approach. Next, in Section 9.8, we discuss design issues and specifically the common benefits of stratified randomized experiments over completely randomized experiments. Section 9.9 concludes.

9.2 THE TENNESEE PROJECT STAR DATA
We illustrate the methods for randomized block experiments using data from a randomized evaluation of the effect of class size on test scores conducted in 1985­1986 in Tennesee called the Student/Teacher Achievement Ratio experiment, or Project Star for short. This was a very influential experiment; Mosteller (1995) calls it "one of the most important educational investigations ever carried out." In this chapter we use the kindergarten data from schools where students and teachers were randomly assigned to small classes (13­17 students per teacher), to regular classes (22­25 students per teacher), or to regular classes with a teacher's aide. To be eligible for Project Star, a school had to have a sufficient number of students to allow the formation of at least one class of each of the three types. Once a school had been admitted to the program, a decision was made on the number of classes of each type (small, regular, regular with aide). We take as fixed the number of classes of each type in each school. The unit of analysis is the teacher or class, rather than the individual student, to help justify the no-interference part of SUTVA.
The experiment is somewhat different from those we have discussed before, so we will be precise in its description. A school has a pool of at least 57 students, so they could support at least one small and two regular-sized classes. Two separate and independent randomizations took place. One random assignment is that of teachers to classes of different types, small, regular, or regular with aide. The second randomization is of students to classes/teachers. In our analysis, we mainly rely on the first randomization, of class-size and aides to teachers, using the teachers as the units of analysis. Irrespective of the assignments of students to classes, the resulting inferences are valid for the effect on the teachers of being assigned to a particular type of class. However, the second randomization is important for the interpretation of the results. Suppose we find that assignment to a small class leads on average to better outcomes for the teacher. Without the randomization of students to classes, this could be due to systematic assignment of better students to the smaller classes. With the second randomization, this is ruled out, and systematic effects can be interpreted as the effects of class size. This type of double randomization is somewhat similar to that in "split plot" designs (Cochran and Cox, 1957), although in split plot designs two different treatments are being applied by the double randomization.
Given the structure of the experiment, one could also focus on students as the unit of analysis, and investigate effects of class size on student-level outcomes. The concern, however, is that the Stable Unit Treatment Value Assumption (SUTVA) is not plausible in that case. Violations of SUTVA complicate the Neyman, regression, and imputation approaches considerably, and we therefore primarily focus on class-level

9.3 The Structure of Stratified Randomized Experiments

189

(i.e., teacher-level) analyses in this chapter. As we see in Section 9.4.4, however, it remains straightforward to use the FEP approach to test the null hypothesis that assignment of students to different classes had no effect on test scores whatsoever, because SUTVA is automatically satisfied under Fisher's sharp null hypothesis of no effects of the treatment.
In the analyses in this chapter, we focus on the comparison between regular (control) and small (treated) classes, and ignore the data for regular classes with teachers' aides. We discard schools that do not have at least two classes of both the small size and the regular size. Focusing on schools with at least two regular classes and two small classes leaves us with sixteen schools, which creates sixteen strata or blocks. Most have exactly two classes of each size, but one has two regular classes and four small classes, and two other schools have three small classes and two regular-sized classes. The total number of teachers and classes in this reduced data set is N = 68. Out of these 68 teachers, Nc = 32 are assigned to regular-sized classes, and Nt = 36 are assigned to small classes. Outcomes are defined at the class (i.e., teacher) level. The class-level outcomes we focus on are averages of test scores over all students for their teacher. One can, however, consider other outcomes, such as median test score of the students with a specific teacher or measures of within-teacher dispersion. The specific outcome we analyze here is the class average score on a mathematics test. The individual student scores were normalized to have mean equal to zero and standard deviation equal to one across all the students in the reduced data set. These individual scores then ranged from a minimum of -4.13 to a maximum of 2.94. The averages for each of the 68 classes in our analysis are reported in Table 9.1, organized by school. Overall, the average for the regular classes is -0.13 with a standard deviation of 0.56, and the average for the small classes is 0.09 with a standard deviation of 0.61. We return to these data after introducing methods for the analysis of such studies.

9.3 THE STRUCTURE OF STRATIFIED RANDOMIZED EXPERIMENTS
In stratified randomized experiments, units are grouped together according to some pre-treatment characteristics into strata. Within each stratum, a completely randomized experiment is conducted, and thus, within each stratum, the methods discussed in Chapters 5­8 are directly applicable. However, the interest is not about hypotheses or treatment effects within a single stratum, but rather it is about hypotheses and treatment effects across all strata. Moreover, the sample sizes are often such that we cannot obtain precise estimates of typical treatment effects within any one stratum. Here we discuss how the methods developed previously can be adapted to take account of the additional structure of the experiment.
9.3.1 The Case with Two Strata As before, we are interested both in assessing null hypotheses concerning treatment effects and in estimating typical treatment effects (usually the average). First we focus

190

Stratified Randomized Experiments

Table 9.1. Class Average Mathematics Scores from Project Star

School/ Stratum
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
Average (S.D.)

No. of Classes
4 4 5 4 4 4 4 6 4 4 4 5 4 4 4 4

Regular Classes (Wi = 0)
-0.197, 0.236 0.117, 1.190
-0.496, 0.225 -1.104, -0.956 -0.126, 0.106 -0.597, -0.495
0.685, 0.270 -0.934, -0.633 -0.891, -0.856 -0.473, -0.807 -0.383, 0.313
0.474, 0.140 0.205, 0.296 0.742, 0.175 -0.434, -0.293 0.355, -0.130
-0.13 (0.56)

Small Classes (Wi = 1)
0.165, 0.321 0.918, -0.202 0.341, 0.561, -0.059 -0.024, -0.450 -0.258, -0.083 1.151, 0.707 0.077, 0.371 -0.870, -0.496, -0.444, 0.392 -0.568, -1.189 -0.727, -0.580 -0.533, 0.458 1.001, 0.102, 0.484 0.855, 0.509 0.618, 0.978 -0.545, 0.234 -0.240, -0.150
0.09 (0.61)

on the case with the sample of N units divided into two subsamples, for example, females (f ) and males (m), with subsample size N(f ) and N(m), respectively, so that N = N(f ) + N(m). To fit the division into two subsamples into the structure developed so far, it is useful to associate with each unit a binary covariate (e.g., the unit's sex) with the membership in strata based on this covariate. Although in general in this text we use the notation Xi for the covariate for unit i, here we use the notation Gi for this particular covariate that determines stratum or group membership. As with any other covariate, the value of Gi is not affected by the treatment. In this example Gi takes on the values f and m. Define fs(f ) and fs(m) to be the finite-sample average treatment effects in the two strata:

1

1

fs(f ) = N(f )

Yi(1) - Yi(0) ,

i:Gi=f

and

fs(m) = N(m) i:Gi=m Yi(1) - Yi(0) .

Within each stratum, we conduct a completely randomized experiment with Nt(f ) and Nt(m) units assigned to the active treatment in the two subsamples respectively, and the remaining Nc(f ) = N(f ) - Nt(f ) and Nc(m) = N(m) - Nt(m) units assigned to the control treatment. It need not be the case that the proportion of treated units, the propensity score, e(f ) = Nt(f )/N(f ) and e(m) = Nt(m)/N(m) for the female and male subpopulations, respectively, is the same in both subpopulations. Let Nt = Nt(f ) + Nt(m) be the total number of units assigned to the treatment group, and Nc = Nc(f ) + Nc(m) be the

9.3 The Structure of Stratified Randomized Experiments

191

total number of units assigned to the control group. Let us consider the assignment mech-

anism. Within the Gi = f subpopulation, Nt(f ) units out of Nf are randomly chosen to

receive the treatment. There are

Nf Nt(f )

such allocations. For every allocation for the set of

units with Gi = m, there are

Nm Nt(m)

ways of choosing Nt(m) units with Gi = m to receive

the treatment out of N(m) units. All of these allocations are equally likely. Combining

these two assignment vectors, the assignment mechanism for a stratified randomized

experiment with two strata can be written as

Pr(W|Y(0), Y(1), S) =

Nf

-1
·

N(m) -1

for W  W+,

Nt(f )

Nt(m)









where W+ = W such that

Wi = Nt(f ),

Wi = Nt(m) .

i:Gi=f

i:Gi=m

Compare the assignment mechanism for a stratified randomized experiment to that for

a completely randomized experiment with Nt = Nt(f ) + Nt(m) assigned to treatment and

Nc = Nf -Nt(f )+N(m)-Nt(m) assigned to control. Many assignment vectors that would

have positive probability with a completely randomized experiment have probability zero

with the stratified randomized experiment: all vectors with

N i=1

Wi

=

Nt(f ) + Nt(m)

but i:Gi=f Wi = Nt(f ) (or, equivalently, i:Gi=m Wi = Nt(m)). If Nt(f )/N(f ) 

Nt(m)/N(m), the stratification rules out substantial imbalances in the covariate distribu-

tions in the two treatment groups that could arise by chance in a completely randomized

experiment. The possible disadvantage of the stratification is that a large number of

possible assignment vectors are eliminated, just as a completely randomized experi-

ment eliminates assignment vectors that would be allowed under Bernoulli trials (where

assignment for each unit is determined independently of assignment for any other unit).

The advantage of a completely randomized experiment over a Bernoulli trial for drawing

causal inferences was argued to be the relative lack of information on treatment effects

of the eliminated assignment vectors, typically those assignment vectors with a severe

imbalance between the number of controls and the number of treated.

Here the argument is similar, although not quite as obvious. If we were to partition the

population randomly into strata, the assignment vectors eliminated by the stratification

are in expectation as helpful as the ones included, and the stratification will not produce

a more informative experiment. However, if the stratification is based on characteristics

that are associated with the outcomes of interest, we shall see that stratified randomized

experiments generally are more informative than completely randomized experiments.

For example, in many drug trials, one may expect systematic differences in typical out-

comes, both given the drug and without the drug, for men and women. In that case,

conducting the experiment by stratifying the population into males and females, rather

than conducting a completely randomized experiment, makes eminent sense. It can lead

to more precise inferences, by eliminating the possibility of assignments with severe

imbalances in sex distribution ­ for example, the extreme and uninformative assignment

with all women exposed to the active treatement and all men exposed to the control

treatment.

192

Stratified Randomized Experiments

9.3.2 The Case with J Strata

Here we generalize the notation to the situation with multiple strata. Let J be the number

of strata, and N(j), Ncj, and Nt(j) the total number of units, and the number of control

and treated units in strata j, respectively, for j = 1, . . . , J. Let Gi  {1, . . . , J} denote the

stratum for unit i, and let Bi(j) = 1Gi=j, be the indicator that is equal to one if unit i is in

stratum j, and zero otherwise. Within stratum j there are now

N(j) Nt (j)

possible assignments,

so that the assignment mechanism is

J
Pr(W|S, Y(0), Y(1)) =

N(j) -1

j=1 Nt(j)

for W  W+,

where W+ = {W  W|

N i=1

Bi(j)

·

Wi

=

Nt(j)

for

j

=

1, . .

. , J}.

9.4 FISHER'S EXACT P-VALUES IN STRATIFIED RANDOMIZED EXPERIMENTS
In stratified randomized experiments, just as in completely randomized experiments, the assignment mechanism is completely known. Hence, given a sharp null hypothesis that specifies all unobserved potential outcomes given knowledge of the observed outcomes, we can directly apply Fisher's approach to calculate exact p-values as discussed in Chapter 5. Let us focus on Fisher's sharp null hypothesis that all treatment effects are zero: H0 : Yi(0) = Yi(1) for i = 1, 2, . . . , N. For ease of exposition, we focus initially on the case with two strata, Gi  {f , m}.

9.4.1 The Choice of Statistics in the FEP Approach with Two Strata
Let Yocbs(j) and Yot bs(j) be the average observed outcome for units in stratum j (currently, in the two-stratum example for j  {f , m}, later, in the general J-stratum case for j = 1, . . . , J) in the control and treatment groups, and let e(j) be the propensity score:

Y

obs c

(j)

=

1 Nc(j)

(1 -
i:Gi=j

Wi)

·

Yiobs,

Y

obs t

(j)

=

1 Nt(j)

Wi
i:Gi=j

·

Yiobs,

and
e(j) = Nt(j)/N(j).
Obvious statistics are the absolute value of the difference in the average observed outcome for treated and control units in the first and in the second stratum:
Tdif(f ) = Ytobs(f ) - Yc(f )obs and Tdif(m) = Yot bs(m) - Yocbs(m) .

9.4 Fisher's Exact P-Values in Stratified Randomized Experiments

193

Neither of the statistics, Tdif(f ) or Tdif(m), is particularly attractive by itself: for either one an entire stratum is ignored, and thus the test would not be sensitive to violations of the null hypothesis in the stratum that is ignored.
A more appealing statistic is based on the combination of the two within-stratum statistics, Tdif(f ) and Tdif(m), for example, the absolute value of a convex combination of the two difference in averages,

Tdif, =

·

Ytobs(f ) - Ycobs(f )

+ (1 - ) ·

Y

ot bs(m)

-

Y

obs c

(m)

,

for some   [0, 1]. For any fixed value of , we can use the same FEP approach and find
the randomized distribution of the statistic under the null hypothesis, and thus calculate the corresponding p-value. The question is what would be an attractive choice for ? An obvious choice for  is to weight the two differences Tdif(f ) and Tdif(m) by the relative sample sizes (RSS) in the strata and choose  = RSS  N(f )/(N(f ) + N(m)). If the relative proportions of treated and control units in each stratum, Nt(f )/N(f ) and Nt(m)/N(m) respectively, are similar, then the stratification from our stratified experiment is close
to the stratification from a completely randomized experiment. In that case, this choice for the weight parameter RSS would lead to the natural statistic that is common in a completely randomized experiment,

T dif,RSS =

N(f ) N(f ) + N(m)

·

Yot bs(f ) - Yocbs(f )

+

N(m) N(f ) + N(m)

·

Y

obs t

(m)

-

Y

ocbs(m)

.

If the relative proportions of treated and control units are very different, however, this choice for  does not necessarily lead to a very powerful test statistic. Suppose, for example, that both strata contain fifty units, where in stratum f , only a single unit gets assigned to treatment, and the remaining forty-nine units get assigned to control, whereas in stratum m, the number of treated and control units is twenty-five. In that case, the test based on Tdif(m) is likely to have substantially more power than the test based on Tdif(f ). Combining Tdif(f ) and Tdif(m) by the relative share of the two strata in the population, thereby giving both stratum-specific average observed outcome differences ^ (f ) and ^ (m) equal weight, would lead to a test statistic with poor power properties because it gives equal weight to the f stratum that is characterized by a severe imbalance in the proportions of treated and control units.
An alternative choice for  is motivated by considering against which alternative hypotheses we would like our test statistic to have power. Often an important alternative hypothesis has a treatment effect that is constant both within and between strata. To obtain a more attractive choice for  based on this perspective, it is useful to consider the sampling variances of the two stratum-specific statistics, Tdif(f ) and Tdif(m), under Neyman's repeated sampling perspective. Applying the results from Chapter 5, we find that under the randomization distribution, the sampling variance of the two within-stratum estimates of the average treatment effects are

VW

Ytobs(f ) - Ycobs(f )

= St2(f ) + Sc2(f ) - Stc(f )2 , Nt(f ) Nc(f ) N(f )

194

Stratified Randomized Experiments

and

VW

Yot bs(m) - Yocbs(m)

= St2(m) + Sc2(m) - St2c(m) . Nt(m) Nc(m) N(m)

Suppose that, within the strata, the treatment effects are constant. In that case, Sc2t(f ) = Sc2t(m) = 0, and the last term drops from both expressions. Assume, in addition, that all four variances Sc2(f ), St2(f ), Sc2(m), and St2(m) are equal to S2. Then the sampling variances of the two observed differences are

VW

Y

obs t

-

Y

obs c

= S2 ·

1+1 Nt(f ) Nc(f )

,

and

VW Yt - Yc = S2 ·

1+1 Nt(m) Nc(m)

.

In that case, a sensible choice for  would be the value that maximizes precision by weighting the two statistics by the inverse of their sampling variances, or

opt =

1

1 Nt(f )

+

1 Nc(f )

1 Nt(m)

1 +

1 Nc(m)

+

1 Nc(m)

1 +

1 Nt(m)

=

N(f ) ·

Nt(f ) N(f )

N(f ) ·

·

Nc(f ) N(f )

Nt(f ) N(f )

·

Nc(f ) N(f )

+

N(m)

·

Nt(m) N(m)

·

Nc(m) N(m)

,

with the weight for each stratum proportional to the product of the stratum size and the stratum proportions of treated and control units. The statistic Tdif,opt often leads to a test statistic that is more powerful against alternatives with a constant treatment effect than Tdif,RSS, especially in settings with substantial variation in stratum-specific proportions of treated units.
We also could have used the exact same statistics we used in Chapter 5. For example, in the setting of a completely randomized experiment, a natural statistic was the difference between average observed treated and control outcomes:

Tdif =

Y

obs t

-

Y

obs c

.

In the current setting of stratified experiments, with two strata, this statistic can be written as

Tdif =

1 Nt(f ) + Nt(m)

N i=1

Wi

· Yiobs

-

Nc(f )

1 + Nc(m)

N i=1

(1 - Wi)

·

Yiobs

.

9.4 Fisher's Exact P-Values in Stratified Randomized Experiments

195

Then we can write this statistic as

Tdif =

Nt(f ) Nt

·

Yot bs(f )

-

N(f )

- Nt(f ) Nc

·

Ycobs(f )

+

Nt(m) Nt

·

Y tobs (m)

-

Nc(m) Nc

·

Y oc bs (m)

.

This statistic Tdif is a valid statistic for testing from the FEP perspective but somewhat unnatural in the current context. Because of Simpson's paradox, one would not always expect small values for the statistic, even when the null hypothesis holds. Suppose that the null hypothesis of zero treatment effects for all units holds and that the potential outcomes are closely associated with the covariate that determines the strata, for example, Yi(0) = Yi(1) = Xi for all units (Yi(0) = Yi(1) = 1 for units with Xi = 1 and Yi(0) = Yi(1) = 2 for units with Xi = 2). In that case, the statistic Tdif is equal to

Tdif = Nt(f ) · 1 - N(f ) - Nt(f ) · 1 + Nt(m) · 2 - Nc(m) · 2 .

Nt

Nc

Nt

Nc

If Nf = 10, Nt(f ) = 5, N(m) = 20, and Nt(m) = 5, this is equal to

Tdif =

5 ·1-

5

·1+

5

· 2 - 15 · 2

=

1 +1- 1 - 3

=

1 .

10

20

10

20

2

42 4

Under

the

sharp

null

hypothesis

of

no

causal

effects,

the

statistic

Y

obs t

-

Y

obs c

no

longer

has expectation equal to zero, whereas it did have expectation zero in the completely

randomized experiment. Nevertheless, Tdif is still a function of assignments, observed

outcomes, and covariates, and as such its distribution under the null hypothesis can be

tabulated, and p-values can be calculated.

Finally, let us consider rank-based statistics. In the setting with a completely random-

ized experiment we focused on the difference in average ranks. In that case we defined

the normalized rank Ri (allowing for ties) as





Ri

=

N j=1

1Yjobs <Yiobs

+

1 2

1 +

N j=1

1Yjobs=Yiobs  -

N

+1 .
2

Given the N ranks Ri, i = 1, . . . , N, an obvious test statistic is the absolute value of the difference in average ranks for treated and control units:

Trank = Rt - Rc ,

where

1

Rt

=

Nt

Ri,
i:Wi=1

1

and

Rc

=

Nc

Ri,
i:Wi=0

where Rt and Rc are the average rank in the treatment and control groups respectively. Although we can use this statistic for the FEP approach, this would not be attractive if there is substantial variation between strata. We therefore propose modifying this statistic

196

Stratified Randomized Experiments

for the setting of a stratified randomized experiment. Let Rsitrat be the normalized withinstratum rank of the observed outcome for unit i:

  Rsitrat = 

j:Gi=f

1Yjobs <Yiobs

+

1 2

1+

j:Gi=m

1Yjobs <Yiobs

+

1 2

1+

j:Gi=f 1Yjobs=Yiobs

-

N(f )

+

1 ,

2

j:Gi=m 1Yjobs=Yiobs

-

N(m)

+

1 ,

2

if Gi = f , if Gi = m.

Then we can use the average value of the within-stratum ranks for treated and control units:

Trank,stratum = Rtstrat - Rcstrat ,

where

Rst trat

=

1 Nt

Rsi trat,
i:Wi=1

and

Rsctrat =

1 Nc

i:Wi=0

Rsi trat.

9.4.2 The FEP Approach with J Strata
Most of the statistics discussed in the previous section extend naturally to the case with J strata. Define for a general J-component vector  the statistic

J

Tdif, =

(j) · Yot bs(j) - Ycobs(j) .

j=1

The first natural choice for  has j proportional to the stratum size,

(j)

=

N(j) ,

N

leading to Tdif,RSS =

J

N(j) · N

Ytobs(j) - Ycobs(j)

.

j=1

The second choice for  minimizes the sampling variance of the contrast between treated and control averages under homoskedasticity, leading to

opt(j) =

N(j)

·

Nt(j) N(j)

·

Nc(j) N(j)

J k=1

N(k)

·

Nt(k) N(k)

·

Nc(k) N(k)

,

in turn leading to

T dif,opt =

1

J j=1

N(j)

·

Nt(j) N(j)

·

Nc(j) N(j)

J N(j) · Nt(j) · Nc(j) ·

j=1

N(j) N(j)

Ytobs(j) - Yocbs(j)

.

9.4 Fisher's Exact P-Values in Stratified Randomized Experiments

197

For the modified rank statistic, we define Ristrat to be the normalized within-stratum rank of the observed outcome for unit i, taking account of ties:





Rsi trat =

1Yiobs <Yiobs

+

1 2

1

+

1Yiobs=Yiobs 

-

N(Gi) 2

+

1 .

i :Gi =Gi

i :Gi =Gi

Then we can use the average value of the within-stratum ranks for treated and control units:

Trank,stratum = Rtstrat - Rcstrat ,

where, as before, Rsttrat and Rcstrat are the averages of the normalized within-stratum ranks for treated and control units.

9.4.3 The FEP Approach with Class-Level Data from Project Star

We now analyze the Project Star data using the FEP approach. Let Bi(j), i = 1, . . . , 68,

j = 1, . . . , 13 be an indicator for unit (i.e., teacher) i being from stratum (school) j. For

the thirteen schools with two classes of each type, there are

4 2

= 6 different possible

assignments. For the two schools with three small classes and two regular classes, there

are

5 2

= 10 different possible assignments, and for the one school with four small and

two regular classes, there are

6 2

= 15 different possible assignments. Hence, the total

number of assignments of teachers to class type with positive probability is (613)×102 ×

15  2 × 1013. We therefore use numerical methods to approximate the p-values for the

FEP approach. We focus in this section on the null hypothesis that there is no effect of class size on
the average test score that a teacher would achieve for their students,

H0 : Yi(0) = Yi(1), for all i = 1, . . . , 68,

in any of the sixty-eight classes. We consider four test statistics based on the stratified class-level data. (Recall that the p-value has a valid interpretation only if one statistic is specified a priori, and our exercise is for illustrative purposes only.) The first test statistic is the absolute value of the difference in the average mathematics scores between small (treated) and regular-sized (control) classes:

Tdif =

Y

obs t

-

Y

obs c

.

As was discussed before, this statistic, which is natural in a completely randomized experiment, is not natural in this setting because one would not necessarily expect small values even when the null hypothesis is true (especially if there is substantial variation of the shares of treated units within the strata), although the results of the test are valid. The value of the statistic in the sample is 0. 224. The p-value, here calculated as the probability under the randomization distribution of finding a value of the statistic at least as large as 0.224, is p = 0. 034, thereby suggesting that it is unlikely that the students of

198

Stratified Randomized Experiments

teachers assigned to the small classes had the same average test scores as the students of teachers assigned to large classes.
The second statistic is the average of the sixteen within-school average differences between small and regular class mathematics scores, weighted by the number of classes in the schools N(j), divided by the total number of classes, N = 68:

T dif,RSS =

J

N(j) · N

Yot bs(j) - Ycobs(j)

.

j=1

The realized value of the test statistic is 0.241. The p-value, now the probability under the randomization distribution of finding a value of the statistic at least as large as 0.241, is p = 0.023. This statistic also suggests that the teachers with smaller classes had different average test scores than teachers with regular-sized classes.
The third statistic also weights the within-school average differences, but now the weights are proportional to the product of the number of classes in each school and the proportions of treated and control classes within each school:

T ave,opt =

1

J j=1

N(j) N

·

Nt(j) N(j)

·

Nc(j) N(j)

J j=1

N(j) N

· Nt(j) · Nc(j) · N(j) N(j)

Y

obs t

(j)

-

Y

obs c

(j)

.

Especially when there is considerable variation in the proportion of treated and control units between strata, this statistic is expected to be more powerful against alternative hypotheses with constant additive treatment effects. The realized value of the test statistic is 0.238, with a corresponding p-value of 0.025, leading to essentially the same substantive conclusion as that based on the previous two statistics.
In the current application, these three test-statistics lead to very similar p-values. This is partly because most of the schools have two classes of each type. If there were more dispersion in the fraction of small classes by school and in the number of classes per school, the results could well differ more for the three statistics. The value of the rank-based test Trank,stratum is 0.48, leading to a p-value of 0.15. Because the outcomes themselves are averages (over students within the classes), there are few outliers, and in this case, the rank-based tests would not be expected to have an advantage over statistics based on simple averages.
Another interesting test statistic here is based on the variation in average mathematics scores in small and regular classes. Suppose that at the individual-student level, it makes no difference to students whether they have many or few classmates, that is, whether they are in a regular or small class. In that case, the expected value of the average mathematics score in regular and small classes should be the same. However, because in small classes the average is calculated over fewer students than in large classes, the small class averages should have a larger variance. More precisely, if the individual test scores have a mean  and variance  2, then the average in a class of size K should have mean  and variance  2/K. So, even if individual student scores are not affected by class size, the null hypothesis that at the teacher level the average test score is not affected by the class size need not be true. We can investigate this phenomenon by choosing a new test statistic.

9.4 Fisher's Exact P-Values in Stratified Randomized Experiments

199

Now calculate for each school and class type the difference between the highest and the lowest average score:

c(j)

=

max
i:Wi=0,Gi=j

Yiobs

-

min
i:Wi=0,Gi=j

Yiobs,

and

t(j)

=

max
i:Wi=1,Gi=j

Yiobs

-

min
i:Wi=1,Gi=j

Yiobs.

(For the schools with two small classes, this amounts to the absolute value of the difference between the two small classes.) We then take, for each school, the difference between this difference for small and regular classes:

(j) = t(j) - c(j).

We then average these differences over all 16 schools, weighted by the number of classes in each school:

Trange = 1

J
N(j) ·

(j).

N j=1

We find that the range does, indeed, on average appear to be larger in the small classes than in the regular classes, with the realized value of the test statistic equal to 0.226. The p-value based on the FEP calculations is 0.109. Thus there is only limited evidence against the null hypothesis that the variation in average scores differs between small and regular-sized classes.

9.4.4 The FEP Approach with Student-Level Data from Project Star
Here we consider an alternative analysis of the Project Star data, using the studentlevel data. This analysis is specific to the FEP approach and the particular structure of the Project Star data, and is not generally applicable to stratified randomized experiments. We present it here to show the richness of the FEP approach. This section can be bypassed without loss of continuity.
The key issue is that for this analysis, the no-interference part of the stability assumption, SUTVA, is automatically satisfied. More precisely, under the null hypothesis of no effects whatsoever, the no-interference assumption holds automatically, but it need not hold under the alternative hypothesis. Recall that the experiment assigned students and teachers randomly to the classes. Without the no-interference assumption, we index potential outcomes by the assignment vector that describes the class and teacher pair for each student. The discussion in this section is relatively informal. In Appendix A we present a more formal discussion of this example, which requires substantial new notation, which is not used in the rest of the text.
First consider the data from a single stratum, in this application a school, say school j. This school has N(j) students and P(j) teachers and classes. These students and teachers will be randomly assigned to P(j) classes, with the class size for class s equal to Ms(j).

200

Stratified Randomized Experiments

The class sizes must add to the school size, or

P(j) s=1

Ms(j)

=

N(j).

The

total

number

of

ways one can select the students, given class sizes, is

P(j)-1 s=1

N(j) - t<s Mt(j) Ms(j)

.

The P(j) teachers can be assigned to the P(j) classes in P(j)! ways, so the total number of ways the students and teachers for school j can be assigned to classes is

P(j)-1 N(j) - t<s Mt(j) · P(j)!.

s=1

Ms(j)

For each student this is the total number of potential outcomes. The basis for the randomization distribution is this set of assignments, which are all equally likely. The total number of assignments is obtained by multiplying this for each school, across all schools:

J Sj-1 N(j) - t<s Mt(j) · P(j)!.

j=1 s=1

Ms(j)

The null hypothesis we consider is that of no effect whatsoever, against the alternative hypothesis that some potential outcomes differ. The test statistic we use is the average over the schools of the average student score for students in small classes minus the average student score for students in regular-sized classes.

Tstudent =

J j=1

N(j) N

1

·

Nc(j) N(j)

·

Nt(j) N(j)

·

J j=1

N(j) N

·

Nc(j) N(j)

·

Nt(j) N(j)

·

Yt(j)obs - Yc(j)obs

,

with the stratum weight equal to
N(j) · Nc(j) · Nt(j) . N N(j) N(j)
In the sample, the statistic is 0.242, with a p-value < 0.001. Thus we get much stronger evidence against this null hypothesis than we did for the null hypothesis using classlevel data.
Now let us compare this analysis to that based on teacher-level data. If we were to maintain the no-interference assumption at the student level, the new null hypothesis requires only that changing student i's assignment from a regular to a small class does not change the outcome. In that case the student-level test score will tend to be more powerful than the class-level average test score, and the former would be preferable to the latter. However, in this application, the student-level stability assumption is a very strong and tenuous one to make. It is very plausible that there are interactions between children that would violate this assumption. Hence, even clear rejections of the null hypothesis of no differences by teacher assignment would not necessarily be credible evidence of systematic effects of class size ­ it may simply indicate the presence of

9.5 The Analysis of Stratified Randomized Experiments

201

effects of teachers or peers. In contrast, the teacher-level assessment does not rely on within-class, no-interference assumptions, and so clear evidence against the null hypothesis of no effect based on that assessment is more credible evidence of class-size effects.

9.5 THE ANALYSIS OF STRATIFIED RANDOMIZED EXPERIMENTS FROM NEYMAN'S REPEATED SAMPLING PERSPECTIVE
The results in Chapter 6 for a completely randomized experiment can be used to analyze data within a stratum. Specifically, within each stratum those results can be used to obtain an estimate of the average treatment effect and to obtain a conservative estimator of the repeated sampling variance of this estimator.

9.5.1 The Two-Stratum Case
Initially we focus on the simple example with two strata and apply the framework to the Project Star data in Section 9.5.2. For the first stratum, the natural unbiased estimator for the average treatment effect fs(f ) is

^ dif(f )

=

Ytobs(f )

- Yocbs(f )

=

1 Nt(f )

i:Gi=f

Wi

·

Yiobs

-

1 Nc(f )

i:Gi=f

(1 -

Wi) · Yiobs.

The sampling variance of this estimator, under the randomization distribution, is

VW

^ dif(f )

= Sc2(f ) + St2(f ) - Sc2t(f ) , Nc(f ) Nt(f ) N(f )

with analogous expressions for the estimator for the average treatment effect in the second stratum and its sampling variance. However, we are not necessarily interested in the two within-stratum average treatment effects. More commonly, we are interested in a weighted average of the two within-stratum average effects. A natural estimand is the finite-sample average treatment effect,

fs =

N(f ) N(f ) + N(m)

·

fs(f )

+

N(m) N(f ) + N(m)

·

fs(m)

=

1 N

N i=1

Yi(1) - Yi(0)

.

With fixed stratum sizes, unbiasedness of the two within-stratum estimators implies unbiasedness of

^ strat

=

N(f ) N(f ) + N(m)

·

^ dif(f )

+

N(m) N(f ) + N(m)

· ^ dif(m),

for the population average treatment effect fs. Similarly, the assumption that the randomizations in the two strata are independent, formalized in the assignment mechanism,

202

Stratified Randomized Experiments

implies that the two estimators are uncorrelated, and thus

VW ^ strat =

N(f ) N(f ) + N(m)

2
· VW (^f ) +

N(m) Nf + N(m)

2
· VW (^m)

=

N(f )

2

N(f ) + N(m) ·

Sc(f )2 + St2(f ) - Sc2t(f ) Nc(f ) Nt(f ) N(f )

+

N(m)

2
·

Sc(m)2 + St2(m) - Sc2t(m)

.

N(f ) + N(m)

Nc(m) Nt(m) N(m)

The same issues that were discussed in Chapter 6 arise here in estimating this sampling variance. There is no direct way to estimate the components of this sampling variance involving the covariance of the unit-level potential outcomes, so typically those terms are ignored to obtain an estimated upper bound on the sampling variance by simply estimating the two within-stratum sampling variances:

V^ neyman =

N(f )

2
·

s2c(f ) + s2t (f )

N(f ) + N(m)

Nc(f ) Nt(f )

+

N(m)

2
·

N(f ) + N(m)

sc2(m) + s2t (m) Nc(m) Nt(m)

.

This estimate of the sampling variance is unbiased if the within-stratum treatment effects are constant and additive, and overestimates the sampling variance in expectation otherwise. Note that we do not need to make assumptions about the variation in treatment effects between strata.
So far in this section, the discussion has focused on the estimation of the population average treatment effect, fs. In some cases we may be interested in a different weighted average of the within-strata treatment effects. For example, we may be interested in the average effect of the treatment on the outcome for the units who received the treatment. Given the random assignment, and within the strata, this effect is equal to fs(f ) and fs(m), respectively. Within each stratum this is, in expectation, the same as the average effect for the full stratum. However, when the proportions of treated units differ between the strata, the weights have to be adjusted to obtain an unbiased estimate of the average effect of the treatment on the units who received treatment. The appropriate weights are proportional to the fraction of treated units in each strata, leading to the estimand

fs,t

=

Nt(f ) Nt(f ) + Nt(m)

·

fs(f )

+

Nt(m) Nt(f ) + Nt(m)

·

fs(m),

and thus to the natural unbiased estimator

^tstrat

=

Nt(f ) Nt(f ) + Nt(m)

·

^ dif(f )

+

Nt(m) Nt(f ) + Nt(m)

·

^ dif(m).

9.5 The Analysis of Stratified Randomized Experiments

203

The sampling variance of ^t can be estimated in the same way as the sampling variance for the population average treatment effect, modifying the weights to reflect the new estimand:

V^ nt eyman =

Nt(f )

2
·

Nt(f ) + Nt(m)

sc(f )2 + s2t (f ) Nc(f ) Nt(f )

+

Nt(m)

2
·

Nt(f ) + Nt(m)

s2c(m) + s2t (m) Nc(m) Nt(m)

.

More generally we can look at other weighted averages, such as the average effect for those who did not receive the treatment, but such averages are often more difficult to motivate as relevant.
Using Neyman's repeated sampling approach, we can also investigate other estimands, such as the differences between the stratum-specific average treatment effects. A natural unbiased estimator for the difference between fs(m) and fs,(f ) is

^ dif(m) - ^ dif(f ) =

Ytobs(m) - Ycobs(m)

-

Y

obs t

(f

)

-

Y

ocbs(f

)

.

This estimator is unbiased for the difference in average treatment effects with sampling variance

VW

^ dif(m) - ^ dif(f )

= Sc2(f ) + St2(f ) - Sc2t(f ) + Sc2(m) + St2(m) - Sc2t(m) . Nc(f ) Nt(f ) N(f ) Nc(m) Nt(m) N(m)

An estimator for the upper bound on this sampling variance is

V^ neyman ^ dif(m) - ^ dif(f ) = sc2(f ) + st2(f ) + sc2(m) + st2(m) . Nc(f ) Nt(f ) Nc(m) Nt(m)
We can use any of the estimated sampling variances and the associated unbiased estimators to construct large-sample confidence intervals for the associated estimator.

9.5.2 The Neyman Approach and Project Star
Next, let us consider point estimates and confidence intervals for the average effect of the class size based on the stratified experiment. First we present estimates that account for the stratification. For each school j, for j = 1, . . . , 16, the average effect of the treatment and its corresponding sampling variance are estimated as

^ dif(j) = Yot bs(j) - Yocbs(j),

and V^ neyman(j) = sc(j)2 + st(j)2 , Nc(j) Nt(j)

respectively. For each school, the estimated average effect and the square root of the estimated sampling variance are reported in Table 9.2. The population average effect is estimated as

^ strat = J N(j) · ^ (j) = 0. 241, j=1 N

204

Stratified Randomized Experiments

Table 9.2. Within-School Estimates of Treatment Effect of Small Classes Relative to Regular Classes ­ Project Star

School
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
^ strat

Estimated Effect
0.223 -0.295
0.417 0.748 -0.077 1.655 -0.254 0.429 -0.006 -0.014 -0.003 0.222 0.432 0.340 0.207 -0.306
0.241

(s. e. )
(0.230) (0.776) (0.404) (0.215) (0.206) (0.405) (0.255) (0.306) (0.311) (0.182) (0.605) (0.309) (0.179) (0.336) (0.396) (0.245)
(0.092)

and its sampling variance by

J
V^ neyman =
j=1

N(j)

2
· V^ neyman(j) = 0.0922.

N

Hence the large sample 95% confidence interval for the average effect is

CI0.95(fs) = 0.061, 0.421 .

It is interesting to compare this point estimate and its associated standard error to

that based on the analysis using the (incorrect) assumption that the data arose from a

completely randomized experiment. The point estimate of the average effect is then

^ dif

=

Y

obs t

-

Y

obs c

=

0.224,

with

an

estimated

standard

error

of

0.141,

leading

to

a

large sample 95% confidence interval of (-0.053, 0.500). This estimator of the sampling

variance is biased if there is variation in the probability of treatment between the differ-

ent strata, or if there is variation in the average potential outcomes by stratum. We know

the former is the case, with the probability of a small class equal to 0.5 in most schools,

and equal to 0.60 and 0.67 in some schools. Assessing the latter issue is more com-

plicated, and we shall return to this in Section 9.7.2. The fact that the point estimates

differ under the assumptions of a completely randomized experiment and a stratified

randomized experiment suggests that average potential outcomes also differ between

strata. The estimated standard error for the stratification-based analysis is smaller than

that for the completely randomized experiment, suggesting, again, that average potential

9.6 Regression Analysis of Stratified Randomized Experiments

205

outcomes differ between strata, which implies that there is a gain in precision from the stratification.

9.6 REGRESSION ANALYSIS OF STRATIFIED RANDOMIZED EXPERIMENTS
In order to interpret regression-based estimators, we take a super-population perspective with a fixed number of strata, and an infinite number of units within each stratum. Because there are few notational simplifications from considering the special case with only two strata, we look in this section immediately at the general situation with J strata.

9.6.1 The General Framework
Let q(j) = N(j)/N and e(j) = Nt(j)/N(j) be the proportion of each stratum in the sample from the infinite super-population, and the proportion of treated units in each stratum, or the propensity score, respectively. We consider two specifications of the regression function in this case. The first specification of the regression function treats the stratum indicators as additional regressors and includes them additively. The second specification includes a full set of interactions of the stratum indicators with the treatment indicator. We then investigate the large-sample properties of the least squares estimators of the coefficients on the treatment indicator.
Similar to the regression function specifications in Chapter 7, the first specification simply includes indicators for the strata additively in addition to the indicator for the treatment:

J
Yiobs =  · Wi + (j) · Bi(j) + i,
j=1

(9.1)

where Bi(j) is an indicator for unit i belonging to stratum j. Because we include, in this specification, a full set of stratum indicators Bi(j), for j = 1, . . . , J, we do not include an intercept in the specification of the regression function. We focus on the least squares estimator for  ,


N

2
J

(^ ols, ^ ols)

=

arg min
 ,

i=1

Yiobs

-



·

Wi

+

j=1

 (j)

·

Bi(j)

.

(9.2)

As before, we define   and  to be the population counterparts to these OLS

estimators,



2

( , )

=

arg

min
 ,

E

Yiobs

-

· Wi

+

J j=1

(j) · Bi(j)

 .

(9.3)

The first question concerns the population value   corresponding to ^ ols. In general ^ ols is not consistent for the population average treatment effect sp. Instead, it estimates a

206

Stratified Randomized Experiments

weighted average of the within-stratum average effects, with weights proportional to the

product of the fraction of observations in the stratum and the probabilities of receiving

and not receiving the treatment. More specifically,





J

J

(j) = q(j) · e(j) · (1 - e(j)), and  = (j) · sp(j)  (j) , (9.4)

j=1

j=1

where sp(j) = E[Yi(1) - Yi(0)|Bi(j) = 1]. Then ^ ols is consistent for . The following theorem formalizes this result.

Theorem 9.1 Suppose we conduct a stratified randomized experiment in a sample drawn at random from an infinite population. Then, for estimands   and w defined in (9.3) and (9.4), the estimator ^ ols satisfies, (i)

  = ,

and (ii),

 N·

^ ols - 

- d

 N 0, E

Wi -

J j=1

q(j)

·

Bi

(j)

2
·

Yiobs -   · Wi -

J j=1

q(j)

·

e(j)

·

(1

-

e(j))

2

J j=1

j

·

Bi(j)

2

  .

The proof appears in Appendix B. The weights j have an interesting interpretation. Suppose we estimate the within-
stratum average treatment effect  dif(j) as ^ dif(j) = Ytobs(j) - Ycobs(j). The sampling variance of ^ dif(j), under the assumption of a constant treatment effect, is (S2/N) · (q(j) · e(j) · (1 - e(j)))-1. Hence the weights j are proportional to the precision of natural unbiased estimators of the within-stratum treatment effects, which leads to a relatively
precisely estimated weighted average effect.
The second specification of the regression function includes a full set of interactions
of the stratum indicators with the indicator for the treatment Wi. In order to be able to interpret the coefficient on the treatment indicator as an average causal effect, we
include the interactions with the stratum indicators relative to their share in the sample
and relative to the indicator for the last stratum:

Yiobs

=



· Wi

·

Bi(j) N(j)/N

+

J j=1

(j) · Bi(j) +

J-1
 (j) · Wi
j=1

·

Bi(j)

-

Bi(J)

·

N(j) N(J)

+ i. (9.5)

Note that in this specification we only include the first J - 1 interactions to avoid perfect collinearity in the regression function. In this case, the population value  , corresponding to the large sample limit of the least squares estimator ^ ols,inter, is equal
to the population average treatment effect sp.

9.7 Model-Based Analysis of Stratified Randomized Experiments

207

Theorem 9.2 Suppose we conduct a stratified randomized experiment in a sample drawn at random from an infinite population. Then, for ^ ols,inter defined as the least squares estimator corresponding to the regression function in (9.5), and   defined as the population
limit corresponding to that estimator, (i)

  = sp,

and (ii),

 N·

^ ols,inter - sp


J
- d N 0, q(j)2 ·
j=1



(1

c2(j) - e(j)) ·

q(j)

+

t2(j) e(j) · q(j)

.

It is interesting to compare the sampling variance of ^ ols and ^ ols,inter. In general, the sampling variance of ^ ols,inter is larger than that of ^ ols.

9.6.2 Regression Analysis of Project Star
The first specification of the regression function includes the treatment indicator and the indicators for the blocks:
J
Yiobs =  · Wi + (j) · Bi(j) + i.
j=1
The point estimate and standard error for fs are
^ ols = 0. 238 (s. e. 0. 103).

Recall from the discussion in Section 9.6 that this estimator is not necessarily consistent for the average effect of the treatment in the population if there is variation in the effect of the class size by school.
The second specification of the regression function includes indicators for the strata, as well as interactions of the stratum indicators and the treatment indicator:

Yiobs

=



· Wi

·

Bi(J) N(J)/N

+

J j=1

j

· Bi(j) +

J-1
 (j) · Wi
j=1

·

Bi(j)

-

Bi(J)

·

N(j) N(J)

+ i.

The point estimate and standard error for  , based on this specification, are

^ols,inter = 0. 241 (s. e. 0. 095).

The two estimates for the average effect are close, with similar standard errors, consistent with limited heterogeneity in the treatment effects.

9.7 MODEL-BASED ANALYSIS OF STRATIFIED RANDOMIZED EXPERIMENTS
In a model-based analysis, it is conceptually straightforward to take account of the stratification. As in the analysis of completely randomized experiments, we combine the specification of the joint distribution of the potential outcomes with the known distribution of the vector of assignment indicators to derive the posterior distribution of

208

Stratified Randomized Experiments

the causal estimand. There is one new issue that arises in this context: the link between the distributions of the potential outcomes in distinct strata.

9.7.1 General Considerations
One can choose to have distinct parameters for the distributions in different strata, that is, independent prior distributions. Alternatively the researcher may wish to link the parameters in the different strata either deterministically by imposing equality restrictions or stochastically through a dependence structure in the prior distribution, that is, for example, through a hierarchical model. In situations with few strata and many units per stratum, one may wish to pursue the first strategy and specify distinct distributions for the potential outcomes in each stratum, with independent prior distributions on the parameters of these distributions. In contrast, in settings with a substantial number of strata, and a modest number of units per stratum, one may wish to link some of the parameters. One can do so by restricting them to be equal, or by incorporating dependence into the specification of the prior distribution.
We make this more specific and illustrate the issues for the case with common and stratum-specific parameters. Suppose we specify the joint distribution of the potential outcomes in stratum j as

Yi(0) Yi(1)

Bi(j),   N

c(j) t(j)

,

c2(j) 0

0 t2(j)

,

(9.6)

where the means (c(j), t(j)) and variances (c2(j), t2(j)) are specific to stratum j. The full parameter vector is  = (c(j), t(j), c2(j), t2(j), w = 0, 1, j = 1, . . . , J).
With few strata and a substantial number of units per stratum, we may wish to use a prior distribution that makes all elements of  a priori independent, for example, using normal prior distributions for the c(j) and t(j) and inverse chi-squared prior distributions for the c2(j) and t2(j).
However, if there are many strata and the number of units per stratum is modest, we
may wish to specify a hierarchical prior distribution for the means to obtain more precise
estimates. For example, we may wish to restrict the variances of the potential outcomes to be the same across strata, c2 and t2 for all j, and to specify the means to have a joint normal prior distribution, independent of the variances c2 and t2:







c(1) c(2)
...
c(J) t(1) t(2)
...



t(J)



N

 

c c ...
c t t ...


 

,

 



c2
0 ... 0 ct
0 ... 0

0 c2
... 0 ct
...

... ... ... ...

0 ...
c2 0 ...
ct

ct
0 ... 0 t2
0 ... 0

0 ct
... 0 t2
...

... ... ... ...

0 ...
ct 0 ...
t2

  .

The full parameter vector is now  = (c2, t2, c, t, c2, t2).

9.7 Model-Based Analysis of Stratified Randomized Experiments

209

9.7.2 A Model-Based Analysis of Project Star
We now conduct a model-based imputation analysis of the Project Star data. The model we consider for the potential outcomes is

Yi(0) Yi(1)

Bi(j) = 1,   N

c(j) t(j)

,

2 0

0 2

,

with a common variance  2. In addition we assume that the pairs of stratum-specific means (c(j), t(j)) are independent across strata given the hyperparameters,

c(j) t(j)

 2, c, t,

N

c t

,

,

c(j) t(j)



c(k) t(k)

 2, c, t, , j = k.

In this model, the two potential outcome means (c(j), t(j)) are specific to the stratum, and the variance  2 is common to all strata and both potential outcomes.
The full parameter vector is  = (c, t, ,  2). For the prior distributions, we use conventional proper choices. For the variance parameter  2, we use a standard inverse
Chi-squared prior distribution,

k0 · 02 ·  -2  X 2(k0), or  2  X -2(k0, 02),

using the notation from Gelman, Carlin, Stern, and Rubin (1995). Our choices for the parameters of the prior distribution are k0 = 2 and 02 = 0.001. For c and t, we use independent normal prior distributions,

c t

N

0 0

,

1002 0

0 1002

.

The prior distribution for is an inverse wishart distribution,

 W-1(k1,

-1 1

).

We consider two pairs of values for (k1, 1). The first is k1 = 1,000, 1 = 1,000 · I2, where Ik is the k × k identity matrix. This essentially corresponds to removing the link

between the parameters in the different strata. We refer to this as the "independent" prior,

corresponding to independence between the stratum-specific means. The second choice

for (k1,

1) is k1 = 3 and

-1 1

=

0.001

·

k1

·

I2,

which

allows

the

hierarchical

structure

to influence answers. We refer to this prior distribution as the hierarchical prior.

For the independent prior distribution, the posterior mean and standard deviation are

E[fs|Yobs, W, B, independent] = 0.241, V(fs|Yobs, W, B, independent) = 0.0952.

Substantitvely it is difficult to see why one would wish to impose the ex post independence. Certainly, as we will see, there is strong evidence in the data to suggest that the average potential outcomes within the schools are related.
For the hierarchical prior distribution, the posterior mean and standard deviation are
E[fs|Yobs, W, B, hierarchical] = 0.235, V(fs|Yobs, W, B, hierarchical)2 = 0.1072.

210

Stratified Randomized Experiments

It is also interesting to assess the evidence for variation in average potential outcomes and treatment effects by strata. In order to do so, we inspect the posterior distribution of
given the hierarchical prior distribution. The logarithm of the square root of the two diagonal elements corresponds to the logarithm of the standard deviation of c(j) and t(j) over the sixteen schools. The posterior means of logarithms of those two standard deviations are
 E ln ( 11) Yobs, W, B, hierarchical = -1.14,
 V ln ( 11) Yobs, W, B, hierarchical = 0.472,

and 
E ln ( 22) Yobs, W, B, hierarchical = -1.08, 
V ln ( 22) Yobs, W, B, hierarchical = 0.452.

There is clearly some evidence of heterogeneity in the stratum means. However, the

heterogeneity is highly correlated across potential outcomes, with the posterior mean for

the Fisher Z transformation of the correlation between c(j) and t(j) (the (1, 2) element of divided by the square root of the product of the (1, 1) and (2, 2) elements) equal to



E

1 ln

1+

12/( 11 22)

2 1 - 12/( 11 22)

Yobs, W, B, hierarchical = 2.63,

and the posterior variance equal to



V

1 ln

1+

12/( 11 22)

2 1 - 12/( 11 22)

Yobs, W, B, hierarchical = 0.672.

The posterior mean of the correlation itself is 0.96. The average treatment effect in school j is approximately  (j) = t,j - c,j. In terms of the parameters, the variance of the treatment effect across the sixteen schools is (-1 1) (-1 1) = 11 - 12 - 21 + 22. We focus on the square root of this, that is, the standard deviation of the treatment effect over the schools. The posterior mean of the logarithm of the standard deviation of the treatment effect is

E ln

11 - 12 - 21 + 22 Yobs, W, B, hierarchical = -2.33,

with posterior variance

V ln

11 - 12 - 21 + 22 Yobs, W, B, hierarchical = 0.592.

Comparing the posterior mean of the standard deviation of the stratum-specific treatment effect  (j) over the sixteen strata, (0.115), with the posterior mean of the standard deviation of the stratum-specific level under the control treatment c,j over the sixteen strata, (0.349), suggests that, although there is considerable evidence that levels of the average test scores vary by school, there is little evidence that average class size effects vary much

9.8 Design Issues: Stratified versus Completely Randomized Experiments

211

by school. The former may be due to differences in teacher quality or to differences in student populations. This type of conclusion highlights the advantage of a fully modelbased analysis, which allows for the simultaneous investigation of multiple questions.

9.8 DESIGN ISSUES: STRATIFIED VERSUS COMPLETELY RANDOMIZED EXPERIMENTS

When designing an experimental evaluation, one may often have the choice between a completely randomized experiment and a stratified randomized experiment. Here we study the implications of the choice between the different experimental designs for the expected sampling variance of the standard unbiased estimator for the average treatment effect. There is a sense in which one is never worse off stratifying on a covariate. However, to make this point precise, we need to pose the question appropriately.
We analyze the problem in a super-population setting. Each unit in this population has a binary characteristic Gi, Gi  {f , m}. The proportion of women (Gi = f types) in the population is p. We consider the following two designs. In the first design we randomly draw N units from the population. Out of this sample of size N, we randomly draw Nt = q · N units to receive the active treatment and Nc = (1 - q) · N units to receive the control treatment. Based on the randomized experiment, we estimate the average treatment effect in the super-population as

^ dif

=

Y

obs t

-

Y cobs ,

with (super-population) sampling variance

Vsp(^ dif)

=

c2 Nc

+

t2 . Nt

In the second design, we randomly draw N(f ) = p · N units from the subpopulation of units who have Gi = f , and N(m) = (1 - p) · N units from the population who have Gi = m. In the first subsample, we randomly select Nt(f ) = p · q · N units to receive the active treatment, and the remaining Nc(f ) = (1 - p) · q · N are assigned to receive the control treatment. In the second subsample Nt(m) = p · (1 - q) · N units are randomly selected to receive the active treatment, and the remaining Nt(m) = (1 - p) · (1 - q) · N
units to receive the control treatment. Note that we assign the same proportion of units in

each subpopulation to the active treatment. In this experiment, we estimate the average treatment effect within the Gi = f and Gi = m subpopulations as

^ dif(f ) = Yot bs(f ) - Yocbs(f ),

and

^ dif(m)

=

Yot bs(m)

-

Y

obs c

(m),

and the overall average effect as

^ strat = N(f ) · ^ dif(f ) + N(m) · ^ dif(m) = q · ^ dif(f ) + (1 - q) · ^ dif(m).

N

N

The super-population variance for this estimator is

Vsp(^ strat)

=

q N

·

t2(f ) p

+

c2(f ) 1-p

+ 1-q · N

t2(m) p

+

c2(m) 1-p

.

212

Stratified Randomized Experiments

The difference between the two sampling variances, normalized by the sample size N, is

N · Vsp(^ dif) - Vsp(^ strat) = q(1 - q) · (c(f ) - c(m))2 + (t(f ) - t(m))2  0.

Although under some conditions there is an unambiguous ranking of the population sampling variances, Vsp(^ dif) and Vsp(^ strat), the estimated sampling variance for the stratified experiment may be larger than for the completely randomized experiment. The
natural estimator for the sampling variance of the simple unbiased estimator in a strat-
ified randomized experiment can be larger than the natural estimators for the sampling
variance in a completely randomized experiment, because of the need to estimate the
within-stratum potential outcome variances.
We can assess the benefits of having the stratification for an experiment with the size of Project Star. Suppose we have J strata, each with Nt treated (small) and Nc = Nt control (regular-sized) classes. Suppose that the true within-stratum variance of the potential outcomes is  2 = 0. 432, which is the posterior mean for the hierarchical model estimated on the Project Star data. Suppose also that the true variance of the within-stratum average potential outcomes over the strata is 11 = 0. 372 for the control averages c,j and 22 = 0. 372 for the averages given the treatment t,j, again estimated on the Project Star data. Then the ratio of the variances under a completely randomized experiment versus a stratified randomized experiment would be (0. 432 + 0. 372)/0. 432 = 1. 65. Using a stratified design reduces the variance by 40%. The stratification appears to be quite
effective in Project Star.

9.9 CONCLUSION
In this chapter we discussed the analysis of stratified randomized experiments using the four approaches developed in the previous four chapters for completely randomized experiments. In general the stratification should not be ignored in design if treatment rates and potential outcomes vary systematically by stratum. All approaches can be adapted in a fairly straightforward manner to take account of the stratification. A key issue is that in the model-based analysis, a hierarchical model can be useful to take account of similarities in potential outcome distributions across strata. As we illustrated using data from the Project Star experiment on class size, stratification can increase precision of estimation when the strata are good predictors of the potential outcomes.
In the next chapter we extend these analyses to an extreme version of stratification in an experimental context, paired randomized experiments, where each stratum consists of only two units, one treated and one control.

NOTES
The Project Star data have been used by numerous researchers. For more recent research papers, see Krueger (1999), Chetty, Friedman, Hilger, Saez, Schanzenbach, and Yagan (2011) and Graham (2008). Graham (2008) looks at implications of within-class interactions on variances, as discussed in Section 9.4.3.

Appendix A: Student-Level Analyses

213

To implement the Bayesian analysis discussed in Sections 9.7 and 9.7.2 it is useful to use modern numerical methods, in particular Markov-Chain-Monte-Carlo methods, which we discuss in some detail in Chapter 8.
In textbook discussions of the benefits of stratification, and its extreme version, pairing versus complete randomization, it is sometimes pointed out that there are costs associated with stratification and pairing in small population settings. For example, Snedecor and Cochran (1989, p. 101) write: "If the criterion has no correlation with the response variable, a small loss in accuracy results from the pairing due to the adjustment for degrees of freedom. A substantial loss may even occur if the criterion is badly chosen so that members of a pair are negatively correlated." The possibility of negative correlation arises only if in the populations in the strata are small. For example, as discussed in Snedecor and Cochran (1967, p. 294), if the strata correspond to litters of rats, then weights within strata may well be negatively correlated. On the other hand, if the withinstrata samples are drawn from large strata, in expectation the stratification can only lead to non-negative correlations.
Box, Hunter, and Hunter (2005, p. 93) also suggest that there is a trade-off in terms of accuracy or variance in the decision to stratify, writing: "Thus you would gain from the paired design only if the reduction in variance from pairing outweighed the effect of the decrease in the number of degrees of freedom of the t distribution." These comments reflect on the implications for testing and interval estimation. In expectation, with large size strata, the sampling variance of the estimated average treatment effect can only decrease as a result of stratification or pairing, not increase.
Samii and Aronow (2012) discuss comparisons between regression approaches and Neyman repeated sampling variances in this setting.

APPENDIX A: STUDENT-LEVEL ANALYSES

Here we discuss the student-level significance tests in more detail. First consider the

data from a single stratum, say school j. This school has N(j) students with P(j)

classes/teachers. The class size for class s in school j is Ms(j), with

P(j) s=1

Ms(j)

=

N(j).

Note that we do not require the class sizes to be the same for all small or all regular-sized

classes. Even if some classes are exactly the same size, we analyze them as distinct in the

sense that having a particular group of twenty students and a teacher assigned to class 1,

and a second group of ten students and another teacher assigned to class 2 is a different

assignment from having the first group of students and their teacher assigned to class

2 and the others to class 1. This is not necessary, but interpreting those assignments as

identical would require keeping track of classes that have identical sizes versus differ by

small numbers. The N(j) students and the P(j) teachers are assigned randomly to the P(j)

classes. Start with the teachers. The P(j) teachers can be assigned to the P(j) classes in

P(j) different ways. Selecting M1(j) students for the first class can be done in

N(j) M1(j)

dif-

ferent ways. Selecting the students for the next class can be done in

N(j)-M1(j) M2(j)

different

ways, and so on, implying that the students can be assigned in

P(j)-1 N(j) - t<s Mt(j)

s=1

Ms(j)

214

Stratified Randomized Experiments

different ways. Combining this with the teachers' assignments, the total number of ways the students and teachers for school j can be assigned is

P(j)-1 N(j) - t<s Mt(j) · P(j)!.

s=1

Ms(j)

For each student this is the total number of potential outcomes. Thus, let Wj be the N(j) vector of student assignments for school j, where the ith element of Wj takes on values in the set {1, . . . , P(j)}, indicating which class student i is assigned to. In addition, Tj is the P(j)-dimensional vector of teacher assignments in school j, again with each element of Tj taking on values in the set {1, . . . , P(j)}. Thus we can write the potential outcome for student i in school j as

Yij Wj, Tj . The null hypothesis we consider is

H0 : Yij Wj, Tj = Yij Wj, Tj for all Wj, Tj, Wj, Tj.

The basis for the randomization distribution is the full set of assignments, which are all equally likely. The total number of assignments is obtained by multiplying the number of assignments for each school:

J P(j)-1 j=1 s=1

N(j) - t<s Mt(j) Ms(j)

· P(j)!.

APPENDIX B: PROOFS OF THEOREMS 9.1 AND 9.2

It is convenient to reparametrize the model slightly. Instead of ( , ), we parametrize the model as ( ,  ), where  (j) = (j) - e(j) ·  , which does not change the least squares estimate of  . In terms of ( ,  ), the regression function is





J

J

Yiobs =  · Wi - e(j) · Bi(j) +  (j) · Bi(j) + i.

j=1

j=1

The population values for the parameters are







2

( ,

 )

=

arg min
 ,

E

Yiobs

-



·

Wi

-

J

e(j) · Bi(j) -

J

 (j) · Bi(j)  .

j=1

j=1

Appendix B: Proofs of Theorems 9.1 and 9.2

215

We can write

J

J

Yiobs = (j) · Bi(j) +  (j) · Wi · Bi(j) + i,

j=1

j=1

where (j) = Esp[Yi(0)|Bi(j) = 1] and sp(j) = Esp[Yi(1) - Yi(0)|Bi(j) = 1], and where by definition E[i|Bi(1), . . . , Bi(J), Wi] = 0. Therefore,



J

J

( ,  ) = arg min E 
 ,

(j) · Bi(j) +

 (j) · Wi · Bi(j) - 

j=1

j=1





2

· Wi - J e(j) · Bi(j) - J  (j) · Bi(j) 

j=1

j=1



J

= arg min E 
 ,

Bi(j) · ((j) -  (j) +  (j) · Wi) - 

j=1



2

· Wi - J e(j) · Bi(j) 

j=1

=

arg

min
 ,

  E

 

J j=1

Bi(j)

·

((j)

-



(j)

+



(j)

·

2 Wi) 



J

- 2 ·  · E  Bi(j) · ((j) -  (j) +  (j) · Wi) ·

j=1

+ 2

·

 E Wi

-

J j=1

e(j)

·

Bi(j)2


J
Wi - e(j) · Bi(j) 
m=1

=

arg

min
 ,

  E

 

J j=1

Bi(j)

·

((j)

-



(j)

+



(j)

·

2 Wi) 





J

J

- 2 ·  · E  Bi(j) ·  (j) · Wi · Wi - e(j) · Bi(j) 

j=1

m=1

+2

·

 E Wi

-

J j=1

e(j)

·

2 Bi(j)

 

216

Stratified Randomized Experiments

because E[Wi|Bi1, . . . , Bi(j)] =

J j=1

e(j)

·

Bi(j).

Minimizing

this

over



leads

to

E  =

J j=1

Bi(j)

·



(j)

·

Wi

·

Wi -

J m=1

e(j)

·

Bi(j)

2

.

E

Wi -

J j=1

e(j)

·

Bi(j)

2

Because pr(Wi = 1) =

J j=1

q(j)

·

e(j),

and

pr(Bi(j)

=

1|Wi

=

1)

=

q(j) · e(j)/

J m=1

q(m)

·

e(m),

it

follows

that

the

numerator

is

equal

to

J j=1

e(j)

·

(1

-

e(j))

·

q(j)

·



(j),

and that the denominator is equal to

J j=1

e(j)

·

(1

-

e(j))

·

q(j),

which

finishes

the

proof

of the first part of Theorem 9.1.

The first-order conditions for the estimators (^ ols, ^ ols) are

N
(Yiobs, Wi, Bi1, . . . , Bi(j), ^ ols, ^ ols) = 0,
i=1
where

(y, w, b1 . . . , bJ,  ,  )

 =  w -



J j=1

e(j)

·

bj

·

y- ·

w-

J j=1

e(j)

·

bj

-

J j=1



(j)

·

bj

 .

bj · y -  · w -

J j=1

e(j)

·

bj

-

J j=1



(j)

·

bj

Given the population values of the parameters,   and  , standard M-estimation (or generalized method of moments) results imply that, under standard regularity conditions, the estimator is consistent and asymptotically normally distributed:

 N·

^ols -   ^ -  

  0
- d N 0 , -1 ( 0

 )-1 ,

where the two components of the covariance matrix are

=E

 ( , 

) (Yiobs, Wi, Bi1, . . . , Bi(j),  ,  )

( , )



J j=1

e(j)

·

(1

-

e(j))

·

q(j)

0

...

= E 

0 ...

pt . . . ... . . .

 0

0 ...

 ,

0

0 . . . e(j)

Appendix B: Proofs of Theorems 9.1 and 9.2

217

and

= E (Yiobs, Wi, Bi1, . . . , Bi(j),  ,  ) · (Yiobs, Wi, Bi1, . . . , Bi(j),  ,  )







2

= E Yiobs -   · Wi - J e(j) · Bi(j) - J j · Bi(j)

j=1

j=1

· Wi -

J j=1

e(j)

·

Bi

(j)

Bi(j)

Wi -

J j=1

e(j)

·

Bi

(j)

Bi(j)



2

= E Yiobs -   · Wi - J j · Bi(j)

j=1

· Wi -

J j=1

e(j)

·

Bi

(j)

Wi -

J j=1

e(j)

·

Bi

(j)

.

Bi(j)

Bi(j)

The sampling variance of ^ is the (1, 1) element of the covariance matrix. Because is block diagonal, the (1, 1) element of -1 ( )-1 is equal to the (1, 1) element of
divided by the square of the (1, 1) element of . Hence the sampling variance of ^ ,
normalized by the sample size N, is equal to

E

Wi -

J j=1

q(j)

·

Bi(j)

2
·

Yiobs -   · Wi -

J j=1

  (j)

·

Bi(j)

2

J j=1

q(j)

·

e(j)

·

(1

-

e(j))

2

.

Proof of Theorem 9.2 First write the regression function as

J

J

Yiobs = (j) · Bi(j) +  (j) · Wi · Bi(j) + i.

j=1

j=1

Estimating the parameters of this regression function by OLS leads to

^ols(j)

=

Y tobs (j)

-

Y

obs c

(j),

which is unbiased and consistent for  (j). Then transform the parameter vector from  (J)

to  =

J j=1

q(j)·

(j),

with

inverse

transformation



(J)

=

(

-

J-1 j =1

q(j

)·

(j

))/q(J).

In

terms of the parameters (1), . . . , (j),  (1), . . . ,  (J - 1) and  , the regression function

is equal to

Yiobs

=



·

Wi

·

Bi(J) q(J)

+

J

J-1
(j) · Bi(j) +  (j) · Wi ·

Bi(j)

-

Bi(J)

·

q(j) q(J)

+ i.

j=1

j=1

218

Stratified Randomized Experiments

Thus ^ ols is identical to

J j=1

q(j)

·

^ ols(j),

and

therefore

is

consistent

for

J j=1

q(j)

·

 (j) = sp.

Because the sampling variance of ^ ols(j) is (c2(j)/((1-e(j))·q(j))+t2(j)/(e(j)·q(j))/N,

the sampling variance of

J j=1

q(j) ·

^

ols(j),

normalized

by

N

,

is

N

·

J j=1

q(j)2

·

V(^

ols(j)),

equal to

J j=1

q(j)2(c2(j)/((1

-

e(j))

·

q(j))

+

t2(j)/(e(j)

·

q(j)))).

CHAPTER 10
Pairwise Randomized Experiments
10.1 INTRODUCTION
In the previous chapter we analyzed stratified randomized experiments, where a sample of size N was partitioned into J strata, and within each stratum a completely randomized experiment was conducted. In this chapter we consider a special case of the stratified randomized experiment. Each stratum contains exactly two units, with one randomly selected to be assigned to the treatment group, and the other one assigned to the control group. Such a design is known as a pairwise randomized experiment or paired comparison. Although this can be viewed simply as a special case of a stratified randomized experiment, there are two features of this design that warrant special attention. First, the fact that there is only a single unit in each treatment group in each stratum (or pair in this case) implies that the Neyman sampling variance estimator that we discussed in the chapters on completely randomized experiments (Chapter 6) and stratified randomized experiments (Chapter 9) cannot be used; that estimator requires the presence of at least two units assigned to each treatment in each stratum. Second, each stratum has the same proportion of treated units, which allows us to analyze the within-stratum estimates symmetrically; the natural estimator for the average treatment effect weights each stratum equally.
As in the case of stratified randomized experiments, the motivation for eliminating some of the possible assignments in pairwise randomized experiments is that a priori those values of the assignment vectors that are eliminated are expected to lead to less informative inferences. This argument relies on the within-pair variation in potential outcomes being small relative to the between-pair variation. Often the assignment to pairs is based on covariates. Units are matched to other units based on their similarity in these covariates, with the expectation that this similarity corresponds to similarity in the potential outcomes under each treatment. Suppose, for example, that the treatment is an expensive surgical procedure for a relatively common medical condition. It may not be financially feasible to apply the treatment to many individuals. To increase the precision of an experiment, it may, in such cases, be sensible to use the following steps. First randomly draw J individuals from the target population of individuals who have the condition for which the surgery may be beneficial. Then, for each of these J individuals, find a matching individual in the same population, as similar as possible to the original
219

220

Pairwise Randomized Experiments

unit in terms of the characteristics that may be correlated with potential outcomes and efficacy of the treatment. If the population is relatively large, it may be possible to get very close matches with respect to a large number of characteristics, thereby reducing the variation in treatment-control differences in potential outcomes. Given these J matched pairs, one can then conduct a pairwise randomized experiment by randomly selecting one member of each pair to be assigned to the active treatment.
In this chapter we discuss analyses for such pairwise randomized experiments. In particular we discuss the calculation of Fisher exact p-values and Neyman's repeated sampling perspective, as well as regression and model-based inference. We focus primarily on conceptual issues that are special to this design.
Section 10.2 describes the data set we use to illustrate the concepts discussed in this chapter, which comes from a randomized experiment conducted around 1970 to evaluate the effect of an educational children's television program on reading ability as measured through test scores. Section 10.3 discusses the structure of paired randomized experiments and introduces some additional notation. In 10.4 we discuss the application of Fisher's exact p-value calculations in the setting of paired randomized experiments. Next, in Section 10.5 we discuss the implications of pairwise randomization for the methods discussed in Chapter 6 based on Neyman's repeated sampling perspective. In Sections 10.6 and 10.7 we analyze regression and model-based imputation methods. Section 10.8 concludes.

10.2 THE CHILDREN'S TELEVISION WORKSHOP EXPERIMENT DATA
The Children's Television Workshop experiment was designed by Ball, Bogatz, Rubin, and Beaton (1973) to evaluate The Electric Company, an educational television program aimed at improving reading skills for young children, somewhat similar to Sesame Street. The experiment was conducted in two locations, Youngstown, Ohio, and Fresno, California, where The Electric Company was not broadcast on local stations. In each location a number of schools was selected. Within each school, a pair of two classes was selected. Within each pair, one class was randomly assigned to be shown The Electric Company show during the standard reading-class period, and the other class continued with the regular reading curriculum.
Here we focus on the data from Youngstown, where two first-grade classes from each of eight schools participated in the experiment. The data for the sixteen classes for the Youngstown location from this experiment are displayed in Table 10.1, which presents values of a pre-test score, the post-test score (the primary outcome), an indicator for the pair or school to which the unit belongs, and an indicator for the treatment (one for classes that viewed The Electric Company program, and zero for classes in the control group).

10.3 PAIRWISE RANDOMIZED EXPERIMENTS
A pairwise randomized experiment is a special case of a stratified randomized experiment where the number of units, N, is even, the number of strata is J = N/2, with one

10.3 Pairwise Randomized Experiments

221

Table 10.1. Data from Youngstown Children's Television Workshop Experiment

Pair

Treatment

Pre-Test Score

Post-Test Score

Normalized Rank

Gi

Wi

Xi

Yiobs

Post-Test Score

Ri

1

0

12.9

54.6

1

1

12.0

60.6

2

0

15.1

56.5

2

1

12.3

55.5

3

0

16.8

75.2

3

1

17.2

84.8

4

0

15.8

75.6

4

1

18.9

101.9

5

0

13.9

55.3

5

1

15.3

70.6

6

0

14.5

59.3

6

1

16.6

78.4

7

0

17.0

87.0

7

1

16.0

84.2

8

0

15.8

73.7

8

1

20.1

108.6

-7.5 2.5
-4.5 5.5 0.5 4.5 1.5 7.5
-6.5 -1.5 -3.5
2.5 5.5 3.5 -0.5 7.5

treated unit and one control unit in each stratum (Nt(j) = Nc(j) = 1 and N(j) = 2 for

all j = 1, . . . , J), so that each stratum is a pair. Let Gi be the variable indicating the pair,

with Gi  {1, . . . , N/2}. The pair indicator can be thought of as a function of covariates.

Of course this indicator is a pre-treatment variable in the sense that it is not affected by

the treatment. Within each pair there are

N(j) Nt (j)

=

2 1

= 2 possible assignments, so that

the probability for any assignment vector W is

N/2
p(W|X, Y(0), Y(1)) =
j=1

N(j) Nt(j)

-1 = N/2 1 = 2-N/2, 2
j=1

for W  W+,

where  
W+ = W

  Wi = 1 for j = 1, . . . , N/2  .
i:Gi=j

Because the assignment mechanism fits into the stratified randomized experiments discussed in Chapter 9, we can directly use many of the methods discussed in that chapter. However, there is one important difference. Because all strata have the property that they contain exactly one treated and one control unit, methods that rely on the presence of multiple control or multiple treated units cannot be applied.
To facilitate the discussion of pairwise randomized experiments, it is useful to introduce some additional notation. We arbitrarily label the two units within a pair as units A and B. Then, for all pairs j = 1, . . . , N/2, let (Yj,A(0), Yj,A(1)) and (Yj,B(0), Yj,B(1)) be the potential outcomes for units A and B, respectively, in pair j, and let Wj,A and Wj,B be

222

Pairwise Randomized Experiments

Table 10.2. Potential Outcomes and Covariates from Children's Television Workshop Experiment, from Table 10.1

Pair

Unit A

Yi,A(0) Yi,A(1) Wi,A Yio,Abs Xi,A

1

54.6

?

0 54.6 12.9

2

56.5

?

0 56.5 15.1

3

75.2

?

0 75.2 16.8

4

76.6

?

0 75.6 15.8

5

55.3

?

0 55.3 13.9

6

59.3

?

0 59.3 14.5

7

87.0

?

0 87.0 17.0

8

73.7

?

0 73.7 15.8

Unit B Yi,B(0) Yi,B(1) Wi,B Yio,Bbs Xi,B

?

60.6 1 60.6 12.0

?

55.5 1 55.5 13.9

?

84.8 1 84.8 17.2

? 101.9 1 101.9 18.9

?

70.6 1 70.6 15.3

?

78.4 1 78.4 16.6

?

84.2 1 84.2 16.0

? 108.6 1 108.6 20.1

the treatment indicators for these units. In a pairwise randomized experiment, one unit in each pair is randomly assigned to the active treatment, and the other unit is assigned to the control treatment, thus Wj,A = 1 - Wj,B, with Pr(Wj,A = 1|Y(0), Y(1), X) = 1/2. Define also

Yjo,Abs =

Yj,A(0) if Wj,A = 0, Yj,A(1) if Wj,A = 1,

and Yjo,Bbs =

Yj,B(0) if Wj,A = 1, Yj,B(1) if Wji,A = 0.

The average treatment effect within pair j is pair(j),

pair(j) =

1 2 i:Gi=j

Yi(1) - Yi(0)

=1 2

Yj,A(1) - Yj,A(0) + Yj,B(1) - Yj,B(0)

.

The finite-sample average treatment effect is

fs

=

1 N

N i=1

Yi(1) - Yi(0)

=

2 N

N/2 j=1

pair(j).

Also define the pair of observed variables, one treated and one control from each pair:

Yjo,cbs =

Yjo,Abs if Wi,A = 0, Yjo,Bbs if Wi,A = 1,

and Yjo,tbs =

Yjo,Bbs if Wi,A = 0, Yjo,Abs if Wi,A = 1.

Table 10.2 displays some of these variables for the 16 classes in the Children's Television Workshop Experiment.

10.4 FISHER'S EXACT P-VALUES IN PAIRWISE RANDOMIZED EXPERIMENTS
The same way stratified randomization did not pose any conceptual difficulties for the calculation of Fisher Exact P-values (FEPs), pairwise randomization does not introduce

10.4 Fisher's Exact P-Values in Pairwise Randomized Experiments

223

any new issues. Let us focus in this discussion on the usual Fisher null hypothesis of absolutely no treatment effects for any units,

H0 : Yi(0) = Yi(1), for all i = 1, . . . , N.

With the assignment mechanism fully known, we can, under H0, for any fixed statistic, derive the randomization distribution and thus calculate the corresponding p-value. An obvious statistic is the average, over the J = N/2 pairs, of the difference between the treated and control outcomes within each pair:

Tdif = 1 J J

Yjo,tbs - Yjo,cbs

j=1

=

1J J j=1

Wi,A ·

Yjo,Abs - Yjo,Bbs

+ (1 - Wi,A) ·

Yjo,Bbs - Yjo,Abs

.

Because each pair has a single treated and a single control unit, this also equals the dif-

ference between average outcomes for treated and control units, Tdif =

Y

obs t

-

Y

obs c

,

the statistic that was the starting point of the discussion of the FEP approach in Chapter

5. However, the p-value for this statistic will be different than that calculated under the

randomization distribution considered in Chapter 5 because here the randomization dis-

tribution is based on the assignment mechanism corresponding to a pairwise randomized

experiment, not the assignment mechanism corresponding to a completely randomized experiment, leading to fewer elements in W+.

Alternative statistics include the average of within-pair differences in logarithms or

other transformations of the basic outcomes, such as ranks. To calculate the rank statistic, let Ri be the rank of Yiobs among the N values Y1obs, . . . , YNobs, normalized to have mean zero, and let Rj,A and Rj,B be the rank of the A and B units in pair j, among all N units. For

the Children's Television Workshop data, the ranks for the sixteen classes are displayed

in the last column in Table 10.2. Then the rank statistic is

Trank =

Rt - Rc

=

1J J j=1

Wj,A ·

Rj,A - Rj,B

+ (1 - Wj,A) ·

Rj,B - Rj,A

.

Using ranks in pairwise randomized experiments has the same advantages as using ranks in completely randomized experiments, namely reducing the sensitivity to outliers. Another statistic that is specific to pairwise randomized experiments is based on the average within-pair rank of the observed outcomes. That is, for each pair we calculate an indicator for whether the observed outcome for the treated unit is larger than the observed outcome for the control unit, and an indicator whether the observed outcome for the control unit is larger than the observed outcome for the treated unit. (Using the two indicators, rather than one of the indicators alone, allows for a simpler way of

224

Pairwise Randomized Experiments

dealing with within-pair ties.) We then average the difference between these indicators,

Trank,pair =

2 N/2 N
j=1

1 - 1 Yjo,1bs>Yjo,0bs

Yjo,1bs <Yjo,0bs

,

similar to the statistic Trank,stratum in Chapter 9. Like the rank-based statistic, Trank, this statistic is particularly insensitive to the presence of outliers in the observed potential outcomes, and when there is substantial variation in the level of the outcomes between the pairs, it has more power than the statistic Trank against alternatives under which the treatment effect is constant.
We apply these Fisher exact p-value calculations to the Children's Television Workshop data, using the null hypothesis of no effect whatsoever. Although the p-value is valid only for a single statistic, for illustrative purposes we do the analysis for all three statistics. For the statistic based on the absolute value of the difference in average outcomes by treatment status, we find

Tdif = 13.4, p-value = 0.031.

Using the rank statistic, we find Trank = 3.8, p-value = 0.031.

The last statistic, based on the indicator for whether within the pair the treated outcome was larger or smaller than the control outcome, leads to
Trank,pair = 0.5, p-value = 0.145.

The mechanical reason that the p-value for the within-pair rank statistic is less significant than for the other statistics is that for the two pairs where the outcome for the treated unit is less than the outcome for the control unit in the pair, the difference in outcomes is small. These small differences do not affect the average difference much, but they do affect the within-pair rank statistic. The other two p-values suggest that the television program did affect reading ability at conventional significance levels.

10.5 THE ANALYSIS OF PAIRWISE RANDOMIZED EXPERIMENTS FROM NEYMAN'S REPEATED SAMPLING PERSPECTIVE

Consider first the analysis of the average treatment effect in a single pair. The obvious estimator for the average treatment effect in pair j, pair(j), is

^ pair(j) = Yjo,tbs - Yjo,cbs =

(2 · Wi - 1) · Yiobs.

i:Gi=j

The values of ^ pair(j) for the eight pairs in the Children's Television Workshop data are displayed in Table 10.3.

10.5 The Analysis of Pairwise Randomized Experiments

225

Table 10.3. Observed Outcome Data from Children's Television Workshop Experiment by Pair

Pair Outcome for Control Unit Outcome for Treated Unit Difference

1

54.6

2

56.5

3

75.2

4

75.6

5

55.3

6

59.3

7

87.0

8

73.7

60.6 55.5 84.8 101.9 70.6 78.4 84.2 108.6

6.0 -1.0
9.6 26.3 15.3 19.1 -2.8 34.9

Mean (S.D.)

67.2 (12.2)

80.6 (18.6)

13.4 (13.1)

Next, let us consider inference, first for the within-pair average treatment effect pair(j). For each pair we have a completely randomized experiment with two units of which
one unit is assigned to active treatment. From the results in Chapter 6 on Neyman's repeated sampling approach, it follows that the estimator ^ pair(j) is unbiased for the average treatment effect pair(j) within this pair and that its sampling variance, based on the randomization distribution, is equal to

VW (^ pair(j))

=

Sc(j)2 Nc(j)

+

St2(j) Nt(j)

-

Sct(j)2 . N(j)

With N(j) = 2 and Nc(j) = Nt(j) = 1, this expression simplifies to

VW (^ pair(j))

=

Sc(j)2

+

St2(j)

-

Sct(j)2 . 2

The within-pair variances can be written as

Sc2(j) =
i:Gi=j

Yi(0) - Yj(0)

2

=

1 2

·

Yj,A(0) - Yj,B(0) 2 ,

St2(j) =
i:Pi=j

Yi(1) - Yj(1)

2= 1· 2

Yj,A(1) - Yj,B(1) 2 ,

and

Sc2t(j)

=

1 2

·

Yj,A(1) - Yj,A(0) - Yj,B(1) - Yj,B(0) 2 ,

where

Y j (0)

=

1 2

·

Yj,A(0) + Yj,B(0)

and

Y j (1)

=

1 2

·

Yj,A(1) + Yj,B(1) .

226

Pairwise Randomized Experiments

If the primary interest is in the finite-sample average treatment effect, fs, that is, the within-pair average treatment effect averaged over the N/2 pairs,

fs

=

1 N/2

N/2 j=1

pair(j),

the natural estimator is

^ dif

=

1 N/2

N/2 j=1

^ pair(j)

=

Y

obs t

- Ycobs.

(10.1)

By unbiasedness of the within-pair estimators, ^ is unbiased for the sample average treatment effect, S. Its sampling variance over the randomization distribution is

VW

^ dif

=

1 (N/2)2

N/2

Sc2(j)

+

St2(j)

-

Sc2t(j) 2

.

j=1

So far the discussion is exactly analogous to the discussion for stratified randomized experiments in the previous chapter. However, one of the special features of pairwise randomized experiments, alluded to in the introduction to this chapter, creates a complication for the estimation of the sampling variance. In a completely randomized experiment (and similarly, within a stratum in the stratified randomized experiment), the standard estimator for the sampling variance for the observed difference in treatment and control averages is

V^ neyman

Y

obs t

-

Y

obs c

= s2c + st2 , Nc Nt

with

sc2

=

1 Nc - 1

i:Wi=0

Yi

(0)

-

Y

obs c

2

1

=

Nc - 1 i:Wi=0

Yiobs

-

Y

obs c

2
,

and analogously

s2t

=

1 Nt - 1

i:Wi=1

Yiobs

-

Y

obs t

2
.

Because within each stratum (or pair in this case) the numbers of control and treated units are Nc = Nt = 1, these estimators, sc2 and st2, cannot be used, and the standard estimator for the sampling variance of the estimated overall average effect is not feasible.
One solution to this problem is to assume that the treatment effect is constant and
additive, not only within pairs but also across pairs. Because of the assumption of a
constant treatment effect within pairs, it follows that the within-pair sampling variance is

VW (^ pair(j)) = 2 · S2(j), where S2(j) = Sc2(j) = St2(j).

10.5 The Analysis of Pairwise Randomized Experiments

227

Moreover, if the treatment effect is constant across pairs, pair(j) = S for all j, the within-pair variances are constant, S2(j) = S2 for all j, and

VW

^ dif

=

1 (N/2)2

N/2 j=1

Sc2(j)

+

St2(j)

-

Sc2t(j) 2

= 4 · S2, N

which can be estimated by calculating the sample variance of the pair-level treatment effect estimates:

V^ pair

^ dif

=

N

4 · (N - 2)

·

N/2 j=1

^ pair(j) - ^ dif

2
.

If there is heterogeneity in the treatment effects, then this sampling variance estimator is upwardly biased, and the corresponding confidence intervals will be conservative in the usual statistical sense.

Theorem 10.1 Suppose we have J pairs of units, and randomly assign one unit from each pair to the active treatment and the other unit to the control treatment. Then (i) ^ dif is unbiased for fs, (ii) the sampling variance of ^ dif is

VW

^ dif

=

1 N2

N/2
(Yj,A(0) + Yj,A(1) -
j=1

Yj,B(0) + Yj,B(1) )2,

and (iii) the estimator for the sampling variance

V^ pair

^ dif

=

N

4 · (N - 2)

·

N/2 j=1

^ pair(j) - ^ dif

2
,

satisfies

E V^ pair ^ dif

=

VW (^ dif)

+

N

·

4 (N

-

2)

·

N/2 j=1

pair(j) - 

2,

with the expected value equal to VW (^ dif) if the treatment effect is constant across and within pairs.

Proof of Theorem 10.1: See Appendix.
Let us return to the data from the Children's Television Workshop experiment. The within-pair differences ^ pair(j) are displayed in Table 10.3. Their average is

^ dif = 1 · 8 ^ pair(j) = 13. 4, 8 j=1

228
and its estimated sampling variance is

Pairwise Randomized Experiments

V^ pair

^ dif

=

1

8
·

8 · (8 - 1) j=1

^ pair(j) - ^ dif 2 = 4. 62.

The standard, Gaussian-distribution-based asymptotic 95% confidence interval is

CI0.95(fs) = ^ - 1. 96 × V^ pair ^ dif , ^ + 1. 96 × V^ pair ^ dif

= (4. 3, 22. 5). (10.2)

Because we have only eight pairs of classes, one may wish to use a confidence interval based on the t-distribution with degrees of freedom equal to N/2 - 1 = 7, with 0.975 quantile equal to 2.365, leading to a slightly wider confidence interval

CI0t(.79)5(fs) = ^ - 2. 365 × V^ pair ^ dif , ^ + 2. 365 × V^ pair ^ dif = (2. 5, 24. 3).

(10.3)

Let us now illustrate the benefits of doing a pairwise randomized experiment instead

of a completely randomized experiment. Suppose we had done a completely randomized

experiment and had the same assignment vector. In that case we would have the same

point

estimate

for

the

average

treatment

effect,

namely

^ dif

=

Y

obs t

-

Y

obs c

=

13.

4.

How-

ever, we would have a different estimate of the sampling variance. Using the standard

Neyman estimated sampling variance discussed in Chapter 6, we would have estimated

the sampling variance of the two potential outcomes as

s2c

=

1 Nc - 1

i:Wi=0

Yiobs

-

Y

obs c

2 = 18. 52,

and

st2 = 12. 22,

leading to an estimate for the sampling variance of the estimated average effect of

V^ neyman = s2c + st2 = 7. 82. 88
This sampling variance estimate is substantially larger than the estimate based on the pairwise randomization, V^ pair = 4. 62, because the observed variance of potential outcome within pairs is substantially smaller than it would be if units were randomly assigned to pairs. In other words, in this application, the assignment to pairs is effective, in the sense that it is based on factors that make the within-pair units substantially more similar than randomly selected units, probably leading to substantially more precise estimates.

10.6 Regression-Based Analysis of Pairwise Randomized Experiments

229

10.6 REGRESSION-BASED ANALYSIS OF PAIRWISE RANDOMIZED EXPERIMENTS

In this section the second special feature of pairwise randomized experiments, alluded to in the introduction of this chapter, motivates an analysis that is different from that discussed for stratified randomized experiments. In the discussions of regression-based analyses in completely and stratified randomized experiments, the basic outcome in the analysis was Yiobs, the observed outcome for unit i. Here, instead, we use as the primary outcome in the regression analysis the within-pair difference in observed outcomes of the treated and the control unit in the pair,

^ pair(j) = Yjo,tbs - Yjo,cbs,

with the pair serving as the unit of analysis. We take a super-population perspective, where the pairs of units are drawn randomly from a large population, and one member of each pair is randomly assigned to the treatment group, and the other to the control group. The population average treatment effect is sp = Esp[pair(j)], with the expectation taken over the random sampling of the pairs.
The standard estimator for the average treatment effect in a pairwise randomized experiment is the simple average of the within-pair differences,

^ dif =

2

N/2
^ pair(j).

N j=1

This estimator can also be interpreted as a regression estimator, where the regression function is specified simply as a constant:

^ pair(j) = sp + j.

The more interesting question is how to include additional covariates, beyond the implicit use of the pair indicators, into the regression function. As before, because of the randomization, we do not need to include additional covariates in order to remove bias, because the estimator ^ is unbiased over the randomization distribution without including covariates. The goal when including additional covariates is to improve the precision of the estimator in cases where the covariates are strongly correlated with the treatmentcontrol differences in potential outcomes. Before discussing particular specifications, we first define Xj,A and Xj,B to be the covariate values for units A and B respectively within pair j. Then we define the within-pair observed difference in covariates between the treated and control units,

X,j = Wj,A · Xj,A - Xj,B + (1 - Wj,A) · Xj,B - Xj,A , and the average covariate value within the pair,

Xj = Xj,A + Xj,B /2.

230

Pairwise Randomized Experiments

There are two leading approaches to including the covariates in the regression analysis. First, we can include them in the form of the within-pair difference X,j. This is an attractive option if one thinks the conditional expectation given covariates of the pairwise difference of potential outcomes is additive and linear in the treatment minus control difference in covariates. In other words, the inclusion of X,j in the regression function makes sense if the covariate Xi is associated with both potential outcomes Yi(0) and Yi(1) to approximately equal degrees. Second, we can include the average value of the covariates Xj. This is a natural specification if one thinks the treatment effect, the difference in potential treated and control outcomes, rather than the level of the potential outcomes, is linear in the covariates. The most general version of the regression function we consider includes the covariates both as within-pair differences and pair averages, where the latter is in deviations from the overall covariate mean X:

^ pair(j) =  +  · X,j +  · (Xj - X) + j.
Let ( , ,  ) be the population values, defined analogously to the way they were defined in Chapter 7:

 , ,   = arg min E
 ,,

^ pair(j) -  -  ·

2
X,j -  · (Xj - X) ,

where X = Esp(X) is the super-population mean of Xi. Here we use again the convention that the expectation operator without subscript is both over the randomiza-
tion distribution and over the distribution induced by the random sampling from the super-population. Also let (^ ols, ^ ols, ^ ols) be the least squares estimators,

N
(^ ols, ^ ols, ^ ols) = arg min
 ,,

^ pair(j) -  -  ·

2
X,j -  · (Xj - X) .

i=1

Theorem 10.2 Suppose we conduct a pairwise randomized experiment in a sample of pairs drawn at random from the super-population. Then, (i),

  = sp,

and (ii),

 N· ^ ols - sp

- d N

0, Esp

^ pair(j) -   -  · X,j -   · (Xj - X) 2

.

Proof of Theorem 10.2 See Appendix. Now let us estimate the average treatment effect using four different specifications for the regression function. First, for the regression model with only a constant, the least squares estimator for  is

^ ols =

2

N/2
^ pair(j) = ^ dif,

N j=1

10.7 Model-Based Analysis of Pairwise Randomized Experiments

231

equal to the estimator in Equation (10.1). Note that we do not directly include the treatment indicator, because the unit of the least squares analysis here is the pair, not the individual unit. Applying this to the Children's Television experiment data leads to
^ ols = 13.4 (s. e. 4.3)

(standard errors in brackets). The next specification for the regression function includes the within-pair difference X,j:
^ pair(j) =  +  · X,j + j.

With the Children's Television Workshop data, this specification leads to

^pair(j) = 9.0 + 5.4 × X,j, (1.5) (0.6)

with a substantially smaller standard error for ^ ols, 1.5 instead of 4.3, because the covariate X,j is a strong predictor of the observed within-pair difference in outcomes. The next specification includes Xj as an additional regressor.

^pair(j) =  +  · Xj + j.

This leads to
^ pair(j) = 13.4 + 3.9 × Xj. (3.5) (1.7)

Whereas including X,j in the regression reduced the standard error of the estimator of the average treatment effect from 4.3 to 1.5, including Xj instead of X,j gives a standard error of 3.5. The final specification includes both X,j and Xj, leading to

^ pair(j) = 8.5 + 5.9 × X,j -1.0 × Xj,

(1.5) (0.8)

(0.7)

with again a substantial reduction of the standard error, to 1.5, relative to that using the specification without covariates, but basically the same as the specification that includes only X,j but not Xj.

10.7 MODEL-BASED ANALYSIS OF PAIRWISE RANDOMIZED EXPERIMENTS
In principle the model-based imputation approach to the analysis of pairwise randomized experiments is little different from that for the case of stratified randomized experiments. In both cases we can carry out the analysis using the covariate that indicates pair or stratum membership, Gi. In practice, the fact that each pair contains only two units implies that we cannot be as flexible regarding the specification of the joint distribution of the potential outcomes within pairs as would be possible within strata in the stratified

232

Pairwise Randomized Experiments

case where we have a larger number of units in each stratum. More appropriate is an analysis with some structure on the variance within pairs, such as a hierarchial structure.
The starting point is, as in the chapter on the model-based approach to completely randomized experiments, a model for the joint distribution of the potential outcomes given the covariates, including the pair indicators, in terms of an unknown vector parameter :

f (Y(0), Y(1)|X, G, ),

in combination with a prior distribution on , p(). These two components, in combination with the known assignment mechanism, allow us to obtain the joint distribution of the missing potential outcomes Ymis given the observed data (X, G, Yobs, W), and thus allow us to obtain the posterior distribution of the estimand of interest (e.g., the average effect of the treatment).
First we assume that, conditional on (X, G, W) and the parameter , the potential outcomes are independent by the usual appeal to de Finetti's theorem:

N
f (Y(0), Y(1)|X, G, W,  ) = f (Yi(0), Yi(1)|Xi, Gi,  ),
i=1
where we implicitly assume that the parameters governing the marginal distribution of (Xi, Gi) are distinct from . The specific model we consider has a hierarchical structure, with pair-specific mean parameters j, for j = 1, . . . , J. Conditional on pair indicators, covariates, and parameters,

Yi(0) Yi(1)

Gi = j, Xi = x, (1), . . . , (N/2),  , , c2, t2

N

(j) + x ·  (j) +  + x · 

,

c2 0 0 t2

.

Conditional on pair-specific mean parameters j, and common parameters  and , we assume that the mean of the two potential outcomes is linear in x. We assume the

variances are constant across pairs but allow them to differ between potential outcomes.

This model is similar in spirit to the regression model where the difference in within-

pair observed outcomes was modeled as linear in the difference in within-pair covariate

values. Note that given this model, the parameter  corresponds to the super-population

average treatment effect, sp. However, in this discussion we focus on inference for the finite-sample average treatment effect, fs, by multiply imputing the missing potential outcomes. For that reason, the interpretation of the parameters in the statistical model is

incidental.

Next, we specify a model for the pair-specific means j:





(1)

    2 . . .

 0

 ...  G, X, W,  , , c2, t2,   N  ...  ,  ... . . . ...  .

(N/2)



0 . . . 2

Just as in the previous chapter, using simulation methods is generally essential here for the purpose of doing inference. Even in simple cases, there are no analytic expressions

10.8 Conclusion

233

Table 10.4. Posterior Moments and Quantiles for Youngstown Children's Television Workshop Experiment Data from Table 10.1

Parameter
  ln (c) ln (t)  ln ()

Mean
8.6 5.9 1.1 0.5 -9.2 1.5

(S.D.)
(1.6) (0.6) (0.5) (0.7) (2.2) (0.4)

Quantiles

0.025

0.975

5.1 4.8 -0.3 -0.8 -13.6 0.4

11.7 7.0 1.9 1.7 -4.7 2.2

for the posterior distributions for estimands of interest in such hierarchical models. However, as we discussed in Chapter 8, this is of no intrinsic importance. Modern Bayesian simulation methods offer efficient algorithms for drawing from the posterior distribution of the estimands given the data. We provide some details in the Appendix for this specific case.
We now implement this model on the Children's Television Workshop data. The single covariate Xi is the pre-test score. We specify independent prior distributions for , 2, c2, t2,  , and . For the mean parameters (,  , ), we use normal prior distributions centered at zero, with variance 1002. For the three variance parameters (2, c2, t2), we use, as we did in Chapter 8, inverse Chi-squared distributions, here with parameters 1 and 1. Based on the Children's Television Workshop data, the posterior mean and variance for the average treatment effect are

E[fs|Yobs, W, X, G] = 8.4,

V(fs|Yobs, W, X, G) = 1.72.

These estimates are quite similar to those for the regression model with the covariate equal to differences in pre-treatment variables, where we estimated the average effect to be 9.0 with a standard error of 1.5. In Table 10.4 we report posterior means, standard deviations, as well as upper and lower limits for 95% posterior intervals for all parameters.

10.8 CONCLUSION
In this chapter we analyzed a special case of stratified randomized experiments: paired randomized experiments. In this special case, each of the strata, now called pairs, contains two units, one assigned to the treatment group and one assigned to the control group. This simplifies some analyses and complicates others. The Fisher exact p-value approach is conceptually not affected by the restrictions on the set of assignments. The Neyman and model-based analyses are modified to take account of the special features of this design. Within each pair there is a natural estimator for the treatment effect, namely the difference in observed outcomes for the treated unit in the pair and the control unit in the same pair. Estimation of the sampling variance for estimators is more complicated in the pairwise randomized experiment because we cannot estimate the sampling variance within each pair separately the way we could estimate the sampling

234

Pairwise Randomized Experiments

variance within each stratum in the previous chapter on randomized block designs. In the Neyman analysis, we therefore focus on a statistically conservative estimator for the overall sampling variance, based on the sample variance of the within-pair differences. In the regression analyses, the differences between the stratified randomized experiment case and the pairwise randomized experiment case are reflected by the focus on the within-pair difference in outcomes as the dependent variable and the pair as the unit of analysis. Finally, just like in the randomized block design, in the model-based analyses the difference between a completely randomized and a pairwise randomized experiment is reflected by the utility of a hierarchical structure for the latter case.

NOTES
The Children's Television Workshop experiment is discussed in detail in Ball, Bogatz, Rubin, and Beaton (1973). See also Gelman and Hill (2006).
The analysis of pairwise randomized experiments is discussed in detail in standard references on classical experimental design: Hinkelmann and Kempthorne (2005, 2008), Cox and Reid (2000), Cox (1958), and Snedecor and Cochran (1967, 1989). To address the issue of the variance estimation, Lynn and McCulloch (1992) suggest estimating the variance assuming homoskedasticity, ignoring the paired design. See also Donner (1987), Diehr, Martin, Koepsell, and Cheadle (1995). Shipley, Smith, and Dramaix (1989) discuss power calculations for pairwise randomized experiments. Rosenbaum (1989b) analyzes optimal matching strategies to construct matched samples that can then be analyzed using the methods for pairwise randomized experiments discussed in this chapter.
Imai (2008) obtains the same expression for the statistically conservative estimator of the sampling variance as we do in Theorem 10.1.

APPENDIX: PROOFS

Proof of Theorem 10.1 Within each pair we have a completely randomized experiment. Therefore we can use the results on the sampling variance from Chapter 6. This directly implies unbiasedness of ^pair(j) for pair(j), and thus unbiasedness of ^ for fs. This proves part (i) of the theorem.
Next consider part (ii). The sampling variance expression from Chapter 6 implies

VW (^ pair(j))

=

Sc(j)2 Nc(j)

+

St2(j) Nt(j)

-

Sc2t(j) . N(j)

With N(j) = 2 and Nc(j) = Nt(j) = 1, this expression simplifies to

VW (^pair(j))

=

Sc(j)2

+

St2(j)

-

Sc2t(j) . 2

The within-pair variances can be written as

Sc2(j) =

Yi(0) - Yj(0) 2 ,

i:Gi=j

Appendix: Proofs

235

St2(j) =

Yi(1) - Yj(1) 2 ,

i:Gi=j

and

Sc2t(j) =

Yi(1) - Yi(0) - pair(j) 2 ,

i:Gi=j

where

Y j (0)

=

1 2

·

Yi(0)
i:Gi=j

=

1 2

·

Yj,A(0) + Yj,B(0) ,

and

1

1

Y j (1)

=

2

·

Yi(1)
i:Gi=j

=

2

·

Yj,A(1) + Yj,B(1) .

Because pair j comprises two units, indexed by A and B, we can rewrite these expressions as

Sc2(j)

=

1 2

·

Yj,A(0) - Yj,B(0) 2 ,

St2(j)

=

1 2

·

Yj,A(1) - Yj,B(1) 2 ,

and

Sc2t(j)

=

1 2

·

Yj,A(1) - Yj,A(0) - Yj,B(1) - Yj,B(0) 2 .

Hence the sampling variance of ^ dif = (2/N)

N/2 j=1

^

pair(j)

is

VW (^ dif)

=

4 N2

N/2

VW (^ pair(j))

=

4 N2

N/2

Sc(j)2

+

St2(j)

-

Sc2t(j) 2

.

j=1

j=1

Substituting for Sc2(j), St2(j), and Sc2t(j) leads to

VW (^ dif)

=

1 N2

N/2

2·

Yj,A(0) - Yj,B(0) 2 + 2 · Yj,A(1) - Yj,B(1) 2

j=1

- Yj,A(1) - Yj,A(0) - Yj,B(1) - Yj,B(0) 2 ,

which simplifies to

VW (^ dif)

=

1 N2

N/2 j=1

Yj,A(0) + Yj,A(1) -

Yj,B(0) + Yj,B(1)

2.

Finally, consider part (iii). If the treatment effect is constant, then Yj,A(1) = Yj,A(0)+ and Yj,B(1) = Yj,B(0) +  for all j. Hence the expression for the sampling variance

236

Pairwise Randomized Experiments

simplifies to

VW (^ )

=

1 N2

N/2 j=1

Yj,A(0) + Yj,A(1) -

Yj,B(0) + Yj,B(1)

2

=

1 N2

N/2 j=1

2 · Yj,A(0) +  -

2 · Yj,B(0) + 

2

=

4 N2

N/2 j=1

Yj,A(0) - Yj,B(0) 2 .

Now consider the variance estimator V^ pair,

V^ pair

=

N

·

4 (N -

2)

·

N/2 j=1

^ pair(j) - ^

2
.

We calculate the expectation of V^ pair. Note that

EW ^ pair(j) = pair(j),

and EW ^ pair(j) · ^ pair(k) =

pair(j) · pair(k)

if j = k,

pair(j)2

+

1 4

·

Yj,A(0) + Yj,A(1) -

Yj,B(0) + Yj,B(1)

2

if j = k.

Then:


N/2
E
j=1

^ pair(j) - ^ dif

 

2

=

E

N/2


^

pair(j)

-

2

·

N/2

2

^ pair(k) 

N

j=1

k=1


N/2
= E  ^ pair(j)2 -

4

·

N/2

N/2
^ pair(j) · ^ pair(k) +

2


N/2

2

 ^ pair(k) 

N

N

j=1

j=1 k=1

k=1





N/2
= E  ^ pair(j)2 -

4

·

N/2

N/2
^ pair(j) · ^ pair(k) +

2

N/2

N/2
^ pair(j) · ^ pair(k)

N

j=1

j=1 k=1

N
j=1 k=1



N/2
= E  ^ pair(j)2 -

4

·

N/2
^ pair(j)2 -

4

·

N/2

^ pair(j) · ^ pair(k)

N

N

j=1

j=1

j=1 k=j



+

2

N/2
^ pair(j)2 +

2

N/2

^ pair(j) · ^ pair(k)

N j=1

N j=1 k=j

Appendix: Proofs

237









=

N-2

N/2
· E  ^ pair(j)2 -

2

N/2
·E

^ pair(j) · ^ pair(k)

N

j=1

N

j=1 k=j

=

N-2 N

·

N/2
pair(j)2
j=1

-

2 N

·

N/2 j=1

k=j

pair(j) · pair(k)

N - 2 N/2

+

4·N

·
j=1

Yj,A(0) + Yj,A(1) -

Yj,B(0) + Yj,B(1)

2

N/2
=
j=1

pair(j) - S

2+

N · (N - 2) 4

· VW

^ dif

.

Thus, E V^ pair





=

E

 N

·

4 (N

-

2)

·

N/2 j=1

^ pair(j) - ^ dif 2



=

4

N/2
·

N · (N - 2) j=1

pair(j) - fs

2+

N · (N - 2) 4

· VW

 ^ dif 

= VW

^ dif

+

4

N/2
·

N · (N - 2) j=1

pair(j) - fs 2 .

Proof of Theorem 10.2 First let us expand the expectation:

E

^ pair(j) -  -  ·

2
X,j -  · (Xj - X)

(A.1)

= Esp EW

^ pair(j) -  -  ·

2
X,j -  · (Xj - X)

= Esp EW pair(j) -  -  · X,j -  · (Xj - X) 2 + Esp EW ^ pair(j) - pair(j) 2

(A.2)

+ 2 · Esp EW ^pair(j) - pair(j) · pair(j) -  -  · X,j -  · (Xj - X) .

Consider the three terms separately. The first term equals

Esp EW pair(j) -  -  · X,j -  · (Xj - X) 2

= Esp EW

pair(j) -  -  · (Xj - X) 2

+ Esp EW

·

2 X,j

- 2 ·  · Esp EW X,j pair(j) -  -  · (Xj - X)

238

Pairwise Randomized Experiments

= Esp pair(j) -  -  · (Xj - X) 2 + 2 · E

2 X,j

= Esp pair(j) -  2 + Esp  · (Xj - X) 2

- 2 · Esp pair(j) -  ·  · (Xj - X) + 2 · E

2 X,j

= Esp pair(j) -  2 +  2 · Esp Xj - X 2

- 2 · Esp pair(j) ·  · (Xj - X) + 2 · E

2 X,j

.

The second term equals

Esp EW ^ pair(j) - pair(j) 2

= Esp

1· 4

Yj,A(0) + Yj,A(1) -

Yj,B(0) + Yj,B(1)

2,

which does not depend on the parameters ( , ,  ), and therefore can be ignored for the purpose of determining the minimand of the objective function (A.1).
The third term equals

2 · Esp EW ^ pair(j) - pair(j) · pair(j) -  -  · X,j -  · (Xj - X) = -2 ·  · Esp EW ^pair(j) - pair(j) · X,j = -2 ·  · E ^pair(j) - pair(j) · X,j .

Collecting the terms that depend on ( , ,  ) leads to

= Esp pair(j) -  2 +  2 · Esp Xj - X 2

- 2 ·  · Esp pair(j) · (Xj - X) + 2 · E

2 X,j

- 2 ·  · E ^pair(j) - pair(j) · X,j .

Minimizing this over ( , ,  ) leads to

  = Esp pair(j) = sp,

  = Esp pair(j) · (Xj - X) , and  = Esp ^pair(j) - pair(j) · X,j .

Esp Xj - X 2

Esp

2 X,j

Next, consider part (ii) of the theorem:

N

(^ ols, ^ ols, ^ ols) = arg min
 ,, i=1

^pair(j) -  -  ·

X,j -  · (Xj - X) 2 .

(A.3)

Appendix: Proofs

239

Define Y,j = ^ pair(j) and ^ = X. The first-order conditions for the estimators (^ ols, ^ ols, ^ ols, ^ ols) in the minimization problem (A.3) are

N/2
( Y,j, X,j, Xj, ^ , ^ , ^ , ^ ) = 0,
j=1

where



y -  -  · x -  · (x - )



(

y,

x, x,  , ,  , ) = 

x· (x - ) ·

y -  -  · x -  · (x - ) y -  -  · x -  · (x - )

 .

x-

By the same arguments as used in the proofs in Chapter 7,

 ^ ols - sp 

  0



 N

·



^ ols -  ^ ols -  

 - d N 

0 0

 ,

-1

(

)-1 ,

^ ols - X

0

where the two components of the covariance matrix are

=E

 (

,

 ,



,

)



and

Y,j, X,j, Xj,  , ,  , 
(sp,, ,X )

= E  Y,j, X,j, Xj, sp, ,  , X ·  Y,j, X,j, Xj, sp, ,  , X .


-1

= 

-E X,j -E X - X

-E X,j

-E

2 X,j

-E X,j · X - X

0

0

 -1

0

0

=  0
0

-E

2 X,j

0

0 -E Xj - X 2

0

0

0

-E X - X

-E X,j · X - X

-E
 

X - X 2 0

0  .
0 -1





  · E X,j 2 ·   · E Xj - X



-1

Thus V(^ ols), the (1, 1) element of -1 ( )-1, is equal to 11 -   · 14, where km is the (k, m) element of . Because

14 = E Y,j - sp -  · X,j -   · (Xj - X) · Xj - X = 0, it follows that the (1, 1) element of -1 ( )-1 is equal to

Vsp(^ ols) = 11 = E Y,j - sp -  · X,j -   · (x - X) 2 .

CHAPTER 11
Case Study: An Experimental Evaluation of a Labor Market Program
11.1 INTRODUCTION
In this chapter we illustrate some of the methods discussed in the previous chapters in an application. The application involves a social program designed to improve labor market outcomes for individuals with relatively poor skills and labor market histories: the Saturation Work Initiative Model (SWIM) program in San Diego, evaluated during the period 1985­1987. As is typical, a substantial amount of background information on the individuals in the program was collected, including demographics and recent labor market histories, allowing us to investigate heterogeneity in the effects of the program. The outcomes of interest, post-program earnings and employment records, are either discrete or mixed discrete-continuous, suggesting that constant additive treatment-effect assumptions are typically not plausible.
Using these data we will calculate Fisher exact p-values for sharp null hypotheses and construct Neyman large-sample confidence intervals. We will also discuss, in detail, regression and model-based inferences for various average treatment effects, using the covariates to increase precision as well as to estimate treatment effects for subpopulations. We emphasize the model selection choices and the various other decisions faced by researchers.
11.2 THE SAN DIEGO SWIM PROGRAM DATA
SWIM primarily targeted women who were eligible for Aid to Families with Dependent Children (AFDC), with children at least six years old (although, as the summary statistics show, there was a substantial proportion of women with younger children, a small number of men, and some individuals with no children). It was a mandatory program, with fairly strong participation enforcement, and provided a sequence of group job search, unpaid work experience, education, and job skills training. Compared to similar programs in other locations, it had broad coverage, with the intention to reach a wide range of individuals eligible for AFDC, including those who may not have participated in such assistance programs. The average cost of participating in this program was $919 per trainee, paid for by the local authorities. The participants faced no direct
240

11.2 The San Diego SWIM Program Data

241

Table 11.1. Summary Statistics San Diego SWIM Data

Variable

All (N = 3211)

Controls (Nc = 1607)

Treated (Nt = 1604)

Mean (S.D.) Mean (S.D.) Mean (S.D.)

Pre-treatment variables

female female

0.91 (0.28) 0.92 (0.28) 0.91 (0.28)

agege35 (age  35)

0.46 (0.50) 0.46 (0.50) 0.46 (0.50)

hsdip

(high school diploma)

0.56 (0.50) 0.56 (0.50) 0.56 (0.50)

nevmar (never married)

0.30 (0.46) 0.30 (0.46) 0.30 (0.46)

divwid (divorced or widowed)

0.37 (0.48) 0.37 (0.48) 0.36 (0.48)

numchild (number of children)

1.76 (1.08) 1.76 (1.07) 1.76 (1.10)

chldlt6 (children younger than 6)

0.10 (0.30) 0.10 (0.31) 0.10 (0.29)

af-amer (african-american)

0.42 (0.49) 0.43 (0.49) 0.42 (0.49)

hisp

(hispanic)

0.25 (0.44) 0.25 (0.43) 0.26 (0.44)

earnyrm1 (earnings year minus 1)

1.57 (3.54) 1.60 (3.56) 1.53 (3.51)

empyrm1 (positive earnings year minus 1) 0.39 (0.49) 0.40 (0.49) 0.39 (0.49)

Outcomes variables earnyr1 (earnings year 1) empyr1 (positive earnings year 1) earnyr2 (earnings year 2) empyr2 (positive earnings year 2)

1.85 (3.78) 1.69 (3.76) 2.02 (3.80) 0.46 (0.50) 0.40 (0.49) 0.52 (0.50) 2.57 (5.08) 2.26 (4.68) 2.89 (5.44) 0.45 (0.50) 0.40 (0.49) 0.49 (0.50)

expenses for the program, although there are likely to have been indirect costs, such as child care and travel expenses. The evaluation started in 1985. Eligible individuals enrolled in the study were randomized to receive training or not. The randomization did use demographics and labor market histories. This program is typical of many labor market programs in the 1980s and 1990s, a substantial number of which were evaluated using randomized experiments. The general emphasis on experimental evaluations around this time was motivated by research (most notably a paper by Lalonde published in 1986, whose data we use in other chapters) that had concluded that non-experimental evaluations (in practice with analyses limited to linear covariance adjustment or regression methods) were often unable to replicate experimental results, and therefore claimed that non-experimental evaluations were not credible in these settings. See the notes at the end of this chapter for more discussion on this topic.
Table 11.1 presents some summary statistics for this data set. We have information on N = 3,211 individuals, with Nt = 1,604 randomly assigned to receive the training, and the remaining Nc = 1,607 assigned to the control group, which was not to receive any training as part of the SWIM program. Individuals in the control group had no access to SWIM program services but may have had access to other, possibly similar, services outside of the SWIM program. This is a common problem with social programs, where individuals assigned to the control group often have access to related programs. This feature implies that the effects should be interpreted as the effect of participating in the program versus being denied access to this particular program, rather than as the effect of participating versus not participating in any job-training program.

242

Case Study: An Experimental Evaluation of a Labor Market Program

There are two sets of pre-treatment variables. First there are some covariates measuring individual-level background characteristics. These pre-treatment variables include whether the individual had a high school diploma, was female (female), was at least 35 years old (agege35), had a high school diploma (hsdip), had never married (nevmar), and was divorced or widowed (divwid), the number of children (numchild); whether any children were present in the household who were younger than six (chldlt6); and whether the individual was African-American (af-amer) or Hispanic (hisp). Second, there are records for earnings for the year prior to the randomization. We use both the actual earnings measure (earnyrm1) and an indicator for positive earnings in this pre-randomization year (empyrm1). The outcome variables of interest are total earnings in the first and second year post-randomization (earnyr1 and earnyr2) and indicators for these earnings being positive. For these covariates and the outcome variables, means and standard deviations for the entire sample, as well as means and standard deviations by treatment status, are displayed in Table 11.1. Notice that approximately 60% of the participants have no earning the year prior to the assignment, suggesting that simple gain scores may not be particularly helpful. All earnings variables are yearly earnings, measured in thousands of dollars.

11.3 FISHER'S EXACT P-VALUES

First we analyze the experimental data using Fisher's exact p-value approach discussed in Chapter 5. We focus on tests of the null hypothesis that there is no effect of the program for any individual:

H0 : Yi(0) = Yi(1), for i = 1, . . . , N.

We calculate the p-values for tests of this null hypothesis for a variety of test statistics using the first and second year post-program earnings (empyr1 and empyr2) as the outcomes. We analyze the full sample and, separately, the subsamples created by whether individuals had graduated from high school. Table 11.2 contains all the p-values discussed in the text. Although for illustrative purposes we calculate a large number of p-values, we should note that the formal interpretation of each holds for one p-value at a time.
Our primary p-value is based on the difference in ranks in first year post-program earnings. As before, we define the normalized rank as:

N

1

Ri =

1Yiobs<Yiobs + 2

i =1

N

1+

1Yiobs =Yiobs

i =1

-

N

+

1 .

2

Then the rank-based test statistic is

Trank = Rt - Rc ,

where Rt and Rc are the average ranks in the treatment and control groups respectively. The average rank is higher for individuals in the treatment group than for individuals in

11.3 Fisher's Exact P-Values

243

Table 11.2. P-Values for Fisher Exact Tests on San Diego SWIM Data (based on 1,000,000 draws from randomization distribution)

Post-Program Earnings Year 1
Year 2

Statistic

All (3,211)

T rank T rank-gain T dif T rank T rank-gain T dif

< 0.0001 < 0.0001
0.0131 < 0.0001 < 0.0001
0.0004

No High School (1,409)
< 0.0001 < 0.0001
0.0051 0.0017 0.0020 0.0980

High School (1,802)
0.0014 0.0001 0.1967 < 0.0001 0.0002 0.0018

the control group, leading to a p-value less than 0.0001, strong evidence against the null

hypothesis of no effect of the treatment.

For comparison purposes, we report p-values for two other statistics. The first of these

exploits the additional information in the form of the covariates. Specifically, because

we have values for earnings prior to the program, we may wish to base the test statistic

on the rank of the gains, rather than the rank of the level of earnings. Let Xi denote the

level of prior earnings. Then the rank of the gains is defined as





Ri =

N

1Yjobs -Xj <Yiobs -Xi

+

1 2

1

+

N

1Yjobs-Xj=Yiobs-Xi 

-

N

+ 2

1 .

j=1

j=1

Then the rank-based test statistic is

Trank,gain = R t - R c ,

where R t and R c are the average ranks of the gain in the treatment and control groups respectively. The p-values based on this statistic are similar to those based on the simple rank statistic. In both cases the evidence against the null is strong for the full sample and for the subsamples based on whether the individuals have a high school degree or not.
The third statistic is the widely (perhaps too widely) used difference in means of the observed outcomes:

Tdif =

Y

obs t

-

Y

obs c

.

Here the evidence against the null hypothesis is statistically significant at conventional levels in most cases, although not quite as strong as for the rank-based tests. The reason appears to be that the distribution of the outcome is heavily skewed. About 50% of the individuals have positive earnings in either Year 1 or Year 2 post-treatment. Figures 11.1 and 11.2 present histograms of the level of earnings and its logarithm, for those with positive earnings. For such distributions, rank-based tests tend to be more sensitive to violations of the null hypothesis of no effect of the treatment than tests based on averages of the levels.
In principle, we can also use sequences of Fisher tests to create Fisher intervals as described in Chapter 5. Such Fisher intervals require specification of the treatment effect for each unit. In most cases we would implement this by considering the set of values c

244

Case Study: An Experimental Evaluation of a Labor Market Program

0.4

0.35

0.3

0.25

Density

0.2

0.15

0.1

0.05

0

0

5 10 15 20 25 30 35 40 45 50

Earnings

Solid curve is normal approximation, vertical tall line is mean, vertical dashed line is median, short vertical solid lines are 0.25 and 0.75 quantiles.

Figure 11.1. Histogram-based estimate of the distribution of Year 1 earnings, for those with positive earnings, San Diego SWIM program data

0.4

0.35

0.3

0.25

Density

0.2

0.15

0.1

0.05

0

-6 -5 -4 -3 -2 -1 0

1

2

3

4

Logarithm of Earnings

Solid curve is normal approximation, vertical tall line is mean, vertical dashed line is median, short vertical solid lines are 0.25 and 0.75 quantiles.

Figure 11.2. Histogram-based estimate of the distribution of the logarithm of year 1 earnings, for those with positive earnings, San Diego SWIM program data

such that we cannot reject the null hypothesis of a constant treatment effect equal to c. In this data set, such an approach is possible, but it is not attractive. Many individuals have earnings equal to zero in some year, because they do not have a job in that year. It is difficult to imagine that the training program would move all these individuals to some positive amount of earnings. On substantive grounds it is therefore extremely unlikely that there is a constant treatment effect, even after considering transformations of the outcome. We will therefore not pursue this strategy.

11.4 Neyman's Repeated Sampling-Based Point Estimates

245

11.4 NEYMAN'S REPEATED SAMPLING-BASED POINT ESTIMATES AND LARGE-SAMPLE CONFIDENCE INTERVALS

In this section we apply Neyman's repeated sampling approach. For the full sample, as well as various subsamples, we estimate the average treatment effect on earnings in the first year after the program, and construct confidence intervals for this average effect. The results for these analyses are displayed in Table 11.3.
First we consider the full sample. The simple difference in average treatment and control outcomes is

^ dif

=

Y

obs t

-

Y

obs c

=

2.02

-

1.69

=

0.33,

(11.1)

with sampling variance

VW ^ dif = E

Y

obs t

-

Y

obs c

-

fs

2

= Sc2 + St2 - St2c . Nc Nt N

Using the standard estimator for this sampling variance discussed in Chapter 6, we find

V^ neyman = s2c + st2 = 3.762 + 3.802 = 0.132. Nc Nt 1607 1604

The implied large sample 95% confidence interval is

 CI0.95(fs) = ^ dif - 1.96 ·

s2c + st2 , ^ dif + 1.96 · Nc Nt

 s2c + st2  = (0.07, 0.59). Nc Nt

(11.2)

Next, we carry out the same calculations for some subpopulations. This serves two purposes. First, we may be interested in average treatment effects by subpopulations. Second, it may lead to more precise estimates of the overall average treatment effect. We begin by partitioning the sample into those at least thirty-five years old and those younger than thirty-five. The subsample of older individuals consists of 1,473 individuals, and the younger subsample consists of 1,738 individuals. For the older group we find

^ dif(old) = 0.50 (s. e. 0.21),

CI0.95(fs(old)) = (0.09, 0.91).

For the younger group the estimated average treatment effect is

^ dif(young) = 0.19 (s. e. 0.17),

CI0.95(fs(young)) = (-0.14, 0.51).

Next we partition the sample into those with no employment experience during the pre-program period, as indicated by zero earnings in the pre-program year (empyrm1 equal to zero, which holds for 1,949 individuals) versus those with positive experience (1,262 individuals with empyrm1 equal to one). For the the first group, the estimated effect and associated estimated standard error are

246

Case Study: An Experimental Evaluation of a Labor Market Program

Table 11.3. Estimates for Average Treatment Effects on Year 1 Earnings Based on Neyman's Repeated Sampling Approach, San Diego SWIM Program Data

Post-Program Earnings

All Young Old Unemployed Employed No HS HS

(3,211) (1,738) (1,473) (1,949)

(1,262) (1,409) (1,802)

Year 1

Est

0.33 0.19 0.50

(s. e. ) (0.13) (0.17) (0.21)

0.34 (0.13)

0.38 (0.25)

0.41 0.27 (0.15) (0.21)

Year 2

Est

0.63 0.52 0.76

(s. e. ) (0.18) (0.24) (0.27)

0.58 (0.19)

0.77 (0.33)

0.31 0.87 (0.19) (0.28)

^ dif(unempl) = 0.34 (s. e. 0.13),

CI0.95(fs(unempl)) = (0.08, 0.601).

For the second group, the estimated average treatment effect is

^ dif(empl) = 0.38 (s. e. 0.25),

CI0.95(fs(emp)) = (-0.12, 0.87).

We can also combine these to obtain an estimate of the overall average treatment effect fs that is possibly more precise than ^ dif. We implement this by weighting the two estimates, ^ dif(empl) for the employed and ^ dif(unempl) unemployed, by their shares in the full sample. These shares are 1,262/(1,262 + 1,949) = 0.39 for those with positive
earnings and 0.61 for those with zero earnings in the year prior to the program. The
weighted estimated average treatment effect, or employment-adjusted estimate is

^ strat =

N(empl)

· ^ dif(empl) +

N(unempl)

· ^ dif(unempl)

N(empl) + N(unempl)

N(empl) + N(unempl)

=

1262 1262 + 1949

· 0.38 +

1949 1262 + 1949

· 0.34 = 0.36

(s. e. 0.15),

with the large sample 95% confidence interval equal to

CI0co.9m5bined(fs) = (0.11, 0.61).
Note that this point estimate differs slightly from ^ in (11.1) where we took the simple difference in average outcomes by treatment status, which reflects a small imbalance in the proportion of treated and control units among those with positive and zero earnings. More specifically, among those with positive earnings, 49.2% were assigned to the active treatment and 50.8% were assigned to the control treatment; and among those with zero earnings, 50.4% were assigned to the active treatment and 49.6% were assigned to the control treatment. This does not mean the randomization was compromised, merely that there is some random variation in these proportions because the randomization was not stratified on initial employment status.
The estimated sampling variance of the average treatment effect is also affected by the post-stratification on prior employment. If the treatment effect varies by covariates, then estimating the average effects within relatively homogeneous subpopulations, and then averaging over them will often reduce the sampling variance and lead to more precise inferences. Here, the change in estimated precision is fairly small.

11.5 Regression-Based Estimates

247

Finally, we partition the sample into those with no high school diploma (1,409 individuals) and those with a high school diploma (1,802 individuals). For the high school dropouts, we find
^ dif(no-hs) = 0. 41 (s. e. 0.15), CI0.95(fs(no-hs)) = (0.12, 0.70).
For the high school graduates, the estimated average treatment effect is
^ dif(hs) = 0.27 (s. e. 0.21), CI0.95(fs(hs)) = (-0.14, 0.68).

11.5 REGRESSION-BASED ESTIMATES

We now consider regression-based estimates of the average effect of the treatment, on the earnings in both the first and the second year after the program started. We consider specifications of the regression function that include the set of eleven pre-treatment variables listed in Table 11.1, indicators for being female (female), being at least 35 years old (agege35), having a high school diploma (hsdip), never having been married (nevmar), being divorced or widowed (divwid), having children younger than six years (chldlt6), being African-American (af-amer), being Hispanic (hisp), the discrete variable giving the number of children (numchild), and the lagged outcome, earnings in the year preceding the training program (earnyrm1), and an indicator for earnings being positive in that prior year (empyrm1). Denoting the row vector of these eleven pre-treatment variables by Xi, the basic specification of the regression function we estimate includes an intercept, the indicator for the treatment, the vector of pre-treatment variables, and the interaction of the two:

Yiobs =  +  · Wi + (Xi - X) + Wi · (Xi - X) + i.

The covariates are included in deviations from the sample average, so that the estimated coefficient on the treatment indicator,  , can be interpreted as an estimator for the average effect of the treatment in the population. Implicitly this specification allows for separate slope coefficients for treated and control regression functions. For comparison, we also include least squares estimates of the regression function without pre-treatment variables:

Yiobs =  +  · Wi + i,

which gives the least squares estimate for  equal to the difference in average outcomes by treatment status,

^ ols

=

^ dif

=

Y

obs t

-

Y

obs c

=

2.02

-

1.69

=

0.33.

The estimates of the average effect of the treatment do not change much with the inclusion of the eleven pre-treatment variables. For the first year earnings, the point estimate increases from 0.33 (in thousands of dollars) to 0.36, and in the second year, the estimate increases from 0.63 to 0.66. This is not unexpected: the fact that the randomization was done without regard to the pre-treatment variables implies that, on average, the

248

Case Study: An Experimental Evaluation of a Labor Market Program

Table 11.4. Regression Estimates for Average Treatment Effects on Earnings, for the San Diego Swim Data

Covariates

Earnings Year 1

Earnings Year 2

Treat Intercept

Est (s. e.)
0.33 (0.13) 1.69 (0.09)

Est (s. e.) Est (s. e.)
0.36 (0.12) 0.63 (0.18) 1.68 (0.09) 2.26 (0.12)

Est (s. e.)
0.66 (0.17) 2.25 (0.11)

Covariates female agege35 hsdip nevmar divwid numchild chldlt6 af-amer hisp earnyrm1 empyrm1

0.35 (0.29) -0.09 (0.17)
0.79 (0.20) 0.38 (0.21) 0.32 (0.20) 0.10 (0.08) -0.46 (0.25) -0.22 (0.22) 0.05 (0.23) 0.33 (0.08) 0.75 (0.30)

-0.03 (0.39) -0.01 (0.23)
0.86 (0.25) 0.47 (0.29) 0.41 (0.26) 0.03 (0.11) -0.20 (0.36) -0.54 (0.28) -0.25 (0.30) 0.33 (0.09) 0.78 (0.34)

Interactions with treatment indicator treat×female treat×age 35 treat×high school dip treat×never married treat×divorced/widowed treat×number of children
treatchldlt6 treat×african-american treat×hispanic
treatearnyrm1
treatempyrm1

-0.01 (0.43) 0.17 (0.25)
-0.15 (0.27) -0.40 (0.29)
0.34 (0.29) -0.18 (0.11)
0.42 (0.39) -0.29 (0.31) -0.26 (0.34)
0.09 (0.10) -0.30 (0.40)

0.48 (0.59) 0.18 (0.36) 0.54 (0.36) -0.33 (0.41) 0.36 (0.41) -0.29 (0.15) 1.15 (0.60) -0.14 (0.42) 0.31 (0.48) 0.22 (0.13) -0.72 (0.50)

R-squared

0.002

0.190

0.004

0.151

pre-treatment variables should be approximately the same in treatment group and control group and that their inclusion or omission usually should not change point estimates of treatment effects as a result of the linear predictive power. The estimated standard error does not change much either. They decrease slightly, as a result of the predictive power of the covariates, but because this predictive power is fairly modest, the reduction in estimated standard error is small.
The main interest in the regression estimates is that they provide some evidence regarding heterogeneity in the effect of the program, which can be seen directly by inspecting the least squares estimates of the coefficients of the interactions of the pretreatment variables with the treatment indicator, as reported in Table 11.4. In addition to these estimates, we also report tests of hypotheses about the coefficients in the linear

11.5 Regression-Based Estimates

249

Table 11.5. P-Values for Tests of Constant and Zero Treatment Effects Assumptions, for San Diego SWIM Data

Null Hypothesis Zero effect
Constant effect

X 2(12) approximation Fisher exact p-value
X 2(11) approximation

Earnings Year 1 0.018 0.157
0.122

Earnings Year 2 <0.001 0.014
0.002

regression model. Specifically we consider two null hypotheses. First, consider the null hypotheses that all least squares coefficients involving the treatment indicator are equal to zero. Formally,
H0 :  = 0 and  = 0,
against the alternative that either  or some components of  differ from zero,
Ha :  = 0 or  = 0,
where 0 denotes a vector of zeros. The results from an F-test on the least squares coefficients are reported in Table 11.5. The value of the F-statistic using the first-year earnings as the outcome variable is 2.11, leading to a p-value of 0.018 based on the asymptotic approximation using the F-distribution with 12 degrees of freedom. We also carried out a different version of this test, where we used the F-statistic in a Fisher-exact-p-value calculation, under the null of no effect of the treatment whatsoever. This led to a considerably less significant p-value of 0.157. The results for the p-value are also reported in Table 11.5. For the second-year earnings outcome, the F-statistic is 3.78, leading to a p-value based on the F-distribution less than 0.001, and a p-value based on the randomization distribution equal to 0.014. Next, we considered the null hypothesis of no treatment effect heterogeneity by pre-treatment variables. In terms of the least squares coefficients, this corresponds to testing the null hypothesis
H0 :  = 0,
against the alternative that some components of  differ from zero,
Ha :  = 0.
We find somewhat different results for the first- and second-year earnings. For the first year we find an F-statistic equal to 1.50, leading to a p-value of 0.122. This suggests little evidence for heterogeneity of the treatment effect. The F-statistic for second-year earnings is 2.68, leading to a p-value of 0.002, suggesting clear evidence that the treatment effect on second-year earnings varies by the values of the pre-treatment variables.

250

Case Study: An Experimental Evaluation of a Labor Market Program

11.6 MODEL-BASED POINT ESTIMATES

Now let us consider the model-based approach. To avoid reporting a large number of estimates, we focus first on estimating the average treatment effect for earnings in the second year.
A simple strategy is to specify a joint normal distribution for the two potential outcomes with unit correlation. If we use a normal prior distribution for the mean parameters and inverse Chi-squared distributions for the two variance parameters, we return to the case analyzed in Chapter 8. With the number of observations as large as in the SWIM program, the choice of prior distribution is unlikely to matter much. We estimate two versions of the normal model. First, a model with no covariates; for the mean parameters, we use normal prior distributions centered at zero with prior variances equal to 1002. For the variance parameters, we use inverse Chi-squared distributions with parameters equal to 1/2 and 0.0005. The posterior mean for fs is 0.33, and the posterior standard deviation is equal to 0.09. Next we include the eleven covariates in the model, assuming they enter linearly for the mean. Now the posterior mean for fs is 0.36 and the posterior standard deviation is 0.08. Although the covariates are moderately strongly associated with the potential outcomes, including the covariates does not affect the posterior distribution for the average effect of interest very much. These results are very similar to those obtained through the Neyman approach, which is not surprising because the sample size implies that, using versions of the central limit theorem, normal distributions are likely to give accurate approximations to both the sampling and the posterior distributions.
It is clear, however, that the model used in this first attempt is not an appropriate one. The distributions are far from normal, with 54% of individuals having zero earnings one year after the program started, as the summary statistics in Table 11.1 show. A more plausible approximation to the distribution of earnings in each treatment regime is therefore a mixed discrete-continuous distribution. We use the following model with one parameter governing the probability of the point mass at zero and a normal distribution for the continuous component (which led to a better fit than a log normal distribution for the continuous part),

Pr(Yi(0)

>

0|Xi,

)

=

1

exp (c) + exp (c

)

,

Yi(0)|Yi(0) > 0, Xi,   N (c, c2),

Pr(Yi(1)

>

0|Xi,

)

=

1

exp (t) , + exp (t)

Yi(1)|Yi(1) > 0, Xi,   N (t, t2),

and assume independence between the potential outcomes. For this specification, it is
difficult to derive an analytic expression for the posterior distribution of the average
treatment effect in terms of the observed data for most prior distributions. We focus,
therefore, on simulation methods.
We use independent prior distributions for the six elements of the parameter vector  = (c, t, c, t, c2, t2). For c, t, c, and t, we use normal prior distributions centered at zero and with variance equal to 1002. The prior distributions for the variance parameters are inverse Chi-squared, with parameters 1/2 and c2/2 and t2/2, respectively. The mean and standard deviation of the posterior distribution for  are 0.33 and

11.6 Model-Based Point Estimates

251

Table 11.6. Posterior Means and Standard Deviations for Model-Based Imputation Estimates, Year 1 Earnings, for San Diego SWIM Data

Linear Model Linear Model No Covariates Covariates

Two-Part Model No Covariates

Two-Part Model Covariates

Logit

Normal

Logit

Normal

Mean (S.D.) Mean (S.D.) Mean (S.D.) Mean (S.D.) Mean (S.D.) Mean (S.D.)

Control Outcome

Intercept

1.69 (0.09) -0.13 (0.40) -0.39 (0.05) 4.17 (0.20) -1.56 (0.27) 1.77 (0.86)

female

0.35 (0.32)

0.04 (0.21) 0.55 (0.68)

agege35

-0.09 (0.19)

-0.28 (0.13) 0.19 (0.41)

hsdip

0.78 (0.19)

0.46 (0.12) 1.39 (0.42)

nevmar

0.38 (0.24)

0.26 (0.16) 0.52 (0.52)

divwid

0.32 (0.21)

0.13 (0.14) 0.68 (0.46)

numchild

0.10 (0.09)

0.06 (0.06) 0.14 (0.19)

chldlt6

-0.47 (0.29)

-0.13 (0.19) -0.89 (0.63)

af-amer

-0.22 (0.21)

-0.05 (0.14) -0.58 (0.45)

hisp

0.05 (0.24)

0.04 (0.16) 0.13 (0.53)

earnyrm1

0.33 (0.03)

0.10 (0.02) 0.32 (0.05)

empyrm1

0.75 (0.21)

1.49 (0.14) -0.63 (0.44)

c

3.76 (0.07) 3.45 (0.06)

4.97 (0.14)

4.72 (0.13)

Treated Outcome

Intercept

2.02 (0.09) 0.69 (0.38) 0.06 (0.05) 3.92 (0.16) -0.62 (0.24) 2.67 (0.67)

female

0.34 (0.30)

0.09 (0.20) 0.08 (0.51)

agege35

0.08 (0.18)

-0.17 (0.12) 0.31 (0.32)

hsdip

0.64 (0.18)

0.22 (0.11) 0.91 (0.32)

nevmar

-0.02 (0.23)

0.23 (0.15) -0.39 (0.41)

divwid

0.66 (0.21)

0.51 (0.13) 0.59 (0.35)

numchild

-0.08 (0.09)

-0.08 (0.05) -0.07 (0.15)

chldlt6

-0.04 (0.30)

-0.23 (0.18) 0.40 (0.53)

af-amer

-0.51 (0.21)

-0.14 (0.13) -0.80 (0.34)

hisp

-0.21 (0.24)

-0.09 (0.15) -0.29 (0.40)

earnyrm1

0.42 (0.03)

0.09 (0.03) 0.43 (0.04)

empyrm1

0.45 (0.21)

1.13 (0.14) -0.37 (0.34)

t

3.80 (0.07) 3.38 (0.06)

4.53 (0.11)

4.10 (0.10)

fs

0.33 (0.09) 0.36 (0.08)

0.33 (0.09)

0.36 (0.08)

0.09, respectively. The posterior means and standard deviations for all elements of  are presented in Tables 11.6 (year 1 earnings) and 11.7 (year 2 earnings).
Next, we consider a similar mixed discrete-continuous model with covariates, often called a "two-part" model. Let Xi denote the vector of covariates reported in Table 11.1. The model is now

Pr(Yi(0)

>

0|Xi

=

x, )

=

1

exp (xc) , + exp (xc)

Yi(0)|Xi = x, Yi(0) > 0,   N (xc, c2),

Pr(Yi(1)

>

0|Xi

=

x, )

=

1

exp (xt) + exp (xt)

and

Yi(1)|Xi = x, Yi(1) > 0, 

 N (xt, t2).

252

Case Study: An Experimental Evaluation of a Labor Market Program

Table 11.7. Posterior Means and Standard Deviations for Model-Based Imputation Estimates, Year 2 Earnings, for San Diego SWIM Data

Linear Model Linear Model No Covariates Covariates

Two-Part Model No Covariates

Two-Part Model Covariates

Logit

Normal

Logit

Normal

Mean (S.D.) Mean (S.D.) Mean (S.D.) Mean (S.D.) Mean (S.D.) Mean (S.D.)

Control Outcome

Intercept 2.26

female

agege35

hsdip

nevmar

divwid

numchild

chldlt6

af-amer

hisp

earnyrm1

empyrm1

c

4.68

(0.12) 0.96 (0.50) -0.40 (0.05) 5.62 (0.23) -1.03 (0.25) 4.04 (1.01)

-0.06 (0.40)

-0.12 (0.20) -0.26 (0.82)

(0.23)

-0.18 (0.12) 0.35 (0.51)

0.88 (0.24)

0.08 (0.12) 2.18 (0.49)

0.46 (0.31)

0.29 (0.15) 0.70 (0.64)

0.40 (0.27)

0.30 (0.13) 0.40 (0.56)

0.03 (0.11)

(0.05) 0.16 (0.24)

-0.22 (0.38)

-0.02 (0.17) -0.55 (0.77)

-0.52 (0.26)

0.05 (0.12) -1.59 (0.55)

-0.24 (0.31)

0.06 (0.14) -0.83 (0.62)

0.33 (0.04)

0.06 (0.02) 0.38 (0.06)

0.76 (0.27)

1.06 (0.14) -0.61 (0.51)

(0.08) 4.42 (0.08)

5.97 (0.17)

5.65 (0.16)

Treated Outcome

Intercept 2.89

female

agege35

hsdip

nevmar

divwid

numchild

chldlt6

af-amer

hisp

earnyrm1

empyrm1

t

5.44

(0.13) 1.05 (0.55) -0.03 (0.05) 5.86 (0.24) -0.73 (0.24) 4.06 (0.98)

0.43 (0.43)

0.10 (0.18) 0.02 (0.75)

0.18 (0.28)

0.01 (0.11) 0.36 (0.46)

1.39 (0.28)

0.36 (0.12) 2.09 (0.49)

0.15 (0.34)

0.13 (0.14) 0.10 (0.59)

0.78 (0.31)

0.33 (0.14) 0.87 (0.51)

-0.26 (0.12)

-0.12 (0.06) -0.22 (0.24)

0.96 (0.45)

0.26 (0.18) 1.17 (0.72)

-0.65 (0.30)

-0.20 (0.12) -0.96 (0.51)

0.06 (0.36)

0.33 (0.14) -0.61 (0.57)

0.55 (0.04)

0.09 (0.02) 0.59 (0.06)

0.06 (0.31)

0.77 (0.13) -1.23 (0.52)

(0.10) 4.97 (0.09)

6.53 (0.16)

5.97 (0.15)

fs

0.64 (0.13) 0.66 (0.12)

0.63 (0.13)

0.67 (0.12)

The posterior mean for fs given this model is 0.36 with a posterior standard deviation equal to 0.08 (Table 11.8) The posterior means and standard deviations for all other elements of  are again presented in Tables 11.6 and 11.7.
One major advantage of the model-based imputation approach is that we can easily accommodate different estimands. Suppose that instead of focusing on the average effect of the treatment, we are interested in the effect of the training program on the probability that individuals who were not working before now have jobs paying more than $5,000. Within the context of the imputations, this is a straightforward calculation. The imputation procedure is exactly as before. Now to calculate the posterior distribution of the

Notes

253

Table 11.8. Summary Statistics Posterior Distribution for Finite-Sample Average Treatment Effect, for San Diego SWIM Data

Post-Program Earnings

Model

Covariates Mean (S. D. )

Posterior Quantiles

0.025 0.25 0.5 0.75 0.975

Year 1 Year 1 Year 1 Year 1 Year 2 Year 2 Year 2 Year 2

Linear

No

Linear

Yes

Two-part

No

Two-part Yes

Linear

No

Linear

Yes

Two-part

No

Two-part Yes

0.33 (0.09) 0.14 0.27 0.33 0.40 0.51 0.36 (0.08) 0.19 0.30 0.36 0.41 0.52 0.33 (0.09) 0.14 0.27 0.33 0.39 0.51 0.37 (0.09) 0.20 0.31 0.37 0.42 0.53 0.63 (0.13) 0.38 0.54 0.63 0.71 0.88 0.66 (0.12) 0.43 0.58 0.66 0.74 0.89 0.63 (0.13) 0.38 0.54 0.63 0.71 0.87 0.67 (0.12) 0.44 0.59 0.67 0.75 0.90

estimand, we simply calculate the fraction, among individuals who had zero earnings before, of individuals who now have earnings more than $5,000. Using the two-part model with covariates, the posterior mean and standard deviation for this probability are 0.029 and 0.009. Another advantage is that it is straightforward to report results on the posterior distribution of the estimands beyond moments, for example posterior quantiles.
Table 11.8 reports posterior quantiles for the average effect of the treatment on postprogram earnings.

11.7 CONCLUSION
In this chapter we illustrate the four basic methods for analyzing classical randomized experiments discussed in the second part of the text. Taking as the example a randomized experiment of a job-training program, we illustrate the calculation of Fisher exact p-values, the construction of confidence intervals based on Neyman's repeated sampling approach, regression analyses, and model-based analyses. The methods generally agree here: there is strong evidence of an effect of the program, and we can estimate its average effects precisely. Ultimately the choice of methods here is somewhat subtle: the randomization ensures that the point estimates tend to be similar, the estimated precisions are similar because the covariates are only moderately predictive of the potential outcomes, and the methods differ mostly in the precise questions they ask. In the next parts of the book, where we address observational studies, these differences are often amplified, and the choices become more consequential.

NOTES
For more detail on the San Diego SWIM program and similar labor market training programs, see Friedlander and Robbins (1995), Friedlander and Gueron (1995), Hotz, Imbens, and Mortimer (2005), and Hotz, Imbens, and Klerman (2001).

254

Case Study: An Experimental Evaluation of a Labor Market Program

Research that concluded that non-experimental evaluations were not credible in social sciences led to a renewed interest in experimental evaluations. Important papers in this literature are Lalonde (1986), Fraker and Maynard (1987), and Friedlander and Robbins (1995). The central thesis in this literature was the claim that non-experimental methods led to a wide range of results, with no reliable methods for choosing among these results. Later research cast some doubt on these claims. Dehejia and Wahba (1999) showed that methods based on the propensity score were considerably more successful in replicating experimental results than the regression-based methods considered by Lalonde (1986).

PART III
Regular Assignment Mechanisms: Design

CHAPTER 12
Unconfounded Treatment Assignment
12.1 INTRODUCTION
In Part III of this text we leave the conceptually straightforward world of perfect randomized experiments and move toward the more common setting of observational studies. Although in simple situations we can still directly apply the tools from randomized experiments and exploit the exact results that accompany them, quickly we will be forced to make approximations in our inferences. No longer will estimators be exactly unbiased as in Chapter 6, nor will we be able to calculate exact p-values of the type considered in Chapter 5.
The first step toward addressing observational studies is to relax the classical randomized experiment assumption that the probability of treatment assignment is a known function. We do maintain, however, in this part of the text, the unconfoundedness assumption that states that assignment is free from dependence on the potential outcomes. Moreover, we continue to assume that the assignment mechanism is individualistic, so that the probability for unit i is essentially a function of the pre-treatment variables for unit i only, free of dependence on the values of pre-treatment variables for other units. We also maintain the assumption that the assignment mechanism is probabilistic, so that the probability of receiving any level of the treatment is strictly between zero and one for all units.
The implication of these assumptions is that the assignment mechanism can be interpreted as if, within subpopulations of units with the same value for the covariates, a completely randomized experiment of the type discussed in Chapters 5­8 was conducted, although an experiment with unknown assignment probabilities for the units. Thus, under these assumptions, we can analyze data from a subsample with the same value of the covariates as if it came from such an experiment. Although we do not know a priori the assignment probabilities for each of these units, we know these probabilities are identical because their covariate values are identical, and hence, conditional on the number of treated and control units composing such a subpopulation, the probability of receiving the treatment, the propensity score, is equal to e(x) = Nt(x)/(Nc(x) + Nt(x)) for all units with Xi = x; here Nt(x) and Nc(x) are the number of units in the control and treatment groups respectively with pre-treatment value Xi = x. In practice, this insight alone is of limited value, as typically there are too many distinct values of the covariates
257

258

Unconfounded Treatment Assignment

in the sample to partition the sample in this way without having either Nc(x) or Nt(x) equal to zero in some strata. Nevertheless, this insight has an important implication that suggests feasible alternatives for analyses.
In this chapter we discuss some general aspects of the unconfoundedness assumption, including the broad strategies we recommend in settings where unconfoundedness is viewed as an appropriate assumption, and we provide a road map for the third and fourth parts of the text. In Section 12.2 we discuss the assumption itself, its implications, and why we think the setting with unconfoundedness is an important case deserving special attention. In Section 12.3 we further explore a particular implication of unconfoundedness related to the propensity score. Even if a large set of covariates is used to ensure unconfoundedness, it is generally sufficient, in a certain sense, to adjust for a scalar function of the covariates, namely the propensity score. We discuss the balancing property of the propensity score, and what other functions of the covariates share this property. Next, in Section 12.4 we outline broad strategies for estimation and inference under regular assignment mechanisms. We discuss the general merits of the various strategies and describe methods that we discuss in more detail in the subsequent chapters. In Section 12.5, we discuss preliminary analyses not involving the outcome data that we recommend as part of what we call the design stage of the observational study. In Section 12.6 we outline how, in some settings, one can do additional analyses that help the researcher assess the plausibility of the unconfoundedness assumption, even though in general unconfoundedness is not testable. Section 12.7 concludes.

12.2 REGULAR ASSIGNMENT MECHANISMS
In this section we revisit the properties of a regular assignment mechanism, the implications of these properties, and why we view this as a central class of assignment mechanisms to consider in observational studies.
12.2.1 The Implications of a Regular Assignment Mechanism As discussed in Chapter 3, a regular assignment mechanism satisfies three conditions. First, the assignment mechanism must be probabilistic, requiring that the unit-level assignment probabilities are strictly between zero and one:
0 < pi (X, Y(0), Y(1)) < 1, for i = 1, . . . , N.
Second, it must be individualistic, requiring that (i) the unit level assignment probabilities can be written as a common function of that unit's potential outcomes and covariates,
pi (X, Y(0), Y(1)) = q(Xi, Yi(0), Yi(1)), for i = 1, . . . , N,

12.2 Regular Assignment Mechanisms

259

and (ii) that

N
Pr(W |X, Y(0), Y(1) ) = c · q(Xi, Yi(0), Yi(1))Wi · (1 - q(Xi, Yi(0), Yi(1)))1-Wi ,
i=1
for some constant c, for W  W+, and zero elsewhere. Third, it must be unconfounded, requiring that all the assignment probabilities Pr(W |X, Y(0), Y(1) ) are free from dependence on the potential outcomes. In combination with individualistic assignment, this implies that we can write the assignment mechanism as

N
Pr(W |X, Y(0), Y(1) ) = c · e(Xi)Wi · (1 - e(Xi))1-Wi ,
i=1

where e(x) is the propensity score. This defines the basic framework we use in Parts III and IV of this text.
Under the assumptions for a regular assignment mechanism, we can give a causal interpretation to the comparison of observed outcomes for treated and control units within subpopulations defined by values of the pre-treatment variables. Specifically, suppose we look at the subpopulation of all units with Xi = x; within this subpopulation the difference in the distributions of the observed outcomes, between treated and control units, fairly represent the effects of the treatment in this subpopulation, because, within this subpopulation, the treated and control units are both random samples from that subpopulation. For example, the difference in average observed outcomes is unbiased for the average effect of the treatment at Xi = x.
Let us first consider the case with a single binary covariate (e.g., sex), so that Xi  {f , m}. Within the subsamples of women and men, the average finite sample treatment effects are, respectively,

1 fs(f ) = N(f )

Yi(1) - Yi(0) ,

i:Xi=f

and

fs(m)

=

1 N(m)

i:Xi=m

Yi(1) - Yi(0)

,

where N(f ) and N(m) are the number of women and men, respectively, in the sample. Within each of these subsamples, estimation and inference are entirely standard. We can directly use the methods from, for example, Chapter 6 in Part II of this text on Neyman's repeated sampling perspective in completely randomized experiments. The fact that we do not know a priori the probability of assignment to the treatment is irrelevant here: we can use the results for the analysis of completely randomized experiments by conditioning on the number of treated women and treated men. If, instead of being interested in  (f ) and  (m) separately, we are interested in the overall average effect

fs

=

N(f ) N(f ) + N(m)

· fs(f )

+

N(m) N(f ) + N(m)

·

fs(m),

we can simply use the methods for stratified randomized experiments discussed in Chapter 9.

260

Unconfounded Treatment Assignment

This approach of partitioning the population into strata by values of the pre-treatment variables extends, in principle, to all settings with discrete-valued pre-treatment variables. However, with pre-treatment variables taking on many distinct values in the sample, there may be a substantial number of strata with only treated or with only control units. For such strata, we cannot estimate the stratum-specific treatment effects using this approach, and thus we cannot estimate overall treatment effects following this strategy. This setting is of great practical relevance, and it is the primary focus of the chapters in Parts III and IV of this text, and indeed of much of the theoretical literature on estimation of, and inference for, causal effects in statistics and related disciplines. In this case, we compare outcomes for treated and control units with "similar" but not identical values for the pre-treatment variables. For such comparisons to be appropriate, we require smoothness and modeling assumptions, and decisions regarding tradeoffs between differences in one covariate versus another. How we make such trade-offs, and what are sensible approaches to find estimators and inferential procedures that lead to robust and credible results, are central topics in Parts III and IV of this text. Beyond depending on substantive insights regarding the association of particular pre-treatment variables with treatment status and potential outcomes, and related assessments of the unconfoundedness assumption, evaluating the various approaches to estimation and inference also requires statistical expertise.

12.2.2 A Super-Population Perspective
For the purpose of discussing various frequentist approaches to estimation and inference under unconfoundedness, it is useful to take a super-population perspective. Moreover, it is helpful to view the covariates Xi as having been randomly drawn from an approximately continuous distribution. If, instead, we view the covariates as having a discrete distribution with finite support, the implication of unconfoundedness is simply that one should stratify by the values of the covariates. In that case there will be, with high probability, in sufficiently large samples, both treated and control units with the exact same values of the covariates. In this way we can immediately remove all biases arising from differences between covariates, and many adjustment methods will give similar, or even identical, answers. However, as we stated before, this case rarely occurs in practice. In many applications it is not feasible to stratify fully on all covariates, because too many strata would have only a single unit. The differences between various adjustment methods arise precisely in such settings where it is not feasible to stratify on all values of the covariates, and mathematically these differences are most easily analyzed in settings with random samples from large populations using effectively continuous distributions for the covariates.
In the super-population, unconfoundedness implies a restriction on the joint distribution of (Yi(0), Yi(1), Wi, Xi), namely

Pr(Wi = 1|Yi(0), Yi(1), Xi) = Pr(Wi = 1|Xi) = e(Xi),

(12.1)

or, in the Dawid (1979) conditional independence notation,

Wi  Yi(0), Yi(1) Xi,

12.2 Regular Assignment Mechanisms

261

where we leave implicit the conditioning on the parameters governing the distributions, as in Section 3.5. Probabilistic assignment now requires that
0 < e(x) < 1,
for all x in the support of Xi, where we ignore measure-theoretic details.

12.2.3 Unconfoundedness Is Not Testable
A key feature of the unconfoundedness assumption is that it has no directly testable implications, even in settings with a large number of units. There is no information in the data that can tell us that unconfoundedness does not hold. Of course this does not mean that unconfoundedness actually holds, or even that it is plausible, but it implies that any assertion that it does not hold must rely on additional, substantive, information beyond the assessment of assumptions of probabilistic and individualistic assignment.
To gain further insight into this feature of the unconfoundedness assumption, it is useful to look at this assumption in a setting with a large sample, where we can estimate the joint distribution of (Yiobs, Wi, Xi).
Theorem 12.1 (Super-Population Unconfoundedness) Super-population unconfoundedness implies two restrictions on the conditional distributions of the potential outcomes. First,

Yi(0) Wi = 1, Xi  Yi(0) Wi = 0, Xi , for i = 1, . . . , N,

(12.2)

and, second,

Yi(1) Wi = 0, Xi  Yi(1) Wi = 1, Xi , for i = 1, . . . , N.

(12.3)

(Here "" denotes equality in distribution.)
Proof. By super-population unconfoundedness, defined in Chapter 3, Section 10, Wi is independent of (Yi(0), Yi(1)) given Xi. Hence Yi(0) is independent of Wi given Xi, implying the first claim in Theorem 12.1. The second claim follows by an analogous argument.
The first restriction states that the conditional distribution of Yi(0) given Wi = 1 and the pre-treatment variables Xi is the same as the conditional distribution of Yi(0) given Wi = 0 and Xi. It is useful to restate this, and (12.3), in terms of missing and observed outcomes:
Yimis Wi = w, Xi  Yimis Wi = 1 - w, Xi , for i = 1, . . . , N.

Now it becomes clear that the unconfoundedness assumption implies the equality of the
distribution of a missing potential outcome (a distribution about which the data are not
directly informative) to the distribution of an observable outcome (about which the data are informative). In large samples we can infer the conditional distribution of Yiobs given Wi and Xi, but no amount of observable data will allow us to infer the distribution of Yimis given Wi and Xi.

262

Unconfounded Treatment Assignment

Although unconfoundedness is not testable, there are in some cases analyses one may be able to carry out that assist the researcher when assessing the plausibility of this critical assumption. These supporting analyses rely on more restrictive assumptions that do generate testable consequences. In Chapter 21 we discuss such analyses in detail.

12.2.4 Why Is Unconfoundedness an Important Assumption?
Before discussing specific methods for estimation and inference based on regular assignment mechanisms, it is useful to discuss why we view this assumption as so important that we devote a large part of this text to methods assuming it.
Of the three assumptions required for regularity of the assignment mechanism, probabilistic assignment is the easiest to motivate. If a particular subpopulation has zero probability of being in one of the treatment groups, then estimates of treatment effects for this subpopulation must, by necessity, rely on extrapolation. There is often little basis for such extrapolation, and we may simply have to put such subpopulations aside. For example, suppose we are interested in evaluating a new drug, and suppose the sample studied contains both women and men, Xi  {f , m}. However, suppose that the treatment group contains only women, so that e(m) = Pr(Wi = 1|Xi = m) = 0. In that case it would clearly require strong, possibly implausible, assumptions to estimate the effect of the treatment for men ­ or, for that matter, for the entire population. It would appear more reasonable to estimate the effect for women and then separately discuss the plausibility of extrapolating that estimate for women to men. Even more prevalent is the case where the probabilistic assumption is close to being violated, without the probabilities being exactly equal to zero or one, which can severely impact our ability to obtain precise estimates of the causal estimands. This raises a number of issues, which we discuss in detail in Chapters 15 and 16.
In practice, the second assumption, individualistic assignment, is rarely controversial. Although formally it is possible that there is dependence in the assignment indicators beyond that allowed through, for example, stratification on covariates, there are no practical examples we are aware of, other than sequential assignment mechanisms (which we do not discuss in this text), where this is plausibly violated.
Next, let us comment on some aspects of what is, typically, the most controversial component of the three requirements for a regular assignment mechanism: the assumption of unconfoundedness. First of all, the assumption is extremely widely used. Although this is obviously not in itself an argument for its validity, it should be noted that, by a wide margin, most analyses involving observational studies fundamentally rely on unconfoundedness, often implicitly, and often in combination with other assumptions, in order to estimate causal effects. It is not always immediately transparent that such an assumption is employed, as it is often formulated in combination with functional form or distributional assumptions, but in many such applied examples, the implication of the assumptions is that differences in outcomes for units with the same values for some set of observed pre-treatment variables, but with different levels of the treatment, can be interpreted as credible estimates of causal effects.
Let us give an example of such an assumption. In many empirical studies in social sciences, causal effects are estimated through linear regression, where, typically it is

12.2 Regular Assignment Mechanisms

263

implicitly assumed that in the super-population,

E [ Yi(w)| Xi] =  + sp · w + Xi,

for some values of the three unknown parameters , sp, and , where sp = Esp[Yi(1) - Yi(0)]. Defining i = Yiobs - sp · Wi - Xi, so that we can write

Yiobs =  + sp · Wi + Xi + i,

(12.4)

it is then assumed that

i  Wi, Xi.
This assumption is often referred to as exogeneity of the treatment (and the pre-treatment variables) in the econometrics literature. The regression function (12.4) is interpreted as a causal relation, in our sense of the term "causal," namely that if we manipulate the treatment Wi, then the outcome would change in expectation by an amount sp. Hence, in the potential outcome formulation, we have

Yi(0) =  + Xi + i, and Yi(1) = Yi(0) + sp. Then, because i is a function of Yi(0) and Xi given the parameters,
Pr(Wi = 1|Yi(0), Yi(1), Xi) = Pr(Wi|i, Xi), and by exogeneity of the treatment indicator, we have

Pr(Wi|i, Xi) = Pr(Wi|Xi),
and thus unconfoundedness holds. However, the exogeneity assumption combines unconfoundedness with functional form and constant treatment effect assumptions that are quite strong, and arguably unnecessary. Therefore we focus here on the cleaner, functional-form-free unconfoundedness assumption.
A second motivation for the unconfoundedness assumption is based on a comparison with alternative assumptions. Unconfoundedness implies that one should compare units similar in terms of pre-treatment variables, that is, one should compare "like with like." This has great intuitive appeal, and underlies many informal, as well as formal, causal inferences. Without this assumption, and without additional assumptions to replace it, we would no longer have guidance on which control units would make good comparisons for particular treated units (and the other way around). In the absence of unconfoundedness, one could still conduct a sensitivity analysis or, in an extreme version, calculate ranges of values for the causal estimands consistent with the data. We discuss such approaches in Chapter 22. However, any alternative approach that would provide specific guidance on which treated units to compare with which control units would have to compare units that differ in terms of observed pre-treatment variables. As Rubin (2006) writes concerning the example of the causal effect of smoking versus not smoking, "it would make little sense to compare disease rates in well-educated non-smokers and poorly educated

264

Unconfounded Treatment Assignment

smokers" (page 3). To be specific, suppose we are interested in the causal effect of a jobtraining program. Now suppose there is a forty-year-old man who has been unemployed for six months, and who was continuously employed for eighteen months prior to that in the automobile industry, with a high school education, who is going through this training program. Assuming unconfoundedness implies that in order to estimate the causal effect of this program for him, we should look for a man with the same pre-training characteristics, who did not go through the training program. Any plausible alternative strategy would still involve looking for a person, or combination of persons, who did not go through the training program. But, in order to be different from the strategy under unconfoundedness, any alternative must imply looking for a person, or combination of persons, who are systematically different from the forty-year-old male high school graduate with six months of unemployment and eighteen months of employment in the automobile industry. In other words, an alternative to unconfoundedness must involve looking for a comparison person who is systematically different in terms of observed pre-treatment variables from the person who went through the training. In many cases it would appear implausible that individuals who differ in terms of pre-treatment characteristics would be more suitable comparisons. Of course, it may be that individuals who differ in terms of two or more pre-treatment variables may have offsetting unobserved differences such that ultimately they provide a better comparison, but it would appear to be difficult to improve systematically comparisons in this manner. Note that the claim is not that unconfoundedness is always plausible per se. The claim is the much weaker statement, that allowing for systematic differences in such pre-treatment characteristics is unlikely to improve comparisons in general practice.
Let us expand on this argument in an example to be clearer. Suppose that a researcher is concerned that the unconfoundedness assumption may be violated, because typically individuals who enrolled in this job market program may be more interested in finding jobs, that is, more motivated, than the individuals who did not enroll. Such a concern is common in the analysis of job-training programs in settings with voluntary enrollment. Let us suppose, for expositional reasons, that motivation is a permanent characteristic of individuals, not affected by the training program. It is plausible that more highly motivated individuals are, typically, better at finding employment conditional on their observed treatment status. Unconfoundedness may in this case be a reasonable assumption if motivation were observed. If motivation is not observed, however, the implication is that the potential outcomes would be correlated with the treatment indicator, and thus unconfoundedness would be violated. However, it is not clear that, in such a scenario, using a control person who differs in terms of observed pre-treatment characteristics as the comparison would improve the credibility of the causal interpretation. In order to improve the comparison, one would have to be able to trade off observed pre-treatment characteristics against the unobserved motivation, without direct information on the latter. It would appear often difficult to do so in a credible manner.
A third aspect of our motivation for focusing special attention on the setting with unconfoundedness concerns the interpretation of assignment processes that lead to differences in treatment levels for units who are identical in terms of observed pretreatment characteristics. In randomized experiments the differences in treatment levels are due to randomization. In observational studies it is less clear why such similar

12.2 Regular Assignment Mechanisms

265

units should receive different treatment assignments. Especially in settings where the units are individuals and the assignment mechanism is based on individual choices, one might be concerned that individuals who look ex ante identical (i.e., identical in terms of pre-treatment characteristics) but who make different choices must be different in unobserved ways that invalidates a causal interpretation of differences in their outcomes. Examples of such settings include those where individuals choose to enroll in labor market assistance programs, based on their assessment of the costs and benefits of such programs, and those where medical treatment decisions are made by physicians, in consultation with patients, choosing treatments based on their perceived costs and benefits. However, in such cases, the unobserved differences that lead to differences in treatments need not lead to violations of unconfoundedness. If the unobserved differences that led the individuals to make different choices, are independent of the potential outcomes, conditional on observed covariates, unconfoundedness still holds. This may arise, for example, in settings where unobserved differences in terms of the costs associated with exposure to the treatment are unrelated to the potential outcomes.
Let us make this argument slightly more specific using an example. Suppose two patients with a particular medical condition have identical symptoms. Suppose they also share the same physician. This physician, in consultation with these patients, faces the choice between two treatments, say drug A and drug B. Suppose drug A is expensive relative to drug B. Furthermore, suppose that as a result of differing health insurance plans, the incremental cost of taking drug A relative to drug B is higher for one patient than for the other. This cost difference may well affect the choice of drug, and as a result one may have data on individuals with similar medical conditions exposed to different treatments without violating unconfoundedness (if we assume that the choice of insurance plan is not related to outcomes given exposure to drug A or drug B, especially after conditioning on observed covariates such as sex or age).

12.2.5 Selecting Pre-Treatment Variables for Conditioning
So far, the only requirement we have imposed on the pre-treatment variables is that they precede the treatment, or that they are not themselves affected by the treatment. Variables that are possibly affected by the treatment, such as intermediate outcomes, should not be included in this set, and correctly adjusting for differences in such variables is generally difficult.
Given this set of proper pre-treatment variables, one generally wants to control for as many as possible, or all of them. If we are interested in, for example, the evaluation of a labor market training program on individuals disadvantaged in the labor market, one would like to include detailed labor market histories and individual characteristics of the individuals to eliminate such characteristics as alternative explanations for differences in outcomes between trainees and control individuals. There are some exceptions to this general advice. In some cases there is additional prior information regarding the dependence of potential outcomes on pre-treatment variables that suggests alternative estimation strategies that do not remove differences in all observed pre-treatment variables. An important case is instrumental variables discussed in more detail in Chapters 23­25. In practice, however, such cases are typically easy to recognize and rarely lead

266

Unconfounded Treatment Assignment

to confusion. Variables that are truly instrumental variables are relatively rare, and when they exist, it is even more rare that they are mistakenly used as covariates for adjustment.

12.3 BALANCING SCORES AND THE PROPENSITY SCORE
Now let us return to the theoretical discussion, using a super-population perspective. Under unconfoundedness, we can remove all biases in comparisons between treated and control units by adjusting for differences in observed covariates. Although feasible in principle, in practice this will be difficult to implement with a large number of covariates. The idea of balancing scores is to find lower-dimensional functions of the covariates that suffice for removing the bias associated with differences in the pre-treatment variables. Formally, a balancing score is a function of the covariates such that the probability (in the super-population) of receiving the active treatment given the covariates is free of dependence on the covariates given the balancing score.
Definition 12.1 (Balancing Scores) A balancing score b(x) is a function of the covariates such that
Wi  Xi b(Xi).
(Here we continue to leave the conditioning on parameters implicit in the superpopulation context.) Balancing scores are not unique. By definition, the vector of covariates Xi itself is a balancing score, and any one-to-one function of a balancing score is also a balancing score. We are most interested in low-dimensional balancing scores. One scalar balancing score is the propensity score, the conditional probability of receiving the treatment given Xi = x (or any one-to-one transformation of the propensity score, such as the linearized propensity score or log odds ratio, (x) = ln (e(x)/(1-e(x)))). First, we show that the propensity score is indeed a balancing score:
Lemma 12.1 (Balancing Property of the Propensity Score) The propensity score is a balancing score.
Proof. We show that
Wi  Xi e(Xi),
or, equivalently,
Pr(Wi = 1|Xi, e(Xi)) = Pr(Wi = 1|e(Xi)),
implying that Wi is independent of Xi given the propensity score. First, consider the left-hand side:
Pr(Wi = 1|Xi, e(Xi)) = Pr(Wi = 1|Xi) = e(Xi),
where the first equality follows because the propensity score is a function of Xi and the second is by the definition of the propensity score. Second, consider the right-hand side.

12.3 Balancing Scores and the Propensity Score

267

By the definition of probability and iterated expectations,

Pr(Wi = 1|e(Xi)) = E[Wi|e(Xi)] = E [E[Wi|Xi, e(Xi)]|e(Xi)] = E[e(Xi)|e(Xi)] = e(Xi).

Balancing scores have an important property: if assignment to treatment is unconfounded given the full set of covariates, then assignment is also unconfounded conditioning only on a balancing score:
Lemma 12.2 (Unconfoundedness Given a Balancing Score) Suppose assignment to treatment is unconfounded. Then assignment is unconfounded given any balancing score:
Wi  Yi(0), Yi(1) b(Xi).

Proof. We show that
PrW (Wi = 1|Yi(0), Yi(1), b(Xi)) = PrW (Wi = 1|b(Xi)),
which is equivalent to the statement in the lemma. By iterated expectations we can write
PrW (Wi = 1|Yi(0), Yi(1), b(Xi)) = EW [Wi |Yi(0), Yi(1), b(Xi) ]
= E EW [Wi |Yi(0), Yi(1), Xi, b(Xi) ] Yi(0), Yi(1), b(Xi) .
By unconfoundedness, the inner expectation is equal to E [Wi |Xi, b(Xi) ] and by the definition of balancing scores, this is equal to E[Wi|b(Xi)]. Hence the last expression is equal to
E EW [Wi|b(Xi)] Yi(0), Yi(1), b(Xi) = E[Wi|b(Xi)] = Pr(Wi = 1|b(Xi)),
which is equal to the right-hand side. The first implication of Lemma 12.2 is that, given a vector of covariates that ensure
unconfoundedness, adjustment for treatment-control differences in balancing scores suffices for removing all biases associated with differences in the covariates. The intuition is that, conditional on a balancing score, the treatment assignment is independent of the covariates. Hence, even if a covariate is associated with the potential outcomes, differences in covariates between treated and control units do not lead to bias because they cancel out by averaging over all units with the same value for the balancing score. The situation is analogous to that in a completely randomized experiment, where the distribution of covariates is the same in both treatment arms. Even though the covariates may differ between specific treated and control units with the same value for the balancing score, they have the same distribution of values in the treatment and control groups.
Because the propensity score is a balancing score, Lemma 12.2 implies that, conditional on the propensity score, assignment to treatment is unconfounded. But within the

268

Unconfounded Treatment Assignment

class of balancing scores, the propensity score has a special place, formally described in the following lemma:
Lemma 12.3 (Coarseness of Balancing Scores) The propensity score is the coarsest balancing score. That is, the propensity score is a function of every balancing score.
Proof. Let b(x) be a balancing score. Suppose that we can not write the propensity score as a function of the balancing score. Then it must be the case that for two values x and x we have b(x) = b(x ), and at the same time e(x) = e(x ). Then, Pr(Wi = 1|Xi = x) = e(x) = e(x ) = Pr(Wi = 1|Xi = x ), and so Wi and Xi are not independent given b(Xi) = b(x), which violates the definition of a balancing score.
Because the propensity score is the coarsest possible balancing score, it provides the biggest benefit in terms of reducing the number of variables we need to adjust for. An important difficulty though arises from the complication that we do not know the value of the propensity score for all units, and thus we cannot directly exploit this result.

12.4 ESTIMATION AND INFERENCE
In this section we discuss general issues regarding estimation and inference for causal effects in regular assignment mechanisms. In subsequent chapters we go into more detail for some of our preferred methods, but here we provide a general overview and discuss the merits of various approaches.

12.4.1 Efficiency Bounds
Before discussing some of the specific approaches to estimation, it is useful to examine how well these methods can work. An important tool for this purpose is the semiparametric efficiency bound. This is a generalization of the Crame´r-Rao sampling variance bound for unbiased estimators.
In order to formulate the variance bound, some additional notation is helpful. Define

c(x) = Esp [Yi(0)|Xi = x] ,

t(x) = Esp [Yi(1)|Xi = x] ,

c2(x) = Vsp ( Yi(0)| Xi = x) , and t2(x) = Vsp ( Yi(1)| Xi = x) ,
to be the conditional expectation and conditional variance of the potential outcomes, respectively. These expectations are with respect to the distribution generated by random sampling from the super-population. Furthermore, let sp be the super-population average treatment effect defined as

sp = Esp [Yi(1) - Yi(0)] = Esp sp(Xi) ,

where

sp(x) = t(x) - c(x) = Esp[Yi(1) - Yi(0)|Xi = x].

12.4 Estimation and Inference

269

It is useful to distinguish sp from two other average treatment effects, first, the average effect of the treatment for the sample of N units at hand, or the finite-sample average treatment effect fs,

fs

=

1 N

N

Yi(1) - Yi(0) ,

i=1

and, second, the finite-sample average effect conditional on the values of the pretreatment variables in the finite sample, the conditional average treatment effect,

cond

=

1 N

N i=1

sp(Xi).

In the current setting, under unconfoundedness and probabilistic assignment, and without additional functional form restrictions beyond smoothness, the sampling variance bound for estimators for sp, normalized by the sample size, is

Vespff = Esp

c2(Xi) 1 - e(Xi)

+

t2(Xi) e(Xi)

+

(sp(Xi)

-

sp)2

.

(12.5)

Details and references for this result are provided in the notes at the end of this chapter. This result implies that for any regular estimator (see again the notes for more details), its asymptotic sampling variance, after normalizing by the square root of the sample size, cannot be smaller than Vsepff. The sampling variance bound consists of three terms. The first term shows that it is more difficult to estimate the average treatment effect if there is a substantial number of units with propensity score values close to one, in the sense that any estimator will have a high sampling variance in such cases. Similarly, the second term shows that it is more difficult to estimate the average treatment effect if there is a substantial number of units with propensity score values close to zero. The third term is the variance of the treatment effect conditional on the pretreatment variables. This term is zero if the treatment effect is constant. Overall the variance expression (12.5) shows that, if the population distribution of covariates is unbalanced between treated and control units, the sampling variance of any estimator will be large. This will be important for analyses, and we return to this issue in Chapters 15 and 16.
If instead of focusing on the population average effect sp, we focus on cond, the efficiency bound changes to

Vecoffnd = Esp

c2(Xi) 1 - e(Xi)

+

t2(Xi) e(Xi)

.

We can, at least in principle, estimate cond more accurately than sp because the latter also reflects the difference between the distribution of the covariates in the sample and the population. The intuition for this is easily presented in terms of a simple example. Suppose there is a single binary covariate, with unknown marginal distribution in the

270

Unconfounded Treatment Assignment

super-population, Xi  {f , m}, with Pr(Xi = f ) = p unknown. Suppose we can estimate the average effects sp(f ) and sp(m) accurately for both subpopulations separately because the conditional variances are small, and suppose these average effects differ substantially. Then it follows that we can estimate cond accurately because it is a known function of sp(f ) and sp(m). However, because p is unknown, we would not be able to estimate sp as accurately.
The implication is that it is important for inference to be precise about the estimand. If we focus on fs or cond, we need to use a different estimator for the sampling variance than if we focus on sp.

12.4.2 Strategies for Estimation
We discuss five broad classes of strategies for estimation, with some overlap between them. These four strategies are model-based imputation, weighting, blocking, and matching methods. These four basic approaches differ in their focus on the unknown components of the joint distribution of the potential outcomes, assignment process, and covariates. In this section, we briefly describe these four general approaches, as well as a fifth class of estimators that combines aspects of some of these strategies. Variations of all five of these strategies have been used extensively in empirical work, although we do not recommend all of them. In Chapters 17 and 18 in Part IV, we discuss in more detail the implementation for two specific strategies that we view as particularly attractive in practice. These two strategies are blocking (i.e., subclassification) on the propensity score, in combination with covariance adjustment within the blocks (Chapter 17), and matching, again in combination with covariance adjustment, possibly within the matched pairs (Chapter 18). We view these two approaches as relatively attractive because of the robustness properties that stem from the combination of methods that ensure approximate comparability, either through blocking or matching, with additional bias removal and precision increases through covariance adjustment.
Although all four general approaches aim at estimating the same treatment effects, there are fundamental differences among them. One important difference between the model-based imputations and the other three (weighting, blocking, and matching methods) is that the first requires building models for the potential outcomes, whereas for the other three all decisions regarding the implementation of the estimators without covariate adjustment can be made before seeing any outcome data. This difference is important because not having outcome data prevents the researcher from adapting the model to make it fit prior notions about the treatment effects of interest. Although the researcher does have to make a number of important decisions when using weighting, blocking, and matching methods, these can be implemented in a way that does not introduce bias in the estimates for treatment effects and so have arguably more credibility.
Model-Based Imputation
The first strategy relies on imputing the missing potential outcomes by building a model for the missing outcomes and using this model to predict what would have happened to a specific unit had this unit been subject to the treatment to which it was not exposed. We discussed this approach for completely randomized experiments in Chapter 8, and

12.4 Estimation and Inference

271

the discussion here is closely related. Following the exposition from Chapter 8, we need a model for
Ymis Yobs, X, W.

Given such a model, we can impute the missing data by drawing from the conditional distribution of Ymis given Yobs, W, and X. Suppose we specify a model for the joint
distribution of the two vectors of potential outcomes given the covariates, now explicitly in terms of an unknown parameter :

Y(0), Y(1) X, .

(12.6)

Because of unconfoundedness, W is independent of (Y(0), Y(1)) given X, and the specification of (12.6) implies the distribution

Y(0), Y(1) W, X, ,

(12.7)

which in turns allows us to derive the conditional distribution of the missing data given the observed data following the argument in Chapter 8. We therefore focus on specifying a model for (Y(0), Y(1)) given X. Given exchangeability of the units and an appeal to De Finetti's Theorem, all we need to specify is the joint distribution of

(Yi(0), Yi(1)) Xi,  ,
for some parameter vector . Given such a distribution, we can, following the same approach as in Chapter 8, impute the missing potential outcomes and use the observed and imputed potential outcomes to estimate the treatment effects of interest.
The critical part of this approach is the specification of the joint distribution of (Yi(0), Yi(1)) given Xi and parameter . With no covariates ­ or, more generally, a lowdimensional set of covariates ­ it is relatively easy to specify a flexible functional form for this conditional distribution. If there are many covariates, however, such a specification is more difficult, and the results can be sensitive to alternative choices. This situation is qualitatively different from the randomized experiment setting in Chapter 8, where such sensitivity will often be minor because the covariate distributions in treatment and control groups are similar. Because this approach treats the problem essentially as a prediction one, it is particularly amenable to Bayesian methods with their focus on treating unobserved quantities, including both the missing potential outcomes and unknown parameters, as unobserved random variables.
In this approach, often there is no need to specify a parametric model for the conditional distribution of the treatment indicator given the covariates, the super-population assignment mechanism,

p(W|X; ),

because, if  and  are distinct parameters, inference for causal effects is not affected by the functional form of the specification of this assignment mechanism. However, it is important for this argument that  and  are distinct parameters.

272

Unconfounded Treatment Assignment

The Concern with Regression Estimators
In practice, however, this approach is often used with standard "off-the-shelf" methods, where typically linear models are postulated for average outcomes, without a full specification of the conditional joint potential outcome distribution. Let us briefly consider the linear regression approach here. Suppose we model the potential outcome distributions as normally distributed with treatment-specific parameters governing the conditional means and variances of the potential outcomes:

Yi(0) Yi(1)

Xi,   N

Xic Xit

,

c2 c · t c · t t2

,

where  = (c, t, c2, t2). (Note that the vector of covariates Xi is assumed to include a constant term.) Then we can estimate c and t by least squares methods:

^ cols

=

arg

min


(Yi - Xi)2 ,

and

^ tols

=

arg

min


(Yi - Xi)2 .

i:Wi=0

i:Wi=1

The population and sample average treatment effects are then estimated as

^ ols = 1 N N i=1

Wi · (Yiobs - Xi^cols) + (1 - Wi) · (Xi^tols - Yiobs)

.

We do not recommend this approach, introduced in Chapter 7, in the context of completely randomized experiments, without substantial modifications. The concern with the simple application of this approach is that, in many situations outside randomized experiments, it can rely heavily on extrapolation. To see this, it is useful to rewrite the estimator as

^ ols

=

Nt

Nt + Nc

·

^tols

+

Nc Nt + Nc

·

^cols,

where ^cols and ^tols are estimators for the population average effect of the treatment for the control and treated units, respectively:

^cols

=

1 Nc

i:Wi=0

Xi^t - Yiobs

,

and

^tols

=

1 Nt

i:Wi=1

Yiobs - Xi^c

.

Furthermore, because of the presence of a constant term in Xi, we can write ^t as

^tols

=

Y

obs t

-

X t ^ cols

=

Y

obs t

-

Y

obs c

-

(Xt

-

X c )^ cols ,

(12.8)

and similarly

^cols

=

X c ^ tols

-

Y

obs c

=

Y

obs t

-

Y

obs c

-

(Xt

-

X c )^ tols .

(12.9)

The last terms in expressions (12.8) and (12.9), (Xt - Xc)^cols and (Xt - Xc)^tols, are
at the core of the concern. If the two covariate distributions are substantially apart, the difference Xt - Xc is substantial. Then the "adjustment" terms (Xt - Xc)^cols and (Xt - Xc)^tols will be sensitive to details of the specification of the regression function. In

12.4 Estimation and Inference

273

the context of completely randomized experiments, this was less of an issue, because the randomization ensured that, at least in expectation, the covariate distributions were balanced, with EW Xt - Xc = 0, with the expectation taken over the randomization distribution. Here, in contrast, the covariate distributions can be far apart even under unconfoundedness. Prior to using regression methods or other modeling approaches, therefore, one has to ensure that there is balance in the two covariate distributions. We return to this issue in Section 12.5 and in more detail in Chapters 14 and 15.

Weighting Estimators That Use the Propensity Score
Whereas the first strategy focused on estimating the two conditional outcome distributions, or at least the two conditional regression functions, the second strategy focuses on estimating the propensity score. Given knowledge of the propensity score, one can directly use some of the strategies that apply to the analysis of randomized experiments with variation in assignment probabilities. Such possible strategies include weighting, subclassification (similar to stratification in the case of randomized experiments), and matching. The key difference between these and the general imputation strategy is that the former three focus on modeling and estimating the conditional probability of assignment, whereas an imputation strategy models the conditional outcome distributions. The issues in implementing any of these three methods therefore are related to estimation of the propensity score. One approach is to treat the estimation of the propensity score as a standard problem of estimating an unknown regression function with a binary outcome and exploit the relevant literature. An alternative approach, more widely used in the evaluation literature, focuses on the essential property of the propensity score, that of balancing the covariates between treated and control groups. In this approach a specification is sought for the propensity score such that, within blocks with similar values of the propensity score, the first few (cross) moments of the covariates are balanced between treatment groups.
The first method involving the propensity score is weighting. Weighting exploits the two equalities

E Yiobs · Wi e(Xi)

= Esp [Yi(1)] ,

and

E

Yiobs · (1 - Wi) 1 - e(Xi)

= Esp [Yi(0)] .

(Here we again index expectations by sp if they are over the distribution generated by random sampling from the super-population and by W if they are over the randomization distribution. Expectations without a subscript are over both the randomization and the random sampling from the super-population.) These equalities follow by taking iterated expectations, and exploiting unconfoundedness, for example,

E

Yiobs · Wi e(Xi)

= Esp E

Yiobs · Wi e(Xi)

Xi

= Esp

E

Yi(1) · Wi e(Xi)

Xi

274

Unconfounded Treatment Assignment

= Esp

Esp[Yi(1)|Xi] · EW [Wi|Xi] e(Xi)

= Esp Esp[Yi(1)|Xi] = Esp [Yi(1)] ,

and similarly for the second equality. One can exploit these equalities by estimating the average treatment effect as

^ ht = 1 N Wi · Yiobs - 1 N (1 - Wi) · Yiobs

N i=1 e(Xi)

N i=1 1 - e(Xi)

=1 N

i

·

Yiobs

-

1 N

i · Yiobs,

i:Wi=1

i:Wi=0

where

i

=

e(Xi)Wi

1 · (1 - e(Xi))1-Wi

=

1/(1 - e(Xi)) if Wi = 0,

1/e(Xi)

if Wi = 1.

The superscript "ht" here stands for Horvitz and Thompson (1952) who introduced, in
a somewhat different setting, the weighting by the inverse of the selection probability.
In practice typically we do not know the true population propensity score, and we have to use an estimate of the propensity score, e^(x) in place of e(x), for the corresponding estimated weights. In addition, instead of using the weights i directly, one can adjust the weights, so that they add up to the sample size for each treatment group, that is, use ^ i, where

^ i =

N · (1 - e^(Xi))-1/ j:Wj=0 (1 - e^(Xi)-1 if Wi = 0,

N · e^(Xi)-1/ j:Wj=1 e^(Xi)-1

if Wi = 1.

Just like we do not recommend the simple regression estimator, we do not recommend this type of estimator in settings with a substantial difference in the covariate distributions by treatment status. In a completely randomized experiment, the propensity score would be constant, and even when the propensity score is estimated, the weights are likely to be similar for all treated and for all control units. In contrast, when the covariate distributions are far apart, the estimated propensity score will be close to zero or one for some units, and the weights, proportional to 1/e^(Xi) or 1/(1 - e^(Xi)), can be large. As a result, in such settings estimators can be sensitive to minor changes in the specification of the model for the propensity score.

Blocking Estimators That Use the Propensity Score
A more robust approach involving the propensity score is to coarsen it through blocking (i.e., subclassification). In this third approach, the sample is partitioned into subclasses, based on the value of the estimated propensity score. Within each subclass, the data can be analyzed as if they arose from a completely randomized experiment. Let bj, j = 0, 1, . . . , J denote the subclass boundaries, with b0 = 0 and bJ = 1, and let Bi(j) be a binary indicator, equal to 1 if bj-1 < e^(Xi) < bj, and zero otherwise. Then we

12.4 Estimation and Inference

275

estimate the finite-sample average effect in subclass j, fs(j), by ^ dif(j), the difference in the average outcome for treated and control units in this subclass:

^ dif(j) =

i:Bi(j)=1 Yi · Wi - i:Bi(j)=1 Wi

i:Bi(j)=1 Yi · (1 - Wi) . i:Bi(j)=1 (1 - Wi)

To estimate the overall finite-sample average effect of the treatment, fs, we average these within-block differences ^ dif(j),

^ strat = J N(j) · ^ dif(j), N
j=1

where N(j) =

N i=1

Bi

(j),

and

the

label

"strat"

is

used

to

stress

the

connection

with

the estimators used in the stratified randomized experiments discussed in Chapter 9.

Although this method is more robust than the weighting estimator to the presence of units

with extreme values of the estimated propensity score, we still do not recommend it with-

out some modifications. In particular, we recommend reducing the bias and increasing

the precision further by using covariance adjustment within the subclasses. In Chap-

ter 17 we describe our specific approach to combining subclassification and covariance

adjustment in detail.

Matching Estimators
Unlike model-based imputation and weighting and blocking methods, the fourth approach, matching, does not always rely on estimating an unknown function. Instead it relies on finding direct comparisons, that is, matches, for each unit. For a given treated unit with a particular set of values for the covariates, one looks for a control unit with as similar a set of covariates as possible. This approach has great intuitive appeal. Suppose we wish to assess the effect of a job-training program on the labor market outcomes for a particular person, say a thirty-year-old woman with two children under the age of six, with a high school education and four months of work experience in the past twelve months, who went through this training program. In the matching approach we look for a thirty-year-old woman with two children under the age of six, with a high school education and four months of work experience in the past twelve months, who did not attend the training program. If exact matches can be found, this is a particularly attractive and simple strategy. If no exact matches can be found, which is typically the case if the number of covariates is large compared to the number of units, this approach becomes more unwieldy. In that case one needs to assess the trade-offs of different violations of exact matching. Who should we use as a match for the thirty-year-old woman with two children and four months of work experiments who went through the training program? One possibility may be a woman from the control group who is four years older, with two months more work experience. A second possibility might be a woman who is two years younger with only one child and two months fewer work experience in the past twelve months. Assessing the relative merits of such matches requires careful inspection of the joint distribution of the covariates and substantive knowledge of the relative importance of the different characteristics for predicting outcomes. Clearly, as soon as

276

Unconfounded Treatment Assignment

such compromises need to be made, matching is more difficult to implement. Difficulties in dealing with many covariates show up here in a different form than in the model-based imputation methods, but they do not disappear. With many covariates, the quality of the matching, measured by some metric of the typical distance between covariates of units and the covariates of their matches, decreases. To implement the matching approach, one needs to be able to assess the trade-offs in choosing between different controls, and this requires a distance metric. We discuss in Chapter 18 some of the choices that have been used in the literature.

Mixed Estimators
In addition to the four basic approaches, there are a number of estimation methods that combine features of two or more of these basic methods in an attempt to combine the benefits of each of them. Regression (i.e., covariance adjustment), for example, is a powerful and effective method for adjusting for modest between-group differences, but it is less effective when the covariate distributions differ substantially between treatment and control groups. Using regression, not globally, but only within blocks with similar covariate distributions for treated and control units ­ for example, defined by the estimated propensity score ­ may therefore combine attractive properties of regression adjustment in relatively well-balanced samples with the robustness of subclassification methods across different distributions. Similarly one can combine matching with regression, again exploiting the strengths of both methods. We view these two combinations, subclassification with covariate adjustment within subclasses, and matching with covariance adjustment, as two of the more attractive methods in practice for estimating treatment effects with regular assignment mechanisms, especially when flexibly implemented. We discuss these approaches, and specific methods for implementing them, in more detail in Chapters 17 and 18.

12.5 DESIGN PHASE
Prior to implementing any of the methods for estimating causal effects in settings with regular assignment mechanisms, it is important to conduct what we call the design phase of an observational study. In this stage, we recommend investigating the extent of overlap in the covariate distributions. This, in turn, may lead to the construction of a subsample more suitable for estimating causal estimands, in the sense of being better balanced in terms of covariate distributions. There is one important feature of this initial analysis: this stage does not involve the outcome data, which need not be available at this stage, or even collected yet. As a result, this analysis cannot be "contaminated" by knowledge of estimated outcome distributions, or by preferences, conscious or unconcious, for particular results.
12.5.1 Assessing Balance The first part of the design stage is to assess the degree of balance in the covariate distributions between treated and control units, which involves comparing the distributions of

12.5 Design Phase

277

covariates in the treated and control samples. We focus on a couple of specific statistics that are useful in assessing the imbalance. First is the difference in average covariate values by treatment status, scaled by their sample standard deviation. This provides a scale-free way to assess the differences. As a rule-of-thumb, when treatment groups have important covariates that are more than one-quarter or one-half of a standard deviation apart, simple regression methods are unreliable for removing biases associated with differences in covariates, a message that goes back to the early 1970s but is often ignored.
Beyond looking at simple differences in average covariate values, we focus on the distributions of the propensity score. If the super-population covariate distributions are identical in the two treatment groups, then the true propensity score must be constant, and vice versa. Variation in the estimated propensity score is therefore a simple way to assess differences between two multivariate distributions. In practice we rarely know the propensity score ex ante, and so we typically have to estimate it, which involves choosing a specification for the propensity score and estimating the unknown parameters of that specification. In Chapter 13 we discuss flexible methods for doing so.
We discuss the specific methods for comparing covariate distributions and assessing balance in detail in Chapter 14.

12.5.2 Subsample Selection Using Matching on the Propensity Score
If the basic sample exhibits a substantial amount of imbalance, we may wish to construct a subsample that is characterized by better balance. Such a subsample leads to more robust and thus more credible causal inferences. In Chapter 15 we provide details for one method of implementing this approach that relies on having a relatively large number of controls and is appropriate for settings where we are interested in the effect of the treatment on the subpopulation of treated units. The proposed procedure consists of two steps. First we estimate the propensity score. Then we sequentially match each treated unit to the closest control unit in terms of the estimated propensity score, typically with the treated units ordered by decreasing estimated propensity score, although the order rarely matters much in practice. We match here without replacement, leading to matched samples with an equal number of treated and control units. We do not simply estimate the average effect of the treatment by taking the difference in average outcomes for the matched sample. Rather, within this matched sample, we apply some of the adjustment methods introduced previously, including those that allow for estimation of more general causal estimands than average effects, with the expectation that, because this sample has better covariate balance, the estimators for the matched sample will be more robust than the corresponding estimators applied to the original, full sample.

12.5.3 Subsample Selection through Trimming Using the Propensity Score
In Chapter 16 of the text, we discuss in more detail a second method for constructing balanced samples that also uses the estimated propensity score. The idea here is that for units with covariate values such that the propensity score is close to zero or one, it is difficult to obtain precise estimates of the typical effect of the treatment

278

Unconfounded Treatment Assignment

because, for such units, there are few controls relative to the number of treated units, or the other way around. We therefore propose putting aside such units and focusing on estimating causal effects in the subpopulation of units with propensity score values bounded away from zero and one. More precisely, we discard all units with estimated propensity scores outside an interval, and we propose a specific way to chose the interval.

12.6 ASSESSING UNCONFOUNDEDNESS
In Chapter 21, in Part V of the text, we discuss methods for assessing the unconfoundedness assumption. We purposely use the term "assess" here rather than "test," because unconfoundedness has no directly testable implications. Nevertheless, there are a number of stastistical analyses that we can conduct that can shed light on its plausibility. Some of these analyses, like the analyses assessing balance, do not involve the outcome data, and so are part of the design stage. The conclusion from such analyses can be that one may deem unconfoundedness an unattractive assumption for the specific data at hand and decide not to pursue further analyses with the outcome data; or it can be that one decides that unconfoundedness is plausible, and analyses based on this assumption are credible. Here we briefly introduce three of these analyses.
12.6.1 Estimating the Effect of the Treatment on an Unaffected Outcome The first set of assessments focuses on estimating the causal effect of the treatment on a variable that is known a priori not to be affected by the treatment, typically because its value is determined prior to the treatment itself. Such a variable can be a time-invariant covariate, but the most interesting case is where this is a lagged outcome. In this case, one uses all the covariates except the single covariate that is being assessed, say the lagged outcome. One estimates the pseudo-treatment effects on the lagged outcome. If these estimated effects are near zero, it is deemed more plausible that the unconfoundedness assumption holds than if the estimated effects are large. Of course, the assessment is not directly testing the unconfoundedness assumption, and so, no matter what the pvalue of the null hypothesis of no effect, it does not directly reflect on the assumption of interest, unconfoundedness. Nevertheless, if the variables used in this proxy test are closely related to the outcome of interest, the assessment has arguably more force than if the variables are unrelated to the outcome of interest. For these analyses, it is clearly helpful to have a number of lagged outcomes. This approach is a design approach, not using any outcome data.
12.6.2 Estimating the Effect of a Pseudo-Treatment on the Outcome The second set of assessments focuses on estimating the causal effect of a different treatment on the original outcome, and in particular a pseudo-treatment that is known a priori not to have an effect. This approach relies on the presence of multiple control groups and uses actual outcome data, but only for the control units. Suppose one has two possible control groups. One interpretation of the assessment is that one compares estimated treatment effects calculated using one control with average treatment effects calculated using the other control group. This procedure can also be interpreted

Notes

279

as estimating an average treatment effect using only the two control groups, with the treatment indicator redefined as an indicator for one of the two control groups. In that case, the pseudo-treatment effect is known to be zero, and statistical evidence of a nonzero estimated treatment effect suggests that, for at least one of the control groups, the unconfoundedness assumption is violated. Again, failure to reject this "test" does not mean the unconfoundedness assumption is valid because it could be that both control groups have similar biases, but non-rejection in the case where the two control groups are a priori likely to have different biases makes it more plausible that the unconfoundness assumption holds. The key for the value of this assessment is to have control groups that are likely to have different biases, if at all. One may use different geographic control groups, for example on either side of the treatment group. This approach is a semi-design approach, using only outcome data for the control units.

12.6.3 Assessing Sensitivity of Estimates to the Choice of Pre-Treatment Variables
The last approach for assessing the unconfoundedness assumption uses outcome data for all units. The idea is to partition the covariates again into two parts. Now the assessment involves comparing estimates for treatment effects using only a subset of the covariates to those for the full set of covariates. Substantial differences suggest that either unconfoundedness relies critically on all covariates, or it does not hold. Because this approach uses outcome data for all units, it is not a (semi-)design approach.

12.7 CONCLUSION
In this chapter we discussed the assumptions underlying regular assignment mechanisms and provided a brief overview of Parts III through V of this text. We focused primarily on the generally most controversial of these assumptions, unconfoundedness, and provided motivation for the central role this assumption plays in the third and fourth parts of this book. We then described briefly how estimation and inference may proceed with regular assignment mechanisms. In settings where the pre-treatment variables take on few distinct values in the sample, the analysis is simple and follows exactly the same path as that under stratified randomized experiments. The more challenging setting is that where the covariates take on too many distinct values in the sample to allow for exact stratification on the covariates with each stratum having both treated and control units. It is this setting that is the focus of a large theoretical literature in statistics and related disciplines. In Chapters 13­22 we provide details on the methods we view as most promising in practice in this setting.
NOTES
The term "unconfoundedness" was introduced in Rubin (1990a, p. 284). Other terms have been used to describe the same, or closely related, assumptions. Rosenbaum and Rubin (1983a) refer to the combination of unconfoundedness and the assumption that

280

Unconfounded Treatment Assignment

assignment is probabilistic as "strong ignorability." Lechner (1999) and Angrist and Pischke (2008) use the term "conditional independence assumption" for the unconfoundedness assumption. The concept of unconfoundedness is closely related to what in the econometrics literature is called "exogeneity." There are no widely agreed upon definitions of exogeneity, although some authors do view it as synonymous with unconfoundedness. Manski, Sandefur, McLanahan, and Powers (1992, p. 28) describe the treatment indicator in this setting as "`exogenous,' or synomymously, `strongly ignorable."' Imbens (2004) discusses the link with definitions of exogeneity in parametric regression models. Following the work by Barnow, Cain, and Goldberger (1980) in a regression setting, it is also referred to as "selection on observables." For a standard discussion of exogeneity in the econometric literature, see Engle, Hendry, and Richard (1974). For general discussions of unconfoundedness in the econometrics literature, with different perspectives, see Blundell and Costa-Dias (2000, 2002), Imbens (2004), and Heckman and Vytlacil (2007ab)
Hirano and Imbens (2001), Huber, Lechner, and Wunsch (2012), and Belloni, Chernozhukov, and Hansen (2014) discuss methods for variable selection in the context of estimating the propensity score. Rosenbaum (1984b) discusses the concerns when adjusting for covariates that are affected by the treatment.
Early applications in economics include Ashenfelter (1978), Ashenfelter and Card (1985), and Card and Sullivan (1988). The semiparametric efficiency bound for sp is derived in Hahn (1998). See also Hirano, Imbens, and Ridder (2003).
The merits of and concerns with regression (covariance) adjustments in settings where the covariate distributions differ substantially between treatment and control groups are discussed in Cochran (1965, 1968), Rubin (1973b, 1979, 2006), and Cochran and Rubin (1973).
Rosenbaum (2009) and Rubin (2007, 2008) discuss the importance of the design stage of an observational study. The discussion in Section 12.6.2 is closely related to Rosenbaum's (1987) notion of multiple control groups. An early application of these ideas is in Lalonde (1986).
There is also a literature concerned with the difficulties of adjusting for many covariates. See Angrist and Hahn (2004), Robins and Ritov (1997), Robins and Rotnitzky (1995), and Belloni, Chernozhukov, and Hansen (2014).
There is now much software available for implementing these methods. Software includes STATA programs by Becker and Ichino (2002), Abadie, Drukker, Herr, and Imbens (2003), and Sianesi (2001), and R-programs by Sekhon (2004­2013) and Hansen (2006).

CHAPTER 13
Estimating the Propensity Score
13.1 INTRODUCTION
Many of the procedures for estimating and assessing causal effects under unconfoundedness involve the propensity score. In practice it is rare that we know the propensity score a priori in settings other than those involving randomized experiments. Such practical settings could have complex designs where the unit-level probabilities differ in known ways. An example is the allocation of admissions to students applying for medical school in The Netherlands in the 1980s and 1990s. Based on high school grades, applicants would be assigned a priority score that determined their probability of getting admitted to medical school. The actual admission to medical school was then based on a (random) lottery. Such settings are rare, however, and a more common situation is where, given the pre-treatment variables available, a researcher views unconfoundedness as a reasonable approximation to the actual assignment mechanism, with only vague a priori information about the form of the dependence of the propensity score on the observed pre-treatment variables. For example, in many medical settings, decisions are based on a set of clinically relevant patient characteristics observed by doctors and entered in patients' medical records. However, there is typically no explicit rule that requires physicians to choose a specific treatment based on particular values of the pre-treatment variables. In light of this degree of physician discretion, there is no explicitly known form for the propensity score. In such cases, for at least some of the methods for estimating and assessing treatment effects discussed in this part of the book, the researcher needs to estimate the propensity score. In this chapter we discuss some specific methods for doing so.
It is important to note that the various methods that will be discussed in the chapters following this one, specifically Chapters 14­17, use the propensity score in different ways. Some of these methods rely more heavily than others on an accurate approximation of the true propensity score by the estimated propensity score. As a consequence, estimators for the treatment effects may be more or less sensitive to the decisions made in the specification of the propensity score. For example, one way in which we can use the propensity score is to construct strata or subclasses, within which further adjustment methods can be used. In that case, the exact specification will likely matter less than when using methods where we rely solely on weighting by the inverse of the estimated propensity score to eliminate all biases in estimated treatment effects arising
281

282

Estimating the Propensity Score

from differences in covariates distributions. Such "Horvitz-Thompson" type weighting methods, briefly discussed in Chapter 12, are therefore not emphasized in this text.
In the basic problem we study in this chapter, we have a sample of N units, viewed as a random sample from an infinite super-population. Each unit in this super-population is either exposed to, or not exposed to, the treatment. In the sample, Nc units are exposed to the control treatment and Nt units are exposed to the active treatment, with N = Nc + Nt. As usual, the observed treatment indicator is denoted by Wi  {0, 1} for unit i. For each unit in the sample, we also observe a K-component row vector of pre-treatment variables, denoted by Xi for unit i. Although many of the uses for the propensity score described in later chapters are motivated by the assumption of unconfoundedness, we do not explicitly use this assumption in the current chapter. In this chapter, the sole focus is on the statistical problem of estimating the conditional probability of receiving the treatment given the observed covariates,

Pr(Wi = 1|Xi = x) = E [Wi|Xi = x] ,

(13.1)

which is equal to the super-population propensity score, e(x), and we will use that notation here. (Here, for ease of notation we continue to omit the conditioning on the parameters governing these distributions.) If the covariate Xi is a binary scalar, or more generally takes on only a few values, the statistical problem of estimating the propensity score is straightforward: we can simply partition the sample into subsamples that are homogeneous in the values of the covariates, and estimate the propensity score for each subsample as the proportion of treated units in that subsample. Using such a fully saturated model is not feasible in many realistic settings. Often we find that many strata defined by unique values of the covariates in the sample contain only a single unit, so that the proportion of treated units within the stratum is either zero or one. Such an occurence makes many of the methods that rely on the estimated propensity score discussed in this text infeasible, and therefore we explicitly focus in this chapter on settings where the covariates take on too many values to allow for a fully saturated model, so that some form of smoothing is essential.
The goal is to obtain estimates of the propensity score that balance the covariates between treated and control subsamples. More precisely, we would like to have an estimate of the propensity score such that, within subsamples with similar values of the estimated propensity score, the distribution of covariates among the treated units is similar to the distribution of covariates among the control units. This criterion is somewhat vague, and we elaborate on its implementation later. First, it is important to note, however, that the goal is not simply to get the best estimate of the propensity score in terms of mean-integrated-squared-error, or a similar criterion based on minimizing the difference between the estimated and true propensity score. Such a criterion would always suggest that using the true propensity score is preferable to using an estimated propensity score. In contrast, for our purposes, it is often preferable to use the estimated propensity score. The reason is that using the estimated score may lead to superior covariate balance in the sample compared to that achieved when using the true super-population propensity score. For example, in a completely randomized experiment with a single binary covariate (but the assignment probability free of dependence on that covariate),

13.1 Introduction

283

using the estimated propensity score to stratify units would lead to perfect within-stratum balance on the covariates in the sample, whereas using the true propensity score generally would not. The difficulty is that our criterion, in-sample balance in the covariates given the (estimated) propensity score, is not as easy to formalize and operationalize as some of the conventional goodness-of-fit measures,
There are two parts to the proposed algorithm for specifying the propensity score. First we specify an initial model, motivated by substantive knowledge. Second, we assess the statistical adequacy of an estimate of that initial model, by checking whether the covariates are balanced within strata defined by the estimated propensity score. In principle, one can iterate back and forth between these two stages, specification of the model and assessment of that model, each time refining the specification of the model. In this chapter we describe an automatic procedure (i.e., an algorithm) for selecting a specification that can, at the very least, provide a useful starting point for such an iterative procedure, and in many cases will lead to a fairly flexible specification with good balancing properties. The specific procedure selects a subset of the covariates to enter linearly into specification of the propensity score, as well as a subset of all second-order interactions of the basic set of linearly included covariates. Although, in principle, one can also include third- and higher-order terms, in our practical experience it is rare that such higher-order terms substantially improve balance for the sample sizes and data configurations commonly encountered in practice. Of course, what is "linear" and what is "higher order" depends on what initial transformation of the covariates has been applied. If one wishes to allow for the inclusion of third- and higher-order terms, or have functions of the covariates such as logarithms, or indicators for regions of the covariate space, one can easily do so by selecting them following largely the same procedure that we discuss for selecting second-order terms.
Three general comments are in order. First, it is important to keep in mind that during this entire process, and in fact in this entire chapter, we do not use the outcome data, and there is, therefore, no way of deliberately biasing the final estimation results for the treatment effects. Consequently, there is no concern regarding the statistical properties of the ultimate estimates of the average treatment effects obtained from iterating back and forth between (i) the specification of the propensity score, and (ii) balance assesments of the estimated propensity score, until an adequate specification is found.
A second point is that, in general, it is difficult to give a fully automatic procedure for specifying the propensity score in a way that leads to a specification that passes all the tests and diagnostics that we may subject that specification to in the second stage. The specification may be much improved by incorporating subject-matter knowledge regarding the role of the covariates in the treatment assignment decision and the outcome process. We therefore emphatically recommend against relying solely and routinely on automatic procedures. Nevertheless, we do present some automatic procedures that lead to flexible specifications of the propensity score, specifications that are increasingly flexible as the sample size grows. Such automatic procedures can provide useful starting points, as well as benchmarks for comparisons against more sophisticated and scientifically motivated specifications. Our procedure is likely to be an improvement over commonly used approaches, such as simply including all pre-treatment variables linearly in a logistic model specification. We should also note that there are many other

284

Estimating the Propensity Score

algorithms one could use for specifying models for the propensity score, and we provide references to some of them in the notes to this chapter.
A final point to emphasize is that the primary goal is to find an adequate specification of the propensity score, in the sense of a specification that achieves statistical balance in the covariates. We are not directly interested in a structural, behavioral, or causal interpretation of the propensity score, although inspecting and assessing the strength and nature of the dependence of the propensity score on the covariates may be helpful when assessing the plausibility of the unconfoundedness assumption. Finding an adequate specification is, therefore, in essence, a statistical problem that relies less on subject-matter knowledge than other aspects of the modeling of causal effects. The goal is simply to find a specification for the propensity score that leads to adequate balance between covariate distributions in treatment and control groups in our sample.
The remainder of this chapter is organized as follows. The next section describes the data used in this chapter, which come from a study of the effect of barbituate exposure on cognitive outcomes. In Section 13.3 we discuss methods for choosing the specification of the propensity score, that is, selecting the covariates for inclusion in the specification of the propensity score. Although for purposes of obtaining balanced samples a simple linear specification for the propensity score may well be adequate, we follow a conventional approach in the literature and use logistic regression models. In Section 13.4 we illustrate our proposed covariate selection procedure with the barbituate data. In the remainder of this chapter we discuss methods for assessing the adequacy of the specification of the propensity score. We do so by assessing whether, conditional on values of the estimated propensity score, the covariates are uncorrelated with the treatment indicator, that is, whether the mean covariate values for the controls are approximately equal, conditional on the estimated propensity score. We implement this idea by first constructing strata (i.e., subclasses or blocks) within which the estimated propensity score is almost constant. In Section 13.5 we discuss an automatic method for constructing such blocks. In Section 13.6 we illustrate this method with the barbituate data. In Section 13.7 we discuss assessing within-block balance in the covariates. In Section 13.8 we illustrate this, again using the barbituate data. Section 13.9 concludes.

13.2 THE REINISCH ET AL. BARBITUATE EXPOSURE DATA
The data we use to illustrate the methods in this chapter come from a study of the effect of prenatal exposure to barbituates (Reinisch, Sanders, Mortenson, and Rubin, 1995). The data set contains information on N = 7,943 men and women born between 1959 and 1961 in Copenhagen, Denmark. Of these 7,943 individuals, Nt = 745 men and women had been exposed in utero to substantial amounts of barbituates due to maternal medical conditions. The comparison group consists of Nc = 7,198 individuals from the same birth cohort who were not exposed in utero to barbituates. The substantive interest is in the effect of the barbituate exposure on cognitive development measured many years later, although we do not access the outcome information in this chapter. The data set contains information on seventeen covariates that are potentially related to both the outcomes of interest, reflecting cognitive development, and the likelihood of having been

13.3 Selecting the Covariates and Interactions

285

Table 13.1. Summary Statistics Reinisch Data Set

Label Variable Description

Controls

Treated

(Nc =7198) (Nt =745)

t-Stat

Mean (S.D.) Mean (S.D.) Difference

sex

Sex of child (female is 0)

0.51 (0.50) 0.50 (0.50)

antih Exposure to antihistamine

0.10 (0.30) 0.17 (0.37)

hormone Exposure to hormone treatment

0.01 (0.10) 0.03 (0.16)

chemo Exposure to chemotherapy agents

0.08 (0.27) 0.11 (0.32)

cage Calendar time of birth

-0.00 (1.01) 0.03 (0.97)

cigar Mother smoked cigarettes

0.54 (0.50) 0.48 (0.50)

lgest Length of gestation (10 ordered categories) 5.24 (1.16) 5.23 (0.98)

lmotage Log of mother's age

-0.04 (0.99) 0.48 (0.99)

lpbc415 First pregnancy complication index

0.00 (0.99) 0.05 (1.04)

lpbc420 Second pregnancy complication index

-0.12 (0.96) 1.17 (0.56)

motht Mother's height

3.77 (0.78) 3.79 (0.80)

motwt Mother's weight

3.91 (1.20) 4.01 (1.22)

mbirth Multiple births

0.03 (0.17) 0.02 (0.14)

psydrug Exposure to psychotherapy drugs

0.07 (0.25) 0.21 (0.41)

respir Respiratory illness

0.03 (0.18) 0.04 (0.19)

ses

Socioeconomic status (10 ordered categories) -0.03 (0.99) 0.25 (1.05)

sib

If sibling equal to 1, otherwise 0

0.55 (0.50) 0.52 (0.50)

-0.3 4.5 2.5 2.5 0.7
-3.0 -0.3 13.8
1.2 55.2 0.7 2.0 -1.9 9.1
0.7 7.0 -1.6

prescribed and taking, barbituates. Many of the covariates relate to the mother's physical and socioeconomic situation and thus are plausibly related to children's subsequent cognitive development.
Table 13.1 presents summary statistics for the data, including averages and standard deviations for the two groups, and t-statistics assessing the test of the null hypothesis of equality of means of the covariates in the control and treatment groups. It is clear that the two groups differ substantially in the distribution of their background characteristics. The subsample of individuals exposed in utero to barbituates has, on average, higher socioeconomic status, older mothers, and a higher prevalence of pregnancy complications (in particular, the second composite pregnancy complication index lpbc420). Such differences may bias a simple comparison of outcomes by treatment status and suggest that, at the very least, adjustments for pre-treatment differences are required to obtain credible inferences for the causal effect of barbituate exposure, on, say, cognitive development outcomes.

13.3 SELECTING THE COVARIATES AND INTERACTIONS
In many empirical studies, the number of covariates can be large relative to the number of units. As a result, it is is not always feasible simply to include all covariates in a model for the propensity score. Moreoever, for some of the most important covariates, it may not be sufficient to include them only linearly, and we may wish to include functions, such as logarithms, and higher-order terms, such as quadratic terms, or interactions between

286

Estimating the Propensity Score

the basic covariates. Here we describe a stepwise procedure for selecting the covariates and higher-order terms for inclusion in the propensity score. In the notes to this chapter, there are references to alternative flexible methods for finding a suitable specification for the propensity score, where again "suitable" refers to obtaining balance on the important covariates.
We focus here on logistic regression models where the log odds ratio of receiving the treatment is modeled as linear in a number of (functions of) the basic covariates, with unknown coefficients. We estimate the coefficients by maximum likelihood; see the Appendix for details. The main question now concerns the selection of the functions of the basic covariates to include in the specification.
The approach starts with the K-component vector of covariates Xi. We select a subset of these K covariates to be included linearly when estimating the log odds ratio of the propensity score, as well as a subset of all K · (K + 1)/2 second-order terms (both quadratic and interactions terms). This leads to a potential set of included predictors equal to K + K · (K + 1)/2 = K · (K + 3)/2. We do not directly compare all possible subsets of this set because this might be too large for commonly encountered values of K (the number of such subsets is 2K·(K+3)/2). Instead we follow a stepwise procedure with three stages.
In the first stage, we select a set of KB basic covariates to be included in the propensity score, regardless of their statistical association with the treatment indicator, because they are viewed as important on substantive grounds. These substantive grounds may be based on a priori expected associations with the assignment process, or a priori expected associations with the outcome. In the second stage, we decide which of the remaining K - KB covariates will also be included linearly to estimate the log odds ratio. At the conclusion of this step, we have a total of KL covariates entering linearly in the log odds ratio. In the third stage we decide which of the KL · (KL + 1)/2 interactions and quadratic terms involving the KL selected covariates to include. This stage will lead to the selection of KQ second-order terms, leaving us with a vector of covariates with KL + KQ components to be included linearly in the specification of the log odds ratio.
Now let us consider each of these three stages in more detail.

Step 1: Basic Covariates In the first step we decide to include KB basic covariates on substantive grounds, which may include covariates that are a priori viewed as important for explaining the assignment and plausibly related to some outcome measures. It may also be that KB = 0 if the researcher has little substantive knowledge regarding the relative importance of the covariates. In evaluations of labor market programs, this step might lead to including covariates that are viewed as important for the decision of the individual to participate, such as recent labor market experiences. The set of covariates selected at this stage may also include covariates that are a priori viewed as likely to be strongly associated with the outcomes. Again, in the setting of labor market programs, this could include proxies for human capital, such as prior earnings or education levels. In the barbituate exposure example analyzed in this chapter, this set includes three pre-treatment variables: mother's age (lmotage), which is plausibly related to cognitive outcomes for the child; socioeconomic status (ses), which is strongly related to the number of physician visits during pregnancies and thus exposes the mother to greater risk of barbituate prescriptions;

13.3 Selecting the Covariates and Interactions

287

and, finally, sex of the child (sex), which may be associated with measures of cognitive outcomes.

Step 2: Additional Linear Terms
In the second step we select some of the remaining covariates for inclusion in the speci-
fication of the propensity score. There are K - KB covariates not included yet. We only consider at most (K - KB) of the 2K-KB different subsets involving these covariates. Exactly how many and which of the subsets we consider depends on the configuration
of the data. We consider one of the remaining covariates at a time, each time checking
whether we wish to add it. More specifically, suppose that at some point in the covariate selection process, we have selected K~L linear terms, including the KB terms selected in the first step. At that point we are faced with the decision whether to include an additional covariate from the set of K - K~L covariates, and if so, which one. This decision is based on the results of K - K~L additional logistic regression models. In each of these K - K~L additional logistic regression models, we add to the basic specification with K~L covariates and an intercept, a single one of the remaining K - K~L covariates. For each of these K - K~L specifications, we calculate the likelihood ratio statistic assessing the null hypothesis that the newly included covariate has a zero coefficient. If all the likeli-
hood ratio statistics are less than some pre-set constant CL, we stop, and we include only the K~L covariates linearly. If at least one of the likelihood ratio test statistics is greater than CL, we add the covariate with the largest likelihood ratio statistic. We now have K~L + 1 covariates, and check whether any of the remaining K - K~L - 1 covariates should be included by calculating likelihood ratio statistics for each of them. We continue this
process until none of the remaining likelihood ratio statistics exceeds CL. This second stage leads to the addition of KL - KB covariates to the KB covariates already selected for inclusion in the linear set in the first stage, for a total of KL covariates.
Step 3: Quadratic and Interaction Terms
In the third step we decide which of the interactions and quadratic terms to include in
the specification of the propensity score. Given that we have selected KL  K covariates in the linear stage, we now decide which of the KL · (KL + 1)/2 quadratic and interaction terms involving these KL covariates to include. (If some of the covariates are binary, some of these KL · (KL + 1)/2 quadratic terms would be identical to some of the linear terms and thus known not to improve the specification, and so the effective set of possible
second-order terms may be smaller than KL · (KL + 1)/2.) Note that with this approach, we include only higher-order terms involving the KL covariates selected for inclusion in the linear part. We follow essentially the same procedure as for the linear stage. Suppose at some point we have added K~Q of the KL · (KL + 1)/2 possible interactions. We then estimate KL · (KL + 1)/2 - K~Q logistic regressions, each of which includes the intercept, the KL linear terms (including the KB basic ones), the K~Q second-order terms already selected, and one of the remaining KL · (KL + 1)/2 - K~Q terms. For each of these KL · (KL + 1)/2 - K~Q logistic regressions, we calculate the likelihood ratio statistic for the null hypothesis that the most recently added second-order term has a coefficient of
zero. If the largest likelihood ratio statistic is greater than some pre-determined constant
CQ, we include that interaction term in the model. Then we re-calculate the likelihood ratio statistics for the remaining KL · (KL + 1)/2 - K~Q - 1 interaction terms, and we

288

Estimating the Propensity Score

keep including the term with the largest likelihood ratio statistic until all of the remaining
likelihood ratio statistics are less than CQ. This algorithm leaves us with a selection of KL linear covariates and a selection of
KQ second-order terms (plus an intercept). We estimate the propensity score using this vector of 1 + KL + KQ terms. To illustrate the implementation of this strategy, we use the threshold value for the likelihood ratio statistic of CL = 1 and CQ = 2. 71, corresponding implicitly to z-statistics of 1 and 1.645, respectively.

13.4 CHOOSING THE SPECIFICATION OF THE PROPENSITY SCORE FOR THE BARBITUATE DATA
Here we illustrate the implementation of the covariate selection procedure on the barbituate data. The ultimate interest in this application is in the effect of in utero barbituate exposure on cognitive outcomes for young adults, although in this chapter we do not look at the outcome data. Based on the substantive argument in the original papers using these data, it was argued that the child's sex, the mother's age, and mother's socio-economic status (sex, lmotage, and ses respectively) are particularly important covariates, the first two because they are likely to be associated with the outcomes of interest, and the last two because they are likely to be related to barbituate exposure. We therefore include these three basic covariates in the specification of the propensity score, irrespective of the strength of their statistical association with barbituate exposure (i.e., KB = 3).
As the first step toward deciding which other covariates to include linearly, we estimate the baseline model with an intercept and the three previously selected covariates, sex, lmotage, and ses. The results for this model are in Table 13.2. Both lmotage and ses are statistically significantly (at the 0.05 level) associated with in utero exposure to barbituates.
Next we estimate fourteen logistic regression models, each including an intercept, sex, lmotage, and ses, and one of the fourteen remaining covariates. For each specification, we calculate the likelihood ratio statistic for the test of the null hypothesis that the coefficient on the additional covariate is equal to zero. For example, for the covariate lpbc420, the second pregnancy complication index, the results are reported in Table 13.3. The likelihood ratio statistic (twice the difference between the unrestricted and restricted log likelihood values), is equal to 1308.0. We do this for each of the fourteen remaining covariates (seventeen covariates minus the three pre-selected). We report the fourteen likelihood ratio statistics in the first column of Table 13.4. We find that the covariate that leads to the biggest increase in the likelihood function is lpbc420. The likelihood ratio statistic for that covariate is 1308.0. Because this value exceeds our threshold of CL = 1, we include the second pregnancy complication index lpbc420 in the specification of the propensity score.
Next we estimate thirteen logistic regression models where we always include an intercept, sex, lmotage, ses, and lpbc420, and additionally include, one at a time, the remaining thirteen covariates. The likelihood ratio statistics for the inclusion of these thirteen covariates are reported in the second column of Table 13.5. Now mbirth, the indicator for multiple births, is the most important covariate in terms of increasing

13.4 Choosing the Specification of the Propensity Score for the Barbituate Data

289

Table 13.2. Estimated Parameters of Propensity Score: Baseline Case; Barbituate Data

Variable
Intercept sex lmotage ses

EST
-2.38 -0.01
0.48 0.10

(s. e.)
(0.06) (0.08) (0.04) (0.04)

t-Stat
-41.0 -0.2 11.7 2.6

Table 13.3. Estimated Parameters of Propensity Score: Baseline Case with lpbc420 Added; Barbituate Data

Variable Intercept sex lmotage ses
lpbc420
LR statistic

EST -3.71
0.07 0.22 0.15
2.11
1308.0

(s. e.)
(0.10) (0.09) (0.05) (0.05)
(0.08)

t-Stat
-36.3 0.8 4.7 3.3
27.2

Table 13.4. Likelihood Ratio Statistics for Sequential Selection of Covariates to Enter Linearly; Barbituate Data

Covariate

Step 

sex

­

­ ­ ­ ­ ­­­­­­

antih

17.5 0.5 1.6 1.3 2.1 1.8 1.6 1.6 1.7 1.3 ­

hormone 3.9 0.3 0.7 0.7 0.4 0.8 0.7 0.7 0.7 0.8 0.9

chemo

10.0 36.6 41.9 ­ ­ ­ ­ ­ ­ ­ ­

cage

0.8 5.8 6.4 7.2 7.6 7.9 ­ ­ ­ ­ ­

cigar

4.3 2.3 3.5 3.7 3.0 2.1 2.1 1.7 2.1 ­ ­

lgest

0.4 11.1 5.0 6.4 7.3 5.5 5.6 ­ ­ ­ ­

lmotage ­

­ ­ ­ ­ ­­­­­­

lpbc415 0.6 0.0 0.2 0.2 0.0 0.0 0.1 0.1 0.0 0.0 0.0

lpbc420 1308.0 ­ ­ ­ ­ ­ ­ ­ ­ ­ ­

motht

0.1 0.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0

motwt

6.1 1.5 0.6 1.2 2.5 2.7 2.4 3.4 ­ ­ ­

mbirth

4.6 66.1 ­ ­ ­ ­ ­ ­ ­ ­ ­

psydrug 93.1 29.8 38.9 46.8 ­ ­ ­ ­ ­ ­ ­

respir

0.1 0.0 0.0 0.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0

ses

­ ­ ­ ­ ­ ­­­­­­

sib

21.0 13.8 12.5 15.0 15.7 ­ ­ ­ ­ ­ ­

290

Estimating the Propensity Score

Table 13.5. Estimated Parameters of Propensity Score: Baseline Case with lpbc420 and mbirth Added; Barbituate Data

Variable Intercept sex lmotage ses
lpbc420 mbirth
LR statistic

EST
-3.73 0.08 0.21 0.16
2.21 -1.96
66.1

(s. e.)
(0.10) (0.09) (0.05) (0.05)
(0.08) (0.30)

t-Stat
-35.9 0.9 4.5 3.4
27.5 -6.6

the likelihood function, and because the likelihood ratio statistic for the inclusion of mbirth, 66.1, exceeds the threshold of CL = 1, mbirth is added to the specification.
We keep checking whether there is any covariate that, when added to the baseline model, increases the likelihood function sufficiently, and if so, we include it in the specification of the propensity score. Proceeding this way leads to the inclusion, in the second step, after the three covariates sex, lmotage, and ses, which were selected in the first step, ten additional covariates. In the order they were added to the specification, these are, lpbc420, mbirth, chemo, psydrug, sib, cage, lgest, motwt, cigar, and antih. The likelihood ratio statistics are reported in Table 13.4. Once we have a model with these thirteen covariates and an intercept, none of the remaining four covariates satisfied our criterion to warrant inclusion in the specification of the propensity score.
Next we consider quadratic terms and interactions. With the thirteen covariates selected in the previous two steps for inclusion in the linear part of the propensity score, there are potentially 13 × (13 + 1)/2 = 91 second-order terms. Not all 91 potential second-order terms are feasible, because some of the thirteen covariates selected in the first two steps are binary indicator variables, so that the corresponding quadratic terms are identical to the linear terms. We select a subset of the non-trivial second-order terms in the same way we selected the linear terms, with the only difference being that the threshold for the likelihood ratio statistic is now 2.71, which corresponds to nominal statistical significance at the 10% level. Following this procedure, adding one second-order term at a time, leads to the inclusion of seventeen second-order terms.
Table 13.6 reports the parameter estimates for the propensity score with all the linear and second-order terms selected, with the variables in the order in which they were selected for inclusion in the specification of the propensity score.
13.5 CONSTRUCTING PROPENSITY-SCORE STRATA
The specification for the propensity score, with estimates for the unknown parameters in that specification, leads to an estimated propensity score at each value x of the covariates, denoted by e^(x). Next we wish to assess the adequacy of that specification by exploiting a

13.5 Constructing Propensity-Score Strata

291

Table 13.6. Estimated Parameters of Propensity Score: Final Specification; Barbituate Data

Variable Intercept

EST -5.67

Linear terms sex lmotage ses lpbc420 mbirth chemo psydrug sib cage lgest motwt cigar antih

0.12 0.52 0.06 2.37 -2.11 -3.51 -3.37 -0.24 -0.56 0.57 0.49 -0.15 0.17

Second-order terms lpbc420 × sib motwt× motwt lpbc420 × psydrug ses× sib cage× antih lpbc420× chemo lpbc420 × lpbc420 cage × lgest lmotage × lpbc420 mbirth× cage lgest × lgest ses× cigar lpbc420× motwt chemo × psydrug lmotage× ses cage × cage mbirth × chemo

0.60 -0.10
1.88 -0.22 -0.39
1.97 -0.46
0.15 -0.24 -0.88 -0.04
0.20 0.15 -0.93 0.10 -0.10 -

(s. e.) t-Stat (0.23) -24.4

(0.09) (0.11) (0.09) (0.36) (0.36) (0.67) (0.55) (0.22) (0.26) (0.23) (0.17) (0.10) (0.13)

1.3 4.7 0.6 6.6 -5.9 -5.2 -6.1 -1.1 -2.2 2.5 2.9 -1.5 1.3

(0.19) (0.02) (0.39) (0.10) (0.14) (0.49) (0.14) (0.05) (0.10) (0.39) (0.02) (0.09) (0.07) (0.46) (0.05) (0.05) (0.00)

3.1 -4.5
4.8 -2.2 -2.8
4.0 -3.3
3.0 -2.5 -2.3 -2.0
2.2 2.0 -2.0 1.9 -1.8 -

property of the true propensity score, namely the independence of the treatment indicator and the vector of covariates given the true super-population propensity score,

Wi  Xi e(Xi).

(13.2)

292

Estimating the Propensity Score

We substitute the estimated propensity score for the true propensity score and investigate whether, at least approximately,

Wi  Xi e^(Xi),

(13.3)

that is, whether, conditional on the estimated propensity score, the covariates and the treatment indicator are independent. Ideally we would do this by stratifying the sample into subsamples or blocks within each of which all units would have the exact same value of e^(x), and then assessing whether Wi and Xi within each resulting block are independent. This plan is feasible only if the estimated propensity score takes on a relatively small number of values, and thus if the covariates jointly only take on a relatively small number of values in the sample. Typically, in practice, that is not the case, and so we coarsen the estimated propensity score by constructing blocks (i.e., strata or subclasses) within which the estimated propensity scores vary only little. For a set of boundary points, 0 = b0 < b1 < . . . < bJ-1 < bJ = 1, define the block indicator Bi(j), for the ith unit, as

Bi(j) =

1 if bj-1  e^(Xi) < bj, 0 otherwise,

for j = 1, . . . , J. (Here we ignore the possibility that there are units with e^(Xi) exactly equal to Bi(J) = 1.) Then we assess adequacy of the estimated propensity score by assessing whether

Wi  Xi Bi(1), . . . , Bi(J).

(13.4)

We operationalize the assessment of independence by examining whether the treatment indicator and the covariates are uncorrelated within each of these blocks:

E [Xi|Wi = 1, Bi(j) = 1] = E [Xi|Wi = 0, Bi(j) = 1] ,

(13.5)

for all blocks j = 1, . . . , J. The first step in implemeting this procedure is the choice of boundary values bj, for
j = 0, . . . , J. We want to choose the boundary values in such a way that within each stratum the variation in the estimated propensity score is modest. The reason is that, if the propensity score itself varies substantially within a stratum, then any evidence that the covariates are correlated with the treatment indicator within that same stratum is not compelling evidence of misspecification of the estimated propensity score. Thus, we choose the boundary values in such a way that, within any stratum, the indicator of receiving the treatment appears statistically unrelated to the estimated propensity score.
We implement the selection of boundary points by an iterative procedure as follows. First we drop from this analysis all control units with an estimated propensity score less than the smallest value of the estimated propensity score among the treated units,

et

=

min
i:Wi=1

e^(Xi),

13.5 Constructing Propensity-Score Strata

293

as well as all treated units with an estimated propensity score greater than the largest value of the estimated propensity score among the control units,

ec = max e^(Xi).
i:Wi=0

This trimming ensures some overlap between the groups: among units i with estimated propensity score values e^(Xi) such that e^(Xi) < et or e^(Xi) > ec, there are no comparisons between treated and control units, without at least some extrapolation. We then start with a single block: J = 1, with boundaries equal b0 = et and b1 = bJ = ec. With these starting values, we iterate through the following two steps.
1. Assessment of Adequacy of Blocks In the first step, we check whether the current number of blocks, at this step in the algorithm equal to J, is adequate. In this procedure we use the estimated linearized propensity score (or log odds ratio), defined as

^(x) = ln

e^(x) 1 - e^(x)

.

The main reason to focus on the linearized propensity score rather than the propensity score itself is that, compared to the propensity score, the linearized propensity score is more likely to have a distribution that is well approximated by a normal distribution. Using the linearized propensity scores, we check the following two conditions for each block j = 1, . . . , J.
1.A Independence Is the estimated linearized propensity score within the block approximately uncorrelated with the treatment indicator? We assess this by calculating a t-statistic. Let Nc(j) and Nt(j) denote the subsample sizes for controls and treated in block j,

N

N

Nc(j) = (1 - Wi) · Bi(j), and Nt(j) = Wi · Bi(j),

i=1

i=1

and let c(j) and t(j) denote the average values for the estimated linearized propensity score, by treatment status and block,

c(j)

=

1 Nc(j)

N i=1

(1 - Wi) · Bi(j) ·

^(Xi),

t(j)

=

1 Nt(j)

N i=1

Wi

·

Bi(j)

·

^ (Xi ),

and finally, let S2 denote the sample variance of the linearized propensity score within block j,



S2(j)

=

1 N(j) -

2

×

N

i:Bi(j)=1

(1

-

Wi)

·

^(Xi) - ^c(j) 2 + N Wi ·
i:Bi(j)=1

 ^(Xi) - ^t(j) 2 .

294

Estimating the Propensity Score

The t-statistic for block j is then defined as

tj =

t(j) - c(j)

.

S2(j) · (1/Nc(j) + 1/Nt(j))

(13.6)

We compare this t-statistic for each stratum to a threshold value, which we fix at tmax, e.g., tmax = 1. If the t-statistic is less than or equal to tmax, we assess the estimated propensity score as varying little within the block, and if the t-statistic exceeds tmax, we assess the block as exhibiting substantial variation in the propensity score.
1.B New Strata Size If we were to split the current jth stratum into two substrata, what would the new boundary value be, and how many observations would fall in each of the new substrata? We compute the median value of the propensity score among the Nc(j)+Nt(j) units with an estimated propensity score in the interval (bj-1, bj). Denote this median by bj. (To be precise, if the current number of units in the stratum, Nc(j)+Nt(j), is odd, the median is the middle value, and if the number of units in the stratum is even, the median is defined as the average of the two middle values.) Then, with the superscripts l and h denoting the low and high substratum respectively, let

N
Ncl (j) = (1 - Wi) · Bi(j) · 1e^(Xi)<bj ,
i=1

N
Ncu(j) = (1 - Wi) · Bi(j) · 1e^(Xi)bj ,
i=1

N

N

Ntl(j) = Wi · Bi(j) · 1e^(Xi)<bj , and Ntu(j) = Wi · Bi(j) · 1e^(Xi)bj ,

i=1

i=1

be the number of control and treated units with estimated propensity scores in the lower
subinterval (bj-1, bj) and in the upper subinterval (bj, bj) respectively. The current block j is assessed to be inadequately balanced if the t-statistic is too
high, |tj| > tmax, and amenable to splitting if the number of units in each new block of each treatment type is sufficiently large to allow for a split at the median, min (Ncl (j), Ntl(j), Ncu(j), Ntu(j))  3, and min (Ncl (j), Ntl(j), Ncu(j), Ntu(j))  K + 2, where K is the number of pre-treatment variables. We choose these numbers so that we can
compare mean covariate values within blocks, and so that later we can do at least some
adjustment for remaining covariate differences within blocks.

2. Split Blocks That Are Both Inadequately Balanced and Amenable to Splitting If block
j is assessed to be inadequately balanced and amenable to splitting, then this block is
split into two new blocks, corresponding to propensity score values in ([bj-1, bj) and in (bj, bj), and the number of strata is increased by one. We iterate between the assessment step (1) and the splitting step (2) until all blocks are assessed to be either adequately
balanced or too small to split.

13.6 CHOOSING STRATA FOR THE BARBITUATE DATA
For the specification of the propensity score obtained in Section 13.4, we implement the strata selection procedure discussed in the previous section.

13.6 Choosing Strata for the Barbituate Data

295

We start with a single block, J = 1, with the lower and upper boundaries equal to b0 = et = mini:Wi=1 e^(Xi) = 0.0080, and b1 = ec = maxi:Wi=0 e^(Xi) = 0.9252 respectively. Out of the 7,198 individuals who were not exposed to barbituates in utero, 2,737 have estimated propensity scores less than b0 = et, and out of the 745 individuals who were exposed to barbituates before birth, 3 have estimated propensity scores exceeding b1 = ec. We discard at this stage both the 2,737 control individuals with estimated propensity scores less than b0, and the 3 exposed individuals with estimated propensity scores exceeding b1. Hence, in this first stratum we have Nc(1) = 4, 461 controls and Nt(1) = 742 treated individuals left with estimated propensity scores between b0 = 0.0080 and b1 = 0.9252. For this first block (i.e., subclass), we calculate the t-statistic, t1, for the test of the null hypothesis that the estimated linearized propensity score has the same mean in the treated and control subsamples, using the expression in (13.7). This leads to a t-statistic of t1 = 36.3, which exceeds by a substantial amount the threshold of tmax = 1. Moroever, if we split the block at the median of the estimated propensity scores within this stratum (equal to 0.06), there will be a sufficient number of observations in each sub-stratum: Ncl (1) = 2,540, Ntl(1) = 61, Ncu(1) =1,921, and Ntu(1) = 681. Therefore the current single-block subclassification is deemed inadequate, and the single block is split into two new blocks, with the new boundary equal to the median in the original subclass, equal to 0.06. These results are in the first panel of Table 13.7.
In the new stratification with two blocks, the first block with boundaries 0.01 and 0.06 has Nc(1) = 2,540 individuals in the control group and Nt(1) = 61 individuals in the treatment group. The t-statistic for the test of the null hypothesis of equality of the average estimated linearized propensity scores by treatment status for this block is 3.2. If we split the block into two parts at the median value of the propensity score (equal to 0.02), we find 1,280 control and 20 treated units in the first sub-block, and 1,260 control and 41 treated units in the second sub-block. The number of units in each subclass is sufficiently large, and therefore the original block will be split into two new blocks, at the median value of 0.02. For the second block with boundary values 0. 06 and 0. 9252, we again find that the stratification is inadequate, with a t-statistic of 23.7. These results are in the second panel of Table 13.7. As a result, we split both blocks, leading to four new blocks.
When we continue this procedure with the four new blocks, we find that the second of the four new blocks was sufficiently balanced in terms of the linearized propensity score. The remaining three new blocks were not well balanced and should be split again, leading to a total of seven blocks in the next round. See the third panel of Table 13.7.
We continue checking the adequacy of the blocks until either all the t-statistics are below the threshold value of one or splitting a block would lead to a new block that would contain an insufficient number of units of one treatment type or another. This algorithm leads to ten blocks, with the block boundaries, block widths, and the number of units of each type in the block presented in the last panel of Table 13.7. In the last column of this table, we also present the t-statistics. One can see that most of the blocks are well balanced in the linearized propensity score, with only two blocks somewhat unbalanced with t-statistics exceeding the threshold of tmax = 1. For example, the second block is not particularly well balanced in the linearized propensity score, with a t-statistic of 1.7, but splitting it would lead to a new block with no treated units, and therefore this block is not split further.

296

Estimating the Propensity Score

Table 13.7. Determination of the Number of Blocks and Their Boundaries; Barbituate Data

Step Block Lower Bound Upper Bound Width # Controls # Treated t-Stat

1

1

0.00

0.94

0.94 4462

742 36.3

2

1

0.00

2

0.06

3

1

0.00

2

0.02

3

0.06

4

0.20

4

1

0.00

2

0.01

3

0.02

4

0.06

5

0.11

6

0.20

7

0.37

5

1

0.00

2

0.01

3

0.02

4

0.06

5

0.11

6

0.20

7

0.37

8

0.50

6

1

0.00

2

0.01

3

0.02

4

0.06

5

0.11

6

0.20

7

0.37

8

0.42

9

0.50

10

0.61

0.06

0.06 2540

61

3.2

0.94

0.88 1922

681 23.7

0.02

0.01 1280

20

2.2

0.06

0.05 1260

41

0.5

0.20

0.14 1163

138

3.9

0.94

0.74

759

543 10.9

0.01

0.00

644

6

-0.0

0.02

0.01

636

14

1.7

0.06

0.05 1260

41

0.5

0.11

0.05

604

46 -0.3

0.20

0.09

559

92

1.0

0.37

0.17

458

192

1.2

0.94

0.57

301

351

5.6

0.01

0.00

644

6

-0.0

0.02

0.01

636

14

1.7

0.06

0.05 1260

41

0.5

0.11

0.05

604

46 -0.3

0.20

0.09

559

92

1.0

0.37

0.17

458

192

1.2

0.50

0.13

181

144

2.5

0.94

0.44

120

207

2.3

0.01

0.00

644

6

-0.0

0.02

0.01

636

14

1.7

0.06

0.05 1260

41

0.5

0.11

0.05

604

46 -0.3

0.20

0.09

559

92

1.0

0.37

0.17

458

192

1.2

0.42

0.05

101

61

0.3

0.50

0.08

80

83

0.7

0.61

0.11

73

90

0.8

0.94

0.34

47

117 -0.3

Note: Boldface block numbers indicate blocks that were split at this step.

13.7 ASSESSING BALANCE CONDITIONAL ON THE ESTIMATED PROPENSITY SCORE
Here we discuss assessing the within-block equality of means of the covariates across the treatment groups. One problem when conducting this assesment is the large amount of relevant information. We may have a large number of covariates (in the barbituate

13.7 Assessing Balance Conditional on the Estimated Propensity Score

297

study, there are seventeen covariates), and a substantial number of blocks (ten in our application). Even if we were to have data from a randomized experiment, where the covariates would be balanced perfectly in expectation, in any finite sample one would expect some covariates, in at least some strata, to be sufficiently correlated with treatment status that some statistical tests ignoring the multiplicity of comparisons would suggest statistical significance of some comparisons at conventional single-test levels. Here we propose a method for assessing the overall balance for a particular specification of the propensity score, and a given set of strata, that allows for comparisons of balance across specifications of the propensity score and across strata definitions.
As before, let the block or stratum indicators be denoted by Bi(j), and let Nc(j) and Nt(j) be the number of control and treated units in block j, for j = 1, . . . , J. Let us also define Xc,k(j) and Xt,k(j) to be the average of the kth component of the K-component covariate vector Xi, for control and treated units within stratum j,

1

1

Xc,k(j)

=

Nc(j)

Bi(j) ·
i:Wi=0

Xik,

and

Xt,k(j)

=

Nt(j)

Bi(j) ·
i:Wi=1

Xik ,

respectively, for k = 1, . . . , K, and j = 1, . . . , J. We are interested in assessing

Wi  Xi Bi(1), . . . , Bi(J),

implemented through an assessment of the equality,
E [Xi|Wi = 1, Bi(j) = 1] = E [Xi|Wi = 0, Bi(j) = 1] , for j = 1, . . . , J.
We discuss three sets of tests for each covariate. The first two are based on single statistics: first, a test for each covariate based on the average of the within-block average differences by treatment status; second, a test based on all within-strata correlations with Wi; and third, a set of tests based on separate within-stratum comparisons.

13.7.1 Assessing Global Balance for Each Covariate across Strata
For the first set of tests, we analyze the data as if they arose from a stratified randomized experiment. Each of the K covariates Xik, k = 1, . . . , K, is taken in turn as if it were the outcome, and the pseudo-average effect of the treatment on this pseudo-outcome, denoted by kX, is estimated using the Neyman-style methods discussed in Chapter 9 on stratified randomized experiments. Alternatively we could have used Fisher exact p-values. Take the kth component of the vector covariate Xi, Xik. In stratum j the pseudoaverage causal effect of the treatment on this covariate can be estimated by

^kX(j) = Xt,k(j) - Xc,k(j),

The sampling variance of this estimator ^kX(j) is estimated as

V^ Xk (j) = s2k(j) ·

1+1 Nc(j) Nt(j)

,

298

Estimating the Propensity Score

where





sk2(j)

=

1 Nc(j) - 2

N



(1 -

i:Bi(j)=1

Wi)

·

N

Xik - Xc,k(j) 2 +

Wi ·

i:Bi(j)=1

Xik - Xt,k(j) 2.

The estimate of the pseudo-average causal effect is then the weighted average of these within-block estimates,

^kX

=

J j=1

Nc(j) + Nt(j) N

· ^kX(j),

with estimated sampling variance

J
V^ Xk =
j=1

Nc(j) + Nt(j) N

2
· V^ Xk (j).

Finally we convert these into a z-value for the (two-sided) test of the null hypothesis that the pseudo-average causal effect kX is equal to zero, against the alternative hypothesis that it differs from zero,

zk = ^kX . V^ Xk

We then assess the distribution of these K correlated z-values, one for each covariate, based on a normal reference distribution. If we find that the z-values are substantially larger in absolute values than one would expect if they were drawn independently from a normal distribution, we would conclude that the stratification does not lead to satisfactory balance in the covariates, suggesting the specification of the propensity score is not adequate.

13.7.2 Assessing Balance for Each Covariate within All Blocks The average pseudo-causal effects kX may be zero, even if some of the stratum-specific pseudo-causal effects kX(j) are not. Next we therefore assess overall balance by calculating F-statistics across all strata, one covariate at a time. Treating the kth covariate as a pseudo-outcome, we use a two-way Analysis of Variance (ANOVA) procedure to test the null hypothesis that its mean for the treated subpopulation is identical to that of the mean of the control subpopulation in each of the J strata. One way to calculate the F-statistic is through a linear regression of the form

J

J

E [ Xik| Wi, Bi(1), . . . , Bi(J)] = kj · Bi(j) + kX(j) · Bi(j) · Wi.

j=1

j=1

13.7 Assessing Balance Conditional on the Estimated Propensity Score

299

First we estimate the unrestricted estimates (^ ur, ^ X) by minimizing



2

N

J

J

(^ ur, ^ X) = arg min
,

Xik -

kj · Bi(j) -

kX(j) · Bi(j) · Wi ,

i=1

j=1

j=1

which leads to

^ kujr = Xc,k(j), and ^kX(j) = Xt,k(j) - Xc,k(j).

Next we estimate the restricted estimates ^ r (under the restriction that all the kX(j) = 0) by minimizing



2

N

J

^ r = arg min


Xik -

kj · Bi(j) ,

i=1

j=1

leading to

^ krj

=

Nc(j) Nc(j) + Nt(j)

·

Xc,k(j)

+

Nt(j) Nc(j) + Nt(j)

·

Xt,k(j).

The F-test of interest is then the statistic for testing the null hypothesis that all kX(j) = 0, for j = 1, . . . , J. The form of the F-statistic for covariate Xik is

Fk

=

(SSRrk - SSRkur)/J SSRkur/(N - 2J)

,

where the restricted sum of squared residuals is



2

N

J

SSRrk = Xik - ^ krj · Bi(j) ,

i=1

j=1

and the unrestricted sum of squares is



2

N

J

J

SSRukr = Xik - ^ kujr · Bij - ^kX(j) · Bi(j) · Wi .

i=1

j=1

j=1

We then convert the p-value associated with this F-stastistic, under normality of the covariates nominally from an F-distribution with J and N - 2 · J degrees of freedom, to a z-value. Following this procedure for each of the K covariates Xik, we obtain a set of K z-values, one for each of the K covariates. Label these K z-values zk, k = 1, . . . , K. If the covariates are well balanced between treatment and control groups conditional on the propensity score, we would expect to find the z-values to be concentrated toward smaller (more negative) values relative to a normal distribution (suggesting less evidence against the null hypothesis of no difference between the two groups). Finding large positive values suggests that the covariates are not balanced within the strata.

300

Estimating the Propensity Score

13.7.3 Assessing Balance within Strata for Each Covariate
The third approach for assessing balance focuses on a single covariate in a single stratum at a time. For each covariate Xik, for k = 1, . . . , K, and for each stratum j = 1, . . . , J, we test the null hypothesis

E [Xi|Wi = 1, Bi(j) = 1] = E [Xi|Wi = 0, Bi(j) = 1] for j = 1, . . . , J

against the alternative hypothesis that the two averages differ. For the kth covariate, and
for this stratum j, we calculate a z-value zjk, analogous to the t-statistics we calculated before. With the stratum-specific sample variances s2k(j) define before, the z-value is

zjk =

Xt,k(j) - Xc,k(j)

.

sk2(j) · (1/Nc(j) + 1/Nt(j))

(13.7)

If the covariates are well balanced, we would expect to find the absolute values of the
z-values to be concentrated toward smaller (less significant) values relative to a normal distribution. To summarize the K ×J z-values it is useful to present Q-Q plots, comparing the z-values against their expected values under independent draws from the normal
distribution. If the covariates are well balanced, we would expect the Q-Q plots to be flatter than a 45 line.

13.8 ASSESSING COVARIATE BALANCE FOR THE BARBITUATE DATA
Given the stratification for the barbituate data obtained in Section 13.6, using the covariate selection methods outlined in Section 13.3, we estimate the propensity score. We then construct the blocks using the methods from Section 13.5, leading to ten blocks as discussed in Section 13.6. Given these ten blocks, and given the estimated propensity score, we calculate a number of statistics to assess the adequacy of the propensity score specification. First, following the discussion in Section 13.7.1 we calculate a t-statistic for the null hypothesis that the block-adjusted average difference in average covariate values is equal to zero for each covariate. This leads to 17 t-statistics or z-values. Next, as discussed in Section 13.7.2, we calculate the F-statistic for assessing the null hypothesis that the difference in average covariate values is zero in each block. We do this separately for each covariate and convert the p-value for the F-statistic to a z-value. Small values here indicate small F-statistics, and so we are concerned only with the presence of large z-values. Next, following the discussion in Section 13.7.3, we calculate t-statistics for each stratum and each covariate separately, leading to K × J = 170 z-values for the stratum-covariate specific t-tests. The results are presented in Table 13.8, with the rows corresponding to the seventeen covariates, and the columns corresponding to the ten blocks. In addition, there are two columns for the two overall tests, and one for the z-value of the test of equality of (unadjusted) average covariate values for treatment and control groups, and one for the test of the stratum-adjusted average covariate values for

Table 13.8. z-Values for Balancing Tests: Final Propensity Score Specification; Barbituate Data

Within Blocks

1

2

3

4

5

6

7

8

9

10

Covariate sex antih hormone chemo cage cigar lgest lmotage lpbc415 lpbc420 motht motwt mbirth psydrug respir ses sib

-0.05 -0.67 -0.14
0.55 -1.41 -0.37
0.90 -2.20 -0.48
1.04 -0.84
1.23 -0.44 -0.66 -0.49 -0.60
1.42

-2.27 -0.47 -0.42 -0.39 -0.29
0.55 0.58 -1.37 -1.84 0.84 0.45 1.14 -0.80 -1.01 0.53 -0.31 2.37

1.97 0.67 -0.65 -0.78 -1.04 0.58 -0.07 0.56 -1.00 -0.67 -0.67 0.12 -1.54 1.05 -0.21 -0.74 -1.09

0.81 0.03 -1.00 -0.75 -0.46 1.50 -0.82 1.64 -0.34 -0.86 0.75 -1.23 -0.37 -0.15 0.98 1.16 -1.58

0.89 0.37 0.25 -1.17 2.11 0.31 0.79 0.95 0.59 -1.61 0.64 -0.05 1.80 -0.78 1.38 0.82 -1.53

-1.28 -0.25
0.71 1.47 0.28 -0.93 -0.36 0.60 0.44 1.80 0.09 -0.45 0.20 0.06 0.24 -0.08 0.11

0.04 0.38 -0.22 -0.94 0.20 0.21 0.05 -0.96 -0.20 -0.39 0.30 -0.32 0.00 -0.18 -0.78 -0.03 0.63

-0.39 -0.53 -1.05
0.61 0.46 -0.99 -0.33 -1.73 -0.16 1.62 -1.37 1.94 2.25 0.08 -1.51 -0.82 1.63

-1.42 -0.11 -1.10
0.66 -1.48
0.25 -1.14 -1.47
1.07 1.14 -0.60 -0.01 -1.58 0.09 0.22 -0.91 1.19

1.14 0.27 0.21 0.29 -0.74 -0.39 1.21 0.36 -0.10 -1.80 -0.13 -0.47 -1.60 0.89 -0.28 0.36 0.23

301

Overall

1-Block

t-Test F-Test t-Test (z-Value)

0.13 -0.17 -0.99 -0.27 -1.38
0.52 0.71 -1.26 -1.49 0.51 -0.50 1.08 -1.28 -0.29 0.24 -0.56 0.98

1.22 -2.88 -0.66 -0.61
0.34 -1.17 -1.48
1.45 -0.82
0.59 -1.37 -0.18
1.00 -1.40 -0.49 -1.37
1.64

-0.73 3.21 1.66 1.76 1.15
-3.13 0.12 8.56 0.75
32.04 0.90 1.44 -2.93 6.32 0.19 5.19 1.48

302

Estimating the Propensity Score

Quantiles of Normal Distribution

4

2

0

-2

-4

-4

-3

-2

-1

0

1

2

3

4

z-values

Figure 13.1. Balance in covariates: QQ-Plot based on CL = 1, CQ = 2.78, barbituate data

treatment and control groups. Finally, for comparison purposes, we also present the tstatistic for the null hypothesis that the overall average covariate values are equal in the two treatment groups, not adjusted for the blocks.
Starting with the last column, the z-value for the test of equality of unadjusted average covariate values, we find that many covariates have unconditional means that differ significantly between treatment and control groups, which is not surprising because assignment was not randomized. It is also not very informative, merely telling us that some adjustment for covariate differences is necessary and that simply comparing average outcomes for treated and control units would not lead to credible estimates of causal effects of barbituate exposure. Out of the 170 z-values, only two exceed 2.0 in absolute value. Next, consider the column with the heading "t-test," presenting z-values for the test of zero average pseudo-causal effects for each of the seventeen covariates after stratification on the estimated propensity score. The largest of the absolute values of the seventeen t-statistics is 1.49, suggesting excellent balance. An alternative test is based on comparing each of the within-stratum pseudo-causal effects to zero using an F-test. For the F-test based on this null hypothesis, converted to a z-value, we find that the largest value is 1.64, with all the others below 1.50, again suggesting excellent balance conditional on the propensity score. Note that for these z-values large negative values suggest good balance, and we are concerned only with large positive values.
The first ten columns of the table give the z-values separately for each block and each of the seventeen covariates. The largest of these 170 z-values is 2.37. To facilitate the overall assessment of these z-values we construct a Q-Q plot, where we plot the ordered z-values, against the corresponding quantiles of the normal distribution. The Q-Q plot is presented in Figure 13.1. The Q-Q plot closely follows the 450 line. It shows that there are, if anything, slightly fewer large negative values and fewer large positive values than one would expect to see if the z-values were independent draws from a normal distribution.
From these balance assessments, we conclude that the specification of the propensity score is adequate in the sense that it leads to somewhat better balance than one would expect to see if assignment were randomized within blocks. If we had found that the balance was poor, we might have attempted to improve balance by changing the specification for the propensity score. We propose no general algorithm to improve balance beyond providing some general guidelines. For example, if one finds that many of the t-statisics for a particular covariate are large in absolute value, one may wish to include

13.8 Assessing Covariate Balance for the Barbituate Data

303

Quantiles of Normal Distribution

4

2

0

-2

-4

-4

-3

-2

-1

0

1

2

3

4

z-values

Figure 13.2. Balance in covariates: QQ-plot based on CL = 1, CQ =  barbituate data

more flexible functional forms for that covariate, possibly piecewise linear components, or indicator variables for particularly important regions of its values.
To put the extent of the covariate balance given our preferred specification in perspective, we consider two alternative specifications of the propensity score.
In the first alternative specification, we include all seventeen linear terms but no second-order terms. Within our algorithm this corresponds to CL = 0, CQ = . This specification appears to be common in empirical work, where researchers often simply include all covariates linearly in the propensity score without investigating whether that specification of the propensity score leads to adequate balance in the covariates. Constructing the blocks with this specification of the propensity score leads to nine blocks. Table 13.9 displays the z-values corresponding to this specification. We find that fifteen out of 153 z-values exceed 2.0, compared to only two out of 170 with our preferred specification of the propensity score. In Figure 13.2 we present the Q-Q plot for the 153 z-values based on the nine blocks and seventeen covariates. Comparing Figure 13.2 to Figure 13.1, it is clear that including some second-order terms leads to substantially better balance in the covariates, supporting the importance of doing a careful assessment of the adequacy of the propensity score specification by inspecting covariate balance.
In the second alternative specification we use lasso methods to select among all seventeen linear terms and 153 second-order terms. We use ten-fold cross-validation to select the penalty term. The lasso procedure selects fourteen covariates, three linear ones (chemo, lpbc420, and mbirth), and eleven second-order terms. Table 13.10 displays the z-values corresponding to this specification. We find that there are now fourteen out of 204 z-values exceeding 2.0, again, compared to two out of 170 with our preferred specification of the propensity score. In Figure 13.3 we present the Q-Q plot for the 153 z-values based on the nine blocks and seventeen covariates. Comparing Figure 13.3 to Figure 13.1, it appears that the lasso does not lead to as good an in-sample fit as our proposed specification, possibly due to its focus on out-of-sample prediction.
The correlation between the linearized propensity score based on our proposed specification and the linear specification is 0.95, between the proposed specification and the lasso specification the correlation is 0.96, and the correlation between the linear and the lasso specification is 0.98. The log likelihood values for the three specifications are -1,556.3 for the proposed specification, -1.627.7 for the linear specification, and -1,614.7 for the lasso specification.

304 Table 13.9. z-Values for Balancing Tests: Simple Linear Propensity Score Specification; Barbituate Data

Within Blocks

Overall

1-Block

1

2

3

4

5

6

7

8

9 t-Test F-Test t-Test

(z-Value)

Covariate sex antih hormone chemo cage cigar lgest lmotage lpbc415 lpbc420 motht motwt mbirth psydrug respir ses sib

1.68 -0.98 -0.34 -1.00 -2.54 -0.41 -0.06
0.50 -1.10
1.69 -1.94 -0.92 -0.65 -0.25 -0.63 -0.30 -2.24

0.41 1.75 -0.75 -2.37 0.38 0.61 -0.81 1.66 -1.10 -1.93 0.61 0.34 -0.91 -1.37 -0.60 1.62 -1.00

-0.39 0.17
-0.45 -0.37 -1.40 -0.36
1.06 1.86 -1.53 0.73 0.19 -0.70 2.95 -0.02 1.97 1.52 -2.24

0.09 0.29 1.23 -0.90 1.08 0.95 1.88 1.30 0.42 -1.97 -0.27 -1.59 -1.22 -0.72 -1.00 0.03 -1.67

-0.25 -1.11 -1.38 -1.44
0.60 2.21 -0.63 2.04 0.91 -1.93 1.02 -0.94 -1.22 -1.50 1.27 0.87 -2.80

-0.51 0.60 0.73
-1.22 -0.71 -1.16
1.18 -0.10
0.46 0.17 -0.48 0.30 3.24 -1.94 0.49 -0.12 0.25

0.78 -0.51
1.23 2.36 1.76 -0.87 -0.92 -1.34 0.40 2.63 -0.15 0.06 1.35 0.63 0.08 -1.92 1.58

-0.63 -0.07
0.22 1.88 -0.59 -1.59 -1.86 -2.57 0.48 2.52 0.27 -0.07 -0.85 0.45 -0.39 -1.40 2.21

-0.20 0.68
-0.54 0.51
-0.07 0.67 1.19
-0.63 -0.03
1.82 -0.59
1.43 -1.65
2.76 -0.59
1.14 2.18

1.47 -0.18 -0.58 -2.03 -2.07
0.04 -0.01
1.58 -1.34
0.77 -1.35 -1.01 -0.62 -1.30 -0.30
0.63 -2.93

-1.16 -0.54 -0.16
2.41 1.11 0.70 0.80 2.26 -0.58 3.09 -0.70 -0.29 2.33 3.09 0.05 0.97 3.09

-0.87 3.43 1.78
-0.02 0.86
-2.96 -0.31 10.74
0.98 36.35 0.57 1.31 -3.26 7.20 0.19 5.61 -0.78

305 Table 13.10. z-Values for Balancing Tests: Lasso Propensity Score Specification; Barbituate Data

Within Blocks

Overall

1-Block

1

2

3

4

5

6

7

8

9

10

11

12 t-Test F-Test t-Test

(z-Value)

Covariate sex antih hormone chemo cage cigar lgest lmotage lpbc415 lpbc420 motht motwt mbirth psydrug respir ses sib

-0.16 -1.22 -0.59 -1.37 -0.31 -0.42
0.16 -1.11 -1.03
0.06 -0.94 -0.93 -1.11 -1.01 -0.28 -0.57
0.20

0.76 2.02 -0.57 -1.71 0.01 0.12 0.76 -0.91 -2.33 0.11 -0.37 0.63 0.27 -0.24 -0.91 1.65 0.64

0.87 1.61 -0.49 -1.09 0.82 0.29 1.11 2.81 -1.27 -2.39 1.20 -1.03 -0.92 -1.54 1.72 1.41 -1.61

-0.44 -0.09
1.37 -1.74
1.86 0.61 0.39 -0.22 0.44 0.90 1.49 -0.49 1.74 0.07 -0.80 -1.65 -1.65

1.21 -0.98 -0.69 -0.66
0.75 2.09 0.81 2.13 1.75 -2.13 -0.11 -1.11 -1.10 -1.43 0.06 -0.11 -3.50

0.81 0.20 -0.49 -0.83 0.07 -0.51 1.22 0.88 -0.29 0.25 0.45 -1.46 2.53 -0.99 1.13 -0.20 -0.17

1.11 0.68 -0.29 -1.03 0.73 -0.91 -0.29 0.34 -0.84 -0.63 0.73 -0.47 -0.41 0.00 -0.29 1.15 -0.91

-0.49 -0.48
0.00 -0.94
0.14 -0.33
0.79 -0.48 -0.69 -0.32 -0.31
0.14 0.99 -1.08 -0.52 0.70 -0.10

0.80 1.05 -1.37 -0.19 -0.36 0.19 -0.60 0.12 0.05 -0.51 -0.41 -0.91 -0.59 -1.25 0.46 -0.16 -0.25

-0.22 -0.34
0.76 1.90 3.54 -2.21 1.19 0.04 1.33 1.99 -1.24 -0.20 0.07 1.01 0.30 -0.91 0.78

-0.15 1.28 1.50 1.53
-0.22 -0.87 -2.62 -0.82 -0.09
2.58 0.27 -1.92 0.00 1.94 -1.24 -0.29 1.58

0.87 0.84 -2.18 0.96 1.33 -1.10 0.66 -1.24 -0.42 0.32 -0.93 0.64 -0.67 0.89 -0.47 -0.57 0.70

0.98 0.89 -1.07 -2.27 1.35 -0.39 1.11 0.16 -1.78 -0.45 -0.30 -1.64 -0.61 -1.41 0.00 0.29 -0.91

-1.19 0.36 1.94 1.37 1.41 0.37 0.26 1.29 0.65 1.26
-0.72 0.10 1.43 1.45
-0.63 -0.17
1.81

-0.31 3.32 1.76
-0.49 1.76
-3.03 0.87 7.71 0.81
29.15 0.70 0.52 -1.74 6.86 -0.11 4.72 1.43

306

Estimating the Propensity Score

Quantiles of Normal Distribution

4

2

0

-2

-4

-4

-3

-2

-1

0

1

2

3

4

z-values

Figure 13.3. Balance in covariates: QQ-plot based on lasso, barbituate data

13.9 CONCLUSION
In this chapter we discuss methods for estimating the propensity score and for creating subclasses based on the estimated propensity score. There are two key points. One is that none of the analyses in this chapter involves the outcome data. There is therefore no concern with introducing biases for estimated causal effects through specification searches and pre-testing. A second key point is that the goal in this chapter is to obtain an estimated propensity score that balances the covariates within subclasses, rather than one that simply estimates the hypothetical true propensity score as accurately as possible. As has been noted in the literature, using the estimated propensity score often leads to better balance than using the true propensity score.
We propose a specific data-driven algorithm for choosing the specification of the propensity score. Although there, undoubtedly, will be situations where our proposed algorithm does not lead to adequate balance, in our limited experience it often performs adequately. We also discuss methods for assessing covariate balance, which show, for our particular application, that the specification of the propensity score and selection of subclasses lead to excellent covariate balance, better than one would expect in a randomized blocks experiment, and also better than the balance achieved by a specification for the propensity score that simply includes all covariates linearly. The algorithm uses two tuning parameters, which define cutoff values for inclusion of covariates linearly and for inclusion of second-order terms.

NOTES
The problem of estimating the propensity score is essentially one of nonparametric estimation of a regression function. There are numerous statistical procedures for doing so. Some are based on kernel smoothing. Such methods tend not to perform well in settings with a substantial number of covariates. Other methods are based on selecting subsets of the covariates for inclusion in the specification. These include subset selection (Breiman and Spector, 1992) and the lasso and related methods (Tibshirani, 1996; Bu¨hlmann and Van Der Geer, 2011; Belloni, Chernozhukov, and Hansen, 2014). We are agnostic about what is the "best" procedure. The key is whether a proposed method leads to adequate balance. Bayesian methods are discussed in Clogg, Rubin, Schenker, Schultz, and Weidman (1991).

Appendix: Logistic Regression

307

The point that using the estimated propensity score rather than the true propensity score leads to better balance and better estimators for causal effects has been made in Rubin and Thomas (1992a, 1992b, 1996, 2000) and Hirano, Imbens, and Ridder (2003).
Ketel, Leuven, Oosterbeek, and VanderKlaauw (2013) analyze data from the Dutch medical school admission lotteries mentioned in the introduction to this chapter to estimate the causal effect of becoming a doctor on earnings.

APPENDIX: LOGISTIC REGRESSION

The basic strategy in this chapter uses logistic regression models. Here we describe briefly how to obtain maximum likelihood estimates of the parameters of such models. Let X be the K-vector of covariates with support X. Then for a known L-component row vector of functions h : X  RL we model the probability of receiving the active treatment in the super-population as

Pr(Wi

=

1|Xi

=

x;

)

=

1

exp (h(x)) + exp (h(x)) ,

(13.8)

where  is an unknown parameter, local to this appendix. A simple case would correspond to choosing h(x) = x and estimating

Pr(Wi

=

1|Xi

=

x;

)

=

1

exp (x) + exp (x) .

(13.9)

More generally, in our algorithm, the function h( · ) may consist of only a subset of the covariates, and additionally may include higher-order terms or transformations of the basic covariates.
The likelihood function can be written as

L(|Yobs,

W, X)

=

N i=1

Pr(Wi

=

1|Xi;

)Wi ·(1

-

Pr(Wi

=

1|Xi;

))1-Wi

=

N i=1

exp (Wi · Xi) , 1 + exp (Xi)

so that he logarithm of the likelihood function is

N
L(|Yobs, W, X) = Wi · Xi - ln (1 + exp (Xi)) .
i=1
The maximum likelihood estimator is

^ ml

=

arg

max


L(|Yobs,

W,

X).

The log likelihood function is straightforward to maximize because it is globally concave

if the matrix

N i=1

h(Xi

)T

·

h(Xi)

is

positive

definite.

As

a

result,

a

simple

Newton-

Raphson algorithm can be effective for finding the maximum likelihood estimates. If

the function of covariates, h(x), includes an intercept and has the form h(x) = (1 h1(x)),

308

Estimating the Propensity Score

a useful starting vector of starting values is 0 = ( ln (Nt/Nc), 0T )T , with updating rule

k+1 = k -



2 

T

L(

k

)

-1  L(k). 

As k - , k generally converges to ^ml, again provided

N i=1

h(Xi

)T

·

h(Xi)

is

positive definite. Given the maximum likelihood estimates ^ , the standard errors are esti-

mated as the square roots of the diagonal elements of inverse of the estimated information

matrix

V^ ^ ml

=-



2 T

L(^ )

-1
.

An alternative to the logit function for the link function is to use the normal distribution function, leading to the probit model with

Pr(Wi = 1|Xi = x) = (h(x)),

where

(a) =

a -

 (1/ 2

)

exp

(

-

z2/2)

dz

is

the

cumulative

normal

distribution

func-

tion. A third possibility, called the robit model where the "r" stands for robust, uses the

cumulative distribution for the t-distribution as a link function (Liu, 2004). If the degrees

of freedom are approximately seven, this is close to the logit model, and with a large

number for the degrees of freedom, this is close to the probit model. Low values for the

degrees of freedom parameter correspond to more robust choices. There is little prati-

cal experience with these models to suggest whether they make a substantial difference

relative to the logit model.

CHAPTER 14
Assessing Overlap in Covariate Distributions
14.1 INTRODUCTION
When a researcher wishes to proceed to estimate causal effects under the assumption of unconfoundedness, there are various statistical methods that can be used to attempt to adjust for differences in covariate distributions. These methods include simple linear regressions, which is adequate in simple situations. They also include more sophisticated methods involving subclassification on the propensity score and matching, the latter two possibly in combination with model-based imputation methods, which can work well even in complicated situations. In order to decide on the appropriate methods, it is important first to assess the severity of the statistical challenge to adjust for the differences in covariates. In other words, it is useful to assess how different the covariate distributions are in the treatment and control groups. If the covariate distributions are similar, as they would be, in expectation, in the setting of a completely randomized experiment, there is less reason to be concerned about the sensitivity of estimates to the specific method choosen than if these distributions are substantially different. On the other hand, even if unconfoundedness holds, it may be that there are regions of the covariate space with relatively few treated units or relatively few control units, and, as a result, inferences for such regions rely largely on extrapolation and are therefore less credible than inferences for regions with substantial overlap in covariate distributions.
In this chapter we address the problem of assessing the degree of overlap in the covariate distributions ­ or, in other words, the covariate balance between the treated and control samples prior to any analyses to adjust for these differences. These assessments do not involve the outcome data and therefore do not introduce any systematic biases in subsequent analyses. In principle we are interested in the comparison of two multivariate distributions, the distributions of the covariates in the treated and control subsamples. We wish to explore how different the measures of central tendency are, and how much overlap there is in the tails of the distributions. There are two aspects of these differences in relation to the statistical challenges faced when adjusting for covariates. First, we ask how different are the two covariate distributions by treatment status. Partly for technical reasons, this part of the discussion focuses initially on assessing differences in population distributions. We then implement these concepts in finite samples. The answer to this first question is important for the choice of methods used to adjust for covariate
309

310

Assessing Overlap in Covariate Distributions

differences. Some methods are more robust to substantial differences in the covariate distributions than others. The second part of the discussion focuses on the question concerning whether there exist, for most units in the sample, similar units with the opposite level of the treatment. Unlike the answers to the first question, the answer to this question depends partly on the sample sizes for the two subsamples: even if the moments of two distributions differ substantially, if the range of values is similar, then at least in large samples one should be able to find close matches for most units. The answer to this second question bears on the ability of any method to adjust credibly for covariate differences.
To focus ideas, in Section 14.2 we initially look at the case with only a single covariate, that is, a scalar Xi, where we compare two univariate distributions. We focus on differences in location, differences in measures of dispersion, and two direct measures of overlap. We then look in Section 14.3 at direct comparisons of multivariate distributions. Next, in Section 14.4, we look at the role the propensity score can play when assessing overlap in covariate distributions in settings with unconfoundedness. In Section 14.5 we assess the ability to adjust for differences in covariates by treatment status, taking into account the sample sizes in the two treatment groups. We illustrate the methods discussed in this chapter in Section 14.6 using four different data sets. These data sets range from one obtained from an experimental evaluation with a high degree of overlap to one from an observational study where covariate distributions exhibit extremely limited overlap.

14.2 ASSESSING BALANCE IN UNIVARIATE DISTRIBUTIONS

Let us first think about measuring the difference between two known univariate population distributions. We denote these probability distributions by fc(x) and ft(x), for the (conditional) covariate distribution for the controls and treated subpopulations respectively, with Fc(x) and Ft(x) denoting the cumulative distribution functions. Although we are ultimately interested in differences between the sample, rather than between the sample covariate distributions, rather than between the population covariate distributions, it is useful for technical reasons to focus initially on the differences between the population distributions. We propose four summary measures of the differences between two distributions. Let c = E[Xi|Wi = 0] and t = E[Xi|Wi = 1] denote the population means for the two distributions, and let c2 = V(Xi|Wi = 0) and t2 = V(Xi|Wi = 1) denote the population variances for the two distributions. A natural measure of the difference between the locations of the distributions is what we call the normalized difference,

ct = t - c , (t2 + c2)/2

(14.1)

which is a scale-free (affinely invariant) measure of the difference in locations, equal to the difference in means, scaled by the square root of the average of the two within-group variances.

14.2 Assessing Balance in Univariate Distributions

311

To estimate this measure, ct, of the difference in covariate distributions, let Xc and Xt denote the sample averages of the covariate values for the control and treatment group respectively:

Xc

=

1 Nc

Xi,
i:Wi=0

and

Xt

=

1 Nt

Xi,
i:Wi=1

where, as before, Nc is the number of control units, and Nt is the number of treated units. Also, let s2c and st2 denote the conditional within-group sample variances of the covariate:

s2c

=

1 Nc -

1

(Xi
i:Wi=0

- Xc)2

and

s2t

=

1 Nt - 1

(Xi
i:Wi=1

- Xt)2.

Then the empirical counterpart to ct is the difference in average covariate values, normalized by the square root of the average of the two within-treatment group sample variances:

^ ct =

Xt - Xc . (sc2 + s2t )/2

(14.2)

It is useful to relate the normalized difference to a different statistic that is often reported
in causal analyses, the t-statistic for the test of the null hypothesis that c = t, against the alternative hypothesis that c = t. When c2 is thought to differ from t2, this t-statistic is equal to

Tct =

Xt - Xc

.

sc2/Nc + s2t /Nt

(14.3)

This t-statistic serves a very different purpose and is less relevant for the problem of assessing the adequacy of simple adjustment methods than the normalized difference. Our aim is not to test whether the data contain sufficient information to support the claim that the two covariate means in the different treatment regimes are different. One typically suspects that the population means are, in fact, different, and whether the sample size is sufficiently large to detect this, or the significance level at which we may be able to reject the null hypothesis is of no difference, is not of great importance. Rather, the goal is, at least at this point, to assess whether the differences between the two distributions are so large that simple adjustment methods, such as linear covariance (i.e., regression) adjustment, are unlikely to be adequate to remove most biases in estimated treatment/control average differences associated with differences in covariates.
Another way to see why the t-statistic Tct is less relevant for assessing the difference between the two distributions than the normalized difference ^ ct, consider what would happen if, for a given pair of distributions fc(x) and ft(x), we quadruple the sample size N. In expectation, the t-statistic would double in value, whereas the normalized difference would, in expectation, remain unchanged. Clearly, the statistical challenge of adjusting for differences in the covariates would be simpler rather than more difficult if we had available four times as many units: more observations drawn from the same distributions will ease the task of finding good comparisons in the treatment and control groups.

312

Assessing Overlap in Covariate Distributions

In addition to comparing the differences in location in the two distributions, one may wish to compare measures of dispersion in the two distributions. For two population distributions, a natural measure of the difference in dispersion, and one that is invariant to scale, is the logarithm of the ratio of standard deviations:

ct = ln

t c

= ln (t) - ln (t) .

(14.4)

The sample analogue of this population difference is the difference in the logarithms of the two sample standard deviations:

^ ct = ln (st) - ln (sc) .

(14.5)

We use the difference in logarithms because it is typically more normally distributed than the difference in their standard deviations or their ratio.
As a second approach to comparing the population distributions, one can investigate what fraction of the treated (control) units have covariate values that are in the tails of the distribution of the covariate values for the controls (treated). In the case with known distributions, one may wish to calculate, for example, for a fixed value  (e.g.,  = 0.05), the probability mass of the covariate distribution for the treated that is outside the 1-/2 and the /2 quantiles of the covariate distribution for the controls:

t = 1 - Ft Fc-1(1 - /2) + Ft Fc-1(/2) ,

and the analogous quantity for the control distribution:

c = 1 - Fc Ft-1(1 - /2) + Fc Ft-1(/2) .

The idea is that, for values of x in between the quantiles Fc-1(/2) and Fc-1(1 - /2), missing control outcomes Yi(0) for the treated units are relatively easy to impute, because
there are relatively many control observations in this part of the covariate space. On the other hand, for values of x less than Fc-1(/2), or for values of x greater than F0-1(1 - /2), it will be relatively more difficult to impute Yi(0) for treated units because there are
relatively few control observations in this part of the covariate space. If the proportion of such treated units, t, is high, it will be relatively difficult to predict missing potential outcomes for the treated units. Note that in a completely randomized experiment, at least in expectation, c = t = , and only  × 100% of the units have covariate values that make the prediction of the missing potential outcomes relatively difficult.
To implement this approach given the sample, let F^ c( · ) and F^ t( · ) be the empirical
distribution function of Xi in the control and treated subsamples, respectively,

F^ c(x)

=

1 Nc

1Xix,
i:Wi=0

and

F^ t(x)

=

1 Nt

1Xix,
i:Wi=1

and let F^ c-1(q) and F^ t-1(q) denote the inverse of these distributions:

F^ c-1(q)

=

min {x
-<x<

:

F^ c(x)



q},

and

F^ t-1(q)

=

min {x
-<x<

:

F^ t(x)



q}.

14.3 Direct Assessment of Balance in Multivariate Distributions

313

Now let us pick  = 0.05. Then ^c and ^t are the proportion of control and treated units with covariate values outside the 0.025 and 0.975 quantiles of the empirical distribution of the covariate values among the treated and control units:

^c0.05 = 1 - F^ c F^ t-1(0. 975) + F^ c F^ t-1(0. 025) ,

(14.6)

and ^t0.05 = 1 - F^ t F^ c-1(0. 975) + F^ t F^ c-1(0. 025) .

(14.7)

An advantage of these last two overlap measures is that they separately indicate the difficulty when predicting missing potential outcomes for the treated and for the control units. It is possible that the data are such that predicting the missing potential outcomes for the treated units is relatively easy, with the control units sufficiently dispersed that there are close comparisons for all covariate values that are observed among the treated. Yet, for the same data set, it may be difficult to find good comparisons for some of the control units if the distribution of the covariates among the treated is less dispersed than among the control units. In that case it may be difficult to estimate, for example, the overall average effect of the treatment, fs, but it may be possible to estimate well the average effect of the treatment for the treated units, fs,t = i:Wi=1 (Yi(1) - Yi(0))/Nt.
These four measures, the standardized difference in averages, the logarithm of the ratio of standard deviations, and the two sets of coverage frequencies, give good summary measures of the balance of a scalar covariate when the distributions are symmetric. More generally, one may wish to inspect normalized differences for higher-order moments of the covariates, or of functions of the covariates (logarithms, or indicators of covariates belonging to subsets of the covariate space). In practice, however, assessing balance simply by inspecting these four measures should provide a good initial sense of possible important differences in the univariate distributions. Finally, it may be useful to construct histograms of the distribution of a covariate in both treatment arms to detect visually subtle differences not captured by differences in means and variances, especially for covariates that are a priori believed to be highly associated with the outcomes.

14.3 DIRECT ASSESSMENT OF BALANCE IN MULTIVARIATE DISTRIBUTIONS
Now consider the case with multiple covariates. Let K be the number of covariates, the number of components of the vector of pre-treatment variables Xi. We may wish to start by looking at each of the K covariates separately using the methods discussed in Section 14.2, but it can also be useful to have a single measure of the difference between the distributions. As before, we look initially at the population distribution of the difference between the covariate values of a random draw from the treated and control distributions. The means of those distributions are the K-vectors c and t, respectively, and the K ×K

314

Assessing Overlap in Covariate Distributions

covariance matrices are c and t. An overall summary measure of the difference in locations between the two population distributions is

mv ct

=

(t - c)

c+ 2

t

-1
(t - c),

(14.8)

the Mahalanobis distance between the means with respect to the (( c + t)/2)-1 inner product. For the sample equivalent of this measure, we use the sample averages Xc and Xt and the following estimators for the covariance matrices,

^c

=

1 Nc - 1

(Xi-Xc)·(Xi-Xc)
i:Wi=0

,

and

^t

=

1 Nt -

1

(Xi-Xt)·(Xi-Xt)
i:Wi=1

,

leading to an estimated measure of the multivariate difference in covariate distributions:

^

mv ct

=

(Xt - Xc)

^c+ ^t 2

-1
(Xt - Xc).

(14.9)

14.4 ASSESSING BALANCE IN MULTIVARIATE DISTRIBUTIONS USING THE PROPENSITY SCORE
A complementary way to assess the overall difference in the covariate distributions is to use the propensity score. The propensity score plays a number of key roles in our discussion of causal analyses under unconfoundedness, and one of these is for assessing balance in covariate distributions. The main reason is that any imbalance in the population covariate distributions, whether in expectation, in dispersion, or in the shape of the distributions, leads to a difference in the population distributions of the true propensity scores by treatment status. As a result, it is theoretically sufficient to assess (e.g., visualize) differences in the distribution of the (true) propensity score in order to assess overlap in the full, joint, covariate distributions. This is very useful because it is easier to assess (e.g., visualize) differences between two univariate distributions than between two multivariate distributions. Moreover, any difference in covariate distributions by treatment status leads to a difference in the population averages of the true propensity scores for the treatment and control groups. There is therefore, in principle, no need to look beyond a mean difference in the true propensity scores by treatment status. In fact, given that there can be dispersion in the marginal (unconditional) distribution of the true propensity score only if the average values of the propensity scores for treated and controls differ, it is, in fact, also sufficient to assess the amount of dispersion in the marginal distribution of the propensity score: a non-zero variance of the marginal propensity score implies, and is implied by, differences in the covariate distributions by treatment status.
To state some formal results, let us initally focus on the case where the propensity score is known, which is why the previous paragraph kept emphasizing the "true" propensity score. We assume that the assignment mechanism is unconfounded,

14.4 Assessing Balance in Multivariate Distributions Using the Propensity Score

315

individualistic, and probabilistic (see Chapter 3 for formal definitions). Let e(x) denote the true propensity score, and let (x) denote the linearized propensity score or log odds ratio of being in the treatment group versus the control group given covariate value Xi = x,

(x) = ln

e(x) 1 - e(x)

.

We can simply look at the normalized difference in means for the propensity score or, better, the linearized propensity score, the same way we did for univariate Xi. Define c and t to be the average values for the linearized propensity scores for control and treated units,

1 c = Nc i:Wi=0 (Xi), and

1 t = Nt i:Wi=1 (Xi),

and s2,c and s2,c to be the sample variances of the linearized propensity scores,

s2,c

=

1 Nc - 1

i:Wi=0

(Xi) - c 2 ,

and

s2,t

=

1 Nt - 1

i:Wi=1

(Xi) - t 2 .

Then the estimated difference in average linearized propensity scores, scaled by the square root of the average squared within-treatment-group standard deviations is

^ ct =

t- c

.

s2,c + s2,t /2

(14.10)

There is not as much need to normalize this difference, t - c, by the square root of the average squared within-treatment-group standard deviations of the linearized propensity score as there was for the original covariates, because the propensity score, and thus any function of the propensity score, is scale-invariant.
The discussion so far is very similar to the discussion where we assessed balance in a single covariate. There are, however, two important differences that make inspection of the difference in average estimated propensity score values by treatment status particularly salient. The first is that differences in the super-population covariate distributions by treatment status imply, and are implied by, variation in the true propensity score. In other words, either the super-population distribution of the true propensity score values is degenerate and the super-population covariate distributions are identical in the two treatment arms, or the super-population distribution of propensity score values is non-degenerate and the super-population covariate distributions in treatment and control groups differ. Second, if the super-population distributions of the covariates in the two treatment groups differ, then it must be the case that the expected value (in the superpopulation) of the propensity score in the treatment group is larger than the expected value (in the super-population) of the propensity score in the control group. The key implication of these two results is that differences in covariate distributions by treatment status imply, and are implied by, differences in the average value of the propensity score by treatment status. Thus, differences in the average propensity score, or differences in

316

Assessing Overlap in Covariate Distributions

averages of strictly monotone functions of the propensity score, such as the linearized propensity score, are scalar measures of the degree of overlap in covariate distributions.
Let us formalize the two claims above. Let fc(x) and ft(x) denote the conditional covariate distributions in the control and treated subpopulations respectively, and let p be the expected value of the propensity score, p = E[Wi] = E[e(Xi)].
Theorem 14.1 (Propensity Score and Covariate Balance) Suppose the assignment mechanism is unconfounded and individualistic. Then, (i) the variance of the true propensity score satisfies

V(e(Xi)) = E

ft(Xi) - fc(Xi) ft(Xi) · p + fc(Xi) · (1 - p)

2

· p2 · (1 - p)2,

(14.11)

and (ii) the expected difference in propensity scores by treatment status satisfies

E[e(Xi)|Wi

=

1] -

E[e(Xi)|Wi

=

0]

=

V(e(Xi)) p · (1 - p)

.

(14.12)

Proof. Under unconfoundedness, and individualistic assignment, we can write the propensity score as

e(x)

=

Pr(Wi

=

1|Xi

=

x)

=

ft(x)

·

p

ft(x) · p + fc(x) ·

(1

-

. p)

(14.13)

Using (14.13) we can write the deviation of the propensity score e(x) from its population mean p as

e(x)

-

p

=

ft(x)

·

ft(x) - fc(x) p + fc(x) · (1

-

p)

·

p

·

(1

-

p).

Hence the population variance of the propensity score is

V(e(Xi)) = E (e(x) - p)2 = E

ft(Xi) - fc(Xi) ft(Xi) · p + fc(Xi) · (1 - p)

2

· p2 · (1 - p)2,

demonstrating part (i) of the theorem. Let us consider part (ii) of the theorem. Let f E(e) be the marginal distribution of
the propensity score e(Xi) in the population, let fcE(e) and ftE(e) denote the conditional distribution of the propensity score in the two treatment arms:

ftE (e)

=

f E(e)

·

Pr(Wi = 1|e(Xi) Pr(Wi = 1)

=

e)

=

f E(e) p

·

e

and

fcE (e)

=

f E(e) · (1 - 1-p

e) .

The two conditional means of the propensity score by treatment status are

E[e(Xi)|Wi = 1] =

eftE(e)de =

e2f E(e)de/p = V(e(Xi)) + p, p

14.5 Assessing the Ability to Adjust for Differences in Covariates by Treatment Status 317

and

E[e(Xi)|Wi

=

0]

=

(E[e(Xi)]

-

E[e(Xi)|Wi

=

1]

·

p)

/(1

-

p)

=

p

-

V(e(Xi)) . 1-p

The difference in means for the treatment and control group propensity scores is then:

E[e(Xi)|Wi

=

1]

-

E[e(Xi)|Wi

=

0]

=

V(e(Xi)) p · (1 - p)

.

Hence, unless the distribution of the true propensity score is degenerate with Pr(e(Xi) = p) = 1 (so that the marginal variance of the propensity score, V(e(Xi)), is equal to zero), there will be a difference in expected true propensity score values between treatment and control groups. Thus a zero difference between expected true propensity scores for treatment and control groups is equivalent to perfect expected balance.
Even though there can be no differences in the distribution of the true propensity score by treatment status unless there is a difference in the conditional expectation of the true propensity score by treatment status, it can be useful to inspect a histogram of the sample distributions of the estimated propensity scores in both groups to get a sense of the full distribution. When the number of covariates is large, it may be impractical to inspect histograms for each of the covariates separately, and inspecting the histogram of the estimated propensity score is a useful way to visualize a summary of the differences between the two distributions.
This discussion highlights the importance of assessing balance in the propensity score. The key insight is that differences in the expected distribution of the covariates lead to differences in expected values of the true propensity scores by treatment group, and that, therefore, inspecting the estimated propensity score distributions by treatment status should be a useful tool for assessing differences in covariate distributions. Although the formal results are based on differences in the population distributions of the true propensity score by treatment status, the practical implication is that it may be useful to assess differences in the sample distributions of the estimated propensity score.

14.5 ASSESSING THE ABILITY TO ADJUST FOR DIFFERENCES IN COVARIATES BY TREATMENT STATUS
In the previous sections we focused on differences between the covariate and estimated propensity score distributions by treatment status. If these differences are substantial, simple methods will likely not be adequate to obtain credible and robust estimates of the causal effects of interest. These measures of distributional differences considered so far do not depend on the sample sizes. The sample sizes by treatment group, however, are important determinants of whether even sophisticated methods will be adequate for obtaining credible and robust estimates. In this section we explore this question further. Specifically, we focus on the question whether for proportions of the samples there are close comparisons in the other treatment group. We do this separately by treatment group.

318

Assessing Overlap in Covariate Distributions

Consider a unit i, with treatment status Wi. We ask the question whether, for this
unit, there is any other unit i with the opposite treatment, Wi = 1 - Wi, such that the difference in linearized propensity scores, (Xi) - (Xi ) is, in absolute value, less than or equal to, a threshold u. In the current discussion, we focus on a threshold of u = 0. 1, implying that the difference in propensity scores is approximately less than

10%. For units for whom there are units with the other treatment with differences in

propensity scores less then 10%, we may be able to obtain credible (in the sense of close

to unbiased), estimates of the causal effects without extrapolation. For units for whom

there are no similar units with the opposite treatment level, it will be more difficult to

obtain credible estimates of causal effects, irrespective of the methods used. If there are

many such units, we may wish to trim the sample to improve balance using some of the

methods discussed in the next two chapters. First define, for each unit i, the indicator i that takes on the value one if there is at
least one unit i with Wi = 1 - Wi that has a similar value for the linearized propensity score and zero otherwise:

  1 i =  0

if i :Wi =Wi 1|^(Xi )-^(Xi)| u  1, otherwise.

Then our two overlap measures are the proportion of units in each treatment group with close comparisons,

qc

=

1 Nc

i
i:Wi=0

and

qt

=

1 Nt

i.
i:Wi=1

14.6 ASSESSING BALANCE: FOUR ILLUSTRATIONS
In this section we illustrate the methods discussed in this chapter. We apply these methods to four data sets, thereby illustrating a range of possible findings arising from the inspection of covariate balance. These four data sets range from a completely randomized experiment with, at least in expectation, identical covariate distributions, to an observational study with covariate distributions exhibiting very limited overlap, as well as two observational data sets with moderate amounts of overlap. In each case, we first estimate the propensity score using the methods from the previous chapter. We follow the algorithm described in that chapter to select, from K covariates Xi, some covariates to enter linearly and, in addition, some second-order terms. The tuning parameters for the algorithm were set, as proposed in Chapter 13, at CL = 1 and CQ = 2. 71. In each case some covariates are always included in the propensity score, again as described in general terms in that chapter. We also present the graphical evidence for the adequacy of the estimated propensity score. Finally, we present, for each of the four data sets, the four covariate balance measures: normalized differences in means, log ratio of standard deviations, the two coverage measures, and the proportions of units with close comparisons.

14.6 Assessing Balance: Four Illustrations

319

14.6.1 Assessing Balance: The Barbituate Data
The first application of the methods discussed in this chapter is based on the Reinisch barbituate data set that was introduced in Chapter 13. These data contain information on 7,943 individuals, 745 of whom were exposed in utero to barbituates, and 7,198 individuals in the control group, who were not exposed to barbituates while in utero. We have seventeen covariates, sex, antih, hormone, chemo, cage, cigar, lgest, lmotage, lpbc415, lpbc420, motht, motwt, mbirth, psydrug, respir, ses, and sib. For a more detailed description of the data, the reader is referred to Chapter 13, where we discussed a method for specifying the propensity score. Starting with the automatic inclusion of three pre-treatment variables, sex (sex of the child), lmotage (mother's age), and ses (parents' socio-economic status), the specific method led to the inclusion of all covariates other than lpbc415, motht, and respir, in the linear part of the propensity score and, in addition, led to the inclusion of nineteen second-order terms, as detailed in the previous chapter. In this chapter we continue to utilize that specification of the propensity score and the resulting estimates.
We start by presenting, in Table 14.1, the summary statistics for the barbituate data. For each of the seventeen covariates, as well as for the propensity score and the linearized propensity score, we report averages and sample standard deviations by treatment group. In addition, we report four measures of overlap for each covariate: ^ ct, the difference in means by treatment group, normalized by the square root of the average within-group squared standard deviation; ^ ct, the log of the ratio of the sample standard deviations; and ^c0.05 ^t0.05, and the proportions of control units and treated outside the 0.025 and 0.975 quantiles of the covariate distributions for both the control and treated units, respectively. These four measures are reported in the last four columns of Table 14.1. The specification of the propensity score, selected in Chapter 13, led to the inclusion of the interaction between the indicator for chemotherapy (chemo) and the indicator for multiple births (mbirth). There was a small set of seventeen individuals who had been exposed to chemotherapy and who had experienced multiple births. These seventeen individuals were all in the control group, so we estimated the propensity score to be equal to zero for these individuals. In the calculation of the average linearized propensity score (lps) by treatment group, in the last row of Table 14.1, these seventeen individuals were excluded from further analyses.
Table 14.1 reveals that there is one covariate that is particularly unbalanced: lpbc420, a constructed index of pregnancy complications; it is highly predictive of exposure to barbituates, with more than a full standard deviation difference in means. This is also the only variable for which the  0.05 overlap measure suggests that there are substantial proportions of both the treated and control units with covariate values that are outside the central 0.95 part of the distribution for the other treatment group. A full 48% of the control units have values for lpbc420 outside the 0.025 and 0.975 quantiles of the distribution of lpbc420 among the treated units, and similarly 28% of the treated units have values for lpbc420 outside the 0.025 and 0.975 quantiles of the distribution among the control units. To further investigate the imbalance of lpbc420, Figures 14.1a and 14.1b present histograms of its distribution by treatment status. These figures show that the range of values for lpbc420 is substantially different for the two treatment groups. In the control group, the value of this variable ranges from -2.41 to 2.59, with a mean of -0.12 and a standard deviation of 0.96. In the treatment group, the range

320

Assessing Overlap in Covariate Distributions

Table 14.1. Balance between Treated and Controls for Barbituate Data

Controls

Treated Overlap Measures

(Nc = 7,198) (Nt = 745) Nor Mean (S.D.) Mean (S.D.) Dif

Log Ratio

 0.05

of STD Controls Treated

sex

0.51 (0.50) 0.50 (0.50) -0.01 0.00

0.00 0.00

antih

0.10 (0.30) 0.17 (0.37) 0.19 0.20

0.00 0.00

hormone

0.01 (0.10) 0.03 (0.16) 0.11 0.43

0.00 0.03

chemo

0.08 (0.27) 0.11 (0.32) 0.10 0.14

0.00 0.00

cage

0.00 (1.01) 0.03 (0.97) 0.03 -0.04

0.07 0.03

cigar

0.54 (0.50) 0.48 (0.50) -0.12 0.00

0.00 0.00

lgest

5.24 (1.16) 5.23 (0.98) -0.01 -0.17

0.05 0.02

lmotage

-0.04 (0.99) 0.48 (0.99) 0.53 0.00

0.07 0.07

lpbc415

0.00 (0.99) 0.05 (1.04) 0.05 0.06

0.01 0.03

lpbc420

-0.12 (0.96) 1.17 (0.56) 1.63 -0.55

0.48 0.28

motht

3.77 (0.78) 3.79 (0.80) 0.03 0.03

0.00 0.00

motwt

3.91 (1.20) 4.01 (1.22) 0.08 0.02

0.00 0.00

mbirth

0.03 (0.17) 0.02 (0.14) -0.07 -0.21

0.03 0.00

psydrug

0.07 (0.25) 0.21 (0.41) 0.41 0.47

0.00 0.00

respir

0.03 (0.18) 0.04 (0.19) 0.03 0.07

0.00 0.00

ses

-0.03 (0.99) 0.25 (1.05) 0.28 0.06

0.00 0.00

sib

0.55 (0.50) 0.52 (0.50) -0.06 0.00

0.00 0.00

Multivariate measure

1.78

pscore

0.07 (0.12) 0.37 (0.22) 1.67 0.62

0.44 0.63

linearized pscore -5.12 (3.40) -0.77 (1.35) 1.68 -0.93

0.45

0.63

is from -0.24 to 2.50, with a mean of 1.17 and a standard deviation of 0.56. In the control

group, 2,914 out of 7,198 individuals (approximately 40%) have a value for lpbc420

that is smaller than -0.2440, the smallest value observed in the treatment group. This

suggests that differences in the value for this variable will be difficult to adjust reliably

using simple covariance adjustment methods and that we should pay close attention to

the balance for this variable using some of the design methods discussed in the next two

chapters. The remaining covariates are substantially better balanced, with the largest

standardized difference in means for lmotage, equal to 0.53 standard deviations. We

also find that the logarithm of the ratio of standard deviations is far from zero for some of

the covariates, suggesting that the dispersion varies between treatment groups. The mul-

tivariate measure is

^ mv
ct

=

1.78, suggesting that overall the two groups are substantially

apart.

Next, we present, in Figures 14.2a and 14.2b, histogram estimates of the distribution

of the linearized propensity score by treatment group. These figures reveal considerable

imbalance between the two groups, further supporting the evidence from Table 14.1,

where we found that the difference in estimated propensity scores by treatment status was

more than a standard deviation. Figure 14.3a displays graphically the balance property

of the propensity score. As discussed in the previous chapter, this is a Q-Q plot for the

14.6 Assessing Balance: Four Illustrations

321

0.7

0.6

0.5

0.4

Density

0.3

0.2

0.1

0

-3

-2

-1

0

1

2

3

Linearized Propensity Score

Figure 14.1a. Histogram-based estimate of the distribution of lpbc420 for control group, for barbituate data

0.8

0.7

0.6

0.5

Density

0.4

0.3

0.2

0.1

0

-3

-2

-1

0

1

2

3

Linearized Propensity Score

Figure 14.1b. Histogram-based estimate of the distribution of lpbc420 for treatment group, for barbituate data

z-values, measuring within-block equality of the covariate means. The algorithm discussed in the previous chapter led to 10 blocks for the barbituate data. As discussed in Chapter 13, this figure suggests that the specification of the propensity score is adequate.
Finally, we present in the first numerical column of Table 14.2 the matching statistics qc and qt. For the barbituate data we find that qc = 0.60, and qt = 0.98, which suggests that it will be challenging to estimate causal effects for a substantial number of control units under unconfoundedness. In contrast, because qt = 0.98, we can find comparable units for almost all treated units, suggesting that we can credibly estimate causal effects

322
0.14

Assessing Overlap in Covariate Distributions

0.12

0.1

0.08

Density

0.06

0.04

0.02

0

-20

-15

-10

-5

0

Linearized Propensity Score

5

10

Figure 14.2a. Histogram-based estimate of the distribution of linearized propensity score for control group, for barbituate data

0.35

0.3

0.25

0.2

Density

0.15

0.1

0.05

0

-20

-15

-10

-5

0

Linearized Propensity Score

5

10

Figure 14.2b. Histogram-based estimate of the distribution of the linearized propensity score for treatment group, for barbituate data

for the treated subpopulation. In this application, that is the natural population of interest, so the fact that we cannot credibly estimate causal effects for many of the control units need not be a concern.

14.6.2 Assessing Balance: The Lottery Data
Next, we use a data set collected by Imbens, Rubin, and Sacerdote (2001), who were interested in estimating the effect of unearned income on economic behavior, including

14.6 Assessing Balance: Four Illustrations

323

4

3

2

Quantiles from Normal Distribution

1

0

-1

-2

-3

-4

-4

-3

-2

-1

0

1

2

3

4

z value

Figure 14.3a. Q-Q plot for covariate balance conditional on propensity score for barbituate data

4

3

2

Quantiles from Normal Distribution

1

0

-1

-2

-3

-4

-4

-3

-2

-1

0

1

2

3

4

z value

Figure 14.3b. Q-Q plot for covariate balance conditional on propensity score for lottery data

labor supply, consumption, and savings. In order to study this question, they surveyed individuals who had played and won large sums of money in the Massachusetts lottery (the "winners"). For a comparison group, they collected data on a second set of

324
4

Assessing Overlap in Covariate Distributions

3

2

Quantiles from Normal Distribution

1

0

-1

-2

-3

-4

-4

-3

-2

-1

0

1

2

3

4

z value

Figure 14.3c. Q-Q plot for covariate balance conditional on propensity score for Lalonde experimental data

4

3

2

Quantiles from Normal Distribution

1

0

-1

-2

-3

-4

-4

-3

-2

-1

0

1

2

3

4

z value

Figure 14.3d. Q-Q plot for covariate balance conditional on propensity score for Lalonde non-experimental data

individuals who also played the lottery but who had won only small prizes, referred to here as "losers." Constructing a comparison group of lottery players who did not win anything was not feasible because the Lottery Commision did not have contact information for such individuals. Although Imbens et al. analyze differences within the winners group by the amount of the prize won, here we focus only on the second comparison of winners versus losers. Specifically, here we analyze a subset of the data with Nt = 259

14.6 Assessing Balance: Four Illustrations

325

Table 14.2. Proportion of Units with Match Discrepancy in Terms of Linearized Propensity Score Less Than 0.10

Barbituate Lottery Lalonde Experimental Lalonde Non-Experimental Data

qc 0.60

0.75

0.98

0.21

qt

0.98

0.69

0.97

0.97

winners and Nc = 237 losers in the sample of N = 496 lottery players. We know the year these individuals won or played the lottery (Year Won), the number of tickets they typically bought (Tickets Bought), their age in the year they won (Age), an indicator for being male (Male), education (Years of Schooling), whether they were working during the year they won (Working Then), and their social security earnings for the six years preceding the year they won (Earnings Year -6 to Earnings Year -1), and six indicators for each of these earnings being positive (Pos Earn Year -6 to Pos Earn Year -1).
We return to a more complete analysis of these data, involving the outcome variables, in Chapter 17. Here we only mention that the outcome we focus on in subsequent analyses is annual labor income, averaged over the first six years after playing the lottery.
We first estimate the propensity score for these data. We use the method discussed in Chapter 13 for selecting the specification, with, as before, cutoff values for the linear and second-order terms equal to CL = 1 and CQ = 2.71, respectively. The four covariates Tickets Bought, Years of Schooling, Working Then, and Earnings Year -1 were selected a priori to be included in the propensity score, partly based on a priori beliefs that they would be highly associated with winning the lottery (Tickets Bought), or highly associated with post-lottery earnings (Years of Schooling, Working Then, and Earnings Year -1). The algorithm then led to the inclusion of four additional covariates, for a total of eight out of the eighteen covariates entering the propensity score linearly, and ten second-order terms. The parameter estimates for this specification, with the covariates listed in the order they were selected for inclusion in the propensity score, are given in Table 14.3. Figure 14.3b suggests that the specification of the propensity score is adequate, in the sense that conditional on the propensity score, the covariates are balanced.
In Table 14.4 we present the balance statistics for the lottery data, which reveal that there are substantial differences between the covariate distributions in the two groups. Most important for post-treatment comparisons of economic behavior, we find that, prior to winning the lottery, the winners were earning significantly less than losers, with differences in all six of the pre-winning years statistically different from zero at conventional significance levels, and also large in substantial terms (on the order of 30% of average annual earnings). We also find that these differences are large relative to their variances, with the normalized differences for many variables on the order of 0.3, with some as high as 0.9 (for Tickets Bought). This suggests that simple regression methods will not reliably remove the biases associated with the differences in covariates. At the same time, the overlap statistics, ^c0.05 and ^t0.05, suggest that there is substantial overlap in the central ranges of the covariate distributions, suggesting that more sophisticated methods for adjustment may lead to credible results.

326

Assessing Overlap in Covariate Distributions

Table 14.3. Estimated Parameters of Propensity Score for the Lottery Data

Variable Intercept

EST (s. e.) t-Stat 30.24 (0.13) 231.8

Linear terms Tickets Bought Years of Schooling Working Then Earnings Year -1 Age Year Won Pos Earnings Year -5 Male

0.56 0.87 1.71 -0.37 -0.27 -6.93 0.83 -4.01

(0.38) (0.62) (0.55) (0.09) (0.08) (1.41) (0.36) (1.71)

1.5 1.4 3.1 -4.0 -3.4 -4.9 2.3 -2.3

Second-order terms Year Won × Year Won Earnings Year -1 × Male Tickets Bought × Tickets Bought Tickets Bought × Working Then Years of Schooling × Years of Schooling Years of Schooling × Earnings Year -1 Tickets Bought × Years of Schooling Earnings Year -1 × Age Age × Age Year Won × Male

0.50 0.06 -0.05 -0.33 -0.07 0.01 0.05 0.00 0.00 0.44

(0.11) (0.02) (0.02) (0.13) (0.02) (0.00) (0.02) (0.00) (0.00) (0.25)

4.7 2.7 -2.6 -2.5 -2.7 2.8 2.2 2.3 2.2 1.7

The estimates for the propensity score also suggest that there are substantial differences between the two covariate distributions. These differences are revealed in the coverage proportions for the treated and controls, ^c and ^t, which are 0.39 and 0.36 for the propensity score, even though these coverage proportions are below 0.10 for each of the covariates separately. Figures 14.4a and 14.4b present histograms estimates of the estimated propensity score.
The values for the overlap statistics, qc = 0.75 and qt = 0.69, suggest that, given the sample size, there are a substantial number of units for whom we will not be able to find close counterparts in the other treatment group, which indicates that we may have to trim the sample in order to focus on a subsample with better overlap. We will discuss specific methods for doing so in Chapters 15 and 16.

14.6.3 Assessing Balance: The Lalonde Experimental Data
These data were previously used and discussed in Chapter 8. Here the four earnings pre-treatment variables, earn'74, earn'74= 0, earn'75, and earn'75= 0, were selected a priori to be included in the propensity score. With these data, the algorithm for the specification of the propensity score leads to the inclusion of three additional pre-treatment variables as linear terms and to the inclusion of three second-order terms. Even if the randomization had been carried out correctly, and there were no missing data,

14.6 Assessing Balance: Four Illustrations

327

Table 14.4. Balance between Winners and Losers for Lottery Data

Losers (Nc =259)

Winners (Nt =237)

Mean (S.D.) Mean (S.D.)

 Nor Log Ratio Dif of STD Controls Treated

Year Won Tickets Bought Age Male Years of Schooling Working Then Earnings Year -6 Earnings Year -5 Earnings Year -4 Earnings Year -3 Earnings Year -2 Earnings Year -1 Pos Earn Year -6 Pos Earn Year -5 Pos Earn Year -4 Pos Earn Year -3 Pos Earn Year -2 Pos Earn Year -1 Multivariate measure

6.38 2.19 53.21 0.67 14.43 0.77 15.56 15.96 16.20 16.62 17.58 18.00 0.69 0.68 0.69 0.68 0.68 0.69

(1.04) 6.06 (1.29) -0.27 (1.77) 4.57 (3.28) 0.90 (12.90) 46.95 (13.80) -0.47 (0.47) 0.58 (0.49) -0.19 (1.97) 12.97 (2.19) -0.70 (0.42) 0.80 (0.40) 0.08 (14.46) 11.97 (11.79) -0.27 (14.98) 12.12 (11.99) -0.28 (15.40) 12.04 (12.08) -0.30 (16.28) 12.82 (12.65) -0.26 (16.90) 13.48 (12.96) -0.27 (17.24) 14.47 (13.62) -0.23 (0.46) 0.70 (0.46) 0.03 (0.47) 0.74 (0.44) 0.14 (0.46) 0.73 (0.44) 0.10 (0.47) 0.73 (0.44) 0.13 (0.47) 0.74 (0.44) 0.15 (0.46) 0.74 (0.44) 0.10
1.49

0.22
0.62 0.07
0.05 0.11 -0.06 -0.20 -0.22 -0.24 -0.25 -0.26 -0.24 -0.01 -0.07 -0.04 -0.06 -0.07 -0.05

0.00 0.15 0.03 0.00 0.06 0.12 0.00 0.00 0.01 0.09 0.00 0.00 0.03 0.00 0.10 0.00 0.10 0.00 0.03 0.00 0.10 0.00 0.03 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00

pscore

0.25 (0.24) 0.73 (0.26) 1.91 0.10

linearized pscore -1.57 (1.67) 1.70 (2.10) 1.73 0.23

0.39 0.36 0.39 0.36

one would expect that the algorithm would select some covariates for inclusion in the specification of the propensity score despite the fact that the true propensity score would be constant. In reality, there are missing data, and the data set used here consists only of the records for individuals for whom all the relevant information is observed, strengthening the case for a non-degenerate specification of the true propensity score. Table 14.5 presents the estimated parameters of the propensity score. Figure 14.3c presents the balancing properties of the estimated propensity score.
Table 14.6 presents the balance statistics for the experimental Lalonde data. Not surprisingly, the summary statistics suggest that the balance in the covariate distributions is excellent, by all four measures, and for all ten pre-treatment variables, as well as for the two overlap statistics qc and qt. Across the ten pre-treatment variables, the maximum value of the normalized difference in covariate means is 0.30, and for the propensity score, the normalized difference is 0.54. The coverage proportion is above 0.91 for all covariates as well as for the propensity score. Figures 14.5a and 14.5b present histogram estimates of the estimated propensity score. These again suggest excellent balance, and thus simple covariance adjustment methods may be reliable here. The overlap statistics are qc = 0.98 and qt = 0.97, indicating that we can hope to estimate causal effects credibly for most units without extrapolation.

328
0.35

Assessing Overlap in Covariate Distributions

0.3

0.25

0.2

Density

0.15

0.1

0.05

0

-10

-8

-6

-4

-2

0

2

4

6

8

10

Linearized Propensity Score

Figure 14.4a. Histogram-based estimate of the distribution of the linearized propensity score for control group, for lottery data

0.25

0.2

0.15

Density

0.1

0.05

0

-10

-8

-6

-4

-2

0

2

4

6

8

10

Linearized Propensity Score

Figure 14.4b. Histogram-based estimate of the distribution of the linearized propensity score for treatment group, for lottery data

14.6.4 Assessing Balance: The Lalonde Non-Experimental Data
The primary focus of Lalonde's (1986) orginal paper was to examine the ability of statistical methods for non-experimental evaluations to obtain credible estimates of average causal effects. The idea was to investigate the accuracy of the estimates obtained by then correct and standard non-experimental methods by comparing them to estimates from a randomized experiment. Taking the experimental evaluation of the National Supported Work (NSW) program, Lalonde set aside the experimental control group, and

14.6 Assessing Balance: Four Illustrations

329

Table 14.5. Estimated Parameters of Propensity Score for the Lalonde Experimental Data

Variable Intercept

EST (s. e.) t-Stat -3.48 (0.10) -34.6

Linear terms earn '74 unempl '74 earn '75 unempl '75 nodegree hispanic education

0.03 -0.24
0.06 -3.48
7.33 -0.65
0.29

(0.05) (0.39) (0.05) (1.65) (4.25) (0.39) (0.37)

0.7 -0.6
1.1 -2.1
1.7 -1.7
0.8

Second-order terms nodegree × education -0.67 earn '74 × nodegree -0.13 unempl '75 × education 0.30

(0.35) (0.06) (0.16)

-1.9 -2.3
1.9

Table 14.6. Balance between Trainees and Experimental Controls for Lalonde Experimental Data

Controls (Nc =260)

Trainees (Nt =185)

Nor Log Ratio

 0.05

Mean (S.D.) Mean (S.D.) Dif of STD Controls Treated

black hispanic age married nodegree education earn '74 unempl '74 earn '75 unempl '75

0.83 0.11 25.05 0.15 0.83 10.09 2.11 0.75 1.27 0.68

(0.38) (0.31) (7.06) (0.36) (0.37) (1.61) (5.69) (0.43) (3.10) (0.47)

0.84 0.06 25.82 0.19 0.71 10.35 2.10 0.71 1.53 0.60

(0.36) 0.04 (0.24) -0.17 (7.16) 0.11 (0.39) 0.09 (0.46) -0.30 (2.01) 0.14 (4.89) -0.00 (0.46) -0.09 (3.22) 0.08 (0.49) -0.18

-0.04 -0.27
0.01 0.08 0.20 0.22 -0.15 0.05 0.04 0.05

0.00 0.00 0.00 0.00 0.01 0.03 0.00 0.00 0.00 0.00 0.01 0.08 0.04 0.01 0.00 0.00 0.02 0.03 0.00 0.00

Multivariate measure

0.44

pscore

0.39 (0.11) 0.46 (0.14) 0.54 0.21

linearized pscore -0.49 (0.53) -0.18 (0.63) 0.53 0.17

0.06 0.09 0.06 0.09

to replace it, he constructed a comparison group from the Current Population Survey (CPS). (Lalonde also constructed a comparison group from the Panel Study of Income Dynamics, PSID, but we do not analyze these data here.) For this group, he observed the same variables as for the experimental sample. He then attempted to use the nonexperimental CPS comparison group, in combination with the experimental trainees, to estimate the average causal effect of the training on the trainees. Here we focus on

330

Assessing Overlap in Covariate Distributions

2

1.8

1.6 1.4

Density

1.2 1

0.8

0.6 0.4

0.2

0

-4

-3

-2

-1

0

1

2

3

4

Linearized Propensity Score

Figure 14.5a. Histogram-based estimate of the distribution of the linearized propensity score for control group, for Lalonde experimental data

1.4

1.2

1

0.8

Density

0.6

0.4

0.2

0

-4

-3

-2

-1

0

1

2

3

4

Linearized Propensity Score

Figure 14.5b. Histogram-based estimate of the distribution of the linearized propensity score for treatment group, for Lalonde experimental data

the covariate balance between the experimental trainees and the CPS comparison group. The treatment group consists of the same set of 185 individuals who received job training that was used in the discussion in Section 14.6.3. The CPS comparison group consists of 15,992 individuals who did not receive the specific NSW training, but these individuals might, of course, have participated in other training programs. This does not affect the analysis but implies that the interpretation of the causal effect being estimated is the net effect of receiving the training associated with the NSW program, beyond any other services these individuals might receive. As in Section 14.6.3, we select the four earning

14.6 Assessing Balance: Four Illustrations

331

Table 14.7. Estimated Parameters of Propensity Score for the Lalonde Non-Experimental Data

Variable

EST (s. e.) t-Stat

Intercept

-16.20 (0.69) -23.4

Linear terms earn '74 unempl '74 earn '75 unempl '75 black married nodegree hispanic age

0.41 0.42 -0.33 -2.44 4.00 -1.84 1.60 1.61 0.73

(0.11) 3.7 (0.41) 1.0 (0.06) -5.5 (0.77) -3.2 (0.26) 15.1 (0.30) -6.1 (0.22) 7.2 (0.41) 3.9 (0.09) 7.8

Second-order terms

age × age

-0.01

unempl '74 × unempl '75 3.41

earn '74 × age

-0.01

earn '75 × married

0.15

unempl '74 × earn '75

0.22

(0.00) -7.5 (0.85) 4.0 (0.00) -3.3 (0.06) 2.6 (0.08) 2.6

pre-treatment variables (earn'74, earn'74= 0, earn'75, and earn'75= 0) for prior inclusion in the propensity score. With the non-experimental Lalonde data set, the algorithm for the specification of the propensity score leads to the inclusion of five additional covariates as linear terms (excluding only education (years of education), but including the closely related variable nodegree, indicating whether an individual received at least a high school degree), and to the inclusion of five second-order terms. It is not surprising that the algorithm favors including substantially more covariates in the non-experimental case than it did in the experimental case discussed in Section 14.6.3. Table 14.7 presents the parameter estimates for the specification of the propensity score selected by the algorithm in this non-experimental case. Figure 14.3d presents the conditional balancing property of the estimated propensity score. Conditional on the propensity score, the covariates are again well balanced, suggesting that the algorithm used to select the specification of the propensity score performed well.
Table 14.8 presents the balance statistics for the non-experimental Lalonde data, and Figures 14.6a and 14.6b present histogram estimates of the estimated propensity score. For these data the balance is very poor. For a number of the covariates, the means by treatment status differ by more than a standard deviation. Consider earnings in 1975 (earn '75). Figures 14.7a and 14.7b present histograms for this covariate by treatment status. If we focus on post-program earnings as the primary outcome, as we will do in a later analysis of this program, it is clear that such large differences between the two groups in a variable such as earn '75, which is expected to be highly correlated with the outcome, could well lead to substantial biases in our estimates unless carefully controlled. All these measures suggest that, in order to estimate causal effects reliably,

332

Assessing Overlap in Covariate Distributions

Table 14.8. Balance between Trainees and CPS Controls for Lalonde Non-experimental Data

Controls

Trainees

(Nc =15,992) (Nc =185)

Nor Log Ratio

 0.05

Mean (S.D.) Mean (S.D.) Dif of STD Controls Treated

black hispanic age married nodegree education earn '74 unempl '74 earn '75 unempl '75 Multivariate measure

0.07 (0.26) 0.84 0.07 (0.26) 0.06 33.23 (11.05) 25.82 0.71 (0.45) 0.19 0.30 (0.46) 0.71 12.03 (2.87) 10.35 14.02 (9.57) 2.10 0.12 (0.32) 0.71 13.65 (9.27) 1.53 0.11 (0.31) 0.60

(0.36) 2.43 (0.24) -0.05 (7.16) -0.80 (0.39) -1.23 (0.46) 0.90 (2.01) -0.68 (4.89) -1.57 (0.46) 1.49 (3.22) -1.75 (0.49) 1.19
3.29

0.33 -0.09 -0.43 -0.14 -0.00 -0.36 -0.67
0.34 -1.06
0.45

0.00 0.00 0.00 0.00 0.21 0.00 0.00 0.00 0.00 0.00 0.19 0.04 0.51 0.01 0.00 0.00 0.60 0.00 0.00 0.00

pscore

0.01 (0.04) 0.41 (0.29) 1.94 1.93

linearized pscore -10.04 (4.37) -0.76 (2.08) 2.71 -0.74

0.86 0.85 0.86 0.85

we need to adjust for covariate differences in a sophisticated manner and, in particular, that simple regression methods are unlikely to be adequate.
It is interesting here to inspect the two overlap statistics, qc and qt. We find qc = 0.21 and qt = 0.97, indicating that we cannot hope to estimate credibly, for example, the average effect of the training program for the control group consisting of individuals surveyed in the Current Population Survey, even if we are willing to assume unconfoundedness. On the other hand, the fact that qt = 0.97 suggests that there is hope of credibly estimating causal effects of the training program for the subpopulation of treated units.
14.6.5 Assessing Balance: Conclusions from the Illustrations
Figures 14.3a through 14.3d show that the algorithm for specifying the propensity score performs well in terms of generating balance in the covariates conditional on the propensity score. For each of the four specifications, the conditional balance is better than what one would expect in a randomized experiment. Unconditionally, however, the balance varies widely. This suggests that, in applications similar to the ones examined here, simple linear covariance adjustment methods are unlikely to lead to reliable estimates. Moreover, these differences suggest that we may wish to create more balanced subsamples, as well as use more sophisticated methods, to adjust for such differences.

14.7 SENSITIVITY OF REGRESSION ESTIMATES TO LACK OF OVERLAP
Here we present a simple illustration of the pitfalls that the lack of balance can lead to, especially in the context of naive adjustment methods such as linear regression. We

14.7 Sensitivity of Regression Estimates to Lack of Overlap

333

0.12

0.1

0.08

Density

0.06

0.04

0.02

0

-20

-15

-10

-5

0

Linearized Propensity Score

5

10

Figure 14.6a. Histogram-based estimate of the distribution of the linearized propensity score for control group, for Lalonde non-experimental data

0.25

0.2

0.15

Density

0.1

0.05

0

-20

-15

-10

-5

0

Linearized Propensity Score

5

10

Figure 14.6b. Histogram-based estimate of the distribution of the linearized propensity score for treatment group, for Lalonde non-experimental data

alluded to these issues at a more abstract level in Chapter 12, Section 4.2. Suppose we are interested in the average effect of the treatment on the subpopulation of treated units,

fs,t

=

1 Nt

i:Wi=1

Yi(1) - Yi(0)

=

Y

obs t

-

1 Nt

Yi(0).
i:Wi=1

334

Assessing Overlap in Covariate Distributions

0.2

0.18

0.16

0.14

0.12

Density

0.1

0.08

0.06

0.04

0.02

0

0

5

10

15

20

25

30

1975 Earnings

Figure 14.7a. Histogram-based estimate of the distribution of the linearized propensity score for control group, for Lalonde non-experimental data

0.7

0.6

0.5

0.4

Density

0.3

0.2

0.1

0

0

5

10

15

20

25

30

1975 Earnings

Figure 14.7b. Histogram-based estimate of the distribution of the linearized propensity score for treatment group, for Lalonde non-experimental data

In order to estimate fs,t, we need to impute, essentially, the missing potential outcomes, Yi(0) for all treated units, given the covariates Xi. We compare predictions based on the experimental data in Section 14.6.3, with predictions based on the non-experimental data in Section 14.6.4, using earnings in 1975 as the only covariate. We compare seven different linear regression models. These models are all of the polynomial form

M
E[Yi(0)|Xi = x] = m · xm,
m=0

14.7 Sensitivity of Regression Estimates to Lack of Overlap

335

16

14

12

10

Earnings

8

6

4

2

0

0

1

2

3

4

5

6

7

8

Order of Polynomial

Figure 14.8a. Intervals for predicted average earnings for trainees in the absence of treatment, for Lalonde experimental data

16

14

12

10

Earnings

8

6

4

2

0

0

1

2

3

4

5

6

7

8

Order of Polynomial

Figure 14.8b. Intervals for predicted average earnings for trainees in the absence of treatment, for Lalonde non-experimental data

with the difference in the specification of the regression functions corresponding to the degree of the polynomial approximation. To illustrate, we use seven different models, corresponding to M = 0, 1, . . . , 6, to predict the outcome, that is, 1978 earnings, for a hypothetical trainee at the average value of 1975 earnings, which is $1,532 (Xi = 1.532).
Figures 14.8a and 14.8b give the 95% nominal intervals for the predicted average of 1978 earnings for trainees with 1975 earnings equal to $1,532, in the absence of the training, in thousands of dollars. The results based on the experimental data are in Figure 14.8a, and the results based on the CPS comparison group are in Figure 14.8b.

336

Assessing Overlap in Covariate Distributions

It is clear that with the experimental data the choice of M, that is, the number of terms in the polynomial, does not matter much: as we increase the number of terms the estimated precision decreases somewhat, but the point estimates do not change much. With the non-experimental data, however, there is substantial sensitivity to the order of the polynomial. Even if we ignore the very substantial change in the results based on the specifications with no covariates, the sensitivity to higher-order terms is striking. With a third-order (cubic) approximation, the 95% nominal interval for E[Yi(0)|Xi = 1.532] is [6.13, 6.53], whereas with a fifth-order polynomial the 95% nominal interval is [6.85, 7.43], which does not even overlap with the 95% nominal interval for the cubic approximation to the regression function. The difficulty when a priori choosing the order of the polynomial makes it impossible to arrive at a credible estimator based on simple regression methods in this setting.

14.8 CONCLUSION
In this chapter we have developed methods for assessing covariate balance in treatment and control groups. If there is considerable balance, simple adjustment methods may well suffice to obtain credible estimates of the causal effects of interest. However, in cases where overlap is limited, such simple methods are likely to be sensitive to minor changes in the methods used, as illustrated in Section 14.7. In the following chapters, we explore two approaches for taking these issues into account. First, we develop methods for constructing subsamples with improved balance in covariate distributions between treatment groups. Second, we discuss methods for adjusting for differences in covariate distributions between treatment and control groups that are more sophisticated than linear adjustment methods. Ultimately we advocate combining both approaches to obtain more credible estimates of the causal estimands: balancing covariate distributions by matching or subclassification, and model-based adjustment.

NOTES
The importance of inspecting covariate balance and the dangers of simple linear regression adjustment goes back a long time (e.g., Cochran and Rubin, 1973; Rubin, 1973ab, 1979). This advice has not always been followed, however, and in empirical studies researchers often focus simply on t-statistics for testing the null hypotheses of no difference in average values between treatment and control groups. More recent publications stressing the importance of assessing balance compared to simply testing for equality of means include Imbens (2004, 2015), Imai, King, and Stuart (2008), Austin (2008), and Rubin (2006, 2008).

CHAPTER 15
Matching to Improve Balance in Covariate Distributions
15.1 INTRODUCTION
In observational studies, the researcher has no control over the assignment of the treatment to units. This lack of control makes such studies inherently more sensitive and controversial than evaluations based on randomized assignment, where biases can be eliminated automatically, at least in expectation, through design, and as a result, for example, p-values can be assigned to sharp null hypotheses without relying on additional assumptions. Nevertheless, even in observational studies, one can carry out what we like to call a design phase during which researchers can construct a sample such that, within this selected sample, inferences are more robust and credible. We refer to this as a design phase because, just like in the design phase of a randomized study, it precedes the phase of the study during which the outcome data are analyzed. In this design phase, researchers can select a sample where the treatment and control samples are more balanced than in the original full sample. Balance here refers to the similarity of the marginal (generally multivariate) covariate distributions in the two treatment arms. This balance is not to be confused with the covariate balance conditional on the true propensity score that we discussed in the previous chapter. The latter holds, in expectation, by definition.
An extreme case of imbalance occurs when the ranges of data values of the two covariate distributions by treatment differ, and as a result there are regions of covariate values that are observed in only one of the two treatment arms. More typical, even if the ranges of data values of the covariate distributions in the two treatment arms are identical, there may be substantial differences in the shapes of the covariate distributions by treatment status. In a completely randomized experiment, the two covariate distributions are exactly balanced, in expectation. In that case, many different estimators ­ for example, simple treatment-control average differences, covariance-adjusted average differences, as well as many different model-based methods ­ tend to give similar point estimates of causal effects when sample sizes are at least moderately large. In contrast, in observational studies we often find substantial differences between covariate distributions in the two treatment arms. Such lack of covariate balance creates two problems. First, it can make subsequent inferences sensitive to ostensibly minor changes in the methods and specifications used. For example, adding an interaction or quadratic term
337

338

Matching to Improve Balance in Covariate Distributions

to a linear regression specification can change the estimated average treatment effect substantially when the covariate distributions are far apart. Second, lack of balance can make the inferences imprecise. For covariate values with either few treated or few controls, it may be difficult to obtain precise estimates for treatment effects, and this, in turn, may make the estimates of overall treatment effects imprecise. In this chapter we discuss one systematic way to address these issues. In the next chapter we discuss an alternative.
In the approach to improving balance discussed in the current chapter, we focus on a setting characterized by a modest number of treated units, and a relatively large pool of possible controls. We are interested in estimating causal effects for the subpopulation of treated units. For example, consider designing an evaluation of a voluntary job-training program, where we are interested in the average effect of the training on those who completed the training program. The population of treated participants is typically well defined. The set of possible controls may include all individuals who are potentially comparable to the participants, which may well be a much larger set of individuals than the set of individuals sampled from the participants in the program. Prior to collecting the data on the outcomes for all individuals in this study, we have to select a set of individuals to serve as a control group. There is no harm in having data available on all possible control individuals, even if some are almost entirely irrelevant for the analysis. However, in practice, there may be trade-offs in terms of costs associated with collecting detailed information on a small set of units, versus those associated with collecting a limited amount of information on more units. With that trade-off in mind, it may be useful to select a subset of the full set of possible controls, based on covariate or pre-treatment information, for which we eventually collect the outcome data. Thus, the specific problem we study in this approach becomes one of selecting this subset, using solely covariate information, in order to create an informative sample for subsequent analyses. These subsequent analyses are likely to involve model-based imputation of the missing potential outcomes, matching, or propensity-score-based methods, all designed to adjust comparisons between treated and control units for remaining differences in covariate distributions. Details of the specific adjustment methods are discussed in subsequent chapters. The focus in this chapter is on selecting a control sample that is more balanced with respect to the treated sample than a random sample from the full population of possible controls. This selection will serve the purpose of making any subsequent analyses, irrespective of the choice of method, more robust, and thus more credible. Here we discuss both some practical and some theoretical issues concerning the selection of the control sample.
In this discussion we consider the set of treated units to be fixed a priori. We discuss two specific matching methods where, in each case, we construct the control sample by matching one or more distinct controls to each treated unit. We consider first Mahalanobis metric matching, where the distance between units is measured using all covariates, and second propensity score matching, where the distance is measured solely in terms of the difference in the estimated propensity score (or, more typically, a monotone transformation of the propensity score such as the linearized propensity score, the logarithm of the odds ratio). We then discuss the theoretical properties of these two matching methods and their relative merits, as well as methods that combine features of both.
This chapter is organized as follows. In the next section we discuss the Reinisch barbituate data used in this chapter. In Section 15.3 we develop the mechanics of matching

15.3 Selecting a Subsample of Controls through Matching to Improve Balance

339

without replacement. Next, in Section 15.4, we illustrate the methods developed so far using a small subsample with six units from the Reinisch barbituate data. In Section 15.5 we discuss some theoretical issues related to matching. In Section 15.6 we apply the methods discussed in this chapter to the Reinisch barbituate data. Section 15.7 concludes.

15.2 THE REINISCH ET AL. BARBITUATE EXPOSURE DATA

We illustrate the issues discussed in this chapter using the same barbituate data, originally analyzed by Reinisch et al., that were previously used in Chapters 13 and 14. The barbituate data contain information on 745 individuals exposed to barbituates while in utero, as well as on 7,198 individuals who were not exposed to barbituates in utero but born in the same group of hospitals as the exposed individuals. The averages and standard deviations by treatment status are presented for these data in Table 15.1, which repeats some of the information from Table 14.1. The last four columns in this table present measures of the degree of overlap introduced in Chapter 12. For each of the covariates, the propensity score, and the linearized propensity score, we present the normalized difference,

^ ct =

Xt - Xc , (s2c + s2t )/2

the logarithm of the ratio of the standard deviations by treatment status,

^ ct = ln

st sc

,

and the overlap probabilities for control and treated units, defined as

^c = 1 - F^ c F^ t-1(1 - /2) + F^ c F^ t-1(/2) ,

where F^ c( · ) and F^ c-1( · ) are the empirical distribution function and its inverse in the control subsample, and

F^ c(x)

=

1 Nc

1Xix,
i:Wi=0

and

F^ c-1(q)

=

min {x
-<x<

:

F^ c(x)



q},

with analogous definitions for F^ t( · ) and f^t-1( · ). We report ^c and ^t for  = 0.05.

15.3 SELECTING A SUBSAMPLE OF CONTROLS THROUGH MATCHING TO IMPROVE BALANCE
In this section we discuss matching as a method for creating a subsample that has more balance in the covariates. First we put some structure on the problem, and then we discuss two specific matching methods: the Mahalanobis metric matching, which attemps to balance all covariates directly; and propensity score matching, which matches only on a

340

Matching to Improve Balance in Covariate Distributions

Table 15.1. Summary Statistics for the Reinisch et al. Barbituate Data

sex antih hormone chemo cage cigar lgest lmotage lpbc415 lpbc420 motht motwt mbirth psydrug respir ses sib

Overlap Measuresa

Controls (N = 7,198) Treated (N = 745) Nor Log Ratio

 0.05

Mean (S.D.) Mean (S.D.) Dif of STD Controls Treated

0.51 0.10 0.01 0.08 -0.00 0.54 5.24 -0.04 0.00 -0.12 3.77 3.91 0.03 0.07 0.03 -0.03 0.55

(0.50) (0.30) (0.10) (0.27) (1.01) (0.50) (1.16) (0.99) (0.99) (0.96) (0.78) (1.20) (0.17) (0.25) (0.18) (0.99) (0.50)

0.50 (0.50) -0.01 0.00 0.17 (0.37) 0.19 0.20 0.03 (0.16) 0.11 0.43 0.11 (0.32) 0.10 0.14 0.03 (0.97) 0.03 -0.04 0.48 (0.50) -0.12 0.00 5.23 (0.98) -0.01 -0.17 0.48 (0.99) 0.53 0.00 0.05 (1.04) 0.05 0.06 1.17 (0.56) 1.63 -0.55 3.79 (0.80) 0.03 0.03 4.01 (1.22) 0.08 0.02 0.02 (0.14) -0.07 -0.21 0.21 (0.41) 0.41 0.47 0.04 (0.19) 0.03 0.07 0.25 (1.05) 0.28 0.06 0.52 (0.50) -0.06 0.00

0.00 0.00 0.00 0.00 0.00 0.03 0.00 0.00 0.07 0.03 0.00 0.00 0.05 0.02 0.07 0.07 0.01 0.03 0.48 0.28 0.00 0.00 0.00 0.00 0.03 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00

Multivariate

measure

pscore

0.07

linearized -5.12

pscore

(0.12) (3.40)

0.37 (0.22) -0.77 (1.35)

1.78
1.67 0.62 1.68 -0.93

0.44 0.63 0.45 0.63

a t0.05 measures the proportion of treated units with a covariate value that is either below the 0.025 quantile of the covariate values or above the 0.975 quantile of the covariate values for the controls, and similarly for c0.05.

scalar function of the covariates, created to balance all covariates in an attempt to mimic randomization.

15.3.1 Setup
Suppose we have Nt treated units, indexed by i = 1, . . . , Nt. In addition, we have a pool of possible controls, of size Nc, larger than Nt. We wish to select Nc < Nc units from this set to construct a sample of size N = Nc + Nt of units that will be used to estimate treatment effects. Let Ic denote the set of indices for the set of possible controls, Ic = {Nt + 1, . . . , Nt + Nc}. We focus on the problem of choosing a subset Ic of the full set of controls, Ic  Ic, that has better balance with respect to the treated units than a random sample of the full set of possible controls. We would like the covariates of
the units included in Ic to be well balanced in terms of covariates relative to the set of treated units and, at the same time, the cardinality of the set Ic to be sufficiently large to

15.3 Selecting a Subsample of Controls through Matching to Improve Balance

341

allow precise causal inferences whenever possible and, also, no larger than necessary to minimize costs associated with collecting outcome data for units in Ic.
In principle this is a decision problem, and we could set it up that way by explicitly defining the cost of data collection, the disutility associated with lack of balance and that associated with lack of precision. These costs may in practice be difficult to specify, especially a priori, and so we simplify the problem by fixing Nc = Nt, the number of treated units. Using exactly the same procedures, we could also select a number of matches for each treated unit. We focus on the case with M = 1 here for ease of exposition. Fixing Nc = Nt may be a reasonable choice if we consider the effect of Nc on the sampling variance of estimators for causal effects. In a randomized experiment, the sampling variance of the usual estimator for the average treatment effect under homoskedasticity and constant treatment effects, is  2 · (1/Nt + 1/Nc). In that case, this variance tends to be dominated by the sample size of the smaller of the treatment and control groups. Adding many more controls than treated units therefore does not improve the precision much in this simple situation, whereas with fewer controls than treated units, the sampling variance is sensitive to the number of controls. This sampling variance calculation does not directly apply to the unconfoundedness setting we are studying in this part of the book, but the intuition is still correct that the sampling variance of the estimated treatment effect is dominated by the sample size of the smaller of the treatment and control groups. Choosing Nc = Nt is also a convenient choice because some of the specific methods we discuss for selecting a set of controls rely on assigning a fixed number of controls to each treated unit.
Given this restriction, the decision problem becomes one of selecting a set of Nt controls from the set Ic to optimize balance. We operationalize this objective by ordering the treated units and then sequentially selecting control units that are closest to each treated unit. Let It = {1, . . . , Nt} denote the ordered set of indices for the treated units. Suppose for convenience that the treated units are ordered based on the value of the propensity score, with the units with the highest value of the estimated propensity score to be matched first, which corresponds to matching the units that are a priori the most difficult to match first. The choice of ordering can alter the results, although in practice the results tend to be fairly robust to this choice. Let d(x, x ) denote some measure of the "distance" between two vectors of covariates (formally not necessarily a distance because we allow d(x, x ) to be zero even if the vectors are not identical). Later we discuss various choices for the measure. Given the choice of the metric, let Mci  Ic denote the set of matched controls for treated unit i. At the moment this set is a singleton, Mic = {mi}, where mi is the index of the control unit that is matched to treated unit i, but later we allow for more general matching strategies. For the first treated unit, i = 1, the set containing the closest match is

Mc1 =

j  Ic

d(X1,

Xj)

=

min
j Ic

d(X1,

Xj

)

.

For the ith treated unit, this set is

Mic =

j  Ic - ii-=11Mic

d(Xi,

Xj)

=

j

min
Ic -ii-=11 Mci

d(Xi,

Xj

)

,

342

Matching to Improve Balance in Covariate Distributions

where Ic-ii-=11Mic is the subset of Ic excluding the set of all the control units previously used as matches, ii-=11Mic . Following this approach for all treated units, i = 1, . . . , Nt, leads to a set of matches Ic = Ni=t 1Mci with Nt distinct elements.
The remaining issue is the choice of distance metric d(x, x ). In the next two
subsections we discuss two of the leading choices.

15.3.2 Mahalanobis Metric Matching

The first choice for the distance measure is the Mahalanobis metric, where the distance between units with covariate values x and x is defined to be

dM(x, x ) = (x - x )

Nc · ^ c + Nt · ^ t Nc + Nt

-1
(x - x )T ,

where, as previously,

^c

=

1 Nc

(Xi
i:Wi=0

- Xc)T

·

(Xi

-

Xc)

and

^t

=

1 Nt

(Xi
i:Wi=1

-

X t )T

·

(Xi

-

Xt),

are the within-group sample covariance matrices of the covariates, and, as previously,

Xc

=

1 Nc

Xi
i:Wi=0

and

Xt

=

1 Nt

Xi,
i:Wi=1

are the within-group averages of the covariates. This metric amounts to normalizing the covariates so that under the assumption c  t, they have the identity matrix as the within-group covariance matrix, and then defining the distance as the sum of squared differences. An important property of the Mahalanobis metric is that the resulting set of matches is invariant to affine transformations of the covariates.

15.3.3 Propensity Score Matching
The second distance measure considers only differences in a scalar function of the covariates, namely the estimated propensity score (or a monotone transformation thereof). The motivation for this choice is twofold. First, the motivation relies on the result, discussed in Chapter 12, that adjusting for differences in the propensity score between treated and control groups eliminates all systematic biases associated with differences in observed covariates. Second, it is simpler to find close matches on a scalar (function of the) covariate(s), than it is to find close matches on all covariates jointly. Let e(x) be the propensity score, and (x) = ln (e(x)/(1 - e(x)) be the linearized propensity score (lps), or the logarithm of the odds ratio. To make this specific, we use as the metric the squared difference in the lps:

d (x, x ) =

2
(x) - (x ) =

ln

e(x) 1 - e(x)

- ln

e(x ) 1 - e(x )

2
.

It is convenient to use differences in the lps rather than differences in the propensity score itself because typically this transformation takes account of the fact that typically

15.3 Selecting a Subsample of Controls through Matching to Improve Balance

343

the difference in propensity scores of 0.10 and 0.05 is larger in substantive effects on outcomes than the difference between propensity scores of 0.55 and 0.50. Put differently, the potential outcomes are more likely to be approximately linear in the lps than in the propensity score. For example, if the potential outcomes are linear in the covariates, the covariates are jointly normal, and the propensity score follows a logistic form, then the potential outcomes are linear in the lps.
In practice we typically do not know the propensity score. In that case we use an estimated version of it to construct the matches. Formally, with the estimated propensity score denoted by e^(x), we define

d (x, x ) =

^(x) - ^(x )

2
=

ln

e^(x) 1 - e^(x)

- ln

e^(x ) 1 - e^(x )

2
.

The use of an estimated function of the covariates for matching raises two issues. First, the estimated propensity score may actually improve the quality of the matches over using the true propensity core, a theme mentioned earlier and one that we return to later. Here, we just note that matching on the estimated propensity score rather than the true propensity score can adjust for random imbalances between covariate distributions, such as those that can arise in a randomized experiment. A second issue is that the model for the propensity score may be misspecified. In that case the balance in covariates conditional on the estimated propensity score may not hold, and the credibility of subsequent inferences may be compromised. In the current setting where we use the propensity score for creating a more balanced sample through matches this is not as likely to be an important concern as it would be if we used the estimated propensity score for weighting or blocking, because the matching is just the first step in the analysis, with subsequent steps consisting of adjustments for remaining differences in covariates.

15.3.4 Hybrid Matching Methods
In some cases, one may wish to ensure that the matched sample is perfectly balanced in some key covariates that are viewed a priori as possibly highly associated with the outcomes. For example, one may wish to ensure that the proportions of men and women are the same in the treatment and control groups. One can achieve this by a simple modification of the previously discussed method. Specifically, one can in such cases partition the samples by values of these covariates, and then match, within the partitioned samples, on the estimated propensity score.

15.3.5 Rejecting Matches of Poor Quality
In some cases, even the closest match may not be close enough. If one finds that the closest match for a particular treated unit is substantially different, as measured by the distance d(x, x ), it may be appropriate to drop the treated unit from the analysis entirely. We discuss a general approach to select the sample based on the estimated propensity score in the next chapter, but here we discuss a simple modification to address this issue in the context of matching methods.
A simple rule would be to drop treated units if the distance between a treated unit and its closest control match is larger than a fixed threshold. For example, we could drop all

344

Matching to Improve Balance in Covariate Distributions

matches where the estimated linearized propensity score exceeds dmax,
^(Xi) - ^(Xmi ) > dmax,
for some pre-specified dmax, say dmax = 0. 1. In practice, this rule will often eliminate only treated units with propensity score values close to one, because, with a reasonably sized set of possible controls, it is likely that there will be sufficiently close control matches for treated units with propensity scores away from one.

15.3.6 Caliper Matching Methods
The two matching methods discussed earlier, Mahalanobis matching and propensity score matching, both assign one control unit to each treated unit, but more generally the method could allow for two or more matches. An alternative strategy is to assign to each treated unit all controls that are within some distance from that treated unit. Given a distance function d(x, x ), we could assign to treated unit i = 1 all control units j  Ic such that
d X1, Xj  dcal
for some pre-set number dcal. Let M1c  Ic be the set of labels for these units. After matching treated unit i = 1, we seek to match the second treated unit i = 2 to all control units from the set of potential controls excluding the ones matched to treated unit i = 1, Ic - Mc1, with distance d X2, Xj less than dcal, and so on, with the set of control units matched to treated unit i defined analogously.
The advantage of the caliper-matching method is that more control units are used in the analysis, and thus potentially more information is used to estimate the missing control potential outcomes for the treated units. Its disadvantage is that the sample that results from this approach is not necessarily very well balanced. It may be that for some treated units there are many control units within the caliper, whereas for other treated units there are only one or two control units. Especially if we match without replacement, the order in which we match the treated units can be important because the method can lead to difficulties in finding good matches for some treated units if other treated units have already been matched with a large number of control units.

15.4 AN ILLUSTRATION OF PROPENSITY SCORE MATCHING WITH SIX OBSERVATIONS
Here we illustrate some of the methods discussed so far using a subset of the Reinisch barbituate data. We use observations on seven units, two with in utero exposure to barbituates, and five from the control group. The values for the estimated propensity score and lps are reported in Table 15.2. (Note that the propensity score is estimated on the full sample of N = 7,643 units.) In terms of the notation introduced in Section 15.3, It = {1, 2}, Ic = {3, 4, 5, 6, 7}. We order the two treated units by the decreasing value of their estimated propensity scores.

15.5 Theoretical Properties of Matching Procedures

345

Table 15.2. Seven Units from the Reinisch et al. Barbituate Data Set

Unit Wi e^(Xi) ^(Xi)

1

1 0.577 0.310

2

1 0.032 -3.398

3

0 0.136 -1.846

4

0 0.003 -5.913

5

0 0.310 -0.798

6

0 0.000 -9.424

7

0 0.262 -1.033

First let us consider matching on the (estimated) lps. The closest match for unit 1,
with an estimated lps equal to 0.310, is control unit 5, with an estimated lps equal to -0.798. For the second treated unit, with an lps equal to -3.398, the closest control unit in Ic - {5} = {3, 4, 6, 7} is unit 3, with an estimated lps equal to -1.846. Control units 4, 6, and 7 are not used as matches, so that Ic = {3, 5}.
Note that the order of the matching is irrelevant here. Had we started with the second
treated unit, the matches would have been identical. It is important here, though, that we
match on the lps. If we match on the propensity score itself, the closest match for treated unit 2 would be control unit 4 instead of control unit 3, so that in that case Ic would be {4, 5}.

15.5 THEORETICAL PROPERTIES OF MATCHING PROCEDURES
In this section we discuss some of the theoretical properties of the matching procedures discussed in the previous section. This section is more technical than others, and a full understanding of it is not essential for implementing the methods. It is primarily intended to provide additional understanding of the way these methods work, and in particular to provide insights into the differences between matching on the propensity score, Mahalanobis matching, and other matching methods. Most of the section deals with special cases where more-precise properties can be derived. In these special cases we assume that the vectors of covariates in both treatment arms have a normal distribution with mean vectors c and t, indexed by the treatment status, and common covariance matrix . The results can be generalized to allow for ellipsoidally symmetric distributions with proportional inner product matrices.
We are primarily concerned with differences in covariate distributions in the matched samples relative to the original sample. This is somewhat of a simplification, because it is likely that one will not simply compare outcomes for treated and control units in the matched or original sample. Instead, it is likely that one will analyze the matched sample using additional methods of the type discussed in Chapters 17 and 18 to adjust for biases associated with remaining differences in covariate distributions. Nevertheless, the stated comparison will provide a good indication of the efficacy of matching

346

Matching to Improve Balance in Covariate Distributions

for removing differences in covariates. Specifically, we are here concerned with biases

in estimators for the super-population average treatment effect for the treated, sp,t =

E[Yi(1) - Yi(0)|Wi = 1]. Moreover, here we consider only estimators based on the dif-

ference in average outcomes for treated and (matched) controls. Without matching, the

estimator

is

^ dif

=

Y

obs t

-

Y oc bs ,

with

bias

E

Y

obs t

-

Y

obs c

-

sp,t

= E Yi(0) Wi = 1

- E Yi(0) Wi = 0

= E E Yi(0) Xi Wi = 1 - E E Yi(0) Xi Wi = 0 ,

with the second equality following by unconfoundedness. This bias depends on the rela-

tion between the outcomes and the covariates, E[Yi(0)|Xi], and on the distributions of

the covariates in the two treatment groups. We do not know this relationship, or this

distribution at this stage, and in general do not wish to rely overly on knowledge about

it for choosing the matching method. We therefore focus on biases in terms of general

linear combinations of the covariates. Let us assume that in the super-population the

conditional mean of Yi(0) given the covariates is E[Yi(0)|Xi = x] = x, where for normalization we assume T  = 1. We do not really believe that the relationship between

the outcomes and the covariates is linear. In fact, if we were confident about the linearity

of the conditional mean, we could simply estimate this relationship by linear regression,

which would eliminate all biases associated with differences in covariate distributions if

the conditional mean were truly linear. However, the goal here is to find a meaningful

comparison between different matching methods, and for that purpose, it is enlightening

to focus on the effect of these matching methods on biases assuming a linear relationship

between outcomes and covariates.

In combination with the notation c and t for the population mean of the covariate

values in the control and treatment groups, the linearity for the conditional mean of

Yi(0) given Xi implies that the bias for the simple average difference estimator, ^ dif =

Y

obs t

-

Y oc bs ,

is

E

Y

obs t

-

Y

obs c

-

sp,t

=E E Yi(0) Xi

Wi = 1

- E E Yi(0) Xi Wi = 0 = (t - c).

Suppose that a generic matching method M, in expectation, changes the mean of the vector covariates for the Nt matched controls from c to Mc . This changes the bias for the simple average difference estimator from (t - c) to (t - cM). The percentage bias reduction, or pbr, is

pbr(

)

=

100

×

(t - M0 ) (t - c)

.

(15.1)

In general the percentage bias reduction will depend on the value of . Some matching methods have the feature that the percentage bias reduction is the same for all linear combinations , so that for all  we have, for some constant cM,

(t - cM) = cM · (t - c).

15.5 Theoretical Properties of Matching Procedures

347

Such methods are called equal percentage bias reducing or epbr methods. Within the
context of our special case assuming normality (or, more generally, ellipsoidal symme-
try and proportional inner products), this property is shared by Mahalanobis metric and
propensity score matching. We shall argue that epbr is an attractive property, even though
at first it may not appear to be an important property. As long as a particular matching
method reduces the bias for each covariate, it might appear not to be a major concern
that it reduces the bias more for some covariates than it does for others. However, if a
matching method is not epbr, it reduces bias for some linear combinations of covariates
but increase bias for others, and in fact to an infinite degree. The key insight is that if a
matching method is not epbr, then there are linear combinations of the covariates (actu-
ally, an infinite number) such that the bias in the matched sample is non-zero, whereas
the bias for that linear combination in the original sample was zero. Hence the matching
makes the bias infinitely worse for that particular linear combination. The implication is
that only epbr matching methods improve the bias for every linear combination.
Let us discuss this property of epbr methods in more detail. First, let us decompose the inverse of the K × K covariance matrix of the covariates -1 (assumed proportional in both treatment groups) as GGT , where G is a lower triangular matrix, so that = (GT )-1G-1. In addition, let H be any orthonormal matrix with the first column equal to H1 = GT (t - c)T /((t - c)GGT (t - c)T ), so that HT GT (t - c)T /((t - c)GGT (t - c)T ) = 1K, where 1K is the K-component vector with the kth element equal to one and the others equal to zero (where K is the dimension of the covariate vector). Because H is orthonormal, it follows that HHT = IK, and thus GHHT GT = GGT = -1. By construction, G and H are invertible, and thus GH is invertible. In terms of the basis defined by the columns of (HT GT )-1, the difference in covariate vectors t - c is

HT GT (t - c)T =  · 1K,

where the constant of proportionality  is  = (t - c)GGT (t - c)T -1. Thus, the
bias of the original sample is, for a linear combination  , measured in the basis defined by the columns of (HT GT )-1, equal to

 1

(t - c)GH

=  ·  T 

0 ...

 =

 · 1,

0

where 1 is the first element of  . Now let us compare two matching methods, matching method A, which is epbr, and
matching method B, which is not. Because matching method A is epbr, it follows that the expectation of the average of the covariates for the matched controls, Ac , satisfies, for some scalar constant cA, (t - cA) = cA · (t - c) for all linear combinations . Choose  = GH , so that

(t - Ac ) = cA · (t - c) = cA · (t - c)GH = cA ·  · 1.

348

Matching to Improve Balance in Covariate Distributions

Because matching method B is not epbr, there is no scalar constant cB such that (1 - Bc ) = cB · (t - c). Hence by invertibility of HT GT , it follows that there is no cB such
that

HT GT (1 - B0 )T = cB · HT GT (1 - 0)T .
Because HT GT (1 - 0)T =  · 1K, it follows that there is no cB such that
HT GT (1 - B0 )T = cB ·  · 1K
Thus it follows that some element of HT GT (t - Bc ), other than the first element, must differ from zero. Suppose that one such element is the jth one, j = 1. Let  be the jth column of HG. Then (t - Bc ) differs from zero (so the bias after matching is nonzero), whereas the bias before matching was (t - c) = 0. Hence matching method B has made the bias for this linear combination infinitely worse.
Second, consider propensity score and Mahalanobis matching in our special case where the covariates in both treatment arms have normal distributions with means w for w = 0, 1 and covariance matrix . First transform the covariates from X to Z = HT GT (X - c). For both Mahalanobis and propensity score matching, the matching results are invariant to affine linear transformations of the covariates, so whether we match on Xi or Zi is irrelevant. After the transformation from Xi to Zi, we have in the original sample, Zi|Wi = 0  N (0, c0 · 1K, IK), and Zi|Wi = 1  N (c0 · 1K, IK), where, as before, 1K is the K-vector with the first element equal to one and the others equal to zero. The transformed covariates are uncorrelated and thus, because of the normality, statistically independent. In terms of Z the bias in the original sample is c0 · 1K, concentrated in the first element. In terms of the transformed covariates, the propensity score is a function of the first element Zi1 only. Now consider matching on (a function of) Zi1, which includes matching on the propensity score or matching on the lps. Because, under normality, the other components of Zi are independent of Zi1, matching on (a function of) Zi1 does not affect the other component's distributions in the two treatment arms. Combined with the fact that there is no bias in the original sample orthogonal to Zi1, this fact implies that there will be no bias in the matched samples orthogonal to Zi1. The matching can affect only the difference in distributions for the first covariate that is being used in the matching, Zi1, and therefore t - cM = c1 · 1K = (c1/c0) · (t - c) and thus all matching methods that match only on (functions of) Zi1 are epbr.
Before considering the properties of Mahalanobis matching, consider matching on a K-vector Zi such that in the original sample Zi|Wi = w  N (0, IK) for both w = 0, 1. In that case, there is no bias in the original sample. Matching on all these (for the bias irrelevant) covariates leaves the difference in means unchanged, or t -cM = t -c = 0, and so there is no bias in the matched samples, and Mahalanobis matching is epbr in this case. Now consider the case of interest, where 1-c = c0·11. In that case there is a bias, coming from the difference in the first element of Z. Matching on all the covariates does not introduce any bias in the other elements of Z, and so t - cM = cM · 1K, and Mahalanobis matching is epbr.
Note that both propensity score and Mahalanobis matching methods are epbr, where bias is defined in terms of the average difference between covariates. This does not mean

15.6 Creating Matched Samples for the Barbituate Data

349

that they also reduce differences in other aspects of the distribution. In fact, they may introduce bias in terms of other moments, even when there was none to begin with. It is easy to see that this can happen. Suppose we are matching on a single covariate Xi, with the same N (0, 1) distribution in both treatment arms. In the matched samples the variance of the covariate in the control distribution will be less than one, and thus there will be a difference in the distribution of the covariates in the two treatment arms, despite there being no such difference in the original sample. To be precise, consider a treated unit with Xi = x < 0. Because the probability density function for Xi is increasing in x for x < 0, there will tend to be slighty more control units j, with Xj close to x and Xj > x than control units with Xj close to x and Xj < x. Thus, the expected value of Xj for a control unit matched to a treated unit with Xi < 0 will be larger than Xi, and the opposite for control units matched to treated units with Xi > 0.
The preceding discussion under normality also illustrates an important aspect of the difference between Mahalanobis and propensity score matching. The latter matches only on the scalar covariate whose distribution differs between treatment and control groups. The former matches in addition on a set of covariates whose distributions are identical in both the treatment and control groups, as well as independent of the key (function of the) covariates whose distribution differs between treatment arms. In this simplified setting with normally distributed covariates, it is clear that Mahalanobis matching is "wasteful" in terms of bias reduction in the sense that it puts much emphasis on matching covariates whose distributions are already perfectly matched in expectation. Putting any emphasis on covariates that are already balanced is disadvantageous for two reasons. First, it may lead to less bias reduction for the covariates that are not balanced in the original sample. Especially when there are many covariates, attempting to match on all of them using Mahalanobis matching may substantially erode the effectiveness for reducing bias in the function of the covariates that matters most, that is, the propensity score. Second, by matching on the covariates that are already balanced, Mahalanobis matching may compromise the balance that is already there in the distribution. On the other hand, even if a covariate is balanced in expectation, as in a randomized experiment, it may still be beneficial in terms of precision to match on such a covariate to eliminate random variation. In addition, a key advantage of Mahalanobis matching is that it has good robustness properties. Outside the special case with normally or, more generally, ellipsoidally distributed covariates, Mahalanobis matching will still balance all covariates with large enough control samples, where estimated propensity score matching may fail to do so, for example, when the model for the propensity score is misspecified.

15.6 CREATING MATCHED SAMPLES FOR THE BARBITUATE DATA
In this section we apply matching methods to the Reinisch barbituate data. We compare results obtained using Mahalanobis metric matching and matching on the estimated lps, which we refer to as propensity score matching, in a slight abuse of language. In both cases, we match each of the 745 individuals who had been exposed in utero to barbituates to a single control individual, selected from the pool of 7,198 individuals with no history of prenatal barbituate exposure. Table 15.1 presents summary statistics for the full sample. The propensity score was estimated using the algorithm decribed in Chapter 13, with

350

Matching to Improve Balance in Covariate Distributions

0.14

0.12

0.1

Density

0.08

0.06

0.04

0.02

0

-20

-15

-10

-5

0

5

10

Linearized Propensity Score

Figure 15.1a. Histogram-based estimate of the distribution of linearized propensity score for control group, for Reinisch barbituate data

0.35

0.3

0.25

Density

0.2

0.15

0.01

0.05

0

-20

-15

-10

-5

0

5

10

Linearized Propensity Score

Figure 15.1b. Histogram-based estimate of the distribution of linearized propensity score for treatment group, for Reinisch barbituate data

fourteen linear terms and nineteen second-order terms selected into the specification of the propensity score. See Table 13.6 in Chapter 13 for details on the parameter estimates for the estimated propensity score. Figures 15.1a and 15.1b, which are analogous to Figures 14.2a and 14.2b in Chapter 14, present histogram estimates of the distribution of the estimated lps for the treated and control subsamples for the Reinisch barbituate data.
For both matching methods (Mahalanobis and lps), we report in Table 15.3 the average covariate differences between treated and control units' matched sample, scaled by the standard deviation of the covariate in the matched sample. For comparison purposes, we include a column with the normalized differences in means in the full sample. We scale all comparisons by the standard deviation in the full sample to make the columns comparable. We also report the results for the balance on the propensity score and the

351

Table 15.3. Between Treated and Control Units before and after Matching for the Reinisch Barbituate Data

Full Sample

Matched Samples

sex antih hormone chemo cage cigar lgest lmotage lpbc415 lpbc420 motht motwt mbirth psydrug respir ses sib

Mahalanobis

Propensity Score

Nor Log Rat

 0.05

Nor Log Rat

 0.05

Nor Log Rat

 0.05

Dif of STD Controls Treated Dif of STD Controls Treated Dif of STD Controls Treated

-0.01 0.00 1.00

1.00 0.00 -0.00 1.00

1.00 -0.03 0.00

1.00

1.00

0.19 0.20 1.00

1.00 0.02 0.01 1.00

1.00 -0.03 -0.02

1.00

1.00

0.11 0.43 1.00

0.97 0.00 0.00 1.00

1.00 0.01 0.03

1.00

0.97

0.10 0.14 1.00

1.00 0.00 0.00 1.00

1.00 0.08 0.10

1.00

1.00

0.03 -0.04 0.93

0.97 -0.03 0.03

0.96

0.95 -0.01 -0.00

0.95

0.95

-0.12 0.00 1.00

1.00 -0.01 -0.00

1.00

1.00 -0.01 -0.00

1.00

1.00

-0.01 -0.17 0.95

0.98 -0.02 0.13

0.98

0.97 0.00 0.01

0.98

0.97

0.53 0.00 0.93

0.93 0.13 0.02

0.97

0.95 0.02 -0.01

0.95

0.97

0.05 0.06 0.99

0.97 0.03 0.06

0.98

0.99 0.07 -0.06

0.99

0.97

1.63 -0.55 0.52

0.72 0.59 -0.01

0.90

0.86 0.10 0.09

0.96

0.94

0.03 0.03 1.00

1.00 -0.03 0.15

1.00

1.00 -0.03 0.03

1.00

1.00

0.08 0.02 1.00

1.00 0.02 0.09

1.00

1.00 0.05 -0.02

1.00

1.00

-0.07 -0.21 0.97

1.00 0.00 0.00

0.98

0.98 0.03 0.12

0.99

0.98

0.41 0.47 1.00

1.00 0.00 0.00

1.00

1.00 0.13 0.09

1.00

1.00

0.03 0.07 1.00

1.00 0.00 0.00

1.00

1.00 0.03 0.07

1.00

1.00

0.28 0.06 1.00

1.00 0.03 0.08

0.99

0.96 -0.04 0.02

0.99

0.96

-0.06 0.00 1.00

1.00 0.03 -0.00

1.00

1.00 0.04 -0.00

1.00

1.00

Multivariate measure 0.43

0.24

0.05

pscore linearized pscore

1.67 0.62 0.44

0.63 1.33 0.08

0.83

0.82 0.08 0.11

0.96

0.93

1.65 -0.96 0.44

0.63 0.45 0.11

0.83

0.82 0.02 0.11

0.96

0.93

352

Matching to Improve Balance in Covariate Distributions

Co variate Label

18 16 14 12 10
8 6 4 2 0 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2
Normalized Difference Figure 15.2. Covariate balance before (+) and after (o) lps and after Mahalanobis (*) matching, for the Reinisch barbituate data

lps. The results show that the matching leads to a substantial improvement in balance. In the full sample, the normalized difference for one of the key covariates, lpbc420, is 1.63. Mahalanobis matching reduces this to 0.59, and propensity score matching reduces it further, to 0.10. In fact, after propensity score matching, none of the normalized differences exceeds 0.13, a degree of balance comparable to what one might expect in a completely randomized experiment. Figure 15.2 shows graphically how the normalized differences have decreased as a result of the matching. In this figure, the stars denote the original normalized differences before matching, the circles denote the normalized differences after lps matching, and the plus signs denote the normalized differences after Mahalanobis matching.
The improvement in balance can be shown graphically by comparing the distributions of the lps by treatment status in the full and matched samples. In order to do so, we re-estimate the propensity score in the matched samples, using the same algorithm as described in Chapter 13. The three covariates sex, lmotage, and ses are automatically selected for inclusion in the propensity score. First, consider the propensity score matched sample. The algorithm now selects six linear terms and one second-order term, compared to the thirty-three terms selected in the full sample. The fact that the algorithm selects fewer terms already indicates the improved balance. The parameter estimates for the propensity score are presented in Table 15.4. Second, consider the Mahalanobis matched sample. The algorithm for estimating the propensity score now selects six additional linear and six second-order terms. The results are in Table 15.5. Figures 15.1a and 15.1b present the distribution of the lps by treatment status in the full sample. Figures 15.3a and 15.3b present the distribution of the (newly estimated) lps in the lps matched samples, and Figures 15.4a and 15.4b present the distributions of the (newly estimated) lps in the Mahalanobis matched sample.
Figure 15.5 shows the distribution of differences in lps within the 745 matches after propensity score matching. This figure shows that about half the matches have

15.6 Creating Matched Samples for the Barbituate Data

353

Table 15.4. Estimated Parameters of Propensity Score for LPS Matched Sample Using the Algorithm from Chapter 13

Variable

Est (s. e.) t-Stat

Intercept

0.03 (0.05) 0.63

Linear terms sex lmotage ses lpbc420 psydrug

-0.04 0.03
-0.04 -0.61
0.05

(0.10) -0.38 (0.06) 0.45 (0.05) -0.78 (0.29) -2.09 (0.15) 0.32

Second-order terms lpbc420 × lpbc420 0.43 (0.14) 3.07

Table 15.5. Estimated Parameters of Propensity Score for Mahalanobis Matched Sample for Barbituate Data Using Algorithm from Chapter 13

Variable

EST (s. e.) t-Stat

Intercept

0.03 (0.06) 0.49

Linear terms sex lmotage ses lpbc420 psydrug chemo mbirth motwt lgest

0.13 0.27 -0.12 1.17 -2.98 -1.04 -1.68 -0.11 -0.69

(0.12) 1.05 (0.13) 2.12 (0.08) -1.49 (0.28) 4.21 (0.67) -4.46 (0.21) -5.06 (0.53) -3.17 (0.05) -2.15 (0.35) -1.98

Second-order terms

lpbc420× lpbc420 0.61

ses×ses

0.20

lgest×lgest

0.08

lpbc420×psydrug 1.15

lmotage×lpbc420 -0.24

lmotage×motwt

1.12

(0.17) 3.52 (0.06) 3.51 (0.03) 2.40 (0.49) 2.35 (0.12) -2.09 (0.63) 1.77

differences in the lps less than 0.03, with the remainder spread out over the range 0.02 to 0.7.
To gain insight into the differences between propensity score and Mahalanobis matching, it is useful to consider the columns in Table 15.3 corresponding to the two matching

354

Matching to Improve Balance in Covariate Distributions

0.35

0.3

0.25

Density

0.2

0.15

0.1

0.05

0

-20

-15

-10

-5

0

5

10

Linearized Propensity Score

Figure 15.3a. Histogram-based estimate of the distribution of linearized propensity score after lps matching for the treatment group, for the Reinisch barbituate data

0.35

0.3

0.25

Density

0.2

0.15

0.1

0.05

0

-20

-15

-10

-5

0

5

10

Linearized Propensity Score

Figure 15.3b. Histogram-based estimate of the distribution of linearized propensity score after lps matching for the control group, for the Reinisch barbituate data

methods in more detail. For most of the covariates for which there is a substantial difference in average values after matching, Mahalanobis matching leads to less balance than propensity score matching. For example, for lpbc420 (a pregnancy complication index), the normalized difference in averages is 0.59 for Mahalobis matching and 0.10 for lps matching. For lmotage (logarithm of mother's age), the numbers are 0.09 and -0.02 for Mahalanobis and lps matching respectively. It may seem surprising that propensity score matching, which considers only one particular linear combination of the covariates for determining the match, does better in terms of generating balance

15.6 Creating Matched Samples for the Barbituate Data

355

0.35

0.3

0.25

Density

0.2

0.15

0.01

0.05

0

-20

-15

-10

-5

0

5

10

Linearized Propensity Score

Figure 15.4a. Histogram-based estimate of the distribution of linearized propensity score after Mahalanobis matching for the treatment group, for the Reinisch barbituate data

0.03

0.025

0.02

Density

0.015

0.01

0.005

0

-20

-15

-10

-5

0

5

10

Linearized Propensity Score

Figure 15.4b. Histogram-based estimate of the distribution of linearized propensity score after Mahalanobis matching for the control group, for the Reinisch barbituate data

on the individual covariates than Mahalanobis matching, which directly focuses on all the covariates. However, part of this comparison is misleading. Mahalanobis matching is designed to minimize differences in all covariates within matches, not to minimize differences in average covariates across all matched pairs. Suppose we look, for each covariate separately, at the square root of the average of the squares of within-pair differences, normalized by the square root of the sum of the squares of the sample standard deviations:

356
14

Matching to Improve Balance in Covariate Distributions

12

10

8

6

4

2

0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Absolute Difference in Linearized Propensity Score
Figure 15.5. Histogram-based estimate of the distribution of the absolute difference in linearized propensity score for matches, for the Reinisch barbituate data

k=

1 Nt

Nt i=1

Xi,k - Xmi,k

2
, k = 1, . . . , K.

s2c,k + s2t,k

By this measure, Mahalanobis matching does considerably better than propensity score matching. For example, for lmotage, the two measures are 0.42 and 0.97 for Mahalanobis and lps matching respectively. Only for the pregnancy complication index, lpbc420, which given its importance in the propensity score, is essentially what propensity score matching is matching on in this data set, do we see a different comparison, with the numbers equal to 0.85 and 0.59 for Mahalanobis and propensity score matching, respectively. In general, propensity score matching leads to better overall balance, but Mahalanobis matching leads to smaller average differences within the matches.
It is also interesting to look at specific matches. In Table 15.6 the covariate values for three matches are presented, for both Mahalanobis matching and propensity score matching: first, the match for the treated unit with the largest value for the propensity score (0.97); second, the match for the treated unit with the median value of the propensity score (0.36); and, finally, the match for the treated unit with the smallest value of the propensity score (0.00). When we inspect the covariate values for the match for the treated unit with the largest value of the estimated propensity score, we see that propensity score matching leads to a good match in terms of lpbc420, the covariate that enters most prominently in the propensity score. Mahalanobis matching leads to a considerably worse match in terms of this covariate. In comparison, Mahalanobis matching leads to better match quality for some of the covariates that do not enter in the propensity score, such as cage.
Because the goal in the current chapter is not to create matches for specific units but to create a sample with substantial overlap in covariate distributions, matching on the lps is

15.6 Creating Matched Samples for the Barbituate Data

357

Table 15.6. Three Treated Units and Their Matches Based on Mahalanobis and Linearized Propensity Score Matching Algorithm, for the Reinisch Barbituate Data

Covariate Obs 1 (Max Pscore) Obs 373 (Med Pscore) Obs 745 (Min Pscore)

Treated

Match

Treated

Match

Treated

Match

Maha LPS

Maha LPS

Maha LPS

sex antih hormone chemo cage cigar lgest lmotage lpbc415 lpbc420 motht motwt mbirth psydrug respir ses sib

0.00 1.00 0.00 0.00 -0.68 1.00 5.00 0.27 0.26 2.50 2.00 6.00 0.00 1.00 0.00 0.48 1.00

0.00 0.00 1.00 0.00 0.00 0.00 0.00 1.00 -0.88 -1.23 1.00 1.00 4.00 5.00 0.57 0.57 0.26 0.26 1.41 2.45 3.00 3.00 4.00 4.00 0.00 0.00 1.00 0.00 0.00 1.00 1.29 -1.15 0.00 1.00

1.00 0.00 0.00 0.00 -1.40 0.00 6.00 1.64 0.74 1.21 4.00 4.00 0.00 0.00 0.00 0.48 0.00

1.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 -1.34 0.27 0.00 0.00 6.00 5.00 1.85 -1.71 0.44 0.93 0.85 0.98 3.00 4.00 4.00 4.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 -1.15 0.00 1.00

1.00 0.00 0.00 0.00 -1.00 1.00 7.00 -0.82 -0.26 -0.20 4.00 5.00 0.00 0.00 0.00 -0.34 0.00

1.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 -1.47 -0.84 1.00 1.00 7.00 2.00 -0.82 -0.09 -0.26 0.74 0.06 -0.35 4.00 4.00 4.00 4.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.34 -1.15 0.00 0.00

pscore lps

0.97 0.40 0.94 0.36 0.24 0.33 0.00 0.01 0.00 3.48 -0.40 2.83 -0.59 -1.14 -0.70 -5.59 -4.68 -5.59

Note: Treated observations with the largest value for the estimated propensity score, the median value for the propensity score, and the smallest value for the propensity score.

Table 15.7. Five Worst Matches for LPS Matching in Terms of LPS Distance, for the Reinisch Barbituate Data

P-Score

LPS

Dif in LPS

Treated Control Treated Control

0.79

0.66 1.34 0.64

0.69

0.79

0.66 1.34 0.67

0.68

0.81

0.69 1.45 0.79

0.66

0.81

0.69 1.45 0.80

0.65

0.97

0.94 3.48 2.83

0.64

clearly preferable to matching on all covariates through Mahalanobis matching, and we recommend it for this purpose, when there are more than a few covariates being matched.
Next, let us inspect, for the propensity score matched sample, the quality of the worst matches (in terms of the distance between the treated units and their matches). Table 15.7 presents, for the five worst matches, the value of the propensity score for the treated

358

Matching to Improve Balance in Covariate Distributions

unit and the control unit, the lps, and the difference in lps. Even for these poorest of the matches, the discrepancies are modest. It is interesting to note that the worst matches are not simply for the units with the largest value of the propensity score. In this case there is little reason to discard any of the matches because of their poor quality.

15.7 CONCLUSION

In this chapter we discuss one approach to the design phase in an analysis of observational data. In this part of the analysis we select the sample for which we subsequently attempt to estimate causal effects. We attempt to construct a sample where the covariate distributions are well balanced, motivated by the fact that lack of balance can make any subsequent analysis imprecise, as well as sensitive to minor changes in the specification of the model for the outcomes given the covariates. The methods discussed in the current chapter uses matching to create a control sample, selected from a larger donor pool of possible controls, in such a way that the covariate distribution in the matched control group is similar to the covariate distribution in the treated sample. In the application in this chapter, propensity score matching is effective in greatly reducing the imbalance between the covariate distributions, with the normalized differences between covariates reduced, from a maximum value of 1.63 in the full sample to a maximum value of 0.13 in the propensity score matched sample.
An important aspect of the analysis in this chapter is that it is entirely based on the covariate and treatment data, and never uses the outcome data. As such, it cannot intentionally introduce biases in the subsequent analyses.

NOTES

The formal results in this chapter on bias reduction for matching methods draw heavily on Rubin and Thomas (1992ab, 1996, 2000). Generalizing earlier ones in Rubin (1973ab, 1976) and Cochran and Rubin (1973), the results in the Rubin and Thomas work and extensions in Rubin and Stuart (2006) are more general than the ones reported in the current chapter, allowing for ellipsoidal distributions, of which normal distributions discussed here are a special case. For ease of exposition, we focus in the current chapter on cases with normal distributions. The chapter also borrows extensively from the discussion in Rosenbaum and Rubin (1984). See also Rubin (2006).
Gu and Rosenbaum (1993) distinguish between two goals of matching: minimizing distance between units within matched pairs and maximizing balance. In this chapter the goal of the matching is the latter: improving balance in covariate distributions between the two treatment groups.
Many applied papers use either Mahalanobis or propensity score matching methods to construct estimators. We discuss some of these methods in Chapter 18. Here, however, we focus on matching solely as a strategy to create more balanced samples rather than to create estimators. Subsequently we discuss various methods for estimating causal effects, all of which will generally be more effective in balanced samples. See also Ho, Imai, King, and Stuart (2007), Rosenbaum and Rubin (1985), and Pattanayak, Rubin, and Zell (2011).

CHAPTER 16
Trimming to Improve Balance in Covariate Distributions
16.1 INTRODUCTION
The propensity score matching approach discussed in the previous chapter was aimed primarily at settings where the focus is on estimating treatment effects for the subset of treated units. The specific plan was to select a set of controls with a joint distribution of covariates similar to that for the treated units and discard the remaining controls. In the current chapter, we discuss a different approach to improving covariate balance. Starting with observations on covariates and treatment status for a sample of units with only limited overlap in terms of covariates, we construct a subsample that has a more substantial degree of overlap. We do so by discarding some units in the treatment group and some in the control group. For the resulting trimmed sample, we focus on estimating causal effects of the treatment versus control. By trimming the sample, this method generally alters the estimand, by changing the reference population. In that sense, this method sacrifices some external validity ­ the eventual estimators are less likely to be valid for typical (e.g., average) treatment effects in the original sample. The advantage is that the internal validity may be improved because estimators for causal effects in the trimmed sample are likely to be more credible and accurate than estimators for causal effects in the original, full sample. This primacy of internal validity, at the expense of external validity, is a general theme in this book as well as in the literature on design of randomized experiments. In studies of causal effects, there is often a trade-off between internal and external validity, with typically more focus on internal validity: given a well-defined population of interest, having a credible and precise answer for a subpopulation is often considered more important than a controversial (in the sense of relying on dubious assumptions) or imprecise answer for the full (original target) population.
The key to the trimming is the propensity score, the conditional probability of receiving the treatment given the pre-treatment variables. This role emerges naturally, rather than being imposed, as a consequence of a mathematical objective function to be minimized that does not itself involve the propensity score. If, for some units, the true propensity score is exactly equal to zero or one, it follows that for such units there are no counterparts with the alternative treatment. Thus, we cannot credibly and accurately estimate the effect of the treatment for such units without relying heavily on extrapolation. In practice, we often set aside such units, acknowledging that estimates for treatment effects for such units are not credible because of the extrapolation. The practical issue is
359

360

Trimming to Improve Balance in Covariate Distributions

what to do with units with values for the estimated propensity score close, but not exactly equal, to zero or one. In this chapter we argue that, in some situations, we may still wish to put aside such units, and estimate treatment effects for the set of units with estimated propensity scores substantially away from zero or one. To provide further motivation for this approach, consider units with the true value of the propensity score equal to e(Xi) = 0. 999. Conditional on such a value for the propensity score, the probability that a unit is in the treatment group is, by definition, e(Xi) = 0. 999. Hence, among units with e(Xi) = 0. 999, there are almost 1,000 times as many treated units as control units. To estimate, say, the average effect of the treatment for such units using simple methods, we would either have to put a very large weight on the few control units with such propensity score values (and for this to even be feasible, we would obviously need a very large data set, large enough that there are in fact control units with such propensity score values), or we would need to extrapolate from control units with possibly quite different values for the propensity score. Neither using large weights nor relying on extrapolation is attractive: the first leads to a large sampling variance for the estimator, and the second one may lead to substantial bias.
In this chapter we discuss a principled and systematic way of selecting units with propensity score values away from zero and one, which involves choosing a threshold to assess whether the estimated propensity score is too close to zero or one. The criterion we use is based on the joint distribution of treatment indicators and pre-treatment variables and, importantly, does not involve data on the outcome variables, and therefore is a designstage activity. It relies on the asymptotic sampling variance of estimators for average treatment effects and leads to a covariate-and-treatment-indicator-dependent criterion for determining a threshold, denoted by , such that all units with estimated propensity score values in the intervals [0, ] and [1 - , 1] are discarded, and causal effects are estimated only for units with values for the estimated propensity score in the interval [, 1 - ]. In terms of motivating the threshold, we will take an infinite super-population perspective, where the sample at hand is viewed as a random sample from this super-population as introduced in Chapter 3, Section 3.5, and used in earlier chapters in this part of the text.
In practice one may wish to use the methods discussed in this chapter as a starting point for trimming the sample to achieve sufficient balance, in combination with scientific judgments. In our examples, however, we illustrate the methods using a rigid rule.
The chapter is organized as follows. In the next section we describe the data used in this chapter to illustrate the concepts and methods, which come from a study by Murphy and Cluff (1990) to investigate the effect of right heart catheterization on survival. In Section 16.3 we discuss, in detail, the intuition behind our approach in the context of a stylized example with a single binary covariate. In Section 16.4 we present results for the general case with multiple and multi-valued covariates. In Section 16.5 we return to the Catheterization Data to illustrate the general concepts developed in this chapter. Section 16.6 concludes.

16.2 THE RIGHT HEART CATHETERIZATION DATA
Murphy and Cluff (1990) studied the effectiveness of right heart catheterization in an observational setting, using data from the "Study to Understand Prognoses and Preferences

16.2 The Right Heart Catheterization Data

361

Table 16.1. Summary Statistics for Selected Pre-Treatment Variables, for Right Heart Catherization Data

Controls (Nc = 3,551) Treated (Nt = 2,184)

Variable Mean

(S.D.)

Mean (S.D.)

cat1 copd cat2 lung neuro aps1 meanbp1 pafi1

0.11 0.004 0.16 51 85 241

(0.32) (0.060) (0.37)
(19) (39) (117)

0.03 0.001 0.05 61 68 192

(0.16) (0.03) (0.23) (20) (34) (106)

Normalized Difference
-0.32 -0.05 -0.33
0.49 -0.44 -0.42

for Outcomes and Risks of Treatments." Right heart catheterization is a diagnostic procedure used for critically ill patients. Their study collected data on hospitalized adult patients at five medical centers in the United States. Based on information from a panel of experts, a rich set of forty-nine covariates (recoded as seventy-two pre-treatment variables) relating to the decision to perform right heart catheterization was collected, as was detailed outcome data. Connors et al. (1996) used a one-to-one propensity score matching approach to study the same data set. Detailed information about the study and the nature of the variables can be found in Murphy and Cluff (1990) and Connors et al. (1996). Connors et al. (1996) found that, based on an analysis assuming unconfounded treatment assignment, right heart catheterization appeared to lead to adverse outcomes, namely lower survival rates. This conclusion contradicted the popular perception among practitioners that right heart catheterization was beneficial to critically ill patients.
The data set from the Connors et al. (1996) study that we use in this chapter consists of observations on N = 5,735 individuals, Nt = 2,184 of them in the treatment group and the remaining Nc = 3,551 in the control group. For each individual, we observe treatment status Wi, equal to one if right heart catheterization was applied within twenty-four hours of admission, and zero otherwise; seventy-two covariates; and eventually the outcome, which is an indicator for survival at thirty days. Hirano and Imbens (2001) present a table containing summary statistics for all seventy-two covariates. In Table 16.1 we present summary statistics for some selected covariates. Note that the cat1 copd (chronic obstructive pulmonary disease) is a fairly rare condition that differs considerably in its prevalence among treated and control units. We focus on the normalized differences,

nordif =

Xt - Xc . (s2t + sc2)/2

With this many covariates, inspecting all normalized differences in means separately is cumbersome. In Figure 16.1, we instead present a histogram estimate of the distribution of the normalized differences. From this figure one can see that many of the covariates are fairly well balanced, although a number of them have substantially different distributions in the two treatment groups. For example, aps1 (Apache score) has a normalized difference of 0.49, and meanbp1 (mean blood pressure) has a normalized difference of 0.44. The mean and standard deviation of the seventy-two absolute values of the normalized differences in the full sample are 0.14 and 0.11, with 51% of the normalized

362 6

Trimming to Improve Balance in Covariate Distributions

5

4

Density

3

2

1

0

0

0.1

0.2

0.3

0.4

0.5

0.6

Normalized Differences

Figure 16.1. Histogram-based estimate of the distribution of normalized differences for full sample, for Connors RHC data

differences exceeding 0.1, and 15% exceeding 0.25. Such differences suggest that simple methods, such as regression analysis, are unlikely to lead to effective and credible adjustments for pre-treatment differences and thereby reliable estimates of treatment effects. In this case, trimming the sample by removing units with extreme values of the estimated propensity score to improve overlap should lead to more robust inferences at the subsequent analysis stage.

16.3 AN EXAMPLE WITH A SINGLE BINARY COVARIATE

To set the stage for the issues discussed in this chapter, consider an example with a
single pre-treatment variable Xi taking on two values, say, for illustrative purposes, f and m (female and male). We have a random sample of size N from an infinite superpopulation. Let N(x) be the sample size for the subsample with Xi = x, with x  {f , m}, so that N = N(f ) + N(m) is the total sample size. Also let q be the super-population share of Xi = m units, q = Esp[N(m)/N]. Let the population average treatment effect conditional on Xi = x be equal to sp(x) = Esp[Yi(1) - Yi(0)|Xi = x]. The super-population average treatment effect is

sp = Esp[Yi(1) - Yi(0)] = (1 - q) · sp(f ) + q · sp(m).

Let

Nc(x) =

(1 - Wi) and Nt(x) =

Wi,

i:Xi=x

i:Xi=x

16.3 An Example with a Single Binary Covariate

363

be the number of control and treated units with covariate value Xi = x, and let e(x) = Nt(x)/N(x) be the propensity score at x. Finally, let

Y oc bs (x)

=

1 Nc(x)

Yiobs
i:Xi=x

· (1 - Wi)

and

Y

obs t

(x)

=

1 Nt(x)

Yiobs
i:Xi=x

·

Wi,

for x = f , m be the average outcome within each of the four subpopulations defined by treatment status and covariate value. Assume, for ease of exposition, that the superpopulation variance of Yi(w) given Xi = x is  2 for all x and w.
Natural estimators for the average treatment effects for each of the two subpopulations, Xi = f , m, are the simple differences in averages by treatment status for each of the two covariate values:

^ dif(f ) = Yot bs(f ) - Ycobs(f ),

and

^ dif(m)

=

Y tobs (m)

-

Y

obs c

(m).

The sampling variances for these estimators derived from Neyman's repeated sampling perspective follow from calculations in earlier chapters. Here it is convenient to work with the approximate, asymptotic, sampling variances, the large-sample approximations to the exact variances normalized by the overall sample size N, denoted by AV(^ ) for a generic estimator ^ . Then, the asymptotic sampling variance, defined here simply as the probability limit of the sampling variance normalized by the sample size, equals:

N · V ^ dif(f ) = N ·  2 · 1 + 1 Nc(f ) Nt(f )

-

2 (1 - q)

·

e(f )

·

1 (1 -

e(f ))

=

AV

^ dif(f )

,

and

N · V ^ dif(m) = N ·  2 · 1 + 1 Nc(m) Nt(m)

2

1

- q · e(m) · (1 - e(m)) = AV

^ dif(m)

.

The natural estimator for the population average treatment effect, sp = Esp[Yi(1) - Yi(0)], is

^ strat =

N(f )

· ^ dif(f ) + N(m) · ^ dif(m).

N(f ) + N(m)

N(f ) + N(m)

Because the two estimates ^ dif(f ) and ^ dif(m) are independent, the sampling variance of the population average treatment effect is simply the weighted average of the two sampling variances:

V ^ strat =

N(f ) N(f ) + N(m)

2
· V ^ dif(m)

+

N(m) N(f ) + N(m)

2
· V ^ dif(m) .

364

Trimming to Improve Balance in Covariate Distributions

Thus, the normalized sampling variance for ^ converges to

N · V ^ strat -  2 ·

e(m)

·

q (1 -

e(m))

+

e(f

)

1-q · (1 - e(f

))

= AV(^ strat).

Let us now consider the three asymptotic sampling variances, AV(^ strat), AV(^ dif(f )), and AV(^ dif(m)). If e(f ) is close to zero or one, it is difficult to estimate sp(f ) precisely. For a given total sample size N, the asymptotic variance increases without limit as e(f )
approaches zero or one. The extreme case where e(f ) is equal to zero or one implies
that neither the estimator nor the sampling variance of the estimator exists in the sense of being finite. If e(f ) approaches zero or one, the sampling variance of ^ strat will also increase, unless q is close to one (and consequently there are few Xi = f units). However, given fixed N, the precision with which we can estimate sp(m) is not affected by e(f ). Therefore, and this is the key insight, if e(f ) is close to zero or one, the researcher may choose to put aside all the women (the Xi = f units) and focus on estimating solely the average effect for men, sp(m).
Now let us pursue this idea more formally. Consider again the three normalized asymptotic variances AV(^ strat), AV(^ dif(f )), and AV(^ dif(m)). Suppose that

e(m) e(f )

· ·

(1 (1

- -

e(m)) e(f ))



1-q 1 - 2 · q.

(16.1)

Then

AV(^ dif(f ))  AV(^ strat)  AV(^ dif(m)).

Hence, under condition (16.1), it is "easier" to estimate sp(f ) than it is to estimate either  (m) or sp. (Here, "easier" refers to the precision of these estimators.) If, on the other hand,

1

+ q

q



e(m) e(f )

· ·

(1 (1

- -

e(m)) ,
e(f ))

(16.2)

then

AV(^ dif(m))  AV(^ strat)  AV(^ dif(f )),

and then sp(m) is more precisely estimable than either sp(f ) or sp. If neither condition (16.1) nor condition (16.2) holds, and thus

1 2

- -

q q



e(m)(1 e(f )(1

- -

e(m)) e(f ))



1

+ q

q ,

(16.3)

then

AV(^ strat)  min AV(^ dif(m)), AV(^ dif(f )) .

16.3 An Example with a Single Binary Covariate

365

The general idea behind the trimming approach in this chapter is based on the estimation of average effects for a subpopulation of units with Xi  C, or

C = E[Yi(1) - Yi(0)|Xi  C],

for a subset of the covariate space, C  X. We look for an "optimal" subset C of the covariate space X where the average treatment effect is most precisely estimable. In this example with a single binary covariate, and covariate space X = {f , m}, the set of possible subsets of X is {{f , m}, {f }, {m}, }. We choose the subset C of the covariate space as

  {f } C =  {m}
{f , m}

if

e(m) e(f )

· ·

(1 (1

- -

e(m)) e(f ))

<

1-q 1-2·q

if

1

+ q

q



e(m) e(f )

· ·

(1 (1

- -

e(m)) e(f ))

otherwise.

We then discard all units with Xi / C , and thus focus on estimating

C = Esp Yi(1) - Yi(0) Xi  C ,

based solely on the subsample of units with Xi  C . In that subsample there are few units with the propensity score close to zero or one, and thus there is, in that sense, substantial overlap for all covariate values in that subsample, making estimators generally more robust to the precise specification of the models used.
Let us make two general points about the trimming approach in the context of this binary example. First, this approach largely ignores external validity, focusing exclusively on internal validity. The binary covariate example reveals what the main issues are. The key is the product of the propensity score and one minus the propensity score, e(x) · (1 - e(x)). If the propensity score for units with Xi = f is close to zero or one, we cannot estimate the average treatment effect for this subpopulation precisely. In that case, we may be able to estimate the average treatment effect for the Xi = m subpopulation more accurately than for the population as a whole, even though we might lose a substantial number of observations by discarding units with Xi = f . Similarly, if the propensity score for the Xi = m subpopulation is close to zero or one, we may still be able to estimate the average treatment effect for the Xi = f subpopulation more accurately than for the population as a whole. If neither e(f ) · (1 - e(f )) nor e(m) · (1 - e(m)) is close to zero, we can estimate the average effect for the population as a whole more accurately than for either of the two subpopulations.
A second point is that the choice of the subset C, or equivalently, the amount of trimming, is not tied to a specific estimator. Although in this example we compared the asymptotic variance of specific estimators for average treatment effects for a given subset C, in general we will compare asymptotic efficiency bounds (in other words, the asymptotic sampling variance for the "best" estimator in a certain sense) for average treatment effects for different subsets C.

366

Trimming to Improve Balance in Covariate Distributions

16.4 SELECTING A SUBSAMPLE BASED ON THE PROPENSITY SCORE

Now let us look at the general case, which allows for multi-component and continuous covariates, where we cannot simply list all subsets of the covariate space (i.e., the power set of the covariate space) and compare within-subset sampling variances, because there are infinitely many such subsets. In fact, for a given subset, we cannot even calculate the exact sampling variance the way we did for the binary covariate case. Instead we focus on the asymptotic sampling variance for the efficient estimator for the average treatment effect for each subset. Under some regularity conditions (mainly concerning smoothness of the various distributions) and as discussed in Chapter 12, the asymptotic sampling variance for the efficient estimator, ignoring any model-based adjustments, for the finite-sample average treatment effect fs, normalized by the sample size, is

AVfesff = Esp

t2(Xi) e(Xi)

+

c2(Xi) 1 - e(Xi)

.

(16.4)

Inspection of this variance bound gives some insight into the problem. If, for a substantial part of the sample, the propensity score is close to zero or one, the sampling variance bound will be relatively large. On the other hand, if the propensity score is far from zero or one for most units, the sampling variance bound will be relatively small. Dropping units for which the propensity score is close to zero or one may, therefore, improve our ability to estimate average treatment effects.
Now suppose we focus on the average treatment effect given that the covariate value X is in some subset C of the covariate space, C, defined as

C = Esp [ (Xi)|Xi  C] .

(16.5)

The asymptotic sampling variance of the efficient estimator for this average treatment effect is, with the original sample size N for the normalization,

AVefsff(C)

=

1 q(C)

· Esp

t2(Xi) + c2(Xi) e(Xi) 1 - e(Xi)

XC

,

where

(16.6)

q(C) = Prsp(Xi  C),

is the probability of the covariate being in the subset C in the super-population. If we
compare (16.4) and (16.6), there are two competing effects on the asymptotic sampling
variance. The first effect is that making the subset C smaller decreases the effective
sample size, as measured by q(C), and thus increases the asymptotic sampling variance. In fact, if the propensity score were constant e(x) = c, and the potential outcomes were homoskedastic, t2(x) = c2(x) =  2 for all x, the asymptotic sampling variance would be proportional to 1/q(C), that is, proportional to the inverse of the effective sample size. The second effect relies on variation in e(x), c2(x), and t2(x). Choosing C such that t2(x)/e(x) and c2(x)/(1 - e(x)) are relatively small lowers the asymptotic sampling

16.4 Selecting a Subsample Based on the Propensity Score

367

variance. The question now is how to balance these two effects, that is, how to minimize
Equation (16.6). If we assume homoskedasticity, V(Yi(w)|Xi = x) =  2, for all w and x, the optimal
sampling variance simplifies to

AVfesff(C)

=

2 q(C)

·

Esp

1+ 1 e(Xi) 1 - e(Xi)

Xi  C

.

(16.7)

Now we look for the optimal C, denoted by C , that is, the set C that minimizes the asymptotic sampling variance (16.7) among all subsets C of X, ignoring possible subsequent model-based adjustments. There are two possibilities. If

sup
xX

e(x)

·

1 (1 - e(x))



2

·

Esp

1 ,
e(Xi) · (1 - e(Xi))

then the optimal C is equal to the entire covariate space, C = X. Otherwise, the optimal set C has the form

C = {x  X |  e(x)  1 -  },

where the threshold  is equal to

= 1- 2

1 4

-

1 

,

where  is a solution to

1

1

 = 2 · Esp e(Xi) · (1 - e(Xi)) e(Xi) · (1 - e(Xi))   .

(16.8)

It is interesting to note that the value of  depends solely on the marginal distribution of the propensity score. In general there will be a unique solution to the equation characterizing  , (16.8), and we can simply estimate the threshold point, , for the propensity score to provide guidance about trimming.
To implement this procedure we conduct the following calculations. First we estimate the propensity score using the methods discussed in Chapter 13. Given the estimated propensity score e^(x), we check whether

max
i=1,...,N

1 e^(Xi) · (1 - e^(Xi))

2·

1 N

N i=1

1 e^(Xi) · (1 - e^(Xi)) .

(16.9)

If this inequality holds, then C^ = X. If the inequality in (16.9) does not hold, then we solve for a value of  satisfying

 N

N
1(e^(Xi)·(1-e^(Xi)))-1
i=1

=

2 N

N i=1

e^(Xi)

·

1 (1 -

e^(Xi))

·

1(e^(Xi)·(1-e^(Xi)))-1

.

(16.10)

368

Trimming to Improve Balance in Covariate Distributions

In general there will not be an exact solution for  . However, if the inequality does not hold, it is the case that for very large values of  the left-hand side of (16.10) exceeds the right-hand side. If  = mini (e^(Xi)(1 - e^(Xi))-1, then the left-hand side is smaller than the right-hand side. Hence there will be a largest value of  such that the left-hand side is smaller than the right-hand side. We focus on this value for  , denoted by ^ . Then we calculate ^ = 1/2 - 1/4 - 1/^ , and finally
C^ = x  X ^  e^(x)  1 - ^ .
We exclude units i with e^(Xi) outside C^ , and focus on balance and estimation of treatment effects for the subset of units with Xi  C^ .

16.5 THE OPTIMAL SUBSAMPLE FOR THE RIGHT HEART CATHETERIZATION DATA
We start by estimating the propensity score in the full sample. We use the two-stage selection procedure for choosing the pre-treatment variables or covariates that enter linearly and the interactions in the specification of the propensity score discussed in detail in Chapter 13. The thresholds we use for the likelihood ratio statistics are 1 for the inclusion of linear terms and 2.71 for the inclusion of interaction terms. We do not select any of the 72 covariates a priori to be included irrespective of their correlation with the treatment indicator because we assume that we have no substantive information beyond the inclusion of the 72 covariates into the set of potentially important covariates. The procedure from Chapter 13 selects 49 covariates out of the collection of 72 for inclusion in the linear part of the propensity score. The second stage leads to the inclusion of 116 interactions of these 49 covariates, out of a total of 1,225 second-order terms, for a total of 165 pre-treatment variables included in the specification of the propensity score.
Before calculating the threshold for the trimming procedure, let us inspect the distribution of the values of the estimated propensity score in the two treatment arms. Table 16.2 displays some summary statistics and some of the extreme values of the propensity score. It is clear that, although there is generally reasonable balance, there are some units without good counterparts in the other treatment group. In fact, for some control units, we estimate the propensity score to be equal to zero, and for some treated units, we estimate the propensity score to be equal to one. To eliminate systematically units with propensity score values for whom there are no good counterparts, we estimate the threshold value . Given the estimated propensity score, we find ^ = 0.0976. There are 1,336 units with estimated propensity scores less than 0.0976 (mainly control units), and 280 units with estimated propensity scores exceeding 1 - ^ = 0.9024 (mainly treated units), which leaves 4,119 units in the trimmed sample. Table 16.3 displays the subsample sizes by treatment group and propensity score value. For the trimmed sample with 4,119 units, we re-calculate the summary statistics, including the normalized differences. The results for a few selected covariates are displayed in Table 16.4. We also include the means of the covariates for units with propensity score values less than ^ and propensity score values exceeding 1 - ^ to improve our understanding of the part of the sample that is discarded. In Figure 16.2 we present a histogram of the distribution of the absolute values

16.5 The Optimal Subsample for the Right Heart Catheterization Data

369

Table 16.2. Estimated Propensity Scores for Full Sample, Connors Heart Catheterization Data

Mean 0.05 quantile 0.25 quantile 0.50 quantile 0.75 quantile 0.95 quantile
Ten smallest values 1 2 3 4 5 6 7 8 9 10
Ten largest values 10 9 8 7 6 5 4 3 2 1

Controls
0.2399 0.0057 0.0548 0.1702 0.3654 0.6963
0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000
0.9198 0.9217 0.9238 0.9253 0.9320 0.9469 0.9473 0.9473 0.9520 0.9560

Treated
0.6099 0.1455 0.4257 0.6508 0.8154 0.9532
0.0162 0.0187 0.0219 0.0231 0.0256 0.0261 0.0280 0.0301 0.0323 0.0351
0.9981 0.9991 0.9991 0.9996 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000

Table 16.3. Sample Sizes for Trimming Based on Estimated Propensity Score ( = 0.0976), Connors Right Heart Catherization Data

e^(Xi) <  ^ < e^(Xi) < 1 -  1 -  < e^(Xi) All

Controls Treated

1,282 54

2,252 1,867

17

3,551

263

2,184

All

1,336

4,119

280

5,735

370

Trimming to Improve Balance in Covariate Distributions

Table 16.4. Summary Statistics for Selected Pre-Treatment Variables for Trimmed Sample, for Connors Right Heart Catherization Data

Variable

Controls (Nc = 2, 252)

Mean

(S.D.)

Treated (Nt = 1, 867) Normalized Discarded (1,616)

Mean (S.D.) Difference e^(Xi) <  e^(Xi) > 1 - 

Mean

Mean

cat1 copd 0.05

cat2 lung 0.000

neuro

0.09

aps1

54.7

meanbp1 78.0

pafi1 221

(0.22) (0.000) (0.29) (18.8) (36.5) (111)

0.03 0.000 0.05 59.1 69.5 196

(0.16) (0.000) (0.23) (19.5) (34.0) (105)

-0.13 0.000
-0.15 0.23
-0.24 -0.23

0.22 0.010 0.28 44.1 97.6 278

0.01 0.007 0.03 75.2 52.3 151

20

18

16

14

12

Density

10

8

6

4

2

0

0

0.1

0.2

0.3

0.4

0.5

0.6

Normalized Differences

Figure 16.2. Histogram-based estimate of the distribution on normalized differences for trimmed sample, for Connors RHC data

of the normalized differences. Here one can see that the normalized differences are substantially smaller in the trimmed sample than they are in the full sample. The average and standard deviation of the absolute value of the normalized differences are 0.07 and 0.06, with only 20% exceeding 0.10, and none of the absolute values of the normalized differences exceed 0.25. For comparison, in the full sample the average and standard deviation were 0.14 and 0.11, with 51% of the normalized differences exceeding 0.1, and 15% exceeding 0.25 in absolute value.
One can also see that the discarded units tend to have relatively extreme values for some of the covariates, e.g., pafi1, or meanbp1. As a result, the trimmed sample is more likely to lead to robust and credible estimates for causal estimands. Interestingly, the value of the pre-treatment variable cat2 lung (lung cancer) is zero for all units in the trimmed sample. In the full sample there are fifteen individuals who have this condition (out of the full sample of 5,735). Only two of these fifteen (15%) are in the

16.5 The Optimal Subsample for the Right Heart Catheterization Data

371

6

5

4

Density

3

2

1

0

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Propensity Score

Figure 16.3a. Histogram-based estimate of the distribution of propensity score values for control units in full sample, for Connors RHC data

6

5

4

Density

3

2

1

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Propensity Score

Figure 16.3b. Histogram-based estimate of the distribution on propensity score values for treated units in full sample, for Connors RHC data

treatment group. Clearly it would be difficult to estimate the effect of the treatment for such individuals, and our automatic trimming procedure eliminates these individuals from the sample.
We re-estimate the propensity score on this trimmed sample, following the same procedure for selecting linear and interaction terms. Figures 16.3a and 16.3b present histogram estimates of the distributions of propensity score values for control and treated units in the full sample. Although in the original sample all units with propensity score

372 6

Trimming to Improve Balance in Covariate Distributions

5

4

Density

3

2

1

0

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Propensity Score

Figure 16.4a. Histogram-based estimate of the distribution of propensity score values for control units in trimmed sample, for Connors RHC data

6

5

4

Density

3

2

1

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Propensity Score

Figure 16.4b. Histogram-based estimate of the distribution on propensity score values for treated units in trimmed sample, for Connors RHC data

values below  = 0.0976 or above 1 - ^ = 0.9024 are dropped, after we re-estimate the propensity score on the trimmed sample, there are a few units with values of the estimated propensity score below 0.0976 and above 0.9024, but the number of such units is relatively small as one can see from Figures 16.4a and 16.4b. One could trim the sample again using the procedures discussed in this chapter if one felt the covariate distributions were not sufficiently balanced. Table 16.5 presents summary statistics for the propensity score values by treatment group for the trimmed sample.

16.6 Conclusion

373

Table 16.5. Estimated Propensity Scores for Trimmed Sample, Connors Right Heart Catherization Data

Mean 0.05 quantile 0.25 quantile 0.50 quantile 0.75 quantile 0.95 quantile
Ten smallest values 1 2 3 4 5 6 7 8 9 10
Ten largest values 10 9 8 7 6 5 4 3 2 1

Controls
0.3328 0.0634 0.1611 0.2849 0.4793 0.7307
0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0014 0.0028 0.0044 0.0048
0.9258 0.9279 0.9302 0.9330 0.9385 0.9412 0.9460 0.9466 0.9474 0.9530

Treated
0.5983 0.1906 0.4201 0.6241 0.7931 0.9234
0.0433 0.0438 0.0519 0.0600 0.0607 0.0654 0.0655 0.0688 0.0711 0.0782
0.9895 0.9905 0.9905 0.9911 0.9970 0.9976 0.9983 0.9990 1.0000 1.0000

16.6 CONCLUSION
In this chapter we discuss our second approach to the design phase in an analysis of observational data. In this second approach, we select a subsample of the full sample for which we subsequently attempt to estimate causal effects. We attempt to construct a subsample where the covariate distributions are well balanced, motivated by the fact that lack of balance can make any subsequent analysis both imprecise and sensitive to minor changes in the specifications. The approach in this chapter is to trim the sample by discarding units with propensity score values close to zero or one, with the exact threshold determined by the joint distribution of covariates and treatment status in order to optimize asymptotic precision. The automatic trimming that we propose is simply guidance and need not be followed religiously. One should use scientific judgment when

374

Trimming to Improve Balance in Covariate Distributions

applying these rules to the initial samples and to subsequent trimmed samples with a re-estimated propensity score.
An important aspect of the analysis in this chapter, shared with the matching approach in the previous chapter, is that it is entirely based on the covariate and treatment data, and never uses the outcome data. As such it cannot intentionally introduce systematic biases in the subsequent analyses for causal effects on outcomes.

NOTES
The trimming approach discussed in this chapter is based on Crump, Hotz, Imbens, and Mitnik (2009) where formal arguments for deriving the optimal threshold are provided. Previously researchers appear to have used more ad hoc methods for trimming the sample to eliminate units with values for the covariates for whom there were no suitable counterparts with the opposite treatment. Dehejia and Wahba (1999, 2002), for example, drop all control units with a value for the estimated propensity score less than the smallest value for the estimated propensity score among the treated units. Lechner (2008) suggests an alternative three-step procedure to drop units with extreme values for the estimated propensity score.
There are many discussions regarding the relative importance of internal versus external validity. See Shadish, Cook, and Campbell (2002), Imbens (2010), Deaton (2010), and Manski (2013) for recent discussions and Fisher (1935), Cochran (1965), and Rubin (1978) for older arguments.

PART IV
Regular Assignment Mechanisms: Analysis

CHAPTER 17
Subclassification on the Propensity Score
17.1 INTRODUCTION
In this chapter we discuss a method for estimating causal effects given a regular assignment mechanism, based on subclassification on the estimated propensity score. We also refer to this method as blocking or stratification.
Given the assumptions of individualistic assigment and unconfoundedness, the definition of the propensity score in Chapter 3 implies that the super-population propensity score equals the conditional probability of receiving the treatment given the observed covariates. As shown in Chapter 12, the propensity score is a member of a class of functions of the covariates, collectively called balancing scores, that share an important property: within subpopulations with the same value of a balancing score, the super-population distribution of the covariates is identical in the treated and control subpopulations. This, in turn, was shown to imply that, under the assumption of superpopulation unconfoundedness, systematic biases in comparisons of outcomes for treated and control units associated with observed covariates can be eliminated entirely by adjusting solely for differences between treated and control units on a balancing score. The practical relevance of this result stems from the fact that a balancing score may be of lower dimension than the original covariates. (By definition, the covariates themselves form a balancing score, but one that has no dimension reduction.) When a balancing score is of lower dimension than the full set of covariates, adjustments for differences in this balancing score may be easier to implement than adjusting for differences in all covariates, because it avoids high-dimensional considerations. Within the class of balancing scores, the propensity score, as well as strictly monotonic transformations of it (such as the linearized propensity score or log odds ratio), have a special place. All balancing scores b(x) satisfy the property that if for two covariate values x and x , b(x ) = b(x ), then it must be the case that e(x) = e(x ).
In this chapter we examine a leading approach to estimating causal effects that relies on blocking, subclassification, or stratification on the estimated propensity score. The sample is partitioned into subclasses (also referred to as strata or blocks), based on the values of the estimated propensity scores, so that within the subclasses, the estimated propensity scores are approximately constant. We then can estimate causal effects within each subclass as if assignment was completely at random within each subclass, using either the Neyman-based methods for
377

378

Subclassification on the Propensity Score

completely randomized experiments from Chapter 6, or the regression and model-based methods from Chapters 7 and 8. To estimate, for example, the overall average treatment effect, we could average the within-subclass estimated treatment effects, weighted by the subclass sizes. We can estimate other estimands, as discussed in more detail in Chapter 21, using, for example, the model-based methods from Chapter 8. Two important practical issues arise in the implementation of subclassification. First, the choice of the number of subclasses or blocks, and, second, the choice of boundary values for the blocks.
As just mentioned, we can combine subclassification with further adjustments for covariates, and in fact we generally recommend doing so. Such further adjustments have two objectives. First, because blocking typically does not eliminate all biases associated with differences in the covariates (because the estimated propensity score is typically not constant within the blocks), regression or model-based adjustments can further reduce bias of estimates. Second, these adjustments can improve the precision of estimators for causal effects even if the estimated propensity scores were constant within the blocks, similar to the way adjusting for covariates can improve efficiency even in completely randomized experiments. There is an important difference, though, between the covariance adjustment in this setting, within blocks defined by a balancing score, and its use in the full sample in observational studies. In the latter case there is generally concern that the implicit imputations of the missing potential outcomes through model-based methods rely, possibly heavily, on extrapolation. Here, by the construction of the strata, the differences in covariate distributions within each stratum are small, the extrapolation in the estimators is therefore more limited, and, as a result, the estimators are more robust to violations of the assumptions in model-based approaches, such as non-linearities in the conditional expectations, than these estimators would be without the stratification.
In the next section we return to the Imbens-Rubin-Sacerdote lottery data, previously used in Chapter 14, which is also used here to illustrate the concepts discussed in this chapter. After that, we return to theoretical issues. In Section 17.3 we discuss the construction of subclasses and the bias reduction properties of these methods. In Section 17.4 we implement subclassification methods with the lottery data. In Sections 17.5 and 17.6, we develop simple estimators for causal effects based on subclassification. These methods are then implemented on the lottery data in Section 17.7. In Section 17.8 we discuss the relation to Horvitz-Thompson style weighting methods. We conclude in Section 17.9.

17.2 THE IMBENS-RUBIN-SACERDOTE LOTTERY DATA
In this chapter we use the lottery data set originally collected by Imbens, Rubin, and Sacerdote (2001) that we used as one of the illustrations in Chapter 14. In Chapter 14 we assessed the overlap in covariate distributions for the lottery data and found that overlap was substantial, although there were subsets of covariate values with little overlap. The second column in Table 17.1 presents the normalized differences for the full sample. Note that the normalized difference for the covariate # Tickets (number of tickets bought in a typical week) is 0.64, suggesting that simple linear regression may not be adequate to remove reliably biases associated with differences in this covariate. To address these concerns with overlap in covariate distributions, we apply the methods discussed in Chapter 16 designed to improve the overlap by discarding units with values

17.2 The Imbens-Rubin-Sacerdote Lottery Data

379

Table 17.1. Normalized Differences in Covariates after Subclassification for the IRS Lottery Data

Variable

Full Sample

Trimmed Sample

One Horvitz-Thompson One Two Five Horvitz-Thompson

Block

Block Blocks Blocks

Year Won

-0.26

# Tickets

0.91

Age

-0.50

Male

-0.19

Education

-0.70

Work Then

0.09

Earn Year -6

-0.32

Earn Year -5

-0.28

Earn Year -4

-0.29

Earn Year -3

-0.26

Earn Year -2

-0.31

Earn Year -1

-0.23

Pos Earn Year -6 0.03

Pos Earn Year -5 0.14

Pos Earn Year -4 0.10

Pos Earn Year -3 0.13

Pos Earn Year -2 0.14

Pos Earn Year -1 0.10

0.10 0.10 -0.30 0.09 0.48 0.05 0.01 0.01 -0.01 0.05 0.06 0.11 0.16 -0.14 -0.19 -0.17 -0.17 0.17

-0.06 -0.03 0.07 0.51 0.17 0.07
-0.09 -0.03 0.05 -0.11 -0.10 -0.14 -0.51 -0.18 -0.10
0.03 0.03 0.01 -0.18 -0.10 -0.03 -0.19 -0.07 -0.00 -0.23 -0.09 -0.01 -0.18 -0.03 0.03 -0.19 -0.03 0.01 -0.17 -0.01 0.00 -0.00 -0.09 -0.09
0.10 0.01 -0.01 0.06 -0.00 -0.01 0.03 -0.04 -0.05 0.06 0.00 -0.04 -0.01 -0.04 -0.07

0.07 -0.04
0.05 -0.13 -0.01
0.00 0.06 0.09 0.06 0.10 0.09 0.06 -0.01 0.06 0.03 -0.00 0.01 -0.01

Table 17.2. Number of Units within Selected Subsamples Defined by the Estimated Propensity Score for the IRS Lottery Data

Low

Middle

High

All

e^(Xi) < 0. 0891 0. 0891  e^(Xi)  0. 9109 0. 9109 < e^(Xi)

Losers

82

172

5

259

Winners

4

151

82

237

All

86

323

87

496

of their estimated propensity scores close to zero or one. Following the specific recommendations from that chapter suggests dropping units with estimated propensity scores outside the interval [0.0891, 0.9009]. Table 17.2 presents the subsample sizes in the various propensity score strata. Out of the 496 units in the full sample, 259 losers and 237 winners, there are N = 323 with estimated propensity scores in the interval [0.0891, 0.9009], of whom Nc = 172 are losers and Nt = 151 are winners. There are eighty-six units discarded because of small estimated propensity score values (less than 0.0891), eighty-two losers and four winners, and eighty-seven units discarded because of large estimated propensity score values (larger than 0.9009), five losers and eighty-two winners. This trimmed sample with 323 units is the sample we focus on in this chapter.
The fourth column in Table 17.1 presents the normalized differences for the trimmed sample. To facilitate the comparison with the normalized differences in the full sample

380

Subclassification on the Propensity Score

Table 17.3. Estimates of Propensity Score in Trimmed Sample for the IRS Lottery Data

Covariate

Est (s. e.) t-Stat

Intercept

21.77 (0.13) 164.8

Linear terms # Tickets Education Working Then Earnings Year -1 Age Pos Earnings Year -5 Year Won Earnings Year -5

-0.08 -0.45
3.32 -0.02 -0.05
1.27 -4.84 -0.04

(0.46) (0.08) (1.95) (0.01) (0.01) (0.42) (1.53) (0.02)

-0.2 -5.7
1.7 -1.4 -3.7
3.0 -3.2 -2.1

Quadratic terms

Year Won × Year Won

0.37

Tickets Bought × Year Won

0.14

Tickets Bought × Tickets Bought -0.04

Working Then × Year Won

-0.49

(0.12) (0.06) (0.02) (0.30)

3.2 2.2 -1.8 -1.6

presented in the second column, we normalize the difference in average covariate values in both columns by the square root of the average of the sample variances in the full sample. The results in the table show that trimming substantially improves the covariate balance. For example, the normalized difference for the Year Won pre-treatment variable decreases from -0.26 in the full sample to -0.06 in the trimmed sample.
On this trimmed sample, we re-estimate the propensity score using the algorithm discussed in Chapter 13 for selecting linear and second-order terms. Starting with the four variables selected for automatic inclusion, # Tickets, Education, Working Then, and Earnings Year -1, the algorithm selects four additional linear terms, Age, Pos Earnings Year -5, Year Won, and Earnings Year -5. In addition the application of the algorithm selects four second-order terms, Year Won × Year Won, Tickets Bought × Year Won, Tickets Bought × Tickets Bought, and Working Then × Year Won. Table 17.3 presents the parameter estimates for the logistic specification choosen. This is the estimated propensity score that we use for the purpose of subclassification. Note that when we used the same algorithm on the full sample, we included more terms, eight linear terms and ten second-order terms (see Table 14.3 in Chapter 14); the substantially improved covariate balance after trimming leads to this algorithm selecting fewer terms for the specification of the propensity score.

17.3 SUBCLASSIFICATION ON THE PROPENSITY SCORE AND BIAS REDUCTION
In Chapter 12 we showed that, if the assignment mechanism is regular, to eliminate biases in comparisons between treated and control units associated with covariates, it is

17.3 Subclassification on the Propensity Score and Bias Reduction

381

sufficient to adjust for differences in the true propensity score, or, in fact, for differences in any balancing score. Here we classify or stratify units by a coarsened version of the estimated propensity score, similar to the way we used propensity score strata in Chapter 13 to evaluate the specification of the model for the propensity score. Note that the construction of strata based directly on the full set of covariates would be infeasible with a large number of covariates, because the number of subclasses that would be required to make the variation in eleven covariates within subclasses modest would generally be very large. For example, with the eighteen covariates in the lottery example, even if we defined subclasses in terms of just two (ranges of) values of each of the covariates, this would lead to an infeasibly large number of subclasses, namely 218 = 262,144, substantially larger than the original sample size of 496 (or 323 in the trimmed sample).

17.3.1 Subclassification
Following the discussion in Chapter 13, let us partition the range of the propensity score into J blocks, that is, intervals of the type [bj-1, bj), where b0 = 0 and bJ = 1 so that jJ=1[bj-1, bj) = [0, 1). We intend to analyze the data as if they arose from a stratified randomized experiment. Initially this means that we analyze units with propensity scores
within an interval (bj-1, bj] as if they have identical propensity scores. For large J, and choices for the boundary values of the intervals so that maxj=1,...,J |bj - bj-1| is at least moderately small, this may be a reasonable approximation.
Recall the notation from Chapter 13: for i = 1, . . . , N, and for j = 1, . . . , J, the binary stratum indicators Bi(j) are

Bi(j) =

1 if bj-1  e^(Xi) < bj, 0 otherwise.

(Here we ignore the possibility that there are units with e^(Xi) exactly equal to 1, in which case we would have to modify the definition for the last stratum.) To keep the notation consistent with the interpretation of the blocks as covariates, let the number of units of each treatment type in each strata be denoted by

N

N

Nc(j) = (1 - Wi) · Bi(j), Nt(j) = Wi · Bi(j), N(j) = Nc(j) + Nt(j),

i=1

i=1

for j = 1, . . . , J. Let q(j) be the fraction of units in stratum j:

q(j)

=

N(j) ,

for j = 1, . . . , J.

N

We implement the selection of boundary points using the iterative procedure introduced in Chapter 13. We start with a single block: J = 1, with boundaries equal to b0 = 0 and bj = b1 = 1. We then cycle through the following two steps. In the first step we assess the adequacy of the current number of blocks. This assessment involves calculating, for each stratum, a t-statistic for the null hypothesis that the average value

382

Subclassification on the Propensity Score

of the estimated linearized propensity score is the same for treated and control units in that stratum. The specific t-statistic used is

t (j) =

t(j) - c(j)

,

s2(j) · (1/Nc(j) + 1/Nt(j))

where

c(j)

=

1 Nc(j)

N i=1

(1 - Wi) · Bi(j) ·

^(Xi),

and

s2(j)

=

Nt(j)

+

1 Nc(j)

-

2

t(j)

=

1 Nt(j)

N i=1

Wi

· Bi(j) ·

^(Xi),

×

N
(1 - Wi) · Bi(j) ·

^(Xi) -

2N
c(j) + Wi · Bi(j) ·

^(Xi) - t(j) 2

.

i=1

i=1

In addition we find, within each of the current strata, the number of treated and control units left in each substratum after a subsequent split, at the median value of the estimated propensity score. Specifically, we check whether the number of controls and treated, Nc(j) and Nt(j),and the total number of units, N(j), in each new stratum, would be greater than some minimum. If at least one of the strata is not adequately balanced, and if splitting that stratum would lead to two new strata each with a sufficient number of units, that stratum is split and the new strata are assessed for adequacy. In order to implement this algorithm, we need to specify three parameters: the maximum acceptable t-statistic (tmax); the minimum number of treated or control units in a stratum, min (Nc(j), Nt(j))  Nmin,1; and the minimum number of units in a new stratum, N(j)  Nmin,2. Here we choose tmax = 1. 96, Nmin,1 = 3, and Nmin,2 = K + 2, where K is the number of components of the covariate vector Xi for which we want to apply further adjustments. The latter choice is motivated by the fact that we may wish to do additional modeling of potential outcome distributions, conditional on covariates, within the strata.

17.3.2 The Subclassification Estimator for the Average Treatment Effect
The first estimator for the average causal effect we consider is the simple blocking estimator. Within block j we estimate the block-specific average effect of the treatment as

^

dif(j)

=

Y

obs t

(j)

-

Y cobs (j),

where

Y

obs t

(j)

=

1 Nt(j)

N i=1

Wi · Bi(j) · Yiobs

and

Y

obs c

(j)

=

1 Nc(j)

N i=1

(1 - Wi) · Bi(j) · Yiobs.

17.3 Subclassification on the Propensity Score and Bias Reduction

383

We then estimate the overall average treatment effect by averaging these estimates over the blocks, weighted by the relative block sizes:
J
^ strat = q(j) · ^ dif(j).
j=1
Later we will modify this estimator by introducing additional adjustments based on some of the covariates, but first we explore some of the properties of this simple subclassification estimator.

17.3.3 Subclassification and Bias Reduction
To gain insights into the properties of estimators based on subclassification, we investigate here some implications for bias reduction. In this discussion we build on the theoretical analysis of the bias-reducing properties of matching presented in Chapter 15. We initially assume, but do not necessarily believe, that, in the super-population, the conditional expectations of the two potential outcomes, conditional on the covariates, are linear in the covariates, with identical slope coefficients under both treatment conditions:

Esp [Yi(w) |Xi = x ] =  + sp · w +  x,

for w = 0, 1. As in most of Part III of the text, the expectation here is taken over the distribution induced by random sampling from an infinite super-population. As before, we do not believe this linearity assumption is necessarily a good approximation (in fact, if the assumption were true, one could simply remove all biases associated with the covariates by simple covariance adjustment), but linearity provides a useful approximation to assess the bias-reducing properties of subclassification.
Now consider estimating the average effect of the treatment on the full sample. Let Xc, Xt, and X be the average values of the covariates in the control, treated, and full samples respectively,

Xc

=

1 c

Xi,
i:Wi=0

Xt

=

1 t

Xi,
i:Wi=1

and

X

=

1 N

N
Xi
i=1

=

Nc N

· Xc +

Nt N

· Xt.

In addition, let Xc(j), Xt(j), and X(j) denote the analogous covariate averages within stratum j,

Xc(j)

=

1 Nc(j)

N i=1

(1 - Wi) · Bi(j) · Xi,

Xt(j)

=

1 Nt(j)

N i=1

Wi

·

Bi(j)

·

Xi,

and

X(j) = 1 N(j)

N

Bi(j) · Xi,

i=1

for j = 1, . . . , J. First we consider the estimator with no adjustment for differences in the covariates at all, where we simply estimate the average treatment in the full sample,

384

Subclassification on the Propensity Score

without subclassification, by differencing the average outcomes for treated and control units. Alternatively, this can be viewed as the subclassification estimator with only a single stratum. We find

^ dif

=

Y

obs t

-

Y

obs c

=

1 Nt

Yiobs
i:Wi=1

-

1 Nc

Yiobs.
i:Wi=0

The bias of ^ dif, conditional on the covariates,

Esp

^ dif X

-

1 N

N i=1

Esp[Yi(1) - Yi(0)|Xi],

arises from two sources. First, we estimate the average treatment potential outcomes for the treatment for the Nc control units, in expectation equal to E[Yi(1)|Wi = 0] by Yot bs; this estimator is equal to the average outcome for the Nt treated units, which, in expectation, equals E[Yi(1)|Wi = 1]. The second source of bias of ^ dif arises from the difference
between the expected control potential outcome for the Nt treated units, E[Yi(0)|Wi = 1], and the expected value of its estimator, Ycobs, which equals the expectation of the control outcomes for the control units, E[Yi(0)|Wi = 0]. Hence the conditional bias of ^ dif is,
under the linear model specification for the regression function, equal to:

E

^ dif - fs X, W

=

Nc N

·

(E [ Yi(1)| Wi

=

1, Xi]

-

E [ Yi(1)| Wi

=

0, Xi])

-

Nt N

·

(E [ Yi(0)|

Wi

=

1,

Xi]

-

E

[ Yi(0)|

Wi

=

0,

Xi])

= Nc · N

Xt - Xc

 - Nt · N

Xc - Xt



= Xt - Xc .

Now consider estimating the average treatment fs by the subclassification estimator ^ strat with J strata, with no further covariance adjustment within the strata (i.e.,
subclasses). In stratum j the bias is, using the same argument as for the overall bias,

E ^ dif(j) - fs(j) X, W = Xt(j) - Xc(j) .

The overall bias for the subclassification estimator is the weighted average of the withinblock biases,





J

E ^ strat - fs|X, W =  q(j) · Xt(j) - Xc(j)  .

j=1

17.4 Subclassification and the Lottery Data

385

As a result of the subclassification, the bias that can be attributed to differences in Xi,k, the kth element of the covariate vector Xi, is reduced, under our simple linear model,

from





J
Xt,k(j) - Xc,k(j) · k to  q(j) · Xt,k(j) - Xc,k(j)  · k,

j=1

where Xc,k(j) and Xt,k(j) are the kth elements of Xc(j) and Xt(j) respectively. Thus, the bias attributable to the kth covariate is reduced by a factor

J
k = q(j) · Xt,k(j) - Xc,k(j)
j=1

Xt,k - Xc,k .

(17.1)

We can calculate these ratios k for any particular subclassification, for each covariate, to assess the bias reduction from the subclassification in a particular application.

17.4 SUBCLASSIFICATION AND THE LOTTERY DATA

Here we return to the lottery data and determine the number of subclasses (or strata) according to the algorithm described in Section 17.3. We use the cutoff values tmax = 1. 96, and Nmin,1 = 3, and Nmin,2 = K + 2, where K, the number of covariates possibly used for model-based adjustments, is here 18, so that Nmin,2 = 20. These choices for the tuning parameters lead to five blocks. The details for the five blocks, including the cutoff values for the propensity score, the number of units by treatment status in each block, and the t-statistics for the null hypothesis of a zero difference in average propensity scores between treated and control units in the block, are presented in Table 17.4. For example, the first stratum contains 67 control and 13 treated units, with the propensity scores ranging from 0.03 to 0.24. The t-statistic for the null hypothesis of no difference in average linearized propensity score values between the two treatment groups within this stratum is -0.1, so there is actually very little difference in average linearized propensity scores between the two groups within the first block. For comparison purposes Table 17.5 presents results based on only two blocks, where the blocks' boundary is the median value of the propensity score, 0.44. Here the treatment and control groups are substantially less balanced.
Next, we investigate for these two specifications of the blocks the extent of the bias reduction based on a simple linear specification of the regression function. Columns two and four of Table 17.1 present, for both the full and trimmed samples, the average difference in covariates, Xt,k - Xc,k, normalized by the square root of the average of the sample variances for treated and controls, (sc2,k + s2t,k)/2 (with the latter calculated on the full sample for the second column and on the selected sample for the fourth column). For the trimmed sample, based on the subclassifications with two or five subclasses, we also present, in Columns five and six,

Nor Dif = J q(j) · Xt,k(j) - Xc,k(j)

j=1

s2c,k + st2,k /2

386

Subclassification on the Propensity Score

Table 17.4. Final Subclassification for the IRS Lottery Data

Subclass Min P-Score Max P-Score # Controls # Treated t-Stat

1

0.03

0.24

67

13 -0.1

2

0.24

0.32

32

8

0.9

3

0.32

0.44

24

17

1.7

4

0.44

0.69

34

47

2.0

5

0.69

0.99

15

66

1.6

Table 17.5. Subclassification with Two Subclasses, Split at Median Propensity Score for the IRS Lottery Data

Subclass Min P-Score Max P-Score # Controls # Treated t-Stat

1

0.03

0.44

123

38

2.8

2

0.44

0.99

49

113

3.8

(normalized by the same function of the standard deviations in the trimmed sample so that the normalized differences are directly comparable to those in Column four). The ratios of the fifth and sixth columns to the fourth column show how much the subclassifications reduce the bias arising from linear effects of the covariates in the trimmed sample, that is, the k in Equation (17.1). We see that the covariates exhibiting substantial differences between the treated and control groups in the full sample show much smaller differences after trimming, and even smaller differences after subsequent subclassifications. For example, consider the covariate # tickets. In the full sample there is a normalized difference of 0.64, whereas trimming the sample reduces that to 0.34. Subclassification with only two blocks reduces that further to 0.12, and five subclasses reduces this to 0.04, or about 6% of the original 0.64. For the covariate with the second biggest normalized difference in the full sample, education, which exhibited a normalized difference of 50% in the full sample, we similarly get a reduction to about 7% in the trimmed sample. For covariates with small initial differences, the reduction is not as dramatic, but with five subclasses, the largest of the normalized differences is 0.10 (for male). Subclassification has clearly been effective in removing most of the mean differences for all eighteen covariates in this data set.

17.5 ESTIMATION BASED ON SUBCLASSIFICATION WITH ADDITIONAL BIAS REDUCTION
The simple estimator for the average treatment effect based on subclassification is
J
^ strat = q(j) · ^ dif(j),
j=1

17.5 Estimation Based on Subclassification with Additional Bias Reduction

387

where ^ dif(j) = Ytobs(j) - Ycobs(j). This simple estimator is not necessarily very attractive.

Even

when

the

propensity

score

is

known,

the

differences

Y

ot bs(j)

-

Y

obs c

(j)

will

likely

be

biased for the average treatment effects within the blocks because the propensity score

is only approximately constant within the blocks. We therefore may wish to attempt to

reduce further any remaining bias by modifying the basic estimator. Two leading alter-

natives are to use regression (covariance) adjustment or model-based imputation within

the blocks, which raises an important issue regarding the choice of blocks. With many

blocks, typically some will contain relatively few units, and so it may be difficult to esti-

mate even simple linear regression functions precisely within each block. Therefore, if

one intends to combine subclassification with regression or model-based adjustment, one

may wish to ensure a relatively large number of units in each stratum, or appropriately

smooth models across blocks, or both.

Here we further discuss the least squares regression approach. It is useful to start by

re-interpreting the within-block difference in average treatment and control outcomes ^ dif(j) as the least squares estimator of the average causal effect in stratum j,  (j), using

the regression function

Yiobs = (j) +  (j) · Wi + i.

(17.2)

We estimate the parameters of this regression function using only the N(j) observations in the jth stratum (i.e., the jth block). We can then generalize this estimator to allow for
covariates by specifying within block j the regression function

Yiobs = (j) +  (j) · Wi + Xi(j) + i,

(17.3)

again using only the N(j) observations in block j. If the balancing on the estimated propensity score created perfect expected balance on the true propensity score, the population correlation between the covariates and the treatment indicator within a block would be zero. In that case the inclusion of the covariates in this regression is intended to improve precision (actual and estimated), the same way using covariates in the analysis of a completely randomized experiment can improve precision ­ even though on average the estimator based on (17.2) would be the same as the estimator based on (17.3). When using an estimated propensity score, however, does not eliminate all correlations within blocks between treatment indicator and covariates, the role of the regression adjustment in (17.3) is threefold. In addition to improving actual and estimated precision, it also can help to reduce any remaining conditional bias arising from imbalances in covariate distributions between treated and controls within the blocks. It is important to note that conceptually the use of regression adjustment is quite different here from using regression methods on the full sample. Within each block there is less concern about using the regression function to extrapolate out of sample, because the blocking has already ensured that the covariate distributions within blocks are similar. In practice the use of regression methods at this stage is more like its use in randomized experiments where the similarity of the covariate distributions greatly reduces the sensitivity to the specification of the regression function.

388

Subclassification on the Propensity Score

Mechanically the analysis now estimates the average treatment effects within the blocks using linear regression:

^ (j), ^ adj(j), ^ (j)

N

= arg min
, ,

Bi(j) ·

Yiobs -  -  · Wi - Xi

2
,

i=1

(17.4)

based on the N(j) units within stratum j. Within each block, the procedure is the same
as that for analyzing completely randomized experiments with regression adjustment discussed in Chapter 6. These within-block least squares estimates, ^ adj(j), are then averaged to obtain an estimator for the overall average treatment effect,

J
^ strat,adj = q(j) · ^ adj(j),
j=1

with the stratum weights still equal to the stratum shares q(j) = N(j)/N.

17.6 NEYMANIAN INFERENCE

For the simple subclassification estimator with no further covariance adjustment, we can directly apply the Neyman analysis for completely randomized experiments. Using the results from Chapter 9 on Neyman's repeated sampling perspective, applied in the context of stratified randomized experiments, the sampling variance of ^ dif(j) is

V ^ dif(j) = Sc(j)2 + St2(j) - Sct(j)2 , Nc(j) Nt(j) N(j)

where,

Sc(j)2

=

1 N(j) - 1

N i=1

Bi(j) ·

Yi(0) - Y(0, j) 2 ,

St(j)2

=

1 N(j) -

1

N

Bi(j) ·

Yi(1) - Y(1, j) 2 ,

i=1

Sct(j)2

=

N

1 -1

N i=1

Bi(j) · (Yi(1) - Yi(0) -  (j))2 ,

and

Y(w, j)

=

1 N(j)

N i=1

Bi(j) · Yi(w).

17.6 Neymanian Inference

389

To obtain a statistically conservative estimate of the sampling variance V(^ dif(j)), we substitute

sc(j)2

=

1 Nc(j) - 1

N i=1

(1 - Wi) · Bi(j) ·

Yiobs

-

Y

obs c

(j)

2
,

and

st(j)2

=

1 Nt(j) - 1

N i=1

Wi

· Bi(j) ·

Yiobs - Yot bs(j)

2
,

for Sc(j)2 and St(j)2 respectively, and sct(j)2 = 0 for Sct(j)2 to obtain the following estimator,

V^

^ dif(j)

1

= Nc(j)

·

(Nc(j)

-

1)

i:Wi=0

Bi(j)

·

Yiobs - Ycobs(j) 2

+

1 Nt(j)(Nt(j)

-

1)

i:Wi=1

Bi(j)

·

Yiobs

-

Y

obs t

(j)

2
.

Because, conditional on X, the within-stratum estimator ^ dif(j) is independent of ^ dif(j )

when j = j , we can estimate the sampling variance of ^ strat =

J j=1

q(j)

·

^

(j)

by

adding

the within-block estimated sampling variances, multiplied by the square of the block

proportions:

J

J

V^ (^ strat) = V^ (^ dif(j)) · q(j)2 = V^ (^ dif(j)) ·

N(j) 2 .

j=1

j=1

N

In practice, however, we typically do further covariance adjustment to reduce the remaining bias. Here we focus on the specific estimator discussed in the previous subsection, where we use linear regression within the blocks, with identical slopes in the treatment and control subsamples, because of possibly small block sizes Nc,j and Nt,j. We use the standard robust estimated sampling variance for ols estimators, robust to general heteroskedasticity. Let ^ (j), ^ adj(j), ^ (j) be the ordinary least squares estimates
defined in Equation (17.4). Then define the matrices ^ and ^ as



^ (j) =

1 N(j)

N
Bi(j) 
i=1

1 Wi Xi

Wi Wi Wi · Xi

 Xi Wi · Xi  , Xi · Xi

and

^ (j)

=

1 N(j)

N i=1

Bi(j)

Yi - ^ (j) - ^ adj(j)Wi - ^ (j) Xi



2·

1 Wi

Xi

Wi Wi Wi · Xi

 Xi Wi · Xi  . Xi · Xi

390

Subclassification on the Propensity Score

Then the robust estimator for the sampling variance of ^ adj(j) is V^ (^ adj(j)), the natural generalization of the Neyman sampling variance estimator, is

V^ ^ adj(j) = 1 ^ (j) ^ (j)-1 ^ (j) -1 ,

N(j)

(2,2)

the (2, 2) element of the (K +2)×(K +2) dimensional matrix

^ (j) ^ (j)-1 ^ (j)

-1
/N(j).

We then combine the within-block variances the same way we did before:

J
V^ ^ strat,adj = V^ ^jadj · q(j)2,
j=1

(17.5)

which is the estimated variance we use in the calculations in the next section.
If we are interested in the average treatment effect for the treated subsample, we do not need to modify the within-block estimates ^ adj(j) or estimated sampling variances V^ (^ adj(j)). Because we analyze the data within the blocks as if assignment is completely random, the average effect for the subsample of treated units within the block is identi-
cal to the average effect for all units within the block. In order to estimate the average
effect for the treated for the entire sample, however, we do modify the block weights to
reflect the proportions of treated units in the different blocks. Instead of using the sample proportions q(j) = N(j)/N, the appropriate weights are now equal to the proportion of treated units in each block, Nt(j)/Nt, leading to

^tstrat,adj

=

J j=1

^ adj(j) ·

Nt(j) . Nt

Similarly for the estimated sampling variance, we sum the within-block estimated sampling variances, multiplied by the square of the block proportions of treated:

V^ ^tstrat,adj

J
= V^ ^ adj(j) ·
j=1

Nt(j)

2
.

Nt

17.7 AVERAGE TREATMENT EFFECTS FOR THE LOTTERY DATA
Now let us return to the lottery data. The algorithm for choosing the number of blocks led to five blocks. Within each of these five blocks we estimate the average treatment effect either (i) using no further adjustment, (ii) using linear regression with four covariates (the same four covariates that are always included in the specification of the propensity score, # Tickets, Education, Working Then, and Earnings Year -1, based on substantive arguments), or (iii) using linear regression with the full set of eighteen covariates.
Table 17.6 presents results for the parameter estimates from the least squares regression for the five blocks with no covariates and with the limited set of four covariates. Although the parameter estimates are of only limited interest here, we note that we see

17.7 Average Treatment Effects for the Lottery Data

391

Table 17.6. Independent Least Squares Regressions within Blocks, with Common Slope Coefficients for Treated and Controls within Blocks for the IRS Lottery Data

Covariates

Block 1 (N = 80)

Block 2 (N = 40)

Block 3 (N = 41)

Block 4 (N = 81)

Block 5 (N = 81)

Est (s. e.) Est (s. e.) Est (s. e.) Est (s. e.) Est (s. e.)

No covariates Intercept Treatment

20.02 (2.25) 12.70 (2.67) 15.59 (3.07) 19.69 (2.76) 12.75 (3.26) -10.82 (4.70) 2.07 (5.10) -1.17 (4.97) -9.43 (3.23) -2.89 (3.59)

Limited covariates

Intercept

-20.04 (10.66) 4.47

Treatment

-6.21 (4.01) -6.51

# Tickets

-3.48 (1.39) 1.17

Education

2.03 (0.87) -0.37

Work Then

-2.66 (2.96) -0.51

Earn Year -1 0.84 (0.06) 0.83

(9.80) -9.91 (10.87) -8.65 (3.86) -4.81 (3.87) -5.88 (1.26) 1.85 (1.24) -0.48 (0.81) 0.48 (0.93) 1.17 (1.84) 5.98 (4.35) 1.16 (0.09) 0.60 (0.15) 0.76

(5.58) -6.70 (1.82) -2.56 (0.34) -0.20 (0.49) 0.59 (2.18) 5.30 (0.07) 0.62

(5.21) (2.39) (0.37) (0.42) (2.52) (0.10)

Table 17.7. Estimated Average Treatment Effects with Final Subclassification for the IRS Lottery Data (regression estimates as in Table 17.6)

Covariates

Full Sample Selected Sample Selected Sample Selected Sample

1 Block

1 Block

2 Blocks

5 Blocks

Est (s. e.) Est (s. e.) Est (s. e.) Est (s. e.)

None

-6.2 (1.4) -6.6 (1.7) -6.0 (1.9) -5.7 (2.0)

# Tickets, Education, Work Then, Earn Year-1-2.8 (0.9) -4.0 (1.1) -5.6 (1.2) -5.1 (1.2)

All

-5.1 (1.0) -5.3 (1.1) -6.4 (1.1) -5.7 (1.1)

some evidence that the covariates do affect the outcomes and also that there is sufficient difference in the covariate distributions within the blocks that the adjustment alters the estimates of the effect of the treatment within the blocks.
Table 17.7 presents the estimates of the overall treatment effect on average annual post-lottery earnings based on the full sample, the trimmed sample with no subclassification, the trimmed sample with two blocks, and the trimmed sample with five blocks as selected by the algorithm. In each case, we present the estimates without covariance adjustment, covariance adjustment with the limited set of four covariates, and covariance adjustment based on the full set of eighteen covariates. The key observation is that both trimming and subclassification greatly reduce the sensitivity to the inclusion of covariates in the regression specification. In the full sample, the estimates range from -6.2 to -2.8 (in terms of thousands of dollars) in reduced labor earnings as a result of winning the lottery, a range of 3.4. In the trimmed sample, the estimates range from -6.6 to -4.0, a range of 2.6. In the trimmed sample with two blocks the range is only 0.8, and with five blocks, the range is down to 0.6. The conclusion is that, at least for this data set,

392

Subclassification on the Propensity Score

trimming and subclassification greatly reduce the sensitivity to the specific least squares regression method used and thus lead to more credible estimates of causal effects.

17.8 WEIGHTING ESTIMATORS AND SUBCLASSIFICATION
There is an alternative way to use the propensity score that is, at first sight, quite different from subclassification. Closer inspection, however, will reveal a close conceptual connection. In this approach, related to the work by Horvitz and Thompson (1952) in survey research, the inverse of the estimated propensity score is used to weight the units in order to eliminate biases associated with differences in observed covariates. We discuss this approach to estimation in this section partly because understanding it provides additional insight into the properties and benefits of our preferred method of subclassification.

17.8.1 Weighting Estimators
The Horvitz-Thompson estimator exploits the following two equalities, which follow from super-population unconfoundedness:

E Wi · Yiobs e(Xi)

= Esp [Yi(1)]

and

E

(1 - Wi) · Yiobs 1 - e(Xi)

= Esp [Yi(0)] .

(17.6)

These inequalities can be derived as follows. Because Yiobs is Yi(1) when Wi = 1, it follows that

E Wi · Yiobs = E Wi · Yi(1) .

e(Xi)

e(Xi)

By iterated expectations, we can write this as

E

Wi · Yi(1) e(Xi)

=E E

Wi · Yi(1) e(Xi)

Xi

.

By super-population unconfoundedness Wi is independent of Yi(1) conditional on Xi, so that the expectation of the product Wi · Yi(1) given Xi is the product of the conditional expectations,

E

Wi · Yi(1) e(Xi)

Xi

= EW [ Wi| Xi] · Esp [ Yi(1)| Xi] = e(Xi) · Esp [ Yi(1)| Xi]

e(Xi)

e(Xi)

= Esp [ Yi(1)| Xi] ,

and thus

E

Wi · Yi(1) e(Xi)

= Esp Esp [ Yi(1)| Xi] = Esp [Yi(1)] .

The same argument leads to the second equality in (17.6) for the average control potential outcome.

17.8 Weighting Estimators and Subclassification

393

The two equalities in (17.6) suggest estimating E[Yi(1)] and E[Yi(0)] as

Esp [Yi(1)] =

1 N

N i=1

Wi · Yiobs e(Xi)

and

Esp [Yi(0)] =

1 N

N i=1

(1

- Wi) · Yiobs 1 - e(Xi)

,

and thus estimating the average treatment effect sp = Esp [Yi(1) - Yi(0)] as a HorvitzThompson estimator,

~ ht = 1 N N
i=1

Wi · Yiobs e(Xi)

-

(1 - Wi) · Yiobs 1 - e(Xi)

=1 N N
i=1

(Wi - e(Xi)) · Yiobs e(Xi) · (1 - e(Xi))

.

(17.7)

In practice we rarely know the propensity score, so we rarely can use the estimator in (17.7) directly. Instead we can weight using the estimated propensity score e^(Xi), and use the estimator

^ ht

=

N i=1

Wi · Yiobs e^(Xi)

N i=1

Wi e^(Xi)

-

N i=1

(1 - Wi) · Yiobs 1 - e^(Xi)

N i=1

1 - Wi 1 - e^(Xi

)

.

(17.8)

(Normalizing the weights to one in finite samples rather than merely in expectation typically improves the mean-squared-error properties of the estimator.) The basic Horvitz-Thompson estimator can be modified easily to incorporate covariates. For this purpose, it is useful to write the weighting estimator as a weighted regression estimator. Consider the regression function

Yiobs =  +  · Wi + i,

estimated by weighted least squares with estimated weights ^ hi t, where

^ iht

=

1 (1 - e^(Xi))1-Wi

· e(Xi)Wi

=

1 1-e^(Xi)

if Wi = 0,

1 e^(Xi)

if Wi = 1.

This weighted regression estimator for  is identical to ^ht as defined in (17.8). With this weighted regression version, it is straightforward to include covariates. Instead of estimating the regression function with only an intercept and an indicator for the treatment, one can estimate a regression function that includes additional covariates,

Yiobs =  +  · Wi + Xi + i,

using the same weights ht,i. The weighted regression estimator is consistent for fs as long as either the specification of the propensity score is correct, or the specification of the regression function is correct, a property referred to as "double-robustness," although it is not necessarily robust in the standard usage of the term "robustness."

394

Subclassification on the Propensity Score

It is useful to see how this Horvitz-Thompson estimator relates to the subclassification estimator. The basic subclassification estimator, with no further adjustment for covariates, has the form

J

J

^ strat = q(j) · ^ dif(j) = q(j) · Yt(j) - Yc(j) ,

j=1

j=1

which can be written as

^ strat

=

1 N

N i=1

Wi · Yiobs

· i -

1 N

N
(1 - Wi) · Yiobs
i=1

· istrat,

where the weights sitrat satisfy

J
istrat = Bi(j) ·
j=1

1 - Wi Nc(j)/N(j)

+

Wi Nt(j)/N(j)

=

J j=1

Bi(j)

·

N(j) Nc(j)

J j=1

Bi(j)

·

N(j) Nt (j)

if Wi = 0, if Wi = 1.

Thus the basic subclassification estimator can be interpreted as a weighting estimator

where the weights are based on the block-based coarsened propensity score. Instead

of using the original estimator for the propensity score, e^(Xi), the blocking estimator implicitly uses as an estimate of the propensity score the fraction of treated units within

the propensity score stratum to which the unit belongs:

e~(Xi)

=

J j=1

Bi(j)

·

Nt(j) . N(j)

Thus, it coarsens the propensity score, approximately averaging it within the subclasses. This modification to the estimated propensity score increases very small values of the propensity score and decreases very large values, and thus it lowers extreme values for the weights in the weighted-average interpretation of the estimator.
What are the relative merits of the subclassification estimator versus the HorvitzThompson estimator? We discuss three issues. Ultimately we prefer the subclassification estimator and see little reason to use the estimator based on weighting by the estimated propensity score. However, in many cases this choice is not important, because it will not make much difference whether one uses the Horvitz-Thompson or subclassification weights. If the number of blocks is large, so that the dispersion of the propensity score within the strata is limited, then the weights according to the blocking estimator will be close to those according to the Horvitz-Thompson estimator, which is also true if there is only limited variation in the propensity score overall, and if there are few extreme values for the propensity score. The weights will be different only if, in at least some blocks, there is substantial variation in the propensity score, which is most likely to happen in blocks with propensity score values close to zero and one. In fact, the similarity between the estimators turns to equality in simple cases where the model for the propensity score

17.8 Weighting Estimators and Subclassification

395

is fully saturated and the number of blocks is sufficiently large that within a block there is no variation in the propensity score.
Now consider bias properties of the two estimators. If one uses the inverse of the true propensity score, the Horvitz-Thompson estimator is exactly unbiased. If one does not know the propensity score, it might then seem that using the best possible estimate of the propensity score (in the sense of minimizing expected mean squared error), rather than an estimator that is further smoothed, may be sensible. This appears the most powerful argument in favor of the Horvitz-Thompson estimator, but it is not particularly persuasive though. Although weighting by the inverse of the true propensity score leads to unbiased estimators for the average treatment effect, weighting using the inverse of a noisy, unbiased, estimator for the propensity score may generate considerable bias because the estimated propensity score enters in the denominator of the weights. Smoothing the weights by essentially averaging them within blocks, as the subclassification estimator does, may remove some of this bias. Moreoever, in practice the propensity score is likely to be misspecified, which may affect the performance of the Horvitz-Thompson estimator more than the subclassification estimator. More specifically, suppose a particular covariate Xi,k is omitted from the propensity score specification. If this covariate is correlated with the potential outcomes, any (small) bias from omitting it may be increased by the larger weights used in the Horvitz-Thompson approach.
The second point concerns the estimated sampling variance. Here the relative merits are clear. By smoothing over the extreme weights from the Horvitz-Thompson estimator, the subclassification estimator tends to have a smaller sampling variance, which also may make the Horvitz-Thompson estimator less robust than the blocking estimator because the large weights also tend to be the ones that are relatively imprecisely estimated or affected by misspecification of the propensity score model. For that reason, shrinking them to their mean within subclasses, as subclassification does, can improve the properties of the resulting estimator.
A final issue concerns modifications of the Horvitz-Thompson and blocking estimator involving additional covariance adjustment. The covariance adjustment version of the Horvitz-Thompson estimator uses a single set of parameters to model the dependence of the outcome on the covariates. In other words, it uses a global approximation to the regression function. Such a global approximation can lead to poor approximations to the two regression functions for some values of the covariates. An analogous procedure given the subclassification would be to restrict the slope coefficients on the covariates to be the same across all blocks. This is not what is typically done, or what we discussed in the previous sections. Instead, the slope coefficients are unrestricted between the blocks, allowing the estimated regression function to provide a better approximation to the conditional mean.

17.8.2 Weighting Estimators and the Lottery Data
To illustrate the Horvitz-Thompson estimator let us return to the lottery data. We look both at the full sample with 496 units and at the trimmed sample with 323 units. In both cases we calculate the weights according to the propensity score estimated through the algorithm described in Section 17.3. Based on the estimated propensity score, we

396

Subclassification on the Propensity Score

Table 17.8. Some Descriptive Statistics for Weights for Horvitz-Thompson and Subclassification Estimators for the IRS Lottery Data

Full Sample

Trimmed Sample

Horvitz-Thompson Subclass Horvitz-Thompson Subclass

Minimum

0.92

1.06

1.00

1.19

Maximum

79.79

17.71

18.18

6.15

Standard deviation

4.20

2.63

1.69

1.35

normalize the weights within each treatment group to ensure they sum to N. We then estimate the implicit weights in the blocking estimator, again for both the full sample and for the trimmed sample.
Table 17.8 presents summary statistics for the weights. Within each data set there is a substantial difference between ranges of the Horvitz-Thompson and subclassification weights. In the full sample, the correlation coefficient between the Horvitz-Thompson and subclassification weights is only 0.64. In the trimmed sample the correlation is higher, namely 0.82. The second observation is that the weights are considerably more extreme for the Horvitz-Thompson estimator. In the full sample the largest of the weights is almost 80 for the Horvitz-Thompson estimator, compared to 17.8 for the subclassification estimator. With the smallest weights around one (the smallest weight would be at least equal to one if it was not for the normalization to ensure that the weights add to the sample size), the weight for this unit is eighty times that for the low-weight unit, making any estimates overly sensitive to the outcome for this unit; for example, increasing the outcome for this individual by one standard deviation (i.e., increasing average postlottery earnings by $15,000), would lead to a change in the estimated average treatment effect of (80/496) × 15,000 = 2,500, which is substantial, given the variation in our subclassification estimates in Table 17.7. The sensitivity of the estimates to the outcome for this unit in the subclassification estimator is less because its weight is only a fifth as large. In the trimmed sample, the largest weights are 18.2 and 6.2 for the HorvitzThompson and subclassification estimators respectively, so now changing the outcome for any single unit by a standard deviation leads to a change in the subclassification estimated average effect of at most (6.2/323) × 15,000 = 300. In particular, for subclassification in the trimmed sample, the ratio of largest to smallest weight is 5.2, ensuring that no single unit is unduly affecting the estimates. The third observation is that the trimming greatly reduces the variation in the weights, and lowers the largest weights, by improving the balance and shrinking the propensity score toward average values. In general, subclassification smooths the weights, avoiding excessively large weights.
Suppose, as we have done before in illustrative calculations, that the conditional expectation of the potential outcomes is linear in the covariates:
Esp [ Yi(w)| Xi] =  +  · Wi + Xi,
with constant variance:
Vsp ( Yi(w)| Xi) =  2.

17.8 Weighting Estimators and Subclassification

397

Table 17.9. Least Squares Regression Estimates for the IRS Lottery Data

Covariate

Full Sample

Est (s. e.)

Intercept Treatment Indicator Year Won # Tickets Age Male Education Work Then Earn Year -6 Earn Year -5 Earn Year -4 Earn Year -3 Earn Year -2 Earn Year -1 Pos Earn Year -6 Pos Earn Year -5 Pos Earn Year -4 Pos Earn Year -3 Pos Earn Year -2 Pos Earn Year -1 Residual 2

21.20 -5.08 -0.64
0.06 -0.26 -0.58
0.04 0.93 -0.00 -0.02 0.02 0.29 0.04 0.48 0.19 1.78 -1.04 -1.60 -1.08 -0.36
8. 452

(4.80) (0.95) (0.34) (0.15) (0.04) (0.89) (0.20) (1.12) (0.11) (0.13) (0.12) (0.12) (0.11) (0.08) (1.66) (2.10) (1.99) (1.90) (2.01) (1.79)

Trimmed Sample

Est (s. e.)

22.76 -5.34 -0.34
0.31 -0.29
0.44 -0.12
1.30 0.01 -0.02 0.01 0.36 -0.20 0.64 0.05 1.44 -0.28 -2.65 0.30 -2.52

(6.49) (1.08) (0.44) (0.21) (0.05) (1.17) (0.27) (1.45) (0.14) (0.17) (0.14) (0.15) (0.16) (0.11) (2.18) (2.72) (2.45) (2.50) (2.98) (2.65)

8. 592

Table 17.10. Estimated Bias and Estimated Sampling Variance for HorvitzThompson and Subclassification Estimators under Linear Model for the IRS Lottery Data

Full Sample

Horvitz-Thompson Subclass

Bias
Variance Bias2+Variance

4.34 2.592 5.062

2.68 0.832 2.812

Trimmed Sample

Horvitz-Thompson Subclass

1.29 1.292 1.832

0.30 1.152 1.192

If this linearity assumption were actually true, we could simply estimate  by least squares. We present the relevant least squares estimates in Table 17.9. However, the point here is not to get an estimate of the average treatment effect under this assumption but rather to compare the Horvitz-Thompson estimate versus the subclassification estimate, under this assumption.

398

Subclassification on the Propensity Score

An estimator of the form

^ =

1 N

N i=1

Wi · Yiobs · i - (1 - Wi) · Yiobs · i

,

with the weights i = (Wi, Xi, W(i), X(i)), has, conditional on W and X, the following bias and sampling variance:

Bias = Esp

^ - fs W, X

=

1 N

N i=1

Wi · t(Xi) · i - (1 - Wi) · c(Xi) · i

- ,

and sampling variance

Vsp

^ W, X

=

1 N2

N i=1

i2

·

Wi · t2(Xi) + (1 - Wi) · c2(Xi)

.

Under our linear homoskedastic model assumptions, the bias simplifies to

Bias

=

1 N

N
(2 · Wi - 1) · Xi · i
i=1

=

Xt,weighted - Xc,weighted

,

where

Xc,weighted =

Xi · i

i, and Xt,weighted =

Xi · i

i,

i:Wi=0

i:Wi=0

i:Wi=1

i:Wi=1

the weighted average of the control and treated covariates, respectively. Under homoskedasticity, the sampling variance simplifies to

Vsp

^ W, X

=

2 N2

·

N i=1

i2.

We can estimate these two objects, Bias and Var, as well as the sum of the sampling variances and the square of the bias, that is, the expected-mean-squared-error, for our particular data set, leading to

MSE =

Xt,weighted - Xc,weighted

^

2

+

2 N2

·

N i=1

i2.

The results are reported in Tables 17.6 and 17.10. In Table 17.6 we report the least squares estimates of the regression function, for both the full and the trimmed samples. In the third and seventh columns of Table 17.1, we report the average difference in covariates, weighted according to the Horvitz-Thompson estimator and normalized by the square root of the sum of the standard deviations

Xt,weighted - Xc,weighted . s2c + st2 /2

Notes

399

If the Horvitz-Thompson estimator were based on the true propensity scores, the average difference in covariates should be zero, at least in expectation. They are not, due in part to sampling variation and due in part to misspecification of the propensity score. We see that, for most covariates, the Horvitz-Thompson estimator has approximately the same normalized differences as the subclassification estimator. Sometimes the Horvitz-Thompson differences are larger, as for the important (in the sense of being, a priori, likely to be correlated with the potential outcomes) lagged earnings variables, and sometimes smaller, as for education and some of the employment indicators. The larger normalized differences are largely due to the presence of extreme weights in the Horvitz-Thompson approach.
Table 17.10 presents the components of the estimated expected-mean-squared-error. It is not surprising that, for both the full and the trimmed samples, the estimated sampling variance is smaller for the subclassification estimator, which is a direct consequence of the smoothed weights of the subclassification estimator. Possibly more surprising is the fact that, for both the full and the trimmed samples, the estimated bias is actually considerably larger for the Horvitz-Thompson estimator than for the subclassification estimator. Not surprising is that the estimated bias and the estimated sampling variance are substantially smaller in the trimmed sample than in the full sample (with the exception of the estimated sampling variance for the subclassification estimator, which is slightly smaller in the full sample than in the trimmed sample).

17.9 CONCLUSION
In this chapter we discuss one of the leading classes of estimators for average treatment effects under unconfoundedness. This subclassification estimator uses the propensity score to construct strata within which the covariates are well balanced. Within the strata, the average treatment effect is estimated by simply differencing average outcomes for treated and control units, or, in our preferred version, by further adjusting for some remaining covariate differences through linear regression. The subclassification estimator with further adjustent is similar conceptually to weighting estimators, although less variable in settings with units with propensity score values close to zero or one. We illustrate the practical value of this estimator using the lottery data.

NOTES
Subclassificiation as a method for estimating treatment effects in the presence of observed confounders has a long tradition in statistics. Early discussions can be found in Cochran (1965, 1968). See also Rosenbaum and Rubin (1983a, 1984). There are many recent applications, including Dehejia and Wahba (1999) and Rubin (2001).
The estimator that combines weighting with regression has been developed by Robins, Rotnitzky, and Zhao (1995). They show that the weighted regression estimator is consistent as long as either the specification of the propensity score is correct, or the specification of the regression function is correct, a property Robins and coauthors

400

Subclassification on the Propensity Score

refer to as "double-robustness." See Hirano and Imbens (2001), Kang and Shafer (2007) and Waernbaum (2012) for some discussion on the properties of doubly-robust estimators and for some simulation studies of blocking.
See Hirano, Imbens, and Ridder (2003) on formal properties of the Horvitz-Thompson estimator with a discussion of the implications of using the estimated versus the true population propensity score to construct the weights for the precision of the resulting estimators.
An interesting extension of the equalities in Equation (17.6) is the following equality, which holds under unconfoundedness:

E

Yiobs

·

Wi e(Xi) ·

- (1

e(Xi) - e(Xi))

Xi = x

= sp(x).

Thus the conditional expectation of the transformed outcome Yi = Yiobs· (Wi -e(Xi)/(e(Xi)·(1-e(Xi))), conditioning on Xi but not on Wi, is equal to  (Xi). Athey and Imbens (2014) exploit this equality to adapt machine learning algorithms devel-
oped for prediction problems to the problem of estimating conditional average treatment
effects.

CHAPTER 18
Matching Estimators
18.1 INTRODUCTION
Following the discussion of subclassification (i.e., blocking, or stratification) in the previous chapter, we discuss in this chapter a second general approach to estimation of treatment effects in regular designs, namely matching. As earlier, we mainly focus on average effects, although the methods readily extend to estimating other causal estimands, for example, the difference in the median or other quantiles by treatment status, or differences in variances. Many of the specific techniques in this chapter are similar to the methods discussed in Chapter 15, but the aim is different. In Chapter 15 we were interested in constructing a sample with improved balance in the covariates. Here we take the sample as given, and focus on estimating treatment effects. In this chapter we consider both methods where only the treated units are matched (and where the focus is on the effects of the treatment for the treated), and methods are matched in order to estimate the effects of the treatment for the full sample.
Matching estimators ­ based on direct comparisons of outcomes for observationally equivalent "matched" units that received different levels of a treatment ­ are among the most intuitive estimators for treatment effects. Informal assessments of causality often rely implicitly on matching: "This unemployed individual found a job because of the skills acquired in a job-training program." Typically the case for or against such a claim is made by a comparison to an individual who did not participate in the training program but who is similar with respect to observed background characteristics. If we maintain the unconfoundedness assumption ­ that the probability of receipt of treatment is free of dependence on the potential outcomes, once observed pre-treatment characteristics are held constant ­ such comparisons between treated and control units with the same covariate values have a causal interpretation. The matching approach estimates average treatment effects by pairing such similar units and averaging the within-pair differences in observed outcomes.
Moreover, in many observational studies there exists no systematically better approach for estimating the effect of a treatment on an individual unit than by finding a control unit identical on all observable aspects except on the treatment received and then comparing their outcomes. For example, suppose we wish to evaluate the effect of a job-training program on a 30-year-old single mother with two children, ages 4 and 6, who had been
401

402

Matching Estimators

employed for eighteen months before being out of work for the last six months, who participated in the program, and about whom we have no additional information. Lacking a randomized design for the evaluation of the training program, it appears most credible to assess the benefits of this program by comparing the labor market outcomes for this woman to those of another 30-year-old single mother with two children, aged 4 and 6, with a similar recent labor market history, in the same geographic location, but who did not go through the job-training program. This is exactly what matching aims to do: it attempts to find the control unit most comparable to the treated unit in all possible pre-treatment characteristics. Although making units comparable along observable dimensions need not be sufficient for obtaining credible causal comparisons, it is often a prerequisite for doing so.
To provide additional intuition for matching, consider the analysis of paired randomized experiments discussed in Chapter 10. Matching can be interpreted as reorganizing the data from an observational study in such a way that the assumptions from a paired randomized experiment hold, at least approximately. There are, however, two important differences between paired randomized experiments and matching in observational studies. The first difference is that in the latter case, unconfoundedness must be assumed ­ it is not guaranteed to be satisfied by design, as it is in a randomized experiment. Even when treated and control observations can be matched exactly on the observed covariates, there may exist, in observational studies, unobservable factors that vary systematically between members of the pairs, affecting both their underlying probabilities of receiving the treatment and their potential outcomes, and therefore creating biases. Thus, inferences based on matched observational data are inherently less credible than those based on data from a paired randomized experiment. The second difference from paired randomized experiments is that matching is often inexact, so that systematic differences in pre-treatment variables across the matched pairs may remain. In contrast, the within-pair randomization guarantees that the assignment probabilities are identical within pairs, and so no systematic biases can arise. Hence the assumptions from a paired randomized experiment do not generally apply, even if unconfoundedness holds, when the matching is not exact.
In this chapter we discuss matching estimators in more detail. In Section 18.2 we introduce the data set that will be used to illustrate the methods discussed in this chapter. They come from an influential study by Card and Krueger evaluating the effect of a change in the minimum wage in New Jersey in 1993. Next, in Section 18.3, we discuss the simplest form of matching estimators where we match each treated unit to a single control unit, with exactly the same values of the covariates, using each control unit at most once as a control. This matching may have been the result of the design strategy in Chapter 15. The resulting pairs of treated and control units can be analyzed using the methods developed for paired randomized experiments in Chapter 10. The natural estimator for the average treatment effect for the treated units is, in this case, simply the average difference within the pairs, and one can estimate the sampling variance by the sample variance of the within-pair differences divided by the number of pairs. This setting is too simple to cover many cases of interest, and in the remainder of the chapter we discuss extensions to more complex and realistic cases, as well as modifications of the simple matching estimator to improve its properties in those more complex situations.

18.1 Introduction

403

These extensions and complications fall into two broad categories. The first involves dealing with the inability to find exact matches in the finite sample at hand. This category includes the issues raised by the choice between various close, but inexact, matches, as well as options to reduce biases from inexact matches. The second category involves departures from the distinct-pair setup, where each pair consists of a single unique treated and a single unique control unit, with distinct units across distinct pairs. This second category includes extensions where units are used more than once as a match, or where multiple matches are used. We now briefly describe the various specific extensions and complications.
The first three complications fit into the first category. In Section 18.4 we address the possibility that there are some treated units for whom we cannot find a control unit that is identical in terms of covariates. In that case, one option is to include matches that are not exact in terms of covariates, which in turn may lead to situations where the order in which the observations are matched affects the specific composition of the pairs, which suggests either choosing a systematic or random ordering of the units, or using a more complicated matching algorithm that takes into account the effect of one choice of match on the remaining pool of control units. A second complication is that, once the matching is inexact, we need to specify a distance measure to operationalize the notion of the "closest" match. Especially when we match on multiple covariates, the choice of metric can be important: that is, with multiple covariates, we often need to choose whether to trade off a difference in, for example, age against a difference in the number of children, or against a difference in previous labor market experience. We discuss some leading choices for such distance measures in Section 18.5. If the matching is inexact, one may be concerned that the quality of some of the matches is not adequate, in the sense that the differences in covariate values within matches is substantial. In Section 18.7 we discuss the biases that may result from this inexact matching. There are several techniques available that attempt to reduce these biases, and we discuss some in Section 18.8. These techniques provide somewhat of a bridge between the matching estimators, discussed in this chapter, and the regression and model-based methods discussed in the context of randomized experiments in Chapters 7 and 8.
Next we discuss three extensions that fit into the second category of techniques. In Section 18.9 we discuss matching with replacement, where we allow a control unit to be used as a match more than once to increase the set of potential matches for each treated unit. Allowing a control unit to be used as a match for more than one treated unit can therefore improve the quality of the matches in the sense that it reduces the expected distance between the treated unit and its control match by expanding the potential set of control matches. Another advantage of matching with replacement is that it removes the dependence on the ordering of the units to be matched, or the need for more sophisticated matching methods that take account of the effect an early matching choice has on future possible matches. A disadvantage of such matching is that it can increase the sampling variance of the matching estimator by decreasing the number of matched controls.
In Section 18.10 we discuss the extension to multiple matches for each treated unit. Often only a single unit is used as a match. However, if multiple high-quality matches are available, one can improve the precision of the matching estimator without substantially

404

Matching Estimators

increasing its bias. We discuss the potential gain in terms of precision as well as the potential cost in terms of bias. In Section 18.11 we discuss using matching to estimate treatment effects for the control units, rather than just for the treated units, and for the full sample.
In Section 18.12 we turn to the full data set from the Card and Krueger study to compare the estimates of the average treatment effect using various matching approaches. In addition, we compare these results to ordinary least squares estimates of the average treatment effect, calculated with, and without, using some or all of the matching variables in the regression model. This example illustrates that, regardless of the number of matches, the distance metric, or bias-adjustment approach used, all of the matching estimates can be fairly tightly clustered. In contrast, as anticipated, the ordinary least squares (regression) results can be sensitive to the specification chosen.

18.2 THE CARD-KRUEGER NEW JERSEY AND PENNSYLVANIA MINIMUM WAGE DATA
The data used in this chapter to illustrate matching methods are from an influential study by Card and Krueger (1995). They were interested in evaluating the effect of raising the state minimum wage in New Jersey in 1993 and collected data on employment at fast-food restaurants in New Jersey and in the neighboring state of Pennsylvania. The unit of analysis here is a restaurant. In addition to the number of employees measured prior to the raise in the minimum wage in New Jersey (initial empl), Card and Krueger collected for each restaurant information on starting wages (initial wage), average time until first raise (time until raise), and the identity of the chain (burger king, kfc, roys, or wendys). The outcome is employment after the raise in the minimum wage (final empl). Here we analyze the data as if they arose from a regular design, which includes the unconfoundedness assumption that, conditional on these covariates, the probability of being exposed to the new minimum wage (i.e., being from New Jersey rather than Pennsylvania) does not depend on the potential outcomes.
Table 18.1 presents summary statistics for the data set. There are 347 restaurants in the data set, 279 in New Jersey (the treated units) and 68 in Pennsylvania (the control units). For the purposes of this discussion we view the New Jersey restaurants as "treated" restaurants (subject to the intervention of the higher minimum wage), and the Pennsylvania restaurants as the "control" restaurants. A quick look at the overlap statistics suggests that the data are fairly well balanced. The largest of the normalized differences, calculated for each covariate as (Xt - Xc)/ (s2t + sc2)/2, is equal to 0.28, for the initial employment variable, initial empl.
We estimate the propensity score, using the methods discussed in Chapter 13, as summarized in Table 18.2. The only covariate we pre-select for inclusion in the propensity score is the initial level of employment, initial empl. The algorithm does not select any other covariate to enter linearly and also does not select any second-order term. Had we not pre-selected initial employment, the algorithm would have selected it in any case, so the results are not sensitive to this choice. The estimated propensity score ranges from

18.3 Exact Matching without Replacement

405

Table 18.1. The Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

(N = 347) (Nt = 279) (treated)

(Nc = 68) (controls)

Mean (S.D.) Mean (S.D.) Mean (S.D.)

 0.05
Nor Log Ratio Dif of STD Controls Treated

initial empl 17.84 (9.62) 20.17 (11.96) 17.27 (8.89) -0.28

burger king 0.42 (0.49) 0.43 (0.50) 0.42 (0.49) -0.02

kfc

0.19 (0.40) 0.13 (0.34) 0.21 (0.41) 0.20

roys

0.25 (0.43) 0.25 (0.44) 0.25 (0.43) 0.00

wendys

0.14 (0.35) 0.19 (0.40) 0.13 (0.33) -0.18

initial wage 4.61 (0.34) 4.62 (0.35) 4.60 (0.34) -0.05

time until 17.96 (11.01) 19.05 (13.46) 17.69 (10.34) -0.11

raise

pscore

0.80 (0.05) 0.79 (0.06) 0.81 (0.04) 0.28

-0.30 -0.01
0.17 -0.00 -0.18 -0.02 -0.26
-0.35

0.10 0.03 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.01 0.10 0.03
0.10 0.03

final empl 17.37 (8.39) 17.54 (7.73) 17.32 (8.55)

Table 18.2. Estimated Parameters of Propensity Score for the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

Variable Intercept

Est

(s. e.)

t-Stat

1.93

(0.14)

14.05

Linear terms initial empl

-0.03

(0.01)

-2.17

0.4247 to 0.8638, again suggesting there is no need to trim part of the sample for lack of overlap.
In some of the initial discussions, we use a small subset of the Card-Krueger data to illustrate in detail some of the specific methods. For this purpose we selected twenty restaurants, five from New Jersey and fifteen from Pennsylvania, for which selected variables are presented in Table 18.3. This subset includes only burger king and kfc restaurants, and we use only initial employment (initial empl) and restaurant chain (burger king or kfc) as pre-treatment variables for this small sample.

18.3 EXACT MATCHING WITHOUT REPLACEMENT
In this section we discuss the simplest case of matching, exact matching without replacement. Initially we focus on the case where only treated units are matched, each to a unique single control. Initially we make the, generally unrealistic, assumption that there is a sufficiently large number of control units such that exact matches exist for each treated unit without the need to use the same control more than once. This may be more plausible after discarding some units using the design methods developed in Chapters 15

406

Matching Estimators

Table 18.3. 20 Units from the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

Unit State chain initial empl final empl

i Wi

Xi1

Xi2

Yiobs

1

NJ BK

22.5

40.0

2

NJ KFC

14.0

12.5

3

NJ BK

37.5

20.0

4

NJ KFC

9.0

3.5

5

NJ KFC

8.0

5.5

6

PA BK

10.5

15.0

7

PA KFC

13.8

17.0

8

PA KFC

8.5

10.5

9

PA BK

25.5

18.5

10 PA BK

17.0

12.5

11 PA BK

20.0

19.5

12 PA BK

13.5

21.0

13 PA BK

19.0

11.0

14 PA BK

12.0

17.0

15 PA BK

32.5

22.5

16 PA BK

16.0

20.0

17 PA KFC

11.0

14.0

18 PA KFC

4.5

6.5

19 PA BK

12.5

31.5

20 PA BK

8.0

8.0

and 16. If there are multiple control units that are exact matches for a particular treated
unit, we choose one element from this set randomly.
To be precise, and in order to deal with some of the subsequent extensions, let us
introduce some notation. As before, we have a sample with N units, indexed by i = 1, . . . , N. Let It = {1, . . . , Nt} be the set of indices for the Nt treated units and Ic = {Nt + 1, . . . , Nt + Nc} the set of indices for the Nc controls. Because (by assumption)
distinct exact matches exist for each treated unit, we will obtain a set of Nt pairs. Let Mci  Ic be the set of control indices containing the matches for treated unit i. Because we use a single match, Mci is a singleton, Mci = {mic}, where mci is the index of the unit with the closest covariate values among the units with the opposite treatment to that of unit i. Because the matches are all distinct, it follows that if i = i , then Mci  Mic = , and because the matching is exact, Xi = Xmi for all i = 1, . . . , Nt. The superscript "c" on the set M1c indicates that the matches are control matches; later, when we also match control units, the set of their matches will be denoted by Mti.
To be clear, suppose we have five units in the population, with units 1 and 2 treated
units and 3, 4, and 5 control units. In that case, we have It = {1, 2}, Ic = {3, 4, 5}; Nt = 2
so that we construct two pairs. One possible pair of matches is to have the first pair equal
to (1, 3) and the second pair equal to (2, 5) ­ for example, if X1 = X3, and X2 = X5. For such a matching scheme to be at all possible, we obviously need Nc  Nt, and in
practice we may need the reservoir of possible control units to be much larger than the

18.4 Inexact Matching without Replacement

407

number of treated units. We ignore these practical issues for now, but later we discuss such issues in some detail (see Section 18.9).
Now consider the ith matched pair, (i, mi), with covariate values Xi = Xmi = x. Because of super-population unconfoundedness, the probability is 1/2 that, of these two units, it is unit i rather than unit mi that received the treatment, conditional on the covariate value x and conditional on the pair of potential outcomes for each element of the pair. Given unconfoundedness, these Nt matched pairs, therefore, can be considered as comprising data from a paired randomized experiment and can be analyzed using the methods discussed in Chapter 10. A key implication, from the results in Chapter 10, is that the matched pair difference for the ith pair,
^imatch = Yiobs - Ymobics,
is an unbiased estimator of the causal effect at X = Xi for both units in the pair, and thus

^tmatch

=

1 Nt

^imatch
i:Wi=1

=

1 Nt

i:Wi=1

Yiobs - Ymobcis

=1 Nt i:Wi=1

Yi(1) - Ymci (0) , (18.1)

is an unbiased estimator for the average treatment effect for the units in It. The second implication is that

V^

^tmatch

=1 Nt i:Wi=1

Yiobs - Ymobics - ^tpair

2
,

(18.2)

is a statistically conservative estimator of the sampling variance of the unbiased estimator in (18.1). We can also calculate exact p-values based on Fisher's approach, conditional on the Nt pairs. In both approaches, the analysis is entirely standard based on the results for the paired randomized experiment discussed in Chapter 10.
In practice, such an exact matching scheme is rarely feasible. The first impediment is that exact matching is typically impossible, and we must instead rely on "close" rather than exact matches, with a host of attendant complications. The second issue is that the pool of potential matches is often too small to ignore the conflicts that may arise when the same control is the best match for more than one treated unit. There are three general options to address this latter complication. One can explicitly match in such a way that the Nt matches remain distinct ­ matching without replacement. An alternative is to pick a particular order of the units and match the units in that order. A third possibility is to allow for duplication in the use of controls in the pairs (matching with replacement). In the remainder of this chapter, we discuss such methods and their attendant complications, as well as provide a number of practical ways to implement matching.

18.4 INEXACT MATCHING WITHOUT REPLACEMENT
In this section we discuss the conventional matching estimator, where we continue to match only the treated units without replacement of choosen controls (assuming Nt <

408

Matching Estimators

Nc), but now without assuming the existence of perfect matches for all units. For each of the Nt treated units we attempt to find the "closest" match within the set of all controls, Ic, with respect to the covariates, thereby leading to Nt pairs. We would like to match the ith treated unit, with covariate values Xi, to control unit mi, that is, the control unit that
solves

mci = argmini Ic Xi - Xi ,

(18.3)

where x denotes a generic metric or distance function.1 The solution to this minimization problem is control unit j that is the closest match to the treated unit being considered. When multiple controls are equally close matches, we could choose randomly one of them.
Even with a specified metric, there remains an issue with this approach. Solving Equation (18.3) for each treated unit separately may lead to the same control unit being selected as a match more than once. In other words, it may be that control unit j  Ic is not only the best match for treated unit i but also for treated unit i . Because at this stage we rule out matching with replacement, we cannot use control unit j as a match for both. There are two ways we can address this. The first is to attempt to match all units simultaneously to obtain the "optimal" allocation of matches across the full population It. Formally, we can do this by minimizing an aggregate measure of the matching distances such as their sum. This amounts to simultaneously choosing the Nt indices m1, . . . , mNt  Ic that solve

Nt

argminm1c ,...,mcNt Ic

Xi - Xmcmi ,

i=1

subject to mi = mi , for i = i . (18.4)

Although this "optimal matching" problem is straightforward to solve in settings with few units, it can become a demanding task computationally if the sample size is moderately large. Researchers therefore often follow an alternative approach by matching units sequentially, using what is often called a "greedy" or "nearest available matching" algorithm. In the first step, the first treated unit, i = 1, is matched to its closest control unit ­ ignoring the effect this choice has on subsequent matches ­ by solving

m1 = argminm1cIc X1 - Xm1c . The second treated unit, i = 2, is then matched by searching over the remaining controls:
m2c = argmini Ic-M1c X2 - Xi , where the notation Ic - Mc1 denotes the set of control units excluding the control unit matched to treated unit 1, M1c = {mc1}. The ith treated unit is then matched to the closest

1 We will discuss a number of choices for the distance metric in Section 18.5. For now it may be
useful to think of the generic distance measure, where, for a K-dimensional vector x, x - x = x - x V = ((x - x )V-1(x - x )T )1/2 for some positive semi-definite matrix V. This metric may not be a formal distance because x - x may be zero even when x = x .

18.4 Inexact Matching without Replacement

409

control unit in the set of all control units, excluding the first i - 1 sets of control matches, leading to

mci

=

argmin
i

Ic-

ii-=1 1Mci

Xi - Xi ,

and so on, until all Nt treated units are matched.

It is important to realize that the result of this matching is now dependent on the

ordering of the treated units. Rather than assigning this order randomly, researchers

sometimes match first those units that are a priori most likely to be difficult to match.

One such order is based on the estimated propensity score, the estimated probability of

receiving treatment. Control units have, in expectation, a smaller estimated propensity

score than treated units, and thus treated units with a larger value for their estimated

propensity score tend to be more difficult to match. A common approach is therefore to

match treated units based on the rank of their estimated propensity scores, starting with

those with the highest value for the propensity score. Such a greedy matching algorithm

is easier to implement than an optimal one, and the loss in terms of the criterion in (18.4)

is often small. In fact, the chosen set of controls tends to be very similar across such

matching orderings. The result of the matching so far is, again, a set of pairs (i, mic), for i = 1, . . . , Nt, now
with approximately ­ rather than exactly ­ the same values for all covariates. Hence,

even under the assumption of unconfoundedness, the probability of assignment to the

treatment may be now only approximately the same for both units in each pair. If we

ignore this inexactness, we can once again rely on the paired randomized experiment

results to obtain an approximately unbiased estimator for the average treatment effect on

the treated, and its sampling variance, given in (18.1) and (18.2), respectively.

When searching for the best match for treated unit i, there may be two or more equally

close control units. There are several ways one can deal with this issue. First, one can

use the average of the outcomes for this set of tied matches as the estimate of the control

potential outcome for treated unit the set Mci . Or, instead, one can

i, use

i Mic
some

Yi (0)/Mi, where Mi is the cardinality of mechanism for choosing among this set

of potential matches, potentially by random selection. The first choice has the advantage

of reducing the sampling variance of the resulting estimator for the treatment effect at Xi.

It is also more systematic than randomly choosing among the set of potential matches.

Yet it has the disadvantage of removing more units from the pool of possible control

units available for subsequent matches. If the overall pool of possible control matches

is relatively small, and if there are many ties, this method of using all potential matches

may lead to poor-quality matches for the remaining treated units compared to randomly

selecting one of the possible control matches.

Inference based on matching estimators that match without replacement is typically

still based on the sampling variance estimator for paired randomized experiments given

by Equation (18.2). Even though there is a potential bias in the estimator for the average

treatment effect (formally, the expectation of the estimator conditional on the covariates

is not exactly equal to the estimand), in practice this is ignored, which can be justified

by appealing to special large-sample results where the size of Ic is much larger than the size of It. See the notes at the end of the chapter for more details and formal results.

410
18.5 DISTANCE MEASURES

Matching Estimators

Before we can implement these ideas in practice, we must discuss how to operationalize the notion of "closeness" in practical situations when exact matching is not possible. Consider the case of a single covariate. In that case, one may, for example, choose between defining distance in terms of differences in levels or logarithms. Consider matching an individual who is 20 years old, with two potential matches, one individual age 15 and one age 26. In terms of levels, the first match is closer, with a difference of only 5 years rather than 6 years. However, if one considers the logarithm of age, so that the difference corresponds approximately to the percentage difference, the first match (between individuals age 20 and 15) corresponds to a difference of 0.29 versus a difference of only 0.26 for the second match (between individuals age 20 and 26). Hence the latter would be considered a closer match if closeness is measured on a logarithmic scale.
This problem of scaling, or transforming, the covariates is particularly relevant if one matches not on the original covariate but on some bounded function of it, such as the propensity score. In substantive terms, the difference between a probability of 0.01 and 0.06 (a sixfold increase) is often much larger than the difference between a probability of 0.06 and 0.11 (less then doubling), even though in both cases the difference in levels of the propensity score is equal to 0.05. In that case, an often more attractive metric is based on the linearized propensity score or log odds ratio, obtained by transforming the probability e(x) into (x) = ln (e(x)/(1 - e(x))), which would make the difference between probabilities of 0.01 and 0.06 equal to | - 4.60 - ( - 2.75)| = 1.84, much bigger than the difference in terms of the linearized propensity score between probabilities of 0.06 and 0.11, namely |-2.75 - (-2.09)| = 0.66.
This problem of the choice of metric is compounded by the presence of multiple covariates, each of which can be continuous, discrete, or a simple indicator variable. A first, commonly used principle when choosing among possible distance metrics is that many covariates have no natural scale, and therefore one should use a metric that is invariant to their scale. Hence, after a transformation is chosen (e.g., logarithm versus level) for a covariate, researchers typically should normalize all covariates to a common variance before matching. However, even choosing a transformation and normalizing the result does not solve all issues with the choice of the metric. In settings with inexact matching and multiple covariates, there is a fundamental problem involving trading off the various covariates. In terms of the Card-Krueger example, if we want a match for a Burger King restaurant in New Jersey with 20 initial employees, should we prefer (as a control from the set of Pennsylvania restaurants) a Burger King with 23 initial employees, or a Kentucky Fried Chicken with 21 initial employees?
We consider distance metrics of the form dV (x, x ) = (x V-1x)1/2 for a positive definite weight matrix V. A common choice for distance is the Mahalanobis metric, where the weight matrix is based on the average of the within-treatment-group sample covariance matrices:





VM

=

1 2

· 1 Nc

(Xi
i:Wi=0

- Xc)T

· (Xi

- Xc) +

1 Nt

N
(Xi
i:Wi=1

- Xt)T

· (Xi

- Xt) .

18.5 Distance Measures

411

This metric takes account of correlations across covariates and leads to matches that are invariant to affine transformations of the covariates.2 This is a particularly attractive property if most of the pre-treatment variables have no natural scale. The second choice we consider is what we call the Euclidean metric,

VE = diag(VM),

the diagonal matrix with variances on the diagonal ignoring the covariances. An even

simpler metric is the sum of squared differences, without normalizing, which we do not

recommend in general but use purely for illustrative purposes in Section 18.6.

Using the affinely invariant Mahalanobis metric can have possibly unexpected conse-

quences. Consider the case where one matches on two highly correlated covariates X1

and X2 with equal variances. To be specific, assume that the correlation coefficient is equal to  = 0. 9, and both variances are equal to X2 = 1. Suppose that we wish to find a match for a treated unit i, with (Xi1, Xi2) = (0, 0). The two potential matches are control unit j with (Xj1, Xj2) = (5, 5) and control unit j with (Xj 1, Xj 2) = (4, 0). The differences in covariates for the two matches are the vectors Xi - Xj = (5, 5) and Xi - Xj = (4, 0),
respectively. Some intuitition suggests that the second match is better: it is strictly closer

to the treated unit with respect to both covariates. Using the Euclidean metric, which sets

the off-diagonal elements of VM equal to zero, this is in fact true; the distance between the second potential match and the treatedunit is Xi - Xj E = 4, considerably smaller than the distance to the first, Xi-Xj E = 50  7. 07. By comparison, using the Mahalanobis metric, the distance to the first match is Xi - Xj M= 5/0.19  5.13, whereas the distance to the second is a much larger Xi - Xj M = 16/0.19  9.18. Because of

the correlation between the covariates in the sample, the difference in covariate values

between the matches is interpreted differently by the two metrics.

To see why this situation arises, and to see the role of affine transformations, consider the artificial regressor X3 = (X1 -  · X2)/ 1 - 2  (X1 - 0. 9 · X2)/ 0.19. Like X1 and X2, the third covariate has variance X2 · (1 - 2)/0.19 = 1. The pair of covariates
(X2, X3) are an affine transformation of the pair of covariates (X1, X2). The transformation

is chosen, however, so that X2 and X3 have zero correlation. Because the transformation

is affine, the ranking of the matches does not change after the transformation according to

the Mahalanobis distance, which is not true for the Euclidean distance. More precisely,

the values of the X3 regressor for the three units in the example are Xi3 = 0, Xj3 = 0. 5/ 0.19  1.15, and Xj 3 = 4/ 0.19  9.18. Thus, in terms of X3, unit j is a

better match for unit i than is unit j . This is also true if we calculate the Euclidean

and Mahalanobis distance based on covariates X2 and X3. Define X~ = (X2, X3) . Based

on the X~ i -

pair X~ j E

of =

covariates (X2, X3), 25 + 16/0.19 

the Euclidean distance 10.45. The Euclidean

between distance

unit i and unit between unit i

j is and

unit j is X~ i - X~ j E  5.13. Because the correlation between X2 and X3 is zero, the

Mahalanobis distance is identical to the Euclidean distance, and X~ i - X~ j M  10. 45

and X~ i - X~ j M  5.13. A choice between the Euclidean and Mahalanobis metrics

corresponds implicitly to a stance on what the appropriate match would be in a case such

as this. The choice of the Euclidean distance versus the Mahalanobis metric makes little

2 An affine transformation is a transformation of the form x = a + Bx.

412

Matching Estimators

difference for estimating treatment effects in situations with low correlations between the covariates, as we will see in Section 18.12 when we calculate various matching estimates of the treatment effect of a minimum wage increase on employment levels.
One may wish to impose additional structure on the distance metric. For example, a particular indicator variable may be considered especially important so that the researcher may insist that it be matched exactly. In the evaluation of a medical treatment, for example, one may wish to impose that women exposed to the new treatment be matched solely to women exposed to the control treatment, and that men be matched solely to men, irrespective of differences in other characteristics. Similarly, in the example discussed here, one may require that restaurants subject to the new minimum wage law be matched only to restaurants in the same chain. More generally, one can choose a distance metric that assigns more weight to covariates that are considered more important a priori by increasing the relevant element of the matrix V-1 to increase its weight when building the scalar distance measure. Notice that "importance" here refers to the loss of credibility resulting from inexact matching on that particular component of X.
Ideally, when considering alternative distance metrics in the pursuit of estimating treatment effects for treated units, the intermediate goal is to obtain a metric that creates matched pairs (i, mi) with Xi = x and Xmi = x such that the expected control outcomes at the covariate values, Esp[Yi(0)|Xi = x] and Esp[Yi(0)|Xi = x ], are identical, or at least very similar. To achieve this objective, however, one would need to know the relationship between Yi(0) and Xi. In some situations it is possible to estimate this relation and use that information to choose between metrics. However, it is, in our view, unattractive to base the matching metric on a relation between potential outcomes and the covariates estimated on the same data set. Suppose, for example, that we estimate the conditional expectation E[Yi(0)|X] based on a parsimonious model for the control potential outcomes in terms of the covariates. Matching units based on E^ [Yi(0)|X] can lead to results that are sensitive to the specification chosen. Remember that much of the appeal of the matching approach is precisely its lack of reliance on modeling the relationship between the potential outcomes and covariates in the data set at hand. Hence, making the construction of a matched sample depend on an initial estimation step that involves outcome data generally detracts from the general appeal of this approach. Moreover, matching is often used to create estimates of causal effects for more than one outcome variable.

18.6 MATCHING AND THE CARD-KRUEGER DATA
Initially we look at a small subset of these data, five restaurants in New Jersey and fifteen in Pennsylvania (listed in Table 18.3). The covariates used are the initial employment level (initial empl), measured prior to the minimum wage change (although not prior to its announcement, which could in principle create problems for this analysis), and the restaurant chain identity (burger king or kfc). Initial employment is a more or less continuous variable (not necessarily an integer because part-time workers are counted as fractions).
Suppose we want to match without replacement these five treated observations using a greedy algorithm. Consider the first, a New Jersey BK with 22.5 employees prior to

18.6 Matching and the Card-Krueger Data

413

the minimum wage increase (unit 1 in Table 18.3). Now let us look for the best match for this restaurant, that is, the most similar unit from Pennsylvania. Among the fifteen Pennsylvania restaurants in our sample, there are eleven BKs and four KFCs. In terms of initial employment, the closest restaurants are one with 25.5 employees (unit 9) and one with 20 (unit 11). Both are BKs, so it is clear that the closest match will be one of these. In terms of the absolute difference, unit 11 is clearly closer. In terms of logs, the initial employment value for unit 1 is 3.11, for unit 9 it is 3.24, and for 11 it is 3.00. Thus, unit 11, the closest match both in levels and in logarithms, seems to be the natural match.3
Skipping units 2 through 4 for the moment, consider matching next the fifth treated observation, a KFC with an initial employment of eight workers. There are four KFCs in the control (Pennsylvania) sample, although none with an employment level of exactly eight. There is also one BK with exactly eight employees (unit 20). The Pennsylvania KFC with employment closest to that of unit 5 is unit 8, with 8.5 initial employees. We therefore face a choice: Is it more important to match exactly on the initial number of employees, or to match exactly on the restaurant chain? In this case, we may think that a difference of half an employee (e.g., a single part-time worker) out of a total of eight is less important than matching exactly on chain. But suppose the nearest KFC restaurant had an initial employment that differed from that of unit 5 (eight employees) by more than three or four employees. At what point would we decide that the better match would be the BK restaurant with exactly eight initial employees?
As we discussed in Section 18.5 on distance metrics, it is clear that the choice of metric establishes a systematic trade-off between matching discrepancies in one variable versus the other. To do so, we first convert the indicator variable into a numerical measure. Suppose we code BK as "0" and KFC as "1." Now for each control we can calculate the covariate difference between itself and the treated unit being matched and convert this into a distance. Suppose we simply square the differences and sum them. In practice we would typically start by normalizing the covariate values, but to simplify the illustrative calculations here we omit this step. Then the distance between unit 5 and the two potential matches, units 8 and 20, is 1/4 and 1, respectively. According to this criterion, unit 8 is closer. However, suppose we had instead coded the chains as "0" and "1/3." In that case the order would be reversed, with the distances now 1/4 and 1/9. When there is no particular reason to assign the indicator variable a difference of 1 across our two types, it is recommended to normalize the data to make the matching results invariant to such choices.
Thus far we have had to make two decisions, first the choice of matching order, and second the choice of distance metric. The three panels of Table 18.4 list the results of matching the five New Jersey restaurants varying the match order and the distance metric used. In each we match without replacement using a greedy algorithm.
In the first panel the treated units are matched in their original order and, for illustrative purposes, the metric used is the sum of the squared differences. Notice that unit 5 is not matched to unit 8 (the KFC with 8.5 employees discussed earlier), because unit 8 has

3 Note, however, that it is easy to find strictly monotone transformations of numbers of employees such that unit 9 is closer to unit 1 than is unit 11.

414

Matching Estimators

Table 18.4. The Roles of Match Order and Distance Metric, for the 20 Units from the Card and Krueger Fast-Food Restaurant Employment Data

Match Order = 1,2,3,4,5; Metric = x12 + x22

i

mic

Yiobs

Ymobci s

^imatch

1

11 40.0 19.5

20.5

2

7 12.5 17

-4.5

3

15 20.0 22.5

-2.5

4

8

3.5 10.5

-7

5

20

5.5

8.0

-2.5

^tmatch

+0.8

Match Order = 1,2,3,5,4; Metric = x12 + x22

i

mci

Yiobs

Ymobics

^imatch

1

11

2

7

3

15

5

8

4

20

^tmatch

40.0 19.5

12.5 17.0

20.0 22.5

5.5 10.5

3.5

8.0

20.5 -4.5 -2.5 -5 -4.5 +0.8

Match Order = 1,2,3,4,5; Metric = 100 · x12 + x22

i

mic

Yiobs

Ymobci s

^imatch

1

11 40.0 19.5

20.5

2

7 12.5 17.0

-4.5

3

15 20.0 22.5

-2.5

4

8

3.5 10.5

-7

5

17

5.5 14.0

-8.5

^tmatch

-0.4

already been "used up" in matching unit 4. Hence, because we are matching without replacement, we are forced to settle for a lower-quality match. For each matched pair, we then estimate the unit-level treatment effect, ^imatch = Yiobs - Ymobcis = Yi(1) - Ymi (0). Across the five pairs, this process gives an estimated average treatment effect for the treated of +0. 8 employees. (It may come as somewhat of a surprise to find a positive estimate, because all else being equal, standard economic theory predicts that a rise in the minimum wage will lower employment levels. But remember that this estimate is based on only five matched pairs.)
In the second panel, the metric remains the same, but the order changes: unit 5 is now matched before unit 4. This leads to a change in the matches: whereas in the first scheme

18.7 The Bias of Matching Estimators

415

unit 4 was matched to unit 8, and unit 5 was matched to unit 20, these matches are now reversed. Notice, however, that the estimator of the average treatment effect remains the same. Because the same set of five controls is being used, regardless of which treated units are being matched, the average post-treatment employment difference across the five pairs is unchanged.
In the third panel we return to the original order but change the distance metric effectively to require exact matching on the chain identity. In practice, this was done by adjusting the standard metric to multiply the square of the difference in chain by 100. Whereas before unit 5 (a New Jersey KFC with initial employment of 8) was matched to unit 20 (a Pennsylvania Burger King with equal initial employment), it is now matched to unit 17 (a Pennsylvania KFC with initial employment of 11). This adjustment in matches changes the estimate of the average treatment effect for the treated from +0.8 to -0.4.

18.7 THE BIAS OF MATCHING ESTIMATORS
We now return to the issue of the potential bias created by discrepancies between the pre-treatment covariates of the units within a matched pair. Consider the ith matched pair (i, mi), where i indexes the treated unit. The unit-level treatment effect for the treated unit (i.e., the unit to be matched, as opposed to the unit used as a match) is equal to i = Yi(1)-Yi(0). Because we can never simultaneously observe both potential outcomes for a given unit, we estimate this causal effect using the difference in observed outcomes for the two units of the matched pair:
^imatch = Yiobs - Ymobcis = Yi(1) - Ymic (0).
When the match is perfect, both units of this pair have covariate values equal to that for the matched unit, that is, Xi = Xmci . With inexact matching, however, Xi = Xmic . We call the difference in covariate values between the matched treated unit and its control match the matching discrepancy:
Di = Xi - Xmci .
Taking the super-population perspective, let
c(x) = Esp[Yi(0)|Xi = x], and t(x) = Esp[Yi(1)|Xi = x],
denote the super-population means for each potential outcome at covariate value X = x. If the matching discrepancy is equal to zero ­ an exact match ­ the expected difference in outcomes within the pair is equal to the average treatment effect conditional on Xi = x. That is, if Di = 0, then the expected difference between outcomes within the pair is equal to the super-population average treatment effect for units with Xi = x:
Esp Yiobs - Ymci Wi = 1, Xi = Xmci = x = Esp Yi(1) - Ymic (0) Xi = Xmic = x = t(x) - c(x) =  (x).

416

Matching Estimators

In general, with a non-zero matching discrepancy, the expectation of the matching estimator of the unit-level treatment effect, which is the difference in observed outcomes in the matched pair, will be equal to
Esp ^imatch Wi = 1, Xi, Xmci = Esp Yi(1) - Ymci (0) Xi, Xmic = t(Xi) - c(Xmic )
=  (Xi) + (c(Xi) - c(Xmci )).
We refer to the last term of this expression,
Bi = c(Xi) - c(Xmci ),
as the unit-level bias of the matching estimator. A matching discrepancy Di can lead to different levels of bias depending on the con-
ditional expectation of the control outcome, c(x). If this regression function does not depend on X, then clearly there is no discrepancy in these covariates that can introduce a bias. In general, the larger the absolute correlation between the covariates and the potential outcomes, the more bias a fixed matching discrepancy Di can introduce.
In practice it will be easier to find good matches if the distributions of the covariates in the treatment and control groups are similar, that is, if there is much overlap between the two distributions. In contrast, if the propensity scores are concentrated near the endpoints ­ for the treated units near a propensity score of 1 and for the control units near a propensity score of 0 ­ it will be difficult to find close matches.

18.8 BIAS-CORRECTED MATCHING ESTIMATORS

In cases where matching is imperfect, there are several model-based approaches, all
involving observed outcome data, one can use to attempt to reduce the unit-level bias
created by the matching discrepancies. Each of these methods uses the within-pair
pre-treatment covariate values Xi and Xmi, combined with additional model-based adjustments, in an attempt to further reduce biases associated with differences in covariates.
Here we introduce a general approach to bias adjustment and discuss its justification. In
Sections 18.8.1 through 18.8.3, we then discuss three specific methods for applying this
adjustment to the matching estimator. Again consider a matched pair (i, mi) where i indexes the treated unit, i = 1, . . . , Nt.
As discussed earlier, the unadjusted estimator of the unit-level treatment effect is equal to ^imatch = Yiobs - Ymobics, with expected value for this estimator, conditional on covariates and treatment indicators, equal to Esp[ ^imatch X, W] = t(Xi) - c(Xmic ). However, conditional on X and W, the super-population expected treatment effect for the matched unit (the treated unit i) is  (Xi) = t(Xi) - c(Xi). The difference is the unit-level bias for matched pair i:

Bi = Esp[Yi(1) - Ymic (0)|X, W] -  (Xi) = c(Xi) - c(Xmic ).

(18.5)

Three simple approaches have been proposed to reduce this bias, which modify the unadjusted unit-level estimate for the treatment effect, ^imatch, by subtracting an estimate of

18.8 Bias-Corrected Matching Estimators

417

the bias Bi in (18.5). Thus, instead of estimating the control outcome Yi(0) by the realized outcome for its match, Ymci (0), we use
Y^i(0) = Ymci (0) + B^ i,

which leads to the following bias-adjusted estimate of the average treatment effect:

^tadj

=

1 Nt

i:Wi=1

Yi(1) - Y^i(0)

1 =
Nt i:Wi=1

Yi(1) - Ymic (0) - B^ i .

Although it is conceptually straightforward to use more general functional forms, in
practice, and in all three methods discussed in the following sections, the bias adjustment is based on a simple linear regression estimate of the conditional bias Bi.4 Suppose the conditional mean of the potential outcome under the control treatment, c(x) = Esp[Yi(0)|Xi = x], is linear in the covariates:

c(x) = c + xc.

(18.6)

For the subsequent discussion, it will be useful to specify an analogous equation for the conditional expectation of the potential outcomes given treatment, possibly with different parameters:

t(x) = t + xt.

(18.7)

If Equation (18.6) holds, then the unit-level bias is Bi = (Xi - Xmci )c = Dic, where Di = Xi - Xmci , the matching discrepancy. More generally, this approach can be thought of as approximating the difference c(Xi) - c(Xmci ) by a function linear in Xi - Xmic . The three model-based approaches discussed here differ in the way they estimate the regression coefficients in this linear regression adjustment.
It is important to note that this approximation is conceptually distinct from the general regression approach discussed in Chapter 7. In that case we also approximate the regression function c(x) by a linear function. However, there we relied on this approximation not just locally but across the full covariate space. We therefore were concerned about the sensitivity of the results to the specification chosen (e.g., the linearity of the regression function) because the distributions of the covariates may differ substantially between the two treatment levels. The current setting is different. Through matching, we have created a subsample in which the distributions of the covariates are likely to be well balanced between the two treatments. Hence, whereas with the full sample the regression function may be used to predict relatively far out of sample, here it is only used locally, and the corresponding results should be less sensitive to minor changes in the specification of the regression function. This statement does not suggest that the specification no longer matters at all, just that it is likely to matter less.

4 It may be useful to use a more local estimate, for example, within strata defined by the covariates or by the propensity score.

418

Matching Estimators

18.8.1 Regression on the Matching Discrepancy
In the first bias-adjustment approach, we assume that the regression functions (18.6) and (18.7) are parallel:

c(x) = d + xd,

and

t(x) =  + c(x) =  + d + xd. (18.8)

We exploit this assumption by estimating the bias-adjustment coefficient d through a least squares regression of the within-pair difference in outcomes, ^imatch = Yiobs - Ymobics on the matching discrepancy, the within-pair difference in pre-treatment values, Di =
Xi - Xmic . To see why this works, consider the difference in observed outcomes, which for each
pair is our unadjusted estimate of the unit-level treatment effect, ^iunadj = Yiobs - Ymobics. Using the notation introduced in (18.8), we can write this difference as

Yiobs - Ymobics = i(Xi)

(18.9)

+ c(Xi) - c(Xmic )

(18.10)

+ (Yi(1) - t(Xi)) - Ymci (0) - c(Xmic ) .

(18.11)

This equation states that Yi - Ymci is equal to the average treatment effect (18.9), plus the bias due to the matching discrepancy (18.10), plus, for each member of the pair, the
difference between the observed outcome and its expected value, (18.11). Now let us
define the residual

i = (Yi(1) - t(Xi)) - Ymic (0) - c(Xmic ) ,
where i is equal to the sum (18.10) and (18.11). We can then write the within-pair difference in observed outcomes, under the linear specification in (18.8), as

Yiobs - Ymobcis =  + Xi - Xmci d + i =  + Did + i.

(18.12)

By definition, i will have zero mean conditional on X and W. Furthermore, because Di = Xi - Xmci is a function of X and W, it follows that i also has mean zero conditional on Di, for i = 1, . . . , Nt. Hence we can use ordinary least squares to estimate the regression function in Equation (18.12) by regressing the within-pair outcome difference on

the matching discrepancy, Di, which leads to the following coefficient estimates for the slope parameters:



-1 



^d = 

Di - D T · Di - D  

Di - D T · (Yiobs - Ymobcis) ,

i:Wi=1

i:Wi=1

where D = i:Wi=1 Di/Nt. We then use ^d to adjust the outcome for the match within each pair, Ymci (0): Y^i(0) = Ymic (0) + B^ i = Ymic (0) + Xi - Xmci ^d.

18.8 Bias-Corrected Matching Estimators

419

To calculate the bias-adjusted estimate of the average treatment effect, we then use these
adjusted values Y^i(0) in place of the observed values Ymci (0) in the standard equation for the estimated treatment effect:

^tadj,d

=

1 Nt

i:Wi=1

Yi(1) - Y^i(0)

=

1 Nt

i:Wi=1

Yi(1) - Ymic (0) - (Xi

- Xmic )^d

=1 Nt i:Wi=1

Yi - Ymci - Di^d

= ^tmatch - D^d.

(18.13)

18.8.2 Control Regression on the Covariates
In the second bias-adjustment approach, we estimate the regression function (18.6) using all control units within the matched sample. We then use these regression coefficients to adjust the observed outcome for the match in a direction toward the expected outcome if the unit and its match had equal covariate values Xi. Specifically, in this approach we estimate the regression function

Ymic = c + Xmci c + ci,

(18.14)

where 0,i = Ymci - 0(Xmic ). We estimate the regression using the control units in each of the Nt pairs. Thus, using the Nt controls, with outcomes Ym1 , . . . , YmNt and covariate values Xm1 , . . . , XmNt , we estimate c and c as



-1 



^c = 

(Xmci - Xm)T · (Xmic - Xm) 

(Xmci - Xm) · Ymic ,

i:Wi=1

i:Wi=1

and

^ c = Ym - Xm^c,

where Xm = i:Wi=1 Xmic /Nt, and Ym = i:Wi=1 Ymobcis/Nt. We use the estimated regression functions to adjust the potential outcomes for the
matches within each pair. The adjusted potential control outcome is equal to

Y^i(0) = Ymci (0) + (Xi - Xmci )^c.
Note that we do not replace the match control outcome by its value predicted by the regression function, Y^mic (0) = ^ c + Xmic ^c. Instead, we simply adjust the observed outcome for the match by a relatively small amount (Xi - Xmci )^c.5 The implied estimate

5 Note that this is a small adjustment whenever unit i is fairly well matched, that is, whenever the matching discrepancy Xi - Xmic is small.

420

Matching Estimators

for the bias-adjusted average treatment effect is thus

^tadj,c

=

1 Nt

i:Wi=1

=1 Nt i:Wi=1

Yi(1) - Y^i(0) Yiobs - Ymobcis - (Xi - Xmci )^c

= ^tmatch - D^c.

(18.15)

The difference with the expression in (18.13) is in the estimator ^c in (18.15) versus ^d in (18.13).

18.8.3 Parallel Regressions on Covariates
Like the first, the third approach for bias-adjusting the simple estimate of the average
treatment effect again restricts the slope coefficients to be equal in Equations (18.6)
and (18.7). To estimate the adjustment coefficients, however, instead of regressing the difference in observed outcomes, Yiobs - Ymobics, on the matching discrepancy Di, this approach instead estimates the regression function on the pooled sample of size 2 · Nt constructed by stacking the treatment and control elements of each of the Nt pairs, that is, by ignoring the matching structure.
More formally, for each unit in this pooled sample of 2 · Nt units (two from each matched pair), we record the unit's outcome, Y~i, its covariate value, X~ i, and an indicator for whether it was a treated or a control unit, W~ i. Note also that, by construction, we have exactly as many treated as control units in this pooled sample.
Given this artificial sample, we regress the outcome variable on a constant, the
covariate values, and the treatment status indicator:

Y~i = p + p · W~ i + X~ ip + i.

(18.16)

Then we estimate the average treatment effect as

^tadj,p

=

1 Nt

i:Wi=1

1 =
Nt i:Wi=1

Yi(1) - Y^i(0) Yiobs - Ymobcis - (Xi - Xmci )^ p

= ^tmatch - D^p,

(18.17)

which is numerically equivalent to the least squares coefficient ^p from the regression
(18.16). The difference with the adjustments in (18.13) and (18.15) is the least squares estimator ^p.

18.8.4 Bias-Adjustment for the Card-Krueger Data
Let us now see how these three bias-adjustment approaches work in our subsample of twenty observations from the Card and Krueger minimum wage data. Returning to our results from Section 18.6, the top panel of Table 18.4 gives the matched pairs, when we match, without replacement, the five treated (New Jersey) restaurants, using a greedy

18.8 Bias-Corrected Matching Estimators

421

algorithm and the sum-of-squared differences as our naive distance metric. For these
units, Table 18.5 presents some additional information: the covariate values (BK and
KFC, with KFC coded as 1, and initial employment) for the treated and control mem-
bers of each pair (Xi and Xmci ), the matching discrepancy Di, the outcome variables (Yiobs and Ymobcis), and the associated within-pair simple estimate of the treatment effect, ^unadj,i. For example, in the first pair, the treated unit, unit i = 1, is a Burger King with an initial employment of 22.5 workers, X1 = (0, 22. 5) , and its control match, unit m1 = 11, is also a Burger King with initial employment of 20.0, Xm1 = (0, 20. 0) . Hence the matching discrepancy for the first pair is D1 = (0, 2. 5) . For all three biasadjustment approaches, the adjustment would be zero if the matching were perfect with
zero matching discrepancies.
In the first bias-adjustment approach, we regress, for the Nt pairs, the simple difference in matched outcomes, ^unadj,i = Yiobs - Ymobics, on a constant and the matching discrepancies, Di1 and Di2. Using the five pairs listed in Table 18.5, the estimated regression function (listed in the first column of Table 18.6) is

Yiobs - Ymobics = -1. 30 - 1. 20 · Di,1 + 1. 43 · Di,2.
We can use these estimated regression coefficients to adjust the outcomes for the match within each pair, in this case the five controls. Following the approach in Section 18.8.1, our adjusted estimate of the unobserved potential outcomes therefore equals
Y^i(0) = Ymic (0) + (Xi - Xmci )^d.
Applying these coefficients to our data, for the first matched pair we observe the control outcome Ymob1s = 19.5 for unit 11 with covariate values Xm1,1 = 0 and Xm1,2 = 20.0. Because the covariate for the treated unit is X1 = (0, 22.5), the match discrepancy is D1 = (0, 2.5). Hence we adjust the imputed control outcome for the match, Y^1(0), from 19.5 to
Y^1(0) = Ym1 + D1^d = 19. 5 - 1. 20 · D1,1 + 1. 43 · D1,2 = 19. 5 - 1. 20 · 0 + 1. 43 · 2. 5 = 23. 1.

This gives an adjusted control outcome, Y^1(0), equal to Ym1(0) + 3. 6 = 19. 5 + 3. 6 = 23. 1, and an adjusted estimate of the unit-level treatment effect, ^1adj = Y1(1) - Y^1(0), equal to 16. 9. Following this same procedure for all five pairs, we find the adjusted control outcomes listed in Table 18.7. Averaging the corresponding adjusted estimates of the unit-level treatment effects gives a bias-adjusted estimate of the average causal effect for the New Jersey restaurants equal to 0.63 employees.
In the second bias-adjustment method, we estimate the regression function c(x) separately using the Nt matched control units to get ^c. Using our five pairs, regressing the five observed outcome values Ymobcis on a constant, Xmci ,1 and Xmic,2, gives the following coefficients (listed in Column 2 of Table 18.6):
Y^mci = 4. 21 + 2. 65 · Xmci ,1 + 0. 62 · Xmic,2.

422

Matching Estimators

Table 18.5. Matching Discrepancy, Match Order is 1,2,3,4,5, Metric is x12 + x22, Matching without Replacement, for the 20 Units from the CardKrueger New Jersey and Pennsylvania Minimum Wage Data

i mi Yiobs Ymobcis ^imatch Xi,1 Xi,2 Xmci ,1 Xmic,2 Di,1 Di,2

1 11 40.0 19.5 20.5 0 22.5 0 2 7 12.5 17.0 -4.5 1 14.0 1 3 15 20.0 22.5 -2.5 0 37.5 0 4 8 3.5 10.5 -7.0 1 9.0 1 5 20 5.5 8.0 -2.5 1 8.0 0

20.0 0 2.5 13.8 0 0.2 32.5 0 5.0
8.5 0 0.5 8.0 1 0

Table 18.6. Bias-Adjustment Regression Coefficients for the 20 Units from the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

Difference Regression Control Regression Pooled Regression

(Approach #1)

(Approach #2)

(Approach #3)

Regression coefficients

Intercept

-1.30

4.21

12.01

Treatment indicator

-

-

1.63

Restaurant chain Initial employment

-1.20 1.43

2.65

-7.32

0.62

0.39

Table 18.7. First Bias-Adjustment Approach: Difference Regression for the 20 Units from the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

i mi Yi(1) Ymic (0) Xi,1 Xi,2 Xmci ,1 Xmci ,2 Di,1 Di,2 ^dT Di Y^i(0)

1 11 40.0 19.5 0 22.5 0 20.0 0 2.5 3.6 23.1

2 7 12.5 17.0 1 14.0 1 13.8 0 0.2 0.3 17.3

3 15 20.0 22.5 0 37.5 0 32.5 0 5.0 7.1 29.6

4 8 3.5 10.5 1 5 20 5.5 8.0 1

9.0 1 8.0 0

8.5 0 8.0 1

0.5 0.7 11.2 0 -1.2 6.8

^tmatch = +0. 8

^tadj = -1. 3

For the first pair this gives an adjusted control outcome of
Y^1(0) = Ymob1s + 2. 65 · D1,1 + 0. 62 · D1,2 = 19. 5 + 2. 65 · 0 + 0. 62 · 2. 5 = 21. 1.
Following this same procedure for the remaining four pairs (summarized in Table 18.8), and averaging the unit-level results, leads to a bias-adjusted estimate of the average causal effect for the New Jersey restaurants equal to 0. 74 employees.
In the third bias-adjustment method, we pool the data (so we have 2 · Nt observations), and regress the unit-level outcome Y~i on a constant, the two covariates X~ i,1 and X~ i,2, and

18.8 Bias-Corrected Matching Estimators

423

Table 18.8. Second Bias-Adjustment Approach: Control Regressions for the 20 Units from the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

i mi Yi(1) Ymic (0) Xi,1 Xi,2 Xmic,1 Xmic,2 Di1 Di2 ^cT Di Y^i(0)

1 11 40.0 19.5 0 22.5 0 20.0 0 2.5 1.5 21.0

2 7 12.5 17.0 1 14.1 1 13.8 0 0.2 0.1 17.1

3 15 20.0 22.5 0 37.5 0 32.5 0 5.0 3.1 25.6

4 8 3.5 10.5 1 9.0 1

8.5 0 0.5 0.3 10.8

5 20 5.5 8.0 1 8.0 0

8.0 1 0 2.7 10.7

^tmatch = +0. 8

^tadj = -0. 7

Table 18.9. Third Bias-Adjustment Approach: Pooled Regression for the 20 Units from the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

i mi Yi(1) Ymci (0) Xi,1 Xi,2 Xmci ,1 Xmci ,2 Di1 Di2 ^sT Di Y^i(0)

1 11 40.0 19.5 0 22.5 0 20.0 0 2.5 1.0 20.5

2 7 12.5 17.0 1 14.0 1 13.8 0 0.2 0.1 17.1

3 15 20.0 22.5 0 37.5 0 32.5 0 5.0 1.9 24.4

4 8 3.5 10.5 1 5 20 5.5 8.0 1
^tmatch = +0. 8

9.0 1

8.5 0

8.0 0

8.0 1

^tadj = +1. 6

0.5 0.2 10.7 0 -7.3 0.7

an indicator for the treatment received, W~ i. The results for this regression using our five pairs (summarized in Column 3 of Table 18.6) are
Y~i = 12. 01 + 1. 63 · W~ i - 7. 32 · X~ i,1 + 0. 39 · X~ i,2.
In this method, as in the first, we can read the bias-adjusted estimate of the average causal effect for the New Jersey restaurants directly from these results, here as the estimated coefficient on the treatment indicator W~ i, equal to +1. 63 employees. We can find this same result by using these coefficients to adjust the observed control outcomes. For the first pair the adjustment is now equal to
B^ i = -7. 32 · D1,1 + 0. 39 · D1,2 = -7. 32 · 0 + 0. 39 · 2. 5 = 0. 98,
and the adjusted control outcome is therefore Y^1(0) = Ym1(0) + 0. 98 = 20. 48. Doing the same across all pairs and averaging (Table 18.9), we get a bias-adjusted estimate equal to +1. 63, as expected.
We conclude this section with some general comments regarding the choice between the three bias-adjustment methods just discussed. There are some theoretical arguments in favor of the second. With sufficient data, one can make the associated regression function more flexible by including higher-order terms, allowing for approximations for t(x) that become arbitrarily accurate. A comparable regression involving the differenced covariates (the first method) would have to involve differences in higher-order moments of the covariates ­ rather than higher-order moments of the matching discrepancy ­ in order to obtain accurate approximations of c(Xi) - c(Xmic ).

424

Matching Estimators

In practice, however, the choice between the three bias-adjustment approaches is likely to be less important than the decision whether or not to use a bias-adjustment method. In many cases, all three methods are preferable to that based on the simple average of within-pair differences, and, from limited experience, all are likely to be closer to one another than to the unadjusted estimate. In our example with only five matched pairs this is not the case, but as we will see in Section 18.12, when we expand the analysis to the full Card and Krueger data set, this similarity of answers does in fact hold.

18.9 MATCHING WITH REPLACEMENT
In this and the next two sections we study the second set of modifications to the basic matching estimator. This set of modifications includes changes to the matching approach in which there is no longer a single, distinct, match for each treated unit, either because we match and replacement control units (this section), we use more than one match (Section 18.10), or we match both treated and control units (Section 18.11).
In this section we consider matching with replacement. Allowing a control unit to be used as a match more than once has both advantages and disadvantages. The first advantage is that it eases the computational burden. Now finding an optimal set of matches is straightforward: for each treated unit we choose its closest match within the entire set of control units. Recall that, for matching without replacement, the choices were either an optimal matching algorithm that was computationally cumbersome in large samples, or a sequential (greedy) matching algorithm. When we match with replacement, there is no such trade-off.
The second advantage of matching with replacement is that matching with replacement may reduce the bias of the matching estimators. Because we no longer restrict the set of matches, and thus allow some matches that were not available with distinct control matches, the discrepancy in pre-treatment covariates across matched pairs is reduced.
A disadvantage of matching with replacement is that the sampling variance of estimators based on matching with replacement is typically larger than the sampling variance of estimators based on matching without replacement. Intuitively, because control units can be used as matches more than once, the resulting estimator is typically based on fewer control units, which increases its sampling variance. A second drawback of matching with replacement is that the sampling variance is more difficult to estimate because using a control more than once creates correlations across pairs that share the same control matches.
Initially we ignore the possibility of ties. Let the first treated unit to be matched be unit i = 1. For this unit the optimal match is now mc1,
m1c = argmini Ic X1 - Xi .
Solving the same minimization problem for all treated units, we obtain a set of Nt pairs (i, mi), for i = 1, . . . , Nt. This set does not depend on the ordering of treated units, because the set from which we choose the match does not change. The average treatment

18.10 The Number of Matches

425

effect for the treated is then estimated as

^trepl

=

1 Nt

i:Wi=1

Yiobs - Ymobcis

=1 Nt i:Wi=1

Yi(1) - Ymic (0)

.

(18.18)

Now that we are matching with replacement, an important variable is the number of

times each control unit is used as a match ­ let us call this L(i) =

N j=1

1jMic

for

control unit i  Ic; L(i) = 0 for all i  It and a non-negative integer for all i  Ic, with

i L(i) = Nt.6 (When matching without replacement, L(i)  {0, 1} for all units.)

The simple matching estimator of the sample average treatment effect on the treated

can be written as

^trepl

=

1 Nt

N i=1

=1 N Nt i=1

Wi · Yiobs - (1 - Wi) · L(i) · Yiobs Wi · Yi(1) - (1 - Wi) · L(i) · Yi(0) .

(18.19)

Notice that here we sum over all N units in the sample ­ hence the notation Yi(0) rather than Ymi(0) ­ but continue to divide by Nt, the number of treated units and thus the number of matched pairs. This representation illustrates that the matching estimator is a weighted average of treated and control outcomes within the full sample. For the treated units the weights are all 1/Nt, and for the control units the weights sum to one, but vary, with the value of the weight reflecting each control units' relative value as a comparison unit for the treated units.

18.10 THE NUMBER OF MATCHES
Although the discussion so far has focused on pairwise matching, where each observation is matched to a single unit, it is also possible to use multiple matches. Especially when the pool of possible control units is large relative to the number of treated units, one may be able to improve the precision of the resulting estimator by using more than one match. However, using multiple matches tends to increase the bias of the resulting estimator by increasing the average covariate discrepancy within pairs. With a sufficiently large number of possible matches, this need not be a problem, but it should be clear that using multiple matches does not come without possible costs.
Although the precision of the matching estimator can be improved by using multiple matches, the improvement is somewhat limited. To see this, consider the case where we match each treated unit to M controls. Let Mci represent the set of matches for unit i, with cardinality #Mci = M. (Before we considered the case with a single match so that the set Mci contained just a single element.) Suppose we have sufficient observations to find M exact matches for each treated unit without using the same control more than once.
6 Remember that we are still assuming no ties. As we discuss later, once we allow ties, L(i) can take on non-integer values.

426

Matching Estimators

Let c2 and t2 be the super-population variances of Yi(0) and Yi(1) conditional on the covariates used for matching, respectively (implicitly assuming homoskedasticity with

respect to the covariates). In that case the simple matching estimator using M matches is

equal to





^tmatch,M

=

1 Nt

Nt
Yi(1) -
i=1

1 M

Yj(0) ,
jMc(i)

and the sampling variance of this estimator is

V(^tmatch,M )

=

1 Nt

t2

+

c2 M

.

If we simplify by assuming that the two variances are equal, c2 = t2, the proportional reduction in sampling variance from using M matches rather than just a single match is
equal to

V(^tmatch,1) - V(^tmatch,M) V(^tmatch,1)

=

M-1 .
2M

Thus, using two matches reduces the sampling variance by 25% relative to using a single match, and using three reduces it by 33%. Increasing M, the reduction in sampling variance will rise toward 50%, but no higher. Thus, going beyond two or three matches can only lead to small improvements in the sampling precision in this simple setting.
We now describe how to implement the matching estimator using the M nearest matches. Let mic,k  Ic be the index for the control unit that solves

1
jIc

Xi -Xmic,k

= k,

(18.20)

that is, mic,k is the index of the control that is the kth closest unit to observation i. The set Mci now includes the closest M matches for unit i:
Mci = {mic,1, mic,2, . . . , mMi }.

Finally, defining

Yi(0)

=

1 M

i Mci

Yiobs,

we can define the matching estimator for the average treatment effect on the treated as

^tmatch,M

=

1 N

iIt

Yi(1) - Yi(0)

=1 N N i=1

Wi

-

L(i) M

· Yiobs.

(18.21)

When there are ties for the Mth closest control match for treated unit i, this will mean that more than M units are at least as close to unit i as is unit miM. If, as before, we use

18.11 Matching Estimators for the Average Treatment Effect

427

all ties, the number of units matched to unit i can therefore be greater than M. In this case, let Mi be the number of matches for unit i, again letting Mc(i) denote the set of indices of those matches. The estimator is then the same as in Equation (18.21), but with
Mi replacing M.

18.11 MATCHING ESTIMATORS FOR THE AVERAGE TREATMENT EFFECT FOR THE CONTROLS AND FOR THE FULL SAMPLE

So far we have focused the discussion on estimating the average effect of the treatment on the subpopulation of treated units. However, especially once we allow for matching with replacement, we can apply the same ideas to estimate the average effect of the treatment for the control units. Combining estimates for the average effect of the treatment for the controls and for the treated, we can also estimate the overall average effect of the treatment. In this section we discuss details of these extensions.
We focus on the bias-adjusted matching estimator for the treated units, based on matching with replacement, with a single match, and the bias adjustment based on the control regression:

^tadj

=

1 Nt

i:Wi=1

Yiobs - Ymobcis - (Xi - Xmci )^c

.

Here the matching set of controls for treated unit i is Mic = {mic}, with

(18.22)

mi = arg min
i :Wi =0

Xi - Xi

,

based on, say the Mahalanobis metric and matching with replacement. The adjustment coefficient ^c is based on the regression of the outcomes for the Nt control matches on the covariates as in (18.15).
Let us first focus on estimating the average effect of the treatment for the controls. The
analogous estimator is

^cadj

=

1 Nc

i:Wi=0

Ymobtis - Yiobs - (Xmit - Xi)^t

.

(18.23)

Here the set of (treated) matches for control unit i is Mit = {mit}, with mit the closest unit with the opposite treatment level:

mit

=

arg
i

min
:Wi =1

Xi - Xi

,

based on, say the Mahalanobis metric and matching with replacement. The adjustment coefficient ^t is based on the regression of the outcomes for the Nc treated matches on the covariates as in analogy with (18.15).
Next, consider the case where we are interested in using a matching estimator for the average effect of the treatment for the entire sample, rather than only for the subsample of treated units or only the subsample of controls. Here we simply sum the estimates for

428

Matching Estimators

the average treatment effect for the controls, ^cadj, and the average treatment effect for the treated, ^tadj, weighted by their shares in the sample, Nc/N and Nt/N, respectively, leading to

^ adj

=

Nc Nc + Nt

· ^cadj

+

Nt Nc + Nt

· ^tadj.

(18.24)

18.12 MATCHING ESTIMATES OF THE EFFECT OF THE MINIMUM WAGE INCREASE

Now we return to the full Card-Krueger data set with 347 restaurants, 279 in New Jer-

sey and 68 in Pennsylvania. First we compare, for four different matching methods,

the normalized average within-match difference in covariates. The second column in

Table 18.10 gives the normalized differences in the seven covariates in the full sample,

identical to those presented in Column 8 in Table 18.1. We then present, for various

matching estimators, the average difference in covariates for the matched samples, nor-

malized by (sc2 + s2t )/2, where sc2 and s2t are calculated on the full sample to facilitate the comparison with the balance in the full sample. Because we are primarily interested

in the effect of the minium wage increase in New Jersey, we initially match only the 279

New Jersey restaurants, not the 68 Pennsylvania restaurants.

The first matching estimator uses a single match, with replacement, using the Maha-

lanobus metric based on the average of the within-treatment group sample covariance

matrices. The third column in Table 18.10 reveals that this greatly reduces the imbal-

ance in the seven covariates. In the full sample one normalized difference is as large as

0.28, and four out of the seven normalized differences exceed 0.10. In the matched sam-

ple, all normalized differences are less than 0.10, with the largest equal to 0.07. Next,

we use the Euclidean metric, ignoring correlations between the covariates. Third, in an

attempt to decrease the sampling variance of the corresponding estimator, we increase

the number of matches to three, albeit at the risk of increasing bias. And fourth and last,

again with only one match, we use the Mahalanobis metric, but modified as discussed

in Section 18.5 to first match exactly on restaurant chain. The results in Columns 4­6

in Table 18.10 show that the choice of matching method itself does not matter much

for covariate balance in this example: all four methods lead to greatly improved balance

compared to the full sample.

Table 18.11 reports the estimates of the average causal effect of the minimum wage

increase on the New Jersey restaurants. To provide a baseline estimate, Table 18.11 first

reports simple ordinary least squares estimates from the full sample, first without covari-

ates

(the

simple

difference

between

average

outcomes

for

treated

and

controls,

Y

obs t

-

Y

obs c

),

and second

with

the six covariates,

initial

empl,

burger

king,

kfc,

roys, initial wage, and time until raise (omitting wendys, because the

four chain indicators add up to one). Ignoring the covariates gives an estimated treat-

ment effect of -0.22 employees. Using covariates the estimator switches signs, to +1.35

employees.

18.12 Matching Estimates of the Effect of the Minimum Wage Increase

429

Table 18.10. Average Normalized Covariate Differences for the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

Full Sample

Matched Samples

Variable

Euclidean Euclidean Mahalanobis Exact on Chain

Euclid on Others

M=1 M=4

M=1

M=1

Initial employment Restaurant chain:
Burger King KFC Roys Wendys Starting wage Time till first raise

-0.28
-0.02 0.20 0.00
-0.18 -0.05 -0.11

0.06
-0.01 0.00 0.01 0.00 0.07
-0.01

0.10
-0.01 0.00 0.01 0.00
-0.01 0.05

0.06
-0.01 0.00 0.01 0.00 0.06
-0.01

0.07
0.00 0.00 0.00 0.00 0.07 -0.01

Table 18.11. Estimated Effect of Minimum Wage Increase on Employment for the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

Estimand

Method

M

Metric

Estimate

OLS, no controls

-0.22

New Jersey

OLS, controls

1.35

New Jersey

Match

1

Mahalanobis

0.89

New Jersey

Match

4

Mahalanobis

1.01

New Jersey

Match

1

Euclidean

0.93

New Jersey

Match

1 Exact on Chain, Mahal. on Others 0.92

Pennsylvania

Match

1

Mahalanobis

0.63

All

Match

1

Mahalanobis

0.84

New Jersey

Bias adj, dif regress 1

Mahalanobis

0.51

New Jersey Bias adj, control regress 1

Mahalanobis

0.71

New Jersey Bias adj, pooled regress 1

Mahalanobis

0.79

The next four estimates rely on the four matching methods with replacement for which we gave the covariate balance in Table 18.10 to motivate adjusting for covariate differences. The first matching estimator listed in Table 18.11 is for the average treatment effect for the New Jersey restaurants based on the Mahalanobis metric and a single match. As one can see in Table 18.11, this approach gives an estimated treatment effect equal to +0.89 employees. When we increase the number of matches to four, this gives an estimated treatment effect of +1.01.
Next consider the matching estimator with replacement based on the Euclidean metric and one match; this gives an estimated average effect for the restaurants in New Jersey equal to +0.93 employees. Thus, as we might predict, given comparable covariate distributions in the two matched samples, in this data set, using Mahalanobis versus the Euclidean distance has little effect because the covariates are nearly uncorrelated. Insisting that the matches are exact on the four-valued indicator for restaurant chain before matching the other covariates, the estimate drops slightly to +0.92 employees.

430

Matching Estimators

Table 18.12. Bias-Adjusted Matching Estimators for the Card-Krueger New Jersey and Pennsylvania Minimum Wage Data

Variable

Regression Coefficients

Difference Control Pooled Regression Regression Regression

Initial employment Restaurant chain:
KFC Roys Wendys Starting wage Time till first raise

0.50
-23.27 - - -3.20 -0.01

0.12
4.05 -3.62 -3.23
7.07 0.12

0.35
2.03 -3.03 -2.00
2.13 0.07

^tadj

0.51

0.71

0.79

The next two entries in Table 18.11 report matching estimates of the average treatment effect for the controls ­ the expected effect on employment levels if Pennsylvania were to institute a comparable minimum wage increase ­ and the average treatment effect overall. Matching using the Mahalanobis metric and a single match gives an average effect for the restaurants in Pennsylvania equal to +0.63 employees and a sample average effect estimator of +0.84. Hence neither estimate varies substantially from our estimate of the average treatment effect for the New Jersey restaurants.
Returning to the original matched sample, based on a single match and the Euclidean metric, we explore the effect of using the bias-adjustment approaches discussed in Section 18.8. The estimated regression coefficients are reported in Table 18.12. When we apply the first approach ­ regressing the within-pair outcome difference Yiobs - Ymobis on the matching discrepancy Di ­ this gives a bias-adjusted estimate of the average effect for the New Jersey restaurants equal to +0. 51 employees. Using the second approach, estimating the bias-adjustment coefficients by estimating c(x), we get an estimated treatment effect equal to +0. 71 employees. Using the third approach, estimating the bias-adjustment coefficients by estimating a regression using the pooled 2 · Nt observations, gives an estimate of +0. 79.
Overall, this exercise with a full data set illustrates the possible benefit of using the matching approach ­ its robustness to minor changes in its implementation. Unlike the two naive least squares estimates, which are very different from one another (even with different signs), all of the matching estimators are relatively close to one another, despite their conceptual differences. This robustness in this one example does not imply that these estimates are correct. But, as seen in this example, their robustness is a possible attraction of using matching methods in observational studies.

18.13 CONCLUSION
In this chapter we discuss matching methods for estimating causal effects. Whereas in Chapter 15 we discussed matching as a method for obtaining samples balanced in terms

Notes

431

of covariate distributions, here we focused on the use of matching methods to construct estimators. We discussed matching with and without replacement, as well as cases where the estimand is the effect for the treated units, the control units, or the overall average causal effect. We looked at different matching metrics and discussed the differences between them, and the use of linear regression methods on the set of units chosen by matching. Applying these methods to a data set collected by Card and Krueger suggested that these methods lead to robust estimates.

NOTES
There is a large literature on matching in statistics and social sciences, starting with more informal discussions (e.g., Peters and Van Voorhis, 1941, and Cochran, 1965) and continuing to the recent, more rigorous literature, that we view as starting with Cochran (1968), followed by Rubin (1970, 1973a, 1976ab). The literature continues at this moment, and more developments are likely. See Rubin (2006) for a number of influential papers going back to the early 1970s, and the introductions therein for a personal overview. Rosenbaum (1989ab, 1995, 2002, 2009) contain detailed discussions of various aspects of matching methods. For formal results in the econometrics literature see Abadie and Imbens (2006, 2009, 2012), and for an overview of the econometric literature, see Imbens (2004) and Imbens and Wooldridge (2009).
Gu and Rosenbaum (1993) discuss various matching algorithms, including optimal algorithms, as well as greedy algorithms that use sequential matching. They make the distinction between evaluating matching methods in terms of distance between matched units and in terms of balance in distributions, without regard to which units are matched (see also Rosenbaum and Rubin, 1984). Gu and Rosenbaum also suggest ordering the units by the propensity score before matching. Whereas in Chapter 15 we focused on global balance, in this chapter the goal is to estimate treatment effects. Cochran and Rubin (1973), Rubin (1973b, 1979), Quade (1982), Rubin and Thomas (2000), Espindle (2004), Abadie and Imbens (2006, 2009), and Rubin and Stuart (2006) discuss various aspects of matching. Gutman and Rubin (2014) discuss bias removal through the combination of spline regression and matching. Our discussion of the various specific bias-reduction methods in this chapter follows partly the discussions in Rubin (1973b) and Abadie and Imbens (2011). Abadie and Imbens (2006) establish large-sample properties regarding the bias of matching estimators with and without bias reduction. Abadie, Drukker, Herr, and Imbens (2003) describe implementations in STATA.
Most of the statistical literature has focused on matching without replacement, so that matched pairs are distinct and the focus is on average effects for the subpopulation of the treated units. Matching with replacement, which introduces complications when estimating sampling variances due to the common units across matched pairs, is discussed extensively in Abadie and Imbens (2006, 2008, 2009, 2010, 2012). We address sampling variance estimation in Chapter 19.
Other recently developed matching methods include genetic matching (Diamond and Sekhon, 2013), entropy matching (Hainmueller, 2012), and optimal full matching (Hansen and Klopfer, 2006). Heckman, Ichimura, and Todd (1997, 1998) study kernel

432

Matching Estimators

matching methods where the multiple matches are weighted by their distance to the units being matched.
Matching on the estimated propensity score is discussed in Rosenbaum and Rubin (1983a, 1984). Formal asymptotic properties for such matching methods are derived in Abadie and Imbens (2012). These include the asymptotic variances for matching estimators for the average effect and the average effect for the treated. Influential applications include Dehejia (2005ab), Dehejia and Wahba (1999, 2002), Lechner (2002), and Smith and Todd (2001, 2005).
There are extensive simulation studies of matching methods in the literature. Cochran and Rubin (1973) focus on the average effect of the treatment for the treated, comparing regression estimators, matching estimators, and matching estimators with bias adjustment based on control regressions. Rubin (1973b) studies the properties of matching estimators for the average effect for the treated using the range of regression methods for bias adjustment discussed in the current chapter. Rubin (1979) also focuses on various bias adjustment methods in combination with single-nearest-neighbor matching. Rubin and Thomas (2000) compare covariate and propensity score matching methods, both in combination with regression adjustments. Waernbaum (2010) compares doubly robust estimators and matching estimators. Abadie and Imbens (2009) look at matching estimators with a substantial number of covariates and study the effect of bias adjustments based on linear regression. Fro¨lich (2004ab), Zhao (2004), and Busso, DiNardo, and McCrary (2009) compare matching and weighting estimators. A common finding in these simulations is that the combination of regression adjustment with matching is superior to simply matching.
An alternative matching strategy uses outcome data to form matches based on best predictors of the outcomes given covariates. Such "predictive mean matching" strategies, also used in general missing data settings, are discussed in Rubin (1986b), Heitjan and Little (1991), Hansen (2008), and Fro¨lich (2004).
Software for particular matching methods is available in R, Matlab, and STATA and at various websites for the authors of the articles cited previously. See Becker and Ichino (2002), Abadie, Drukker, Herr, and Imbens (2003), and Sekhon (2004­2013).
Card and Krueger (1994) do not use matching methods in their original analysis of the minimum wage data. Instead they use difference-in-difference methods. Rosenbaum (2002) re-analyzes their data using matching methods. The Card and Krueger data are available at http://www.princeton.edu/.
The employment variables used in this discussion are created as follows: initial employment = emppt × 0. 5 + empft, and final employment = emppt2 × 0. 5 + empft2, where emppt refers to part-time employees, empft to full-time employees, and "2" refers to the post-minimum-wage measures. We use only those observations with complete data for each of these four employment variables, as well as for the other three matching variables.

CHAPTER 19
A General Method for Estimating Sampling Variances for Standard Estimators for Average Causal Effects
19.1 INTRODUCTION
In Chapters 17 and 18, two general frequentist approaches for estimating causal effects were discussed, with special focus on estimating average causal effects. In order to conduct inference in those settings, it is important to have methods for estimating sampling variances so that we can construct large-sample confidence intervals. In the current chapter we discuss such methods. In doing so, a number of issues arise.
The first issue we raise concerns the choice of estimand. If we are interested in the average effect of the treatment, we need to be explicit about whether we are interested in the average effect in the sample, or in the average effect in the super-population from which the sample is hypothetically randomly drawn. Although this choice is generally immaterial for the estimation of causal effects, the associated sampling variances generally differ, even in large samples, and so will the corresponding estimators for the sampling variances, at least in settings allowing for heterogeneity in the causal effects. Thus, in such settings, the researcher faces a choice regarding the estimand and the estimator for the associated sampling variance.
Second, we face the choice as to whether we should construct estimators for the sampling variance tied to the specific method for estimating the average treatment effects or estimators that apply more generally. In the current chapter we emphasize the second approach, exploiting some of the properties shared by most standard estimators for average causal effects, and develop a general method for estimating sampling variances for such estimators. A key insight is that nearly all the estimators discussed in the previous chapters, as well as most others proposed in the literature, have a common structure. These estimators can be written as the difference between two terms, both weighted averages of observed outcomes. The first term is a weighted average of the observed outcomes for the treated units, and the second term is a weighted average of the observed outcomes for control units. The weight on the observed outcome for unit i depends on the level of the treatment for unit i, the levels of the treatment assignment for the other units, and the values of the set of pre-treatment variables (including the pre-treatment variables for other units). The weight is free, however, of dependence on any missing or observed potential outcomes for any unit. In addition, the weights in the first term (the weighted sum of the treated units) sum up to one, and the weights in the second term (the
433

434

Sampling Variances for Standard Estimators for Average Causal Effects

weighted sum of the control units) sum up to one. As a result, these estimators share the following three desirable properties, which we collectively refer to as affine consistency: (i), adding a constant ct to all observed outcomes for treated units increases the estimated average causal effect by ct; (ii), adding a constant cc to all observed outcomes for control units decreases the estimated average effect by cc; and (iii), changing the scale of the outcome by multiplying all observed outcomes by a constant cs changes the estimated average effect by a factor cs. All standard estimators for average causal effects proposed in the literature have this form and differ only in the functional form of the dependence of the weights on the treatment assignments and pre-treatment variables.
The sampling variance of any affinely consistent estimator for average treatment effects can be written as a simple function of the conditional unit-level potential outcome variances given covariates, the covariate values, and the treatment indicators. We discuss a matching-based method for estimating these unit-level conditional variances, using ideas from Chapter 18. We discuss how simple versions of these matching estimators for the unit-level variance may be improved by bias-adjustment methods. We also discuss, for both the blocking and the matching estimators discussed in detail in Chapters 17 and 18, specific estimators for the sampling variance appropriate for the particular estimation methods. Other options for estimating the sampling variances discussed in the current chapter include resampling methods such as the bootstrap, although there is both theoretical and simulation evidence that such methods may not work well for matching estimators.
To discuss the properties of the methods for estimating sampling variances in this chapter, we take a super-population perspective, where the sample of N units is viewed as a random sample from an infinite super-population, with the random sampling and randomization of the assignment vector given covariates together generating a joint distribution on the quadruple of covariates, treatment indicator, and the two potential outcomes. We should also note that the perspective taken here is entirely frequentist. Alternative approaches use multiple imputation to simulate draws of the missing potential outcomes under a Bayesian model on the potential outcomes, but currently there are only a few examples of such approaches in the literature, although they appear promising.
The data set used in this chapter to illustrate the methods is the Imbens-RubinSacerdote lottery data set we previously used in Chapters 14 and 17. We briefly revisit these data in Section 19.2. In Section 19.3 we discuss possible estimands, and the implications the choice of estimand has for the sampling variance of estimators. In Section 19.4 we formulate the common structure of standard estimators for average causal effects. Next, in Section 19.5, we derive the general expression for the sampling variance conditional on covariates and treatment assignments. In Sections 19.6 we propose estimators for the unit-level conditional sampling variance, including methods that use regression adjustment to account for inexact matching. In Section 19.7 we develop estimators for the sampling variance for the estimator for the sample average causal effect. In 19.8 we modify the methods for settings where the focus is on the average effect for the subsample of treated units. In Section 19.9 we discuss the problem of estimating the sampling variance when the focus is on estimating the super-population average treatment effect. In Section 19.10 we discuss two alternatives to the matching-based sampling variance estimators: first, one based on covariance adjustment methods, and second, methods based on resampling techniques such as the bootstrap. Section 19.11 concludes.

19.2 The Imbens-Rubin-Sacerdote Lottery Data

435

Table 19.1. Summary Statistics for the Trimmed Sample, IRS Lottery Data

Covariate
Year Won # Tickets Age Male Education Work Then Earn Year -6 Earn Year -5 Earn Year -4 Earn Year -3 Earn Year -2 Earn Year -1 Pos Earn Year -6 Pos Earn Year -5 Pos Earn Year -4 Pos Earn Year -3 Pos Earn Year -2 Pos Earn Year -1

Losers (Nc = 172) Winners (Nt = 151) Nor

Mean (S.D.) Mean (S.D.)

Dif

6.40 2.40 51.5 0.65 14.01 0.79 15.5 16.0 16.4 16.8 17.8 18.4 0.71 0.70 0.71 0.70 0.70 0.72

(1.12) (1.88) (13.4) (0.48) (1.94) (0.41) (14.0) (14.4) (14.9) (15.6) (16.4) (16.6) (0.46) (0.46) (0.46) (0.46) (0.46) (0.45)

6.32 3.67 50.4 0.60 13.03 0.80 13.0 13.3 13.4 14.3 14.7 15.4 0.71 0.74 0.74 0.72 0.72 0.71

(1.18) (2.95) (13.1) (0.49) (2.21) (0.40) (12.4) (12.7) (12.7) (13.3) (13.8) (14.4) (0.46) (0.44) (0.44) (0.45) (0.45) (0.46)

-0.06 0.51
-0.08 -0.11 -0.47
0.03 -0.19 -0.20 -0.22 -0.18 -0.20 -0.19 -0.00
0.10 0.06 0.03 0.05 -0.01

19.2 THE IMBENS-RUBIN-SACERDOTE LOTTERY DATA
We illustrate the ideas in this chapter using the Imbens-Rubin-Sacerdote lottery data, previously used in Chapters 14 and 17. The specific sample we use in this chapter is trimmed using the propensity score, following the method discussed in Chapter 16, which leaves us with a sample of size N = 323, of whom Nc = 172 are "losers" (people who won only small, one-time prizes) and Nt = 151 are "winners" (people who won big prizes, paid out in yearly installments over twenty years). Table 19.1 presents summary statistics for the trimmed sample for all eighteen basic pre-treatment variables, including the averages and standard deviations by treatment status, and the normalized differences (Xt - Xc)/ (st2 + s2c)/2. (Note that these normalized differences are based on sample variances in the trimmed sample, in contrast to the normalized difference in Table 17.1 in Chapter 17, where the focus was on the change in normalized differences when going from the full sample to the trimmed sample.)
As before, we are interested in the average effect of winning a big prize in the lottery versus being a loser on subsequent earnings for some set of units to be specified subsequently. The specific outcome we use is the average of yearly earnings over the first six years after winning the lottery, measured by averaging social security earnings in thousands of 1995 dollars. We apply three estimators for average treatment effects to this sample. First, we implement the blocking estimator described in detail in Chapter 17 with the tuning parameters recommended in that chapter. As reported in Chapter 17, this leads to five subclasses based on the estimated propensity score and, after least squares

436

Sampling Variances for Standard Estimators for Average Causal Effects

regression in each subclass with the full set of eighteen covariates, a point estimate for the average treatment effect equal to a reduction in annual labor earnings of 5.74 (in thousands of 1995 dollars). Second, we apply a bias-adjusted matching estimator discussed in Chapter 18. We use the Mahalanobis metric based on all eighteen covariates with a single match (M = 1), with replacement, followed by bias-adjustment based on all eighteen covariates; this leads to a point estimate of -4.54. Third, we use the same matching estimator with M = 4 matches, leading to a point estimate of -5.03.

19.3 ESTIMANDS

First let us discuss the choice of estimand. This discussion builds on the discussion of finite-sample and super-population average treatment effects in the context of randomized experiments in Chapter 6, but in the current context, there are some additional implications of this choice that are often ignored in the empirical literature. Recall the definition of the finite-sample average effect of the treatment, averaged over the N units in the finite sample,

fs

=

1 N

N i=1

Yi(1) - Yi(0)

,

and the super-population average treatment effect,

sp = Esp Yi(1) - Yi(0) = Esp fs ,

where, as before, the subscript "sp" on the expectation operator indicates that the expectation is taken over the distribution induced by random sampling from an (infinite) super-population. In most of this chapter we focus on average effects for the entire sample or population, rather than for the subsample or subpopulation of the treated. Conceptually the extension to the case where the focus is on the average effect for the treated is straightforward, and we discuss this extension in Section 19.8.
The difference between the two estimands, fs and sp, is not important for estimation in a setting where we have a random sample from the population because the random sampling implies sp = Esp[fs]; this in turns implies that an estimator ^ that is attractive for estimating the sample average treatment effect is, in this setting, also attractive for estimating the population average effect. Therefore, the researcher need not make a distinction between the estimands for the purpose of point estimation. The difference between the estimands, fs and sp, is important, however, for inference (i.e., interval estimation): the sampling variance for a generic estimator ^ is

VW ^ = EW ^ - fs 2 ,

(where, as before, the subscript "W" on the expectation or variance operators indicates that expectations are taken only over the randomization distribution induced by

19.3 Estimands

437

the assumed regular assignment mechanism) is, in general, different from

V ^ = E ^ - sp 2 .

(Recall that expectations and variances without a subscript "W" or "sp" are taken over both the randomized treatment assignment and over the random sampling from the superpopulation.) As we will see, the approximate difference is

V(^ ) - VW (^ )  Vsp( (Xi))/N.

To illustrate this difference in sampling variances, let us start with a simple example.
Suppose we have a single, binary, pre-treatment variable, for example, sex, Xi  {f , m}. Let N(f ) and N(m) be the number of females (units with Xi = f ) and males (units with Xi = m) respectively in the finite sample. For x  {f , m}, let Nc(x), Nt(x), and N(x) denote the number of control, treated, and all units with Xi = x, and let Yocbs(x) and Ytobs(x) denote the average observed outcomes for control and treated units with covariate value
Xi = x:

Nc(x) =

(1 - Wi), Nt(x) =

Wi, N(x) = Nc(x) + Nt(x),

i:Xi=x

i:Xi=x

Y cobs (x)

=

1 Nc(x)

(1 - Wi) · Yiobs,
i:Xi=x

and

Y

obs t

(x)

=

1 Nt(x)

Wi
i:Xi=x

· Yiobs.

Finally, let fs(x) and sp(x) denote the average causal effect for units with Xi = x in the sample and the population respectively, for x = f , m:

fs(x)

=

1 N(x)

i:Xi=x

Yi(1) - Yi(0)

,

and

sp(x) = Esp [ Yi(1) - Yi(0)| Xi = x] .

Suppose that treatment assignment is super-population unconfounded,

Wi  Yi(0), Yi(1) Xi,

and suppose there is at least some overlap in the covariate distributions in the sample,
so that Nc(f ), Nc(m), Nt(f ), and Nt(m) are all strictly positive. Under these assumptions, natural estimators for fs(x) and sp(x) are

^ dif(x)

=

Yot bs(x)

-

Y

obs c

(x),

for

x = f , m.

(19.1)

A natural estimator for the sample average treatment effect, fs, is the weighted average of the estimators for the two subsamples, with the weights equal to the proportions of the two subsamples:

^ strat

=

N(f ) N(f ) + N(m)

·

^ dif(f )

+

N(m) N(f ) + N(m)

· ^ dif(m).

(19.2)

438

Sampling Variances for Standard Estimators for Average Causal Effects

This estimator, ^ , is also a natural estimator for sp, unless we have additional information about the proportions of males and females in the super-population beyond the sample proportions.
Now let us consider the sampling variances of these estimators, as well as estimators for these sampling variances. First we focus on the estimators for the withinsubpopulation average treatment effects ^ dif(x), for x  {f , m}, and then we turn to the estimator for the overall average effect, ^ . The sampling variance for ^ dif(x), given random assignment conditional on the pre-treatment variable, following the discussion in Chapter 6 (see in particular Equation 6.4) is

VW (^ dif(x)) = EW

^ dif(x) - fs(x) 2

= Sc2(x) + St2(x) - Sc2t(x) . Nc(x) Nt(x) N(x)

The denominators of the first two terms in the variance are

Sc2(x)

=

1 N(x) - 1

i:Xi=x

Yi(0)

-

1 N(x)

2
Yi (0) ,

i :Xi =x

and

St2(x)

=

1 N(x) - 1

i:Xi=x

Yi(1)

-

1 N(x)

2
Yi (1) ,

i :Xi =x

respectively. Recall, by analogy with the discussion in Chapter 6 on Neyman's repeated sampling perspective, that the numerator in the third term equals the variance of the unit-level treatment effect in the subsample with Xi = x:

Sc2t(x)

=

1 N(x) - 1

i:Xi=x

Yi(1) - Yi(0) - fs(x)

2
,

which vanishes if the treatment effect is constant in the subsample with Xi = x. In Chapter 6 we discussed in detail the difficulties with estimating the third term, and the reasons for commonly ignoring this term. As a result, we commonly estimate the (socalled conservative) sampling variance

VW

^ dif(x)

= Sc2(x) + St2(x) . Nc(x) Nt(x)

(19.3)

The two numerators in the expression for the sampling variance in (19.3), Sc2(x) and St2(x), are unknown, but an unbiased estimator for (19.3) is available (again, see the discussion in Chapter 6). Letting

s2c (x)

=

1 Nc(x) - 1

i:Wi=0,Xi=x

Yiobs - Ycobs(x)

2
,

19.3 Estimands

439

and

st2(x)

=

1 Nt(x) -

1

i:Wi=1,Xi=x

Yiobs - Yot bs(x)

2
,

we have the following, Neyman-type, statistically conservative estimator for the sampling variance of ^ (x):

V^ W (^ dif(x))

=

sc(x)2 Nc(x)

+

st(x)2 . Nt(x)

(19.4)

Now let us turn to the sampling variance of ^ dif(x) as an estimator of the super-population average effect sp(x). Using the results from Chapter 6 (see in particular Equation 6.14), we find:

V ^ dif(x) = E

^ dif(x) - sp(x) 2

= c2(x) + t2(x) , Nc(x) Nt(x)

where c2(x) and t2(x) are the super-population variances of Yi(0) and Yi(1) in the subpopulation with Xi = x, respectively. We do not know c2(x) and t2(x), but unbiased estimators for these variances exist in the form of s2c(x) and st2(x), leading to an estimated sampling variance identical to (19.4). Thus, in terms of the estimated sampling variance of ^ dif(x), it is immaterial whether we focus on ^ dif(x) as an estimator for the finitesample estimand fs(x), or as an estimator for the super-population estimand sp(x) ­ in both cases the expression in (19.4) gives a natural estimator for the sampling vari-
ance, in the former case generally an upwardly biased estimator, and in the latter case an
unbiased estimator. This situation, however, changes when we focus on the estimator ^ strat for the overall
average treatment effect. First, the sampling variance of ^ strat in (19.2) as an estimator of the sample average effect fs is

VW ^ strat = EW ^ strat - fs 2

=

N(f )

2
·

Sc2(f ) + St2(f ) - Sc2t(f )

N(f ) + N(m)

Nc(f ) Nt(f ) Nf

+

N(m)

2
·

N(f ) + N(m)

Sc2(m) + St2(m) - Sc2t(m) Nc(m) Nt(m) Nm

.

The natural (but conservative) estimator for this sampling variance is based on ignoring the Sc2t(f ) and Sc2t(m) terms, and replacing St(x)2 by st(x)2, and Sc(x)2 by sc(x)2 for x = f , m, leading to:

V^ W (^ strat) =

N(f )

2
·

N(f ) + N(m)

s2c(f ) + st2(f ) Nc(f ) Nt(f )

+

N(m) N(f ) + N(m)

2
·

sc2(m) + st2(m) Nc(m) Nt(m)

.

(19.5)

440

Sampling Variances for Standard Estimators for Average Causal Effects

Second, consider the sampling variance of ^ strat in (19.2) as an estimator of the population average effect, sp:

V(^ strat) = E ^ strat - sp 2

= Esp +

^ -

N(f

N(f ) ) + N(m)

·

sp(f

)

+

N(f

N(m) ) + N(m)

·

sp(m)

N(f

N(f ) ) + N(m)

·

sp(f

)

+

N(m) N(f ) + N(m)

·

sp(m)

- sp

2

=E

N(f ) N(f ) + N(m)

2
·

^ dif(f ) - sp(f )

2
+

N(m) N(f ) + N(m)

2

·

^ dif(m) - sp(m)

2
+

N(f

N(f ) ) + N(m)

-

q(f

)

2
·

sp(f ) - sp(m) 2

.

A natural estimator for the sampling variance of ^ as an estimator of sp is

V^ (^ strat) =

N(f ) N(f ) + N(m)

2
·

s2c(f ) + s2t (f ) Nc(f ) Nt(f )

+

N(m)

2

N(f ) + N(m)

·

s2c(m) + st2(m) Nc(m) Nt(m)

+

1 N

·

N(f ) · (N(f ) +

N(m) N(m))2

·

^ dif(f ) - ^ dif(m) 2

=

V^ W (^ strat)

+

N(f ) · N(m) N3

·

^ dif(f ) - ^ dif(m)

2
.

(19.6)

Because

Vsp( (Xi))

=

N(f ) · N(m) N2

·

( (f )

-  (m))2

,

the difference between V^ (^ strat) and V^ W (^ strat), the final term on the right-hand side of (19.6), can be approximated by

V^ (^ strat

-

sp)

- V^ W (^ strat

-

fs)



1 N

· Vsp( (Xi)),

the variance, over the super-population, in the treatment effect conditional on the pretreatment variable. The interpretation of this difference is that if we are interested in the average effect for the super-population, and if the treatment effect varies by the value of the pre-treatment variables (here, if  (f ) =  (m)), we need to take into account the difference between the distribution of the pre-treatment variable in our sample and its distribution in the population. In the example with the binary covariate, sex, the proportion of women in the sample is q^(f ) = N(f )/(N(f ) + N(m)), but in the population it is q(f ), with the sampling variance of the difference between these two proportions equal to q(f )q(m)/N, traditionally estimated as q^(f )q^(m)/N = N(f )N(m)/N3. Because the last term in (19.6) is of the same order of magnitude as the other terms, taking it into account will generally matter, even in large samples.

19.4 The Common Structure of Standard Estimators for Average Treatment Effects 441
Although the extension from the scalar binary pre-treatment variable to the general case with multiple, and multi-valued, pre-treatment variables is algebraically messy, a similar distinction arises between the sampling variance of an estimator of the sample average effect and the sampling variance of an estimator of the population average effect, with approximately,

V(^ strat)  VW (^ strat) + Vsp  (Xi) /N.

(19.7)

In this chapter, we present estimators for the general version of both (19.5), in Section 19.7, and (19.6), in Section 19.9. However, our view is that, in general, one should focus on the sampling variance of an estimator viewed as an estimator of the sample average effect rather than viewed as an estimator of the super-population average effect. Thus we recommend focusing on the generalization of (19.5), rather than taking into account differences between the distribution of the pre-treatment variables in the sample and the analogous distribution in a somewhat vague, hypothetical, and often ill-defined, super-population.

19.4 THE COMMON STRUCTURE OF STANDARD ESTIMATORS FOR AVERAGE TREATMENT EFFECTS
Most estimators for average treatment effects, including those discussed in Chapters 12, 17, and 18, have a common structure, which is that each can be written as a linear combination of observed outcomes, with specific restrictions on the coefficients. Viewed as a property of estimators, we refer to this structure as affine consistency of the estimators, defined in Section 19.1. This property has intuitive appeal, and estimators that do not have this property often have particular unattractive features. In this section we explore this structure, and in Sections 19.5­19.7 we exploit it to develop expressions and estimators for their sampling variances.

19.4.1 Weights
Most estimators for average treatment effects that are used in practice can be written as the difference between two terms, the first an average of observed outcomes for treated units and the second an average of observed outcomes for control units:

^

=

^ (Yobs, W, X)

=

1 Nt

i
i:Wi=1

· Yiobs

-

1 Nc

i
i:Wi=0

· Yiobs,

(19.8)

with weights i/Nt for treated units and weights and i/Nc for control units. For all the estimators we have considered so far, the normalized weights i share a number of properties. First, they can be written as a function of the treatment indicator and
pre-treatment variables for unit i, Wi, Xi, and the treatment indicators and covariate values for other units, W(-i) and X(-i), where W(-i) is the N - 1 vector of treatment

442

Sampling Variances for Standard Estimators for Average Causal Effects

indicators omitting the ith indicator Wi, and X(-i) is the (N - 1) × K dimensional matrix equal to X with the ith row omitted:

i = (Wi, Xi, W(-i), X(-i)),

with (Wi, Xi, W(-i), X(-i)) a row exchangeable function in (W(-i), X(-i)). The specific form of the weight function (Wi, Xi, W(-i), X(-i)) depends on the estimator. The weights also satisfy two summation restrictions:

1 Nc

i
i:Wi=0

=

1,

and

1 Nt

i:Wi=1

i

=

1.

(19.9)

Expression (19.8), with the restrictions in (19.9) that capture affine consistency, is a natural form for estimators for average treatment effects.
Now let us return to some of the estimators discussed in the previous chapters to illustrate the forms of the weights and to document that these estimators are affinely consistent.

Difference Estimator

First, the simple difference between average outcome for treated and control units, ^ dif =

Y

obs t

-

Y

obs c

corresponds

to

di if

=

1,

for

all

i.

Regression Estimator
Second, consider a regression estimator where ^ ols is the least squares estimator in the regression with a scalar covariate Xi (affine consistency also holds in the case with multiple pre-treatment variables, but the form of the weights is more complicated algebraically):

Yiobs =  +  · Wi +  · Xi + i.

This implies

iols

=

W Wi

·

(1

-

W )1-Wi

·

SX2 (N SX2 (N -

- 1)/N 1)/N -

- W

(Xt - Xc) · (Xi - X) · (1 - W) · (Xt - Xc)2

for all i, and where SX2 =

N i=1

(Xi

-

X)2/(N

-

1)

is

the

sample

variance

of

Xi.

Note

that

in this case, the weights need not all be non-negative.

Weighting Estimator
Third, consider weighting proportional to the inverse of the true propensity score e(Xi). In that case the estimator is

^ ht =

Yiobs

1-

Yiobs

1 ,

i:Wi=1 e(Xi) i :Wi =1 e(Xi ) i:Wi=0 1 - e(Xi) i :Wi =0 1 - e(Xi )

19.4 The Common Structure of Standard Estimators for Average Treatment Effects 443

(where the superscript "ht" stands for Horvitz-Thompson) so that



 Nc

hi t = 

1-e(Xi) Nt

e(Xi)

j:Wj=0

1 1-e(Xj

)

,

j:Wj=1

1 e(Xj)

,

if Wi = 0, if Wi = 1.

The same argument applies to the case where we use the estimated propensity score to construct the weights, with the difference that the weights are now a more complicated function of all the pre-treatment variables and treatment indicators. In both cases, however, the weights are all positive.

Subclassification Estimator
Fourth, consider the simple, unadjusted, subclassification estimator. Let the number of units in subclass j be equal to N(j), and the number of control and treated units in this subclass be equal to Nc(j) and Nt(j) respectively, and let Bi(j)  {0, 1} be a binary indicator for unit i falling in subclass j. Then

istrat =

J j=1

Bi(j)

·

(Nc/Nc(j))

·

(N

(j)/N),

if Wi = 0,

J j=1

Bi(j)

·

(Nt/Nt(j))

·

(N(j)/N

),

if Wi = 1.

Using regression within the subclasses maintains the affine consistency property, with the weights now a more complicated function of the pre-treatment variables for other units. Because of the regression adjustment, the weights can in that case be negative.

Matching Estimator
Finally, let us consider matching estimators. A simple matching estimator with M matches for each treated and control unit has the form (see Chapter 18 for details)

^ match = 1 N N i=1

Y^i(1) - Y^i(0) ,

where

 

Yiobs

Y^i(w) = 

jMc(i) Yjobs/M jMt(i) Yjobs/M

if Wi = w, if Wi = 1, w = 0, if Wi = 0, w = 1,

ensuring that Y^i(w) is a linear combination of Yjobs with weights summing to one, and therefore satisfying affine consistency. The affine consistency is maintained if we combine the matching with regression adjustment, but again this can lead the weights to become negative.

19.4.2 Weights for the Lottery Data
To illustrate the weighting representations of the subclassification and matching estimators, we calculate the weights for the regression-adjusted version of these two estimators

444

Sampling Variances for Standard Estimators for Average Causal Effects

Table 19.2. Summary Statistics for the Normalized Weights for Different Estimators, for the IRS Lottery Data

Trimmed Sample

Blocking with Regression Matching with Regression Weighting

(Nc = 172, Nt = 151) Controls Treated Controls Treated Controls Treated

Mean Median Standard deviation Minimum Maximum

1.00 1.03 1.09 -1.98 3.87

1.00 0.73 0.87 -0.74 3.55

1.00 0.53 0.94 -0.11 6.62

1.00 0.49 0.95 -0.14 6.59

1.00 1.00 0.74 0.72 0.87 0.82 0.55 0.47 9.68 6.45

Full Sample

Blocking with Regression Matching with Regression Weighting

(Nc = 259, Nt = 237) Controls Treated Controls Treated Controls Treated

Mean Median Standard deviation Minimum Maximum

1.00 0.79 1.57 -1.13 9.42

1.00 0.80 1.43 -1.88 7.35

1.00 0.48 1.47 -1.08 14.22

1.00 0.52 1.45 -0.44 14.18

1.00 0.57 2.69 0.48 41.7

1.00 0.61 1.34 0.50 13.2

for the lottery data, as well as for the simple weighting estimator. Table 19.2 reports some summary statistics for the normalized weights i, including the mean and median weight, the standard deviation of the weights, and the minimum and maximum value of the weights. Note that the average of the normalized weights is exactly equal to one by affine consistency. We report the summary statistics for the weights for two samples, in the first panel for the trimmed sample, and in the second panel for the full sample, for three estimators: the subclassification estimator with regression adjustment, matching with a single match and regression adjustment, and weighting on the estimated propensity score.
First consider the results for the trimmed sample. For all three estimators, the regression-adjusted subclassification and matching estimators, and the weighting estimator, the standard deviation of the weights is approximately one, in both treatment groups. The largest value of the weights is markedly larger for the matching and the weighting estimators than for the subclassification estimator. For both the subclassification and matching estimators, the weights are negative for some units, which occurs because in both cases we use least squares covariance adjustment, either within subclasses or over the matched pairs. For the simple weighting estimator, the weights are non-negative. In general, it is useful to inspect the weights for any particular estimator. If some of the weights are extreme, the resulting estimator is likely to be sensitive to small changes in the specific implementation. With the lottery data, the relatively large weights for the simple weighting estimator suggest that this estimator may be an unattractive choice in this setting.
Next, consider the weights for the full sample. For all three estimators the weights are now substantially more variable. In particular for the weighting estimator, some units have fairly extreme weights, as large as 41, which occurs because of the bigger difference between covariate distributions for controls and treated in the full sample,

19.5 A General Formula for the Conditional Sampling Variance

445

and is another way of highlighting the consequences for inference of limited overlap in covariate distributions.

19.5 A GENERAL FORMULA FOR THE CONDITIONAL SAMPLING VARIANCE

Using the notation introduced in Chapter 7, let c(x) and t(x) denote the superpopulation expected values of the potential outcomes Yi(0) and Yi(1) in the subpopulation with Xi = x respectively, and let c2(x) and t2(x) denote the super-population variances of Yi(0) and Yi(1) in the subpopulation with Xi = x, respectively. By super-population unconfoundededness it follows that these expectations and variances satisfy
c(x) = Esp Yi(0) Xi = x = Esp Yiobs Wi = 0, Xi = x ,

t(x) = Esp Yi(1) Xi = x = Esp Yiobs Wi = 1, Xi = x ,

c2(x) = Vsp Yi(0) Xi = x = Vsp Yiobs Wi = 0, Xi = x , and

t2(x) = Vsp(Yi(1)|Xi = x) = Vsp(Yiobs|Wi = 1, Xi = x).

Also define the unit-level conditional expectations and variances:

i = Esp Yiobs|Wi, Xi =

c(Xi), if Wi = 0, t(Xi), if Wi = 1,

i2 = Vsp Yiobs|Wi, Xi =

c2(Xi), if Wi = 0, t2(Xi), if Wi = 1.

Using this notation, we can write a generic affinely consistent estimator ^ for the average

effect, with the representation in (19.8), as

^

=

1 Nt

i
i:Wi=1

· Yiobs

-

1 Nc

i
i:Wi=0

·

Yiobs





=

1 Nt

i
i:Wi=1

·

i

-

1 Nc

i
i:Wi=0

·

i





+

1 Nt

i
i:Wi=1

·

(Yiobs

-

i)

-

1 Nc

i
i:Wi=0

·

(Yiobs

-

i) .

(19.10)

The difference between the first pair of terms on the right-hand side of (19.10),
i:Wi=1 i · i/Nt - i:Wi=0 i · i/Nc, and the estimand fs equals the conditional bias. With a sufficiently flexible estimator, this term will generally be small. We ignore
this term for the purpose of inference for the estimand. The second pair of terms on the right-hand side in (19.10), i:Wi=1 i · (Yiobs - i)/Nt - i:Wi=0 i · (Yiobs - i)/Nc,

446

Sampling Variances for Standard Estimators for Average Causal Effects

has expectation equal to zero, over the distribution induced by random sampling from the super-population and conditional on (X, W). Hence, conditional on (X, W), the sampling variance of ^ in (19.8) is equal to the variance of the second term:

Vsp(^ |X, W)

=

1 Nt2

2i
i:Wi=1

·

i2

+

1 Nc2

i2
i:Wi=0

·

i2.

(19.11)

Because the weights i are, for a specific estimator, a known function of the covariates
and the assignment vector, the only unknown components of the conditional sampling
variance of ^ given (W, X) are the conditional unit-level potential outcome variances i2. Our proposed estimator for the sampling variance substitutes estimators ^i2 for i2, leading to the following generic estimator for the conditional sampling variance:

Vsp(^ |X, W)

=

1 Nt2

2i
i:Wi=1

·

^i2

+

1 Nc2

i2
i:Wi=0

·

^i2.

(19.12)

The next section discusses specific estimators for i2.

19.6 A SIMPLE ESTIMATOR FOR THE UNIT-LEVEL CONDITIONAL SAMPLING VARIANCE
In this section we discuss a general approach to estimating i2 for all units. We first discuss the simplest case, followed by an illustration based on a subset of the lottery data consisting of ten treated units. Then we introduce two extensions, again followed by an illustration, now based on the trimmed lottery sample with N = 323 units.

19.6.1 A Single Exact Match Suppose we wish to estimate the conditional variance, i2, for a particular unit i, and suppose this unit received the active treatment, so that Wi = 1. Suppose there is a second unit, say unit i , with an identical value for the pre-treatment variables, and which also received the active treatment, so that Wi = Wi = 1 and Xi = Xi = x. Then the expected outcomes for these units, conditional on Wi = Wi = 1 and Xi = Xi = x, based on the distribution generated by random sampling from the super-population, are equal:
Esp Yiobs - Yiobs Xi = Xi = x, Wi = Wi = 1
= Esp i + (Yiobs - i) - i + (Yiobs - i ) Xi = Xi = x, Wi = Wi = 1
= Esp (Yiobs - i) - (Yiobs - i ) Xi = Xi = x, Wi = Wi = 1 = 0,
exploiting the fact that, because Xi = Xi = x and Wi = Wi = 1, it follows that i = i = t(x). Hence, the expected square of the difference in outcomes, conditional on Xi = Xi = x and Wi = Wi = 1, is

19.6 A Simple Estimator for the Unit-Level Conditional Sampling Variance

447

Esp Yiobs - Yiobs 2 Xi = Xi = x, Wi = Wi = 1

= Esp

Yiobs - i

2
+

Yiobs - i

2
Xi = Xi = x, Wi = Wi = 1

= Vsp Yiobs Xi = x, Wi = 1 + Vsp Yiobs Xi = x, Wi = 1 = 2 · t2(x),

by random sampling from the super-population. Thus, we can estimate the conditional variance i2 = t2(Xi) as

^i2 =

Yiobs - Yiobs

2
/2.

(19.13)

This estimator for the unit-level sampling variance is unbiased for i2 conditional on W and X: Esp[^i2|X, W] = i2. However, it is not consistent, meaning that even in large samples, the difference between ^i2 and i2 does not converge to zero, because its sampling variance does not vanish. Nevertheless, despite ^i2 in (19.13) being an imprecise
estimator of the sampling variance of Yi(w), we obtain an attractive estimator for the conditional sampling variance of ^ by substituting this estimator ^i2 into the expression for the sampling variance for ^ , which averages N such noisy (but unbiased) estimates:

Vsp(^

X, W)

=

1 Nt2

i2 · ^i2 +
i:Wi=1

1 Nc2

2i · ^i2.
i:Wi=0

Under mild regularity conditions, the difference between this estimator and its target, normalized by the sample size, will converge to zero:

N · Vsp(^ X, W) - Vsp(^ X, W)

=

N Nt2

2i
i:Wi=1

·

^i2 - i2

+

N Nc2

2i
i:Wi=0

·

^i2 - i2

- 0.

Even though the differences ^i2 - i2 do not vanish for a particular i with an increasing sample size, summing these differences over all units, suitably weighted, leads to an
asymptotically attractive estimator for the normalized sampling variance of ^ .

19.6.2 A Single Approximate Match
In general we may not be able to find for each unit i a matching unit i with the same treatment level and exactly the same covariate values. Nevertheless, if we look for the most similar unit (in terms of covariate values) in the set of units with the same level of the treatment, we can obtain an approximately unbiased estimator for i2. Here we use the same ideas as we used in developing matching estimators in Chapter 18. There is one key difference: we now match treated units to treated units and control units to control units. Formally, we match treated unit i to the closest treated unit. Let, as in Chapter 18, Ic  {1, . . . , N} be the set of indices for the control units and It  {1, . . . , N} the set of

448

Sampling Variances for Standard Estimators for Average Causal Effects

indices for the treated units. Then, let Mic be the set of control matches for unit i and Mit the set of treated matches for this unit, in both cases excluding unit i itself. In Chapter
18 we focused on control matches for treated units and treated matches for control units.
Here the key difference is that we focus on control matches for control units and treated matches for treated units. Initially we will let Mic and Mti be singletons, with its element denoted by mic and mit, respectively. Then

mic

=

arg
i

min
=1,...,N,i =i,Wi

=0

Xi - Xi

,

and

mit

=

arg

i

min
=1,...,N,i =i,Wi

=1

Xi - Xi

.

Also define

i=

mit if Wi = 0, mic if Wi = 1.

Then we estimate i2 as

^i2 =

Yiobs

-

Y obs i

2
/2.

(19.14) (19.15)

This estimator for the unit-level conditional potential outcome variance i2 can be written as

^i2 =

i

-



i

+

(Yiobs

-

i)

-

(Y obs i

-



i)

2
/2.

Taking the expectation of this squared difference, conditional on (X, W), over the distri-
bution induced by random sampling from the super-population, and subtracting the true variance i2, gives

Esp ^i2 X, W /2 - i2 = i -  i 2

2+

2 i

-

i2

/2.

There are two reasons why this difference is not equal to zero, that is, why the estimator is biased for i2. First, because the match is not exact (Xi = X i), the two conditional expectations i and  i are not identical, and so the first term generally differs from zero. Second, the two conditional variances are not the same. The second component of the bias can be positive or negative, but will tend to average to zero over all units in large samples. The first component of the bias is always positive, and it will vanish as the sample size increases, at least if we ignore measure-theoretic details. In Section 19.6.4
we discuss methods to reduce this first component of the bias. Regarding the choice of metric, the same issues arise here that were discussed in
Chapter 18. In the illustrations in this chapter we use the Mahalanobis metric.

19.6 A Simple Estimator for the Unit-Level Conditional Sampling Variance

449

Table 19.3. Ten Treated Observations from the IRS Lottery Data

Unit Earn Year -1 Outcome i

1

29.7

3.4 6

2

19.7

6.4 10

3

0.8

0.0 5, 9

4

28.8

25.5 1

5

0.0

0.0 9

6

30.3

42.0 1

7

39.4

25.4 8

8

39.9

42.4 7

9

0.0

1.4 5

10

19.3

10.1 2

^i2
27.32 2.62 0.82 15.62 1.02 27.32 12.02 12.02 1.02 2.62

19.6.3 An Illustration

Let us illustrate the ideas developed this far in this chapter with a subset of the lottery

data introduced earlier. Table 19.3 presents information on ten treated units (winners)

from the Imbens-Rubin-Sacerdote lottery data set. In the table we report the value

of only one of the covariates, Earn Year -1 (earnings the year before playing

the lottery) and the outcome (the average of six years of earnings after winning the

lottery).

We wish to estimate, for each of these ten individuals (all winners), the conditional

variance of the outcome, by matching each unit to the closest winner in terms of prior

earnings. Consider the first individual. The value of the covariate for this individual is

X1 = 29. 7 (corresponding to earnings equal to $29,700 in the year prior to winning the

lottery), and the value of the outcome is Y1obs = 3. 4. The closest individual, in terms

of prior earnings, to this individual is unit 1 = 6, with prior earnings equal to X 1 =

X6

=

30. 3,

and

outcome

Y obs 1

=

Y6obs

=

42. 0.

The

difference

in

outcomes

is

therefore

Y1obs

- Yobs 1

=

38. 6,

leading

to

an

estimate

for

12

equal

to

^12

=

38. 62/2

=

27. 32.

Analogously, the second individual, with X2 = 19. 7, is matched to 2 = 10, with

X

2

=

X10

=

19.

3.

For

this

pair

the

difference

in

outcomes

is

Y2obs

- Yobs 2

=

6.

4 - 10. 1,

leading to ^22 = (6. 4 - 10. 1)2/2 = 2. 62.

Matching the third individual leads to a minor complication: this individual, with

X3 = 0. 8, is equally close to individuals 5 and 9, with X5 = X9 = 0. 0. We therefore use both as matches, and estimate the conditional variance for unit 3 as the sample variance

for the three units, unit 3 and the two units that are equally close:

^32

=

1 2

·

Y3obs - Y3

2
+

Y5obs - Y3

2
+

Y9obs - Y3

2

= 0. 82,

where Y3 = Y3obs + Y5obs + Y9obs /3 = 0. 5. Table 19.3 presents the results of this matching exercise for all ten units.

450

Sampling Variances for Standard Estimators for Average Causal Effects

19.6.4 A Bias-Adjusted Variance Estimator As we discussed before, the bias of the unit-level conditional variance estimator is

Esp

^i2 X, W

/2 - i2 =

i -  i 2 /2 +

2 i

-

i2

/2.

If the number of covariates is large, this expectation may be substantially different from the unit-level conditional variance i2. This bias has two components. The unit-level conditional variance at the match,  2 , may be different from that at the ith unit itself,
i
i2. Unless there is substantial heteroskedasticity, this is unlikely to be a problem, and we ignore it in this discussion. The other, and the more likely source of bias, is the difference in conditional expectations, i -  i. To remove some of this bias, it is useful to apply some of the bias-reduction methods we used for matching estimators in
Chapter 18.
To reduce the bias, we approximate the conditional expectation of the potential
outcomes as linear and estimate the regression functions

Esp[Yiobs|Xi, Wi = 1] = Xit, and Esp[Yiobs|Xi, Wi = 0] = Xic.

Given the two estimated regression functions, we calculate the residuals

^i =

Yiobs - Xi^c if Wi = 0, Yiobs - Xi^t if Wi = 1.

Now we estimate the unit-level conditional variance i2 using the same match defined in (19.14), and the same estimator as in (19.16), with observed outcome Yiobs replaced by the residual ^i:

^i2,adj = ^i - ^ i 2 /2.

(19.16)

If instead of the estimated residuals ^i, we used the true deviations from the conditional means, Yiobs -i, this would eliminate the (i - i)2 term from the bias of the unit-level conditional variance estimator.
The corresponding bias-adjusted estimator for the sampling variance of the estimator
for the average treatment effect is

Vsp(^ |X, W)

=

1 Nt2

2i
i:Wi=1

·

^i2,adj

+

1 Nc2

i2
i:Wi=0

· ^i2,adj.

(19.17)

19.6.5 Multiple Matches
In the discussion in the previous section, we use only the square of the difference in outcomes between unit i and its closest match to estimate i2. More generally, we may be able to improve the precision of the estimator for i2 by using multiple matches or additional model-based adjustments. Specifically, one can for some M  1 use the closest M units to unit i in terms of covariate values, so that Mci and Mit are sets with L elements.

19.6 A Simple Estimator for the Unit-Level Conditional Sampling Variance

451

Table 19.4. Unit-Level Standard Deviation Estimates (^i) for the IRS Lottery Data

Unadjusted

Adjusted

M = 1 M = 4 M = 10 M = 1 M = 4 M = 10

Mean Median Standard deviation Min Max Proportion equal to zero

4.9 2.5 6.2 0.0 29.8 0.22

6.8 6.4 5.7 0.0 21.5 0.16

7.7 8.0 5.1 0.0 20.0 0.11

4.8 2.6 5.4 0.0 33.2 0.00

6.4 5.3 4.7 0.3 21.1 0.00

7.0 6.6 4.0 1.1 19.0 0.00

Then we can estimate the conditional variance i2 using all units in these sets. For example, if unit i is a treated unit:

^i2,M

=

1 2·M

·
i Mit

Yiobs - Yiobs

2
,

(19.18)

and analogously for control units.
What are the trade-offs when choosing the number of matches M? Using more than one match increases the precision in the estimator for i2, because the estimator is now based on a larger sample. The disadvantage is that, when using more matches,
the quality of the typical match decreases. In other words, the difference between the
pre-treatment variables for a unit and its typical match, Xi - Xi , increases, and thus we introduce an additional upward bias in the estimation of i2. In general the increase in the bias may be the bigger concern, because the averaging of the ^i2 in the variance estimator Vsp(^ |X, W) suggests that the precision is of less concern. However, if the weights 2i on the different ^i2 vary widely, the precision of ^i2 may be more of a concern. In practice we recommend a small number of matches, between one and
four.

19.6.6 An Illustration with the Trimmed Lottery Data Set
Here we estimate the unit-level sampling variances on the lottery data for the purpose of estimating the sampling variance of the subclassification estimator ^ strata. We consider three values for the number of matches, M = 1, 2, and 4. Table 19.4 reports summary statistics for the estimates of the 323 standard deviations i. The median estimate of the standard deviation in the single match case is 2.8. Using a larger value for M leads to a larger average estimate but a smaller standard deviation. Note that there is a substantial fraction of the units for whom the conditional variance i2 is estimated to be zero. This happens for units with outcome equal to zero for both the unit and its closest matches. To put the values for these conditional variances in perspective, the standard deviation of the outcome in the trimmed sample is sY = 15. 5.

452

Sampling Variances for Standard Estimators for Average Causal Effects

19.7 AN ESTIMATOR FOR THE SAMPLING VARIANCE OF ^ CONDITIONAL ON COVARIATES

To estimate the sampling variance of ^ , the estimator for the average treatment effect, conditional on the covariates, we substitute the unit-level sampling variance estimates using a single match into the expression for the conditional sampling variance given in (19.12):

V^ M=1

=

1 Nt2

i2
i:Wi=1

· ^i2

+

1 Nc2

i2
i:Wi=0

· ^i2.

(19.19)

Let us again return to the lottery data. In Table 19.5 we present some of the estimates
for the sampling variances. First we estimate the sampling variance with a single match, V^ M=1. For the subclassification estimator, with a single match, the sampling variance is estimated to be V^ M=1 = 1. 532. Using M = 4 matches leads to a small decrease in the estimated sampling variance, to V^ M=4 = 1. 472. With M = 10 matches, we find V^ M=10 = 1. 522. For the matching estimator, we find estimates ranging from 1. 322 to 1. 422.
If we are willing to assume homoskedasticity, so that t2(x) = c2(x) =  2 for all x, one can first average the unit-level variance estimates ^i2 to estimate the common variance  2,

^ 2

=

1 N

N
^i2,
i=1

and then combine this estimator with the weights to estimate the sampling variance of

the estimator for the average treatment effect as





V^ homoskedastic

=

^ 2

·

1 Nt2

i:Wi=1

i2

+

1 Nc2

i:Wi=0

i2

.

(19.20)

In the lottery data set, V^ homoskedastic = 1.342, for the case with M = 1. Assuming homoskedasticity does not change the sampling variance estimates substantially in this example.

19.8 AN ESTIMATOR FOR THE SAMPLING VARIANCE FOR THE ESTIMATOR FOR THE AVERAGE EFFECT FOR THE TREATED

So far we focused on the overall average effect of the treatment in the full sample, fs =

1 N

N i=1

(Yi

(1)

-

Yi(0)).

In

some

cases

researchers

are

interested

in

the

average

effect

of

the treatment only for those who actually received the treatment,

fs,t

=

1 Nt

(Yi(1) -
i:Wi=1

Yi(0)) .

19.8 Sampling Variance for Estimator for Average Effect for the Treated

453

Table 19.5. Estimated Standard Errors for Average Treatment Effect Estimates for the IRS Lottery Data

Point estimate -

Blocking plus Regression Matching plus Regression

(M = 1) (M = 4)

-5.74

-4.54

-5.03

Method for calculating standard error  Matching, heteroskedastic (M = 1) Matching, heteroskedastic (M = 4) Matching, heteroskedastic (M = 10)

(1.53) (1.47) (1.52)

(1.40) (1.32) (1.41)

(1.40) (1.32) (1.41)

Matching, homoskedastic (M = 1) Matching, homoskedastic (M = 4) Matching, homoskedastic (M = 10)

(1.36) (1.41) (1.48)

(1.34) (1.39) (1.46)

(1.34) (1.39) (1.46)

Analytic Bootstrap

(1.37) (2.09)

(1.18) (1.43)

In this section we discuss the modification of the estimator for the sampling variance for settings where the focus is on fs,treated.
Like its counterpart for the overall average, the generic estimator for fs,t can be written as a weighted average of the observed outcomes,

^fs,t

=

1 Nt

i
i:Wi=1

· Yiobs

-

1 Nc

i
i:Wi=0

·

Yiobs.

Again the weights i are functions of the matrix of pre-treatment variables X and the vector of treatment assignments W, and average to one for the treated units and to one for the control units. The only difference is that the values of the weights are different for estimators of fs,t. Typically i is equal to 1/Nt for all treated units in this case.
The conditional variance has the same form as before:

VW

^fs,t

= VW

^fs,t X, W

=

1 Nt2

2i
i:Wi=1

·

^i2

+

1 Nc2

2i
i:Wi=0

· ^i2.

We can use the same estimator for i2 as in Section 19.6, and substitute that into this expression for the sampling variance to get

N
V^ W ^fs,t = 2i · ^i2.
i=1

454

Sampling Variances for Standard Estimators for Average Causal Effects

19.9 AN ESTIMATOR FOR THE SAMPLING VARIANCE FOR THE POPULATION AVERAGE TREATMENT EFFECT

In the previous two sections we focused on estimating VW (^ ) for a generic estimator ^ . In some cases the researcher may be interested in estimating the sampling variance of ^ as an estimator for the population average treatment effect sp and therefore wish to estimate V(^ ). In this section we develop general methods for doing so.
As noted in Section 19.3, the difference between V(^ ) and VW (^ ) is the superpopulation variance of the average treatment effect conditional on the pre-treatment variable, V( (Xi))/N. Given that we developed, in Section 19.7, an estimator for the finite-sample variance VW (^ ), it now suffices to develop an estimator for the sampling variance of the average effect conditional on the pre-treatment variables, V( (Xi)).
The proposed estimator for this sampling variance is based on a preliminary matching estimator of the type discussed in Chapter 18. For simplicity we focus on a matching estimator with a single match. For each unit we find the closest unit, in terms of pretreatment variables, with the alternative value for the treatment. For unit i, let the index of this match be denoted by (i). We estimate the unit-level treatment effect for unit i as
^ match = Y^i(1) - Y^i(0),

where

Y^i(0) =

Yiobs if Wi = 0,

Y

obs (i)

if Wi = 1,

We can write

and Y^i(1) =

Y

obs (i)

if Wi = 0,

Yiobs if Wi = 0.

^ match = i + (2 · Wi - 1) · i -  (i) + (2 · Wi - 1) ·

(Yiobs

-

i)

-

(Y

obs (i)

-



(i))

.

In sufficiently large samples, the second term on the right-hand side of this expression will be small relative to the other terms, and so we will ignore it and write

^ match  i + (2 · Wi - 1) ·

(Yiobs

-

i)

-

(Y

obs (i)

-



(i))

.

Now suppose we observe i. In that case we could estimate V( (Xi)) as



2

V( (Xi)) =

1 N-1

N i=1

i

-

1 N

N
i
j=1

=

N

1 -1

N i=1

(i

- fs)2 .

However, we do not observe i, only the estimate ^imatch. Let us therefore examine the

average squared difference between ^imatch and the average fs =

N i=1

i

/N:

E

1N N i=1

^imatch - fs 2

=E

1 N

N
(i - fs)2
i=1

+E

1N N i=1

^imatch - i 2

.

(19.21)

19.9 Sampling Variance for Population Average Treatment Effect

455

First consider the second term. Ignoring the terms involving i -  (i), this average squared difference is, in expectation, approximately equal to

E

1N N i=1

^imatch - i 2

E

1 N

N
(i + (2 · Wi - 1)
i=1

·

(Yiobs

-

i)

-

(Y

obs (i)

-



(i))

2
- i

Thus,

=1

N
E

N i=1

(2 · Wi - 1) ·

(Yiobs - i)

·

-(Y

obs (i)

-



(i))

2

=1 N N i=1

i2

+



2 (i)



2 N

N
i2.
i=1

Vsp(i)  E

1N N i=1

^imatch - fs 2

-

2 N

N i=1

i2,

which we can estimate as

V^ sp(i)  E

1N N i=1

^imatch - ^

2

-

2 N

N
^i2.
i=1

Thus, our proposed estimator for the sampling variance for the estimated population average treatment effect is

V^ sp(^ )

=

V^ W (^ )

+

1 N

·

V^ sp( (Xi))

=

N

^i2 ·

i=1

2i

-

2 N2

1N + N2
i=1

^imatch - ^

2
.

(19.22)

Let us return to the lottery data again. Using a single match to estimate i2, we estimate the variance of  (Xi) to be

V^ sp( (Xi))  E

1 N

N

^imatch - ^ 2

-2 N

N
^i2 = 2. 92.

i=1

i=1

Thus, the estimate of the sampling variance of ^ as an estimator of the super-population average treatment effect is

N
V^ (^ ) = ^i2 ·
i=1

i2

-

2 N2

+E

1N N2 i=1

^imatch - ^ 2

= 1. 412,

slightly larger than the variance relative to the sampling variance relative to the finite-sample average treatment effect (which we estimated to be 1. 402 in
Table 19.5).

456

Sampling Variances for Standard Estimators for Average Causal Effects

19.10 ALTERNATIVE ESTIMATORS FOR THE SAMPLING VARIANCE

In this section we discuss two alternative estimators for the sampling variance of  . Neither of these methods is, in our view, to be recommended, and we mention them largely to contrast them with the methods discussed so far, and also because versions of these methods have been used, perhaps ill-advisedly so, in practice. The first alternative is based on conventional least squares standard errors. Both of the estimators we recommend use least squares regression to estimate the average effect, not applied to the original sample but in combination with initial adjustment based on subclassification or matching. In Section 19.10.1 we use the regression step to motivate an estimator for the sampling variance. The second alternative is based on resampling. For simplicity we focus on the simplest version of the bootstrap.

19.10.1 Least Squares Sampling Variance Estimators

Least Squares Sampling Variance Estimators for the Subclassification Estimator

Consider the subclassification estimator. First we construct the subclasses. Suppose there

are J subclasses, with, as before, Bi(j) the zero-one indicator for the event that unit i
belongs to subclass j. We then estimate the average effect in subclass j, denoted by  (j), by least squares regression of the outcome Yiobs on an intercept, the indicator for receipt of the treatment, Wi, and the vector of covariates (or pre-treatment) variables Xi. Let Zi be the vector (Wi, 1, Xi). Then let the least squares estimator be ^ (j), defined by



-1 



^ (j) = 

ZiT · Zi 

ZiT · Yiobs .

i:Bi(j)=1

i:Bi(j)=1

The estimator for the average treatment in subclass j is the first element of the vector ^ (j), or ^ ols(j) = ^1(j). The conventional least squares estimator of the sampling variance for ^ ols(j) is the (1, 1) element of



-1

V^ ^ (j) = ^j2 · 

ZiT · Zi ,

i:B(j)=1

where

^j2

=

N

1 -K

-2

i:Bi(j)=1

Yiobs - Zi^ (j)

2
,

and K is the number of elements of the vector of pre-treatment variables Xi. Let V^ (^ ols(j)) denote this estimate, the (1, 1) element of V^ ^ (j) . The estimator for the average effect
of the treatment is a weighted average of the within-block estimators:

^ strat = J Nc(j) + Nt(j) · ^ ols(j).

j=1

N

19.10 Alternative Estimators for the Sampling Variance

457

Table 19.6. Estimates and Estimated Standard Errors by Subclass for the IRS Lottery Data

Subclass Estimate (s. e.) Weight ^ 2,block(j)

1

-8.20 (3.19) 0.25

9.63

2

-6.74 (3.84) 0.12

6.93

3

-2.19 (4.13) 0.13

9.78

4

-7.30 (2.01) 0.25

7.84

5

-3.06 (2.82) 0.25

9.26

Overall -5.74 (1.37) 1

The corresponding estimator for the sampling variance of the subclass estimator for the overall average treatment effect is

J
V^ ^ strat =

Nc(j) + Nt(j)

2
· V^ (^ ols(j)).

j=1

N

Let us illustrate this approach with the lottery data. Our algorithm for the subclassification estimator led to five subclasses. The first and last two subclasses each have approximatley 25% of the units, and the second and third each have between 12% and 13%. In Table 19.6 we present point estimates and estimated standard errors for each of the five subclasses, and the standard error for the point estimate of the overall average treatment effect. The estimated standard error for the overall estimate is equal to 1.37, somewhat smaller than the matching-based estimated standard errors. The within-subclass estimates of the conditional variances, the ^j2, are slightly larger than the matching-based estimated conditional sampling variances.

A Sampling Variance Estimator for the Matching Estimator for Paired Randomization
The simple (i.e., without bias adjustment) matching estimator with M matches has the form

^ = 1 N

N

Y^i(1) - Y^i(0) ,

i=1

(19.23)

where the, partly imputed, potential outcomes Y^i(w) have the form

Y^i(0) =

Yiobs

1 M

jMic Yjobs

if Wi = 0, if Wi = 1,

and

Y^i(1) =

Yiobs

1 M

jMit Yjobs

if Wi = 1, if Wi = 0.

Let us first consider the case with a single match, M = 1, so that Mci = { ci } and Mti = { it}, and with matching without replacement. In that case, all the pairs (Y^i(0), Y^i(1)) correspond to outcomes for distinct units, exactly like a paired randomized

458

Sampling Variances for Standard Estimators for Average Causal Effects

experiment. Hence, a natural estimator for the sampling variance is V^ = ^ 2/N,

where ^ 2 is the obvious estimator for the sampling variance of the treatment effect, that is,

^ 2

=

N

1 -1

N i=1

Y^i(1) - Y^i(0) - ^

2
.

(19.24)

There are two complications that make estimating the sampling variance more compli-

cated for our matching estimator. First, we match with replacement, which introduces

some dependence because the ith pair (Y^i(0), Y^i(1)) may have one or two outcomes in

common with the i th pair (Y^i (0), Y^i (1)). To capture the dependence that results from

this overlap, define the N × N matrix , with





1 1

if i = i , if i = j, i = i,

ii

= 

1/2 1/2

if i = i , i = i, if i = i, i = i ,

0 otherwise.

For matching without replacement, would be equal to the identity matrix, and V^ = ^ 2N N/N2. With the modified , we can estimate the sampling variance of ^ in (19.23) as

V^

=

^ 2 N2

·

N

N ,

(19.25)

where N is the vector of dimension N with all elements equal to unity, and ^ 2 is as in

Equation (19.24).

The second complication arises from the use of multiple matches. Let M be the number

of matches. For any pair of units i and i 

let Mii

be the number of shared matches:

Mii

 = 

0 0 #

#

Mic  Mic Mti  Mti

if i = i , if Wi = Wi , if Wi = Wj = 1, if Wi = Wj = 0.

Then define as the N × N with typical element

ij

=

 

1 2/(M + 1) 2/(M + 1) 1/(M + 1) 1/(M + 1) 1/(M + 1) 1/(M + 1) Mij/(M(M + 1))

if i = i ,
if i = i , Wi = 0, Wi = 1, i  Mit, i  Mic , if i = i , Wi = 1, Wi = 0, i  Mci , i  Mit , if i = i , Wi = 0, Wi = 1, i  Mit, i / Mci , if i = i , Wi = 1, Wi = 0, i  Mic, i / Mti , if i = i , Wi = 0, Wi = 1, i  Mit , j / Mci , if i = i , Wi = 1, Wi = 0, i  Mic , j / Mti, if i = i , Wi = Wi ,

and we can estimate the sampling variance again as V^ = N N^ 2/N2. For the bias-adjusted matching estimator, we first define

X^ i(0) =

Xi
1 M

if Wi = 0, jMic Xj if Wi = 1,

and X^ i(1) =

Xi

if Wi = 1,

1 M

jMci Xj if Wi = 0.

19.10 Alternative Estimators for the Sampling Variance

459

Next we define

Y~i(0) =

Y^ i (0)

if Wi = 0,

Y^i(0) + Xi - X^ i(0) ^0 if Wi = 1,

and Y~i(1) =

Y^ i (1)

if Wi = 1,

Y^i(1) + Xi - X^ i(1) ^1 if Wi = 0.

Then, the bias-adjusted matching estimator is

^ adj =

1 N

N i=1

Y~i(1) - Y~i(0)

.

We use the sampling variance estimator in (19.25), replacing ^ 2 in this expression with

~ 2

=

N

1 -

1

Y~i(1) - Y~i(0) - ^ adj

2
.

The estimator for the sampling variance of ^bias-adj is then

V^ bias-adj

=

~ 2 N2

·

N

N .

(19.26)

For the matching estimator based on the trimmed lottery sample, and a single match, using the variance estimator in (19.26) leads to an estimated sampling variance of

V^ bias-adj = 1. 182.

19.10.2 Bootstrap Sampling Variance Estimators
In this section we discuss resampling methods for estimating the sampling variance of estimators for average treatment effects. Resampling methods have become popular in the empirical literature, partly due to the lack of guidance in the theoretical literature regarding sampling variance estimation, and partly due to its conceptual simplicity and computational ease of implementation. Nevertheless, for two reasons we do not generally recommend the bootstrap here. First of all, there is theoretical evidence against its validity. The intuition for the theoretical results rests on the non-smooth nature of matching estimators. For example, if one matches treated units, adding a replicate of a control unit to a bootstrap sample does not affect the point estimate of the matching estimator. Second, at best it delivers the sampling variance for the estimator with estimand equal to the super-population average treatment effect, rather than the sample average treatment effect, and we are often interested in the sampling variance of estimators for the sample average treatment effect.
Here we implement a simple version of the bootstrap. We bootstrap separately the control and treated subsamples, to create a bootstrap sample of size N, with Ncunits

460

Sampling Variances for Standard Estimators for Average Causal Effects

in the control group and Nt units in the treatment group. Given this bootstrap sample, we follow exactly the same procedure as applied to the original sample to calculate the bootstrap estimate. For the subclassification estimator, this procedure includes reestimating the propensity score, choosing the optimal number of subclasses again, and averaging the within-subclass estimates over the blocks. For the matching estimator, this includes re-normalizing the pre-treatment variables, and then matching the treated and control units again. Note that, in the bootstrap sample, there will likely be many ties, even if in the original sample there are no ties. This is one reason for the failure of the bootstrap to deliver valid confidence intervals for matching estimators.
Given the B bootstrap estimates, denoted by ^b, b = 1, . . . , B, we calculate the bootstrap variance as the sampling variance over the bootstrap estimates, V^ boot =
b (^b -  boot)/(B - 1), where  boot = b ^b/B is the average over the bootstrap estimates.
There is no formal justification for the bootstrap for either the subclassification or the matching estimator. In fact, it has been shown that using the bootstrap sampling variance estimator can lead to confidence intervals with over, or under, coverage for matching estimators.

19.11 CONCLUSION
In this chapter we discuss an approach to frequentist inference for average treatment effects that applies to many estimators. The approach relies on the characterization of estimators as weighted averages of the observed outcomes, with the weights known functions of the covariates and treatment indicators. Given this characterization, the only unknown component of the sampling variance of the estimator is the unit-level outcome variance conditional on specific covariate values. We propose an estimator for this unit-level variance, and show how it can be used to estimate the sampling variance of estimators for the average treatment effect.
We briefly compare this estimator for the sampling variance to two alternatives, one analytic and one based on resampling.

NOTES
The theoretical discussion in this chapter builds heavily on the papers by Abadie and Imbens (2006, 2008, 2009, 2010). These studies also present simulation evidence for the effectiveness of the matching estimators of sampling variances, at least in certain situations, as well as of evidence of theoretical problems with the bootstrap in the same situations. Simulation evidence demonstrating problems with the bootstrap are also presented in Du (1998). For general bootstrap discussions and alternative resampling strategies, see Efron and Tibshirani (1993), Horowitz (2002), and Politis and Romano (1999).

CHAPTER 20
Inference for General Causal Estimands
20.1 INTRODUCTION
Much of the discussion in the fourth part of the book focused on an average treatment effect as the causal estimand of primary interest. Although this is an important case, many of the analyses extend to other causal estimands in a conceptually straightforward manner. In this chapter we discuss some examples of other estimands, and show how some of the earlier analyses apply with other estimands.
In many cases concerning causal questions, average effects are the most obviously interesting objects. Sometimes the focus is on average effects after taking some transformation of the outcome, possibly involving pre-treatment variables, but this does not lead to any conceptual problems or operational difficulties when applying the analyses from the previous chapters. In other cases, however, the causal estimands are conceptually distinct from average treatment effects. This includes situations where the average effect is just one of the objects of interest, as well as settings where the primary object is not an average effect. For example, policy makers may be interested in the effect of a new program on specific parts of the distribution of outcomes. In a labor market training program, policy makers may be less interested in the effect of the program on relatively high-earning individuals, instead being more concerned about the effect on the left tail of the distribution. In that case, differences between quantiles of the two potential outcome distributions may be more interesting estimands. Alternatively, policy makers may be interested in the effect of a new program on inequality in outcomes, say, through the effect of the treatment on the variance or the inter-quartile range of the distribution of outcomes.
The approach to estimation and inference that is the focus here is model-based imputation, which has a number of conceptual advantages relative to other approaches. The most important one is that once the missing potential outcomes are imputed, any causal estimand of the type we consider can be directly calculated. As a result, under this approach, estimation of and inference for any causal estimand are conceptually straightforward. We can therefore consider a variety of estimands given the same model for the potential outcomes. In contrast, if one uses, say, regression estimates, one would implicitly be using different models for the potential outcomes when focusing on the average
461

462

Inference for General Causal Estimands

effect versus the median effect of the treatment. The main alternative to using modelbased imputation is weighting. Weighting approaches also can be used to estimate a variety of estimands, including some of the causal estimands considered in this chapter. As discussed in Chapter 12, a concern with weighting methods, specifically when weights must be estimated, is that the resulting estimators for causal effects can be particularly sensitive to the model for the propensity score. As a result, relatively minor changes in the specification for the propensity score can lead to substantial changes in the estimates of causal effects.
To implement the imputation of the missing potential outcomes, in our preferred approach we first estimate the propensity score. Next we block on the estimated propensity score. Within blocks defined by the estimated propensity score, we build parametric models for the outcome distributions conditional on the covariates, possibly with crossblock restrictions. We then use these models to impute the missing potential outcomes. Note that different models for imputation will generally be used for different outcome variables, an approach that fundamentally differs from the weighting or the pure propensity score approaches in important ways that give the model-based approaches substantial flexibility to obtain reliable causal effect estimates.
The rest of this chapter is organized as follows. In the next section we describe the data used in this chapter, originally collected and analyzed by Lalonde (1986), and previously used in Chapter 14, and we conduct some preliminary analyses on the data based on the previous chapters. In Section 20.3 we introduce some causal estimands that are of interest in the context of this application. In Section 20.4 we discuss the models for the potential outcomes used in this chapter. Next, in Section 20.5 we discuss the implementation of the methods. In Section 20.6 we return to the Lalonde data and report results for the application. Finally, Section 20.7 concludes.

20.2 THE LALONDE NSW OBSERVATIONAL JOB-TRAINING DATA
Here we return to the non-experimental part of the Lalonde data that we previously used in Chapter 14. The treated subsample consists of 185 men, and the control sample consists of 15,992 men. We first estimate the propensity score on the full sample of 16,177 men. As discussed in Chapter 14, there are substantial differences in the covariate distributions between the treated and control subsamples. We then use the trimming described in Chapter 16 to construct subsamples with more overlap. The estimated optimal threshold based on the methods from Chapter 16 is 0.0792. Dropping men with an estimated propensity score below 0.0792 or above 1-0.0792 = 0.9208 leaves us with a subsample consisting of Nc = 282 men in the control sample and Nt = 151 men who received the job training. Table 20.1 gives summary statistics for this trimmed sample. In the trimmed sample, the overlap is still limited, with the normalized difference for some covariates as large as 0.54. Nevertheless, this is a substantial improvement over the original sample where some normalized differences were in excess of 2.0 (see Table 14.7 in Chapter 14).
Next we re-estimate the propensity score. This time the algorithm from Chapter 13 selects eight linear terms and six second-order terms. The parameter estimates for the propensity score models are reported in Table 20.2. Given this estimate of the propensity score, we construct blocks based on the methods from Chapter 17. The algorithm

20.2 The Lalonde NSW Observational Job-Training Data

463

Table 20.1. Summary Statistics for Trimmed Lalonde Non-Experimental Data

Controls (Nc =282)

Trainees (Nc =151)

mean (S.D.) mean (S.D.)

black hispanic age married nodegree education earn '74 unempl '74 earn '75 unempl '75

0.92 0.06 25.13 0.26 0.64 10.54 2.75 0.52 1.84 0.39

(0.27) (0.23) (7.64) (0.44) (0.48) (3.05) (4.63) (0.50) (2.66) (0.49)

0.95 0.03 25.70 0.13 0.74 10.26 1.67 0.77 1.01 0.66

(0.21) (0.18) (7.02) (0.34) (0.44) (2.05) (4.64) (0.42) (1.97) (0.48)

pscore

0.26 (0.19) 0.51 (0.24)

linearized pscore -1.26 (1.12) 0.07 (1.15)

Nor Log Ratio Dif of STD

0.15 -0.12
0.08 -0.32
0.22 -0.11 -0.23
0.54 -0.36
0.56
1.15 1.18

-0.27 -0.26 -0.08 -0.25 -0.09 -0.40
0.00 -0.17 -0.30 -0.03
0.22 0.03

Table 20.2. Estimated Parameters of Propensity Score for the Trimmed Lalonde Non-Experimental Data

Variable
Intercept Linear terms earn '74 unempl '74 earn '75 unempl '75 married black nodegree age

Est (s. e. ) t-Stat -11.65 (0.13) -92.6

0.15 -1.76
0.45 -0.95 -3.15
2.70 1.33 0.55

(0.04) (1.17) (0.38) (1.18) (0.79) (0.55) (0.35) (0.12)

3.4 -1.5
1.2 -0.8 -4.0
4.9 3.8 4.7

Second-order terms

age × age

-0.01

married × nodegree

2.16

unempl '74 × age

0.12

earn '74× nodegree

-0.10

earn '75 × black

-0.58

unempl '74 × unempl '75 1.89

(0.00) (0.86) (0.05) (0.05) (0.38) (1.20)

-5.1 2.5 2.4
-2.0 -1.5
1.6

from that chapter leads to eight blocks. Summary statistics for the blocks are reported in Table 20.3.
Using the blocking estimator discussed in Chapter 17, including within-block regression adjustment, we obtain an estimate for the average effect for the treated equal to 2.33 (in thousands of dollars), with a standard error of 0.92. In this chapter, however, we are

464

Inference for General Causal Estimands

Table 20.3. Optimal Subclassification for the Trimmed Lalonde NonExperimental Data

Subclass Min P-Score Max P-Score # Controls # Treated t-Stat

1

0.00

0.17

96

4

0.8

2

0.17

0.18

11

5

-0.1

3

0.18

0.22

46

10

0.9

4

0.22

0.29

37

19

-0.2

5

0.29

0.40

38

19

0.4

6

0.40

0.47

15

19

0.4

7

0.47

0.73

29

38

0.5

8

0.73

1.00

10

38

1.6

0.5

0.45

0.4

0.35

0.3

Density

0.25

0.2

0.15

0.1

0.05

0

0

10

20

30

40

50

60

70

1978 Earnings

Figure 20.1. Histogram of 1978 earnings, trimmed Lalonde non-experimental data

interested in different causal estimands, and we will therefore build more flexible models for the conditional potential outcome distributions given the covariates and treatment levels. To inform the choice of such models, it is useful to inspect the marginal distributions of the observed outcomes, earnings in 1978 in thousands of dollars, either for the full trimmed sample, or separately by treatment group. Figure 20.1 presents a histogram of the outcome for the trimmed sample with 433 men. Two key features are the large proportion of individuals with zero earnings and the excess skewness and kurtosis of the distribution of earnings conditional on earnings being positive. In the trimmed sample, the proportion of men with zero earnings is 0.29, and the skewness among those positive earnings is 2.0, and the kurtosis is 10.7. It should also be noted that there is

20.3 Causal Estimands

465

an extreme value for the outcome. One individual in the trainee sample had subsequent 1978 earnings over $60,000. The next highest earning individual had yearly earnings less than $40,000. To put this in context, the average earnings for trainees in 1974 and 1975, respectively, are $1,670 and $1,010, with maximum values in the sample in those years equal to $31,000 and $11,500. Given that there are only 151 trainees in our sample, changing the 1978 earnings for this one man from over $60,000 to less than $40,000. would lower the point estimate of the average treatment effect substantially, from $2,327 to $2,170. We will attempt to take these features into account when developing models for the conditional distributions of the potential outcomes.

20.3 CAUSAL ESTIMANDS

At the very beginning of this book, in Chapter 1, we defined causal estimands to be a general function of the potential outcomes, the covariates, and the vector of treatment assignments,

 =  (Y(0), Y(1), X, W).

(20.1)

Because of tradition and mathematical tractability we often focused on the finite-sample average effect

fs

=

1 N

N

Yi(1) - Yi(0) ,

i=1

or the super-population average treatment effect

sp = Esp[Yi(1) - Yi(0)].

In this chapter we consider two alternatives. For example, in a job-training program, policy makers may be interested in the effects of the program on the lower tail of the distribution. We can do this in a variety of ways. We may simply look at the average effect on a transformation of the original outcome. For example, we could define as the outcome whether an individual has positive earnings, or earnings exceeded some threshold level, such as some measure of the poverty level. Such transformations do not require any conceptual change in the methods discussed in previous chapters. Here we discuss some causal estimands that cannot be written as average effects on transformations of the original outcomes.

20.3.1 Quantile Treatment Effects
Distributional effects may conveniently be summarized by the difference in quantiles of the empirical distribution of the potential outcomes. For any outcome Y, with observations on N units Y1, . . . , YN, define qsY to be the sth quantile of the empirical

466

Inference for General Causal Estimands

distribution of Yi:

qsY

=

inf
q

1N

q  {-, } N

1Yiq  s

.

i=1

Then we can define the sth quantile treatment effect as the difference of the sth quantile of the Yi(1) and Yi(0) distributions:

qsuant = qYs (1) - qsY(0).

We can estimate quantile treatment effects at different quantiles. Using the median gives a more robust estimate of a "typical" effect, although it should be kept in mind that the difference in medians by treatment status is generally not the median of the unit-level treatment effects. We can also look at differences in lower or higher quantiles to assess the effect of the treatment at the bottom or top of the distribution.

20.3.2 Causal Effects on Dispersion and Inequality
A conceptually very different estimand we consider in this chapter is a measure of inequality of the outcome distributions. A simple measure of this would be the difference in standard deviations in the two potential outcome distributions:

sd =

1N N - 1 i=1

Yi(1) - Y(1) 2 -

1N N - 1 i=1

Yi(0) - Y(0) 2.

Such a measure may be sensitive to the presence of outliers, in which case a more robust measure might be the interquartile range:

iqr = q0Y.(715) - qY0.(215) - q0Y.(705) - q0Y.(205) .

Alternatively, a common scale-free measure of inequality widely used in the social sci-
ences is the so-called Gini coefficient. The Gini coefficient is often used to measure
inequality of wealth. Given the ordered non-negative values 0  Y1 < Y2 < . . . < YN, define the Lorenz curve as the piece-wise linear function LY (y) : [0, 1]  [0, 1], going through the N + 1 pairs of values (F0Y , L0Y ), . . . , (FNY , LNY ) where (F0Y , L0Y ) = (0, 0), and, for i = 1, . . . , N,

FiY

=

i ,
N

and

LiY =

i j=1
N j=1

Yi Yi

.

The Lorenz curve LY (v) for, say, wealth, at a value y  [0, 1], measures the share of the total wealth held by the bottom v proportion of the population. If wealth is shared equally, the Lorenz curve is equal to the forty-five-degree line, LV (v) = v. The Gini coefficient, denoted by G, is a scalar functional of the Lorenz curve, measuring the area

20.3 Causal Estimands

467

between the forty-five-degree line and the Lorenz curve as a share of the area underneath the forty-five-degree line:

1
GY = 1 - 2 LY (y) dy.
0

(20.2)

If all values Zi are identical, there is no inequality, the Lorenz curve equals to the fortyfive-degree line, and the Gini coefficient is zero. The other extreme value is one, which occurs when all values Zi are zero other than ZN (and so all wealth is concentrated the hands on one extremely wealthy individual). There are other measures of inequality available in the literature, but the Gini coefficient is widely used.
The causal estimand we focus on is the difference in Gini coefficients, the causal effect of the program on the Gini coefficient of the outcome distribution:

gini = GY(1) - GY(0).

Policy makers may be interested to know whether the program increases inequality in earnings in the population.

20.3.3 Other Estimands
Here we focus primarily on two estimands, qsuant for some specific values of s, and gini. Many other estimands are possible. It is important, however, to note one common aspect of the two estimands we consider here. Both are functionals of the two marginal distributions of the potential outcomes, rather than functionals of the full joint distribution of the pair of potential outcomes. An example of a functional of the (full) joint distribution that cannot be written as a functional of the two marginal potential outcome distributions, and that is sometimes discussed in the literature, is the sth quantile of the difference in potential outcomes, which is generally different from the difference in the sth quantiles. In contrast to the distinction between the quantile of the difference and the difference in the quantiles, the average of the treatment effects is identical to the difference in the averages of the potential outcomes, because of the linearity of the expectations operator. In principle, the methods discussed in this chapter apply equally to estimands such as the median of the treatment effect, and we can directly apply the methods discussed in this chapter. In practice, though, it can be difficult to draw precise inferences about causal estimands that depend on the dependence structure of the potential outcomes. As discussed in the chapters on model-based inference in randomized experiments (Chapter 8), the data are not directly informative about the conditional dependence structure of the potential outcomes given covariates, and therefore prior information about the dependence structure may have important effects on posterior distributions, even in large samples. A question that sometimes arises is which object is of more interest, the median of the differences or the differences in the medians. In general, that question is difficult to answer without context. However, often policy makers contemplate exposing all units in a population (possibly homogeneous in characteristics) to the treatment versus no units. In that case, their decision should be based solely on the two marginal potential outcome distributions, not on the joint distribution of potential outcomes.

468

Inference for General Causal Estimands

20.4 A MODEL FOR THE CONDITIONAL POTENTIAL OUTCOME DISTRIBUTIONS

The main model we consider is similar to the fourth model in Chapter 8 used for the model-based analysis of the experimental part of the Lalonde data. First we describe the general model and then extend it to the current setting that has substantial differences in the covariate distributions between the two treatment groups.

20.4.1 Single Block ­ Model I
We separately model the distribution of potential outcomes for each of the two treatment levels. For each treatment group we build a model for two parts of the conditional distribution given the pre-treatment variables Xi (all ten covariates other than the two indicators for ethnicity, black and hispanic, because there is little variation in ethnicity in the sample). Note that by unconfoundedness, these conditional distributions are free of dependence on Wi, that is, the same for units with Wi = 0 and Wi = 1. First, consider the probability of a positive value for Yi(0). A possible model for the event of a positive value for Yi(0) is a logistic model:

Pr(Yi(0)

>

0|Xi,  )

=

1

exp (c,0 + + exp (c,0

Xic,1) + Xic,1)

,

(20.3)

and, analogously, we model the probability of a treated potential outcome for treated outcome as

Pr(Yi(1)

>

0|Xi,  )

=

1

exp (t,0 + + exp (t,0

Xit,1) + Xit,1)

.

Second, we build models for the distributions of Yi(0) and Yi(1) conditional on a positive value for the potential outcome. Here, taking into account the excess skewness, we assume that the logarithm of the potential outcomes have normal distributions. Thus for the potential control outcome, we assume

ln (Yi(0)) |Yi(0) > 0, Xi,   N c,0 + Xic,1, c2 ,

(20.4)

and for the treated potential treated outcome,

ln (Yi(1)) |Yi(1) > 0, Xi,   N (t,0 + Xit,1, t2 ,

where Yi(0) and Yi(1) are independent conditional on Xi and the parameters. Let  = (c, t, c, t, c2, t2) denote the full parameter vector for these two distributions.
For convenience in conveying ideas, we specify a prior distribution for  that is inde-
pendent in its components and relatively dispersed, and for the regression parameters
c, t, c, and t, we use normal prior distributions centered at zero with the variance equal to 102 times the identity matrix to capture relative ignorance about the components of these parameters. Similarly, for the variance parameters, c2 and t2, we use inverse Chi-squared distributions with parameters 1 and 0. 01 respectively.

20.4 A Model for the Conditional Potential Outcome Distributions

469

The implementation of this model using Markov-Chain Monte Carlo methods is similar to that in Chapter 8. In Table 20.4 we report summary statistics for the posterior distributions of the parameters. These are not of intrinsic interest but are useful to ensure that the posterior distribution is reasonable. Next we report in Table 20.5 the results for the causal estimands.

20.4.2 A Model with Multiple Blocks ­ Model II
The model in the previous subsection is a reasonable one in experimental settings where the covariate distributions are similar for treated and control units. However, in the current setting, even after the trimming, the covariate distributions are substantially different in the two treatment groups. We therefore consider a different model to allow for more flexibility. Specifically, we estimate separate models in each of the eight blocks of the propensity score. In this section we ignore the covariates. Using the methods from Chapter 17, we partition the range of the propensity score into J = 8 blocks, that is, intervals of the type (bj-1, bj), where b0 = 0 and bJ = 1, so that Jj=1(bj-1, bj] = (0, 1], where Bi(j)  {0, 1} is an indicator. Let Bi(j)  {0, 1} be an indicator for unit i being in block j, for j = 1, . . . , J:

Bi(j) =

1 if bj-1  e^(Xi) < bj, 0 otherwise.

Within each block and treatment level, we again specify a model for the event that the outcome is equal to zero, and a model for the outcome conditional on being positive. Specifically, for the control potential outcome Yi(0) in block j, we specify the model

Pr(Yi(0)

>

0|Bi(j)

=

1, )

=

1

exp c(j) + exp c(j)

,

(20.5)

and analogously, we model the probability of a positive outcome for treated outcome in this block as

Pr(Yi(1)

>

0|Bi(j)

=

1, )

=

1

exp t(j) . + exp t(j)

Next, we build a model for the distribution of Yi(0) and Yi(1) in block j conditional on a positive value for the potential outcome. We assume

ln (Yi(0)) |Yi(0) > 0, Bi(j) = 1,   N c(j), c2 ,

(20.6)

and for the potential treated outcome,

ln (Yi(1)) |Yi(1) > 0, Bi(j) = 1,   N t(j), t2 ,

where Yi(0) and Yi(1) are assumed to be independent conditional on the block and the parameter. Here, for simplicity, we let the conditional variances differ by treatment status but not by block.

470

Table 20.4. Single Block Model for Trimmed Lalonde Non-Experimental Data

Sample

Controls

Treated

c

c

t

t

q0.025 med q0.975 q0.025 med q0.975 q0.025 med q0.975 q0.025 med q0.975

Intercept

0.25 1.39 3.20 1.02 1.25 1.48 0.89 4.00 9.05 1.43 1.66 1.89

age

-0.25 -0.09 0.05 -0.05 -0.01 0.03 -0.16 0.06 0.39 -0.04 -0.01 0.03

married

-2.82 -0.00 2.95 -0.38 0.20 0.78 -3.34 4.15 17.68 -0.52 0.08 0.69

nodegree -2.55 0.70 4.02 -0.97 -0.29 0.38 -8.66 -1.64 4.19 -0.97 -0.34 0.30

education -0.44 0.04 0.50 -0.03 0.08 0.18 -1.84 -0.25 0.95 -0.12 0.01 0.14

earn '74 -0.34 0.06 0.57 -0.07 -0.01 0.05 -0.71 0.14 1.45 -0.06 0.01 0.08

unempl '74 -3.02 0.59 4.85 -1.29 -0.66 -0.03 -3.98 6.35 23.43 -0.35 0.47 1.27

earn '75 -0.29 0.44 1.82 -0.01 0.09 0.20 -2.93 -0.12 2.22 -0.15 0.03 0.21

unempl '75 -4.87 -0.94 2.30 -0.42 0.23 0.88 -28.20 -6.64 4.07 -0.81 -0.10 0.61



1.30 1.43 1.59

0.95 1.08 1.24

471

Table 20.5. Model-Based Analysis for Various Estimands for Trimmed Lalonde Non-Experimental Data

avg Model q.025 med q.975

med

Yi > 0

Yi > 1

q.025 med q.975 q.025 med q.975 q.025 med q.975 q.025

Gini med

q.975

I,fs

1.71 3.11 4.00 -0.52 1.65 3.35 -0.09 0.11 0.31 0.01 0.18 0.34 -0.23 -0.16 -0.07

I,sp -0.10 2.43 4.82 -0.97 2.17 5.28 -0.16 0.13 0.40 -0.03 0.22 0.45 -0.25 -0.13 0.01

II,fs 1.12 2.61 4.00 -1.41 0.85 2.74 -0.07 0.07 0.24 -0.01 0.12 0.27 -0.20 -0.13 -0.06 II,sp 0.08 2.25 4.43 -1.81 1.11 4.02 -0.10 0.12 0.34 -0.01 0.20 0.40 -0.24 -0.13 -0.01

III,fs III,sp

2.09 3.19 4.00 -0.53 1.48 3.07 -0.02 0.11 0.24 0.07 0.19 0.30 -0.22 -0.16 -0.10 0.38 2.11 3.85 -0.89 1.77 4.37 -0.08 0.10 0.26 0.02 0.19 0.34 -0.19 -0.11 -0.02

Note: Model I: single block, with covariates; Model II, eight blocks, no covariates; Model III: eight blocks, with covariates; fs, focus on finite sample causal estimand; sp, focus on super-population causal estimand.

472

Inference for General Causal Estimands

Let  = (c(j), t(j), c(j), t(j), j = 1, . . . , J, c2, t2) denote the full parameter vector. Again, we use independent, fairly dispersed prior distributions for all elements of .

20.4.3 Multiple Blocks and Covariates ­ Model III
In our final model we incorporate both the block information and the covariates, and we combine the previous two specifications, using the analogous two-part model. We now specify for the control outcome the probability of a positive outcome as

Pr (Yi(0)

>

0|Xi, Bi(j)

=

1, )

=

1

exp (c,0(j) + + exp (c,0(j)

Xic,1(j)) + Xic,1(j))

,

with, for positive income,

ln (Yi(0)) |Yi(0) > 0, Xi, Bi(j) = 1,   N c,j,0 + c,j,1Xi, c2 ,

and analogously for the treated outcome Yi(1). Thus we allow the intercepts in both models to be block-specific but restrict the slope coefficients to be identical. This restriction is partly motivated by the modest sample size. In some of the blocks there are only a few treated or only a few control units, so that it would be impossible to estimate precisely the slope coefficients separately within each block. An alternative would be a hierarchical structure where the parameters in each block are allowed to be different but are linked through a hierarchical structure through their prior distributions.

20.5 IMPLEMENTATION
We use Markov-Chain Monte Carlo methods to obtain draws from the posterior distribution of the parameters. Then we use two methods to obtain draws from the posterior distribution of the causal estimands. The first method follows closely that of Chapter 8. In this approach we draw values of the parameters from the posterior distribution given the observed data. We then use those parameter values in combination with the statistical model to impute the missing potential outcomes. Finally we calculate the estimand as a function of observed and imputed potential outcomes. Doing so repeatedly gives us the draws from the posterior distribution of the causal estimand.
However, this method does not always give credible results, and it is useful to sound a cautionary note. Specifically, in order for this first method to give accurate results, it relies heavily on the statistical model being a good approximation to the underlying distribution with regard to the particular estimand. For example, suppose we are interested in the average treatment effect for the treated, and we use the two-part model described in the previous section, with no covariates and a single block. We estimate the model for the control outcome using the control units. For this subsample, the proportion of zero outcomes is 0.31. Among the 69% control units with positive outcomes, the average and standard deviation of the logarithm of the outcome are 1.39 and 1.49 respectively. This implies, under the two-part model, that the expected value should be approximately 0.69·exp (1.39+1.492/2) = 8.41, whereas the actual average is 7.71. Because the model

20.6 Results for the Lalonde Data

473

is non-linear, at the fitted values the implied expectation is not necessarily equal to the sample average. In this simple example one could address this by estimating a linear model, but when we look at different estimands, unless the model fits the data well, it will not necessarily give good results for all estimands.
The second method addresses this as follows. We again draw parameter values from the posterior distribution of the parameters given the observed data. Now, however, for all units, we draw values for both potential outcomes. We then calculate the causal estimand as a function of these imputed potential outcomes, instead of combining observed and imputed outcomes. Implicitly this changes the focus from the sample causal estimand to the super-population causal estimand.

20.6 RESULTS FOR THE LALONDE DATA

For the Lalonde data we focus on estimands for the subsample of treated men. There is no interest in extending the labor market training program to the control individuals, only in assessing the benefits, if any, of the training program to those who took part in it. We focus on five estimands. The first is, for comparison purposes with earlier analyses, the average effect of the treatment on the treated:

fs,t

=

1 Nt

i:Wi=1

Yi(1) - Yi(0)

.

The second estimand is, the difference in medians of Yi(1) and of Yi(0) for the treated units. First, extending the earlier definitions, we define the quantiles for the treated subsample as







qYs ,t

=

inf
q

q

:

1 Nt

i:Wi=1

1Yiq



 s .

Then we define the sth quantile treatment effect for the treated as the difference of the sth quantile of the Yi(1) and Yi(0) distributions for the treated:

qsuant,t = qYs (1),t - qsY(0),t.

Here we focus on the difference in medians,

med,t = q1Y/(12),t - qY1/(02),t.

The next estimand is the causal effect of the treatment on the probability of having positive earnings,

pos,t

=

1 Nt i:Wi=1

1Yi(1)>0 - 1Yi(0)>0

,

474

Inference for General Causal Estimands

and the probability of having earnings exceeding 1 ($1,000),
1 1,treated = Nt i:Wi=1 1{Yi(1)>1} - 1{Yi(0)>1} .
Finally, the fifth estimand is the difference in Gini coefficients in the Yi(1) and Yi(0) distributions for the treated units. Let GY(1),treated denote the Gini coefficient for the Yi(1) distribution among the treated. Then the causal estimand we focus on is

gini,t = GY(1),t - GY(0),t.

We estimate all three models, the one with covariates (Model I), with block indicators (Model II), and with both covariates and block indicators (Model III) on the Lalonde data.
In Table 20.4 we present posterior percentiles for the parameters of the first model. These parameter estimates are not of intrinsic interest and are presented here for completeness. In Table 20.5 we present posterior percentiles for the causal estimands. There are two rows for the first model, one for the finite-sample causal estimand, where only the control outcomes are imputed for all treated units, and one for the super-population causal estimand, where both control and treated outcomes are effectively imputed in the super-population. In general the estimates suggest that there is a positive effect of the treatment, as seen by the posterior medians for the average and median effects. It also suggests that the program may have led to a modest decrease in inequality as measured by the effect on the Gini coefficient.

20.7 CONCLUSION
In this chapter we discuss estimation of and inference for estimands other than average treatment effects. Under our preferred, model-based approach, there are no conceptual difficulties to studying general causal estimands. The approach of imputing the missing potential outcomes is valid in general. The main issue is that, in many cases, it becomes obvious that one has to be more careful in the choice of models. Depending on the choice of estimand, the results may be sensitive to particular modeling choices.

NOTES
Quantile treatment effects, defined as the difference in quantiles, as in the current chapter, have been considered previously by Lehman (1974). Causal effects of treatments on inequality measured through their effect on the Gini coefficient has been considered by Firpo (2003, 2007). In applied work, Bitler, Gelbach, and Hoynes (2006) study distributional effects beyond the average treatment effects and find, in the context of a randomized labor market program, that the effects are bigger at the lower tail of the distribution than in the upper tail.

Notes

475

For an early study of the sensitivity of estimates of causal effects to the choice of Bayesian model, see Rubin (1983); this example is discussed further in Gelman, Carlin, Stern, and Rubin (1995).
The discussion regarding the difference between, on the one hand, the difference between the medians of the potential outcomes by treatment status and the median of the difference in potential outcomes is an old one. See for recent comments on this Manski (1996), Deaton (2010), and Imbens (2010).
The first general discussion of the imputation approach to inference for general causal estimands beyond average treatment effects is in Rubin (1978). Althauser and Rubin (1970) discuss computational issues.
Dehejia (2005b) and Manski (2013) discuss decision problems in a treatment effect context, where the intermediate focus is often on more complex estimands than simple average treatment effects.

PART V
Regular Assignment Mechanisms: Supplementary Analyses

CHAPTER 21
Assessing Unconfoundedness
21.1 INTRODUCTION
The previous three chapters assume a regular assignment mechanism, requiring the assignment mechanism to be individualistic, probabilistic, and unconfounded. In this chapter we maintain the first two conditions, which are often uncontroversial, and focus on the plausibility of the third, most controversial assumption, unconfoundedness. Formally, unconfoundedness requires that the probability of treatment assignment is free of dependence on the potential outcomes. Specifically, the super-population version implies, by Theorem 12.1, first, that the conditional distribution of the outcome under the control treatment, Yi(0), given receipt of the active treatment and given covariates, is identical to its distribution conditional on receipt of the control treatment and conditional on covariates, and second, that, analogously, the conditional distribution of the outcome under the active treatment, Yi(1), given receipt of the control treatment and conditional on covariates, is identical to its distribution given receipt of the active treatment and conditional on covariates. Informally, unconfoundedness requires that we have a sufficiently rich set of pre-treatment variables so that adjusting for differences in values for observed pre-treatment variables removes systematic biases from comparisons between treated and control units. This critical assumption is not testable. The issue is that the data are not directly informative about the distribution of the control outcome Yi(0) for those who received the active treatment (for those with Wi = 1, we never observe Yi(0)), nor are they directly informative about the distribution of the active treatment outcome given receipt of the control treatment (for those with Wi = 0, we never observe Yi(1)). Thus, the data cannot directly provide evidence on the validity of the unconfoundedness assumption. Nevertheless, here we consider ways to assess the plausibility of this assumption from the data at hand.
The analyses discussed in this chapter are supporting or supplementary analyses that can, depending on their results, increase or reduce the credibility of the main analyses. These supporting analyses focus on estimating, and doing inference for, "pseudo"-causal estimands with a priori known values, under assumptions more restrictive than unconfoundedness. If these analyses suggest that the null hypotheses assessing whether these pseudo-causal effects are equal to their null values are not supported by the data, then the unconfoundedness assumption will be viewed as less plausible than in cases where
479

480

Assessing Unconfoundedness

these null hypotheses are supported by the data. How much the results of these analyses change our assessment of the unconfoundedness assumption depends on specific aspects of the substantive application at hand, in particular on the richness of the set of pre-treatment variables, their number and type.
The results of these assessments of the unconfoundedness assumption may suggest that unconfoundedness is less plausible than we thought beforehand, and thus that important pre-treatment differences between treated and control units may not have been measured. An important point is that finding pseudo-causal effects different from their known values generally will not suggest an alternative approach to estimating the causal estimands. Establishing that methods based on adjusting for observed differences between control and treated units may be unlikely to be adequate for drawing credible causal inferences does not imply the existence of credible alternative methods for causal inferences based on alternative assumptions. The implication may, therefore, be that, given the current data, it is simply not possible to estimate credibly and precisely the causal effects of interest and that one may either have to abandon any attempt to do so without either additional information or without richer data, or at least should be explicit about the lack of credibility.
The specific methods discussed in this chapter are divided here into three classes. The first class of methods can be viewed as comprising a design approach, not requiring data on the outcome variable. We partition the full set of pre-treatment variables into two parts, the first set consisting of some selected pre-treatment variables, and the second set consisting of the remaining covariates. Typically the first set consists of a single pre-treatment variable, but in principal it can consist of multiple pre-treatment variables. It takes the first set of selected pre-treatment variables and analyzes them as pseudo-outcomes, known a priori not to be affected by versus treatment control. These pre-treatment variables will be viewed in this approach as "proxy" variables for the potential outcomes, variables likely to be statistically associated with the potential outcomes. In principle, such a proxy variable can be any pre-treatment variable. However, the most compelling case arises when the proxy variable is a lagged outcome, that is, a measure of the same substantive quantity as the outcome but measured at a point in time prior to the receipt of treatment. We then assess the null hypothesis that there are no systematic differences in the pseudo-outcome by treatment status, after adjusting for the second set of covariates. We refer to this hypothesis as pseudo-outcome unconfoundedness. A finding that one cannot reject the null hypothesis that these pseudocausal effects are zero (or small) lends credibility to the unconfoundedness assumption based on the full set of covariates. Again, this approach is not a direct assessment of the unconfoundedness assumption. Even if the null hypothesis of no treatment effect on the pseudo-outcome is found to be implausible, one cannot be confident that the hypothesis underlying the planned main analysis, unconfoundedness, is violated. Nevertheless, if two conditions are satisfied, we will argue that the assessment is informative about the credibility of the analysis under unconfoundedness. The first is that the pseudo-outcome used in this assessment is a good proxy for one of the potential outcomes. The second condition is that subset unconfoundedness (which requires that the pseudo-outcome is not required for unconfoundedness to hold) is plausible ­ in other words, that there should be an a priori argument that the pseudo-outcome is not essential for removing

21.1 Introduction

481

biases in comparisons between treated and control units given the second set of pretreatment variables. This is often most compelling if the pseudo-outcome differs from some of the remaining pre-treatment variables only in the time of measurement. In cases where all the pre-treatment variables are qualitatively different, it may be more difficult to argue that any of the pre-treatment variables can be omitted without leading to violations of unconfoundedness. This first approach to assessing unconfoundedness is a design approach that does not use data on the outcome variable.
The second approach to assessing the unconfoundedness assumption focuses on pseudo-causal effects for the original outcome. Instead of focusing on causal effects of the actual treatment, this approach analyzes the effects of a pseudo-treatment that is known a priori not to have a causal effect. We refer to it as a semi-design approach, using only outcome data for the units in the control group. Originally proposed by Rosenbaum (1987), this approach relies on the presence of multiple control groups. Suppose the researcher has available two potential comparison groups consisting of units not exposed to the active treatment. In the main analysis, one may have combined the two comparison groups into a single control group to estimate the treatment effects of interest. However, one can also compare the two comparison groups to each other, arbitrarily viewing one of them as being a "pseudo-treatment" group and the other as a "clean" control group under the stronger version of unconfoundedness that we call group unconfoundedness. Because neither group did, in fact, receive any active treatment, there should be no causal effects of this pseudo-treatment. Statistical evidence of the presence of systematic differences between the two control groups after adjusting for pre-treatment differences (non-zero "pseudo-causal effects") implies that unconfoundedness is violated for at least one of the comparison groups. Finding no evidence of a difference between the two groups does not imply the unconfoundedness assumption is valid, because it could be that both comparison groups exhibit the same bias for comparing the actual treated and control units after adjusting for differences in pre-treatment variables. However, if a priori any potential biases in treatment-control differences between the two control groups are judged to be different, the finding that the hypothesis of a zero effect of the pseudo-treatment is consistent with the data makes the analysis under unconfoundedness more plausible. The key for the force of this approach is to have control groups that are systematically different and, as a result, are likely to exhibit different biases in treatment-control comparisons, if they have any biases at all.
The third class of methods focuses on the robustness of estimates of causal effects to the choice of pre-treatment variables. Here we require outcome data for both the treatment and control groups, and so this is not a design-stage analysis. We again partition the full set of pre-treatment variables into two parts, the first set consisting of some selected pre-treatment variables, and the second set consisting of the remaining covariates. We then assume subset unconfoundedness, where unconfoundedness is assumed to hold conditional only on the remaining set of pre-treatment variables. Given subset unconfoundedness, we estimate the causal effects of the treatment on the actual outcome and compare the results to those based on (full) unconfoundedness to assess the null hypothesis that both unconfoundedness and subset unconfoundedness hold. If we find substantial and statistically significant differences, we would conclude that either (i) the first set of selected pre-treatment variables is critical for unconfoundedness (subset unconfoundedness is violated), or (ii) unconfoundedness does not hold. If

482

Assessing Unconfoundedness

we a priori view that the substantive difference between unconfoundedness and subset unconfoundedness is minor, the implication is that we should be concerned with the unconfoundedness assumption. Clearly this assertion depends on the context and the nature of the variables in the two sets.
In all three approaches, we are interested in assessing the presence and magnitude of causal effects under an unconfoundedness assumption. In practice, we often focus on testing whether an estimated average pseudo-causal effect under unconfoundedness is different from its presumed known value (typically zero). It should be noted, though, that in principle the interest here is in assessing whether there is any effect of the (pseudo)treatment on the (pseudo)-outcome different from its presumed known value, not just a zero average difference. That is, we may therefore wish to go beyond studying average effects and also investigate differences in distributions of outcomes, as well as average outcomes by subpopulations. In doing so, we are interested in both statistically and substantially significant differences between the comparison groups.
The remainder of this chapter is organized as follows. In Section 21.3, we discuss the role of pseudo-outcomes for assessing the unconfoundedness assumption. In the next section, Section 21.4, we discuss how one can exploit the presence of multiple control groups. In Section 21.5 we focus on assessing the robustness of the causal effect estimates to changes in the set of pre-treatment variables. In Section 21.6 we illustrate some of the methods using the Imbens-Rubin-Sacerdote lottery data, which we previously used in Chapters 14, 17, and 19. Section 21.7 concludes.

21.2 SETUP

The setup in this section is largely the same as in the previous chapters. For unit i we
postulate the existence of two potential outcomes Yi(0) and Yi(1), a treatment indicator Wi  {0, 1}, and a vector of covariates or pre-treatment variables Xi. We observe the triple consisting of the vector of covariates Xi, the treatment indicator Wi, and the realized and observed outcome

Yiobs = Yi(Wi) =

Yi(0) if Wi = 0, Yi(1) if Wi = 1.

We consider the super-population unconfoundedness assumption,

Wi  Yi(0), Yi(1) Xi (unconfoundedness),

(21.1)

where the dependence on the parameter  is suppressed. This assumption is not testable, as discussed in Chapter 12.

21.3 ESTIMATING EFFECTS ON PSEUDO-OUTCOMES
In this section we discuss the first approach to assessing unconfoundedness, where we focus on tests for causal effects on pseudo-outcomes. This is an approach that can be used

21.3 Estimating Effects on Pseudo-outcomes

483

at the design stage, without access to outcome data. First we introduce some additional

notation. We partition the vector of covariates Xi into two parts, the first denoted by Xip

("p" for pseudo), and the remainder denoted variables can be written as Xi = (Xip, Xir).

by

Xir,

so

that

the

full

vector

of

pre-treatment

Instead of testing whether the conditional independence assumption in (21.1) holds,

which we showed before is impossible to do from the data at hand, we shall test whether

the following conditional independence relation, which we label pseudo-outcome

unconfoundedness, holds:

Wi  Xip Xir (pseudo-outcome unconfoundedness).

(21.2)

The two issues are, first, the interpretation of assumption (21.2) and specifically its connection to full unconfoundedness (21.1), which is of primary interest, and second, the implementation of the assessment.

21.3.1 Interpretation
The first issue concerns the link between the conditional independence relation in (21.2) and unconfoundedness in (21.1). This link is indirect, because unconfoundedness cannot be tested directly. Here we lay out the arguments for the connection. First consider an additional version of unconfoundedness, which we label subset unconfoundedness

Wi  Yi(0), Yi(1) Xir (subset unconfoundedness).

(21.3)

Subset unconfoundedness is not testable for the same reasons full unconfoundedness is not testable: we do not observe Yi(0) if Wi = 1, and we do not observe Yi(1) if Wi = 0. Here we explore an alternative approach to assess it. Suppose we have a proxy for either
of the potential outcomes, and in particular a proxy or pseudo-outcome whose value
is observed irrespective of the realized treatment status; one can test independence of
that proxy variable and the treatment indicator Wi. We use the selected pre-treatment variable Xip as such a pseudo-outcome or proxy variable. For example, we view Xip as a proxy for Yi(0), and assess (21.3) by testing (21.2), which involves only observed variables.
The most compelling applications of these assessments are settings where the two
steps in going from unconfoundedness (21.1) to the testable condition (21.2) are plau-
sible. One such example occurs when Xi contains multiple lagged measures of the outcome, as in the Imbens-Rubin-Sacerdote lottery study that we use to illustrate
these methods in this chapter. The pre-treatment variables Xi in that application consist of some time-invariant pre-treatment variables Vi (e.g., age, education), and some lagged outcomes (earnings), (Yi,-1, . . . , Yi,-T ). One can implement these ideas using earnings for one of the most recent pre-program years (Yi,-1, . . . , Yi,-T ) as the pseudooutcome Xip. Under unconfoundedness, Yi(0) is independent of Wi given Yi,-1, . . . , Yi,-6 and Vi, which would suggest that it is also plausible that Yi,-1 is independent of Wi given Yi,-2, . . . , Yi,-6 and Vi. Given those arguments, one can plausibly assess

484

Assessing Unconfoundedness

unconfoundedness by testing whether

Wi  Yi,-1 Vi, Yi,-2, . . . , Yi,-6.

(21.4)

The claim now is that finding that (21.4) is not supported by the data would lower the credibility of an analysis that relies on unconfoundedness (21.1), relative to a finding that the relation in (21.4) is consistent with the data.

21.3.2 Implementation
Now we turn again to the implementation of this assessment of unconfoundedness. One
approach to test the conditional independence assumption in (21.2) is to estimate the average difference in Xip by treatment status, after adjusting for differences in Xir. This is exactly the same problem as estimating the average effect of the treatment, using Xip as the pseudo-outcome and Xir as the vector of pre-treatment variables. We can do this using any of the methods discussed in the previous chapters, such as blocking or
matching, ideally in combination with model-based adjustment.
The main limitation of this approach, testing whether an adjusted average difference
is equal to zero, is that it does not test all aspects of the conditional independence
restriction. It effectively tests only whether

E E Xip Wi = 1, Xir - E Xip Wi = 0, Xir = 0.

Pseudo-outcome unconfoundedness (21.2) implies two additional sets of restrictions. First, of all, it implies that

E E g(Xip) Wi = 1, Xir - E g(Xip) Wi = 0, Xir = 0,

for any function g( · ), not just the identity function. We can implement this by comparing average outcomes for different transformations of the pseudo-outcome and testing jointly whether any of the averages effects are zero. For example, for a pseudo-outcome bounded between zero and one, one might test jointly whether the effects of the treatment on 1Xip0.2, 1Xip0.4, 1Xip0.6, and 1Xip0.8 are all zero. For non-negative outcomes such as earnings, we may wish to test whether the average value of earnings, as well as the fraction of individuals with positive earnings, are equal in treatment and control groups. Of course one has to be careful here doing multiple comparisons, because in that case some contrasts may appear substantial just by chance.
Second, the conditional independence restriction in (21.2) implies that, not only on average, but conditional on Xir = xr, for all xr,
E Xip Wi = 1, Xir = xr - E Xip Wi = 0, Xir = xr = 0.

One can therefore also consider tests of the restriction E E g(Xip) Wi = 1, Xir - E g(Xip) Wi = 0, Xir Xir  Xrj = 0,

(21.5)

21.4 Estimating Effects of Pseudo-treatments

485

for some partitioning {Xjr}Jj=1 of the support Xr of the set of remaining covariates Xir. That is, rather than testing whether the overall average effect of the treatment on the pseudo-
outcome differs from zero, one might wish to test the null hypothesis that the average
effect of the treatment on the pseudo-outcome in subpopulations differ from zero.

21.4 ESTIMATING EFFECTS OF PSEUDO-TREATMENTS
We now discuss the second approach to assessing unconfoundedness, which focuses on tests for non-zero causal effects of pseudo-treatments.

21.4.1 Setup
This approach to assess the plausibility of the unconfoundedness assumption relies on the presence of additional control information, specifically, a two-component control group. For this approach, we require outcome data for the control group but not for the treatment group. It could therefore be called a semi-design stage method. We change notation in a subtle way. Let Gi be an indicator variable denoting the generalized treatment group that unit i is a member of. This indicator variable takes on three or more values. For ease of exposition we focus on the case with two control groups and thus three values for Gi, Gi  {c1, c2, t}. Units with Gi = c1 or c2 receive the control treatment, Wi = 0, and units with Gi = t receive the active treatment, Wi = 1:

Wi =

0 1

if Gi = c1, c2, if Gi = t.

Unconfoundedness only requires that

Wi  Yi(0), Yi(1) Xi,

(21.6)

which is not testable with the data at hand. Instead we focus on testing an implication of the stronger conditional independence relation, which we label group unconfoundedness:

Gi  Yi(0), Yi(1) Xi, (Group Unconfoundedness)

(21.7)

This independence condition implies unconfoundedness, but in contrast to unconfoundedness, it has testable restrictions. In particular, we focus on the implication that

Gi  Yi(0) Xi, Gi  {c1, c2},

which is equivalent to

Gi  Yiobs Xi, Gi  {c1, c2},

(21.8)

because Gi  {c1, c2} implies that Wi = 0, and thus Yiobs = Yi(Wi) = Yi(0). This conditional independence condition has the same form as (21.2), and we test it in the same

486

Assessing Unconfoundedness

fashion. Again we discuss first the link between (21.8) and unconfoundedness, (21.1), and second the implementation of tests of this conditional independence assumption.

21.4.2 Interpretation
Because condition (21.12) is stricly stronger than unconfoundedness, (21.1), the question is whether there are interesting settings where the weaker and untestable condition of unconfoundedness holds but not the stronger condition. To discuss this question, it is useful to consider two alternative unconfoundedness-like conditional independence conditions, both of which are implied by (21.6):

Wi  Yi(0), Yi(1) Xi, Gi  {c1, t},

(21.9)

and

Wi  Yi(0), Yi(1) Xi, Gi  {c2, t}.

(21.10)

If (21.9) holds, then we can estimate causal effects by invoking the unconfoundedness assumption using only the first control group. Similarly, if (21.10) holds, then we can estimate causal effects by invoking the unconfoundedness assumption using only the second control group. The point is that it is difficult to envision a situation where unconfoundedness based on the two comparison groups (21.6) holds, but using only one of the two comparison groups the unconfoundedness condition fails (i.e., neither (21.9) nor (21.10) holds). So, in practice, if unconfoundedness holds, typically also the stronger condition (21.6) would hold, and we have the testable implication (21.8). Again, there is no theorem here, but an implication that when stronger conditional independence assumptions are false, weaker conditional independence assumptions are more likely also to be false.

21.4.3 Implementation
The implementation of the test follows the same pattern as the implementation of the tests of (21.2). We test whether there is a difference in average values of Yiobs between the two control groups, after adjusting for differences in Xi. That is, we effectively test whether

E E Yiobs Gi = c1, Xi - E Yiobs Gi = c2, Xi = 0.

We can then extend the test by simultaneously testing whether the average value of transformations of the form g(Yiobs) differs by group, that is, whether

E E g(Yiobs) Gi = c1, Xi - E g(Yiobs) Gi = c2, Xi = 0.

In addition we can extend the tests by assessing the null hypothesis whether, given a partition {Xj}jJ=1 of the support X of Xi,

E E g(Yiobs) Wi = 1, Xi - E g(Yiobs) Wi = 0, Xi Xi  Xj = 0,

(21.11)

for all subsets Xj, for j = 1, . . . , J.

21.5 Robustness to the Set of Pre-treatment Variables

487

21.5 ROBUSTNESS TO THE SET OF PRE-TREATMENT VARIABLES

Here we discuss the third approach to assessing unconfoundedness: investigating the sensitivity of the estimates of causal effects to the choice of pre-treatment variables used for adjustments.

21.5.1 Subset Unconfoundedness and Robustness
We use the same notion of partitioning the set of pre-treatment variables into two parts that we introduced in Section 21.3. Again let us consider subset unconfoundedness:

Wi  Yi(0), Yi(1) Xir (subset unconfoundedness).

(21.12)

If this subset unconfoundedness condition were to hold, one could use the adjustment methods described in Chapters 17 and 18, using only the subset of covariates Xir, instead of the full vector of pre-treatment variables Xi to obtain apporoximately unbiased estimates of treatment effects. Although this is not a formal result, subset unconfoundedness
in (21.3) is intuitively a more restrictive condition than the original unconfoundedness
condition (21.1). One has to be careful because it is theoretically possible that conditional on a subset of the covariates (e.g., Xir) subset unconfoundedness (21.3) holds, but at the same time, unconfoundedness (21.1) does not hold conditional on the full set of covariates (Xir, Xip). In practice, however, this situation is rare if all covariates are proper pre-treatment variables. For example, it is difficult to imagine in an evaluation of a labor
market program where unconfoundedness would hold given age, last year's earnings,
and the level of education, but not hold if one additionally conditions on sex. Generally
having subpopulations that are more homogeneous in pre-treatment variables improves
the plausibility of unconfoundedness, although, again, theoretically it is possible that the
biases are exactly canceled out if one of the pre-treatment variables is omitted from the
analysis. This possibility, however, appears to be of little practical interest.
The main concern for the application of this approach is not this remote possibility of canceling biases but the very real possibility that the pseudo-outcome Xip may be critical to unconfoundedness, and so that (21.1) may hold, but not (21.3). This is likely to be the case if Xip is qualitatively different from the variables in Xir. Again this reinforces the idea that this approach is most valuable when Xi contains several variables that differ from each other only in their time of measurement.
On its own, the assumption of subset unconfoundedness is not directly testable for the
same reason that unconfoundedness is not testable: it restricts distributions of missing
potential outcomes in terms of distributions of observed potential outcomes. However,
the combination of the two assumptions, subset unconfoundedness (21.3) and uncon-
foundedness (21.1), both not testable on their own, does have testable implications. The combination implies that adjusting for differences in the subset of covariates Xir and adjusting for differences in the full set of covariates Xi should give similar point estimates (but not necessarily precisions). Thus, we can compare point estimates based on
adjusting for the full set of covariates and the subset of covariates. If we find that the
results are statistically different for the two sets of covariates, it must be that at least one

488

Assessing Unconfoundedness

of the two assumptions, (full) unconfoundedness or subset unconfoundedness, does not hold. The fact that, in that case, the presence of Xip is critical for the adjustment suggests that there may be concerns about unconfoundedness in general. On the other hand, if we
find that the point estimates based on the two assumptions are similar, one may be more
confident in the underlying unconfoundedness assumption.
One of the leading examples occurs when Xi contains multiple lagged measures of the outcome. For example, in the evaluation of the effect of a labor market program
or lottery on annual earnings, one might have observations on earnings for multiple
years prior to the program. Consider the Imbens-Rubin-Sacerdote lottery data, where
we have six years of annual earnings prior to winning the lottery. Denote these lagged outcomes by Yi,-1, . . . , Yi,-6, where Yi,-1 is the most recent and Yi,-6 is the most distant (in time) pre-lottery earnings measure, and denote the remaining covariates by Vi, so that Xi = (Yi,-1, . . . , Yi,-6, Vi). Unconfoundedness corresponds to the independence relation

Wi  Yi(0), Yi(1) Vi, Yi,-1, Yi,-2, . . . , Yi,-6.

(21.13)

This assumption is not testable with the data at hand. However, one could implement the
foregoing ideas using earnings for the most recent pre-program year Yi,-1 as the selected pre-treatment variable Xip, so that the vector of remaining pre-treatment variables Xir would still include the five prior years of pre-program earnings, Yi,-2, . . . , Yi,-6, and the additional pre-treatment variables Vi. In that case, one might reasonably argue that, on a priori grounds, unconfoundedness is viewed as reasonable given the presence of six
years of pre-program earnings (i.e., (21.13) holds), and it is plausible that it would also
hold given only five years of pre-program earnings, so that also

Wi  Yi(0), Yi(1) Vi, Yi,-1, . . . , Yi,-5.

(21.14)

21.5.2 Implementation Here we discuss the implementation of this approach. First we focus on a specific testable implication, and then we discuss more general results. Let SP = E[Yi(1) - Yi(0)] be the super-population average causal effect of the treatment. Under (super-population) unconfoundedness,
sp = E E Yiobs Wi = 1, Xi - E Yiobs Wi = 0, Xi .
Under subset unconfoundedness, it is also true that adjusting solely for differences in Xir removes biases from comparisons between treated and control units:
sp = E E Yiobs Wi = 1, Xir - E Yiobs Wi = 0, Xir .
These two results imply the testable restriction that
E E Yiobs Wi = 1, Xi] - E Yiobs Wi = 0, Xi = E E Yiobs Wi = 1, Xir - E Yiobs Wi = 0, Xir .

21.5 Robustness to the Set of Pre-treatment Variables

489

We can implement this assessment by estimating the average effect of the treatment using

the full set of covariates and comparing that to the estimate of the average treatment

effect based on the subset of covariates.

We compare two quantities that both estimate the average causal effect under the com-

bination of two assumptions, unconfoundedness and subset unconfoundedness. If both

assumptions hold, the treatment effects should also be identical for subpopulations and

for causal estimands other than the average effect, and for comparisons of both poten-

tial outcomes separately. We can capture these additional implications by focusing on

comparisons of more general estimands. Let fYiobs|Wi=w,Xi=x(y|w, x) be the conditional

distribution in the super-population of Yiobs conditional on Wi = w and the full set of

covariates Xi = x, Xir. By definition,

tahneddsiismtriiblaurtliyonfocrofnYidobist|iWoin=iwn,gXiro=nxrt(hye|ws,uxbrs)e, twohfetrheewceovoanrliyatceosnXdiritcioann

on be

written as

fYiobs|Wi=w,Xir=xr (y|w, xr) = fYiobs|Wi=w,Xi=x(y|w, x) · fXi|Wi=w,Xir=xr (x|w, xr)dx.
At its most general level, the implication of the combination of the two assumptions, unconfoundedness and subset unconfoundedness, is that

fYiobs|Wi=w,Xir=xr (y|w, xr) = fYiobs|Wi=w,Xi=x(y|w, x) · fXi|Xir=xr (x|xr)dx.
Hence, the hypothesis that is being assessed is whether the conditioning on Wi = w in the conditional distribution of Xi given Xir = xr in this integral matters:

fYiobs|Wi=w,Xi=x(y|w, x) · fXi|Wi,Xir=xr (x|w = 1, xr) - fXi|Wi,Xir=xr (x|w = 0, xr) dx = 0. (21.15)

Directly comparing the two complete conditional distributions is complicated, so here we focus on a different set of comparisons. Let Xr be the support of Xir, and let Xr1, . . . , XrJ partition this space. Then consider, for some function g( · ) of the outcome, conditional on Xir  Xjr the conditional average outcome,

E g(Yiobs) Wi = w, Xir  Xjr .

(21.16)

If we maintain both assumptions, unconfoundedness and subset unconfoundedness, we can estimate the expectation in (21.16) in two different ways. First, under unconfoundedness, it is equal to

E E g(Yiobs) Wi = w, Xi Wi = 0, Xir  Xjr .

(21.17)

Second, under subset unconfoundedness, the expectation in (21.17) is also equal to

E E g(Yiobs) Wi = w, Xir Wi = 1, Xir  Xrj ,

490

Assessing Unconfoundedness

leading to the restriction that for all functions g( · ), for all subsets Xjr and for both w = 0, 1,

E E g(Yiobs) Wi = w, Xi Wi = 0, Xir  Xjr = E E g(Yiobs) Wi = w, Xir Wi = 1, Xir  Xjr .

To gain some insight into this approach, let us consider a simple case. In this example we focus on the case with g(y) = y, leading to the restriction

E E Yiobs Wi = 1, Xi Wi = 0, Xir  Xrj - E E Yiobs Wi = 1, Xir Wi = 1, Xir  Xrj .

(21.18)

Moreoever, suppose that the conditional

Xit, Xiptp

with t + Xirtr.

= (tp, tr) Then:

corresponding

etoxpXeciptaatniodnXs ira,resolintheaatr,EE[Y[Yioiobbs|sW|Wi i

= =

1, Xi] 1, Xi]

= =

E E Yiobs Wi = 1, Xi Wi = 0, Xir  Xrj = E Xiptp + Xirtr Wi = 0, Xir  Xrj

= Xirtr + E Xip Wi = 0, Xir  Xrj tp, and the difference (21.18) reduces to

E[Xip|Wi = 0, Xir] - E[Xip|Wi = 1, Xir] tp.

(21.19)

In this linear conditional expectation case, the combination of unconfoundedness and
subset unconfoundedness implies that the association (i.e., correlation here) of the selected covariates Xip with the outcome conditional on the remaining covariates is zero on average.

21.6 THE IMBENS-RUBIN-SACERDOTE LOTTERY DATA
In this section we apply the methods developed in this chapter to the lottery data previously analyzed in Chapter 13. We start with the full sample of 496 individuals. In Table 21.1 we present summary statistics for these 496 individuals. We focus on estimates based on the blocking or subclassification methods from Chapter 17, after using the trimming approach from Chapter 16. In that chapter we estimated the average effect of winning a big prize on average earnings for the next six years to be approximately -$6,000 per year, with a standard error of approximately $1,000. In this section we investigate the plausibility of the unconfoundedness assumption for this data set.
21.6.1 Testing for Effects on Pseudo Outcomes The data are well-suited for using the methods discussed in Section 21.3, because the data set contains information on earnings (whose value after winning the lottery is the outcome of primary interest) for six years prior to winning the lottery prize, making

21.6 The Imbens-Rubin-Sacerdote Lottery Data

491

Table 21.1. Summary Statistics for Selected Lottery Sample for the IRS Lottery Data

Variable

Label

All

Non-Winners Winners

(N = 496)

(Nt = 259) (Nc = 237)

Nor

Mean (S.D.)

Mean

Mean [t-Stat] Dif

Year Won Tickets Bought Age Male Years of Schooling Working Then Earnings Year -6 Earnings Year -5 Earnings Year -4 Earnings Year -3 Earnings Year -2 Earnings Year -1 Pos Earnings Year -6 Pos Earnings Year -5 Pos Earnings Year -4 Pos Earnings Year -3 Pos Earnings Year -2 Pos Earnings Year -1

(X1)
(X2)
(X3)
(X4)
(X5)
(X6)
(Y-6) (Y-5) (Y-4) (Y-3) (Y-2) (Y-1) (Y-6 > 0) (Y-5 > 0) (Y-4 > 0) (Y-3 > 0) (Y-2 > 0) (Y-1 > 0)

6.23 3.33 50.22 0.63 13.73 0.78 13.84 14.12 14.21 14.80 15.62 16.31 0.69 0.71 0.71 0.70 0.71 0.71

(1.18) (2.86) (13.68) (0.48) (2.20) (0.41) (13.36) (13.76) (14.06) (14.77) (15.27) (15.70) (0.46) (0.45) (0.45) (0.46) (0.46) (0.45)

6.38 2.19 53.21 0.67 14.43 0.77 15.56 15.96 16.20 16.62 17.58 18.00 0.69 0.68 0.69 0.68 0.68 0.69

6.06 4.57 46.95 0.58 12.97 0.80 11.97 12.12 12.04 12.82 13.48 14.47 0.70 0.74 0.73 0.73 0.74 0.74

-3.0 9.9
-5.2 -2.1 -7.8
0.9 -3.0 -3.2 -3.4 -2.9 -3.0 -2.5
0.3 1.6 1.1 1.4 1.6 1.2

-0.27 0.90
-0.47 -0.19 -0.70
0.08 -0.27 -0.28 -0.30 -0.26 -0.27 -0.23
0.03 0.14 0.10 0.13 0.15 0.10

these variables attractive candidates to play the role of pseudo-outcomes. In this first set

of assessments, we before winning) as

fthoecusseloenctaendalpyrsee-streuastimngenetitvhaerriaXbiple=, oYri,X-ip1

(earnings in the last year = Yi,-6 (earnings in the

sixth year before winning) as the selected pre-treatment variable, and in each case the

remaining pre-treatment variables as Xir. The first analysis is design-based and

uses

Xip

=

Yi,-1 as the pseudo-outcome.

First, note that the difference in average prior earnings for winners and losers is

14. 47 - 18. 00 = 3.53 (in thousands of dollars; see Table 21.1). This raw difference is

substantial, relative to the estimated effect of winning the lottery of -5.74, and it is statis-

tically significantly different from zero at conventional significance levels. Because this

difference cannot be a causal effect of winning the lottery, it must be due to pre-existing

differences between the winners and the losers. The question is whether adjusting for the

remaining pre-treatment variables removes this difference.

To implement the analyses discussed in this chapter, recall that in the analysis that

led to the point estimate of -5.74, we included automatically in the propensity score

the selected covariates Xi2 (Tickets Bought), Xi5 (Years of Schooling), Xi6

(Working Then), and the most recent earnings, Yi,-1. To make the analysis with

the pseudo-outcome as similar as possible to the main analyses, we always include in

the propensity score the covariates Xi2, Xi5, Xi6, and the most recent earnings Yi,-2. The

blocking estimate based on this setup is

^ strat = -0.53 (s. e. = 0.58),

This is statistically not significantly different from zero at conventional significance levels, and substantively unimportant. It is also small compared to the effect we find for the actual outcome, that is, -5.74.

492

Assessing Unconfoundedness

Table 21.2. Estimates of Average Treatment Effect on Pseudo-outcome for the IRS Lottery Data

PseudoOutcome

Remaining Covariates

Selected Covariates

Est (s. e.)

Y-1

X1, . . . , X6, Y-6, . . . , Y-2, Y-6 > 0, . . . , Y-2 > 0 X2, X5, X6, Y-2 -0.53 (0.58)

Y-1 +Y-2 2
Y-1 +Y-2 +Y-3 3
Y-1 +...+Y-4 4

X1, . . . , X6, Y-6, . . . , Y-3, Y-6 > 0, . . . , Y-3 > 0 X2, X5, X6, Y-3 -1.16 (0.71)

X1, . . . , X6, Y-6, Y-5, Y-4, Y-6 > 0, Y-5 > 0, Y-4 > 0 X2, X5, X6, Y-4 -0.39 (0.77)

X1, . . . , X6, Y-6, Y-5, Y-6 > 0, Y-5 > 0

X2, X5, X6, Y-5 -0.56 (0.89)

Y-1 +...+Y-5 5
Y-1 +...+Y-6 6

X1, . . . , X6, Y-6, Y-6 > 0 X1, . . . , X6

X2, X5, X6, Y-6 -0.49 (0.87) X2, X5, X6 -2.56 (1.55)

Actual outcome Y

X1, . . . , X6, Y-6, . . . , Y-1, Y-6 > 0, . . . , Y-1 > 0

X2, X5, X6, Y-1 -5.74 (1.14)

Next, we repeat this for five additional choices of the pseudo-outcome. In each of the five additional analyses we take the average of the J most recent pre-treatment earnings as the pseudo-outcome, and use the remaining pre-treatment earnings as pre-treatment variables. The results for all six tests are in Table 21.2. We find that, as long as there are some pre-treatment earnings left in the set of covariates used to remove biases, the estimates are statistically and substantively insignificant. Only with the average of all pre-treatment earnings used as the pseudo-outcome, so that there are no earnings variables among the remaining pre-treatment variables to be used in the adjustment, do we find a substantially and statistically significant estimate. In that case, the point estimate is -2.56 with an estimated standard error of 1.55. It appears that some measures of pretreatment earnings are required to remove biases and make unconfoundedness plausible, but we do not appear to need more than one such measure.
Finally, we return to the case with the pseudo-outcome equal to the most recent pretreatment earnings. Now we look at both the effect on the pseudo-outcome, and on the indicator that the pseudo-outcome is positive. In addition, we do this separately for those with positive and zero earnings in the second year prior to winning the lottery (the most recent pre-treatment year left in the set of pre-treatment variables) in order to assess whether the distribution of the pseudo-outcome differs between treatment groups conditional on covariates, excluding the pseudo-outcomes. The number of individuals with positive earnings in the second year prior to winning the lottery is 351, with 145 individuals with zero earnings in that year. In Table 21.3 we present the four estimates separately, as well as a p-value for the overall test. The p-value of 0.13 suggests that there is relatively little evidence that the distributions of the most recent pre-treatment earnings differ by treatment group conditional on the remaining pre-treatment variables.
Overall the pseudo-outcome assessments suggest that, with the rich set of covariates used, for the selected sample with overlap, the unconfoundedness assumption may be a reasonable assumption, and therefore the estimate of -5.74 for the effect of winning the lottery on subsequent earnings is credible.

21.6 The Imbens-Rubin-Sacerdote Lottery Data

493

Table 21.3. Estimates of Average Treatment Effect on Transformations of Pseudo-Outcome for Subpopulations for the IRS Lottery Data

Pseudo-Outcome

Subpopulation Est (s. e.)

1Y-1=0 1Y-1=0 Y-1 Y-1
Combined statistic (chi-squared, df 4)

Y-2 = 0 Y-2 > 0 Y-2 = 0 Y-2 > 0

-0.05 -0.04 -1.46 -0.59

(0.04) (0.03) (0.92) (0.58)

statistic p-value 5.51 (0.24)

21.6.2 Assessing Effects of Pseudo-Treatments
Next we investigate the plausibility of unconfoundedness through the second approach of testing for the presence of effects of pseudo-treatments, the so-called semi-design approach. In the context of the lottery study it would have been most useful to have a comparison group, say of individuals who did not play the lottery at all. Such individuals might have been expected to be quite different from lottery players in terms of earnings levels and growth. Then we would have two possible control groups: first lottery players who did not win a major prize ("losers"), and second non-lottery players. Then we could have compared the outcome distributions for these two possible control groups. In that case finding that the observed covariates were sufficient to remove differences between non-lottery players and losers would have lent substantial support to the results based on unconfoundedness, precisely because non-lottery players and lottery players might a priori have been expected to be quite different in terms of their unobserved economic behavior. However, in the lottery sample we do not have a second control group for whom we are confident that there is no causal effect. Nevertheless, we have a subsample that is almost as good as that, and which we will use for that purpose. Specifically, a subset of the treatment group of lottery winners will be used to serve as such a pseudo-control group. We take the subsample of winners whose yearly prizes were relatively small. For this subset we expect, a priori, the causal effects of winning to be modest.
First we define what we mean by "small yearly prize winners." In our sample the median yearly prize is 31.8, and the average is 55.2, all in thousands of dollars. The 75th percentile is 63.0 per year. First, we take the subsample of 111 yearly winners who won an annual prize less than or equal to $30,000. Even if there is some effect of such a prize on subsequent earnings, one would expect it to be modest compared to the effects of a bigger prize.
Thus, for the purpose of this illustrative analysis, we view those who won more than $30,000 per year as members of the treatment group, and both winners who won a large enough amount to be paid in yearly installments, but less than $30,000 per year, and losers as part of the control group.
The results for these analyses are in Table 21.4. For the winners of prizes less than $30,000, we find that the differences from the losers, after adjusting for all observed covariates, are substantially small and statistically insignificant at conventional levels.

494

Assessing Unconfoundedness

Table 21.4. Estimates of Average Difference in Outcomes for Controls and Small Winners (less than $30,000) for the IRS Lottery Data

Outcome

Subpopulation Est (s. e.)

Yi 1Yi=0 1Yi=0 Yi Yi
Combined statistic (chi-squared, dof 4)

All
Yi,-1 = 0 Yi,-1 > 0 Yi,-1 = 0 Yi,-1 > 0

-0.82 -0.02
0.07 -1.18 -0.16

(1.37) (0.05) (0.05) (1.10) (0.69)

statistic p-value 1.24 (0.87)

21.6.3 Assessing Robustness

Finally, we carry out the robustness analysis from Section 21.5.2. To make the analysis fully comparable to those in Chapter 17, we start by trimming the sample using Xir = Zi, Yi,-2, . . . , Yi,-6 as the pre-treatment variables to create a common sample with which to compare confoundedness and subset unconfoundedness. Starting with the full sample
with 259 control units and 237 treated units, for a total of 496 units, this leads to a trimmed sample with Nc = control units and Nt = treated units for a total of N = 327 units. Given the trimmed sample, we estimate the average treatment effect, first
using the full set of covariates (justified by unconfoundedness), and second using the
restricted set of covariates (justified by subset unconfoundedness). The estimates, based
on subclassification on the estimated propensity score with additional adjustment within
the blocks by linear regression, are

^sXp = -6. 94 (s. e. = 1.20),

^sXpr = -5. 92 (s. e. = 1.16),

for the estimate based on the full and restricted sets of covariates respectively, and based on the selected sample of 327 units. The difference in the estimates is relatively modest, supportive of unconfoundedness.
We also look directly at the differences in adjusted average outcomes,

E[Xip|Wi = 0, Xir] - E[Xip|Wi = 1, Xir] tp.

Approximating the two conditional expectations by linear functions,

E[Xip|Wi = 0, Xir] = Xirc,

E[Xip|Wi = 1, Xir] = Xirt,

we find

1 N

N i=1

E^ [Xip|Wi = 0, Xir] - E^ [Xip|Wi = 1, Xir]

^tp = -0. 13

s. e. = 0.12

and

1 N

N i=1

E^ [Xip|Wi = 0, Xir] - E^ [Xip|Wi = 1, Xir]

^cp = -0. 19

s. e. = 0.11,

in both cases small relative to the average causal effect estimate of -5.74.

Notes

495

Again the overall conclusion from these supporting analyses is that unconfoundedness appears to be credible for this data set.

21.7 CONCLUSION
In this chapter we discuss how one can assess the critical unconfoundedness assumption. Although this assumption is not testable, there are three broad classes of methods that can, in some settings, be used to assess whether unconfoundedness is plausible. One of the three classes is design based, not requiring the use of outcome data. One is semidesign, only using control outcome data. The third uses treated and control outcome data. All three classes estimate pseudo-causal effects known, or presumably known, to be equal to zero. If one cannot reject the null hypothesis that (all of) these pseudo-causal effects are equal to zero, one may, cautiously, and with caveats, proceed and accept the unconfoundedness assumption. Rejections of the hypotheses of zero effects, however, do not suggest alternatives to the unconfoundedness assumption. Instead such rejections may simply suggest that it may be impossible to obtain credible inferences regarding the causal effects of interest with the data at hand.

NOTES
Rosenbaum (1987) was one of the first to stress formally the benefits of having multiple control groups when assessing unconfoundedness. His ideas have been used in a variety of ways. Sometimes researchers use the multiple control groups to obtain multiple estimates of the effects of interest and compare those. For a leading example, pre-dating Rosenbaum's work, see Lalonde (1986). Lalonde was interested in comparing experimental estimates to non-experimental estimates of a job-training program. For his non-experimental estimates, he uses comparison groups constructed from the Panel Study of Income Dynamics (PSID) and from the Current Population Survey (CPS). Lalonde then compares estimates of the average effect of the treatment, the job-training program, based on the two different comparison groups. This is a somewhat indirect way of comparing the adjusted differences between the two comparison groups that we discuss in the current chapter.
The idea of using estimates of the effect of the treatment on pseudo-outcomes known not to be affected by the intervention has also a long history. Most often this is in the context of settings with lagged outcomes where one analyzes the data as if the intervention has occurred prior to the time it was actually implemented. See, for example, Heckman and Hotz (1989) and Crump, Hotz, Imbens, and Mitnik (2008).

CHAPTER 22
Sensitivity Analysis and Bounds
22.1 INTRODUCTION
Part IV of this text focused on estimation and inference under regular assignment mechanisms, that is, ones that are individualistic with probabilistic assignment, as well as unconfounded. In Part V we study methods that confront the unconfoundedness assumption. In Chapter 21 we discussed methods to assess the plausibility of this assumption by combining it with additional assumptions. In the current chapter we relax the unconfoundedness assumption without replacing it with additional assumptions, and so do not focus on obtaining point estimates of the causal estimands of interest. Instead we end up with ranges of plausible values for these estimands, with the width of these ranges corresponding to the extent to which we allow the unconfoundedness assumption to be violated.
We consider two approaches that have much in common. The first, developed by Manski in a series of studies (e.g., Manski, 1990, 1996, 2003, 2013), allows for arbitrarily large violations of the unconfoundedness assumption. This bounds or partial identification approach, as it is called, leads to sharp results, but at the same time will be seen to limit severely the types of inferences about causal effects that can be drawn from observational data. The second approach, following work in this area by Rosenbaum and Rubin (1983) and Rosenbaum (1995), with important antecedents in the work by Cornfield et al. (1959), works from the other extreme in the sense that unconfoundedness is the starting point, and only limited violations from it need to be considered. If we allow for large violations in the Rosenbaum-Rubin approach, it will often lead to essentially the same results as the Manski bounds approach, but with limited violations of the unconfoundedness assumption, the sensitivity approach results in narrower ranges for the estimands than the partial identification approach.
The key to any sensitivity analysis will be how to assess the magnitude of violations from unconfoundedness. The setup in the current chapter assumes that unconfoundedness is satisfied conditional on an additional, unobserved covariate. If, conditional on the other, observed, covariates, this unobserved covariate is independent of the potential outcomes, or if, again conditional on the observed covariates, it is independent of treatment assignment, unconfoundedness holds even without conditioning on this additional covariate. If, however, this additional, unobserved covariate is associated both
496

22.3 Bounds

497

with the potential outcomes and with the treatment indicator, biases will result from estimates based on the assumption of unconfoundedness. The magnitude of the bias depends on the strength of the associations between the unobserved covariate and the potential outcomes and treatment indicator.
In the Rosenbaum-Rubin sensitivity approach we consider the range of implied treatment effects as a function of the magnitude of the associations between the unobserved covariate and the potential outcomes and treatment indicator. To assess what reasonable magnitudes are for those associations, we compare them to the associations between observed covariates and the potential outcomes and treatment indicators in the current data, or in cases where other more extensive data are available, to those data.
We also consider a second approach to sensitivity analyses developed by Rosenbaum (1995). Here the sensitivity analyses only requires the researcher to specify the magnitude of the association between the unobserved components and the treatment assignment, taking a Manski-style attitude to the associations between the hidden covariate and the potential outcomes. Without making assumptions about associations with the potential outcomes we again obtain ranges of average treatment effects consistent with the evidence in the current study.
Throughout this chapter we take a super-population approach where the sample is viewed as a random sample from an infinite population, with the random sampling generating a distribution for the potential outcomes. In Section 22.2 we describe the subset of the lottery data that will be used to illustrate the sensitivity analyses. Next, in Section 22.3, we study the Manski bounds approach. In Section 22.4 we study the RosenbaumRubin sensitivity approach for the case with binary outcomes. Next, in Section 22.5 we discuss Rosenbaum's approach. Section 22.6 concludes.

22.2 THE IMBENS-RUBIN-SACERDOTE LOTTERY DATA
Here we use again the lottery data originally collected by Imbens, Rubin, and Sacerdote (2001) that we used previously in Chapters 14, 17, 19, and 21. In Chapter 14 we assessed the overlap in covariate distributions for the lottery data and found that overlap was substantial, although there were subsets of covariate values with little overlap. In Chapter 17 we used the methods from Chapter 16 to trim the sample, originally consisting of 496 units, which led to the creation of a sample containing information on N = 323 individuals, of whom Nc = 172 are losers and Nt = 151 are winners, which comprise the sample that is the basis for the analyses in this chapter. The outcome that we are studying is the indicator for having positive earnings during the six-year period (essentially being employed full time during each of these six years) following the lottery.
Assuming unconfoundedness, and using the subclassification estimator developed in Chapter 17, the point estimate of the average effect of winning the lottery on the outcome is -0.134, with an estimated standard error equal to 0.049.

22.3 BOUNDS
We start by focusing on a simple case with no covariates. For unit i, there are two potential outcomes, Yi(0) and Yi(1). For illustrative purposes, we consider the average effect

498

Sensitivity Analysis and Bounds

of the treatment in the super-population,

sp = Esp [Yi(1) - Yi(0)] .
In this section we restrict the discussion to the case with binary outcomes, Yi(0) and Yi(1)  {0, 1} (some period of non-employment during the six years post lottery versus full-time employment during this period) to allow a sharper focus on the key conceptual issues.
We observe for unit i the treatment received, Wi, and the realized outcome, Yiobs = Yi(Wi). In the case without covariates, super-population unconfoundedness simply corresponds to independence of the treatment indicator and the potential outcomes:

Wi  Yi(0), Yi(1) .

Under random assignment we can unbiasedly estimate the average treatment effect as the difference in average observed outcomes by treatment status, which for the lottery data leads to:

^ dif

=

Y

obs t

-

Y

obs c

=

0. 4106

-

0.5349

=

-0.1243.

Using Neyman's approach (see Chapter 6), it follows that, if assignment were completely random, ^ dif would be unbiased for both the finite-sample average treatment effect fs and for the super-population average treatment effect sp, with associated standard sampling variance estimate V^ neyman = 0.0552. We also calculate the exact Fisher p-value
assuming complete randomization, using the difference in average outcomes for treated
and control units as the statistic, leading to a p-value of 0.034.
Now suppose we do not wish to assume unconfoundedness and, moreover, we do
not wish to make any alternative assumptions (but we maintain the stability assumption, SUTVA). What can we learn about sp in the absence of this assumption? Manski's approach to this problem is as follows. Suppose we observe for all units in the superpopulation the treatment indicator Wi and the realized outcome Yiobs, Yiobs = 1 indicating employment every year versus Yiobs = 0 if individual i was unemployed for at least one year during the six-year post-lottery period. We can obtain method-of-moments esti-
mates for, or using the terminology from the econometric literature, in large samples
we can identify, three quantities. First, in the super-population share of treated units, p = E[Wi] = Pr(Wi = 1), which, in this case without covariates, is also the propensity score for each unit. Second, we can similarly estimate the population distribution of Yi(0) conditional on Wi = 0. Because Yi(0) is binary, this distribution can be summarized by the scalar c,0 = Pr(Yi(0) = 1|Wi = 0) = E[Yi(0)|Wi = 0]. Finally, we can estimate the population distribution of Yi(1) given Wi = 1, t,1 = Pr(Yi(1) = 1|Wi = 1) = E[Yi(1)|Wi = 1]. In addition, define the super-population quantities

c,1 = E [ Yi(0)| Wi = 1] , and t,0 = E [ Yi(1)| Wi = 0] .

Note that if super-population unconfoundedness holds, then c,1 and t,0 are equal to c,1 = c,0 = E[Yi(0)] = E[Yiobs|Wi = 0],

22.3 Bounds

499

and t,0 = t,1 = E[Yi(1)] = E[Yiobs|Wi = 1],
respectively, so that under super-population unconfoundedness
sp = t,1 - c,0 = E [ Yi(1)| Wi = 1] - E [ Yi(0)| Wi = 0] = E[Yiobs|Wi = 1] - E[Yiobs|Wi = 0],
and ^ dif is unbiased for sp. Without the unconfoundedness assumption, however, we cannot infer sp from only these three quantities, p, c,0, and t,1.
In general, without assuming unconfoundedness, we can rewrite sp as the difference in the average of the potential outcomes,
sp = t - c,
where
t = E [Yi(1)] = p · t,1 + (1 - p) · t,0,
and
c = E [Yi(0)] = p · c,1 + (1 - p) · c,0.
Without unconfoundedness (and without making any additional assumptions to replace it), the data are not informative about t,0 or c,1 beyond the obvious fact that, because the outcomes are binary, these quantities must lie inside the interval [0, 1]. These natural bounds on t,0 and c,1 imply bounds on t and c:
c  (1 - p) · c,0, (1 - p) · c,0 + p ,
and
t  p · t,1, p · t,1 + (1 - p) .
These ranges on t and c in turn imply bounds on the estimand, the population average effect sp:

sp  p · t,1 - p - (1 - p) · c,0, p · t,1 + (1 - p) - (1 - p) · c,0 .

(22.1)

These bounds on the average treatment effect are sharp, in the sense that any value of sp inside these bounds is consistent with the data if we are not assuming unconfoundedness. In other words, we cannot rule out, even in an infinitely large sample, any value inside these bounds. If we wish to obtain sharper inferences for sp, we need to make stronger assumptions about the distribution of the potential outcomes, the assignment mechanism, or both. It is useful to see precisely why the bounds are sharp. Consider the upper bound in (22.1), p · t,1 + (1 - p) - (1 - p) · c,0. What is the joint distribution of the potential outcomes and the assignment mechanism that would lead to this value for the average

500

Sensitivity Analysis and Bounds

treatment effect? In order for  to be equal to this upper bound, it must be the case

that t,0 = 1 (i.e., all the units who received the control treatment would have survived given the active treatment), and c,1 = 0 (i.e., all the units receiving the active treatment

would have died had they received the control treatment). Although such a scenario

appears extreme, there is nothing in the data that formally rules out this possibility.

In this specific setting, the bounds are arguably not very informative. Note that with-

out any data, we can infer from the fact that the outcomes are binary that the average

effect sp must lie in the interval [-1, 1], with the width of that interval equal to two.

The data, with everyone exposed to treatment or control, but without the unconfounded-

ness assumption, can narrow this range to Equation (22.1). Inspection of these bounds

shows that they are of the form [-c, 1-c] for some c  [0, 1]. Thus, in this case, the

bounds always have range one, and always include zero (corresponding to the Fisher

null hypothesis of no effect of the treatment for any unit), irrespective of the data. The

fact that the bounds must include zero follows immediately from the fact that nothing in

our setup so far rules out the possibility that the treatment effect is zero for all units. The

fact that the width of this bounding interval is always one follows from the fact that the

width of the interval without the data is two, in combination with the fact that exactly

half the potential outcomes are missing.

For the IRS lottery data, the fraction treated is Nt/N = 0. 4675, and the survival rates

in

the

control

and

treatment

groups

are

Y

obs c

=

0.5349

and

Y

obs t

=

0.

4106,

respectively.

Replacing

p,

t,1

and

c,0

by

Nt/N,

Y

obs t

,

and

Y oc bs ,

respectively,

in

Equation

(22.1)

leads

to a lower and upper bound for the super-population average treatment effect, without

additional assumptions, equal to:

sp  p · t,1 - p - (1 - p) · c,0, p · t,1 + (1 - p) - (1 - p) · c,0 = [-0.56, 0. 44].

22.4 BINARY OUTCOMES: THE ROSENBAUM-RUBIN SENSITIVITY ANALYSIS

Now let us study the same setting from a different perspective, the sensitivity analysis approach developed by Rosenbaum and Rubin (1983). Rosenbaum and Rubin start with the assumption that super-population unconfoundedness holds given an unobserved scalar covariate. Let us denote this unobserved covariate by Ui. Super-population unconfoundedness given this unobserved covariate, in the absence of observed covariates, requires that

Wi  (Yi(0), Yi(1)) Ui.

(22.2)

It is convenient, at least initially, to model Ui as binary with

q = Pr(Ui = 1) = 1 - Pr(Ui = 0).

22.4 Binary Outcomes: The Rosenbaum-Rubin Sensitivity Analysis

501

Now let us build parametric models for the relations between the unobserved covariate Ui and both the treatment indicator and both potential outcomes. In principle we would like a model for

f (Wi, Yi(0), Yi(1)|Ui).

By Equation (22.2) Wi is independent of (Yi(0), Yi(1)) given Ui, so we can write this as

f (Wi|Ui) · f (Yi(0), Yi(1)|Ui).

As discussed in Chapters 6 and 8, the data are not informative about the dependence
structure between Yi(0) and Yi(1), so here, for simplicity, we model them as independent conditional on Ui. Thus, we need to specify models for f (Wi|Ui), f (Yi(0)|Ui), and f (Yi(1)|Ui). We use the following specifications, taking into account the fact that Yi(0) and Yi(1) are binary:

Pr(Wi

=

1|Ui

=

u)

=

1

exp (0 + + exp (0

1 · u) + 1 · u)

,

Pr(Yi(1)

=

1|Ui

=

u)

=

1

exp (0 + + exp (0

1 · u) + 1 · u)

,

and

Pr(Yi(0)

=

1|Ui

=

u)

=

1

exp (0 + + exp (0

1 · u) + 1 · u)

,

where dependence on the parameters is notationally supressed to avoid clutter. There are seven scalar components of the parameter  = (q, 1, 1, 1, 0, 0, 0),
which we partition into two subvectors. The first, s = (q, 1, 1, 1), comprises the sensitivity parameters, which we do not attempt to estimate. Instead we postulate (ranges of)
values for them a priori. We discuss later how we select the particular values, or rather
the range of values for these parameters, but now we discuss how to proceed condi-
tional on postulated values for these parameters. Conditional on values for the sensitivity parameters (q, 1, 1, 1), we estimate the remaining parameters, that is the estimable parameters e = (0, 0, 0), from the data and infer the average treatment effect sp. The approach has in common with the bounds approach that even in large samples we cannot reject any combination of values for (q, 1, 1, 1): the data do not lead to unbiased method-of-moment estimates of these parameters even in infinite samples, or, in the
econometric terminology, these parameters are not identified.
Let us look at this argument in more detail. The data allow for unbiased estimates of p = E[Wi], t,1 = E[Yiobs|Wi = 1] = E[Yi(1)|Wi = 1] and c,0 = E[Yiobs|Wi = 0] = E[Yi(0)|Wi = 0]. Let us take those parameters as known, and ignore for the moment the sampling variation in their estimates. These three estimable quantities relate to the parameters (q, 1, 1, 1) and (0, 0, 0) through the three equalities

p = q · exp (0 + 1) + (1 - q) · exp (0) ,

1 + exp (0 + 1)

1 + exp (0)

(22.3)

502

Sensitivity Analysis and Bounds

t,1 = Pr(Ui = 1|Wi = 1) · E[Yi(1)|Wi = 1, Ui = 1]

+ (1 - Pr(Ui = 1|Wi = 1)) · E[Yi(1)|Wi = 1, Ui = 0]

=

q·

q

·

exp (0+1) 1+exp (0+1)

exp (0+1) 1+exp (0+1)

+

(1

-

q)

·

exp (0) 1+exp (0)

·

exp (0 + 1) 1 + exp (0 + 1)

+

(1

-

q)

·

exp (0) 1+exp (0)

q

·

exp (0+1) 1+exp (0+1)

+

(1

-

q)

·

exp (0) 1+exp (0)

·

1

exp (0) + exp (0)

,

(22.4)

and

c,0

=

q·

q

·

1 1+exp (0+1)

1 1+exp (0+1)

+

(1

-

q)

·

1 1+exp (0)

·

exp (0 + 1) 1 + exp (0 + 1)

+

q·

(1

-

q)

·

1 1+exp (0)

1 1+exp (0+1)

+

(1

-

q)

·

1 1+exp (0)

·

exp (0) . 1 + exp (0)

(22.5)

It is straightforward to see that for all values of (q, 1, 1, 1), and for all distributions of the observed data (captured by the values for the triple (p, t,c, c,0)), we can find values for the triple (0, 0, 0) such that all three of these equalities hold. Moreover, these values for the estimable parameters (0, 0, 0) are unique for all values of c,0, t,1, and p, and for all values of the sensitivity parameters. For example, If 0  -, the right-hand side of the first equality goes to zero, and if 0  , the right-hand side goes to one. Because the right-hand side is strictly increasing in 0, there must be a unique value such that (22.3) holds for any p  (0, 1). Let us write these implied values for

(0, 0, 0) as functions of the data and (q, 1, 1, 1):

0(q, 1, 1, 1|data),

0(q, 1, 1, 1|data),

and

0(q, 1, 1, 1|data),
where, ignoring sampling variation, the data consist of the triple
data = (p, t,c, c,0).
Given the postulated values for (q, 1, 1, 1), and given the values for (0, 0, 0) that are implied by the combination of the data and the postulated values for (q, 1, 1, 1), there are implied values for t,0 and t,1. In terms of  = (q, 1, 1, 1, 0, 0, 0), we can write

t,0(q, 1, 1, 1, 0, 0, 0) = E[Yi(1)|Wi = 0]

=

q·

q

·

1 1+exp (0+1)

1 1+exp (0+1)

+

(1

-

q)

·

1 1+exp (0)

·

exp (0 + 1) 1 + exp (0 + 1)

+

q·

(1

-

q)

·

1 1+exp (0)

1 1+exp (0+1)

+

(1

-

q)

·

1 1+exp (0)

·

1

exp (0) + exp (0)

,

22.4 Binary Outcomes: The Rosenbaum-Rubin Sensitivity Analysis

503

and

c,1(q, 1, 1, 1, 0, 0, 0) = E[Yi(0)|Wi = 1]

=

q·

q

·

exp (0+1) 1+exp (0+1)

exp (0+1) 1+exp (0+1)

+

(1

-

q)

·

exp (0) 1+exp (0)

·

exp (0 + 1) 1 + exp (0 + 1)

+

q·

(1

-

q)

·

exp (0) 1+exp (0)

exp (0+1) 1+exp (0+1)

+

(1

-

q)

·

exp (0) 1+exp (0)

·

1

exp (0) + exp (0)

,

where the conditioning on parameters is notationally suppressed. Then, finally, we can write the average treatment effect sp as

sp = t - c = p · (t,1 - c,1) + (1 - p) · (t,0 - c,0).

In summary, given the (super-population) data = (p, t,c, c,0), there is a function that gives sp as a function of (p, t,c, c,0) and the sensitivity parameters:

sp =  (q, 1, 1, 1|data) =  (q, 1, 1, 1|p, t,c, c,0).

(22.6)

It is this function in which we are interested. Given the data, that is, for fixed values for (p, t,1, c,0), we wish to inspect how sensitive the average treatment effect sp is to assumptions about the sensitivity parameters (q, 1, 1, 1).
There are two special sets of values for the sensitivity parameters. First, if we fix 1 = 0, then we are back assuming unconfoundedness (or a completely randomized experiment in this case without covariates), and

sp = t,1 - c,0.
The same holds if we fix both 1 = 1 = 0. Note that it is not necessary that both 1 = 0, and 1 = 1 = 0, for there to be no bias associated with estimates based on unconfoundedness ignoring Ui. It is sufficient if (a) the unobserved covariate does not affect assignment (1 = 0), or (b) the unobserved covariate is not associated with either potential outcome (1 = 1 = 0).
Second, suppose we fix q = p, and let 1  . In that case Wi and Ui become perfectly correlated. If we also let 1  - and 1  -, then
sp  p · t,1 + (1 - p) - (1 - p) · c,0,
which equals to the upper limit in the Manski bounds, showing that the setup with unconfoundedness given an unobserved binary covariate is not technically restrictive in this sense. Similarly, if we again fix q = p, and let 1  , 1  , and 1  , then
sp  p · t,1 - p - (1 - p) · c,0,
which is equal to the lower limit in the Manski bounds. This demonstrates that, in this setting, the bounds analysis can be viewed as an extreme version of a sensitivity analysis, or

504

Sensitivity Analysis and Bounds

taking the opposite perspective, the sensitivity analysis can be viewed as a generalization of the bounds analysis.
Outside of these special values, the key question concerns the set of reasonable values for the sensitivity parameters s = (q, 1, 1, 1). Given a set of reasonable values s for s, we calculate a lower and upper bound of the average treatment effect sp over that set,

low

=

inf
(q,1,1,1)

 (q, 1, 1, 1|p, t,1, c,0),

and

high = sup  (q, 1, 1, 1|p, t,1, c,0),
(q,1,1,1)
leading to the range

sp  low, high .

We generally do not have any substantive judgment regarding q, and one could simply investigate all values for q. Often results are not sensitive to intermediate values for q, and q can be taken to be equal to E[Wi] = p. The remaining parameters are more interesting. The sensitivity parameter 1 represents the effect on the log odds ratio of receiving the treatment of a change from Ui = 0 to Ui = 1. In cases where the researcher has specific variables in mind that could bias the results based on assuming unconfoundedness, this can be a meaningful, interpretable parameter. In specific cases, one could be able to make an informed judgment about reasonable values for this parameter. Note that the Manski bounds on sp implicitly allow Ui to be perfectly correlated with the receipt of treatment Wi, corresponding to 1  . In settings where researchers have attempted to record all relevant determinants of treatment assignment, such a correlation may be viewed as logically too extreme. On the other hand, it may be difficult to specify a number that would meet with widespread agreement as a bound for 1, and our preferred strategy is therefore to report the sensitivity of sp to changes in these parameters.
One specific strategy, in cases where covariates are available, is to consider the association between the observed covariates and both the treatment assignment and the potential outcomes, assuming unconfoundedness, and use the estimated associations as indicative of ranges of reasonable values for the association between the unobserved covariate and the treatment indicator and the potential outcomes.
We illustrate this strategy with the lottery data where we observe eighteen covariates. For each covariate we estimate two logistic regression models. Denote the kth covariate, after normalizing by its standard deviation, by Xki. We estimate a model for the treatment indicator conditional on the covariate,

Pr(Wi

=

1|Xik)

=

1

exp (k0 + + exp (k0

k1 · Xki) + k1 · Xki)

,

22.4 Binary Outcomes: The Rosenbaum-Rubin Sensitivity Analysis

505

and another model for the outcome conditional on the covariate and the treatment indicator,

Pr(Yiobs

=

1|Wi, Xik)

=

1

exp (k0 + + exp (k0

k1 · Xki + + k1 · Xki

k2 · Wi) + k2 · Wi)

,

again with dependence on parameters notationally suppressed. Estimating these two models for each covariate Xki leads to eighteen estimates ^k1
and ^k2, k = 1, . . . , 18. The largest values, in absolute value, were |^2,1| = 0.56 (the association between the number of tickets bought and winning the lottery) and |^18,1| = 1.61 (the association between the indicator for positive earnings in the year prior to
winning the lottery and post-lottery employment). We use these two values to anchor
the sensitivity parameters. The idea is to limit the association between the unobserved
binary covariate Ui and the treatment indicator and potential outcomes by assuming that they are bounded by the strongest marginal associations of the observed covariates. If
one has made a good-faith effort to collect all relevant covariates, it may be difficult
to see how one would miss covariates more important than any of those observed, at least unless there are specific reasons, such as confidentiality concerns. If q = 1/2, the standard deviation of Ui is 1/2, so we implement the sensitivity analysis by letting 1 range over the interval [-0.56/(1/2), 0.56/(1/2)] = [-1.12, 1.12] and 1 and 1 over the interval [-1.61/(1/2), 1.61/(1/2)] = [-3.22, 3.22] (multiplying the maximum of the coefficients by a factor two, equal to the ratio of the standard deviation of the
normalized covariates and the maximum standard deviation of U, to take account of the
normalization of the covariates). We let q range over the interval [0, 1] because there is no
substantive argument to restrict its range. Choosing values for the sensitivity parameters
in this range leads to values for the average treatment effect in the interval

sp  -0.28, 0.05 {q  [0, 1], 1  [-1.12, 1.12], 1  [-3.22, 3.22], 1  [-3.22, 3.22]}.

Substantively this range suggests that the unobserved covariate would have to be fairly
strongly associated with both treatment and potential outcomes to change the conclusion
in the lottery example that the treatment has a positive and substantial effect on employ-
ment. We do not know whether such a covariate exists, but it would have to be somewhat
stronger than any of the covariates the researchers managed to collect in terms of its
association with the outcome and the treatment indicator. Note that in these calculations we allow 1 to be as large as the effect of any observed covariate on the log odds ratio for receiving the treatment, and simultaneously allow 1 and 1 to be as large as the effect of any observed covariates on the log odds ratio for the potential outcome. No single
covariate in the sample had such strong effects on both simultaneously. In fact, for each covariate separately, the range of values for the average treatment effect  associated with letting q  [0, 1], 1  [-2 · |^k1|, 2 · |^k1|], and 1, 1  [-2 · |^k1|, 2 · |^k1|], for some k = 1, . . . , 18, the widest range we find for the average treatment effect is [-0.18, -0.07], with these values corresponding to the 12th covariate, earnings in the year prior to winning the lottery, with ^12,1 = -0.1891 and ^12,1 = 1.3257.

506

Sensitivity Analysis and Bounds

Another approach for assessing the sensitivity that does not directly require us to postulate reasonable values for the sensitivity parameters is to explore the magnitude necessary for (1, 1, 1) in order to change the sign for the estimated average treatment effect found under unconfoundedness. There are trade-offs between the parameters, because with a larger value for 1, the required values for 1 and 1 will not be quite as large. For example, and this is also useful for a subsequent comparison with the Rosenbaum sensitivity analysis, it is also interesting to look at the range of values for the average treatment effect given that |1|  0.52, with 1 and 1 essentially unrestricted. Then,

sp  [-0.22, 0.000] |{q  [0, 1], 1  [-0.52, 0.52], 1  (-, ), 1  (-, )},

just on the margin where the sign of the average treatment effect switches.

22.5 BINARY OUTCOMES: THE ROSENBAUM SENSITIVITY ANALYSIS FOR P-VALUES

Rosenbaum (1995) is interested in calculating Fisher p-values under the sharp null hypothesis of no treatment effects and wishes to assess how sensitive the conclusions under unconfoundedness are to that assumption. In principle applying these methods requires knowledge of the propensity score. Although we do not know the propensity score in observational studies, under unconfoundedness we can estimate the propensity score for each unit. Let these estimated propensity score values be denoted by e^i. Given these values, we can use Fischer's exact p-value approach to obtain p-values for the null hypothesis of no effect whatsoever of the treatment. In the IRS lottery data, still without covariates, using the difference in average ranks as the statistic, the p-value is 0.034. Assuming random assignment, we can be very confident that the treatment has some effect on employment.
Now suppose unconfoundedness does not hold. In that case it is no longer the case that the estimated probability of the treatment is e^i, where e^i was estimated under the assumption of unconfoundedness. Let us denote the actual treatment probability by pi. Rosenbaum then limits the difference between the actual probability pi and the estimated probability under unconfoundedness e^i. Specifically, he assumes that the difference in log odds ratios, under the assumption of unconfoundedness, and based on the true assignment probabilities, is bounded by a pre-specified constant :

ln e^i - ln pi

,

1 - e^i

1 - pi

(22.7)

for all i = 1, . . . , N. We can relate this to the analysis in the previous subsection by specifying a model for the treatment assignment as a function of an unobserved binary covariate u:

pi

=

Pr(Wi

=

1|Ui

=

u)

=

1

exp (0 + 1 · u) , + exp (0 + 1 · u)

(22.8)

22.5 Binary Outcomes: The Rosenbaum Sensitivity Analysis for P-Values

507

so that the logarithm of the true odds ratio is ln (pi/(1 - pi)) = 0 + 1 · u. If we approximate the average propensity score, averaged over the distribution of Ui, by the propensity score at the average value of Ui, q = E[Ui], so that ei = exp (0 + 1 · q)/ (1 + exp (0 + 1 · q)), the implied logarithm of the odds ratio is ln (ei/(1 - ei)) = 0 + 1 · q. The difference between the log odds ratio for the average propensity score under unconfoundedness and the log odds ratio for the true treatment probability is then ln (ei/(1 - ei)) - ln (pi/(1 - pi)) = 1 · (q - Ui). The Rosenbaum restriction implies we should consider all possible values for (q, 1) such that

q · |1| < , and (1 - q) · |1| < .

We can simplify the problem in this context by allowing for all possible values for q in the interval [0, 1], and all possible values for 1 such that |1| < , thus requiring the difference in log odds ratios for units with Ui = 1 and units with Ui = 0 to be restricted to

ln Pr(Wi = 1|Ui = 1) - ln Pr(Wi = 1|Ui = 0)

1 - Pr(Wi = 1|Ui = 1)

1 - Pr(Wi = 1|Ui = 0)

= 1  .

The question we now address is, given that we restrict 1 but place no restrictions on q, what is the evidence in the data against the null hypothesis of no effect whatsoever

of the treatment? It is immediately clear that without any restriction on 1 there is no

evidence against the null hypothesis that there is no effect of the treatment: if we let

1  , then Wi and Ui are perfectly correlated.

Let us consider a particular statistic. In this case with a binary outcome, the natural

statistic

is

the

difference

in

means,

T dif

=

Y

obs t

-

Y

obs c

.

The

value

of

this

statistic

for

the

lottery data is -0.12, with an exact Fisher p-value for the null hypothesis of no effects,

calculated under complete random assignment, equal to 0.034. To make the compari-

son with the Rosenbaum sensitivity analysis easier, it is useful to change the assignment

mechanism slightly; from a completely randomized experiment to a Bernoulli exper-

iment with assignment probability 0.47, the p-value changes to 0.026. Now, pick a

particular value for (q, 1). Given these values, the probability of receiving the treatment

for unit i can be either

plow

=

1

exp (0) + exp (0)

,

or

phigh

=

1

exp (0 + + exp (0

1) + 1)

,

with the first probability corresponding to the case where unit i has Ui = 0, and the second corresponding to the case where unit i has Ui = 1. Now suppose we assign each unit a value for Ui, and thus implicitly assign the unit a value for the assignment probability. Denote this assignment probability for unit i by pi. Given that assignment probability, we can calculate the p-value for any statistic under its randomization distribution. The
statistic we focus on is the the difference in average outcomes by treatment status, Tdif = Y¯tobs - Y¯cobs. The fact that the assignment probabilities are not all equal does not create any problems when calculating or simulating the p-values.

508

Sensitivity Analysis and Bounds

The question now is what the most extreme (and in particular what the largest) p-value
is we can find by assigning the unobserved covariate Ui to each unit for a given value of 1, allowing q to range over the interval [0, 1]. We can again turn to the associations between covariates and the treatment indicator to find a possibly reasonable value for 1. The largest value we found for k1, which captures the relationship between an observed covariate (normalized to have unit variance) and the treatment indicator was approxi-
mately 0.56. (Recall that this corresponds to the number of lottery tickets bought.) This suggests that limiting 1 to be less than or equal to 2 · 0.56 = 1.12 (where the factor 2 captures the fact that the standard deviation of the binary covariate U is bounded by 1/2) may present a reasonable range of values for 1. This changes the p-value from 0.026 to 0.99, suggesting that such an association between the treatment indicator and the unob-
served covariate eliminates any evidence of a negative effect of the treatment. Instead, using the k for earnings, 0.19, to bound  to less than 0.38 in absolute value leads to p-value of 0.27. Finally, using an upper bound on 1 equal to 0.52 leads to a p-value equal to 0.50.

22.5.1 The Rosenbaum Sensitivity Analysis for Average Treatment Effects It is instructive, for the purpose of understanding the similarities and differences between the two approaches to sensitivity analyses, to modify Rosenbaum's approach to derive a range of feasible values for the average treatment effect. Instead of looking at the p-values associated with a pair of values for (q, 1), we again look at a range of values for the average treatment effect. Using the derivations from Section 22.4, we look at the range of values for  if we allow q  [0, 1], 1  [- , ]. In addition, we allow 1  (-, ) and 1  (-, ), which reveals how the Rosenbaum sensitivity approach differs from the Cornfield-Rosenbaum-Rubin method for assessing sensitivity. In the latter we restrict 1 and 1, in addition to 1, whereas the former approach only restricts 1. This modification obviously leads to a wider range of possible values for  . Restricting 1 to be less than 1.12 in absolute value, without restricting 1 or 1, leads to a range of possible values for the average effect of the treatment equal to
sp  [-0.23, 0.12] |{q  [0, 1], 1  [-0.52, 0.52], 1  (-, ), 1  (-, )},
considerably wider than the values we found before when we also restricted 1 and 1. It is also interesting to restrict 1 to be less than 0.52 in absolute value, without
restricting 1 or 1. This leads to a range of possible values for the average effect of the treatment equal to
sp  [-0.62, 0.000] |{q  [0, 1], 1  [-1.12, 1.12], 1  (-, ), 1  (-, )}.
Now the set of estimates (ignoring sampling uncertainty) has zero as its upper limit. This corresponds to the case where the upper bound on the p-values is equal to 0.50.

Notes

509

22.6 CONCLUSION

In this chapter we presented methods for assessing the sensitivity of results obtained under unconfoundedness. The unconfoundedness assumption can be controversial, and the analyses discussed here allow the researcher to quantify how much the estimates and p-values rely on the full force of this assumption. Finding that particular results are, or are not, sensitive to this assumption helps evaluate the results of any analysis under unconfoundedness.
However, in our limited experience, the application and value of such sensitivity analyses depend rather critically on the context of the study and general scientific knowledge that the investigators can bring to bear on the problem at hand.

NOTES
The key papers underlying the first sensitivity analysis in this chapter are Cornfield et al. (1959) and Rosenbaum and Rubin (1983a). Rosenbaum and Rubin focus on the case with a binary outcome, where, in their example, the sample is divided into five subclasses or blocks, and use the analysis where the sensitivity parameters are restricted to the same values in each block. They directly limit the values of the sensitivity parameters 1, 1, and 1 to be less than or equal to three in absolute value. Rosenbaum (1995, 2002) developed the sensitivity analysis that restricts only the assignment probabilities. Imbens (2003) applies the Rosenbaum-Rubin sensitivity analysis and is the original source for the suggestion to anchor the thresholds to values based on the association between treatment and observed covariates and between the outcomes and observed values. For another recent application, see Ichino, Mealli, and Nannichini (2008).
Manski (1990, 1996, 2003, 2013) in a series of papers proposed calculating worstcase bounds of the type discussed in this chapter, with earlier results for special cases in Cochran (1977). Manski, Sandefur, McLanahan, and Powers (1992) present an early application.

PART VI
Regular Assignment Mechanisms with Noncompliance: Analysis

CHAPTER 23
Instrumental Variables Analysis of Randomized Experiments with One-Sided Noncompliance
23.1 INTRODUCTION
In this chapter we discuss a second approach to analyzing causal effects when unconfoundedness of the treatment of interest is questionable. In Chapter 22 we also relaxed the unconfoundedness assumption, but there we did not make any additional assumptions. The resulting sensitivity and bounds analyses led to a range of estimated values for treatment effects, all of which were consistent with the observed data. Instead, in this chapter we consider alternatives to the standard unconfoundedness assumption that still allow us to obtain essentially unbiased point estimates of some treatment effects of interest, although typically not the overall average effect. In the settings we consider, there is, on substantive grounds, reason to believe that units receiving and units not receiving the treatment of interest are systematically different in characteristics associated with the potential outcomes. Such cases may arise if receipt of treatment is partly the result of deliberate choices by units, choices that take into account perceptions or expectations of the causal effects of the treatment based on information that the analyst may not observe. In order to allow for such violations of unconfoundedness, we rely on the presence of additional information and consider alternative assumptions regarding causal effects. More specifically, a key feature of the Instrumental Variables (IV) approach, the topic of the current chapter and the next two, is the presence of a secondary treatment, in the current setting the assignment to treatment instead of the receipt of treatment, where by "secondary" we do not mean temporily but secondary in terms of scientific interest. This secondary treatment is assumed to be unconfounded. In fact, in the randomized experiment setting of the current chapter, the assignment to treatment is unconfounded by design. This implies we can, using the methods from Part II of the book, unbiasedly estimate causal effects of the assignment to treatment. The problem is that these causal effects are not the causal effects of primary interest, which are the effects of the receipt of treatment. Assumptions that allow researchers to link these causal effects are at the core of the instrumental variables approach.
This chapter is the first of three chapters on instrumental variables approaches. For readers unfamiliar with this terminology, instrumental variables methods refer to a set of techniques originating in the econometrics literature, starting in the 1920s with work by Wright (1927), Tinbergen (1930), and later Haavelmo (1943). A central role in these
513

514

Analysis of Randomized Experiments with One-Sided Noncompliance

methods is played by a variable, the so-called instrument or instrumental variable, which is a variable known a priori almost certainly to have a causal effect on the treatment of primary interest, Wi. The key characteristic of this instrument, here denoted by Zi, is the a priori assumed absence of a "direct" causal effect of the instrument on the outcome of interest Yi, with any causal effect of Zi on Yi "passing through" a causal effect of the instrument on the treatment Wi, where these terms will become clear shortly. More generally, principal stratification refers to settings with latent unconfoundedness of the primary treatment, where, conditional on an only partially observed covariate, unconfoundedness holds. In the special case of instrumental variables, this latent unconfoundedness applies with the latent compliance status to assigned secondary treatment, more precisely defined later, playing the role of the partially unobserved covariate.
We start this instrumental variables discussion in the simplest setting of a completely randomized experiment with one-sided noncompliance. By noncompliance we refer to the situation where some units who are assigned to receive a particular treatment level do not comply with their assignment and instead receive an alternative treatment. In this chapter, compliance is assumed to be all or nothing: units cannot receive, or be exposed to, only part of the treatment. By one-sided, we mean that the noncompliance is asymmetric in the sense that only units assigned to receive the active treatment can potentially circumvent their assigned treatment and receive the control treatment. In contrast, all units assigned to receive the control treatment do, in fact, comply with this assignment. This type of noncompliance is common in settings with individual people as the units of analysis, where receipt of the active treatment requires individuals to take, or subject themselves to, a particular action, such as undergoing surgery or entering a job-training program. In such cases, it is often difficult, or even impossible, to compel individuals to undergo the active treatment if assigned to it, even if individuals give consent prior to the randomization. As a result, compliance among those assigned to the active treatment is often imperfect. In contrast, those assigned to receive the control treatment can often effectively be denied access to the active treatment, so the noncompliance is onesided. In this setting, the assignment to treatment is the instrument Zi, and the receipt of treatment is the treatment of primary interest Wi.
Many traditional formal statistical analyses of randomized experiments with noncompliance focus on the relation between the random assignment and the outcome of interest, discarding entirely any information about the treatment, in the current setting actually received, that is, ignoring Wi. Such an approach is generally referred to as an intention-to-treat (ITT) analysis. In our setting of a completely randomized experiment, ITT analyses are validated by the randomization of the assignment to treatment, without the need for additional assumptions beyond SUTVA. The main drawback of these ITT analyses is that they do not answer questions about causal effects of the receipt of treatment itself, only about causal effects of the assignment to treatment. Two other simple analyses, focusing directly on causal effects of the treatment of interest, but neither of which is generally valid, are sometimes conducted in such settings. First, per protocol analyses, where units that are observed not to comply with the treatment assigned are discarded (i.e., units with Zi = Wi), and the data for all units who are observed to comply with their assigned treatment (i.e., units with Zi = Wi) are analyzed as if they came from a randomized experiment with full compliance; that is, the analysis is as if Wi were randomized for units who appear to comply, discarding units who are observed to be

23.1 Introduction

515

noncompliers. A second simple alternative is an as-treated analysis where data from all units are analyzed as if they had been randomly assigned to the treatment they actually received, ignoring information on assignment Zi, and simply comparing treated units having Wi = 1 with control units having Wi = 0, as if Wi were randomized for all units. Both of these naive analyses are generally invalid as we discuss in Section 23.9.
In this chapter we focus on defining causal estimands and on the additional assumptions that allow us to go beyond the global effect of assignment that is the focus of ITT analyses, and estimate "local" average effects for the treatment of interest, that is, averages for subsets of units. Although we briefly mention some traditional econometric, moment-based, estimators for simple cases with no covariates, we leave the main discussion of our preferred model-based estimators and inference to Chapter 25.
In order to obtain alternatives to the assumption of unconfoundedness of the receipt of the treatment, we consider separately the nature of the noncompliance and the causal effects of the assignment to treatment for what we will call compliers and noncompliers. These groups are defined by their partly unobserved compliance behavior, and thus define latent strata. A key insight is that, although unconditionally receipt of treatment is confounded, within these latent strata the receipt of treatment is unconfounded. We then consider assumptions that rule out effects of assignment to the treatment on outcomes for certain groups but allow for general differences between units who comply and those who do not comply with their treatment assignment. Assessment of the plausibility of these assumptions relies heavily on subject-matter knowledge, in addition to the design of the assigned treatment.
In general there are two key assumptions justifying instrumental variables approaches. The first is that, although the receipt of the treatment is generally confounded when noncompliance occurs, the assignment to the treatment is unconfounded. As a result of unconfoundedness, we can estimate the effect of the assignment to treatment on both the outcome of interest, and on the receipt of treatment, that is, the two ITT effects. The unconfoundedness of assignment assumption is satisfied by design in the completely randomized experiment setting considered in this chapter, although in other applications of IV methods, this assumption can be controversial. The second key assumption is that the assignment to treatment has no effect on the final outcome of interest for those units whose receipt of treatment is unaffected by the assignment. For instance, for those who do not take the drug even when assigned to take it, the assignment itself is assumed to have no effect on the final outcome. We refer to this assumption as an exclusion restriction, because the instrument is excluded from affecting the outcome of interest for noncompliers. This assumption can be justified by design, for example, using doubleblind experiments, where neither the unit nor the physician knows which treatment was assigned, thereby supporting the exclusion restriction. The key result in this chapter is that the exclusion assumption, when combined with the unconfoundedness assumption, enables us to estimate causal effects of the assignment to treatment on the principal outcome, Yi, for the subpopulation of compliers, known as the local average treatment effect (LATE) or the complier average causal effect (CACE). The estimand, the average effect for compliers, is equal to the ratio of the ITT effect of Zi on the outcome of interest, Yi, and the ITT effect of Zi on the receipt of treatment Wi. In other words, under the exclusion restrction, the ITT effect of assignment on the outcome of interest is due entirely to those units for whom receipt of treatment Wi is always identical to the

516

Analysis of Randomized Experiments with One-Sided Noncompliance

assignment to treatment Zi, irrespective of their assignment. In many cases, it may then be reasonable to attribute the causal effect of assignment for the compliers to the causal effect of the receipt of treatment, the same way researchers often do, typically implicitly, in completely randomized experiments with full compliance.
We must emphasize from the outset that the assumptions underlying the instrumental variables approach, most importantly various forms of exclusion restrictions, are often controversial. When appropriate, these assumptions allow the researcher to make more interesting, and stronger, inferences than those obtained from ITT analyses. However, these assumptions are not always appropriate. Moreoever, unlike the unconfoundedness assumption, the validity of the exclusion restriction cannot be guaranteed solely by physical randomization, requiring in addition double blinding. Therefore, like SUTVA, its validity often relies on subject-matter knowledge.
The rest of the chapter is organized as follows. In Section 23.2 we describe the data set that will be used to illustrate the theoretical concepts introduced in this chapter. Next, in Section 23.3 we extend the potential outcomes notation to account for the instrumental variables setup. In the following section, Section 23.4, we analyze intention-to-treat effects. We define compliance behavior in Section 23.5. In Section 23.6 we discuss the instrumental variables estimand. In Section 23.7 we briefly discuss traditional momentbased estimators for the instrumental variables estimand. Then, in Section 23.8 we relate the discussion to traditional, linear-model-based instrumental variables methods. In Section 23.9 we discuss three naive methods for analyzing data from a randomized experiment with one-sided noncompliance. Section 23.10 concludes.

23.2 THE SOMMER-ZEGER VITAMIN A SUPPLEMENT DATA
We illustrate the methods discussed in this chapter using data previously analyzed by Sommer and Zeger (1991). Sommer and Zeger study the effect of vitamin A supplements on infant mortality in Indonesia. The vitamin supplements were randomly assigned to villages, but some of the individuals in villages assigned to the treatment group failed to receive them. None of the individuals assigned to the control group received the supplements, so noncompliance is one-sided. In this study, outcomes are observed for N = 23,682 infants. The observed outcome of interest, denoted by Yiobs, is a binary variable, indicating survival of an infant. Receipt of the vitamin supplements, which is considered the treatment of interest, is denoted by Wiobs  {0, 1}. In a slight departure from the notation in previous chapters, we add here the superscript "obs" to Wi for reasons that will become apparent later. Assignment to the supplements, the instrument, is denoted by Zi  {0, 1}. This assignment varies only at the village level. We ignore the clustering of the assignment at the village level because we do not have indicators for villages; this will tend to lead us to understate standard errors.
With all three observed variables binary, there are, in principal, eight different possible values for the triple (Zi, Wiobs, Yiobs). Because of the noncompliance, there may be units with Zi = Wiobs, but because Zi = 0 implies Wiobs = 0, there are only six values of the triple with positive counts in our sample. Table 23.1 contains the counts of the six observed values for the triple in the data set, with a total sample size of N = 23,682.

23.3 Setup

517

Table 23.1. Sommer­Zeger Vitamin Supplement Data

Compliance Type
co or nc co or nc nc nc co co

Assignment Zi
0 0 1 1 1 1

Vitamin Supplements
Wiobs
0 0 0 0 1 1

Survival Yiobs
0 1 0 1 0 1

Number of Units (N = 23,682)
74 11,514
34 2385
12 9663

23.3 SETUP
First, let us expand the potential outcomes notation to fit the IV setting. Given the divergence between assignment to, and receipt of, treatment, the potential outcomes notation becomes more complex than in previous chapters. We maintain throughout this chapter the SUTVA assumption, that (i) there are no versions of the treatments, and (ii) there are no causal effects of one unit's treatment assignment on another unit's outcome. We focus on the case where the assignment Zi takes on two values, Zi = 0 if unit i is assigned to the control group, and Zi = 1 if unit i is assigned to the treatment group. The treatment of primary interest (in the Sommer-Zeger application, the receipt of the vitamin supplements) is denoted by Wiobs. Formally recognizing the role of this variable as an outcome, possibly affected by the assignment to treatment Zi, we postulate the existence of two potential outcomes, Wi(0) and Wi(1), describing the treatment that would be received under each of the two values of the assignment Zi. Thus Wi(0) is the treatment unit i would receive if assigned to the control, Zi = 0, and Wi(1) is the treatment unit i would receive if assigned to the active treatment, Zi = 1. Both Wi(0) and Wi(1) take values in {0, 1}. For unit i, the realized or observed treatment status, Wiobs, equals

Wiobs = Wi(Zi) =

Wi(0) Wi(1)

if Zi = 0, if Zi = 1.

In contrast to earlier chapters, we use the superscript "obs" for the treatment here to distinguish the observed value of the primary treatment from the potential primary treatment, which is generally a function of the secondary treatment, Zi.
For the outcome of interest we take into account that there are, in the noncompliance setting, two "treatments," assignment to treatment Zi and receipt of treatment Wi. Each takes on two values, so to be general we postulate four potential outcomes, Yi(z, w), describing the outcome observed if unit i were assigned treatment z and actually received treatment w. For each unit, only two of these four potential outcomes can possibly be observed, Yi(0, Wi(0)) and Yi(1, Wi(1)). The remaining two, Yi(0, 1-Wi(0)) and Yi(1, 1- Wi(1)), cannot be observed irrespective of the assignment, and so we refer to the last two as a priori counterfactuals. The observed outcome for unit i in our sample, denoted

518

Analysis of Randomized Experiments with One-Sided Noncompliance

by Yiobs, is



Yi(0, 0),

Yiobs

=

Yi(Zi, Wiobs)

=

Yi(Zi,

Wi(Zi))

=

YYii((11,,

0), 1),

if Zi = 0, Wiobs = 0, if Zi = 1, Wiobs = 0, if Zi = 1, Wiobs = 1.

Note that because the noncompliance is one-sided, there are no units for whom we observe Yi(0, 1). As usual, we think of the population of interest as the N units for which we observe: the instrument Zi, the treatment received Wiobs, and the outcome Yiobs.
In this chapter we consider both (a) averages over observations by treatment received, and (b) averages by treatment assigned. It is therefore useful to have formal notation for these. For notational clarity, the subscripts 0 and 1 denote treatment assignment levels, and the subscripts c and t denote the level of receipt of treatment. Define the subsample sizes by treatment assignment:

N
N0 = (1 - Zi),
i=1

N
N1 = Zi,
i=1

sample sizes by treatment received:

N
Nc = (1 - Wiobs),
i=1

N
and Nt = Wiobs
i=1

and sample sizes by both treatment assignment and receipt:

N
N0c = (1 - Zi) · (1 - Wiobs),
i=1

N
N0t = (1 - Zi) · Wiobs,
i=1

N
N1c = Zi · (1 - Wiobs),
i=1

N
and N1t = Zi · Wiobs.
i=1

Analogously, define the average outcomes and average treatment received by assignment subsample:

Y

obs 0

=

1 N0

N
(1 - Zi) · Yiobs,
i=1

Y

obs 1

=

1 N1

N
Zi · Yiobs,
i=1

W

obs 0

=

1 N0

N
(1 - Zi) · Wiobs,
i=1

W

obs 1

=

1 N1

N i=1

Zi · Wiobs,

average outcomes by treatment received:

Y

obs c

=

1 Nc

N i=1

(1 - Wiobs) · Yiobs,

and

Y

obs t

=

1 Nt

N i=1

Wiobs · Yiobs;

23.4 Intention-to-Treat Effects

519

and, finally, average outcomes by both treatment assignment and treatment receipt:

Y

obs 0c

=

1 N0c

N i=1

(1 - Zi) · (1 - Wiobs) · Yiobs,

Y

obs 0t

=

1 N0t

N i=1

(1 - Zi) · Wiobs · Yiobs,

Y

obs 1c

=

1 N1c

N i=1

Zi · (1 - Wiobs) · Yiobs,

and

Y

obs 1t

=

1 N1t

N
Zi · Wiobs · Yiobs.
i=1

Some of the Nzw may be zero (in fact, N0t is zero in the current chapter with one-sided compliance), and the corresponding Yzw would not be defined in that case.

23.4 INTENTION-TO-TREAT EFFECTS
The first step in our discussion of the IV approach is to study intention-to-treat (ITT) estimands. As we mentioned in Section 23.1, ITT analyses entirely avoid the problem of noncompliance by focusing only on the relationship between the random assignment of Zi and the outcome, because inference for such effects relies solely on the randomization of the assignment. In contrast to many conventional ITT analyses, we consider two versions of such analyses: analyzing, as "outcomes," both the receipt of treatment (receipt of vitamin A supplements) and the final outcome (survival).

23.4.1 ITT Estimands
Let us first consider the intention-to-treat effect on the receipt of treatment. The unit-level effect of the assignment on the receipt of treatment is

ITTW,i = Wi(1) - Wi(0).

The ITT effect on the receipt of treatment is the average of this over all units:

ITTW =

1 N

N i=1

ITTW,i

=

1 N

N i=1

Wi(1) - Wi(0)

.

(23.1)

Because noncompliance is one-sided, Wi(0) = 0 for all i, and the expression in Equation (23.1) simplifies to

ITTW

=

1 N

N
Wi(1).
i=1

Next, let us consider the outcome of primary interest, Yi. The unit-level intention-totreat effect is equal to the difference in unit-level outcomes Yi by assignment status Zi:

ITTY,i = Yi(1, Wi(1)) - Yi(0, Wi(0)),

520

Analysis of Randomized Experiments with One-Sided Noncompliance

for i = 1, . . . , N. The average ITT effect on Y is therefore

ITTY

=

1 N

N i=1

ITTY,i

=

1 N

N i=1

Yi(1, Wi(1)) - Yi(0, Wi(0))

.

The key assumption for identifying the ITT effects in the simple setting of the Sommer-Zeger data set is that the assignment is random. (More generally, we could allow for unconfounded treatment assignment.) Here we formulate that in terms of the extended potential outcome notation, by assuming the distribution of Zi is free from dependence on all potential outcomes, including the two potential treatments Wi(z) and four potential outcomes Yi(z, w):

Assumption 23.1 (Random Assignment of Zi)

Pr(Zi = 1 |Wi(0), Wi(1), Yi(0, 0), Yi(0, 1), Yi(1, 0), Yi(1, 1) ) = Pr(Zi = 1) .
From a super-population perspective, the assumption, is in the Dawid conditionalindependence notation,

Zi  Wi(0), Wi(1), Yi(0, 0), Yi(0, 1), Yi(1, 0), Yi(1, 1).

23.4.2 Estimating the ITT Effect for the Receipt of Treatment
Given Assumption 23.1, we can estimate ITTW following Neyman's approach, outlined in Chapter 6. Complete randomization of the assignment implies that an unbiased estimator for the average causal effect ITTW exists in the form of the average difference in treatment status by assignment status:

ITTW

=

W

obs 1

-

W

obs 0

=

W 1obs ,

where we use the fact that Wi(0) = 0 for all units. Following the derivation presented in Chapter 6, the general form of the (conservative) estimator for the finite-sample sampling variance of ITTW, under the randomization distribution, is

V(ITTW)

=

s2W,0 N0

+

s2W,1 , N1

where s2W,0 and sW2 ,1 are the sample variances of Wi(z) within each assignment arm. Because Wi(0) = 0, it follows that

sW2 ,0

=

1 N0 - 1

i:Zi=0

Wiobs

-

W

obs 0

2
= 0,

and we are concerned only with

sW2 ,1

=

1 N1 - 1

i:Zi=1

Wiobs

-

W

obs 1

2

=

N1 N1 -

1

·

W

obs 1

· (1

-

W o1bs ).

23.4 Intention-to-Treat Effects

521

Hence the estimator for the sampling variance of ITTW reduces to

V(ITTW)

=

1 N1 -

1

·

W

obs 1

·

(1

- Wo1bs).

Recall, from the discussion of randomized experiments in Chapter 6, that this is also a valid estimator for the sampling variance of ITTW when it is viewed as an estimator of the super-population average treatment effect. Using a normal approximation to the sampling distribution, we can construct a randomization-distribution-based, large-sample, 95% confidence interval for ITTW as

CI0.95(ITTW) = ITTW - 1.96 · V(ITTW), ITTW + 1.96 · V(ITTW) .

Let us illustrate this using the Sommer-Zeger vitamin A data. For these data we find

W

obs 1

=

0.8000,

and s2W,1 = 0.40002.

Given that N1 = 12,094 individuals were assigned to receive the vitamin supplements, it follows that

ITTW = 0.8000, and V ITTW = 0.00362,

leading to a 95% large-sample confidence interval for ITTW equal to CI0.95(ITTW) = 0.7929, 0.8071 .

Thus, we obtain for the Sommer-Zeger data a precise estimate of the ITT effect of assignment to treatment on the receipt of treatment (with the caveat that we ignore the clustered randomization).

23.4.3 Estimating the ITT Effect for the Outcome of Interest
Next let us consider the outcome of primary interest, Yi. Because the assignment Zi is unconfounded, we can unbiasedly estimate the conventional intention-to-treat estimand, ITTY. Using the analysis for randomized experiments from Chapter 6, an unbiased estimator for this effect can be obtained by differencing the average outcomes for those assigned to the treatment and those assigned to the control:

ITTY

=

Y

obs 1

-

Y

obs 0

,

where

Y

obs 1

and

Y

obs 0

are

as

defined

in

Section

23.3.

The

sampling

variance

for

this

estimator can also be estimated using the methods from Chapter 6:

V(ITTY)

=

sY2 ,1 N1

+

s2Y,0 , N0

522

Analysis of Randomized Experiments with One-Sided Noncompliance

where

s2Y ,0

=

1 N0 - 1

i:Zi=0

Yiobs

-

Y

obs 0

2
,

and

sY2 ,1

=

1 N1 -

1

i:Zi=1

Yiobs

-

Y

obs 1

2
.

Let us return again to the vitamin A supplement data. Using the survival indicator Yiobs as the outcome, we find:

Y

obs 0

=

0.

9956,

Y

obs 1

=

0.

9962,

s2Y,0 = 0. 07972,

and

sY2 ,1 = 0. 06162.

Given that N1 = 12, 094 individuals were assigned to receive the supplements, and N0 = 11, 588 were assigned to receive no supplements, it follows that

ITTY = 0. 0026, and V ITTY = 0. 00092,

leading to a large-sample 95% confidence interval for ITTY:
CI0.95(ITTY) = 0. 0008, 0. 0044 .
We conclude that the estimated ITT effect of assignment to supplements on survival is positive and statistically different from zero at conventional significance levels. If all we were interested in is these ITT effects, we could stop here. In many cases, however, there is also interest in the causal effect of taking the supplements as opposed to the causal effect of being assigned to take them. Part of the motivation is that one may believe that the causal effect of actually taking the treatment has more external validity, that is, is more likely to generalize to other settings and populations, than the causal effect of being assigned to take them. The argument for this is that the ITT effect combines partly the biological effect of taking the supplements, and the psychological effect of assignment to take the supplements on actually taking them. When this is true, the causal effect of taking the supplements may be more relevant than the causal effect of assigning individuals to take the supplements for policy makers who are considering making them available in other parts of the country or on a wider scale, with more or less encouragement to them than in the current experiment. This point is particularly compelling when the reasons for the noncompliance are idiosyncratic to the setting in which the experiment was conducted, so that in different settings, compliance may be substantially different.

23.5 COMPLIANCE STATUS
A crucial role in the analyses discussed in this chapter is played by the compliance behavior of the units. Here we continue our analysis of the IV approach with a detailed discussion of this behavior, captured by the pair of potential outcomes (Wi(0), Wi(1)). A key feature of our approach is that we view the compliance behavior in this study when assigned not to take (Wi(0)) and when assigned to take (Wi(1)) as reflecting partially observed characteristics of each unit.

23.5 Compliance Status

523

Table 23.2. Possibly Compliance Status by Observed Assignment and Receipt of Treatment for the Sommer-Zeger Vitamin Supplement Data

Assignment Zi

0

1

Receipt of treatment Wiobs

0

nc or co

nc

1

­

co

Note: One-sided noncompliance rules out the Zi = 0 Wiobs = 1 cell.

23.5.1 Compliers and Noncompliers
Let us return to the two potential outcomes for the treatment received, Wi(0) and Wi(1). By the assumption that noncompliance is one-sided, it follows that all units assigned to the control in fact receive the control, thus Wi(0) = 0 for all i. In contrast, Wi(1), the treatment unit i would receive if assigned to the active treatment, can equal either 0 or 1. Units with Wi(1) = 1 will be observed to comply with their assignment, irrespective of what that assignment is, whereas those with Wi(1) = 0 will be observed not to comply if assigned to Zi = 1. We therefore label the former group compliers and the latter group noncompliers. In a randomized experiment with full compliance, Wi(z) would be equal to z for all units, and as a result, all units would be compliers. Note that this definition of compliance status is based solely on a unit's behavior given assignment to the active treatment in this experiment. Because all units assigned to the control can be prevented from receiving the active treatment, all units will be observed to comply when assigned Zi = 0. Thus we can only distinguish, by observation, compliers from noncompliers in the subgroup assigned to the treatment. For the purposes of our discussion, compliance status will be denoted by a group indicator Gi  {co, nc}, with Gi = co for compliers and Gi = nc for noncompliers:

Gi =

co nc

if Wi(1) = 1, if Wi(1) = 0.

Table 23.2 illustrates the compliance status and its relation to the observed assignment Zi and the observed receipt of the treatment Wiobs. The "-" entry, corresponding to Zi = 0 and Wiobs = 1, indicates that by the fact that noncompliance is one-sided, there are no units with Zi = 0 and Wiobs = 1.
When we consider two-sided noncompliance in the next chapter, we generalize these
ideas to allow for the possibility that some of those assigned to the control group in fact
can receive the active treatment, and thus allow Wi(0) to differ from zero. Let Nco and Nnc denote the number of units of each type in the sample:

N

N

Nco = 1Gi = co, and Nnc = 1Gi=nc = N - Nco,

i=1

i=1

and let co and nc denote the sample fractions of compliers and noncompliers:

co

=

Nco , N

and

nt

=

Nnc N

=

1 - co.

524

Analysis of Randomized Experiments with One-Sided Noncompliance

In the potential outcomes notation, it becomes clear that the compliance status in this experiment is a latent characteristic of an individual unit. It is a characteristic in the sense that compliance status is not affected by outside manipulation (specifically, it is not affected by the assignment to treatment Zi); it is latent because we cannot observe its value for all units: that is, for those units assigned to the control group, we do not observe their compliance status. In contrast, for units assigned to receive the active treatment, we do observe whether they are compliers or noncompliers (although this will change when we allow for two-sided noncompliance in the next chapter). Hence the three key features of this latent compliance status are: (i) it is a function of the two (secondary) potential outcomes, which describe the receipt of treatment for different values of the assignment Zi; (ii) the value of the characteristic is not affected by the assignment to treatment, although which value is observed is affected by the assignment; and (iii) it cannot always be entirely inferred from the observed values for assignment and treatment, Zi and Wiobs. This last feature is illustrated in Table 23.2 by the fact that the (Zi = 0, Wiobs = 0) cell contains a mixture of compliers and noncompliers.

23.5.2 The ITT Effect on the Treatment Received by Compliance Status
First let us consider the population ITT effect on the secondary outcome, treatment received, separately by compliance status. For noncompliers, Wi(z) = 0 for z = 0, 1. Hence

1

1

ITTW,nc = Nnc i:Gi=nc Wi(1) - Wi(0)

=

Nnc

Wi(1)
i:Gi=nc

=

0.

For compliers, Wi(z) = z for z = 0, 1. Hence

ITTW,co

=

1 Nco

i:Gi=co

Wi(1) - Wi(0)

=

1 Nco

Wi(1)
i:Gi=co

=

1.

The overall ITT effect on treatment received is a weighted average of the withincompliance subpopulation ITT effects:

ITTW = nc · ITTW,nc + co · ITTW,co = co,

and nc = 1 - ITTW. In words, the ITT effect on treatment received is equal to the population fraction of compliers. Note that this does not rely on any assumptions. It simply follows from the definition of compliance behavior and the existence of the potential outcomes.

23.5.3 The ITT Effect on the Primary Outcome by Compliance Status
The next step is to decompose the intention-to-treat effect for the primary outcome, ITTY, into a weighted average of the intention-to-treat effects by compliance status. Define

ITTY,co

=

1 Nco

i:Gi=co

Yi(1, Wi(1)) - Yi(0, Wi(0))

,

23.5 Compliance Status

525

and 1
ITTY,nc = Nnc i:Gi=nc Yi(1, Wi(1)) - Yi(0, Wi(0)) , so that we can write

ITTY = ITTY,co · co + ITTY,nc · nc

(23.2)

= ITTY,co · ITTW + ITTY,nc · (1 - ITTW).
Let us consider directly the ITTY effects by compliance type. The average ITT effect for noncompliers is

ITTY,nc

=

1 Nnc

i:Gi=n

Yi(1, 0) - Yi(0, 0)

.

Note, however, that this ITT effect for noncompliers is not informative about the effect of the primary treatment: it compares two potential outcomes for a group of units, all of which always receive the control treatment.
For compliers the ITT effect is generally more interesting for the causal effects of the receipt of treatment. The average ITTY effect for compliers is

ITTY,co =

1 Nco

i:Gi=c

Yi(1, 1) - Yi(0, 0)

.

This ITT effect is at least potentially informative about the effect of the primary treatment, because it is based on a comparison of potential outcomes when receiving the active treatment and when not receiving the active treatment for the subpopulation of compliers.
The two ITT effects on Y by complier status, ITTY,co and ITTY,nc, cannot be estimated directly from the observable data, because we cannot infer the latent compliance status for units assigned to the control group. Nevertheless, because receipt of treatment, Wiobs, is unconfounded conditional on compliance status given randomization of the assignment, we can still distentangle the ITT effects by compliance type under an additional assumption: the exclusion restriction.
It is important here that the receipt of treatment is unconfounded within subpopulations defined by compliance status. This follows from Assumption 23.1, that Zi is randomly assigned, in combination with the fact that Wiobs is a deterministic function of Zi given compliance status.
Lemma 23.1 (Super-Population Unconfoundedness of Receipt of Treatment Given Compliance Status) Suppose Assumption 23.1 holds. Then, for g  {co, nc},

Pr Wiobs = 1 Yi(0, 0), Yi(0, 1), Yi(1, 0), Yi(1, 1), Gi = g = Pr Wiobs = 1 Gi = g ,

526

Analysis of Randomized Experiments with One-Sided Noncompliance

or
Wiobs  Yi(0, 0), Yi(0, 1), Yi(1, 0), Yi(1, 1) Gi.
To see this, consider the two compliance types separately. First, for noncompliers (Gi = nc), we always have Wiobs = 0, so unconfoundedness holds trivially. For compliers (Gi = co), Wiobs = Zi, and thus Lemma 23.1 holds by Assumption 23.1, random assignment of Zi. The problem is that we cannot directly exploit the latent unconfoundedness result in Lemma 23.1 (latent, because it only holds given a partially unobserved covariate), because compliance type is only partially observed. We therefore rely on indirect methods for exploiting this latent unconfounedness property.

23.6 INSTRUMENTAL VARIABLES
In this section we discuss the key assumption underlying the method of instrumental variables, and present the main result of this chapter that, under that key assumption, we can estimate the average ITT effect for compliers, ITTY,co. We discuss the interpretation of this ITT effect and how it may be related to the causal effect of the receipt of treatment. We then discuss two approaches to inference for this average effect.
23.6.1 Exclusion Restriction for Noncompliers First we discuss the key assumption that underlies, in some form or another, all instrumental variables analyses.
Assumption 23.2 (Exclusion Restriction for Noncompliers) For all noncompliers, that is, all units with Gi = nc,
Yi(0, 0) = Yi(1, 0).
This assumption, the exclusion restriction, rules out, for noncompliers, an effect of the assignment, the instrument Zi, on the outcome of interest Yi. It states that changing the assignment has no causal effect on the outcome, for those units for whom the level of the primary treatment Wi does not change with the change in assignment.
This exclusion restriction is the key assumption underlying the instrumental variables approach. Unlike the latent unconfoundedness assumption, however, it is not implied by the randomization of the assigned treatment. Instead, it is a substantive assumption that need not be appropriate in all randomized experiments with noncompliance, although it can be made plausible by design features such as double-blinding.
A slightly weaker version of the exclusion restriction for noncompliers requires the exclusion restriction to hold in distribution for the super-population:
Assumption 23.3 (Stochastic Exclusion Restriction for Noncompliers)
Zi  Yi(Zi, Wi(Zi)),
for all noncompliers, that is, all units with Gi = nc.

23.6 Instrumental Variables

527

This assumption implies that the super-population distribution of Yi(0, 1) is the same as that of Yi(1, 0) for noncompliers with Wi(0) = Wi(1) = 0. One advantage of this assumption is that there is a natural way to relax it in the presence of pre-treatment variables by requiring the independence to hold only conditional on the pre-treatment variables.

23.6.2 Exclusion Restriction for Compliers
Because of the central role of the exclusion restriction, some general comments about the applicability of this assumption are in order. Before doing so, let us also formulate a second exclusion restriction, this time for compliers.
Assumption 23.4 (Exclusion Restrictions for Compliers) For all units with Gi = co, that is, all compliers,
Yi(0, w) = Yi(1, w)
for both levels of the treatment w.
This is an assumption of a very different nature from the exclusion restriction for noncompliers. It restricts, for compliers, Yi(0, 0) to be equal to Yi(1, 0), and restricts Yi(0, 1) to be equal to Yi(1, 1). But for compliers, we observe either Yi(0, 0) or Yi(1, 1), and never observe Yi(0, 1) or Yi(1, 0), and so these restrictions have no empirical consquences, either in the current form or in a stochastic version, unlike the exclusion restriction for noncompliers. In a sense, this restriction is essentially an attribution of the ITT effect for compliers to the causal effect of the receipt of treatment, rather than to its assignment. It is primarily about the interpretation of this ITT effect, not about issues concerning estimating it from the data.
Note that the exclusion restriction for compliers is routinely made, often implicitly, in randomized experiments with full compliance (in that case all units are compliers). For instance, when analyzing and interpreting the results from double-blind randomized drug trials with full compliance, one often implicitly assumes that the estimated effect is due to the receipt of the drug, not to the assignment to receive the drug. Thus, the assumption is implicitly made that similar unit-level treatment effects will occur if the assignment mechanism is changed from randomized assignment to either voluntary assignment or full adoption. Specifically, suppose a drug company estimates the efficacy of a new drug in a randomized trial. Implicitly the assumption is that, had, at the start of the trial, all individuals been told that they would receive the new active drug and that no one would receive the control treatment, the typical outcome would have been approximately the same as the typical outcome observed in the subsample actually assigned to the treatment. Moreoever, after the drug is approved, physicians will presumably prescribe the new drug without using randomization. Again the presumption is that their patients will respond to the prescribed treatment in the same way that similar subjects in the randomized trial responded to assignment to the possibly unknown, blinded, treatment.
Yet the fact that this assumption is often implicitly made does not mean that this exclusion restriction is innocuous. There are many examples of studies where assignment did

528

Analysis of Randomized Experiments with One-Sided Noncompliance

make an important difference, separate from receipt of the active treatment. Concerns about potential complications from such direct effects of assignment motivate the use of placebos, and blinding or double blinding, in clinical trials with human subjects. If individuals do not know their values of assignment, it is difficult to see how the assignments could affect their outcomes, except through the biological effect of the treatment received. But, again, receipt of a known, approved drug is not necessarily the same as receipt of a blinded drug being evaluated in the experiment.

23.6.3 Discussion of the Exclusion Restrictions
In some settings where noncompliance is an issue, however, placebos and (double-) blinding are often infeasible. If the treatment is an invasive procedure or requires active participation on the part of the individual, the researcher typically cannot hide the nature of the treatment. Even in randomized eligibility designs, where access (eligibility) to the treatment is randomized, the exclusion restriction may be violated. Individuals assigned to the active treatment may refuse to accept it but, in response to the notification of eligibility, may take actions they would not have taken otherwise. For example, consider the evaluation of a smoking cessation program. Suppose the program is offered to a random sample of smokers. Some may be unwilling to go through the program if it takes a large amount of time or effort. Yet in response to the assignment such individuals may still change their lifestyles, including their smoking habits in ways that affect their subsequent health outcomes. In that case, health outcomes would differ by assignment for such individuals, even though they are noncompliers who do not participate in the program irrespective of their assignment. Examples such as these illustrate that the exclusion restriction requires careful consideration of the various paths through which assignment may affect outcomes.
One should note, however, that the exclusion restrictions, Assumptions 23.2 and 23.4, do not in any way restrict compliance behavior itself. For example, it allows for the possibility that individuals know their outcomes under both treatments and deliberately choose to comply when assigned to the active treatment only if it will benefit them. Specifically, suppose that all those with Yi(1, 1) > Yi(1, 0) (those whose health status would improve with the receipt of the treatment) choose to comply, and all those with Yi(1, 1)  Yi(1, 0) choose not to. Such behavior would imply that the receipt of treatment Wiobs is confounded, and it is often exactly this type of systematic noncompliance behavior that motivates researchers to consider instrumental variable analyses. Such behavior is not, however, inconsistent with the exclusion restriction and thus will be compatible with the analyses developed here.
Let us consider the exclusion restriction for noncompliers for the Sommer-Zeger vitamin A supplement data. This restriction requires that, for those individuals who would not receive the supplements even if assigned to take them, the potential outcomes are unaffected by assignment. This assumption seems fairly plausible. If some mothers living in villages assigned to the treatment did not receive the supplements because of administrative mishaps, or through lack of interest, it is quite likely that the infants of such mothers would not have had different outcomes had their village been assigned to the control group, except if there are fewer contiguous infant diseases in the villages that were assigned the vitamin supplements. Nevertheless, this is a key assumption for

23.6 Instrumental Variables

529

the validity of the IV approach, and even in this example it is not necessarily satisfied. Violations of this assumption could arise if the reason these women did not receive the supplements was related to other health improvement measures taken in some villages but not in others. For example, suppose that noncompliance was high in some villages because the administrators in those villages, if assigned to receive the supplements, diverted the program funding toward other health care improvements that would have been otherwise unaffordable. In that case, outcomes for noncomplying mothers would differ by assignment, even though none took the supplements, violating the exclusion restriction. Such a story may seem fairly implausible in this case, but such stories are important to consider. We will return to discuss such violations in other examples in subsequent chapters.

23.6.4 Local Average Treatment Effects
In this section we discuss the most important result in this chapter. Consider the average ITT effect in the population, decomposed by compliance status:

ITTY = ITTY,co · ITTW + ITTY,nc · (1 - ITTW),

(23.3)

using the fact that the one-sided nature of the noncompliance implies that ITTW = co. The exclusion restriction for noncompliers implies that for noncompliers Yi(0, 0) = Yi(1, 0), and thus,

ITTY,nc = 0.

Hence, the second term on the right-hand side of (23.3) is zero, reducing the global ITT on the outcome to the product of two ITT effects, the "local" ITT effect on the outcome for the compliers, and the global ITT effect on the receipt of treatment:

ITTY = ITTY,co · ITTW.

(23.4)

We now rearrange Equation (23.4) to give our formal result:
Theorem 23.1 (Local Average Treatment Effect) Suppose that Assumption 23.2 holds. Then

late

=

ITTY,co

=

ITTY . ITTW

In other words, under the exclusion restriction for noncompliers, the ratio of the ITT effect on the outcome to the ITT effect on the treatment is equal to the ITT effect on the outcome for compliers, or what is called the Local Average Treatment Effect (LATE), or, synonymously, the Complier Average Causal Effect (CACE).
If we are also willing to assume the second exclusion restriction, the exlusion restriction for compliers given in Assumption 23.4, we can interpret this local average treatment effect as the average causal effect of the receipt of treatment for compliers. Thus, given both exclusion restrictions and the randomization assumption, we can learn about the effect of the primary treatment for the subpopulation of compliers, because we can unbiasedly estimate both the numerator and the denominator of late.

530

Analysis of Randomized Experiments with One-Sided Noncompliance

To give a different interpretation for the result in Theorem 23.1, suppose for a moment that we could observe compliance status for all units. By Lemma 23.1, receipt of treatment is unconfounded given compliance status Gi, and so we could then analyze the data separately for noncompliers and compliers. Within these subpopulations, we can compare outcome by treatment status. For noncompliers, there would be no information in the data regarding the effect of the primary treatment on the outcome, because no noncomplier ever receives the active treatment. The data from noncompliers would therefore be discarded because of the absence of units who received the active treatment. For compliers, receipt of treatment is identical to assignment, and for this subpopulation we can therefore consistently estimate effects of the receipt of the treatment on the outcome, because, by the second exclusion restriction, it equals the intention-to-treat effect of the assignment on the final outcome. The only, but crucial, missing piece in this argument is that we do not observe the compliance status for all units. However, given the exclusion restriction, we can disentangle the potential outcome distributions for compliers and noncompliers from the mixture of noncompliers and compliers in the subpopulation assigned to the control treatment, through, for example, an imputation-based approach such as that outlined in Chapter 25 or the moment-based approach introduced here.

23.7 MOMENT-BASED INSTRUMENTAL VARIABLES ESTIMATORS
Summarizing the discussion so far, the overall ITT effect consists of two parts, the ITT effect for compliers and the ITT effect for noncompliers, weighted by their population proportions. The exclusion restriction for noncompliers implies that the ITT effect for noncompliers is zero. Hence, under the exclusion restriction for noncompliers, the ratio of the overall ITT effect, to the population proportion of compliers, is equal to the ITT effect for compliers.
In Section 23.4 we discussed how to estimate and conduct inference for ITTW and ITTY. Given those two unbiased estimators, a simple moment-based instrumental variables (iv) estimator for late is the ratio of estimated ITT effects,
^ iv = ITTY . ITTW
This simple estimator has some drawbacks, and in Chapter 25 we discuss model-based methods that have more attractive statistical properties, especially in small samples. One of the reasons is that it does not necessarily satisfy all the restrictions implied by Assumptions 23.1 and 23.2. We will discuss these restrictions in more detail in Chapter 25, but as a simple example, suppose that ITTW = 0. In that case there are no compliers, and by the exclusion restriction for noncompliers, it must be the case that ITTY = 0. More generally, the restrictions imply that the joint distribution of the data is consistent with the subpopulation of (Zi = 0, Wiobs = 0) being a mixture of compliers and noncompliers, and the outcome distribution for noncompliers being the same as that for units with (Zi = 1, Wiobs = 0).
The sampling variance calculations for the two ITT effects separately followed from the Neyman approach discussed in Chapter 6. Here we discuss the extension to the

23.8 Linear Models and Instrumental Variables

531

sampling variance for ^ iv. Here we take explicitly a super-population perspective. That
is, we view our sample as a random sample from a large population. In that large population, there is an average ITT effect for compliers, ITTY,co = E[Yi(1, Wi(1)) - Yi(0, Wi(0))|Gi = co. We consider the sampling variance of ^ iv - ITTY,co. To calculate the sampling variance of the IV estimator ^ iv requires estimation of the sampling
covariance between ITTW and ITTY. With that covariance, we can use the delta method to estimate the large-sample sampling variance of the ratio of ITT effects. (See the
Appendix to this chapter for more details on the delta method in general.) The result is that in large samples, ^ iv, as an estimator of the super-population ITT effect for
compliers, will be approximately normally distributed with sampling variance

Vsp(^ iv)

=

1 ITTW2

· V(ITTY) +

ITT2Y ITT4W

· V(ITTW)

-

2

·

ITTY ITT3W

·

C(ITTY, ITTW),

(23.5)

where C(·, ·) denotes the covariance of two random variables. A simple estimator for the sampling variance can be based on substituting estimates for the components of this
sampling variance. Using this to construct confidence intervals raises some issues, such
as if the denominator of (23.5), ITTW, is close to zero, normality is likely to be a poor approximation to the sampling distribution of the estimator.
Returning to the vitamin A supplement data, using our earlier estimates for ITTY, V(ITTY), ITTW, and V(ITTW), in combination with the estimate for the covariance of ITTY and ITTW, C(ITTY, ITTW) = -0. 00000017 (corresponding to a correlation between ITTY and ITTW equal to -0.0502), we find that the method-of-moments IV estimate for the effect of taking vitamin A supplements on survival is

^ iv = ITTY = 0.0032, and V(^ iv) = 0.00122, ITTW
leading to a 95% large-sample confidence interval for ITTY,co (or late) equal to
CI0.95(ITTY,co) = 0.0010, 0.0055 .
Because the ITT effect on the receipt of treatment is precisely estimated, and far from zero, the 95% confidence interval is likely to be valid (in the statistically conservative sense), with the qualification that we ignored the clustering of the experiment by village.
If in addition to the exclusion restriction for noncompliers, we are willing to assume the exclusion restriction for compliers, this estimated ITT effect for compliers can be interpreted as equal to the estimated average effect of the primary treatment on the primary outcome for compliers.

23.8 LINEAR MODELS AND INSTRUMENTAL VARIABLES

Even for readers familiar with traditional discussions of instrumental variables in econometric textbooks, the discussion thus far may look unfamiliar. In this section we discuss the link between the approach advocated in this book and conventional econometric

532

Analysis of Randomized Experiments with One-Sided Noncompliance

instrumental variables analyses. Readers not familiar with the textbook econometrics approach may wish to skip this section.
The traditional use of instrumental variables in the economics literature relies heavily on linear parametric specifications, even though some of these are not critical. It also takes a super-population perspective, where the sample at hand is assumed to be a random sample from an infinitely large population, and the estimands are population average causal effects. We maintain here both exclusion restrictions, for noncompliers and compliers. As a result we can drop the dependence of the potential outcome Yi(z, w) on z and write, without ambiguity, Yi(w), as a function of the receipt of treatment alone. In order to see the connection with our framework, it is useful to assume initially a constant treatment effect: Yi(1) - Yi(0) =  for all i. We relax this assumption later. Define  = Esp[Yi(0)] to be the super-population average outcome given the control treatment, so that we can write

Esp [Yi(w)] =  +  · w,

for w = {0, 1}. We define the residual i = Yi(0) -  to be the unit-level deviation of the control outcome from its population mean, so that we can further write

Yi(w) =  +  · w + i.

(23.6)

Equation (23.6) is what is known in the econometric literature as a structural or behavioral equation: it relates treatments to outcomes in a causal way. For a given unit i (and thus, for a fixed value i), Yi(w) is the outcome we would observe if we fixed (set in Pearl's (2000) terminology) Wi = w.
Equation (23.6) is not, however, a conventional regression function. Note that it is not written in terms of observed quantities. Substituting observed values for the treatment and outcome we can instead write

Yiobs = Yi(Wiobs) = Yi(0) + Wiobs · (Yi(1) - Yi(0)) =  +  · Wiobs + i.

(23.7)

Yet, as written, Equation (23.7) remains a behavioral equation, not a conditional expectation: in general it is not true that E[Yiobs|Wiobs = w] =  +  · Wiobs. The coefficient  for the treatment indicator Wiobs represents the causal effect of the treatment on the outcome; it is not equal to the ratio of the super-population covariance of Yiobs and Wiobs, to the variance of Wiobs.
The key factor distinguishing Equation (23.7) from a standard regression function is that the regressor, the receipt of treatment Wiobs, is possibly correlated with Yi(0), and thus with the residual i. To see this, let us first calculate the conditional mean of i given Wiobs in the super-population. Here let g be the share in the super-population of compliance type Gi = g. Remember that i is defined as the difference between the observed and expected control outcome: i = Yi(0) -  = Yi(0) - Esp[Yi(0)]. Given Wiobs = 1 we have:
Esp[i|Wiobs = 1] = Esp[i|Gi = co]

= Esp[Yi(0)|Gi = co] - Esp[Yi(0)]

23.8 Linear Models and Instrumental Variables

533

= Esp[Yi(0)|Gi = co] - Esp[Yi(0)|Xi = co] · co + Esp[Yi(0)|Gi = nc] · nc

= nc · Esp[Yi(0)|Gi = co] - Esp[Yi(0)|Gi = nc]

= nc · co,nc,

where co,nc is defined as the difference in average control outcome for compliers
and noncompliers, co,nc = Esp[Yi(0)|Gi = co] - Esp[Yi(0)|Gi = nc]. To calculate Esp[i|Wiobs = 0], first decompose Esp[i] = 0:

0 = Esp[i] = Esp[i|Wiobs = 1] · Pr(Wiobs = 1) + Esp[i|Wiobs = 0] · Pr(Wiobs = 0).

Given that the probability Pr(Wiobs = 1) is equal to pZ · co, and thus Pr(Wiobs = 0) = (1 - pZ · co), it follows that

Esp[i|Wiobs

=

0]

=

- nc · pZ · co 1 - pZ · co

·

co,nc.

These expectations Esp[i|Wiobs = w] are typically not zero. In econometric terminology, the explanatory variable Wiobs is endogenous, and least squares methods do not lead to consistent estimation of  .
Although the receipt of treatment, Wiobs, is not independent of i, the assignment to treatment, or the instrument Zi is independent of i. This follows from the random assignment assumption and the definition of i in terms of the potential outcomes. This independence of Zi and i can be exploited through what is known in econometrics as
Two-Stage-Least-Squares (TSLS) estimation. First, this independence implies that the
conditional expectation of i given Zi is zero. This in turn implies that the conditional expectation of Yiobs given Zi equals,

Esp[Yiobs|Zi] =  +  · Esp[Wiobs|Zi] + Esp[i|Zi] =  +  · Esp[Wiobs|Zi].

This conditional expectation of Yiobs given Zi is linear in Esp[Wiobs|Zi], with coefficient equal to the treatment effect of interest  . We can therefore write

Yiobs =  +  · Esp[Wiobs|Zi] + Wiobs - Esp[Wiobs|Zi] + i =  +  · Esp[Wiobs|Zi] + i,

(23.8)

where the composite residual is i =  · (Wiobs - Esp[Wiobs|Zi]) + i. By random assignment (Assumption 23.1), both i and this unit-level difference Wiobs - Esp[Wiobs|Zi] are uncorrelated with Zi. Thus, the composite residual i is uncorrelated with Zi. This in turn implies that least squares regression of Yiobs on the conditional expectation Esp[Wiobs|Zi] will lead to an unbiased estimate of  , the treatment effect of interest.
Unfortunately this linear regression is infeasible because we do not know the conditional expectation Esp[Wiobs|Zi]. However, we can estimate this conditional expectation. First let us write out the expected value of Wiobs given Zi as a function of Zi ­ for those familiar with IV, the first-stage equation:

Esp[Wiobs|Zi] = 0 + 1 · Zi,

534

Analysis of Randomized Experiments with One-Sided Noncompliance

where 0 = Esp[Wiobs|Zi = 0] and 1 = Esp[Wiobs|Zi = 1] - Esp[Wiobs|Zi = 0]. Given one-sided noncompliance, 0 = 0 (Zi = 0 implies Wiobs = 0), and 1 equals Esp[Wiobs|Zi = 1], which is equal to the super-population proportion of compliers, co. Hence Esp[Wiobs|Zi] = 1 · Zi = co · Zi.
Using this expression we can rewrite Equation (23.8):

Yiobs =  +  · Zi + i, where  =  · co.

(23.9)

Equation (23.9) is known as a reduced form in econometric terminology. Here the regres-

sion function does represent a conditional expectation, and as a result, its parameters can

be consistently estimated by ordinary least squares. The least squares estimator, equal to

the ratio of the covariance of Zi and Yiobs, and the variance of Zi will give an unbiased

estimator of the composite coefficient  =  · co. With Zi binary, this estimator will be

equal to the difference in average outcomes by assignment, ^

=

ITTY

=

Y

obs 1

-

Y

obs 0

.

Similarly, given the unconfoundedness of Zi, regressing Wiobs on Zi will give an unbiased

estimate

of

co.

The

estimator,

with

Zi

binary,

equals

^ co

=

ITTW

=

W

obs 1

-

W

obs 0

.

Dividing the least squares estimator ^ = ITTY, by the estimator ^co = ITTW, gives

the instrumental variables estimator ^ iv = ITTY /ITTW given earlier. For noncompliers,

Wi(z) = 0 for z = 0, 1. Hence, given a binary assignment and treatment, using the linear

parametric specification leads to an estimator identical to the moment-based estimator

based on the potential outcomes approach. This estimator is also identical to that based

on regressing Yi on ^co · Zi. The mechanical two-stage procedure of first regressing the receipt of treatment on the instrument to get an estimate of Esp[Wiobs|Zi], followed by
regressing the outcome of interest on this predicted value of the receipt of treatment, is

what led to the econometric terminology of TSLS, and the IV estimator is therefore also

known as the TSLS estimator.

As just noted, we assumed in this derivation that the treatment effect is constant.

Yet we did not make this same assumption in our potential outcomes discussion of the

instrumental variables approach. As it turns out, this assumption is not necessary in either

approach. Without it, we end up estimating the average treatment effect for compliers.

More precisely, the numerical equivalence of the linear-equation IV estimand to the ratio

of ITT effects does not rely on the assumption of a constant treatment effect. To see this,

let late be the average treatment effect for compliers, or the local average treatment effect, late = Esp[Yi(1) - Yi(0)|Gi = c], and let i be the unit-level difference between i and  , i = Yi(1) - Yi(0) -  . Again let  = Esp[Yi(0)], and i = Yi(0) - . As before

Yiobs = Yi(0) + Wiobs · (Yi(1) - Yi(0)) ,

which, given the definitions provided here, can be rewritten as

Yiobs =  + Wiobs · late + i + Wiobs · i.

(23.10)

We now have a new composite disturbance term, i + Wiobs · i, which again is potentially correlated with Wiobs. Thus an ordinary least squares regression of Yiobs on Wiobs will not provide an unbiased estimate of  .
However, just as i is uncorrelated with Zi, the second component of this new error term, Wiobs · i, is also uncorrelated with Zi. To see this, consider this expectation

23.9 Naive Analyses: "As-Treated," "Per Protocol," and Unconfoundedness

535

separately for Zi = 0 and 1. Because Zi = 0 implies Wiobs = 0, it follows that Esp[Wiobs · i|Zi = 0] = 0. To calculate the expectation given Zi = 1, begin by expanding the expectation for both possible values of Wiobs:
Esp[Wi · i|Zi = 1] = Esp[0 · i|Zi = 1, Wi = 0] · Pr(Wi = 0|Zi = 1)

+ Esp[1 · i|Zi = 1, Wi = 1] · Pr(Wi = 1|Zi = 1)
= Esp[i|Zi = 1, Gi = c] · co = Esp[Yi(1) - Yi(0) -  |Zi = 1, Gi = c]
= Esp[Yi(1) - Yi(0) -  |Gi = c] · co = 0,
by the definition of  as the average treatment effect for compliers. Hence, looking at Equation (23.10), given that Zi is uncorrelated with both elements of the error term, we can use the same argument as used earlier to motivate the moment estimator ^ iv.

23.9 NAIVE ANALYSES: "AS-TREATED," "PER PROTOCOL," AND UNCONFOUNDEDNESS
To put the simple instrumental variables analysis that is the main topic of this chapter in perspective, we conclude this chapter by discussing three other analyses, two of which are occasionally used in randomized experiments with noncompliance, and one of which serves to provide some perspective. (Note that we have already discussed one such alternative, the intention-to-treat analysis.) Like the IV approach, but unlike the ITT approach, these two additional analyses focus on the receipt of treatment, not merely on the causal effect of the assignment to treatment. Four analyses, IV, ITT, As-Treated, and Per Protocol, are identical when observed compliance is perfect, but they generally differ from one another when compliance is less than perfect. As will be seen here, however, in the presence of noncompliance, there is no compelling justification for these two other approaches. We present them merely to provide a better understanding of the competing intention-to-treat and instrumental variables methods.

23.9.1 As-Treated Analyses
The first of these two analyses is the "as-treated" approach. In this approach, the causal effect of the receipt of treatment is estimated as the difference in average outcomes by treatment received, Wiobs:

^at

=

Y

obs t

-

Y oc bs .

(23.11)

This approach would be justified, in the sense that it would give an unbiased estimate of the average treatment effect, if receipt of treatment Wiobs were unconfounded. In general, however, it will not estimate a causal estimand. Here we explore the properties of this
estimator. It will be convenient to take a super-population perspective, where we take the
expectation over the randomization as well as over the distribution generated by random
sampling from a large population.

536

Analysis of Randomized Experiments with One-Sided Noncompliance

The expectation of this estimator in the super-population is

at = Esp Yiobs Wiobs = 1 - Esp Yiobs Wiobs = 0 .

Let us look at this difference in expectations under the two instrumental variables
assumptions, random assignment and the exclusion restriction on noncompliers. Note that in our one-sided noncompliance case, units receiving the treatment must have Zi = 1 and be compliers. Hence Esp[Yiobs|Wiobs = 1] = Esp[Yi(1)|Gi = co]. The second half of Equation (23.11) shows that units not receiving the treatment are a mixture of those
assigned to the control and those assigned to the treatment who did not comply:

Esp[Yiobs|Wiobs = 0] = Esp[Yiobs|Wiobs = 0, Zi = 0] · Prsp(Zi = 0|Wiobs = 0)

+ Esp[Yiobs|Wiobs = 0, Zi = 1] · Pr(Zi = 1|Wiobs = 0).

(23.12)

With pZ = Prsp(Zi = 1), Bayes rule implies that, the probability that Zi = 1 among those who do not take the treatment is equal to

Prsp(Zi

=

1|Wiobs

=

0)

=

nc

·

nc pZ +

· 1

pZ · (1

-

pZ

)

.

In the two expectations on the right-hand side of Equation (23.12), the second is simply the expected outcome for noncompliers under the control treatment. The first expectation in Equation (23.12) is a mixture of the expected value given the control treatment, for both compliers and noncompliers:

Esp[Yiobs|Zi = 0, Wiobs = 0] = Esp[Yi(0)|Gi = co] · co + Esp[Yi(0)|Gi = nc] · nc.

Combining all of the above, we can rewrite the expectation of the as-treated estimator as

at = ITTY,co +

co,nc

·

pZ

·

nc nc + 1

-

pZ

,

where, as before, co,nc is the expected difference in control outcomes for compliers and noncompliers:

co,nc = Esp[Yi(0)|Gi = co] - Esp[Yi(0)|Gi = nc].

Unless compliance is perfect and there are no noncompliers (nc = 0), or the average control outcome is the same for compliers and noncompliers ( co,nc = 0, as implied by unconfoundedness of the treatment Wi), the expected value of ^at differs from the complier average causal effect.
This bias is easy to interpret: at compares the average observed outcome given the active treatment to the average observed outcome given the control treatment. The first term is the average outcome given the active treatment for compliers, but the second term is an average of expected control outcome for compliers and noncompliers. If, as estimated in our example, noncompliers have lower average outcomes without the active treatment than compliers without the active treatment, this lowers the average outcome in the as-treated "control" group. Hence, the as-treated approach will overestimate the average treatment effect for compliers.

23.9 Naive Analyses: "As-Treated," "Per Protocol," and Unconfoundedness

537

Let us illustrate this using the vitamin supplement data. In this sample the estimate of the average outcomes, with and without the supplements, are

Y

obs c

=

11, 514 + 2, 385 11, 514 + 2, 385 + 74

+

34

=

0. 9923,

and

Y

obs t

=

9, 663 9, 663 + 12

=

0. 9988.

Hence the as-treated estimate is

^at = 0. 9988 - 0. 9923 = 0. 0065 (s. e. 0. 0008).

This estimator differs substantially from the IV estimate of 0.0033 calculated earlier. The reason can be seen by considering the estimates of the average outcomes of those assigned to the control for compliers and noncompliers separately. For noncompliers we estimated Esp[Yi(0)|Gi = nc] = 0. 9859, whereas for compliers we estimated Esp[Yi(0)|Gi = co] = 0. 9955, considerably higher. If the exclusion restriction holds, and hence our estimates of Esp[Yi(0)|Gi = co] and Esp[Yi(0)|Gi = nc] are unbiased, the fact that the average outcome under the control treatment is higher for compliers than for noncompliers will lead the as-treated estimator to overestimate the complier average causal treatment effect.

23.9.2 Per Protocol Analyses
Now let us look at a second alternative to ITT and IV analyses, the per protocol analysis, in which only those units who are observed to comply with their assigned status are compared. In this analysis we therefore discard all observed noncompliers assigned to the treatment. Given the observable data, however, we cannot discard noncompliers assigned to the control. By one-sided noncompliance, these individuals automatically take the control; we would only be able to observe their compliance status if we instead saw them assigned to the treatment. If we could, in fact, discard all noncompliers, we would be left with only compliers, and then comparing their average outcomes by treatment status would estimate the average effect of receipt of treatment for compliers.
The per protocol analysis, however, discards only those noncompliers who do not comply with their observed treatment assignment and not those noncompliers who were assigned to the control group. The result is that the per protocol estimator, ^pp, compares units receiving the treatment, that is, the compliers assigned to the treatment, to all units assigned to the control, with the latter a mixture of both compliers and noncompliers:

^pp

=

Y

obs t

-

Y

obs 0

=

1 Nt

N
Wiobs · Yiobs -
i=1

1 N0

N
(1 - Zi) · Yiobs,
i=1

which is biased for co. Its expectation is:

pp = E[Yiobs|Wiobs = 1, Zi = 1] - E[Yiobs|Wiobs = 0, Zi = 0] = Esp[Yi(1)|Gi = co] - Esp[Yi(0)].

(23.13)

538

Analysis of Randomized Experiments with One-Sided Noncompliance

The last term in this expression is equal to E[Yi(0)|Gi = co]·co -E[Yi(0)|Gi = nc]·nc; hence we can rewrite pp as
pp = E[Yi(1) - Yi(0)|Gi = co] · co + (E[Yi(0)|Gi = co] - E[Yi(0)|Gi = nc]) · nc
= ITTY,co + nc · co,nc.
Again, unless either nc or co,nc (or both) are equal to zero, ^pp will not give an unbiased estimate of the average effect of the treatment on compliers, even under the exclusion restriction for nomcompliers.
To illustrate this, we again use the Sommer-Zeger data to estimate pp. Given these data, the first term of the estimand, Esp[Yi(1)|Gi = c] = Esp[Yiobs|Wiobs = 1], is estimated as 0.9988 (s. e. 0.0004), and the second, Esp[Yi(0)] = Esp[Yiobs|Zi = 0], as 11, 514/(11, 514 + 74) = 0. 9936 (s. e. 0.0007). Thus the per protocol estimate,

^pp = 0. 9988 - 0. 9936 = 0. 0051

(s. e. 0. 0008),

is again much larger than our estimate of the local average treatment effect, ^late = 0. 0033.

23.9.3 Analyses under Conditional Unconfoundedness Given the Instrument A final analysis we wish to discuss briefly assumes unconfoundedness, like the "astreated" analysis, but only conditional on the instrument. That is, it focuses on comparisons of units receiving and not receiving the treatment within subpopulations receiving the same level of assignment. Implicitly it treats the instrument as a covariate or pre-treatment variable that needs to be controlled for. In the current setting, with onesided noncompliance among the subpopulation of units assigned to the control group, there are no units receiving the treatment, so we can do this only for the units assigned to the treatment.
The conditional unconfoundedness (cu) statistic focuses, for units assigned to the treatment, on the difference in average outcomes by receipt of treatment:
^cu = Y1t - Y1c.
This approach would be justified if, conditional on the assignment, receipt of treatment is random. Of course, the concern is that the very fact that these units, although assigned to the same level of the treatment, receive different levels of the treatment reflects systematic differences between these units. Let us look at the interpretation of this estimand under the instrumental variables assumptions. Given the definition of the compliance types, ^CU estimates
cu = Esp[Yi(1)|Gi = co] - Esp[Yi(0)|Gi = nc].
It is fundamentally comparing different subpopulations of units, under different treatment levels. More interesting, from a perspective of understanding the differences between the units, is to estimate the average outcomes for compliers and noncompliers

Notes

539

under the control treatment:

co,nc = Esp[Yi(0)|Gi = co] - Esp[Yi(0)|Gi = nc],
because this compares the same potential outcomes for different subpopulations. For the Sommer-Zeger data, we find

^cu = 0. 9988 - 0. 9859 = 0. 0128

(s. e. 0. 0024).

Survival rates for compliers assigned to the control treatment are substantially higher than for noncompliers assigned the active treatment, despite the fact that neither group took any active treatment.

23.10 CONCLUSION
The discussion in this chapter describes the instrumental variables approach to estimation of causal effects in randomized experiments with one-sided noncompliance, in settings where unconfoundedness of the receipt of treatment of interest is viewed as untenable. The approach exposited here relies on two key assumptions, which together replace the assumption of unconfoundedness of the receipt of treatment. The two assumptions are: unconfoundedness of the assignment to the active treatment (the instrument), rather than the receipt of treatment; and an exclusion restriction that rules out an effect of assignment on the outcome of interest for noncompliers. The first of these assumptions is implied by design in the randomized experiment setting. The second assumption relies more heavily on subject-matter knowledge, although it can be made more plausible by design measures such as double-blinding. Under those two assumptions, we can estimate the average effect of the treatment on a subset of the population, the so-called compliers, who comply with the treatment assignment irrespective of what that assignment is.

NOTES
Instrumental variables analyses have a long tradition in econometrics. The first cases of such analyses include S. Wright (1921, 1923), P. Wright (1928), Tinbergen (1930), and Haavelmo (1943). See Stock and Tregbi (2003) for a fascinating historical perspective. In these early analyses, as in most of the subsequent econometric discussions, models were typically specified in terms of linear equations. There was a clear sense, however, of what these equations meant: by assumption they describe behavioral or causal relationships between variables, not correlations, and thus they do not necessarily (although they may do so accidentally) describe conditional expectations.
Early on these models were characterized by constant treatment effects and tight parametric and distributional assumptions. More recently researchers have tried to relax these models by allowing for heterogeneity in the treatment effects and flexible functional forms. Heckman (1990) showed that conditions required for identification of the population average treatment effect in these models were very strong: essentially they

540

Analysis of Randomized Experiments with One-Sided Noncompliance

required that the instruments changed the probability of receiving the treatment from zero to one so that for an identifiable subset of the population there was a randomized experiment.
For discussions on intention-to-treat effects, see Fisher, Dixon, Herson, Frankowski, Hearron, and Peace (1990) and Meier (1991).
Starting with the work by Imbens and Angrist (1994), Angrist, Imbens, and Rubin (1996), and Imbens and Rubin (1997ab), explicit connections were made between the Rubin Causal Model, or the potential outcomes perspective, and instrumental variables. Imbens and Angrist referred to the average effect for compliers as the Local Average Treatment Effect. Imbens and Rubin referred to it as the Complier Average Causal Effect. Sheiner and Rubin (1995) discuss the links to ITT effects. Other recent theoretical work in econometrics using the potential outcome framework in instrumental variables settings includes Abadie, Angrist, and Imbens (2002), Abadie (2002, 2003), and Chernozhukov and Hansen (2005). Rosenbaum (1996) and Imbens and Rosenbaum (2005) discuss randomization inference in instrumental variables settings. Athey and Stern (1998) discuss settings in which the exclusion restriction arises naturally from substantive assumptions in economics. Interesting applications in economics include Angrist and Krueger (1999) and Angrist and Lavy (1999).
Traditionally in statistics such structural equation methods, and specifically instrumental variables, were largely ignored. Noncompliance was viewed as a nuisance and largely ignored by focusing on intention-to-treat effects. More recently, this has changed. Independently of the econometric work, researchers analyzed issues in design of clinical trials with noncompliance. Zelen in a series of papers proposed designing experiments to avoid problems with subject consent by randomizing individuals to treatments before seeking consent of those assigned to the active treatment. Such designs were originally called Randomized Consent Designs and have sometimes been referred to as Zelen's Design (e.g., Zelen, 1979, 1990; Baker, 2000; Torgerson and Roland, 1998). Also related are Randomized Encouragement Designs where individuals are randomly assigned to receive encouragement or incentives to take part in an active treatment (Powers and Swinton, 1984; Holland, 1988). Bloom (1984) also studied the one-sided noncompliance case, allowing for heterogeneity in the causal effects. Robins (1986) analyzed models more closely related to the econometric tradition with noncompliance. Cuzick, Edwards, and Segnan (1997) independently derived the relation between the ratio of ITT effects and the average effect for compliers. Rubin (1998) studies Fisher-style p-value calculations in these settings.
The data used in this chapter were previously analyzed by Sommer and Zeger (1991) and Imbens and Rubin (1997b). They come from an experiment conducted in Indonesia in the early 1980s. For more detail on the specific issues in this evaluation, see the Sommer and Zeger paper and Sommer, Tarwotjo, Djunaedi, West, Loeden, Tilden, and Mele (1986).
Mealli and Rubin (2002ab) discuss extensions to missing data. Lui (2011) focuses on the case with binary outcome data. McNamee (2009) compares per protocol, intentionto-treat, and instrumental variables approaches.

Appendix

541

APPENDIX

We first approximate the super-population joint sampling distribution of the two ITT estimators by a normal distribution centered around the ITTY and ITTW:

ITTY  N ITTW

ITTY ITTW

,

V(ITTY) C(ITTY, ITTW) C(ITTY, ITTW) Var(ITTW)

.

We have already seen in Chapter 6 how to estimate V(ITTY) and V(ITTW); thus the only

remaining element is the covariance of ITTY and ITTW. To estimate this covariance,

first

note

that

the

covariance

between

Y

obs 1

and

W

obs 0

and

the

covariance

between

Y

obs 0

and

W

obs 1

are

both

zero,

because

these

averages

are

estimated

on

different

subsamples.

In

addition,

W

obs 0

=

0.

Hence

the

covariance

between

ITTY

=

Y

obs 1

-

Y

obs 0

and

ITTW

=

W

obs 1

-

W 0obs

is

equal

to

the

covariance

between

Y

obs 1

and

W 1obs .

C

Y

o1bs,

W

obs 1

is just

the covariance between two sample averages:

C(ITTY, ITTW) = C

Y

1obs,

W

obs 1

=

1

N1 · (N1 - 1) i:Zi=1

Yiobs

-

Y

obs 1

·

Wiobs - Wo1bs

.

Given this quantity, we can estimate the sampling variance of ^ iv by substituting our estimates for ITTY, ITTW, V(ITTY), V(ITTW), and C(ITTY, ITTW) into Equation (23.5).
In the Sommer-Zeger example,

C(ITTY, ITTW) = -0. 00000017,

corresponding to a correlation between ITTY and ITTW, equal to -0.0502.

CHAPTER 24
Instrumental Variables Analysis of Randomized Experiments with Two-Sided Noncompliance
24.1 INTRODUCTION
In this chapter we extend the instrumental variables analyses discussed in Chapter 23 to allow for two-sided noncompliance in a randomized experiment. In the discussion on one-sided noncompliance, only those units assigned to the active treatment could choose whether or not to comply with their assignment. Now we allow for the possibility that some of the units assigned to the control group do in fact receive the active treatment. In terms of the notation introduced in Chapter 23, we allow the value of the potential receipt of treatment given assignment to the control group, Wi(0), to be 1. This generalization implies that there are now possibly four different compliance types, defined by the pair of values of potential treatment responses, (Wi(0), Wi(1)), instead of two as in the onesided compliance case. As in Chapter 23, these compliance types play a key role in our analysis.
Critical again in our analysis are assumptions about the absence of effects of assignment on the primary outcome for subgroups for which the assignment has no effect on the receipt of treatment. These are assumptions that we referred to as exclusion restrictions in the previous chapter. A new type of assumption in this chapter is what we refer to as monotonicity. This assumption rules out the presence of units who always, in this experiment, that is, under both values of the assignment, do the opposite of their assignment; such units are characterized by Wi(z) = 1 - z for z = 0, 1, that is, Wi(0) = 1 and Wi(1) = 0. Units with such compliance behavior are sometimes referred to as defiers. The monotonicity assumption, which rules out the presence of these defiers, implies that Wi(z) is weakly monotone in z for all units and is also referred to as the no-defier assumption. In many applications this assumption is a pausible one, but in some cases it can be controversial. In the previous chapter it was satisfied by construction because no one assigned to the control group could receive the active treatment. In the two-sided noncompliance setting, monotonicity is a substantive assumption that need not always be satisfied. Given monotonicity and exclusion restrictions, we can identify causal effects of the receipt of treatment for the subpopulation of compliers, as we discuss in this chapter.
This chapter is organized as follows. In the next section, Section 24.2, we discuss the data used in this chapter. These data are from a seminal study by Angrist (1990) that spawned a resurgence of interest in instrumental variables analyses in economics.
542

24.2 The Angrist Draft Lottery Data

543

Building on work by Hearst, Newman, and Hulley (1986), Angrist (1990) is interested in estimating the causal effect of serving in the military during the Vietnam war earnings. To address possible concerns with unobserved differences between veterans and nonveterans, he used the random assignment to draft priority status as an instrument. In Section 24.3 we discuss compliance status in the two-sided noncompliance setting. In Section 24.4 we look at the intention-to-treat effects. Next, in Section 24.5 we study the critical assumptions for instrumental variables analyses. We discuss the arguments for and against validity of the key assumptions in the Angrist application and illustrate what can be learned using the instrumental variables perspective. In Section 24.6 we take a detour and look at more traditional econometric analyses and see how they relate to our approach. Section 24.7 concludes.

24.2 THE ANGRIST DRAFT LOTTERY DATA
Angrist (1990) is concerned with the possibility that veterans and non-veterans are systematically different in unobserved ways, even after adjusting for differences in observed covariates, and that these unobserved differences may correspond to systematic differences in their earnings. For example, to serve in the military, drafted individuals need to pass medical tests and to have achieved minimum education levels. These variables are known to be associated with differences in earnings, and might imply that veterans would have had higher earnings than non-veterans, had they not served in the military. On the other hand, individuals with attractive civilian labor market prospects may have been less likely to volunteer for military service, which could imply that the civilian earnings of veterans, had they not served in the military, would have been lower than those of nonveterans. As a result of these unobserved differences, simple comparisons of earnings between veterans and non-veterans are arguably not credible estimates of causal effects of serving in the military. Adjusting for covariates that are associated with both civilian labor market prospects, as well as the decision to enroll in the military, may improve such comparisons but ultimately may not be sufficient to remove all biases. Thus, a strategy based on unconfoundedness of military service is unlikely to be satisfactory in the absence of detailed background information beyond what is available.
Angrist exploits the implementation of the draft during the Vietnam War. During this conflict all men of a certain age were required to register for the draft. However, the military did not need all men in these cohorts, and for birth cohorts 1950­1953 established a policy to determine draft priority that would make all men within a birth year cohort a priori equally likely to be drafted. Ultimately draft priority was assigned based on a random ordering of birth dates within birth year cohorts. Thus, for birth year 1950, a random ordering of the 365 days was constructed. Eventually, although this was not known in advance, all men born in 1950 with birth dates corresponding to draft lottery numbers less than or equal to 195 were drafted, and those with birth dates corresponding to draft lottery numbers larger than 195 were not. For the birth cohorts from 1951 and 1952, these thresholds were 125, and 95, respectively. (No one born in 1953 was drafted although all men in this birth year were required to register for the draft and draft priority numbers were assigned.)

544

Analysis of Randomized Experiments with Two-Sided Noncompliance

Table 24.1. Summary Statistics for the Angrist Draft Lottery Data

Non-Veterans (Nc = 6,675)

Veterans (Nt = 2,030)

Min Max Mean (S.D.) Min Max Mean (S.D.)

Draft eligible

0 1 0.24 (0.43) 0 1 0.40 (0.49)

Yearly earnings 0 62.8 11.8 (11.5) 0 50.7 11.7 (11.8)

(in $1,000's)

Earnings positive 0 1 0.88 (0.32) 0 1 0.91 (0.29)

Year of birth

50 52 51.1 (0.8) 50 52 50.9 (0.8)

Let Zi be a binary indicator for being draft eligible, meaning that the individual had a draft lottery number less than or equal to the threshold for their birth year. Angrist uses
this binary indicator as an instrument for serving in the military (described subsequently as "veteran status"). Observed veteran status for individual i is denoted by Wiobs. We focus on civilian earnings in thousands of dollars in 1978 as the outcome of interest, with the realized and observed value for the ith person in our sample denoted by Yiobs.
Table 24.1 presents some summary statistics for the three "birth-year" cohorts (1950­
1952) used in our analyses. We see that veterans have approximately the same average
earnings as non-veterans (11.8 for non-veterans, and 11.7 for veterans, in thousands
of dollars per year) but are slightly more likely to be employed (91% versus 88%).
However, the concern is that these simple comparisons of veterans and non-veterans, yielding a point estimate of -0.2 (s. e. 0.2), for annual earnings, and 0.03 (s. e. 0.01) for employment, are not credible estimates of causal effects of veteran status because
of the anticipated systematic observable and unobservable differences between veterans
and non-veterans just discussed.

24.3 COMPLIANCE STATUS
As in Chapter 23, we postulate the existence of a pair of compliance potential responses to assignment, Wi(z), for z = 0, 1. The first, Wi(0), describes for unit i the treatment response to being assigned to the control group. If unit i would receive the treatment (serving in the military in the draft-lottery application) when assigned to the control group, then Wi(0) = 1, otherwise Wi(0) = 0, and similarly for Wi(1). Compliance status refers to a unit's response to the assignment, for both values of the assignment whether that status is observed or unobserved. Formally, it is a function of the pair of potential responses (Wi(0), Wi(1)). Because both Wi(0) and Wi(1) are binary indicators, there are four possible values for the pair of potential responses to treatment assignment. Let us consider the four groups in turn. We continue to refer to those who always comply with their assignment in the context of this study, units with Wi(z) = z for z = 0, 1, and thus (Wi(0) = 0, Wi(1) = 1), as compliers. All others units are noncompliers, but they can be of different noncomplier types.
We distinguish three distinct types of noncompliers. Those who never (in the context of these drafts) take the treatment, irrespective of their assignment

24.3 Compliance Status

545

(Wi(0) = 0, Wi(1) = 0), will be referred to as nevertakers. Those who would, in this study, always take the treatment, irrespective of their assignment (Wi(0) = 1, Wi(1) = 1), will be referred to as alwaystakers. Finally, those who, in the context of this study, irre-
spective of the value of their assignment, would do the opposite of their assignment, that is, units with (Wi(0) = 1, Wi(1) = 0), will be referred to as defiers. We denote the compliance type by Gi, taking values in {nt, at, co, df}:



Gi

=

g(Wi(0),

Wi(1))

=

ncot df

at

if Wi(0) = 0, Wi(1) = 0, if Wi(0) = 0, Wi(1) = 1, if Wi(0) = 1, Wi(1) = 0, if Wi(0) = 1, Wi(1) = 1.

Here the function g( · ) emphasizes the fact that compliance status is a deterministic function of the two potential outcomes, Wi(0) and Wi(1). Let g = pr (Gi = g), for g  {nt, at, co, df} denote the shares of the four compliance types in the super-population.
The compliance type of a unit is not directly observable. We observe the realized
treatment status

Wiobs = Wi(Zi) =

Wi(0) Wi(1)

if Zi = 0, if Zi = 1,

but not the value of Wimis = Wi(1 - Zi). In this regard, the two-sided noncompliance case analyzed in this chapter is more complicated than the one-sided case. In the one-
sided noncompliance case, we could infer the compliance type for at least some units; specifically, we could infer for all units with Zi = 1 what compliance type they were. For units with (Zi = 1, Wiobs = 0) we could infer that they must be noncompliers with (Wi(0), Wi(1)) = (0, 0), and for units with (Zi = 1, Wiobs = 1) we could infer that they must be compliers with (Wi(0), Wi(1)) = (0, 1). However, for units with Zi = 0, we could not infer what type they were. Here we cannot tell the compliance status of any particular unit without additional assumptions. For unit i we observe Zi and Wiobs = Wi(Zi), but we do not know what that unit would have done had it received the alternative assignment, 1 - Zi. Because noncompliance is two-sided, for all values of Zi, the unobserved Wimis = Wi(1 - Zi) can take either the value 0 or 1.
As a result, there will always be two compliance types that are consistent with the
observed behavior of a specific unit. For example, if we observe unit i assigned to the
control group and taking the treatment, we can infer that unit i is not a complier or
nevertaker, but we cannot infer whether unit i is a defier or an alwaystaker. For a unit
assigned to the control group and not taking the treatment, we can infer that such a unit
is not an alwaystaker or a defier, but the observed behavior is consistent with that unit
being a complier or a nevertaker. If unit i is assigned to the treatment group and takes the
treatment, we can only infer that this unit is an alwaystaker or a complier. Finally if unit
i is assigned to the treatment group and does not receive the treatment, we can only infer
that unit i is a nevertaker or a defier. Tables 24.2 and 24.3 summarize this discussion by
describing the compliance status and the extent to which we can learn about compliance
status from the data on assignment and receipt of treatment.

546

Analysis of Randomized Experiments with Two-Sided Noncompliance

Table 24.2. Compliance Status in the Case with Two-Sided Noncompliance, for the Angrist Draft Lottery Data

Wi(1)

0

1

0

nt

co

Wi(0)

1

df

at

Table 24.3. Possible Compliance Status by Observed Assignment and Observed Receipt of Treatment in the Case with Two-Sided Noncompliance, for the Angrist Draft Lottery Data

Zi

0

1

0

nt/co

nt/df

Wiobs

1

at/df

at/co

We use the compliance status as a latent pre-treatment variable or latent characteristic. It is a pre-treatment variable or characteristic because it is not affected by either the assigned treatment or the received treatment. It is latent because it is not fully observed.

24.4 INTENTION-TO-TREAT EFFECTS
Let us briefly look at the Intention-To-Treat (ITT) effects in this setting. This analysis is largely unchanged from that in the previous chapter on one-sided noncompliance.
First consider the ITT effect on the treatment received. The unit-level effect of treatment assigned on treatment received is equal to 1 for compliers, 0 for both nevertakers and alwaystakers, and -1 for defiers, so that the super-population average intention-to-treat effect on the receipt of treatment is
ITTW = Esp [Wi(1) - Wi(0)] = co - df,
the difference in population fractions of compliers and defiers. Here the expectations are taken over the distribution induced by random sampling from the super-population. The ITT effect on the primary outcome is, as in the previous chapter,
ITTY = Esp [Yi(1, Wi(1)) - Yi(0, Wi(0))] .
As before, we assume that assignment is super-population unconfounded and completely randomized.

24.4 Intention-to-Treat Effects

547

Assumption 24.1 (Super-Population Random Assignment)

Zi  Wi(0), Wi(1), Yi(0, 0), Yi(0, 1), Yi(1, 0), Yi(1, 1) .

We can relax this assumption by requiring it to hold only within homogeneous subpopulations defined by fully observed pre-treatment variables, thus combining an analysis based on unconfoundedness with an instrumental variables analysis. However, in the draft lottery example, the physical randomization of the draft lottery ensures that Assumption 24.1 holds by design. In other applications, this assumption may be substantive, rather than satisfied by design, and as a result more controversial. This assumption validates two intention-to-treat analyses, one with the receipt of treatment as the outcome, and one with the primary outcome, for example, earnings in the Angrist example.
Given a random sample and random assignment, we can estimate the average causal effect of assignment on Wi in the super-population as

ITTW

=

W

obs 1

-

W 0obs ,

with the (Neyman) sampling variance estimated as

V(ITTW)

=

s2W,0 N0

+

sW2 ,1 , N1

Here, for z = 0, 1, Nz =

N i=1

1Zi

=z

,

W

obs z

=

i:Zi=z Wiobs/Nz, and SW2 ,z =

i:Wiobs =z

(Wiobs - Wozbs)2/(Nz - 1) = Wz(1 - Wz)/(Nz - 1).

Let us illustrate these ideas using the Angrist draft lottery data. Of the N = 8,705 men

in our sample, N0 = 6,293 had a draft lottery number exceeding the threshold (and so

were not draft eligible), and N1 = 2,412 had a draft lottery number less than or equal to

the threshold for their birth year. Thus we find:

ITTW

=

W

obs 1

-

W o0bs

=

0.

3387

-

0.

1928

=

0.

1460,

with the sampling variance for the super-population average treatment effect estimated as

V(ITTW) =

s2W,0 N0

+

s2W,1 N1

= 0. 01082,

leading to a large-sample 95% confidence interval for ITTW equal to

CI0.95(ITTW) = (0. 1247, 0. 1672).

Thus, unsurprisingly, we find that being draft eligible (having a low draft lottery number) leads to a substantially, and at conventional levels statistically significant, higher probability of subsequently serving in the military.
Next, let us consider estimation of the super-population ITT effect on the primary outcome. As in the case for the ITT effect on the treatment received, this analysis is

548

Analysis of Randomized Experiments with Two-Sided Noncompliance

identical to that in Chapter 23. We estimate ITTY as the difference in average outcomes by assignment status,

ITTY

=

Y

obs 1

-

Y o0bs .

The sampling variance for this estimator of the ITT effect is, using Neyman's approach, estimated as

V(ITTY)

=

sY2 ,1 N1

+

sY2 ,0 . N0

Let us return to the Angrist draft lottery data. Here we find

ITTY

=

Y

obs 1

-

Y

obs 0

=

11.634

-

11.847

=

-0.2129,

a drop in annual earnings of $212.90, and,

V(ITTY)

=

s2Y ,1 N1

+

s2Y ,0 N0

=

0.19802,

and thus we have the 95% large-sample confidence interval

CI0.95(ITTeYarn) = (-0.6010, 0.1752).

We may also wish to look at the effect of draft eligibility on employment (measured as having positive annual earnings). Here we find a point estimate of -0.005, with a 95% large-sample confidence interval equal to

CI0.95(ITTYemp) = (-0.018, 0.011).

In a traditional ITT analysis, we are essentially done. One might not even estimate the ITT effect on the treatment received, because this estimate has little relevance for the causal effects of interest, those on the outcome. However, this ITT analysis does not really answer the question of interest: What is the causal effect on earnings of actually serving in the military? Instead, it informs us about the effect of changing the draft priority on earnings. If, in a future conflict, there were again to be a military draft, it would likely be implemented in a very different way. The effect of the lottery number on earnings is therefore of limited interest. Of considerably more interest is the effect of actually serving on future earnings, as this may be of use in predicting the effect, or cost, of military service in subsequent drafts.

24.5 INSTRUMENTAL VARIABLES
In this section we discuss the main results of this chapter, which extend the analyses from the previous chapter to allow for two-sided noncompliance. We consider the assumptions underlying instrumental variables and use those to draw additional inferences regarding the relation between the outcome of interest and the treatment of primary interest beyond

24.5 Instrumental Variables

549

what can be learned from the ITT analyses. Much of this analysis is about extending the ITT analyses by obtaining separate ITT effects by compliance status:
ITTW,g = ESP [Yi(1, Wi(1)) - Yi(0, Wi(0))|Gi = g] ,
for g  {nt, at, co, df}. The challenge is that this decomposition is not immediately feasible because compliance status is only partly observed. However, if we were to observe compliance status directly, one could simply estimate the ITT effects separately by compliance status. In that case, the ITT effects for nevertakers and alwaystakers would obviously not be informative about the causal effect of the receipt of treatment, because there is no variation in the receipt of treatment for these two subgroups of units. In contrast, for defiers and compliers there is variation in the receipt of treatment. In fact, for compliers and defiers, receipt of treatment and assignment to treatment are perfectly (positively for compliers and negatively for defiers) correlated, and the strategy will be to attribute the causal effect of the assignment to treatment to the effect of the receipt of treatment, Wiobs.

24.5.1 Exclusion Restrictions The first set of assumptions we consider are exclusion restrictions. As in the previous chapter, we consider multiple versions of these restrictions. All versions capture the notion that there is no effect of the assignment on the outcome, in the absence of an effect of the assignment of treatment on the treatment received, the treatment of primary interest. The first set of exclusion restrictions rules out dependence of the potential outcomes on the assignment: Assumption 24.2 (Exclusion Restriction for Nevertakers) For all units i with Gi = nt,
Yi(0, 1) = Yi(1, 1).
This assumption requires that changing z for nevertakers does not change the value of the realized outcome.
We can make a similar assumption for alwaystakers:
Assumption 24.3 (Exclusion Restriction for Alwaystakers) For all units i with Gi = at,
Yi(0, 1) = Yi(1, 1).
We also state exclusion restrictions for compliers and defiers: Assumption 24.4 (Exclusion Restriction for Compliers) For units with Gi = co,
Yi(0, w) = Yi(1, w), for both levels of the treatment w. Assumption 24.5 (Exclusion Restriction for Defiers) For units with Gi = df,
Yi(0, w) = Yi(1, w),
for both levels of the treatment w.

550

Analysis of Randomized Experiments with Two-Sided Noncompliance

A key feature of these exclusion restrictions is that they are, at their core, substantive assumptions, requiring judgment regarding subject-matter knowledge. It is rarely satisfied by design outside of settings with double-blinding. In settings where units are individuals who are aware of their assignment and treatment, one needs to consider the incentives and restrictions faced by units assigned and not assigned to receive the treatment, and argue on the basis of such considerations whether each of the exclusion restrictions is plausible. In many cases they need not be satisfied for all groups, but in some classes of applications, they may be useful approximations to the underlying process. At some level this is not so different from the type of assumptions we have considered before. In particular, the stable-unit-treatment-value assumption required that there was no interference between units. This required substantive judgments about the possibility of interference: applying fertilizer in area A may well affect crops in area B if there is some possibility of leaching, but this is less plausible if the areas are sufficiently separated. The differences between the exclusion restrictions and SUTVA is a matter of degree: often the subject-matter knowledge required to assess the plausibility of exclusion restrictions is more subtle than that required to evaluate SUTVA, especially for some subgroups such as compliers.
Let us consider the exclusion restriction for alwaystakers and nevertakers in the draft lottery application. Consider first the subpopulation of nevertakers. These are men who would not serve in the military, irrespective of whether they had a high or a low lottery number. One can think of different types of men in this subpopulation of nevertakers. Some may have had medical exemptions for the draft. For such men it would appear reasonable that the lottery number had no effect on their subsequent lives. Especially if these men already knew, prior to the allocation of their draft lottery number, that they would not be required to serve in the military, there is no reason to expect that any decisions these men made would be affected by the lottery number they were assigned. On the other hand, there may also be individuals whose educational or professional career choices allowed them exemptions from military service. For some of these individuals, these choices would have been made irrespective of the value of the draft lottery number assigned to them. Again, for such individuals the exclusion restriction appears plausible. For other individuals, however, it may be the case that a low lottery number allowed them to change their plans so that they would not have to serve in the military. For example, men intent on avoiding military service may have decided to enter graduate school or to move to Canada to avoid the draft. However, these men would need to do so only if they were assigned a low lottery number, because with a high lottery number they would not get drafted anyway. For such men, even though the lottery number did not affect their veteran status, it could have affected their outcomes, and thus the exclusion restriction could be violated. This example illustrates that in many cases there are reasons to doubt the exclusion restriction, and an assessment as to whether it provides a sufficiently accurate description of the underlying processes is important for the credibility of any subsequent analyses based on the assumption.
For compliers, the exclusion restriction is again one of attribution. It implies that the causal effect of assignment to the treatment for these units can be attributed to the causal effect of the receipt of treatment. For defiers, the substantive content of the exclusion restriction is the same as for the compliers. However, in practice it is less

24.5 Instrumental Variables

551

important because we often are willing to make the monotonicity (no-defier) assumption that implies that the proportion of defiers in the population is zero.
We can weaken the exclusion restriction for alwaystakers and nevertakers by requiring the equality to hold in distribution in the super-population:
Assumption 24.6 (Stochastic Exclusion Restriction for Nevertakers)

Zi  Yi(Zi, Wi(Zi)) Gi = nt.

Assumption 24.7 (Stochastic Exclusion Restriction for Alwaystakers)

Zi  Yi(Zi, Wi(Zi)) Gi = at.

These versions of the assumption require that there is no difference between the distribution of outcomes for nevertakers or alwaystakers with given assignment to control or treatment group. It weakens the non-stochastic versions of the assumption; rather than requiring the effect to be identically zero for all units, they only require the difference to be zero in a distributional sense, similar to the difference between the Fisher and Neyman null hypotheses of no effect of the treatment in a randomized experiment. An important advantage of the stochastic versions of the exclusion restrictions are that covariates are easily incorporated: in that case we need the independence in Assumptions 24.6 and 24.7 to hold only conditional on covariates.

24.5.2 The Monotonicity Assumption
The next assumption is special to the two-sided noncompliance setting. We rule out the presence of defiers or, in other words, restrict the sign of the effect of the assignment on the treatment:
Assumption 24.8 (Monotonicity/No Defiers) There are no defiers: Wi(1)  Wi(0).
In the one-sided noncompliance case analyzed in Chapter 23, this assumption was automatically satisfied because Wi(0) = 0 for all units, ruling out the presence of both defiers and alwaystakers. In that case monotonicity was essentially verifiable. Here it is a substantive assumption, that is not directly testable (beyond the implication that ITTW is non-negative: if we find that our estimate of ITTW is negative and statistically significant at conventional levels, we may want to reconsider the entire model!). Given monotonicity, Table 24.3 simplifies to Table 24.4. Now we can infer, at least for units with Wiobs = Zi, which compliance type they are: for units with Zi = 0, Wiobs = 1, we observe Wi(0) = 1, and we can, because of the monotonicity assumption, infer the value of Wi(1) = 1, so such units are alwaystakers. Similarly, for units with Zi = 1, Wiobs = 0 we observe Wi(1) = 0, and thus can, because of monotonicity, infer the value of Wi(0) = 0, and therefore such units are nevertakers. For units whose realized treatment is identical to the assigned treatment, we cannot infer what type they are: if Wiobs = Zi = 0, unit i could be a nevertaker or complier, and observing Wiobs = Zi = 1 is consistent with unit i being an alwaystaker or complier.

552

Analysis of Randomized Experiments with Two-Sided Noncompliance

Table 24.4. Compliance Status by Observed Assignment and Observed Receipt of Treatment with the Monotonicity Assumption in the Case with Two-Sided Noncompliance, for the Angrist Draft Lottery Data

Zi

0

1

0

nt/co

nt

Wiobs

1

at

at/co

In the draft lottery example, monotonicity appears to be a reasonable assumption. Having a low draft lottery number imposes restrictions on individuals' behaviors: it requires individuals to prepare, if fit for military service, to serve in the military, where having a high lottery number would not require them to do so. The monotonicity assumption asserts that, in response to these restrictions, individuals are more likely to serve in the military, and that no one responds to this restriction by serving only if they are not required to do so. It is of course possible that there are some individuals who would be willing to volunteer if they are not drafted but would resist the draft if assigned a low lottery number. It seems likely that, in actual fact, this is a small fraction of the population, and we will ignore this possibility here, and so accept monotonicity. In Section 24.5.5 we return to a discussion of the implications of violations of this assumption. Similarly, in a randomized experiment, it is often plausible that there are no individuals who would take the treatment if assigned to the control group and not take the treatment if assigned to the treatment. It seems reasonable to view the assignment to the treatment as increasing the incentives for the individual to take the treatment. These incentives need not be strong enough to induce everybody to take the treatment, but in many situations (e.g., drug trials) these incentives would rarely be perverse in the sense that individuals would do the opposite of their assignment. In many applications the instrument has this interpretation of increasing the incentives to participate in or to be exposed to a treatment, and in such cases the monotonicity assumption is often plausible, but this conclusion is not automatic.
Let us return to the ITT effect on the treatment received and investigate the implications of monotonicity for this ITT effect. The effect of the assignment on the receipt of treatment by compliance status, in the super-population, can be written as
ITTW = Esp [Wi(1) - Wi(0)]

=

Esp [ Wi(1) - Wi(0)| Gi = g] · Prsp (Gi = g)

g{co,nt,at,df}

= Esp [ Wi(1) - Wi(0)| Gi = co] · Prsp (Gi = co)

+ Esp [ Wi(1) - Wi(0)| Gi = nt] · Prsp (Gi = nt)

+ Esp [ Wi(1) - Wi(0)| Gi = df] · Prsp (Gi = df)

24.5 Instrumental Variables

553

+ Esp [ Wi(1) - Wi(0)| Gi = at] · Prsp (Gi = at)
= Pr(Gi = co) - Pr(Gi = df) = co - df,
the difference in proportions of compliers and defiers. By the monotonicity or nodefiers assumption, this is equal to the proportion of compliers co. Thus, under two-sided noncompliance, as long as there are no defiers, the ITT effect on the treatment received still equals the proportion of compliers, just as we found in the one-sided noncompliance case.

24.5.3 Local Average Treatment Effects under Two-Sided Noncompliance
Now consider the intention-to-treat effect, the average effect of assignment on the outcome. Again we decompose this super-population ITT effect into four local effects by the four compliance types:

ITTY = Esp[Y(1, D(1)) - Y(0, D(0))]

=

Esp [ Yi(1, Wi(1)) - Yi(0, Wi(0))| Gi = g] · Prsp(Gi = g)

g{co,nt,at,df}

= Esp [ Yi(1, Wi(1)) - Yi(0, Wi(0))| Gi = co] · Prsp(Gi = co)

+ Esp [ Yi(1, Wi(1)) - Yi(0, Wi(0))| Gi = nt] · Prsp(Gi = nt)

+ Esp [ Yi(1, Wi(1)) - Yi(0, Wi(0))| Gi = at] · Prsp(Gi = at)

+ Esp [ Yi(1, Wi(1)) - Yi(0, Wi(0))| Gi = df] · Prsp(Gi = df) .

Under either the deterministic (Assumptions 24.2 and 24.3) or the stochastic (Assumptions 24.6 and 24.7) version of the exclusion restrictions, the super-population average ITT effect for nevertakers and alwaystaker is zero, and hence the ITT effect on the primary outcome is equal to

ITTY = Esp [ Yi(1, 1) - Yi(0, 0)| Gi = co] · co

- Esp [ Yi(0, 1) - Yi(1, 0)| Gi = df] · df.
Maintaining the monotonicity assumption implies the proportion of defiers is zero, and so this expression further simplifies to

ITTY = Esp [ Yi(1, 1) - Yi(0, 0)| Gi = co] · co,

or, dropping the Z argument in the potential outcomes because under the exclusion restriction it is redundant,

ITTY = Esp [ Yi(1) - Yi(0)| Gi = co] · co.

In other words, under the exclusion restrictions and the monotonicity assumption, the ITT effect on the primary outcome can be attributed entirely to the compliers. The noncompliers either have a zero effect (this holds for nevertakers and alwaystakers by the

554

Analysis of Randomized Experiments with Two-Sided Noncompliance

exclusion restrictions), or they are absent from the population (this holds for defiers by the monotonicity assumption).
Now consider the ratio of average effects of assignment:

Theorem 24.1 (Local Average Treatment Effect) Suppose that Assumptions 24.1­24.3 (or 24.1, 24.6, 24.7) and 24.8 hold. Then

late

=

ITTY ITTW

= ESP [ Yi(1) - Yi(0)| Gi

=

co] .

This local average treatment effect is also referred to as the complier average causal effect.
Note that by assuming monotonicity, we extend the main result from the one-sided noncompliance case.
Let us return to the draft lottery application. Previously we estimated the two ITT effects:

ITTW = 0.1460 (s. e. 0.0108), and ITTY = -0.21 (s. e. 0.20).
The analysis in this section implies that, under the stated assumptions, the ratio of the two estimated intention-to-treat effects can be interpreted as a simple method-of-moments estimator of the average effect of serving in the military for compliers:

^ iv = ITTY = - 0.21 = -1.46 (s. e. 1.36),

ITTW

0.1460

with the estimated standard error based on the same type of calculation as in the previous chapter and the appendix thereof.

24.5.4 Inspecting Outcome Distributions for Compliers and Noncompliers
We cannot estimate the effect of the treatment for the subpopulations of alwaystakers or nevertakers, because each group appears in only one of the two treatment arms. Nevertheless, we can compare their potential outcome distributions given the treatment they are exposed to and compare them to the potential outcome distributions given the same treatment for compliers. The latter relies on the insight that the data are not just informative about the average of Yi(1) - Yi(0) for compliers, they are also informative about the entire potential outcome distributions for compliers. This result follows from the mixture structure of the distribution of observed data. Comparing, say, the distribution of Yi(0) for nevertakers and compliers is useful to assess the plausibility of generalizing the local average treatment effect for compliers to other subpopulations, something about which these data are not directly informative.
Consider the distribution of observed outcomes for units assigned to the control group, who receive the control treatment. By the definition of the compliance types, this subpopulation consists of compliers and nevertakers, with shares proportional to their population shares. Thus, the distribution of the observed outcome in this subpopulation

24.5 Instrumental Variables

555

has a mixture structure

f (Yiobs|Wiobs

=

0, Zi

=

0)

=

nt

nt + co

·f

(Yi(0)|Gi

=

nt)+

co nt + co

·f

(Yi

(0)|Gi

=

co).

Note that these distributions are induced by the random sampling from the superpopulation. For this result we use the fact that if Gi = nt, then Yiobs = Yi(0), and if Gi = co and Zi = 0, then Yiobs = Yi(0). Moreover, units with Wiobs = 0 and Zi = 1 must be nevertakers, and thus the distribution of observed outcomes in this subpopulation
estimates

f (Yiobs|Wiobs = 0, Zi = 1) = f (Yi(0)|Gi = nt, Zi = 1),

where, by random assignment of the instrument Zi we can drop the conditioning on Zi, and this distribution is therefore equal to f (Yi(0)|Gi = nt). We can disentangle these mixtures to obtain the distribution of Yi(0) for compliers:

f (Yi(0)|Gi

=

co)

=

nt + co co

·

f (Yiobs|Wiobs

=

0, Zi

=

0)

-

nt co

·

f (Yiobs|Wiobs

=

0, Zi

=

1).

By a similar argument we can obtain the distribution of Yi(1) for compliers:

f (Yi(1)|Gi

=

co)

=

a + c c

·

f (Yiobs|Wiobs

=

1, Zi

=

1)

-

a c

· f (Yiobs|Wiobs = 1, Zi = 0).

Thus, the data are indirectly informative about four distributions, f (Yi(0)|Gi = co), f (Yi(1)|Gi = co), f (Yi(0)|Gi = nt), and f (Yi(1)|Gi = at).
Estimating the average annual earnings for compliers with and without military
service in this manner, using method-of-moments estimators, leads to

E[Yi(0)|Gi = co] = 13.22,

E[Yi(1)|Gi = co] = 11.77.

For nevertakers and alwaystakers we estimate

E[Yi(0)|Gi = nt] = 11.60,

E[Yi(1)|Gi = at] = 11.65.

Thus, earnings for compliers who do not serve appear to be substantially higher than earnings for nevertakers, but compliers who serve in the military appear to have earnings comparable to those of alwaystakers.

24.5.5 Relaxing the Monotonicity Condition Suppose we do not assume monotonicity. In that case the ITT effect of assignment on treatment received is the difference in population proportions of compliers and defiers:
ITTW = co - df.

556

Analysis of Randomized Experiments with Two-Sided Noncompliance

The ITT effect on the primary outcome is

ITTY = Esp [ Yi(1) - Yi(0)| Gi = co] · co - Esp [ Yi(1) - Yi(0)| Gi = df] · df.

Thus, the ratio of average effects of the assignment on outcome and treatment is equal to

Esp[Yi(1)

-

Yi(0)|Gi

=

co]

·

co co - df

-

Esp[Yi(1) -

Yi(0)|Gi

=

df]

·

df . co - df

Without the monotonicity assumption, the ratio is equal to a weighted average of the ITT effects for compliers and defiers. Although the weights add up to one, the weight on the average effect of the treatment for defiers is always negative, which implies that the weighted average can be outside the range spanned by the average effects for compliers and defiers. As a result, modest violations of the monotonicity assumption are therefore not critical to the interpretation of instrumental variables estimates, but in settings with substantial heterogeneity of causal effects, substantial violations of the monotonicity assumption may lead to instrumental variables estimates that are not representative of causal effects of the treatment of primary interest.

24.6 TRADITIONAL ECONOMETRIC METHODS FOR INSTRUMENTAL VARIABLES

As in Chapter 23, we will compare the methods developed so far to the traditional equation-based approach originally developed in the econometrics literature. Again, the goal is primarily to link the two approaches and illustrate the benefits of the framework presented in this chapter. It will be seen that the two approaches lead to the same estimands and estimators in this simple case without covariates, although they get there in different ways, with the traditional approach appearing to rely on restrictive and unnecessary linearity assumptions. We first go through the mechanics of the traditional econometrics approach and then discuss the traditional formulation of the critical assumptions.
Traditional econometric analyses start with a linear relation between the outcome and the primary treatment. Here we derive that relation in terms of population parameters. Let late = ESP[Yi(1) - Yi(0)|Gi = co] be the average treatment effect for compliers. Also define

 = nt · Esp[Yi(0)|Gi = nt] + co · Esp[Yi(0)|Gi = co] + at · Esp[Yi(1)|Gi = at] - at ·  .

Finally, define the residual

i = Yi(0) -  + Wiobs · (Yi(1) - Yi(0) - late).

Now we can write the observed outcome as a function of the residual and the treatment received:

Yiobs =  + Wiobs · late + i.

(24.1)

24.6 Traditional Econometric Methods for Instrumental Variables

557

This is the key equation, and in fact the starting point, of traditional econometric analy-
ses. Equation (24.1) is viewed as describing a causal or structural relationship between the treatment Wiobs and the outcome Yiobs. Typically late is interpreted as the (constant across units) causal effect of the receipt of treatment on the outcome. However, this rela-
tionship cannot be estimated by standard regression methods. The problem is that the residual i is potentially correlated with the regressor Wiobs. Units with large unobserved values of the residual may be more or less likely to receive the treatment. Therefore, least
squares methods will not work. The critical assumption in the traditional econometric
approach is that

Esp[i|Zi = z] does not depend on z.
We will first show that, using the potential outcomes framework, by construction, the residual is uncorrelated with the instrument. Consider the expectation of the residual given Zi = z, first given Zi = 0. We decompose it out by compliance status, taking into account the absence of defiers:
Esp[i|Zi = 0] = Esp Yiobs -  - Wiobs ·  iv Zi = z = nt · Esp[Yi(0) -  + Wiobs · (Yi(1) - Yi(0) -  iv)|Gi = nt, Zi = 0] + at · Esp[Yi(0) -  + Wiobs · (Yi(1) - Yi(0) -  iv)|Gi = at, Zi = 0] + co · Esp[Yi(0) -  + Wiobs · (Yi(1) - Yi(0) -  iv)|Gi = co, Zi = 0] = nt · (Esp[Yi(0)|Gi = nt] - ) + at · (Esp[Yi(1)|Gi = at] - ) - at ·  iv + co · Esp([Yi(0)|Gi = co] - ) = nt · Esp[Yi(0)|Gi = nt] + at · Esp[Yi(1)|Gi = at] + co · Esp[Yi(0)|Gi = co] - at ·  iv -  = 0.

Similarly,
Esp[i|Zi = 1] = nt · Esp[Yi(0) -  + Wiobs · (Yi(1) - Yi(0) -  )|Gi = nt, Zi = 1] + at · Esp[Yi(0) -  + Wiobs · (Yi(1) - Yi(0) -  )|Gi = at, Zi = 1] + co · Esp[Yi(0) -  + Wiobs · (Yi(1) - Yi(0) - late)|Gi = co, Zi = 1]
= nt · (Esp[Yi(0)|Gi = nt] - ) + at · (Esp[Yi(1)|Gi = at] - ) - at ·  + co · Esp[Yi(0)|Gi = co] - ) + co · Esp[Yi(1) - Yi(0) -  |Gi = co] = 0.
Thus, Esp[i|Zi = z] = 0 for z = 0, 1, and i is uncorrelated with Zi. Exploiting the zero correlation between Zi and i, we can use the same approach as in
the one-sided noncompliance case. Consider the conditional expectation of the outcome of interest given the instrument:
Esp[Yiobs|Zi] =  + late · ESP[Wiobs|Zi].

558

Analysis of Randomized Experiments with Two-Sided Noncompliance

Hence we can write a new regression function with a different explanatory variable but the same coefficients as (24.1):

Yiobs =  + Esp[Wiobs|Zi] ·  iv + i,

(24.2)

where the new residual is a composite of two residuals:

i = i + (Wiobs - Esp[Wiobs|Zi]) ·  iv.
Because (Wiobs - Esp[Wiobs|Zi]) is by definition uncorrelated with Zi, it follows that the composite disturbance term i = i + (Wiobs - Esp[Wiobs|Zi]) ·  is uncorrelated with Zi. Moreoever, this composite residual is also uncorrelated with functions of Zi, such as Esp[Wiobs|Zi]. If we observed Esp[Wiobs|Zi], we could therefore estimate the regression function (24.2) by least squares. We do not observe Esp[Wiobs|Zi], so this is not feasible, but we can follow the same two-stage least squares (TSLS) procedure as in the previous chapter. First regress, using ordinary least squares, the indicator for receipt of treatment
Wiobs on the instrument Zi to get an estimate for Esp[Wiobs|Zi]. Let Esp[Wiobs|Zi] be the predicted value from this estimated regression function. Second, regress the outcome of interest using ordinary least squares on the predicted value of the treatment indicator:

Yiobs =  + Esp[Wiobs|Zi] ·  iv + i.
The coefficient on Esp[Wiobs|Zi] is the TSLS estimator for the average treatment effect for compliers. In this case with no additional covariates, this TSLS estimate is numerically identical to the ratio of ITT effects. This is easy to see here:

Esp[Wiobs|Zi] = W1 · Zi + W0 · (1 - Zi) = W0 + Zi · W1 - W0 .
Hence the regression coefficient on Esp[Wiobs|Zi] is simply the regression coefficient in a regression on Zi (which itself is the ITT effect on Yi), divided by W1 - W0 .
Now let us return to the formulations of the critical assumptions in the traditional econometric approach. The starting point is equation (24.1). The key assumption in many econometric analyses is that
Esp [i|Zi = z] = 0,
for all z. This assumption captures implicitly the exclusion restriction by excluding Zi from the structural function (24.1). It also captures the independence assumption by requiring the residual to be uncorrelated with the instrument. It is therefore a mix of substantive and design-related assumptions, making it difficult to assess its plausibility. Perhaps most clearly this is shown by the role of the randomization of the instrument. Clearly, randomization of the instrument makes an instrumental variables strategy more plausible. However, it does not imply that the instrument is uncorrelated with the residual i. The separation of the critical assumptions into some that are design-based and implied by randomization, and some that are substantive and unrelated to the randomization, clarifies the benefits of randomization and of the substantive assumptions.

Notes

559

24.7 CONCLUSION

In this chapter we extend the discussion of instrumental variables methods from the setting of randomized experiments with one-sided noncompliance to the setting with two-sided noncompliance. We introduce an additional assumption, the monotonicity or no-defier assumption. We also introduce types of noncompliance. With stronger forms of the exclusion restrictions, distinct for each type of noncomplier, we show that one can again estimate, using the method-of-moments, the causal effect of the treatment for the subpopulation of compliers.

NOTES
The traditional econometric approach to instrumental variables can be found in many textbooks. See, for example, Wooldridge (2002), Angrist and Pischke (2008), and Greene (2011). Imbens and Angrist (1994) and Angrist, Imbens, and Rubin (1996) developed the link to the potential outcomes framework. Bjo¨rklund, and Moffitt (1987) use a more model-based approach.
Frumento, Mealli, Pacini, and Rubin (2012) consider various versions of exclusion restrictions in the context of the evaluation of a labor market program with random assignment, noncompliance, and missing data.

CHAPTER 25
Model-Based Analysis in Instrumental Variable Settings: Randomized Experiments with Two-Sided Noncompliance
25.1 INTRODUCTION
In this chapter we develop a multiple-imputation, or model-based alternative, to the Neyman-style moment-based analyses for super-population average treatment effects introduced in Chapters 23 and 24. The model-based approach discussed in this chapter has a number of advantages over the moment-based approach, both conceptual and practical. First, it offers a principled way to incorporate the restrictions on the joint distribution of the observed variables that arise from the various exclusion restrictions and the monotonicity assumption. Second, it allows for a straightforward and flexible way to incorporate covariates. In the current chapter we allow for continuous covariates, or at least covariates taking on too many values for analyses to be feasibly conducted separately on subpopulations homogeneous in the covariates' values. Therefore, we focus on a model-based approach, similar to that in Chapter 8 used in completely randomized experiments. As in Chapter 8, we start by building statistical models for the potential outcomes. A distinct feature of the approach in this chapter is that we also build a statistical model for the compliance behavior. We use these models to simulate the missing potential outcomes and the missing compliance behaviors, and use those in turn to draw inferences regarding causal effects of the primary treatment for the subset of units who would always comply with their assignment.
The remainder of this chapter is organized as follows. In the next section we introduce the data used to illustrate the concepts and methods discussed in this chapter. These data come from a randomized experiment designed to evaluate the effect of an influenza vaccine on hospitalization rates. Rather than randomly giving or withholding the flu vaccine itself (the latter was considered unethical), encouragement to vaccinate was randomized, making this what Holland (1988) called a randomized encouragement design, closely related to Zelen's (1979, 1990) randomized consent design. In Section 25.2 we also carry out some preliminary analyses of the type discussed in the previous chapters, including simple intention-to-treat analyses. In Section 25.3 we discuss the implications of the presence of covariates and formulate critical assumptions to account for them. Next, in Section 25.4, we introduce the model-based imputation approach to the Instrumental Variables (IV) setting. In Section 25.5 we discuss simulation methods to obtain draws from the posterior distribution of the causal estimands. In the following section, Section
560

25.2 The McDonald-Hiu-Tierney Influenza Vaccination Data

561

25.6, we return to the flu-vaccination example and develop a model for that application as well as discuss a scientifically motivated analysis that can easily be conducted from the model-based perspective. In Section 25.7 we discuss the results for the flu-shot data. Section 25.8 concludes.

25.2 THE MCDONALD-HIU-TIERNEY INFLUENZA VACCINATION DATA
To illustrate these methods, we re-analyze a subset of the data set on influenza vaccinations previously analyzed by McDonald, Hiu, and Tierney (1992) and Hirano, Imbens, Rubin, and Zhou (2000). In the original study, a population of physicians was selected. A random subset of these physicians was sent a letter encouraging them to vaccinate patients deemed at risk for influenza. The remaining physicians were not sent such a letter. In a conventional moment-based analysis, the sending of the letter would play the role of the instrument. The treatment of primary interest is each patient's actual receipt or not of the influenza vaccine, not the randomly assigned encouragement in the form of the letter sent to each patient's physician. In this discussion, the units are patients; in particular, we focus on the subset of female patients. The outcome we focus on in this discussion is whether or not the patient was hospitalized for influenza-related reasons.
For each unit (patient) we observe whether the patient's physician was sent the letter encouraging vaccination for at-risk patients, denoted by Zi, equal to one if a letter was sent to the physician, and zero otherwise. For the ith patient we also observe whether a flu shot was received, denoted by the binary indicator Wiobs; whether the patient was hospitalized for flu-related illnesses, Yiobs; and a set of pre-treatment variables, Xi. Note that the design of the experiment involved randomization of physicians rather than patients. Some physicians in our sample have multiple patients, which may lead to correlated outcomes between patients. Although we do not have information on the clustering of patients by doctor, we do have some covariate information on patients. We therefore assume exchangeability of patients conditional on these covariates. To the extent that outcomes and compliance behavior are associated with missing cluster (physician) indicators, even after conditioning on the covariates, our analysis may lead to incorrect posterior inferences, typically the underestimation of posterior uncertainty. This situation has this feature in common with the example in Chapter 23 on randomized experiments with one-sided noncompliance.
There are 1,931 female patients in our sample, and Table 25.1 presents averages by treatment and assignment group for outcomes and covariates. Table 25.2 presents the number of individuals in each of the eight subsamples defined by the binary assignment, binary treatment received and binary outcome, as well as averages for four basic covariates (i.e., pre-treatment variables), age (age measured in years), copd (a binary indicator for chronic obstructive pulmonary disease), and heart (an indicator for prior heart problems), possible latent compliance status.
Before discussing the model-based analyses with covariates that are the main topic of this chapter, let us apply the methods introduced in Chapters 23 and 24 to these data. A standard intention-to-treat (ITT) analysis suggests, not surprisingly, a relatively strong effect of sending the letter encouraging vaccination on the receipt of the influenza

562

Model-Based Analysis in Instrumental Variable Settings

Table 25.1. Summary Statistics for Women by Assigned Treatment, Received Treatment: Covariates and Outcome for Influenza Vaccination Data

letter (Zi) flu shot (Wiobs) hosp (Yiobs) age
copd
heart

Mean
0.53 0.24 0.08 65.4 0.20 0.56

STD
(0.50) (0.43) (0.27) (12.8) (0.40) (0.50)

Means
No Letter Letter Zi = 0 Ziobs = 1

0

1

0.18

0.29

0.09

0.06

65.2

65.6

0.21

0.20

0.56

0.57

t-Stat dif
­ [7.7] [-3.2] [1.1] [-1.3] [0.6]

Means
No Flu Shot Flu Shot Wiobs = 0 Wiobs = 1

0.49

0.63

0

1

0.08

0.07

64.9

67.1

0.20

0.23

0.55

0.60

t-Stat dif
[7.8] ­
[-0.4] [4.9] [2.4] [2.4]

Table 25.2. Summary Statistics for Women by Assigned Treatment, Received Treatment and Outcome, and Possible Latent Compliance Status for Influenza Vaccination Data

Type under Monotonicity and Exclusion Restr.

Assign. Receipt of Hosp. # of Units

(Letter) Flu Shot

Zi

Wiobs

Yiobs

1,931

Means age copd heart

Complier or nevertaker

0

Complier or nevertaker

0

Alwaystaker

0

Alwaystaker

0

Nevertaker

1

Nevertaker

1

Complier or alwaystaker 1

Complier or alwaystaker 1

0

0

685 64.7 0.18 0.524

0

1

64

62.9 0.33 0.77

1

0

148 67.8 0.28 0.60

1

1

20

68.9 0.30 0.70

0

0

672 65.4 0.19 0.55

0

1

51

62.0 0.29 0.69

1

0

277 66.6 0.20 0.57

1

1

14

67.3 0.21 0.79

vaccination. Patients whose physicians were not sent a letter were vaccinated at a rate of 18%, whereas those patients whose physicians were sent the letter were vaccinated at a rate of 29%, equivalent to roughly a 50% increase in the proportion of female patients vaccinated. The difference is a method-of-moments estimate for the ITT effect on the treatment received, ITTW = E[Wi(1) - Wi(0)]:

ITTW

=

W

obs 1

-

W

obs 0

=

0.104

(s. e. 0.019).

Here, as in the previous two chapters, subscripts 0 and 1 refer to levels of the assignment Zi, and subscripts c and t refer to levels of the treatment received Wiobs. The estimated effect is substantial and statistically significant at conventional levels. Clearly the sending of the letter was effective in encouraging actual vaccination, although it is also clear from Table 25.2 that many patients whose physicians were sent the letter did not receive a flu shot (71%), and many patients whose physicians were not sent the letter nevertheless received a flu shot (18%).
Next, let us consider the ITT effect on the outcome of interest, the hospitalization rate: 6.4% of patients whose physicians received the letter were hospitalized for flu-related reasons, whereas 9.2% of patients whose physicians did not receive the letter were

25.2 The McDonald-Hiu-Tierney Influenza Vaccination Data

563

hospitalized for flu-related reasons, which suggests a substantial effect of assignment on hospitalization rates:

ITTY

=

Y

obs 1

-

Y

obs 0

= -0.028

(s. e. 0.012),

approximately a 50% decrease. The estimated effect is substantial in terms of percentage

reduction, and statistically significant at the 5% level. Now, let us look at some IV analyses ignoring covariates, maintaining both the exclu-
sion restrictions for all compliance types and the monotonicity assumption, largely

following the discussion from Chapter 24. Define, as in the previous chapter, the four compliance groups as



Gi

=

 

nt co df

at

if Wi(0) = 0, Wi(1) = 0, if Wi(0) = 0, Wi(1) = 1, if Wi(0) = 1, Wi(1) = 0, if Wi(0) = 1, Wi(1) = 1.

First, let us interpret the ITT effect on the receipt of treatment, under the monotonicity assumption. Without the monotonicity assumption, this ITT effect is equal to the difference in proportions of compliers and defiers. The monotonicity assumption rules out the presence of defiers, so in that case this ITT effect is equal to the proportion of compliers, and the share of compliers in the super-population is estimated by method-of-moments to be

^co = ITTW = 0.104 (s. e. 0.019).

The population proportion of those receiving the vaccination, despite their physician not being sent the encouragement letter, equals the population proportion of alwaystakers. The sample proportion of those receiving the vaccination, even though their physician was not sent the letter equals 0.183, so that the population share of alwaystakers is estimated, by a simple method-of-moments procedure, to be

^ at

=

N0t N0t + N0c

= 0.183

(s. e. 0.013).

The sample proportion of individuals not vaccinated among those whose physicians were sent the letter is a simple method-of-moments estimator of the proportion of nevertakers in the population, also equal to one minus the proportions of compliers and alwaystakers. With our data the resulting estimate equals

^nt = 1 - ^co - ^at =

N1c N1c + N1t

= 0.713

(s. e. 0.014).

Next, let us consider the primary outcome, hospitalization for flu-related reasons, by treatment assigned and treatment received. Table 25.3 gives average outcomes and their associated standard errors for the four groups defined by treatment assigned and treatment received. From this table we can obtain method-of-moments estimates of average potential outcomes for nevertakers and alwaystakers. Patients who did not receive the

564

Model-Based Analysis in Instrumental Variable Settings

Table 25.3. Average Outcomes and Estimated Standard Errors by Treatment Assigned and Treatment Received, for Influenza Vaccination Data

Receipt of

c

treatment Wiobs

t

Assignment of Treatment Zi

0

Y

obs 0c

=

0.

085

(0.010)

1

Y

obs 1c

=

0.

071

(0.010)

Y

obs 0t

=

0.

112

(0.025)

Y

obs 1t

=

0.

048

(0.013)

vaccine, despite their physician having been sent the encouragement letter, must be nevertakers given that, under monotonicity, defiers do not exist. Hence we can estimate the super-population average outcome for nevertakers as

E^ [Yi(0)|Gi

=

nt]

=

Y

obs 1c

= 0.071

(s. e. 0.010).

Similarly, patients who got vaccinated, even though their physicians were not sent the letter, must be alwaystakers, and thus

E^ [Yi(1)|Gi

=

at] =

Y

obs 0t

=

0. 119

(s. e. 0.025).

Those assigned to the control group (i.e., those patients whose physicians were not

sent a letter) who did not receive the flu shot can be one of two types: their observed

behavior is consistent with being a complier or a nevertaker. The expected proportion of

each in this subgroup is the same as their relative proportions in the population. Hence,

within the subgroup of those assigned to the control group who did not receive the flu

shot, the (ex ante) proportion of compliers is co/(co + nt). The population share of

compliers is estimated to be ^co = 0.104. The share of nevertakers is estimated to be

^nt = 0.713. Hence the share of compliers among those not receiving the flu shot is

estimated as ^co/(^co + ^nt) = 0.127. The average outcome in the control group who

were

not

assigned

the

treatment

is

estimated

as

Y

obs 0c

=

0.085.

This

reflects

a

mixture

of

compliers, with an estimated share equal to 0.127, and nevertakers, with an estimated

share of 0.713. In terms of super-population quantities,

E Yiobs Zi = 0, Wiobs = 0

=

co co + nt

·

E [Yi(0)|Gi

=

co]

+

nt co + nt

·

E [Yi(0)|Gi

=

nt] .

Because we estimated the average outcome for nevertakers to be E^ [Yi(0)|Gi = nt] = 0.071, we can estimate the average control potential outcome for compliers as

E^ [Yi(0)|Gi = co] = E^

Yiobs Zi = 0, Wiobs = 0 - E^ [Yi(0)|Gi = n] · ^nt/(^co + ^nt) ^co/(^co + ^nt)

=

Y

obs 0c

-

Y

obs 1c

·

^ nt /(^ co

+

^ nt )

^co/(^co + ^nt)

= 0.188

(s. e. 0.092).

25.2 The McDonald-Hiu-Tierney Influenza Vaccination Data

565

Similarly, those assigned to the control group who did receive the vaccination must be alwaystakers, again because, by monotonicity, there are no defiers. Hence we can estimate the average treatment potential outcome for compliers as

E^ [Yi(1)|Gi = co] = E^

Yiobs

Zi = 1, Wiobs = 1 - E^ [Yi(1)|Gi = at] · ^a/(^co + ^at) ^co/(^co + ^at)

=

Y

obs 1t

-

Y

obs 0t

·

^ at /(^ co

+

^ at )

= -0. 077

(s. e. 0. 054).

^co/(^co + ^at)

Thus, the method-of-moment-based IV estimate of the local average treatment effect (or average causal effect) for women in the flu-shot data set is

^ iv = E^ [Yi(1)|Gi = co] - E^ [Yi(0)|Gi = co] = -0.265 (s. e. 0.110).

We could repeat this analysis for subpopulations defined by covariates, but that would not work well in settings with covariates taking on many values. That is a key reason why, in this chapter, we pursue a model-based strategy to incorporate the covariates, similar to that in Chapter 8 on randomized experiments.
Note that the moment-based estimate of E[Yi(1)|Gi = co] is negative, -0.077. Because this is the probability of an event, E[Yi(1)|Gi = co] = Pr(Yi(1) = 1|Gi = co), the true value of E[Yi(1)|Gi = co] is obviously bounded by zero and one. The momentbased IV estimate does not impose these restrictions, and as a result it does not make efficient use of the data. The model-based strategy discussed in the current chapter provides a natural way to incorporate these restrictions efficiently, and this is an important benefit of the model-based strategy. Note also that one would not necessarily have realized that implicitly the moment-based IV estimate of -0.265 is based on a negative estimate of E[Yi(1)|Gi = co] without performing the additional calculations in the previous paragraph, that is, additional to calculating mechanically the moment-based instrumental variables estimate.
Let us return briefly to the ITT analyses. As an alternative to the Neyman-style analyses for ITTY and ITTW, we could apply the methods discussed in the model-based chapter for randomized experiments, Chapter 8. In the specific context of the flu-shot study, both the primary outcome (hospitalization for flu-related reasons) and the secondary outcome (receipt of influenza vaccination) are binary. Hence natural models for these potential outcomes are binary regression (e.g., logistic) models. We consider these models with the additional assumption that the Zi = 0 and Zi = 1 potential outcomes conditional on Gi are independent.
First, consider ITTW, where we continue for the moment to ignore the presence of covariates. Recall that there are two inputs into a model-based analysis: first, the joint (i.i.d.) distribution for the potential outcomes given a parameter, and second, a prior distribution on that parameter. We begin by specifying

Pr(Wi(z)

=

1| W )

=

1

exp (zW ) + exp (zW

)

,

566

Model-Based Analysis in Instrumental Variable Settings

for z = 0, 1, with  W = (0W , 1W ), and where we assume independence of Wi(0) and Wi(1) given  W , and the zW are functions of a global parameter  . In this simple case, we could have specified a binomial model, Wi(z)  B(N, pWz ), for z = 0, 1, but we use the logistic specification to facilitate the generalization to models with covariates. Given
this model, the super-population average ITT effect is

ITTW

=

1

exp (1W ) + exp (1W )

-

1

exp (0W ) + exp (0W

)

.

The second input is the prior distribution on . In the current setting, with a fairly large data set and the focus on the ITT effects, the choice of prior distribution is largely immaterial, but again to facilitate the comparison with the models discussed later in this chapter, we use a prior distribution specifically designed for logistic regression models. The prior distribution can be interpreted as introducing Nprior artificial observations, divided equally over (z, w)  {(0, 0), (0, 1), (1, 0), (1, 1)}, so that the prior distribution is

p(0W , 1W ) 

exp (0W )

Nprior /4

1 + exp (0W )

1 1 + exp (0W )

Nprior /4

×

exp (1W )

Nprior /4

1 + exp (1W )

1

Nprior /4

1 + exp (1W )

.

In the calculations, we use Nprior = 4. Using simulation methods to obtain draws from the posterior distribution, we find that

the mean and variance of the posterior distribution for ITTW are

E ITTW| Yobs, W = 0.104, V ITTW| Yobs, W = 0.01912.

These numbers are very similar to the point estimate and standard error based on the Neyman-style analysis, which is not surprising given the size of the data, the simple model being used, and the choice of relatively diffuse prior distributions.
To conduct the model-based analysis for ITTY, we reinterpret the current setup slightly. We specify the following model for the two potential outcomes:

Pr(Yi(z, Wi(z))

=

1| Y )

=

1

exp (zY ) + exp (zY

)

,

for z = 0, 1, with  Y = (0Y , 1Y ) independent of  W , and where, as stated earlier, Yi(0, Wi(0)) is independent of Yi(1, Wi(1)) conditional on  Y , so that the super-population average ITT effect is

ITTY

=

exp (1Y ) 1 + exp (1Y )

-

1

exp (0Y ) + exp (0Y

)

.

Using the same prior distribution with four artificial observations for (0Y , 1Y ) as we used for (0W , 1W ), we find for the posterior mean and variance for the

25.3 Covariates

567

intention-to-treat effect ITTY, E ITTY| Yobs, W = -0.028,

V ITTY| Yobs, W = 0.0122.

Again, not surprisingly, these numbers are very similar to those based on the Neyman moment-based analysis.

25.3 COVARIATES
Now we consider settings where, in addition to observing the outcome, the treatment, and the instrument, we observe for each unit a vector of covariates (i.e., pre-treatment variables), denoted by Xi. As in the earlier chapters on analyses under unconfoundedness, the key requirement for these covariates is that they are not affected by the treatment. In the current setting that requirement extends to being unaffected by the instrument or the primary treatment. The pre-treatment variables may include permanent characteristics of the units, or pre-treatment outcomes whose values were determined prior to the determination of the value of the instrument and the treatment. In the presence of covariates we can relax the critical assumptions underlying the analyses discussed in the previous chapter.
The generalization of the random assignment assumption is standard, and mirrors the unconfoundedness assumption for regular assignment mechanisms. It requires that conditional on the pre-treatment variables the assignment is effectively random:
Assumption 25.1 (Super-Population Unconfoundedness of the Instrument)
Zi  Wi(0), Wi(1), Yi(0, 0), Yi(0, 1), Yi(1, 0), Yi(1, 1) Xi.
Because the compliance type Gi is a one-to-one function of (Wi(0), Wi(1)), we can also write this assumption as
Zi  Gi, Yi(0, 0), Yi(0, 1), Yi(1, 0), Yi(1, 1) Xi.
In the flu-shot application, this assumption is satisfied by design both with, and without, the pre-treatment variables, because the instrument, Zi, is randomly assigned independent of the values of the pre-treatment variables. In observational studies, unconfoundedness of the instrument is often a substantive assumption, and it may represent an important relaxation of the stronger assumption that Zi is independent of all potential outcomes without any conditioning. For example, a class of applications of instrumental variables methods in public health settings uses distance from a patient's residence to the nearest medical facility (with particular capabilities or expertise) as an instrument for the use of those capabilities (e.g., McClellan and Newhouse, 1994). To be specific, one might be interested in the effect of the presence of advanced neo-natal urgent care facilities in a hospital on outcomes for prematurely born infants. Typically, the distance to hospitals with such facilities is a strong predictor of the use of those facilities. However, families do not choose location of their residence randomly, and full independence of the distance from their residence to such hospitals may not be plausibly viewed as

568

Model-Based Analysis in Instrumental Variable Settings

random. It may be more plausible to view the distance as essentially random given other characteristics of the location such as median housing cost, population density, and distance to nearest medical facility of any kind.
The presence of covariates does not affect the deterministic version of the exclusion restriction substantially. We continue to make the assumption that for nevertakers and alwaystakers the change in instrument does not affect the outcome.
Assumption 25.2 (Exclusion Restriction for Nevertakers)

Yi(0, Wi(0)) = Yi(1, Wi(1)), for all nevertakers, that is units i with Gi = nt. Assumption 25.3 (Exclusion Restrictions for Alwaystakers)

Yi(0, Wi(0)) = Yi(1, Wi(1)),
for all alwaystakers, that is units i with Gi = at.
The generalization of the stochastic exclusion restriction is more subtle. This is stated as a conditional independence assumption and therefore can be weakened to hold only conditional on covariates:
Assumption 25.4 (Stochastic Exclusion Restrictions for Nevertakers)

Zi  Yi(Zi, Wi(Zi)) Xi, Gi = nt.

Assumption 25.5 (Stochastic Exclusion Restrictions for Alwaystakers) Zi  Yi(Zi, Wi(Zi)) Xi, Gi = at.

In practice these may not be substantial weakenings of the exclusion restrictions relative to the deterministic versions of the restrictions.

25.4 MODEL-BASED INSTRUMENTAL VARIABLES ANALYSES FOR RANDOMIZED EXPERIMENTS WITH TWO-SIDED NONCOMPLIANCE
Now we turn to a model-based strategy for estimating treatment effects in randomized experiments with two-sided noncompliance in settings with covariates. We maintain the exclusion restrictions for nevertakers and alwaystakers, Assumptions 25.2 and 25.3.
We develop the likelihood function using a missing data approach, similar to that used in the model-based chapter on completely randomized experiments, Chapter 8. The key difference is that in the current setting there are, for each unit, two missing potential outcomes. The first missing potential outcome is the primary outcome corresponding to the treatment not received, and the second one is for the secondary outcome, the treatment that would be received under the alternative assignment.

25.4 Analyses for Randomized Experiments with Two-Sided Noncompliance

569

25.4.1 Notation
As before, let W(0) and W(1) be the N-vectors of secondary potential outcomes with ith element equal to Wi(0) and Wi(1), indicating the primary treatment received under assignment to Zi = 0 and Zi = 1 respectively, and let W = (W(0), W(1)).
For the primary outcomes the notation we use is more subtle. Because we maintain the
exclusion restriction for nevertakers and alwaystakers, we drop the z (assignment) argu-
ment of the potential outcomes Yi(z, w) and write, without ambiguity, Yi(w), indexed only by the level of the primary treatment of interest. For compliers, Yi(0) = Yi(0, Wi(0)) = Yi(0, 0) and Yi(1) = Yi(1, Wi(1)) = Yi(1, 1). For nevertakers, Yi(0) = Yi(0, Wi(0)) = Yi(1, Wi(1)), but Yi(1) is not defined, and to be mathematically precise we use the notation Yi(1) = to capture this for nevertakers. For alwaystakers, Yi(1) = Yi(0, Wi(0)) = Yi(1, Wi(1)), but Yi(0) is not defined, and we use Yi(0) = for them. Given this notation, let Y(0) denote the N-vector of primary potential outcomes under receipt of the control treatment, with the ith element equal to Yi(0), and Y(1) the N-vector of potential outcomes under receipt of the active treatment, with ith element equal to Yi(1). Let Y = (Y(0), Y(1)) be the corresponding N × 2 matrix formed by combining Y(0) and Y(1).
We focus on causal estimands that can be written as functions of (Y, W, X, Z),
although in practice interesting causal estimands rarely depend on Z or on Y values equal to . Let Gi  {nt, df, co, at} denote the compliance type of unit i, and let G denote the N-vector with ith element equal to Gi. Then G is a one-to-one function of W, so we can also write the causal estimands as functions of (Y, G, X, Z). This class of estimands
includes, for example, the average effect for compliers,

1 late = Nc i:Gi=co Yi(1) - Yi(0) ,
where, for g  {nt, df, co, at}, Ng is the number of units of type Gi = g: Ng = 1Gi=g. The class of estimands also includes other functions of the potential outcomes for compliers, or even functions of outcomes for the different types of noncompliers, as we see later.
Recall the definitions of the missing and observed outcomes from Chapter 3. Here we define missing and observed values for the treatment received in similar fashion:

Wimis = Wi(1 - Zi) =

Wi(0) if Zi = 1, Wi(1) if Zi = 0,

and Wiobs = Wi(Zi) =

Wi(0) if Zi = 1, Wi(1) if Zi = 0,

where Wmis and Wobs are the N-vectors with ith elements equal to Wimis and Wiobs respectively. For compliers we define

Yimis = Yi(1 - Wiobs) =

Yi(0) if Wiobs = 1, Yi(1) if Wiobs = 0,

570

Model-Based Analysis in Instrumental Variable Settings

and Yiobs = Yi(Wiobs) =

Yi(0) if Wiobs = 0, Yi(1) if Wiobs = 1.

For nevertakers

Yiobs = Yi(0), and Yimis = ,

and for alwaystakers

Yiobs = Yi(1), and Yimis = .
Finally, let Ymis and Yobs be the N-vectors with ith elements equal to Yimis and Yiobs respectively.
Any causal estimand of the form  (Y, G, X, Z) can be written in terms of observed and missing variables as  (Yobs, Ymis, Wobs, Wmis, X, Z). The estimand is unknown because (Ymis, Wmis) are not observed. In order to derive the posterior distribution of  (Y, G, X, Z), we therefore need to derive the predictive distribution of the missing data (Ymis, Wmis) given the observed data (Yobs, Wobs, X, Z), that is, the posterior predictive distribution of the missing data.

25.4.2 The Inputs into a Model-Based Approach We do not directly specify the posterior predictive distribution of the missing data, f (Ymis, Wmis|Yobs, Wobs, X, Z). As in the randomized experiment setting, such a task would generally be difficult, because this predictive distribution combines features of the assignment mechanism with those of the distribution of the potential outcomes. Instead we start with three inputs into the analyses. The first two together specify the joint distribution of all four potential outcomes, (Yi(0), Yi(1), Wi(0), Wi(1)) given covariates and parameters, or equivalently, because Gi is a one-to-one function of (Wi(0), Wi(1)), the joint distribution of the two primary potential outcomes and the compliance type, (Yi(0), Yi(1), Gi), given covariates and parameters. We factor this joint distribution into two parts. First, a model for the primary potential outcomes given covariates, compliance status, and its parameters, denoted
f (Yi(0), Yi(1)|Gi, Xi;  ),
which implies that the joint distribution
N
f (Y|G, X;  ) = f (Yi(0), Yi(1)|Gi, Xi;  ),
i=1
has independence of the units conditional on the unknown parameter . As in the simpler situation of Chapter 8, such an i.i.d specification follows from the unit exchangeability and an appeal to de Finetti's theorem. Often we specify distributions for each of the compliance types and for potential outcomes given compliance types with parameters

25.4 Analyses for Randomized Experiments with Two-Sided Noncompliance

571

a priori independent. For example, with continuous outcomes, we could use Gaussian models. For compliers,

Yi(0)|Gi = co, Xi;   N (Xico,c, c2o,c), and, independently,

Yi(1)|Gi = co, Xi;   N (Xico,t, c2o,t); and for nevertakers,

Yi(0)|Gi = nt, Xi;   N (Xint, n2t); and finally, for alwaystakers,

Yi(1)|Gi = at, Xi;   N (Xiat, a2t),
in combination with a priori independence of the parameters. For notational convenience we include an intercept in Xi. Alternatively we may wish to impose some restrictions, for example, assuming the slope coefficients, or conditional variances, for different complier types are equal. Note that we do not model Yi(1) for nevertakers or Yi(0) for alwaystakers because these are a priori counterfactual and values cannot be observed for them in the current setting.
The second input is a model for compliance status given covariates and the parameters:

N
f (G|X;  ) = f (Gi|Xi,  ).
i=1

Here one natural model is a multinomial logit model, where again we include the intercept in Xi,

Pr(Gi

=

co|Xi,  )

=

1

+

1 exp (Xint)

+

, exp (Xiat)

Pr(Gi

=

nt|Xi,  )

=

1+

exp

exp (Xint) (Xint) + exp

(Xiat)

,

and

Pr(Gi

=

at|Xi,  )

=

1

exp (Xiat)

.

+ exp (Xint) + exp (Xiat)

If we generalize this specification to include functions of the basic covariates, this general specification is essentially without loss of generality.
An alternative to the multinomial logistic model would be a sequence of two binary response models. The first binary response model specifies the probability of being a

572

Model-Based Analysis in Instrumental Variable Settings

complier versus a noncomplier (nevertaker or alwaystaker):

Pr(Gi

=

co|Xi,  )

=

1

exp (Xico) + exp (Xico

)

.

The second model specifies the probability of being a nevertakers conditional on being a noncomplier:

Pr(Gi

=

nt|Xi,

Gi



{nt, at},

)

=

1

exp (Xint) . + exp (Xint)

The third input is the prior distribution for the unknown parameter  = (co,c, co,t, nt, at, nt, at):

p( ) = p(co,c, co,t, nt, at, nt, at).

We will generally attempt to specify prior distributions that are not dogmatic and instead are relatively diffuse. Because of the delicate mixture nature of the model, it will be important to specify proper prior distributions to stabilize estimation. We will specify prior distributions that correspond to the introduction of a few artificial units for whom we observe the covariate values, the compliance types, and different values of the outcome. We specify the prior distribution in such a way that these artificial units carry little weight relative to the observed data. Their presence, in combination with the fact that for these artificial units we observe the compliance types that we may not in reality observe for any units in our sample, ensures that the posterior distribution is always proper and well behaved in a sense that is clear in particular cases, though vague in general.
Now we follow the same four steps described in Chapter 8 to derive the posterior predictive distribution of the estimands (i.e., given the data). Here we do this for general specifications of the potential outcome distributions. Next, we discuss simulation-based methods for approximating these posterior distributions. Later we provide more detail in the specific context of the flu-shot application.

25.4.3 Derivation of f (Ymis, Wmis|Yobs, Wobs, X, Z,  )
The first step is to derive the conditional distribution of the missing data, (Ymis, Wmis), given the observed data, (Yobs, Wobs, X, Z), and the parameter  , from the specifications just described.
Given the specifications of f (Y|G, X; ) and f (G|X; ), we can infer the joint distribution

f (Y(0), Y(1), W(0), W(1))|X, ),

which, because of the unconfoundednes assumption is equal to the conditional distribution

f (Y(0), Y(1), W(0), W(1))|X, Z, ).

(25.1)

25.4 Analyses for Randomized Experiments with Two-Sided Noncompliance

573

Next we use the fact (a special case of which was also exploited in Chapter 8) that there is a one-to-one relation between (Y(0), Y(1), W(0), W(1), Z) and (Ymis, Yobs, Wmis, Wobs, Z), and therefore we can write

(Y(0), Y(1), W(0), W(1)) = g(Ymis, Yobs, Wmis, Wobs, Z).

(25.2)

We can use this, in combination with (25.1), to derive f (Ymis, Yobs, Wmis, Wobs|X, Z,  ).

(25.3)

Then, using Bayes' Rule, we can infer the conditional distribution of the missing potential outcomes given the observed values and :

f (Ymis, Wmis|Yobs, Wobs, X, Z,  )

=

f (Ymis, Yobs, Wmis, Wobs|X, Z,  ) f (Ymis, Yobs, Wmis, Wobs|X, Z,  )dYmisdWmis ,

which, because of the conditioning on , is the product of N factors.

25.4.4 Derivation of the Posterior Distribution p( |Yobs, Wobs, X, Z) In the previous subsection, when deriving the conditional distribution of missing potential outcomes given observed data, we derived the joint distribution of missing and observed outcomes given covariates, instruments, and parameter,
f (Ymis, Yobs, Wmis, Wobs|X, Z,  ).

Integrating out the missing data leads to the joint distribution of observed data given the parameter , which, when regarded as a function of the unknown vector parameter , given observed data, is proportional to the likelihood function of :
L( |Yobs, Wobs, X, Z) = f (Yobs, Wobs|X, Z,  )

=

f (Ymis, Yobs, Wmis, Wobs|X, Z,  )dYmisdWmis.

To obtain analytically the posterior distribution of , we multiply this likelihood function of  by the prior distribution for , p(), and find the normalizing constant to make the product integrate to one:

p( |Yobs, Wobs, X, Z)

=

p( ) · f (Yobs, Wobs|X, Z,  ) f (Yobs, Wobs|X, Z) ,

where the denominator,

f (Yobs, Wobs|X, Z) = p( ) · f (Yobs, Wobs|X, Z,  )d ,

is the marginal distribution of the observed outcomes given , integrated over the vector parameter .

574

Model-Based Analysis in Instrumental Variable Settings

25.4.5 Derivation of the Posterior Distribution of Missing Potential Outcomes f (Ymis, Wmis|Yobs, Wobs, X, Z)
The third step outlined in Chapter 8 applies to the current situation without any modification. Combining the conditional posterior distribution of the missing potential outcomes, given the parameter  , f (Ymis, Wmis|Yobs, Wobs, X, Z,  ), with the posterior distribution of  , p( |Yobs, Wobs, X, Z), and integrating over  , we obtain the posterior distribution of the missing potential outcomes:
f (Ymis, Wmis|Yobs, Wobs, X, Z)

= f (Ymis, Wmis|Yobs, Wobs, X, Z,  ) · p( |Yobs, Wobs, X, Z)d .

25.4.6 Derivation of the Posterior Distribution of Estimands
The final step is again analogous to that in Chapter 8. We have the distribution of the missing potential outcomes given observed potential outcomes, covariates and instruments, f (Ymis, Wmis|Yobs, Wobs, X, Z). Because of (25.2) we can rewrite any estimand that is a function of (Y(0), Y(1), W(0), W(1), X, Z), as a function of missing and observed potential outcomes and covariates and instruments, (Ymis, Yobs, Wmis, Wobs, X, Z). We combine these two results to infer the posterior distribution of  given the observed data, (Yobs, Wobs, X, Z).

25.5 SIMULATION METHODS FOR OBTAINING DRAWS FROM THE POSTERIOR DISTRIBUTION OF THE ESTIMAND GIVEN THE DATA

In many cases the steps outlined in the previous section are often difficult, and in fact essentially impossible, to implement analytically. In practice we therefore often use simulation and, specifically, data augmention methods to obtain approximations to the posterior distribution of causal estimands. Here we describe the general outline for these methods in instrumental variables settings, meaning settings where we accept randomization of the instrument, no defiers, and the exclusion restrictions on the primary outcome for the nevertakers and the alwaystakers.
The conditional joint distribution of the matrix of primary outcomes Y is the product of the N conditional distributions given , and assuming conditional independence between the potential outcomes under Wi = 0 and Wi = 1, this can be written as:

N
f (Y|G, X;  ) = f (Yi(0)|Gi, Xi,  ) · f (Yi(1)|Gi, Xi,  )
i=1

=

f (Yi(0)|Gi = co, Xi,  ) · f (Yi(1)|Gi = co, Xi,  )

i:Gi=co

×

f (Yi(0)|Gi = nt, Xi,  )

i:Gi=nt

×

f (Yi(1)|Gi = at, Xi,  ),

i:Gi=at

25.5 Obtaining Draws from Posterior Distribution of Estimated Given the Data

575

because the distributions of Yi(0) for alwaystakers and Yi(1) for nevertakers are degenerate. Moroever, as above, assume that f (Yi(w)|Gi = g, Xi, Zi,  ), depends only on a subset of the parameter vector, gw, and assume for notational simplicity that these distributions have the same functional form for all pairs (g, w), so that we can write f (y|x; gw)
without ambiguity. Moreover, let us specify the compliance type probabilities as

N
f (G|X;  ) = p(Gi|Xi,  ),
i=1
depending only on a subvector of the full parameter vector,  , so that  = (co,c, co,t, nt, at,  ). (For nevertakers and alwaystakers the distribution of Yi(0) is identical to that of Yi(1) by the two exclusion restrictions, so we do not index nt and at by the treatment received.)
Now, let us consider the actual observed data likelihood function for . There are four possible patterns of missing and observed data corresponding to the four possible values for (Zi, Wiobs): (0, 0), (0, 1), (1, 0), and (1, 1). Partition the set of N units in the sample into the subsets of units exhibiting each pattern of missing and observed data, and denote these subsets by S(z, w), for z, w  {0, 1}, with S(z, w)  {1, . . . , N}, and z,wS(z, w) = {1, 2, . . . , N}, where the sets S(z, w) are disjoint, S(z, w)  S(z , w ) = , unless z = z and w = w .
First consider the set S(0, 1). Under the monotonicity assumption we can infer that units with this pattern of observed compliance behavior are alwaystakers, and we observe Yi(1) for these units. Hence the likelihood contribution from the ith such unit is proportional to:

L(0,1),i = p(Gi = at|Xi, Zi,  ) · f (Yi(1)|Gi = at, Xi, Zi, at), i  S(0, 1). (25.4)

Next, for units in the set S(1, 0), we can infer that they are nevertakers. Hence the likelihood contribution from the ith such unit is proportional to:

L(1,0),i = p(Gi = nt|Xi, Zi,  ) · f (Yi(0)|Gi = nt, Xi, Zi, nt), i  S(1, 0). (25.5)

For units in the two remaining sets, we cannot unambiguously infer the compliance type of such units. Consider first S(0, 0). Receiving the control treatment after being assigned to the control treatment is consistent with being either a nevertaker or a complier. The likelihood contribution for units in this set is therefore a mixture of two outcome distributions. First, the outcome distribution for nevertakers under the control treatment, and second, the outcome distribution for compliers under the control treatment. Using this argument, we can write the likelihood contribution for the ith unit in the set S(0, 0) as proportional to:

L(0,0),i = p(Gi = nt|Xi, Zi,  ) · f (Yi(0)|Gi = nt, Xi, Zi, nt)

(25.6)

+ p(Gi = co|Xi, Zi,  ) · f (Yi(0)|Gi = co, Xi, Zi, co,c), i  S(0, 0).
The set S(1, 1) is also a mixture of two types, in this case compliers and alwaystakers. Hence, we can write the likelihood contribution for the ith unit in the subset S(1, 1) as

576

Model-Based Analysis in Instrumental Variable Settings

proportional to:

L(1,1),i = p(Gi = at|Xi, Zi,  ) · f (Yi(1)|Gi = at, Xi, Zi, at)

(25.7)

+ p(Gi = co|Xi, Zi,  ) · f (Yi(1)|Gi = co, Xi, Zi, co,t), i  S(1, 1).
Combining (25.4)­(25.7), we can write the likelihood function in terms of the observed data as

Lobs( |Zobs, Wobs, Yobs, Xobs)

=

p(Gi = at|Xi, Zi,  ) · f (Yi(1)|Gi = a, Xi, Zi, at)

iS (0,1)

×

p(Gi = nt|Xi, Zi,  ) · f (Yi(0)|Gi = nt, Xi, Zi, nt)

iS (1,0)

×

p(Gi = nt|Xi, Zi,  ) · f (Yi(0)|Gi = nt, Xi, Zi, nt)

iS (0,0)

+ p(Gi = co|Xi, Zi,  ) · f (Yi(0)|Gi = co, Xi, Zi, co,c)

×

p(Gi = at|Xi, Zi,  ) · f (Yi(1)|Gi = at, Xi, Zi, at)

iS (1,1)

+ p(Gi = co|Xi, Zi,  ) · f (Yi(1)|Gi = co, Xi, Zi, co,t) .

This likelihood function has a very specific mixture structure. Had we observed the full compliance types of the units, the resulting complete-data likelihood function would factor into five components, each component depending on a single (a priori independent) subvector of the full parameter vector:

Lcomp( |G, Z, Wobs, Yobs, X)

=

f (Yi(0)|Gi = nt, Xi, Zi, nt)

i:Gi=nt

×

f (Yi(1)|Gi = at, Xi, Zi, at)

f (Yi(0)|Gi = co, Xi, Zi, co,c)

i:Gi=at

i:Gi=co,Zi=0

×

f (Yi(1)|Gi = at, Xi, Zi, co,t)

p(Gi = co|Xi, Zi, )

i:Gi=co,Zi=1

i:Gi=co

×

p(Gi = at|Xi, Zi, )

p(Gi = nt|Xi, Zi, ).

i:Gi=at

i:Gi=nt

With conventional models for the distribution of the potential outcomes and the compliance types, and with coventional prior distributions, analyzing posterior distributions given this complete-data likelihood function would be straightforward. Specifically, it would generally be simple to estimate the parameters by maximum likelihood or Bayesian methods. The key complication is that we do not fully observe the compliance

25.5 Obtaining Draws from Posterior Distribution of Estimated Given the Data

577

types, leading to the mixture observed-data likelihood function. To exploit the simplicity of the complete-data likelihood function, it is useful to use missing data methods, either the Expectation Maximization (EM) algorithm to find the maximum likelihood estimates (i.e., the posterior mode given a flat prior distribution), or Data Augmentation (DA) methods to obtain draws from the posterior distribution.
The key step in these methods is to impute, either stochastically in a DA algorithm or by expectation in the EM algorithm, the missing compliance type, conditional on both current draws or estimates of the parameters, and the observed data. For units with i  (S(0, 1)  S(1, 0)), we know the compliance type, either alwaystaker or nevertaker. For units with i  (S(0, 0)  S(1, 1)) we do not know the compliance type. Specifically, for units with i  S(0, 0) we can only infer that they are either nevertakers or compliers. The probability of such a unit being a complier given observed data and parameters is

Pr(Gi = co|Yiobs = y, Wiobs = 0, Zi = 0, Xi = x,  )

(25.8)

=

p(co|x, ) · f (y|x, co,c)

.

p(co|x, ) · f (y|x, co,c) + p(nt|x, ) · f (y|x, nt)

Similarly,

Pr(Gi = co|Yiobs = y, Wiobs = 1, Zi = 1, Xi = x,  )

(25.9)

=

p(co|x, )

·

p(co|x, ) · f (y|x, co,t) f (y|x, co,t) + p(at|x, )

·

f (y|x,

at) .

It is straightforward to obtain draws from this distribution, or to calculate the numerical conditional probabilities.
To be specific, suppose we wish to obtain draws from the posterior distribution of the average effect of the treatment on the outcome for compliers, the local average treatment effect (or the complier average causal effect),

1 late = Nco i:Gi=co Yi(1) - Yi(0) ,

where Nco =

N i=1

1Gi=co

is

the

number

of

compliers.

To

estimate

late

we

obtain

such

draws using the Data Augmention algorithm. Starting with initial values of the param-

eter , we simulate the compliance type, using (25.10) and (25.9). Given the complete

(compliance) data G, and given the parameters, we draw from the posterior predictive

distribution of the missing potential outcomes for compliers. That is, for compliers with

Zi = 0, we impute Yi(1), and for compliers with Zi = 1, we impute Yi(0). With these
imputations we can calculate the value of late. In the fourth step we update the parameters given (Yobs, G, Z, X). Then we return to the imputation of the compliance types

given the updated parameters.

578

Model-Based Analysis in Instrumental Variable Settings

25.6 MODELS FOR THE INFLUENZA VACCINATION DATA

In this section we illustrate the methods discussed in the previous section using the flushot data set with information on 1,931 women. We focus on estimating the average effect of the flu shot on flu-related hospitalizations for compliers. We exploit the presence of the four covariates, age (age minus 65, in tens of years), copd (heart disease), and heart dis (indicator for prior heart conditions), in order to improve precision and to obtain subpopulation causal effects. Because the instrument, receipt of the letter, was randomly assigned irrespective of covariate values, the posterior distribution for the complier average treatment effect is likely to be relatively robust to modeling choices regarding the conditional distributions given the covariates. In settings where the instrument is correlated with the covariates, such assumptions are likely to be more important.

25.6.1 A Model for Outcomes Given Compliance Type
First, we specify a model for the conditional distribution of the potential outcomes given compliance type, covariates, and parameters. We use a logistic regression model, although other binary regression models are certainly possible. For compliers

Pr(Yi(0)

=

y|Xi

=

x, Gi

=

co, )

=

exp (y · 1 + exp

xco,c) (xco,c)

,

Pr(Yi(1)

=

y|Xi

=

x, Gi

=

co, )

=

exp (y · 1 + exp

xco,t) (xco,t)

,

for nevertakers,

Pr(Yi(0)

=

y|Xi

=

x, Gi

=

nt, )

=

exp (y · xnt) , 1 + exp (xnt)

and, finally, for alwaystakers,

Pr(Yi(1)

=

y|Xi

=

x, Gi

=

at, )

=

exp (y · 1 + exp

xat) . (xat)

Given this model, the super-population average effect of the treatment on the outcome for compliers with Xi = x, is equal to

E [ Yi(1) - Yi(0)| Gi

=

co, Xi

=

x]

=

exp (xco,t) 1 + exp (xco,t)

-

1

exp (xco,c) + exp (xco,c)

.

However, this super-population average treatment effect is not what we want to estimate. Instead we are interested in the average causal effect for compliers in the sample,

late =

1 Nco

i:Gi=co

Yi(1) - Yi(0)

.

25.6 Models for the Influenza Vaccination Data

579

25.6.2 A Model for Compliance Type

The compliance type is a three-valued indicator. We model this through a trinomial logit

model:

Pr(Gi

=

g|Xi

=

x)

=

  1
 1 1

+ + +

exp exp exp

1 (xat) + exp
exp (xnt) (xat) + exp
exp (xat) (xat) + exp

(xnt) (xnt) (xnt)

, , ,

if g = co, if g = nt, if g = at,

where, again, x includes a constant term. An alternative, discussed in Section 25.4.2, is to model first the probability of being a complier versus a noncomplier, and then the probability of being a nevertaker versus alwaystaker conditional on being a noncomplier.

25.6.3 The Prior Distribution
The prior distribution is based on adding artificial observations. These artificial observations are somewhat special because we assume that for them we observe not only the values of the instruments, the treatment, the outcome, and the covariates, but also their compliance type (which is observed for only some but not all units in the sample even under monotonicity and both exclusion restrictions). Each of the artificial observations is of the type (ya, za, ga, xa), where ya  {0, 1}, za  {0, 1}, ga  {co, nt, at}, and xa takes on the observed values of the covariates in the sample. Because there are potentially N = 1,931 different values of the vector of covariates in the actual sample, there are 2 × 2 × 3 × N different values for the quadruple (ya, za, ga, xa). For example, there are 4 × N artificial observations that are nevertakers, for each value of xa, two with ya = 0 and two with ya = 1. Fixing the total weight for these 12 × N artificial observations at Na, the prior distribution for  = (co,c, co,t, nt, at, nt, at) takes the form

p() =

N i=1

1

2

1 + exp (Xiat)

exp (Xiat) 2 1 + exp (Xiat)

N
×
i=1

1

2

1 + exp (Xint)

exp (Xint) 2 1 + exp (Xint)

N
×

1

· exp (Xico,c)

i=1 1 + exp (Xico,c) 1 + exp (Xico,c)

N
×

1

· exp (Xico,t)

i=1 1 + exp (Xico,t) 1 + exp (Xico,t)

N
×

1

i=1 1 + exp (Xiat) + exp (Xint)

580

Model-Based Analysis in Instrumental Variable Settings

×

N i=1

1

+

exp (Xiat) exp (Xiat) + exp (Xint)

N
×

exp (Xint)

Na/(12×N)
.

i=1 1 + exp (Xiat) + exp (Xint)

By keeping the value of Na small but positive (with the limiting prior distribution flat, i.e., constant, as Na  0), we limit the total influence of the prior distribution, while ensuring that the resulting posterior distribution is proper. In the implementation here,

we fix Na at 30, which is small relative to the actual sample size, which is nearly 100 times as large.

25.6.4 Implementation
Given the specification for the outcome distributions and the specification for the model of compliance type, the full parameter vector is  = (nt, at, nt, at, co,0, co,1). The likelihood function is

Lobs( |Zobs, Wobs, Yobs, Xobs)

=

exp (Xint)

· exp (Yiobs · Xint)

iS(0,0) 1 + exp (Xiat) + exp (Xint) 1 + exp (Xint)

+

1

· exp (Yiobs · Xico0)

1 + exp (Xiat) + exp (Xint) 1 + exp (Xico,0)

×

iS (0,1)

1

+

exp

exp (Xiat) (Xiat) + exp (Xin)

·

exp (Yiobs · Xiat) 1 + exp (Xiat)

×

iS (1,0)

1

+

exp

exp (Xint) (Xiat) + exp (Xint)

·

exp (Yiobs · Xint) 1 + exp (Xint)

×

exp (Xiat)

· exp (Yiobs · Xiat)

iS(1,1) 1 + exp (Xiat) + exp (Xint) 1 + exp (Xiat)

+ 1

+

exp

1 (Xiat)

+

exp (Xint)

·

exp (Yiobs 1 + exp

· Xico,1) (Xico1)

.

Let us consider implementing our methods, using this likelihood function and the specified prior distribution, on the flu data. To be specific, we will focus on obtaining draws from the posterior distribution for

late

=

1 Nco

i:Gi=co

Yi(1) - Yi(0) .

We condition on the number of compliers in the sample being positive, so draws from the vector of compliance types with no compliers are discarded.

25.7 Results for the Influenza Vaccination Data

581

Let (0) denote the starting values for the parameter vector  . Given these values we impute the compliance type Gi for units i with i  S(0, 0) and i  S(1, 1) (for units with i  S(0, 1) and i  S(1, 0) we can directly infer the compliance type). This impu-
tation involves drawing from a binomial distribution. Specifically, consider a unit i with i  S(0, 0), that is, a unit with Zi = 0 and Wiobs = 0. Suppose this unit has a realized outcome Yiobs = y. We cannot infer with certainty whether this unit is a complier or a nevertaker, although we can be sure this unit is not an alwaystaker. The probability of
this unit being a complier is

Pr(Gi = co|Yiobs = y, Wiobs = 0, Zi = 0, Xi = x,  )

(25.10)

=

p(co|x, ) · f (y|x, co,c)

p(co|x, ) · f (y|x, co,c) + p(nt|x, ) · f (y|x, nt)

=





1 1+exp (xat)+exp (xnt)

·

exp (xco,c) 1+exp (xco,c)

1 1+exp (xat)+exp (xnt)

·

exp (xco,c) 1+exp (xco,c)

+

exp (nt) 1+exp (xat)+exp (xnt)

·

y

exp (xnt) 1+exp (xnt)



×



1+exp

1 (xat)+exp

1 1+exp (xat)+exp (xnt)

·

1 1+exp (xco,c)

(xnt)

·

1 1+exp (xco,c)

+

exp (xnt) 1+exp (xat)+exp

(xnt

)

·

1-y
.
1 1+exp (xnt)

Similarly, we impute the compliance type for units with Zi = 1 and Wiobs = 1, who may be compliers or nevertakers.
In the second step we impute the missing potential outcomes for all units. For compliers with Zi = 0, this means imputing Yi(1) from a binomial distribution with mean (exp (Xico,c)/(1 + exp (Xico,c)), and for compliers with Zi = 1, this means imputing Yi(0) from a binomial distribution with mean exp (Xico,t)/(1 + exp (Xico,t)), using the appropriate subvectors of the current parameter value (0). Given these values, we can calculate the average treatment effect for compliers, late,(0), where the second subscript indexes the iteration. We also impute the missing potential outcomes for nevertakers and
alwaystakers in order to update the parameter vectors in the third step. In the third step we update the parameter vector, from (k) to (k+1). For each of the
subvectors (nt, at), nt, at, co,c, and co,t, we use the corresponding factor of the complete-data likelihood function with a Metropolis-Hastings step (see, e.g., Gelman,
Carlin, Stern and Rubin, 1995). In each of these five cases, this is a straightforward step,
with the likelihood in four cases corresponding to a binary logit one, and in one case
corresponding to a trinomial logit model.

25.7 RESULTS FOR THE INFLUENZA VACCINATION DATA
Now let us apply this approach to the flu-shot data. We implement five versions. First, in the first column of Table 25.4, we report maximum likelihood estimates (posterior modes with a flat prior distribution) assuming no covariates were observed. In the randomized experiment settings we considered in Chapter 8, maximum likelihood estimates for the parameters of the statistical model were generally close to the posterior means, and asymptotic standard errors (estimated using the information matrix) were close to

582

Model-Based Analysis in Instrumental Variable Settings

Table 25.4. Model-Based Estimates of Local Average Treatment and Intention-to-Treat Effects: Posterior Quantiles, for Influenza Vaccination Data

MLE
(flat prior)

Post Mode

Quantiles of Posterior Distribution with Model for Potential Outcomes given Covariates

No Cov q.025 med q.975

Parallel q.025 med q.975

Unrestricted

q.025 med

q.975

late

-0.11 -0.10 -0.32 -0.15 -0.02 -0.32 -0.14 -0.01 -0.48 -0.16

0.13

ITTW

0.12 0.13 0.09 0.12 0.15 -0.03 -0.02 -0.00 0.05 0.10

0.13

ITTY

-0.01 -0.01 -0.04 -0.02 -0.00 0.09 0.12 0.15 -0.04 -0.02

0.01

E[Yi(0)|Gi = co] 0.11 0.15 0.06 0.19 0.35 0.69 0.71 0.72 0.01 0.22

0.53

E[Yi(1)|Gi = co] 0.00 0.06 0.00 0.03 0.09 0.16 0.18 0.19 0.00 0.04

0.31

E[Yi(0)|Gi = nt

0.08 0.08 0.06 0.07 0.08 0.06 0.18 0.35 0.06 0.07

0.08

E[Yi(1)|Gi = at] 0.11 0.11 0.08 0.09 0.10 0.00 0.04 0.09 0.06 0.09

0.10

co,c,intercept

-2.07 -1.71 -2.64 -1.42 -0.53 -3.32 -2.06 -1.09 -7.83 -2.88

0.17

co,c,age

-0.25 -0.11 0.02 -0.04 0.02

0.10

co,c,copd

0.08 0.46 0.83 -5.06 1.29

7.66

co,c,heart

0.42 0.79 1.16 -2.35 1.88

6.00

co,t,intercept co,t,age co,t,copd co,t,heart

- -2.82 -4.71 -3.13 -2.09 -5.30 -3.70 -2.66 -14.05 -4.18

0.61

-0.25 -0.11 0.02 -0.02 0.06

0.20

0.08 0.46 0.83 -6.56 0.37

7.32

0.42 0.79 1.16 -4.75 0.58

5.34

nt,intercept nt,age nt,copd nt,heart
at,intercept at,age at,copd at,heart

-2.41

-2.42

-2.82

-2.55

-2.31

-3.56 -0.25
0.08 0.42

-3.16 -0.11
0.46 0.79

-2.79 0.02 0.83 1.16

-2.08

-2.13

-2.58

-2.18

-1.82

-3.36 -0.25
0.08 0.42

-2.84 -0.11
0.46 0.79

-2.37 0.02 0.83 1.16

-3.72 0.02 0.13 0.18
-3.67 0.02
-0.91 -0.25

-3.23 0.04 0.75 0.71
-2.78 0.04 0.07 0.58

-2.81 0.06 1.28 1.23
-2.09 0.06 0.95 1.47

nt,intercept

1.78 1.66 1.47 1.74 2.06 1.36 1.80 2.39 1.40 1.91

3.03

nt,age

-0.19 0.02 0.22 -0.22 0.04

0.26

nt,copd

-0.48 0.28 1.50 -0.30 0.69

2.36

nt,heart dis

-0.80 -0.14 0.46 -1.18 -0.12

0.64

at,intercept at,age at,copd at,heart

0.48 0.36 0.05 0.36 0.74 -0.35 0.21 0.91 -0.28 0.35

1.63

-0.01 0.25 0.50 -0.05 0.25

0.53

-0.12 0.79 2.10 0.06 1.21

2.94

-0.79 -0.02 0.73 -1.16 0.01

0.88

posterior standard deviations. This is sometimes the case in instrumental variables settings, but there can be substantial differences because of the restrictions on the joint distributions of the observed variables implied by the instrumental variables assumptions. Moreover, in such cases, the curvature of the logarithm of the likelihood function need not provide a good approximation to either the posterior standard deviation or the repeated sampling standard error of the estimates. For the flu-shot data, one of the parameter estimates is zero, which is on the boundary of the parameter space, which is not surprising considering that the simple moment-based estimate of E[Yi(1)|Gi = at] is negative. In the second column of Table 25.4 we report posterior modes given the prior distribution we use, again assuming no covariates were observed.
Next, we report summary statistics for posterior distributions for three models. First, we report summary statistics for the posterior distribution for the model assuming no covariates were observed. We report posterior medians and posterior 0.025 and 0.975 quantiles, in Columns 3­5 of Table 25.4. Here the posterior medians are fairly close

25.7 Results for the Influenza Vaccination Data

583

6

5

4

Density

3

2

1

0 ­0.5 ­0.4 ­0.3 ­0.2 ­0.1 0 0.1 0.2
Local Average Treatment Effect
Figure 25.1. Histogram-based estimate of the distribution of the LATE, influenza vaccination data
to the maximum likelihood estimates for nt and at. The posterior medians for the parameters for the outcome distributions for the compliers are somewhat different from the maximum likelihood estimates, which is not surprising considering that one of the maximum likelihood estimates is on the boundary of the parameter space. A normal approximation to the posterior distribution for the local average treatment effect is not particularly accurate. The skewness of the posterior distribution is -0.79, and the kurtosis is 3.29. Interestingly, the posterior probability that late is exactly equal to zero is 0.08, which corresponds to the probability that, among the compliers, the fractions of treated and control units that are hospitalized are exactly equal. Figure 25.1 presents a histogram estimate of the marginal posterior distribution of late under this model.
The second model includes the three covariates, age, copd, and heart dis. We assume the slope coefficients in the models for the four potential hospitalization outcomes are identical for the groups, nevertakers, alwaystakers, and compliers with and without flu shots. The posterior 0.025 and 0.975 quantiles and the median for this model are reported in Columns 6­8 of Table 25.4. Finally, we relax the model and allow the slope coefficients to differ between the four potential hospitalization outcomes. The results for this model are reported in the Columns 9­11 of Table 25.4.
Note that in all cases the posterior medians are well above the moment-based estimates of the local average treatment effect. The reason for this result is that the momentbased estimate is based implicitly on estimating the probability of being hospitalized

584

Model-Based Analysis in Instrumental Variable Settings

Table 25.5. Estimated Average Covariate Values by Compliance Type, for Influenza Vaccination Data

Sample
Compliers age copd heart

Models for Potential Outcomes given Covariates

No Cov

Parallel

Unrestricted

65.5

64.9

64.9

0.21

0.16

0.12

0.57

0.58

0.57

Nevertakers

age

70.7

70.8

70.7

copd

0.19

0.20

0.20

heart

0.55

0.55

0.55

Alwaystakers

age

75.0

75.0

75.0

copd

0.24

0.26

0.27

heart

0.60

0.60

0.60

for compliers given the flu shot to be negative. The model-based estimates restrict this to be non-negative, leading to a higher value for the posterior medians than the method-of-moments estimates.
In Table 25.5 we report estimated values for average covariate values for the three covariates, age, copd, and heart, within each of the three complier types to assess how different the three compliance types are. We see that nevertakers are older, less likely to have heart complications compared to compliers. Alwaystakers are even older, and more likely to have heart complications compared to compliers. Such results may be of substantive relevance.

25.8 CONCLUSION
In this chapter we discuss a model-based approach to estimating causal effects in instrumental variables settings. A key conceptual advantage of a model-based approach over a moment-based one is that with a model-based approach, it is straightforward to incorporate the restrictions implied by the instrumental variables assumptions, or to relax them. We discuss in detail the complications in analysis relative to the method-of-momentsbased approach in settings with randomized experiments and unconfoundedness.

NOTES
The model-based approach to instrumental variables discussed in the current chapter was developed in Imbens and Rubin (1997b) and Hirano, Imbens, Rubin, and Zhou (2000). Hirano, Imbens, Rubin, and Zhou (2000) also consider alternative models where the exclusion restrictions are relaxed. Rubin and Zell (2010) uses a similar model. Rubin,

Notes

585

Wang, Yin, and Zell (2010) uses the two binary models, one for being a complier or not, and one for being a nevertaker conditional on not being a complier, to model the three-valued compliance status indicator.
An alternative Bayesian posterior predictive check approach to assessing Fishers sharp null hypothesis in in the presence of noncompliance is proposed in Rubin (1998). Although that is not developed in this text, it may have interesting applications.
Distance to facilities that provide particular treatments are a widely used class of instruments. In health care settings examples include McClellan and Newhouse (1994) and Baiocchi, Small, Lorch, and Rosenbaum (2010). In the economics literature examples include the use of distance to college in Card (1995) and Kane and Rouse (1995).
For the Data Augmentation algorithm, see Tanner and Wong (1987), Tanner (1996), and Gelman, Carlin, Stern, and Rubin (1995).

PART VII
Conclusion

CHAPTER 26
Conclusions and Extensions
In this text we exposited the potential outcomes approach to causality, also known as the Rubin Causal Model, and hope to have convinced the reader of its usefulness. In this final chapter we briefly summarize this approach and discuss other topics in causal inference where this approach may be useful. Many of these are areas of ongoing research, and we hope to discuss them in more detail in a second volume.
The starting point of our approach is the notion of potential outcomes. For each unit in a population, and for each level of a treatment, there is a potential outcome. Comparisons of these potential outcomes define the causal effects; we view these as well-defined irrespective of the assignment mechanism, and thus irrespective of what we actually are able to observe. We often place restrictions on these potential outcomes. Most important in the current text is the stability assumption, or SUTVA, that rules out differences between potential outcomes corresponding to different levels of the treatment for units other than the unit under consideration, and rules out unrepresented levels of treatments
We can observe at most one of the potential outcomes for each unit. Causal inference is therefore intrinsically a missing data problem. Given the potential outcomes, there is a key role in our approach for the assignment mechanism, which defines which potential outcomes are observed and which are missing. The current text is largely organized by different types of assignment mechanisms. The simplest is that of a classical randomized experiment where the researcher knows the assignment mechanism entirely. Such assignment mechanisms are discussed in Part II of the text. Then, in the main part of the text, Parts III and IV, we discuss regular assignment mechanisms where we know part but not all of the assignment mechanism. We discuss the importance of the design stage of a study for causal effects where the outcome data are not yet used. At this stage a researcher can carry out preliminary analyses that make the final analyses that do involve the outcome data more credible and robust.
In Part V we examine the unconfoundedness assumption, which implies that units with the same values of the pre-treatment variables but different treatment levels are comparable in terms of potential outcome distributions. First we assess its plausibility, and then we discuss the sensitivity of conclusions based on its possible violations.
In Part VI we discuss some particcular, non-regular, assignment mechanisms involving noncompliance with assigned treatments, in parciular, instrumental variables settings.
589

590

Conclusions and Extensions

There are many areas of causal inference that we do not discuss in the current text, and which we intend to discuss in a second volume. A partial list of such methods where we feel the potential outcome framework can clarify assumptions and methods includes settings where SUTVA is violated because there are network or peer effects. It also includes generalizations of instrumental variables settings to principal stratification where there are latent strata such that unconfoundedness holds generally only within the strata. We will also discuss treatments that take on more than two values, including both finite unordered discrete cases and continuous dose-response cases. We also plan to discuss dynamic, sequential, treatment settings. Another currently active area of research is regression discontinuity designs, both sharp and fuzzy, where the overlap assumption regarding covariate distributions is not necessarily satisfied, but the extrapolation is limited. A set of methods popular in economics is referred to as difference-in-differences. A related set of methods includes the use of artificial control groups. In epidemiological settings case-control studies are popular, which we intend to disucss from our perspective. Causal methods are now also used in duration settings, which we also intend to address.

NOTES
Many of the topics mentioned in this chapter are the subject of active research. General text on evaluation methods in economics, with a special focus on regression methods, include Angrist and Krueger (2000) and Angrist and Pischke (2008). A more general social science text is Shadish, Campbell, and Cook (2002). See also Gelman and Hill (2006). Papers on difference-in-differences methods include Abadie (2005), Athey and Imbens (2006), and Blundell, Gosling, Ichimura, and Meghir (2007). For regression discontinuity designs, see Thistlewaite and Campbell (1960), Goldberger (1991), Black (1999), Van Der Klaauw (2002), Imbens and Lemieux (2008), Hahn, Todd, and Van Der Klaauw (2000), Porter (2003), Imbens and Kalyanaraman (2012), Lee and Lemieux (2010), and Lee (2008). Artificial control groups were introduced by Abadie, Diamond, and Hainmueller (2010). For discussions in duration models, see Abbring and Van Den Berg (2003) and Ham and Lalonde (1996). For the notion of the generalized propensity score and multi-valued treatments, see Imbens (2000), Hirano and Imbens (2004), Yang, Imbens, Cui, Faries, and Kadziola (2014), and Imai and Van Dyk (2004). Principal stratification was introduced in Frangakis and Rubin (2002), and a recent application is Frumento, Mealli, Pacini, and Rubin (2012).

References
Abadie, A. (2002), "Bootstrap Tests for Distributional Treatment Effects in Instrumental Variable Models," Journal of the American Statistical Association, Vol. 97(457): 284­292.
Abadie, A. (2003), "Semiparametric Instrumental Variable Estimation of Treatment Response Models," Journal of Econometrics, Vol. 113(2): 231­263.
Abadie, A. (2005): "Semiparametric Difference-in-Differences Estimators," Review of Economic Studies, Vol. 72(1): 1­19.
Abadie, A., J. Angrist, and G. Imbens, (2002), "Instrumental Variables Estimation of Quantile Treatment Effects," Econometrica, Vol. 70(1): 91­117.
Abadie, A., A. Diamond, and J. Hainmueller, (2010), "Control Methods for Comparative Case Studies: Estimating the Effect of California's Tobacco Control Program," Journal of the American Statistical Association, Vol. 105(490): 493­505.
Abadie, A., D. Drukker, H. Herr, and G. Imbens, (2003), "Implementing Matching Estimators for Average Treatment Effects in STATA," The STATA Journal, Vol. 4(3): 290­311.
Abadie, A., and G. Imbens, (2006), "Large Sample Properties of Matching Estimators for Average Treatment Effects," Econometrica, Vol. 74(1): 235­267.
Abadie, A., and G. Imbens, (2008), "On the Failure of the Bootstrap for Matching Estimators," Econometrica, Vol. 76(6): 1537­1557.
Abadie, A., and G. Imbens, (2009), "Bias-Corrected Matching Estimators for Average Treatment Effects," Journal of Business and Economic Statistics, Vol. 29(1): 1­11.
Abadie, A., and G. Imbens, (2010), "Estimation of the Conditional Variance in Paired Experiments," Annales d'Economie et de Statistique, Vol. 91: 175­187.
Abadie, A., and G. Imbens, (2011), "Bias-Corrected Matching Estimators for Average Treatment Effects," Journal of Business and Economic Statistics, Vol. 29(1): 1­11.
Abadie, A., and G. Imbens, (2012), "Matching on the Estimated Propensity Score," National Bureau of Economic Research Working paper 15301.
Abbring, J., and G. van den Berg, (2003), "The Nonparametric Identification of Treatment Effects in Duration Models," Econometrica, Vol. 71(5): 1491­1517.
Althauser, R., and D. Rubin, (1970), "The Computerized Construction of a Matched Sample," The American Journal of Sociology, Vol. 76(2): 325­346.
Altman, D., (1991), Practical Statistics for Medical Research, Chapman and Hall/CRC. Angrist, J. (1990), "Lifetime Earnings and the Vietnam Era Draft Lottery: Evidence from Social
Security Administrative Records," American Economic Review, Vol. 80: 313­335. Angrist, J. (1998), "Estimating the Labor Market Impact of Voluntary Military Service Using Social
Security Data on Military Applicants," Econometrica, Vol. 66(2): 249­288. Angrist, J. D., and J. Hahn, (2004) "When to Control for Covariates? Panel-Asymptotic Results for
Estimates of Treatment Effects," Review of Economics and Statistics, Vol. 86(1): 58­72.
591

592

References

Angrist, J., G. Imbens, and D. Rubin, (1996), "Identification of Causal Effects Using Instrumental Variables," Journal of the American Statistical Association, Vol. 91: 444­472.
Angrist, J., and A. Krueger, (1999), "Does Compulsory Schooling Affect Schooling and Earnings," Quarterly Journal of Economics, Vol. CVI(4): 979­1014.
Angrist, J. D., and A. B. Krueger, (2000), "Empirical Strategies in Labor Economics," in A. Ashenfelter and D. Card, eds. Handbook of Labor Economics, vol. 3. Elsevier Science.
Angrist, J. D., and G. M. Kuersteiner, (2011), "Causal Effects of Monetary Shocks: Semiparametric Conditional Independence Tests with a Multinomial Propensity Score," Review of Economics and Statistics, Vol. 93(3): 725­747.
Angrist, J., and V. Lavy, (1999), "Using Maimonides' Rule to Estimate the Effect of Class Size on Scholastic Achievement," Quarterly Journal of Economics, Vol. CXIV: 1243.
Angrist, J., and S. Pischke, (2008), Mostly Harmless Econometrics: An Empiricists' Companion, Princeton University Press.
Anscombe, F. J. (1948), "The Validity of Comparative Experiments," Journal of the Royal Statistical Society, Series A, Vol. 61: 181­211.
Ashenfelter, O. (1978), "Estimating the Effect of Training Programs on Earnings," Review of Economics and Statistics, Vol. 60: 47­57.
Ashenfelter, O., and D. Card, (1985), "Using the Longitudinal Structure of Earnings to Estimate the Effect of Training Programs," Review of Economics and Statistics, Vol. 67: 648­660.
Athey, S., and G. Imbens, (2006), "Identification and Inference in Nonlinear Difference-InDifferences Models," Econometrica, Vol. 74(2): 431-497.
Athey, S., and G. Imbens, (2014), "Supervised Learning Methods for Causal Effects" Unpublished Manuscript.
Athey, S., and S. Stern, (1998), "An Empirical Framework for Testing Theories About Complementarity in Organizational Design," NBER working paper 6600.
Austin, P. (2008), "A Critical Appraisal of Propensity-Score Matching in the Medical Literature Between 1996 and 2003," Statistics in Medicine, Vol. 27: 2037­2049.
Baiocchi, M., D. Small, S. Lorch, and P. Rosenbaum, (2010), "Building a Stronger Instrument in an Observational Study of Perinatal Care for Premature Infants," The Journal of the American Statistical Association, Vol. 105(492): 1285­1296.
Baker, S. (2000), "Analyzing a Randomized Cancer Prevention Trial with a Missing Binary Outcome, an Auxiliary Variable, and All-or-None Compliance," The Journal of the American Statistical Association, Vol. 95(449): 43­50.
Ball, S., G. Bogatz, D. Rubin, and A. Beaton, (1973), "Reading with Television: An Evaluation of The Electric Company. A Report to the Children's Television Workshop," Vol 1 and 2, Educational Testing Service, Princeton NJ.
Barnard, J., J. Du, J. Hill, and D. Rubin, (1998), "A Broader Template for Analyzing Broken Randomized Experiments," Sociological Methods & Research, Vol. 27: 285­317.
Barnow, B. S., G. G. Cain, and A. S. Goldberger, (1980), "Issues in the Analysis of Selectivity Bias," in E. Stromsdofer and G. Farkas, eds. Evaluation Studies, vol. 5, Sage.
Becker, S., and A. Ichino, (2002), "Estimation of Average Treatment Effects Based on Propensity Scores," The Stata Journal, Vol. 2(4): 358­377.
Beebee, H., C. Hitchcock, and P. Menzies, (2009), The Oxford Handbook of Causation, Oxford University Press.
Belloni, A., V. Chernozhukov, and C. Hansen, (2014), "Inference on Treatment Effects After Selection Amongst High-Dimensional Controls," The Review of Economic Studies, Vol. 81(2): 608­650.
Bertrand, M., and S. Mullainathan, (2004), "Are Emily and Greg More Employable than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination," American Economic Review, Vol. 94(4): 991­1013.
Bitler, M., J. Gelbach, and H. Hoynes, (2002), "What Mean Impacts Miss: Distributional Effects of Welfare Reform Experiments," American Economic Review, Vol. 96(4): 988-1012.
Bjo¨rklund, A., and R. Moffitt, (1987), "The Estimation of Wage Gains and Welfare Gains in Self­ Selection Models," Review of Economics and Statistics, Vol. LXIX: 42­49.

References

593

Black, S. (1999), "Do Better Schools Matter? Parental Valuation of Elementary Education," Quarterly Journal of Economics, Vol. CXIV: 577.
Bloom, H. (1984), "Accounting for No-Shows in Experimental Evaluation Designs," Evaluation Review, Vol. 8: 225­246.
Blundell, R., and M. Costa-Dias, (2000), "Evaluation Methods for Non-Experimental Data," Fiscal Studies, Vol. 21(4): 427­468.
Blundell, R., and M. Costa-Dias, (2002), "Alternative Approaches to Evaluation in Empirical Microeconomics," Portuguese Economic Journal, Vol. 1(1): 91­115.
Blundell, R., A. Gosling, H. Ichimura, and C. Meghir, (2007), "Changes in the Distribution of Male and Female Wages Accounting for the Employment Composition," Econometrica, Vol. 75(2): 323­363.
Box, G., S. Hunter, and W. Hunter, (2005), Statistics for Experimenters: Design, Innovation and Discovery, Wiley.
Box, G., and G. Tiao, (1973), Bayesian Inference in Statistical Analysis, Addison Wesley. Breiman, L., and P. Spector, (1992), "Submodel Selection and Evaluation in Regression: The
x-Random Case," International Statistical Review, Vol. 60: 291­319. Brillinger, D. R., Jones, L. V., and Tukey, J. W. (1978), "Report of the statistical task force for the
weather modification advisory board." The Management of Western Resources, Vol. II: The Role of Statistics on Weather Resources Management. Stock No. 003-018-00091-1, Government Printing Office, Washington, DC. Brooks, S., A. Gelman, G. Jones, and X. -Li. Meng, (2011), Handbook of Markov Chain Monte Carlo, Chapman and Hall. Bu¨hlman, P., and S. van der Geer, (2011), Statistics for High-Dimensional Data: Methods, Theory and Applications, Springer Verlag. Busso, M., J. DiNardo, and J. McCrary, (2009), "New Evidence on the Finite Sample Properties of Propensity Score Matching and Reweighting Estimators," Unpublished Working Paper. Caliendo, M. (2006), Microeconometric Evaluation of Labour Market Policies, Springer Verlag. Card, D. (1995), "Using Geographic Variation in College Proximity to Estimate the Return to Schooling," in Christofides, E. K. Grant, and R. Swidinsky, ed. Aspects of Labor Market Behaviour: Essays in Honour of John Vanderkamp, University of Toronto Press. Card, D., and A. Krueger, (1994), "Minimum Wages and Employment: A Case Study of the Fastfood Industry in New Jersey and Pennsylvania," American Economic Review, Vol. 84(4): 772­784. Card, D., and D. Sullivan, (1988), "Measuring the Effect of Subsidized Training Programs on Movements In and Out of Employment," Econometrica, Vol. 56(3), 497­530. Chernozhukov, V., and C. Hansen, (2005), "An IV Model of Quantile Treatment Effects," Econometrica, Vol. 73(1): 245­261. Chetty, R., J. Friedman, N. Hilger, E. Saez, D. Schanzenbach, and D. Yagan, (2011), "How Does Your Kindergarten Classroom Affect Your Earnings? Evidence from Project STAR," Quarterly Journal of Economics, Vol. 126(4): 1593­1660. Clogg, C., D. Rubin, N. Schenker, B. Schultz, and L. Weidman, (1991), "Multiple Imputation of Industry and Occupation Codes in Census Public-Use Samples Using Bayesian Logistic Regression,", Journal of the American Statistical Association, Vol. 86(413): 68­78. Cochran, W. G. (1965), "The Planning of Observational Studies of Human Populations," Journal of the Royal Statistical Society, Series A (General), Vol. 128(2): 234­266. Cochran, W. G. (1968) "The Effectiveness of Adjustment by Subclassification in Removing Bias in Observational Studies," Biometrics, Vol. 24: 295­314. Cochran, W. G. (1977), Sampling Techniques, Wiley. Cochran, W. G., and G. Cox, (1957), Experimental Design, Wiley Classics Library. Cochran, W. G., and D. Rubin, (1973), "Controlling Bias in Observational Studies: A Review," Sankhya, Vol. 35: 417­46. Cook, T. (2008), "`Waiting for Life to Arrive': A History of the Regression-Discontinuity Design in Psychology, Statistics, and Economics," Journal of Econometrics, Vol. 142(2): 636­654. Cook, T., and D. DeMets, (2008), Introduction to Statistical Methods for Clinical Trials, Chapman and Hall/CRC.

594

References

Cornfield et al. (1959), "Smoking and Lung Cancer: Recent Evidence and a Discussion of Some Questions," Journal of the National Cancer Institute, Vol. 22: 173­203.
Cox, D. (1956), "A Note on Weighted Randomization," The Annals of Mathematical Statistics, Vol. 27(4): 1144-1151.
Cox, D. (1958), Planning of Experiments, Wiley Classics Library. Cox, D. (1992), "Causality: Some Statistical Aspects," Journal of the Royal Statistical Society, Series
A, Vol. 155: 291­301. Cox, D., and P. McCullagh, (1982), "Some Aspects of Covariance," (with discussion). Biometrics,
Vol. 38: 541­561. Cox, D., and N. Reid, (2000), The Theory of the Design of Experiments, Chapman and Hall/CRC. Crump, R., V. J. Hotz, G. Imbens, and O. Mitnik, (2008), "Nonparametric Tests for Treatment Effect
Heterogeneity," Review of Economics and Statistics, Vol. 90(3): 389­405. Crump, R., V. J. Hotz, G. Imbens, and O. Mitnik, (2009), "Dealing with Limited Overlap in
Estimation of Average Treatment Effects," Biometrika, Vol. 96: 187­99. Cuzick, J., R. Edwards, and N. Segnan, (1997), "Adjusting for Non-Compliance and Contamination
in Randomized Clinical Trials," Statistics in Medicine, Vol. 16: 1017­1039. Darwin C., (1876), The Effects of Cross- and Self-Fertiilisation in the Vegetable Kingdom, John
Murry. Davies, O. (1954), The Design and Analysis of Industrial Experiments, Oliver and Boyd. Dawid, P. (1979), "Conditional Independence in Statistical Theory," Journal of the Royal Statistical
Society, Series B, Vol. 41(1): 1­31. Dawid, P. (2000), "Causal Inference Without Counterfactuals," Journal of the American Statistical
Association, Vol. 95(450): 407­424. Deaton, A. (2010), "Instruments, Randomization, and Learning about Development," Journal of
Economic Literature, Vol. 48(2): 424­455. Dehejia, R. (2002), "Was There a Riverside Miracle? A Hierarchical Framework for Evaluating
Programs with Grouped Data," Journal of Business and Economic Statistics, Vol. 21(1): 1­11. Dehejia, R. (2005a), "Practical Propensity Score Matching: A Reply to Smith and Todd," Journal of
Econometrics, Vol. 125: 355­364. Dehejia, R. (2005b) "Program Evaluation as a Decision Problem," Journal of Econometrics, Vol.
125: 141­173. Dehejia, R., and S. Wahba, (1999), "Causal Effects in Nonexperimental Studies: Reevaluating the
Evaluation of Training Programs," Journal of the American Statistical Association, Vol. 94: 1053­ 1062. Dehejia, R., and S. Wahba, (2002), "Propensity Score-Matching Methods for Nonexperimental Causal Studies," Review of Economics and Statistics, Vol. 84(1): 151­161. Diaconis, P. (1976), "Finite Forms of de Finetti's Theorem on Exchangeability," Technical Report 84, Department of Statistics, Stanford University. Diamond, A., and J. Sekhon, (2013), "Genetic Matching for Estimating Causal Effects: A General Multivariate Matching Method for Achieving Balance in Observational Studies," Review of Economics and Statistics, Vol. 95(3): 932­945. Diehr, P., D. Martin, T. Koepsell, and A. Cheadle, (1995), "Breaking the Matches in a Paired t-Test for Community Interventions When the Number of Pairs is Small," Statistics in Medicine, Vol. 14: 1491­1504. Donner, A. (1987), "Statistical Methodology for Paired Cluster Designs," American Journal of Epidemiology, Vol. 126(5), 972­979. Du, J. (1998) "Valid Inferences After Propensity Score Subclassification Using Maximum Number of Subclasses as Building Blocks," PhD Thesis, Department of Statistics, Harvard University. Duflo, E., R. Hanna, and S. Ryan, (2012), "Incentives Work: Getting Teachers to Come to School," American Economic Review, Vol. 102(4): 1241­1278. Efron, B., and D. Feldman, (1992), "Compliance as an Explanatory Variable in Clinical Trials," Journal of the American Statistical Association, Vol. 86(413): 9­17. Efron, B., and R. Tibshirani, (1993), An Introduction to the Bootstrap, Chapman and Hall. Engle, R., D. Hendry, and J.-F. Richard, (1974) "Exogeneity," Econometrica, Vol. 51(2): 277-304.

References

595

Espindle, L. (2004), "Improving Confidence Coverage for the Estimate of the Treatment Effect in a Subclassification Setting," Undergraduate Thesis, Department of Statistics, Harvard University.
de Finetti, B. (1964), "Foresignt: Its Logical Laws, Its Subjective Sources," in Kyburg and Smokler, eds. Studies in Subjective Probability, Wiley.
de Finetti, B. (1992), Theory of Probability: A Critical Introductory Treatment, Vol. 1 & 2, Wiley Series in Probability & Mathematical Statistics.
Feller, W. (1965), An Introduction to Probability and its Applications, Vol. 1, John Wiley and Sons, New York City.
Firpo, S. (2003), "Efficient Semiparametric Estimation of Quantile Treatment Effects," PhD Thesis, Chapter 2, Department of Economics, University of California, Berkeley.
Firpo, S. (2007), "Efficient Semiparametric Estimation of Quantile Treatment Effects,"Econometrica, Vol. 75(1): 259-276.
Fisher, L., D. Dixon, J. Herson, R. Frankowski, M. Hearron, and K. Peace, (1990), "Intention to Treat in Clinical Trials," in Peace, ed. Statistical Issues in Drug Research and Development, Marcel Dekker, Inc.
Fisher, R. A. (1918), "The Causes of Human Variability," Eugenics Review, Vol. 10: 213­220. Fisher, R. A. (1925), Statistical Methods for Research Workers, 1st ed, Oliver and Boyd. Fisher, R. A. (1935), Design of Experiments, Oliver and Boyd. Fisher, R., and W. MacKenzie, (1923), "Studies in Crop Vacation. II. The Manurial Response of
Different Potato Varieties," Journal of Agricultural Science, Vol. 13: 311­320. Fisher, L. et al. (1990), "Intention-to-Treat in Clinical Trials," in K.E. Peace ed., Statistical Issues in
Drug Research and Development, Marcel Dekker. Fraker, T., and R. Maynard, (1987), "The Adequacy of Comparison Group Designs for Evaluations
of Employment-Related Programs," Journal of Human Resources, Vol. 22(2): 194­227. Frangakis, C., and D. Rubin, (2002), "Principal Stratification," Biometrics, Vol. 58(1): 21­29. Freedman, D. A. (2006), "Statistical Models for Causation: What Inferential Leverage Do They
Provide," Evaluation Review , Vol. 30(6): 691­713. Freedman, D. A. (2008a), "On Regression Adjustmens to Experimental Data, " Advances in Applied
Mathematics , Vol. 30(6): 180­193. Freedman, D. A. (2008b), "On Regression Adjustmens in Experiments with Several Treatments,"
Annals of Applied Statistics, Vol. 2: 176­196. Freedman, D. A. (2009), in D. Collier, J. S. Sekhon, and P. B. Stark, eds. Statistical Models and
Causal Inference: A Diagogue with the Social Sciences, Cambridge University Press. Freedman, D. A., Pisani, R. and Purves, R. (1978). Statistics, Norton. Friedlander, D., and J. Gueron, (1995), "Are High-Cost Services More Effective Than Low-Cost
Services," in C. Manski and I. Garfinkel, eds. Evaluating Welfare and Training Programs, Harvard University Press, pp. 143­198. Friedlander, D., and P. Robins, (1995), "Evaluating Program Evaluations: New Evidence on Commonly Used Nonexperimental Methods," American Economic Review, Vol. 85: 923­937. Fro¨lich, M. (2000), "Treatment Evaluation: Matching versus Local Polynomial Regression," Discussion paper 2000-17, Department of Economics, University of St. Gallen. Fro¨lich, M. (2004a), "Finite-Sample Properties of Propensity-Score Matching and Weighting Estimators," The Review of Economics and Statistics, Vol. 86(1): 77­90. Fro¨lich, M. (2004b), "A Note on the Role of the Propensity Score for Estimating Average Treatment Effects," Econometric Reviews, Vol. 23(2): 167­174. Frumento, P., F. Mealli, B. Pacini, and D. Rubin, (2012), "Evaluating the Effect of Training on Wages in the Presence of Noncompliance, Nonemployment, and Missing Outcome Data," Journal of the American Statistical Association, No. 498: 450­466. Gail, M. H., S. Mark, R. Carroll, S. Green, and D. Pee, (1996), "On Design Considerations and Randomization-based Inference for Coomunity Intervention Trials," Statistics in Medicine, Vol. 15: 1069­1092. Gail, M. H., W. Tian, and S. Piantadosi, (1988), "Tests for No Treatment Effect in Randomized Clinical Trials," Biometrika, Vol. 75(3): 57­64.

596

References

Gail, M. H., S. Wieand, and S. Piantadosi, (1984), "Biased Estimates of Treatment Effect in Randomized Experiments with Nonlinear Regressions and Omitted Covariates," Biometrika, Vol. 71(3): 431­444.
Gelman, A., J. Carlin, H. Stern, and D. Rubin, (1995), Baeysian Data Analysis, Chapman and Hall. Gelman, A., and J. Hill, (2006), Data Analysis Using Regression and Multilevel/Hierarchical
Models, Cambridge University Press. Gill, R., and J. Robins. (2001), "Causal Inference for Complex Longitudinal Data: The Continuous
Case," Annals of Statistics, Vol. 29(6): 1785­1811. Goldberger, A. (1991), A Course in Econometrics, Harvard University Press. Graham, B., (2008), "Identifying Social Interactions through Conditional Variance Restrictions,"
Econometrica, Vol. 76(3): 643­660. Granger, C. (1969), "Investigating Causal Relations by Econometric Models and Cross-spectral
Methods," Econometrica, Vol. 37(3): 424­438. Greene, W. (2011), Econometric Analysis, 7th Edition, Prentice Hall. Gu, X., and P. Rosenbaum, (1993), "Comparison of Multivariate Matching Methods: Struc-
tures, Distances and Algorithms," Journal of Computational and Graphical Statistics, Vol. 2: 405­420. Guo, S., and M. Fraser, (2010), Propensity Score Analysis, Sage Publications. Gutman, R., and D. Rubin, (2014), "Robust Estimation of Causal Effects of Binary Treatments in Unconfounded Studies with Dichotomous Outcomes," Statistics in Medicine, forthcoming. Haavelmo, T. (1943), "The Statistical Implications of a System of Simultaneous Equations," Econometrica, Vol. 11(1):1­12. Haavelmo, T. (1944), "The Probability Approach in Econometrics," Econometrica, Vol. 11. Hahn, J. (1998), "On the Role of the Propensity Score in Efficient Semiparametric Estimation of Average Treatment Effects," Econometrica, Vol. 66(2): 315­331. Hahn, J., P. Todd, and W. VanderKlaauw, (2000), "Identification and Estimation of Treatment Effects with a Regression-Discontinuity Design," Econometrica, Vol. 69(1): 201­209. Hainmueller, J. (2012), "Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies," Political Analysis, Vol. 20: 25­46. Ham, J., and R. Lalonde, (1996), "The Effect of Sample Selection and Initial Conditions in Duration Models: Evidence from Experimental Data on Training," Econometrica, Vol. 64: 1. Hansen, B. (2007), "Optmatch: Flexible, Optimal Matching for Observational Studies," R News, Vol. 7(2): 18­24. Hansen, B. (2008), "The Prognostic Analogue of the Propensity Score," Biometrika, Vol. 95(2): 481­488. Hansen, B., and S. Klopfer, (2006), "Optimal Full Matching and Related Designs via Network Flows," Journal of Computational and Graphical Statistics, Vol. 15(3): 609­627. Hartigan, J. (1983), Bayes Theory, Springer Verlag. Hartshorne, C., and P. Weiss, (Eds.). (1931). Collected Papers of Charles Sanders Peirce (Vol. 1), Harvard University Press. Hearst, N., Newman, T., and S. Hulley, (1986), "Delayed Effects of the Military Draft on Mortality: A Randomized Natural Experiment," New England Journal of Medicine, Vol. 314 (March 6): 620­624. Heckman, J., and J. Hotz, (1989), "Alternative Methods for Evaluating the Impact of Training Programs," (with discussion), Journal of the American Statistical Association, Vol. 84(804): 862­874. Heckman, J., H. Ichimura, and P. Todd, (1997), "Matching as an Econometric Evaluation Estimator: Evidence from Evaluating a Job Training Program," Review of Economic Studies, Vol. 64: 605­ 654. Heckman, J., H. Ichimura, and P. Todd, (1998), "Matching as an Econometric Evaluation Estimator," Review of Economic Studies, Vol. 65: 261­294. Heckman, J., H. Ichimura, J. Smith, and P. Todd, (1998), "Characterizing Selection Bias Using Experimental Data," Econometrica, Vol. 66: 1017­1098.

References

597

Heckman, J., R. Lalonde, and J. Smith, (2000), "The Economics and Econometrics of Active Labor Markets Programs," in A. Ashenfelter and D. Card, eds. Handbook of Labor Economics, vol. 3, Elsevier Science.
Heckman, J., and R. Robb, (1984), "Alternative Methods for Evaluating the Impact of Interventions," in Heckman and Singer, eds., Longitudinal Analysis of Labor Market Data, Cambridge University Press.
Heckman, J., and E. Vytlacil, (2007a), "Econometric Evaluation of Social Programs, Part I: Causal Models, Structural Models and Econometric Policy Evaluation," in J. Heckman and E. Leamer, eds. Handbook of Econometrics, vol. 6B, Chapter 70, 4779-4874, Elsevier Science.
Heckman, J., and E. Vytlacil, (2007b), "Econometric Evaluation of Social Programs, Part II: Using the Marginal Treatment Effect to Organize Alternative Econometric Estimators to Evaluate Social Programs, and to Forecast their Effects in New Environments," in J. Heckman and E. Leamer, eds. Handbook of Econometrics, vol. 6B, Chapter 71, 4875-5143, Elsevier Science.
Heitjan, D., and R. Little, (1991), "Multiple Imputation for the Fatal Accident Reporting System," Applied Statistics, Vol. 40: 13­29.
Hendry, D., and Morgan, M. (1995). The Foundations of Econometric Analysis, Cambridge University Press.
Hewitt, E., and L. Savage, (1955), "Symmetric Measures on Cartesian Products,"Transactions of the American Mathematical Society, Vol. 80: 470-501.
Hinkelmann, K., and O. Kempthorne, (2005), Design and Analysis of Experiments, Vol. 2, Advance Experimental Design, Wiley.
Hinkelmann, K., and O. Kempthorne, (2008), Design and Analysis of Experiments, Vol. 1, Introduction to Experimental Design, Wiley.
Hirano, K., and G. Imbens, (2001), "Estimation of Causal Effects Using Propensity Score Weighting: An Application of Data on Right Heart Catherization," Health Services anf Outcomes Research Methodology, Vol. 2: 259­278.
Hirano, K., and G. Imbens, (2004), "The Propensity Score with Continuous Treatments," in Gelman and Meng, eds. Applied Bayesian Modelling and Causal Inference from Missing Data Perspectives, Wiley.
Hirano, K., G. Imbens, and G. Ridder, (2003), "Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score," Econometrica, Vol. 71(4): 1161­1189.
Hirano, K., G. Imbens, D. Rubin, and A. Zhou, (2000), "Estimating the Effect of Flu Shots in a Randomized Encouragement Design," Biostatistics, Vol. 1(1): 69­88.
Ho, D., and K. Imai, (2006), "Randomization Inference with Natural Experiments: An Analysis of Ballot Effects in the 2003 California Recall Election," Journal of the American Statistical Association, Vol. 101(476): 888­900.
Ho, D., K. Imai, G. King, and E. Stuart, (2007), "Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference," Political Analysis, Vol. 81: 945­970.
Hodges, J. L., and Lehmann, E., (1970), Basic Concepts of Probability and Statistics, 2nd ed., Holden-Day.
Holland, P. (1986), "Statistics and Causal Inference" (with discussion), Journal of the American Statistical Association, Vol. 81: 945­970.
Holland, P. (1988), "Causal Inference, Path Analysis, and Recursive Structural Equations Models," (with discussion), Sociological Methodology, Vol. 18: 449­484.
Holland, P., and D. Rubin, (1982), "Introduction: Research on Test Equating Sponsored by Educational Testing Service, 1978­1980," in Test Equating, Academic Press, Inc. pp. 1­6.
Holland, P., and D. Rubin, (1983), "On Lord's Paradox," in Wainer and Messick, eds. Principles of Modern Psychological Measurement: A Festschrift for Frederick Lord, Erlbaum, pp. 3­25.
Hood, and T. Koopmans, (1953), Studies in Econometric Method, Wiley, New York. Horowitz, J. (2002), "The Bootstrap," in Heckman and Leamer, eds. Handbook of Econometrics,
Vol. 5, Elsevier. Horvitz, D., and D. Thompson, (1952), "A Generalization of Sampling Without Replacement from a
Finite Universe," Journal of the American Statistical Association, Vol. 47: 663­685.

598

References

Hotz, V. J., G. Imbens, and J. Klerman, (2001), "The Long-Term Gains from GAIN: A Re-Analysis of the Impacts of the California GAIN Program," Journal of Labor Economics, Vol. 24(3): 521­ 566.
Hotz, J., G. Imbens, and J. Mortimer, (2005), "Predicting the Efficacy of Future Training Programs Using Past Experiences," Journal of Econometrics, Vol. 125: 241­270.
Huber, M., M. Lechner, and C. Wunsch, (2012), "The Performance of Estimators Based on the Propensity Score," Journal of Econometrics, Vol. 175(1): 1­21.
Imai, K. (2008). Variance Identification and Efficiency Analysis in Randomized Experiments under the Matched-Pair Design." Statistics in Medicine, Vol. 27(24) (October): 4857­4873.
Imai, K., and D. van Dyk, (2004), "Causal Inference with General Treatment Regimes: Generalizing the Propensity Score," Journal of the American Statistical Assocation, Vol. 99: 854­866.
Imai, K., G. King, and E. A. Stuart, (2008), "Misunderstandings among Experimentalists and Observationalists about Causal Inference," Journal of the Royal Statistical Society, Series A (Statistics in Society), Vol. 171(2): 481-502.
Imbens, G. (2000), "The Role of the Propensity Score in Estimating Dose-Response Functions," Biometrika, Vol. 87(3): 706­710.
Imbens, G. (2003), "Sensivity to Exogeneity Assumptions in Program Evaluation," American Economic Review, Papers and Proceedings.
Imbens, G. (2004), "Nonparametric Estimation of Average Treatment Effects Under Exogeneity: A Review," Review of Economics and Statistics, Vol. 86(1): 1­29.
Imbens, G. (2010), "Better LATE Than Nothing: Some Comments on Deaton (2009) and Heckman and Urzua (2009)," Journal of Economic Literature, Vol. 48(2): 399­423.
Imbens, G. (2011), "On the Finite Sample Benefits of Stratification, Blocking and Pairing in Randomized Experiments," Unpublished Manuscript.
Imbens, G. (2014), "Instrumental Variables: An Econometrician's Perspective," Statistical Science, Vol. 29(3): 375­379.
Imbens, G., (2015), "Matching Methods in Practice: Three Examples," forthcoming, Journal of Human Resources.
Imbens, G., and J. Angrist, (1994), "Identification and Estimation of Local Average Treatment Effects," Econometrica, Vol. 61(2): 467­476.
Imbens, G., and K. Kalyanaraman, (2012), "Optimal Bandwidth Choice for the Regression Discontinuity Estimator Review of Economic Studies," Review of Economic Studies, Vol. 79(3): 933­959.
Imbens, G., and T. Lemieux, (2008), "Regression Discontinuity Designs: A Guide to Practice," Journal of Econometrics, Vol. 142(2): 615­635.
Imbens, G., and P. Rosenbaum, (2005), "Randomization Inference with an Instrumental Variable," Journal of the Royal Statistical Society, Series A, Vol. 168(1): 109­126.
Imbens, G., and D. Rubin, (1997a), "Estimating Outcome Distributions for Compliers in Instrumental Variable Models," Review of Economic Studies, Vol. 64(3): 555­574.
Imbens, G., and D. Rubin, (1997b), "Bayesian Inference for Causal Effects in Randomized Experiments with Noncompliance," Annals of Statistics, Vol. 25(1): 305­327.
Imbens, G., and J. Wooldridge, (2009), "Recent Developments in the Econometrics of Program Evaluation," Journal of Economic Literature, Vol. 47(1): 1­81.
Jin, H., and D. B. Rubin, (2008), "Principal Stratification for Causal Inference with Extended Partial Compliance: Application to Efron-Feldman Data," Journal of the American Statistical Association, Vol. 103: 101­111.
Kane, T., and C. Rouse, (1995), "Labor-Market Returns to Two- and Four- Year College," American Economic Review, Vol. 85(3): 600­614.
Kang, J., and J. Schafer, (2007), "Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a Population Mean from Incomplete Data," Statistical Science, Vol. 22(4): 523­539.
Kempthorne, O. (1952), The Design and Analysis of Experiments, Robert Krieger Publishing Company.

References

599

Kempthorne, O. (1955), "The Randomization Theory of Experimental Evidence," Journal of the American Statistical Association, Vol. 50927(1): 946­967.
Ketel, N., E. Leuven, H. Oosterbeek, and B. VanderKlaauw, (2013), "The Returns to Medical School in a Regulated Labor Market: Evidence from Admission Lotteries," Unpublished Manuscript.
Koch, G., C. Tangen, J. W Jung, and I. Amara, (1998), "Issues for Covariance Analysis of Dichotomous and Orderd Categorical Data from Randomized Clinical Trials and Non-Parametric Strategies for Addressing Them," Statistics in Medicine, Vol. 17: 1863­1892.
Koopmans, T., (1950), Statistical Inference in Dynamic Economic Models, Wiley, New York. Krueger, A. (1999), "Experimental Estimates of Education Production Functions Experimental Esti-
mates of Education Production Functions," The Quarterly Journal of Economics, Vol. 114(2): 497-532. Lalonde, R.J., (1986), "Evaluating the Econometric Evaluations of Training Programs with Experimental Data," American Economic Review, Vol. 76: 604­620. Lancaster, T. (2004), An Introduction to Modern Bayesian Econometrics, Blackwell Publishing. Leamer, E. (1988), "Discussion on Marini, Singer, Glymour, Scheines, Spirtes, and Holland," Sociological Methodology, Vol. 18: 485-493. Lechner, M. (1999), "Earnings and Employment Effects of Continuous Off-the-job Training in East Germany After Unification," Journal of Business and Economic Statistics, Vol. 17(1): 74­90. Lechner, M. (2001), "Identification and Estimation of Causal Effects of Multiple Treatments under the Conditional Independence Assumption," in Lechner and Pfeiffer, eds. Econometric Evaluations of Active Labor Market Policies in Europe, Heidelberg. Lechner, M. (2002), "Program Heterogeneity and Propensity Score Matching: An Application to the Evaluation of Active Labor Market Policies," Review of Economics and Statistics, Vol. 84(2): 205­220. Lechner, M. (2008), "A Note on the Common Support Problem in Applied Evaluation Studies," Annales d'conomie et de Statistique, Vol. 91-92: 217­234. Lee, D. (2008), "Randomized Experiments from Non-random Selection in U.S. House Elections," Journal of Econometrics, Vol. 142(2): 675­697. Lee, D., and T. Lemieux, (2010), "Regression Discontinuity Designs in Economics," Journal of Economic Literature, Vol. 48(2): 281­355. Lee, M.-J. (2005), Micro-Econometrics for Policy, Program, and Treatment Effects, Oxford University Press. Lehman, E. (1974), Nonparametrics: Statistical Methods Based on Ranks, Holden-Day. Lesaffre, E., and S. Senn, (2003), "A Note on Non-Parametric ANCOVA for Covariate Adjustment in Randomized Clinical Trials," Statistics in Medicine, Vol. 22: 3583­3596. Lin, W. (2012), "Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman's Critique," Annals of Applied Statistics. Lindley, D. V., and N. R. Novick, (1981), "The Role of Exchangeability in Inference," Annals of Statistics, Vol. 9: 45­58. Little, R., and D. Rubin, (2002), Statistical Analysis with Missing Data, Wiley. Lord, F. (1967), "A Paradox in the Interpretation of Group Comparisons," Psychological Bulletin, Vol. 68: 304­305. Lui, Kung-Jong (2011), Binary Data Analysis of Randomized Clinical Trials with Noncompliance, Wiley, Statistics in Practice. Lynn, H., and C. McCulloch, (1992), "When Does It Pay to Break the Matches for Analysis of a Matched-pair Design," Biometrics, Vol. 48: 397­409. McCarthy, M. D. (1939), "On the Application of the z-Test to Randomized Blocks," Annals of Mathematical Statistics, Vol. 10: 337. McClellan, M., and J. P. Newhouse, (1994), "Does More Intensive Treatment of Acute Myocardial Infarction in the Elderly Reduce Mortality," Journal of the American Medical Association, Vol. 272(11): 859­866. McDonald, C., S. Hiu, and W. Tierney, (1992), "Effects of Computer Reminders for Influenza Vaccination on Morbidity During Influenza Epidemics," MD Computing, Vol. 9: 304­312.

600

References

McNamee, R. (2009), "Intention to Treat, Per Protocol, as Treated and Instrumental Variable Estimators Given Non-Compliance and Effect Heterogeneity," Statistics in Medicine, Vol. 28: 2639­2652.
Mann, H. B., and D. R. Whitney, (1947), "On a Test of Whether One of Two Random Variables Is Stochastically Larger Than the Other," Annals of Mathematical Statistics, Vol. 18(1): 50­60.
Manski, C. (1990), "Nonparametric Bounds on Treatment Effects," American Economic Review Papers and Proceedings, Vol. 80: 319­323.
Manski, C. (1996), "Learning about Treatment Effects from Experiments with Random Assignment of Treatments," The Journal of Human Resources, Vol. 31(4): 709­773.
Manski, C. (2003), Partial Identification of Probability Distributions, Springer-Verlag. Manski, C. (2013), Public Policy in an Uncertain World, Harvard University Press. Manski, C., G. Sandefur, S. McLanahan, and D. Powers, (1992), "Alternative Estimates of the Effect
of Family Structure During Adolescence on High School," Journal of the American Statistical Association, Vol. 87(417): 25­37. Marini, M., and B. Singer, (1988), "Causality in the Social Sciences," Sociological Methodology, Vol. 18: 347­409. Mealli, F., and D. Rubin, (2002a), "Assumptions When Analyzing Randomized Experiments with Noncompliance and Missing Outcomes," Health Services Outcome Research Methodology, Vol. 3: 225­232. Mealli, F., and D. Rubin, (2002b), "Discussion of Estimation of Intervention Effects with Noncompliance: Alternative Model Specification by Booil Jo," Journal of Educational and Behavioral Statistics, Vol. 27: 411­415. Meier, P. (1991), "Compliance as an Explanatory Variable in Clinical Trials: Comment," Journal of the American Statistical Association, Vol. 86(413):19­22. Miguel, E., C. Camerer, K. Casey, J. Cohen, K. M. Esterling, A. Gerber, R. Glennerster, D. P. Green, M. Humphreys, G. Imbens, D. Laitin, T. Madon, L. Nelson, B. A. Nosek, M. Petersen, R. Sedlmayr, J. P. Simmons, U. Simonsohn, and M. Van der Laan, (1991), "Promoting Transparency in Social Science Research," Science, Vol. 343(6166): 30­31. Mill, J. S. (1973), A system of logic , In Collected Works of John Stuart Mill, University of Toronto Press. Miratrix, L., J. Sekhon, and B. Yu, (2013), "Ajdusting Treatment Effect Estimates by PostStratification in Randomized Experiments," Journal of the Royal Statistical Society, Series B, 75, 369­396. Morgan, K., and D. Rubin, (2012), "Rerandomization to Improve Covariate Balance in Experiments," Annals of Statistics, Vol. 40(2): 1263­1282. Morgan, S. (2013), Handbook of Causal Analysis for Social Research, Springer. Morgan, S., and C. Winship, (2007), Counterfactuals and Causal Inference, Cambridge University Press. Morris, C., and J. Hill, (2000), "The Health Insurance Experiment: Design Using the Finite Selection Model," Public Policy and Statistics: Case Studies from RAND 2953. Springer, New York. Morton, R., and K. Williams, (2010), Experimental Political Science and the Study of Causality, Cambridge University Press. Mosteller, F. (1995), "The Tennessee Study of Class Size in the Early School Grades," The Future of Children: Critical Issues for Children and Youths, V(1995): 113­127. Murnane, R., and J. Willett, (2011), Methods Matter: Improving Causal Inference in Educational and Social Science Research, Oxford University Press. Murphy, D., and L. Cluff, (1990), "SUPPORT: Study to understand prognoses and preferences for outcomes and risks of treatmentsstudy design," Journal of Clinical Epidemiology, Vol. 43: 1S­ 123S. Neyman, J. (1923, 1990), "On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9," translated in Statistical Science, (with discussion), Vol. 5(4): 465­480, 1990.

References

601

Neyman, J. (1934), "On the Two Different Aspects of the Representative Method: The Method of Stratified Sampling and the Method of Purposive Selection," Journal of the Royal Statistical Society, Vol. 97(4): 558-625.
Neyman, J. with the cooperation of K. Iwaskiewicz and St. Kolodziejczyk, (1935), "Statistical Problems in Agricultural Experimentation," (with discussion), Supplement, Journal of the Royal Statistal Society, Series B, Vol. 2: 107­180.
Pattanayak, C., D. Rubin, and E. Zell, (2011), "Propensity Score Methods for Creating Covariate Balance in Observational Studies," Review of Experimental Cardiology, Vol. 64(10): 897-903.
Paul, I., J. Beiler, A. McMonagle, M. Shaffer, L. Duda, and C. Berlin, (2007), "Effect of Honey, Dextromerhorphan, and No Treatment on Nocturnal Cough and Sleep Quality for Coughing Childre and Their Parents," Archives of of Pediatric and Adolescent Medicine, Vol. 161(12): 1140­1146.
Pearl, J. (1995), "Causal Diagrams for Empirical Research," Biometrika, Vol. 82: 669­688. Pearl, J., (2000, 2009), Causality: Models, Reasoning and Inference, Cambridge University Press. Peirce, C., and J. Jastrow, (1885), "On Small Differences in Sensation," Memoirs of the National
Academy of Sciences, Vol. 3: 73­83. Peters, C., and W. van Vorhis, (1941), Statistical Procedures and Their Mathematical Bases,
McGraw-Hill. Politis, D., and J. Romano, (1999), Subsampling, Springer Verlag. Porter, J. (2003), "Estimation in the Regression Discontinuity Model," Unpublished Manuscript,
Harvard University. Powers, D., and S. Swinton, (1984), "Effects of Self-Study for Coachable Test Item Types," Journal
of Educational Measurement, Vol. 76: 266­278. Quade, D. (1982), "Nonparametric Analysis of Covariance by Matching," Biometrics, Vol. 38: 597­
611. Reid, C. (1998), Neyman from Life, Springer. Reinisch, J., S. Sanders, E. Mortensen, and D. Rubin, (1995), "In Utero Exposure to Phenobarbital
and Intelligence Deficits in Adult Men," The Journal of the American Medical Association, Vol. 274(19): 1518-1525. Robert, C. (1994), The Bayesian Choice, Springer Verlag. Robert, C., and G. Casella, (2004), Monte Carlo Statistical Methods, Springer Verlag. Robins, J. (1986), "A New Approach to Causal Inference in Mortality Studies with Sustained Exposure Periods - Application to Control of the Healthy Worker Survivor Effect," Mathematical Modelling, Vol. 7: 1393­1512. Robins, J., and Y. Ritov, (1997), "Towards a Curse of Dimensionality Appropriate (CODA) Asymptotic Theory for Semi-parametric Models," Statistics in Medicine, Vol. 16: 285­319. Robins, J. M., and A. Rotnitzky, (1995), "Semiparametric Efficiency in Multivariate Regression Models with Missing Data," Journal of the American Statistical Association, Vol. 90: 122­129. Robins, J. M., Rotnitzky, A., and Zhao, L-P., (1995), "Analysis of Semiparametric Regression Models for Repeated Outcomes in the Presence of Missing Data," Journal of the American Statistical Association, Vol. 90: 106­121. Romer, C. D., and D. H. Romer, (2004), "A New Measure of Monetary Shocks: Derivation and Implications," The American Economic Review, Vol. 94(4): 1055­1084. Rosenbaum, P. (1984a), "Conditional Permutation Tests and the Propensity Score in Observational Studies," Journal of the American Statistical Association, Vol. 79: 565­574. Rosenbaum, P. (1984b), "The Consequences of Adjustment for a Concomitant Variable That Has Been Affected by the Treatment," Journal of the Royal Statistical Society, Series A, Vol. 147: 656­666. Rosenbaum, P. (1987), "The Role of a Second Control Group in an Observational Study," Statistical Science, (with discussion), Vol. 2(3), 292­316. Rosenbaum, P. (1988), "Permutation Tests for Matched Pairs," Applied Statistics, Vol. 37: 401­411. Rosenbaum, P. (1989a), "Optimal Matching in Observational Studies," Journal of the American Statistical Association, 84, 1024­1032. Rosenbaum, P. (1989b), "On Permutation Tests for Hidden Biases in Observational Studies: An Application of Holley's Inequality to the Savage Lattice," Annals of Statistics, Vol. 17: 643­653.

602

References

Rosenbaum, P. (1995, 2002), Observational Studies, Springer Verlag. Rosenbaum, P. (2009), Design of Observational Studies, Springer Verlag. Rosenbaum, P. (2002), "Covariance Adjustment in Randomized Experiments and Observational
Studies," Statistical Science, Vol. 17(3): 286­304. Rosenbaum, P., and D. Rubin, (1983a), "The Central Role of the Propensity Score in Observational
Studies for Causal Effects," Biometrika, Vol. 70: 41­55. Rosenbaum, P., and D. Rubin, (1983b), "Assessing the Sensitivity to an Unobserved Binary Covariate
in an Observational Study with Binary Outcome," Journal of the Royal Statistical Society, Series B, Vol. 45: 212­218. Rosenbaum, P., and D. Rubin, (1984), "Reducing the Bias in Observational Studies Using Subclassification on the Propensity Score," Journal of the American Statistical Association, Vol. 79: 516­524. Rosenbaum, P., and D. Rubin, (1985), "Constructing a Control Group Using Multivariate Matched Sampling Methods that Incorporate the Propensity Score," American Statistician, Vol. 39: 33­38. Rubin, D. B. (1973a), "Matching to Remove Bias in Observational Studies," Biometrics, Vol. 29: 159­183. Rubin, D. B. (1973b), "The Use of Matched Sampling and Regression Adjustments to Remove Bias in Observational Studies," Biometrics, Vol. 29: 185­203. Rubin, D. B. (1974), "Estimating Causal Effects of Treatments in Randomized and Non-randomized Studies," Journal of Educational Psychology, Vol. 66: 688­701. Rubin, D. B. (1975), "Bayesian Inference for Causality: The Importance of Randomization," Proceedings of the Social Statistics Section of the American Statistical Association, 233­239. Rubin, D. B. (1976a), "Multivariate Matching Methods That Are Equal Percent Bias Reducing, I: Some Examples," Biometrics, Vol. 32(1): 109­120. Rubin, D. B. (1976b), "Multivariate Matching Methods That Are Equal Percent Bias Reducing, II: Maximums on Bias Reduction for Fixed Sample Sizes," Biometrics, Vol. 32(1): 121­132. Rubin, D. B. (1976c), "Inference and Missing Data," Biometrika, (with discussion and reply), Vol. 63(3): 581­592. Rubin, D. B. (1977), "Assignment to Treatment Group on the Basis of a Covariate," Journal of Educational Statistics, Vol. 2(1): 1­26. Rubin, D. B. (1978), "Bayesian Inference for Causal Effects: The Role of Randomization," Annals of Statistics, Vol. 6: 34­58. Rubin, D. B. (1979), "Using Multivariate Matched Sampling and Regression Adjustment to Control Bias in Observational Studies," Journal of the American Statistical Association, Vol. 74: 318­328. Rubin, D. B. (1980a), "Discussion of "Randomization Analysis of Experimental Data in the Fisher Randomization Test" by Basu," The Journal of the American Statistical Association, Vol. 75(371): 591­593. Rubin, D. B. (1980b), "Bias Reduction Using Mahalanobis' Metric Matching," Biometrics, Vol. 36(2): 293­298. Rubin, D. B. (1986a), "Statistics and Causal Inference: Comment: Which Ifs Have Causal Answers," Journal of the American Statistical Association, Vol. 81(396): 961­962. Rubin, D. B. (1986b), "Statistical Matching Using File Concatenation with Adjusted Weights and Multiple Imputations," Journal of Business and Economic Statistics, Vol. 4(1): 87­94. Rubin, D. B. (1990a), "Formal Modes of Statistical Inference for Causal Effects," Journal of Statistical Planning and Inference, Vol. 25: 279­292. Rubin, D. B. (1990b), "Comment on Neyman (1923) and Causal Inference in Experiments and Observational Studies," Statistical Science, Vol. 5(4): 472­480. Rubin, D. B. (1998), "More Powerful Randomization-Based p-Values in Double-Blind Trials with Non-Compliance," Statistics in Medicine, Vol. 17: 371­385. Rubin, D. B. (2001), "Using Propensity Scores to Help Design Observational Studies: Application to the Tobacco Litigation," Health Services & Outcomes Research Methodology, Vol. 2: 169­188. Rubin, D. B. (2004), "Causal Inference Using Potential Outcomes: Design, Modeling, Decisions," Fisher Lecture, The Journal of the American Statistical Association, Vol. 100(469): 322­331. Rubin, D. B. (2005).

References

603

Rubin, D. B. (2006), Matched Sampling for Causal Effects, Cambridge University Press. Rubin, D. B. (2007), "The Design versus the Analysis of Observational Studies for Causal Effects:
Parallels with the Design of Randomized Trials," Statistics in Medicine, Vol. 26(1): 20­30. Rubin, D. B. (2008), "The Design and Analysis of Gold Standard Randomized Experiments. Com-
ment on `Can Nonrandomized Experiments Yield Accurate Answers? A Randomized Experiment Comparing Random to Nonrandom Assignment' by Shadish, Clark, and Steiner," Journal of the American Statistical Association, Vol. 103: 1350­1353. Rubin, D. B. (2010), "Reflections Stimulated by the Comments of Shadish (2010) and West and Thoemmes (2010)," Psychological Methods, Vol. 15(1): 38­46. Rubin, D. B. (2012), "Analyses That Inform Policy Decisions," Biometrics, Vol. 68: 671­775. Rubin, D., and E. Stuart, (2006), "Affinely Invariant Matching Methods with Discriminant Mixtures of Ellipsoidally Symmetric Distributions," Annals of Statistics, Vol. 34(4): 1814­1826. Rubin, D. B., and N. Thomas, (1992a), "Affinely Invariant Matching Methods with Ellipsoidal Distributions," Annals of Statistics, Vol. 20(2): 1079­1093. Rubin, D. B., and N. Thomas, (1992b), "Characterizing the Effect of Matching Using Linear Propensity Score Methods with Normal Distributions," Biometrika, Vol. 79(4): 797­809. Rubin, D. B., and N. Thomas, (1996), "Matching Using Estimated Propensity Scores: Relating Theory to Practice," Biometrics 52: 249-264. Rubin, D. B., and N. Thomas, (2000), "Combining Propensity Score Matching with Additional Adjustment for Prognostic Covariates," Journal of the American Statistical Association, Vol. 95(450): 573­585. Rubin, D. B., X. Wang, L. Yin, and E. Zell, (2010), "Bayesian Causal Inference: Approaches to Estimating the Effect of Treating Hospital Type on Cancer Survival in Sweden Using Principal Stratification," in A. OHagen and M. West, eds. The Handbook of Applied Bayesian Analysis, Chapter 24, pp. 679­706. Rubin, D. B., and E. Zell, (2010), "Dealing with Noncompliance and Missing Outcomes in a Randomized Trial using Bayesian Technology: Prevention of Perinatal Sepsis Clinical Trial, Soweto, South Africa," Statistical Methodology, Vol. 7(3): 338­350. Sabbaghi, A., and D. Rubin, (2014), "Comments on the Neyman-Fisher Controversy and Its Consequences," Statistical Science, Vol. 29(2): 267­284. Samii, C., and P. Aronow, (2012), "Equivalencies Between Design-Based and Regression-Based Variance Estimators for Randomized Experiments," Statistics and Probability Letters, Vol. 82: 365­370. Sekhon, J. (2004-2013), "Matching: Multivariate and Propensity Score Matching with Balance Optimization," http://sekhon.berkeley.edu/matching, http://cran.r-project.org/package=Matching. Senn, S. (1994), "Testing for Baseline Balance in Clinical Trials," Statistics in Medicine, Vol. 13: 1715­1726. Shadish, W., T. Campbell, and T. Cook, (2002), Experimental and Quasi-experimental Designs for Generalized Causal Inference, Houghton and Mifflin. Sheiner, L., and D. Rubin, (1995), "Intention-to-treat Analysis and the Goals of Clinical Trial," Clinical Pharmacology and Therapeutics, Vol. 57: 6­15. Shipley, M., P. Smith, and M. Dramaix, (1989), "Calculation of Power for Matched Pair Studies when Randomization is by Group," International Journal of Epidemiology, Vol. 18(2): 457­461. Shu, Y., G. Imbens, Z. Cui, D. F., and Z. Kadziola, (2013), "Propensity Score Matching and Subclassification with Multivalued Treatments," Unpublished Manuscript. Sianesi, B. (2001), "Psmatch: Propensity Score Matching in STATA," University College London, and Institute for Fiscal Studies. Sims, C. (1972), "Money, Income and Causality," American Economic Review, Vol. 62(4): 540-552. Smith, J. A., and P. E. Todd, (2001), "Reconciling Conflicting Evidence on the Performance of Propensity-Score Matching Methods," American Economic Review, Papers and Proceedings, Vol. 91: 112­118. Smith, J. A., and P. E. Todd, (2005), "Does Matching Address LaLonde's Critique of Nonexperimental Estimators," Journal of Econometrics, Vol. 125(12): 305­353. Snedecor, G., and W. Cochran, (1967, 1989), Statistical Methods, Iowa State University Press.

604

References

Sommer, A., I. Tarwotjo, E. Djunaedi, K. West, A. Loeden, R. Tilden, and L. Mele, (1986), "Impact of Vitamin A Supplementation on Child Mortality: A Randomized Controlled Community Trial," Lancet, Vol. 1: 1169­1173.
Sommer, A., and S. Zeger, (1991), "On Estimating Efficacy from Clinical Trials," Statistics in Medicine, Vol. 10: 45­52.
Stigler, S. (1986), American Contributions to Mathematical Statistics in the Nineteenth Century, Arno Press.
Stock, J., and F. Trebbi, (2003),"Who Invented Instrumental Variable Regression?" Journal of Economic Perspectives, Vol. 17: 177­194.
"Student" (1923), "On Testing Varieties of Cereals," Biometrika, Vol. 15: 271­293. Tanner, M. (1996), Tools for Statistical Inference: Methods for the Exploration of Posterior
Distributions and Likelihood Functions, Springer Verlag. Tanner, M., and W. Wong, (1987),"The Calculation of Posterior Distributions by Data Augmenta-
tion," Journal of the American Statistical Association, Vol. 82(398): 528­540. Thistlewaite, D., and D. Campbell, (1960), "Regression-Discontinuity Analysis: An Alternative to
the Ex-Post Facto Experiment," Journal of Educational Psychology, Vol. 51: 309­317. Tibshirani, R. (1996), "Regression Shrinkage and Selection via the Lasso," Journal of the Royal
Statistical Society, Series B (Methodological), Vol. 58(1): 267­288. Tinbergen, J. (1930), "Bestimmung und Deutung von Angebotskurven: in Beispiel," Zietschrift fur
Nationalokonomie, 669­679. Torgerson, D., and M. Roland, (1998), "Understanding Controlled Trials: What Is Zelen's Design?"
BMJ, Vol. 316: 606. Van Der Klaauw, W. (2002), "A Regression­discontinuity Evaluation of the Effect of Financial Aid
Offers on College Enrollment," International Economic Review, Vol. 43(4): 1249­1287. Van Der Laan, M., and J. Robins, (2003), Unified Methods for Censored Longitudinal Data and
Causality, Springer Verlag. Van Der Vaart, A., (1998), Asymptotic Statistics, Cambridge University Press, Cambridge. Victora, C., J.-P. Habicht, and J. Bryce, (2004), "Evidence-Based Public Health: Moving Beyond
Randomized Trials," American Journal of Public Health, Vol. 94(3): 400­405. Waernbaum, I. (2010), "Model Misspecification and Robustness in Causal Inference: Comparing
Matching with Doubly Robust Estimation," Statistics in Medicine, Vol. 31(15): 1572­1581. Welch, B. (1937), "On the z Test in Randomized Blocks and Latin Squares," Biometrika, Vol. 29:
21­52. Wilcoxon, F. (1945), "Individual Comparisons by Ranking Methods," Biometrics Bulletin, Vol. 1(6):
80­83. Wooldridge, J. (2002), Econometric Analysis of Cross Section and Panel Data, 2nd edition, MIT
Press. Wright, P. (1928), The Tariff on Animal and Vegetable Oils, Macmillan. Wright, S. (1921), "Correlation and Causation," Journal of Agricultural Research, Vol. 20: 257-285. Wright, S. (1923), "The Theory of Path Coefficients: A Reply to Niles' Criticism," Genetics, Vol. 8:
239­255. Wu, J., and Hamada, M. (2009), Experiments, Planning, Analysis and Optimization, Wiley Series in
Probability and Statistics. Yang, S., G. Imbens, Z. Cui, D. Faries, and Z. Kadziola, (2014) "Propensity Score Matching and
Subclassification with Multi-level Treatments," unpublished manuscript. Yule, G. N. (1897), "On the Theory of Correlation," Journal of the Royal Statistical Society, 812­854. Zelen, M. (1979), "A New Design for Randomized Clinical Trials," New England Journal of
Medicine, Vol. 300: 1242­1245. Zelen, M. (1990), "Randomized Consent Designs for Clinical Trials: An Update," Statistics in
Medicine, Vol. 9: 645­656. Zhao, Z. (2004), "Using Matching to Estimate Treatment Effects: Data Requirements, Matching
Metrics and an Application," Review of Economics and Statistics, Vol. 86(1): 91­107. Zhang, J., D. Rubin, and F. Mealli, (2009), "Likelihood-Based Analysis of Causal Effects of Job-
Training Programs Using Principal Stratification," Journal of the American Statistical Association, Vol. 104(485): 166­176.

Author Index

Abadie, A., 177, 280, 431­432, 460, 540, 590 Abbring, J., 590 Althauser, R., 475 Altman, D., 30, 56 Amara, I., 134 Angrist, J., 22, 43­44, 134, 280, 540, 542­544, 547,
559, 590 Anscombe, F. J., 25 Ashenfelter, O., 280 Athey, S., 540, 590 Austin, P., 336
Baiocchi, M., 585 Baker, S., 540 Ball, S., 220, 234 Barnow, B. S., 280 Beaton, A., 220, 234 Becker, S., 280, 432 Beebee, H., 22 Bertrand, M., 5 Bitler, M., 474 Bjo¨rklund, A., 559 Black, S., 590 Bloom, H., 540 Blundell, R., 280, 590 Bogatz, G., 220, 234 Box, G., 56, 178 Breiman, L., 306 Brillinger, D. R., 25 Brooks, S., 178 Bryce, J., 134 Bu¨hlmann, P., 306­307 Busso, M., 432
Cain, G. G., 280 Caliendo, M., 22 Campbell, 22, 44, 374, 590 Card, D., 280, 402, 404, 410, 412­415, 421­424,
428­432, 585 Carlin, J., 178, 475, 585 Casella, G., 178 Cheadle, A., 234 Chermozhukov, V., 540 Clogg, C., 307 Cluff, 360­361

Cochran, W. G., 28, 31, 56, 134, 188, 213, 234, 280, 336, 358, 374, 399, 431
Connors, 361 Cook, T., 22, 30, 56, 374, 590 Cornfield, J., 24, 496­497, 500­506, 508­509 Costa-Dias, M., 280 Cox, D., 21, 26, 28, 56, 188, 234 Crump, R., 374, 495 Cui, Z., 590 Cuzick, J., 540
Davies, O., 30, 56 Dawid, P., 22, 119, 260, 520 Deaton, A., 374, 475 Dehejia, R., 143­144, 177­178, 254, 374, 399,
432, 475 DeMets, D., 30, 56 Diaconis, P., 178 Diamond, A., 431, 590 Diehr, P., 234 DiNardo, J., 432 Dixon, D., 540 Djunaedi, E., 540 Donner, A., 234 Dramaix, M., 234 Drukker, D., 280, 431­432 Du, J., 460
Edwards, R., 540 Efron, B., 114­116, 134, 460 Espindle, L., 431
Faries, D., 590 Feldman, D., 114­116, 134 Feller, W., 178 Firpo, S., 474 Fisher, L., 540 Fisher, R., 21­24, 26­27, 30, 47, 56, 93n1,
104, 374 Fraker, T., 254 Frangakis, C., 43 Frankowski, R., 540 Fraser, M., 22 Freedman, D. A., 22, 26, 113­114, 134
605

606

Author Index

Friedlander, D., 253­254 Fro¨lich, M., 432 Frumento, P., 43, 559
Gail, M. H., 82, 134 Gelbach, J., 474 Gelman, A., 22, 178, 234, 475, 585, 590 Goldberger, A., 134, 280, 590 Gosling, A., 590 Gossett, 26 Granger, C., 22 Greene, W., 559 Gu, X., 358, 431 Gueron, J., 253 Guo, S., 22 Gutman, R., 431
Haavelmo, T., 28­29, 43, 513, 539 Habicht, J.-P., 134 Hahn, J., 134, 280, 590 Hainmueller, J., 431, 590 Ham, J., 590 Hamada, M., 30, 56 Hanna, R., 84­85, 87, 94­97, 102­103 Hansen, B., 280, 431, 540 Hartigan, J., 178 Hearst, N., 543 Heckman, J., 22, 177, 280, 431, 495, 539 Heitjan, D., 432 Hendry, D., 29 Herr, J., 280, 431­432 Herson, J., 540 Hewitt, E., 178 Hill, J., 22, 234, 590 Hinkelmann, K., 234 Hirano, K., 134, 178, 280, 307, 361, 400, 561,
584, 590 Hitchcock, C., 22 Hiu, S., 560­567 Ho, D., 82, 358 Hodges, J. L., 25 Holland, P., 6, 21, 22, 540, 560 Horowitz, J., 460 Hotz, J., 177, 253, 374, 495 Hoynes, H., 474 Huber, M., 280 Hulley, S., 543 Hunter, S., 56, 213 Hunter, W., 56, 213
Ichimura, H., 22, 431, 590 Ichino, A., 280, 432, 509 Imai, K., 82, 134, 234, 336, 358, 590 Imbens, G., 43­44, 56, 82, 134, 177­178, 253, 307,
322, 336, 361, 374, 378­380, 400, 431­432, 434­436, 444t, 449, 451t, 453t, 457t, 460, 475, 482­483, 488, 491t­494t, 495, 497, 509, 540, 559, 561, 585
Jastrow, J., 26 Jin, H., 134 Jones, G., 178 Jones, R., 25 Jung, J. W., 134

Kadziola, Z., 590 Kalyanaraman, K., 590 Kane, T., 585 Kang, J., 400 Kempthorne, O., 25, 56, 82, 234 Ketel, N., 307 King, G., 134, 336, 358 Klerman, J., 253 Klopfer, S., 431 Koch, G., 134 Koepsell, T., 234 Koopmans, T., 29 Krueger, A., 22, 212, 402, 404, 410, 412­415,
421­424, 428­432, 540, 590 Kuersteiner, G. M., 22
Lancaster, T., 178 Lalonde, R., 22, 143­144, 177­178, 241, 254, 280,
326­333, 462­464, 470t­471t, 468, 473­474, 495, 590 Lavy, V., 540 Leamer, E., 22 Lechner, M., 43, 280, 374, 432 Lee, D., 44, 590 Lee, M.-J., 22 Lehman, E., 25, 82, 474 Lemieux, T., 44, 590 Lesaffre, E., 134 Leuven, E., 307 Lin, W., 134 Little, R., 43, 432 Loeden, A., 540 Lorch, S., 585 Lui, K.-J., 30, 308, 540 Lynn, H., 234
McCarthy, M. D., 25 McClellan, M., 567, 585 McCrary, J., 432 McCullagh, P., 28 McCulloch, C., 234 McDonald, C., 560­567 MacKenzie, W., 26 McLanahan, S., 43, 280, 509 McNamee, R., 540 Mann, H. B., 82 Manski, C., 43, 280, 374, 474­475, 496,
503, 509 Martin, D., 234 Maynard, R., 254 Mealli, F., 43, 178, 540, 559 Meghir, C., 590 Meier, P., 30, 540 Mele, L., 540 Meng, X.-L., 178 Menzies, P., 22 Mill, J. S., 24 Mitnik, O., 374, 495 Moffitt, R., 559 Morgan, S., 22, 29, 56 Morris, C., 56 Mortenson, E., 284 Mortimer, J., 253 Morton, R., 22 Mosteller, F., 188, 212

Author Index

607

Mullainathan, S., 5 Murnane, R., 22 Murphy, 360­361
Newhouse, J. P., 567, 585 Newman, T., 543 Neyman, J., 21, 23­27, 29, 30, 57, 83
Oosterbeek, H., 307 O'Rourke, K., 26n2
Pacini, B., 43, 559 Pattanayak, C., 358 Paul, L., 59 Peace, K., 540 Pearl, J., 22 Peirce, C. S., 26 Peters, C., 431 Piantadosi, S., 82, 134 Pisani, R., 26 Pischke, S., 22, 43­44, 134, 280, 559,
590 Pitman, 25 Politis, D., 460 Porter, J., 590 Powers, D., 43, 280, 509, 540 Purves, R., 26
Quade, D., 431
Reid, C., 27, 234 Richard, J.-F., 280 Ridder, G., 134, 280, 307, 400 Ritov, Y., 280 Robb, R., 22 Robbins, P., 253­254 Robert, C., 178 Robins, J., 22, 134, 280, 399­400, 540 Roland, M., 540 Romano, J., 460 Romer, C. D., 22 Romer, D. H., 22 Rosenbaum, P., 22, 39, 43, 56, 82, 279­280,
399, 481, 496­497, 500­509, 508­509, 540, 585 Rotnitzky, A., 134, 280, 399 Rouse, C., 584 Rubin, D. B., 3, 10, 14, 21­24, 26, 29­30, 39, 43, 56, 82, 104, 144n1, 178, 180, 209, 220, 234, 263, 279­280, 284, 307, 322, 336, 358, 374, 378­379, 434­436, 444t, 449, 451t, 453t, 457t, 474­475, 482­483, 488, 491t­494t, 496­497, 500­506, 508­509; 540, 559, 561, 584 Ryan, S., 84­85, 87, 94­97, 102­103
Sandefur, G., 43, 280, 509 Sanders, S., 284 Savage, L., 178 Schenker, N., 307 Schultz, B., 307 Segnan, N., 540 Sekhon, J., 280, 431 Senn, S., 134 Shadish, W., 22, 374, 590

Shafer, J., 400 Sheiner, L., 30, 540 Shipley, M., 234 Sianesi, B., 280 Sims, C., 22 Small, D., 585 Smith, J., 22, 177, 432 Smith, P., 234 Snedecor, G., 213, 234 Sommer, A., 516­517, 520­521, 528,
538­541 Spector, P., 306 Stern, H., 178, 475, 540, 585 Stewart, J., 7­8 Stigler, S., 26 Stock, J., 43, 539 Stuart, E., 134, 336, 358, 431 Sullivan, D., 280 Swinton, S,, 540
Tangen, C., 134 Tanner, M., 178, 584 Tarwotjo, I., 540 Thistlewaite, D., 44, 590 Thomas, N., 307, 358, 431­432 Tian, W., 82 Tiao, G., 178 Tibshirani, R., 306, 460 Tierney, W., 560­567 Tilden, R., 540 Tinbergen, J., 28­29, 43, 513,
539 Todd, P., 22, 177, 431, 590 Torgerson, D., 540 Trebbi, F., 43, 539 Tukey, J. W., 25
Van Den Berg, G., 590 Van Der Geer, S., 307 VanderKlaauw, W., 307, 590 Van Der Laan, M., 22 Van Dyk, D., 590 Van Voorhis, W., 431 Victora, C., 134 Vytlacil, E., 280
Waernbaum, I., 432 Wahba, S., 143­144, 177, 254, 374,
399, 432 Wang, X., 584 Weidman, L., 307 Welch, B., 25 West, K., 540 Whitney, D. R., 82 Wieand, S., 134 Willett, J., 22 Williams, K., 22 Winship, C., 22 Wong, W., 584 Wooldridge, J., 43, 431 Wright, P., 43, 539 Wright, S., 43, 513, 539 Wu, J., 30, 56 Wunsch, C., 280

608
Yang, S., 590 Yin, L., 585 Yule, G. N., 3, 27­28
Zeger, S., 516­517, 520­521, 528, 538­541

Zelen, M., 540, 560 Zell, E., 358, 584­585 Zhang, R., 178 Zhao, Z., 399, 432 Zhou, A., 178, 561, 584

Author Index

Subject Index

active treatments: assignment mechanisms and, 33­38, 41; basics of, 4, 8, 11, 13, 16­17, 19; classical randomized experiments and, 47­50, 52; Fisher exact p-values and, 59, 62, 64; instrumental variables analysis and, 514, 517, 523­525, 528, 530, 536, 539­540, 542, 569; labor market and, 246; model-based analysis and, 169­170, 569; Neyman's repeated sampling approach and, 83, 87, 105; pairwise randomized experiments and, 220­221, 225, 227; propensity score and, 282, 307; regression analysis and, 131; sampling variances and, 446; sensitivity analysis and, 500; stratified randomized experiments and, 187, 190, 211; unconfoundedness and, 266, 479, 481, 485
affine consistency, 434, 441­444 AIDS, 12 Aid to Families with Dependent Children (AFDC),
240 alwaystakers: instrumental variables analysis and,
545­546, 549­555, 562t, 563­565, 568­572, 574­579, 581, 583; model-based analysis and, 562t, 563­565, 568­572, 574­579, 581, 583 Analysis of Variance (ANOVA), 298 assignment mechanisms, xviii, 34, 589; a priori approach and, 33, 41; assumptions and, 16, 32­34, 36, 39, 42­43; attributes and, 33; balance and, 32, 42; basics of, 3, 7, 13­17, 20­21; before Neyman, 24; causal effects and, 31, 36, 42; causal estimands and, 34; classical randomized experiments and, 47­54; classification of, 31­44; completely randomized experiments and, 41; conditional independence assumption and, 43; control units and, 35, 41­42; covariates and, 20, 31­39, 42; design stage and, 32; drug treatment and, 34, 40; exclusion restrictions and, 42; Fisher exact p-values and, 58; general causal estimands and, 479­495; ignorable assignment and, 39; individualistic assignment and, 31, 37­39, 43, 259, 261­262, 316; instrumental variables analysis and, 43, 527, 567, 570; irregular, 20, 42­43; missingness and, 43; model-based analysis and, 141­143, 151­153, 156, 177, 567, 570; notation and, 32­34, 39; observation and, 31­32, 41­43; observed outcomes and, 33, 36,

41; overlap and, 314­316; pairwise randomized experiments and, 41, 221, 223, 232; populations and, 13, 33­35, 39­41; potential outcomes and, 23­24, 27­40; pre-treatment variables and, 32­33, 42; propensity score and, 35­40, 377, 380; randomized experiments and, 31­32, 35­36, 40­43; regression analysis and, 43; regular, 20, 32, 41 (see also regular assignment mechanisms); restrictions on, 37­39; samples and, 31­32, 39­40; sampling variances and, 437; sensitivity analysis and, 496, 499, 507; stratified randomized experiments and, 41­42, 191­192, 201­202; strongly ignorable treatment assignment and, 39, 43, 280; subpopulations and, 20, 35; super-populations and, 39­40; treatments and, 31­43; unbalanced, 32; unconfoundedness and, 31­32, 32, 38­43
assignment probabilities, 20; classical randomized experiments and, 52­53; classification and, 31­32, 34­37, 39, 41, 43; matching and, 402; propensity score and, 282; sensitivity analysis and, 506­507, 509; unconfoundedness and, 257­259, 273
assumptions, 6­8, 589­590; a priori approach and, 20 (see also a priori approach); assignment mechanisms and, 16, 32­34, 36, 39, 42­43; classical randomized experiments and, 53, 55; Fisher exact p-values and, 58, 62, 67­68, 74; general causal estimands and, 468­469; instrumental variables analysis and, 513­517, 520, 523­539, 542­584; labor market and, 240, 249t, 250; Lord's paradox and, 16­18, 22, 28; matching and, 337, 345­347, 401­402, 404, 405, 418, 425n6, 426; model-based analysis and, 142, 144, 148­151, 153, 155­157, 160, 163, 165­172, 175­176, 181, 560­584; Neyman's repeated sampling approach and, 84, 92, 94, 96, 98, 100­101, 104 overlap and, 309, 314, 332; pairwise randomized experiments and, 226 path diagrams and, 22; potential outcomes and, 25­26; propensity score and, 282, 284, 377­378, 383, 397­398; regression analysis and, 113, 115­116, 118­122, 126, 128, 130, 133­134; sampling variances and, 437, 452; sensitivity analysis and, 496­500, 503­506, 509; stratified

609

610

Subject Index

assumptions (cont.) randomized experiments and, 189, 194, 199­202, 204, 206, 209; SUTVA (see also stable unit treatments value assumption (SUTVA)), 3; trimming and, 359, 361, 363, 367­368; unconfoundedness and, 257­265, 272, 278­280, 479­492, 495
as-treated analysis, 515, 535­539 asymptotic distribution: Fisher's exact p-values and,
81; instrumental variables analysis and, 581; matching and, 432; model-based analysis and, 174, 581; regression analysis and, 114, 135; sampling variances and, 447; stratified randomized experiments and, 216; trimming and, 360, 363­367; unconfoundedness and, 269 asymptotic efficiency bound, 365 attributes: assignment mechanisms and, 33; instrumental variables analysis and, 516, 549­550, 553; potential outcomes and, 29; pre-treatment variables and, 15­16; propensity score and, 385 average treatment effect, 19; classical randomized experiments and, 56; common estimator structure for, 441­445; conditional, 269; Fisher's exact p-values and, 57, 63, 81; frequentist perspective and, 172­174; general causal estimands and, 461, 465, 472, 474­475; instrumental variables analysis and, 515, 521, 529­531, 534­540, 547, 553­556, 558, 560, 565, 577­578, 581­583; labor market and, 240, 245­250, 253t; local (LATE), 515, 529­531, 534­535, 538, 540, 553­554, 565, 577, 582t, 583; matching and, 337­338, 341, 346, 401­402, 404, 407, 409, 414­420, 425­430; model-based analysis and, 141­142, 146­151, 156, 163­166, 168­173, 171­172, 175t, 181­183, 185, 560, 565, 577­578, 581, 583; Neyman's repeated sampling approach and, 83­109; pairwise randomized experiments and, 219, 222, 224­233; populations and, 98­101, 454­455; propensity score and, 283, 378, 382­383, 386­399; regression analysis and, 114­134; Rosenbaum approach and, 508; sampling variances and, 433­443, 450­460; sensitivity analysis and, 508; stratified randomized experiments and, 190, 194, 201­206, 210­211, 213; super-population and, 116­117, 171­172; trimming and, 359­366; unconfoundedness and, 268­269, 272, 274, 278, 489, 492t­493t, 494, 497­508; weighting and, 441­445
balance: assignment mechanisms and, 32, 42; barbituate data and, 319­322; classical randomized experiments and, 52, 55­56; conditional, 323f­325f, 331, 332, 337; direct assessment of, 313­314; equal percentage bias reducing (epbr) methods and, 347­348; labor market and, 246; Lalonde experimental data and, 326­327; Lalonde non-experimental data and, 328­333; lottery data and, 322­326; matching and, 337­358, 401, 404, 417, 428­431; model-based analysis and, 145; multivariate distributions and, 313­314; normalized difference and, 310­315, 318, 325, 327, 339, 350, 352, 354, 356f, 358, 361­362, 368, 370,

378­379, 386, 399, 404, 428, 435, 462; overlap and, 309­333, 336; propensity score and, 282­284, 286, 294­307, 314­317, 377­382, 385, 387, 396, 399; regression analysis and, 134; stratified randomized experiments and, 191­193; subsample controls and, 339­344; trimming and, 359­374; unconfoundedness and, 258, 266­269, 273, 276­278
balancing scores, 266; coarseness of, 268; propensity score and, 265­266, 377­378, 381; unconfoundedness and, 265­266
Bayesian approach: absence of covariates and, 150­163; analytic example and, 156­163; Fisher exact p-values and, 82, 144n1; four steps of, 153­156; frequentist perspective and, 172­174; general causal estimands and, 475; imputation and, 150­163; instrumental variables analysis and, 536, 573, 576; likelihood functions and, 178; model-based analysis and, 150­163; model-based inference and, 141, 143­163, 172­174, 178, 573, 576; pairwise randomized experiments and, 232­233; propensity score and, 306; sampling variances and, 434; stratified randomized experiments and, 213; unconfoundedness and, 271
Bernoulli trials, 47­50, 53­55, 191, 507; assignment mechanism for, 49
bias: equal percentage bias reducing (epbr) methods and, 347­348; Fisher's exact p-values and, 65; instrumental variables analysis and, 513, 520­521, 530, 533­538, 543; matching and, 337, 342, 345­349, 358, 402­404, 407, 409­410, 415­432; model-based analysis and, 142, 172; Neyman's repeated sampling approach and, 83­90, 92­94, 96, 98, 101­102, 104, 108, 110, 112; overlap and, 309, 311, 318, 325, 331; pairwise randomized experiments and, 225­227, 229, 234; potential outcomes and, 25­26; propensity score and, 281, 283, 285, 306, 377­378, 380­389, 392, 395, 397t, 398­399; reduction of, 346­347, 349, 358, 378, 383­388, 431, 450; regression analysis and, 113­114, 118­119, 122, 124­125, 128, 134; sampling variances and, 434, 436, 438­439, 445­448, 450­451, 457­459; sensitivity analysis and, 497­504; stratified randomized experiments and, 187, 201­204, 206, 211­212, 217; trimming and, 360, 374; unconfoundedness and, 257, 259­260, 266­268, 270, 275, 277, 279, 479­481, 487­488, 492
blocking: classical randomized experiments and, 52; general causal estimands and, 463, 468­469, 472; matching and, 343, 401; propensity score and, 377­378, 382­383, 387, 394­396, 400; sampling variances and, 434­435, 444t, 453t; unconfoundedness and, 270, 274­275, 484, 490­491
bootstrap, 434, 453t, 456, 459­460
bounds: binary outcomes and, 500­508; efficiency, 268­270, 365; estimable parameters and, 501­502; Manski, 503; Neyman's repeated sampling approach and, 95, 101; partial identification approach and, 496; sensitivity analysis and, 496­509, 513; trimming and, 365; unconfoundedness and, 268­270

Subject Index

611

cancer, 24, 370 case-control designs, 43­44, 590 catheterization, 360­362, 368­373 causal effects, 589; assignment mechanisms and, 31,
36, 42; basics of, 3­9; Bayesian approach and, 141, 143­163, 172­174, 178, 573, 576; classical randomized experiments and, 47; in common usage, 7­8; definition of, 5­7, 21; dispersion and, 466­467; Fisher exact p-values and, 57, 62, 65, 78­79, 82; general causal estimands and, 462, 466­467, 473­474; instrumental variables analysis and, 513­517, 520, 522, 525­527, 529, 532, 535­536, 539­540, 542­544, 547­550, 554, 556­557, 559­560, 565, 577­578, 584; matching and, 337­338, 341, 358, 404, 407, 415, 421, 423, 428, 430; model-based analysis and, 141­142, 151, 153, 177­178, 560, 565, 577­578, 584; multiple units and, 3, 7­10, 21, 560­568, 578; Neyman's repeated sampling approach and, 102; overlap and, 309, 317­318, 320, 327­333, 336; post-treatment variables and, 6 (see also post-treatment variables); potential outcomes and, 14, 23­30; propensity score and, 281, 284­285, 297­298, 302, 306­307, 377­378, 382, 387, 392; pseudo, 298, 302, 479­482, 495; regression analysis and, 113, 115, 118, 126­127, 133­134; sampling variances and, 433­440; sensitivity analysis and, 496; stratified randomized experiments and, 195, 206; SUTVA and, 11 (see also stable unit treatments value assumption (SUTVA)); treatments and, 16 (see also treatments); trimming and, 359­360, 373­374; unconfoundedness and, 260­264, 268, 271, 276, 278, 479­495; unit-level, 7, 14­15, 18, 78, 126­127 causal estimands: assignment mechanism and, 34; basics of, 17­19, 21; conditional potential outcome distributions and, 468­472; covariates and, 18­19; defined, 17; dispersion and, 466­467; drug treatment and, 18; general mechanisms for, 461­475; implementation and, 472­473; inequality and, 466­467; instrumental variables analysis and, 515, 535, 561, 569­570, 574; Lord's paradox and, 16­18, 22, 28; matching and, 401; model-based analysis and, 141­142, 147­148, 152, 155, 163, 170­171, 561, 569­570, 574; Neyman's repeated sampling approach and, 84; other estimands and, 467; overlap and, 336; populations and, 18­19; potential outcomes and, 25; pre-treatment variables and, 21; quantile treatment effects and, 465­466; sensitivity analysis and, 496; stratified randomized experiments and, 208; trimming and, 370; unconfoundedness and, 262­263, 276­277, 479­480, 489 causal inference: assignment mechanism and, 13­15 (see also assignment mechanisms); attributes and, 15­16; causal effects in common usage and, 7­8; covariates and, 15­16; definition of causal effects and, 5­7; design stage and, 32; multiple units and, 3, 7­10, 21; populations and, 20­21; potential outcomes and, 3­5 (see also potential outcomes); pre-treatment variables and, 15­16; samples and, 20­21; stable unit treatments value assumption (SUTVA) and, 9­15, 21­22, 25, 33,

84, 188­189, 199, 498, 514, 516­517, 550, 589­590 causality, 589; action and, 4; assignment mechanism and, xviii; association and, xvii; basics of, 1­22; description and, xvii; inference and, xviii, 3 (see also causal inference); matching and, 401; potential outcomes and, 24; treatments and, 4 (see also treatments); unit and, 4 causal language, 3­4 Children's Television Workshop, 220­228, 231, 233t, 234 classical randomized experiments, 40: a priori approach and, 47, 51, 55; assignment mechanisms and, 40­41, 47­54; assignment probabilities and, 52­53; assumptions and, 53, 55; balance and, 52, 55­56; Bernoulli trials and, 47­50, 53­55; blocking and, 52; causal effects and, 47; classification and, 31; completely randomized experiments and, 50­56; control units and, 48­50, 55; covariates and, 47­49, 51­52, 55­56; drug treatment and, 49; estimators and, 55­56; multivariate distributions and, 313­314; notation and, 48, 50, 54; pairwise randomized experiments and, 47­48, 52­55; populations and, 47, 49, 51, 56; potential outcomes and, 47, 50­52, 55­56; pre-treatment variables and, 51­53, 55; probabilistic assignment and, 48, 53; propensity score and, 48­53; samples and, 50, 52­54, 56; stratified randomized experiments and, 47­48, 51­55; taxonomy of, 45­56; treatments and, 47­56; unconfoundedness and, 47­48, 53 completely randomized experiments: assignment mechanisms and, 41; Bernoulli trials and, 191, 507; classical randomized experiments and, 47­56; completely randomized experiments and, 21, 25; Fisher exact p-values and, 57­82; instrumental variables analysis and, 514­516, 560, 568; matching and, 337, 352; model-based analysis and, 141­186, 560, 568; Neyman's repeated sampling approach and, 21, 25­26, 83­112; overlap and, 318; pairwise randomized experiments and, 219, 223, 225­226, 228, 232, 234; potential outcomes and, 25­26; propensity score and, 282, 378, 387­388, 390; regression analysis and, 113­140; sensitivity analysis and, 498, 503, 507; stratified randomized experiments and, 187­195, 197, 201, 204, 207, 211­212; unconfoundedness and, 257, 259, 267, 270, 273­274 complier average causal effect (CACE), 515, 529, 540 compliers: instrumental variables analysis and, 515­516, 523­546, 549­559, 562t, 563­565, 569­572, 575­584; latent strata and, 515; model-based analysis and, 562t, 563­565, 569­572, 575­584 conditional average treatment effect, 269 conditional distribution: general causal estimands and, 465, 468; instrumental variables analysis and, 572­574, 578; model-based analysis and, 143, 144n1, 151­155, 157­158, 160, 163, 167­173, 176, 178, 182, 185; overlap and, 314, 316; unconfoundedness and, 261, 271, 479, 489 conditional independence assumption: assignment mechanisms and, 43; Dawid, 520; instrumental variables analysis and, 520, 568, 574;

612

Subject Index

conditional independence assumption (cont.) model-based analysis and, 568, 574; unconfoundedness and, 260, 280, 483­487
conditional mean: instrumental variables analysis and, 532; matching and, 346, 417; model-based analysis and, 162, 176; propensity score and, 302, 316; regression analysis and, 114, 117, 119, 133, 162, 176, 272, 302, 316, 346, 417, 450, 532; sampling variances and, 450; unconfoundedness and, 272
confidence intervals: instrumental variables analysis and, 521­522, 531, 547­548; labor market and, 240, 242, 245­247, 253; model-based analysis and, 142, 174; Neyman's repeated sampling approach and, 84, 87, 92­96, 102­103; overlap and, 335­336; regression analysis and, 120, 134; sampling variances and, 433, 460; stratified randomized experiments and, 187, 203­204, 227­228
control distribution, 312­313, 349 control pairs, 11 control treatments: assignment mechanisms and,
32­34, 36, 38; basics of, 4, 8, 13, 16­17; classical randomized experiments and, 47­48, 50­52; Fisher exact p-values and, 57; instrumental variables analysis and, 514, 525, 527, 530, 532, 536­537, 539, 554, 565, 569, 575; labor market and, 246; matching and, 412, 417; model-based analysis and, 147, 169­170, 565, 569, 575; Neyman's repeated sampling approach and, 83, pairwise randomized experiments and, 222, 227; potential outcomes and, 29; propensity score and, 282; sensitivity analysis and, 500; stratified randomized experiments and, 187, 192, 210­211; unconfoundedness and, 479, 485 control units: assignment mechanisms and, 35, 41­42; classical randomized experiments and, 48­50, 55; Fisher's exact p-values and, 67­69, 75­78; general causal estimands and, 469, 472; instrumental variables analysis and, 515, 583; labor market and, 246; matching and, 338, 341, 344­345, 349­350, 357, 401­411, 416, 419­421, 424­427, 431; model-based analysis and, 181, 193­198, 583; Neyman's repeated sampling approach and, 87, 90, 94, overlap and, 309, 311­313, 319, 320; pairwise randomized experiments and, 220­221, 223­224, 225t, 229, 233; potential outcomes and, 29­30; propensity score and, 282, 292­293, 302, 377, 380­385, 399; regression analysis and, 127; sampling variances and, 433­434, 441­443, 447­448, 451, 453, 459­460; sensitivity analysis and, 498; trimming and, 360­361, 368, 371t­372t, 374; unconfoundedness and, 257, 259­260, 263, 266­267, 269, 274­279, 479­481, 488, 494 counterfactuals, 5, 8, 517­518, 571 covariance matrices: Fisher's exact p-values and, 71; matching and, 342, 345, 347­348, 410, 428; model-based analysis and, 156, 165, 174, 180­186; overlap and, 314; pairwise randomized experiments and, 239; regression analysis and, 117, 122, 130, 135­136, 138­140; stratified randomized experiments and, 216­217 covariates, 590; ability to adjust for differences and, 317­318; additional linear terms and, 287; assignment mechanisms and, 20, 31­39, 42;

attributes and, 15­16; balance and, 277, 282, 296­306, 309, 316­318, 329, 336­337, 359, 380, 428­429; basic, 386­387; causal estimands and, 18­19; classical randomized experiments and, 47­49, 51­52, 55­56; distance measures and, 410­412; Fisher exact p-values and, 59, 78­80; general causal estimands and, 462­469, 472­474; imputation and, 150­163, 169­171; instrumental variables analysis and, 514­515, 526, 538, 543, 551, 556, 558, 560­583; interactions and, 125­127, 285­288; labor market and, 240, 242­243, 246­248, 250­253; limits on increases in precision and, 128­129; Lord's paradox and, 17­18; matching and, 337­358, 401­404, 407­432; model-based analysis and, 142­144, 150­151, 153­161, 169­171, 173­176, 177t, 560­583; Neyman's repeated sampling approach and, 84­85, 101­102, 104; normalized difference and, 310­315, 318, 325, 327, 339, 350, 352, 354, 356f, 358, 361­362, 368, 370, 378­379, 386, 399, 404, 428, 435, 462; overlap and, 309­336; pairwise randomized experiments and, 219­222, 229­233; populations and, 20­21; propensity score and, 282­308, 377­387, 390­399; quadratic terms and, 287­288; regression analysis and, 114­134; sampling variances and, 434­437, 440­452, 456, 460; sensitivity analysis and, 496­509; single binary, 259, 269­270, 282, 360, 362­365, 437; stratified randomized experiments and, 187, 190­191, 195; trimming and, 359­374; unconfoundedness and, 257­260, 262, 265­280, 479­494 Cowles Commission, 29 Current Population Survey (CPS), 325t, 329­335, 464t, 495
Data Augmentation (DA) methods, 574, 577, 585 Dawid conditional independence assumption, 520 defiers: instrumental variables analysis and, 542,
545­546, 549­557, 559, 563­565, 574; model-based analysis and, 563­565, 574 de Finetti's theorem, 152, 169, 178, 232, 271, 570 design phase: matching and, 337, 358; trimming and, 373; unconfoundedness and, 276­278 difference in difference (DID) methods, 43­44, 432, 590 dispersion: causal effects and, 466­467; Fisher's exact p-values and, 70­72; model-based analysis and, 141, 150, 170; overlap and, 310, 312, 314, 321; propensity score and, 394; sampling variances and, 466­467; stratified randomized experiments and, 189, 198 double-blind experiments, 515­516, 526­528, 539, 550 drug treatments: assignment mechanisms and, 34, 40; causal estimands and, 18; classical randomized experiments and, 49; drug trials, 12­13, 191, 527, 552; Fisher's exact p-values and, 59; instrumental variables analysis and, 515, 527­528, 552; Lipid Research Clinics Coronary Primary Prevention Trial (LRC-CPPT) and, 115­116, 131­133; matching and, 340t, 351t, 353t, 357t; overlap and, 319, 320t; placebos and, 11­12, 49, 115­116, 131, 528; potential

Subject Index

613

outcomes and, 12­16; propensity score and, 285t, 289t, 290, 291t, 301t, 304t­305t; regression analysis and, 115­116, 131­132, 134; Reinisch barbituate exposure data and, 284­290, 294­296, 300­306, 319­322, 325t, 338­339, 340t, 344, 345t, 349­358; stratified randomized experiments and, 191; SUTVA and, 12­15; unconfoundedness and, 262, 265 Duflo­Hanna­Ryan teacher-incentive experiment, 84­85, 87, 94­97, 102­103
empirical distribution: Fisher's exact p-values and, 66, 69, 72; general causal estimands and, 465; matching and, 339; model-based analysis and, 149t; overlap and, 312­313
equal percentage bias reducing (epbr) methods, 347­348
estimators: average treatment effect and, 441­445, 452­455; bias and, 65 (see also bias); blocking, 274­275, 382­383, 394­396, 435, 463; bootstrap, 434, 453t, 456, 459­460; classical randomized experiments and, 55­56; difference, 346, 442; efficiency bounds and, 268­270; Fisher's exact p-values and, 65, 68, 71; general causal estimands and, 463; heteroskedasticity and, 121, 125, 389, 450, 453t; homoskedasticity and, 120­121, 125, 196, 234, 341, 366­367, 398, 426, 452, 453t; instrumental variables analysis and, 515­516, 520­521, 530­531, 534­538, 541, 548, 554­556, 558, 563; internal validity and, 359, 365; least squares, 114, 118­128, 130 (see also least squares estimators); matching and, 275­276, 337, 341, 345­346, 358, 401­432, 443; mixed, 276; model-based analysis and, 147, 165, 174, 270­271, 563; moment-based, 530­531; natural, 86, 212, 219, 226, 233, 363, 402, 437­440, 458; Neyman's repeated sampling approach and, 83­84, 86­102, 104, 106­109; overlap and, 314, 336; pairwise randomized experiments and, 219, 224­227, 229­231, 233­234, 236, 239, 457­459; precision of, 55; propensity score and, 273­275, 281­282, 297, 307, 378­384, 386­400; regression, 113­114, 118­122, 124­128, 130, 132, 134­135, 137, 229, 272­274, 393, 399, 432, 442; regular, 259; sampling variances and, 121, 433­460; sensitivity analysis and, 497; simple, 56, 378, 386­387, 446­451, 530­531; strategies for, 270­276; stratified randomized experiments and, 201­207, 211­212, 216; subclassification, 382­384, 388, 394­399, 443­444, 452, 456­457, 460, 497; superpopulation limits and, 120; trimming and, 359­360, 363­366; unconfoundedness and, 257, 260, 268­277; weighting, 273­275, 378, 392­399, 432, 441­445
exclusion restrictions: alwaystakers and, 549; compliers and, 527­528 (see also compliers); defiers and, 542, 545­546, 549­553, 555­557, 559, 563­565, 574; discussion of, 528­529; instrumental variables analysis and, 515­516, 525­532, 536­540, 542, 545­546, 549­555, 558­565, 568­579, 581, 584; irregular assignment mechanisms and, 20, 42; model-based analysis and, 560­565, 568­579,

581, 584; nevertakers and, 545­546, 549­555, 562t, 563­565, 568­572, 574­575, 577­579, 581, 584; noncompliers and, 526­527; SUTVA and, 10­13 exogeneity, 43, 263, 280 Expectation Maximization (EM) algorithm, 577
finite samples, 18; assignment mechanisms and, 31; Fisher exact p-values and, 70; general causal estimands and, 465, 474; instrumental variables analysis and, 520; labor market and, 253t; matching and, 403; model-based analysis and, 141, 172, 181, 185; Neyman's repeated sampling approach and, 83, 89, 96, 98­99, 104­106; overlap and, 309; pairwise randomized experiments and, 222, 226, 232; propensity score and, 35, 297, 393; regression analysis and, 113­114, 117­118, 122, 124­125, 128; sensitivity analysis and, 498, 501; stratified randomized experiments and, 190, 201; super-populations and, 21; trimming and, 366; unconfoundedness and, 259, 269, 275; variances and, 436­437, 454­455
Fisher information matrix, 174, 180 Fisher's exact p-values: a priori approach and, 58, 70,
80; assignment mechanisms and, 58; assumptions and, 58, 62, 67­68, 74; asymptotic distribution and, 81; Bayesian approach and, 82, 144n1; bias and, 65; causal effects and, 57, 62, 65, 78­79, 82; Children's Television Workshop and, 222­224; choice of null hypothesis and, 63­64; computation of, 75­78; control units and, 67­69, 75­78; covariance matrices and, 71; covariates and, 59, 78­80; development of, 57­58; dispersion and, 70­72; drug treatment and, 59; empirical distribution and, 66, 69, 72; honey study and, 59­63, 67, 70, 74­77, 80­81; instrumental variables analysis and, 540; interval estimation and, 58, 74­75, 82; J strata case and, 196­197; Kolmogorov-Smirnov statistic and, 69­70, 81; labor market and, 240, 242­244, 243t, 249, 253; least squares estimators and, 68, 79; maximum likelihood and, 68­69, 72; Mahalanobis metric and, 71; model-based analysis and, 68­69, 82, 142; multiple components and, 70­71; Neyman's repeated sampling approach and, 83, 85, 102, 104; normal distribution and, 66, 69, 73; notation and, 57; observation and, 67, 74, 75t, 80; observed outcomes and, 57­58, 60­61, 64, 67­68, 70, 75t, 78, 80; observed value and, 58, 62t, 68, 75­78, 80; outliers and, 65­67, 72­73; pairwise randomized experiments and, 220, 222­224, 233; populations and, 61, 72; post-treatment variables and, 80; potential outcomes and, 17, 57­80, 83; pre-treatment variables and, 57, 64, 78­79, 81; Project Star and, 197­201; propensity score and, 297; quantiles and, 66; randomization distribution and, 57­58, 62t, 63, 66, 70, 74­75, 80­81, 83; random variables and, 72; rank statistics and, 66­68; regression analysis and, 79­82, 129­130, 133t; residuals and, 82; robustness and, 66; samples and, 57, 59, 62­63, 66­72, 76­77, 81; sensitivity analysis and, 506; sharp null hypothesis and, 57­83, 93, 189, 192,

614

Subject Index

Fisher's exact p-values: a priori approach and (cont.) 195, 240, 337; simulation and, 58, 72­74, 77t; small simulation study and, 72­74; statistical power and, 58, 64, 80; stochastic assignment vector and, 57­58; stratified randomized experiments and, 188­201; subsamples and, 66; test statistic and, 57­81; transformations and, 65; treatments and, 57­82; two strata case and, 192­196; typical effect and, 57; Wilcoxon rank sum test and, 67, 82
frequentist perspective, 172­174 F-statistic, 249, 298­300
general causal estimands: assumptions and, 468­469; Bayesian approach and, 475; blocking and, 463, 468­469, 472; causal effects and, 462, 466­467, 473­474; conditional distribution and, 465, 468; control units and, 469, 472; covariates and, 462­469, 472­474; empirical distribution and, 465; estimators and, 463; Gini coefficient and, 466­467, 474; implementation and, 472­473; imputation and, 461­462, 475; inequality and, 461, 466­467, 474; marginal distribution and, 464, 467; model-based analysis and, 461, 467­468, 474; multiple block, 469, 472; National Supported Work (NSW) job-training data and, 462­465, 470t­471t, 473­474; normal distribution and, 468; normalized difference and, 462; observed outcomes and, 464; other estimands and, 467; outliers and, 466; populations and, 465­467, 473­474; posterior distribution and, 467, 469, 472­473; potential outcomes and, 461­474; pre-treatment variables and, 461, 468; prior distribution and, 468, 472; propensity score and, 462­463, 469; quantile treatment effects and, 465­466; randomized experiments and, 467; regression analysis and, 461­463, 468; robustness and, 466; samples and, 462, 464­474; single block, 468­469; standard deviation and, 466, 472; statistical model and, 472; subclassification and, 464t; subsamples and, 462, 472­473; super-populations and, 465, 473­474; treatments and, 461­469, 472­475; unconfoundedness and, 468; weighting and, 462
general equilibrium, 11 Gini coefficient, 466­467, 474 gross domestic product (GDP), 22
heteroskedasticity, 121, 125, 389, 450, 453t homoskedasticity, 120­121, 125, 196, 234, 341,
366­367, 398, 426, 452, 453t honey study, 59­63, 67, 70, 74­77, 80­81 Horvitz-Thompson estimators, 282, 378, 379t,
392­400, 443
ignorable treatment assignment, 39 imputation: analytic example and, 156­163; Bayesian
approach and, 150­163; covariates and, 150­163, 169­171; de Finetti's theorem and, 152, 169, 178; estimators and, 270­271; general causal estimands and, 461­462, 475; instrumental variables analysis and, 530, 560, 577, 581; labor market and, 251t, 252­253; matching and, 338; missing outcomes and, 160­161; model-based analysis and, 141,

146­163, 164t, 169­171, 177, 187­188, 209, 220, 231, 251t, 252, 270­271, 275­276, 309, 338, 387, 461, 560, 577, 581; naive approaches to, 146­150; overlap and, 309; pairwise randomized experiments and, 220, 231; propensity score and, 378, 387; regression analysis and, 113, 126­127; sampling variances and, 434, 451; sophisticated approaches to, 146­150; stratified randomized experiments and, 187­189, 209; SUTVA violations and, 188; unconfoundedness and, 270­271, 273, 275­276 incentives: Duflo­Hanna­Ryan teacher-incentive experiment and, 84­85, 87, 94­97, 102­103; instrumental variables analysis and, 540, 550, 552 individualistic assignment: definition of, 38; overlap and, 316; as restriction, 37­39, 43; unconfoundedness and, 259, 261­262 inequality: general causal estimands and, 461, 466­467, 474; trimming and, 367­368 influenza vaccination data, 560­567, 578­583 instrumental variables analysis: alwaystakers and, 545­546, 549­555, 562t, 563­565, 568­572, 574­579, 581, 583; Angrist study and, 543­544, 547; assignment mechanisms and, 43, 527, 567, 570; assignment vs. receipt effects and, 513, 516, 527, 538; assumptions and, 513­517, 520, 523­539, 542­584; as-treated analysis and, 515, 535­539; asymptotic distribution and, 581; average treatment effect and, 515, 521, 529­531, 534­540, 547, 553­556, 558, 560, 565, 577­578, 581­583; Bayesian approach and, 536, 573, 576; behavioral equation and, 532; bias and, 513, 520­521, 530, 533­538, 543; causal effects and, 513­517, 520, 522, 525­527, 529, 532, 535­536, 539­540, 542­544, 547­550, 554, 556­557, 559­560, 565, 577­578, 584; causal estimands and, 515, 535, 561, 569­570, 574; completely randomized experiments and, 514­516, 560, 568; compliance status and, 522­526, 544­546; compliers and, 515­516, 523­546, 549­559, 562t, 563­565, 569­572, 575­584; conditional distribution and, 572­574, 578; conditional independence assumption and, 520, 568, 574; conditional mean and, 532; conditioning and, 265­266; confidence intervals and, 521­522, 531, 547­548; control units and, 515, 583; covariates and, 514­515, 526, 538, 543, 551, 556, 558, 560­583; data augmentation (DA) methods and, 574, 577, 585; defiers and, 542, 545­546, 549­557, 559, 563­565, 574; double-blind experiments and, 515­516, 526­528, 539, 550; estimators and, 515­516, 520­521, 530­531, 534­538, 541, 548, 554­556, 558, 563; exclusion restrictions and, 515­516, 525­532, 536­540, 542, 549­553, 558­560, 562t, 563, 568­569, 572, 574­575, 579, 584; Expectation Maximization (EM) algorithm and, 577; Fisher's exact p-values and, 540; imputation and, 530, 560, 577, 581; incentives and, 540, 550, 552; influenza vaccination data and, 560­567, 577­583; intention-to-treat (ITT) effects and, 514­516, 519­531, 534­541, 546­558, 562­567, 582t; latent strata and, 515; least squares estimators and, 533­534, 557­558; linear models and, 531­535; marginal

Subject Index

615

distribution and, 573; model-based analysis and, 515­516, 530, 559­584; moment-based, 530­531; monotonicity and, 542, 551­556, 559­565, 575, 579; nevertakers and, 545­546, 549­555, 562t, 563­565, 568­572, 574­575, 577­579, 581, 583­584; noncompliers and, 515, 532­533, 536­539, 544­545, 553­555, 559, 569, 572, 579; OLS estimators and, 534, 558; one-sided noncompliance and, 513­541; per protocol, 514, 535­540; potential outcomes and, 513, 516­517, 520, 522­525, 528, 530, 532­534, 539­540, 545­546, 549, 553­554, 557, 559­560, 563­583; pre-treatment variables and, 527, 538, 546­547, 561, 567; principal stratification and, 514; randomization distribution and, 520­521; regression analysis and, 532­534, 557­558, 565­566, 578; robustness and, 578; sampling variances and, 520­521, 530­531, 541, 547­548; simulation and, 561, 566, 572, 574­577; Sommer­Zeger dataset and, 516­517, 520­521, 528, 538­541; stable unit treatment value assumption (SUTVA) and, 514, 516­517, 550, 589­590; statistical model and, 560, 581; stochastic treatments and, 526­527, 551, 553, 568, 577; subsamples and, 518, 527, 541, 561; traditional economic methods and, 556­558; two-sided noncompliance and, 542­559; unconfoundedness and, 513­516, 520­521, 525­526, 530, 534­539, 543, 547, 567, 572, 584; vitamin supplements and, 516­517, 520­521, 528, 538­541 intention-to-treat (ITT) effects: cholesterol data and, 131; compliance status and, 522­526; estimands for, 519­520; instrumental variables analysis and, 514­516, 519­531, 534­541, 546­558, 561­567, 582t; model-based analysis and, 561­567, 582t; outcome of interest and, 521­522; random assignment and, 520; receipt of treatment and, 520­521, 524; regression analysis and, 131 internal validity, 359, 365 interval estimators: Fisher's exact p-values and, 58, 74­75, 82; model-based analysis and, 142; Neyman's repeated sampling approach and, 83­84, 87, 102­103; sampling variances and, 436; stratified randomized experiments and, 213 irregular assignment mechanisms, 20, 42­43 It's a Wonderful Life (film), 7­8
Journal of the Royal Statistical Society, 104
kernel smoothing, 306, 432 Kolmogorov­Smirnov statistic, 69­70, 81
lasso method, 303­306 latent strata, 515, 590 least squares estimators: Fisher's exact p-values and,
68, 79; instrumental variables analysis and, 533­534, 557­558; labor market and, 247­249; matching and, 404, 418, 420, 428­430; model-based analysis and, 173, 179; ordinary (OLS), 28, 113, 118, 127, 135, 173, 205, 389, 404, 418, 428, 534, 558; pairwise randomized experiments and, 230­231; potential outcomes and, 28; propensity score and, 387­393,

397­398; regression analysis and, 113­114, 118­130, 134­135; sampling variances and, 435­436, 442, 444, 456­459; stratified randomized experiments and, 205­207, 214; unconfoundedness and, 272 likelihood: classical randomized experiments and, 56; Fisher's exact p-values and, 68­69, 72; instrumental variables analysis and, 568, 573­577, 580­583; maximum likelihood estimation and, 68­69, 72, 173­174, 180, 286, 307­308, 576­577, 581­583; model-based analysis and, 154, 158­159, 166­167, 172­174, 178, 180­183, 568, 573­577, 580­583; propensity score and, 284­290, 307­308; trimming and, 368 Lipid Research Clinics Coronary Primary Prevention Trial (LRC-CPPT), 115­116, 131­133 local average treatment effect (LATE), 515, 529­531, 534­535, 538 Lord's paradox, 16­18, 22, 28 lung cancer, 24, 370
Mahalanobis metric: Fisher's exact p-values and, 71; matching and, 338­339, 342, 344­358, 410­412, 427­430; overlap and, 314; sampling variances and, 448
manipulation, 3­5, 7, 21, 263, 524. See also treatments
marginal distribution: general causal estimands and, 464, 467; instrumental variables analysis and, 573; model-based analysis and, 153­154, 157­158, 160, 169­170, 573; overlap and, 314, 316; trimming and, 367; unconfoundedness and, 269­270
Markov­Chain­Monte Carlo (MCMC) methods, 142­143, 178­179, 213, 469, 472
matching: approximate, 447­449; a priori approach and, 338, 341, 343, 409, 412; assignment probabilities and, 402; assumptions and, 337, 345­347, 401­402, 404, 405­409, 418, 425n6, 426; asymptotic distribution and, 432; balance and, 337­358, 401, 404, 417, 428­431; bias and, 337, 342, 345­349, 358, 402­404, 407, 409­410, 415­432; blocking and, 343, 401; caliper methods and, 344; causal effects and, 337­338, 341, 358, 404, 407, 415, 421, 423, 428, 430; causal estimands and, 401; causality and, 401; completely randomized experiments and, 337, 352; conditional mean and, 346, 417; control distribution and, 349; covariance matrices and, 342, 345, 347­348, 410, 428; covariates and, 337­358, 401­404, 407­432; design phase and, 337, 358; distance measures and, 410­412; drug treatment and, 340t, 351t, 353t, 357t; equal percentage bias reducing (epbr) methods and, 347­348; estimators and, 275­276, 337, 341, 345­346, 358, 401­432, 443; exact, 275, 405­408, 410, 415; full sample and, 427­428; hybrid methods for, 343; imputation and, 338; inexact, 403, 407­410, 412, 415, 434; kernel, 432; least squares estimators and, 404, 418, 420, 428­430; Mahalanobis metric and, 338­339, 342, 344­358, 410­412, 427­430; model-based analysis and, 337­338; multiple, 403, 425, 432, 450­451; normalized difference and, 339, 350,

616

Subject Index

matching: approximate (cont.) 352, 354, 356f, 358, 404, 428; number of matches and, 425­427; overlap and, 309, 321, 336; pairwise randomized experiments and, 219, 234, 402, 406­407, 409­410, 425; populations and, 338, 346, 407­408, 415­416, 426­427, 431; post-treatment variables and, 415; potential outcomes and, 338, 343, 401­402, 404, 407, 409, 412, 415­417, 419, 421; pre-treatment variables and, 338, 401­402, 405, 411, 415­416, 418, 424; propensity score and, 337­359, 361, 374, 383, 404­405, 409­410, 416­417, 431­432; randomized experiments and, 337, 341, 343, 349, 352, 402­403, 407, 409; regression analysis and, 346, 404, 416­424, 427­428, 430­432; Reinisch barbituate exposure data and, 338­339, 340t, 344, 345t, 349­358; rejecting poor quality matches, 343­354; replacement and, 277, 338­339, 344, 403, 405­410, 412­414, 420, 422t, 424­425, 427­431, 436, 457­458; residuals and, 418; robustness and, 337­338, 341, 349, 430­432; samples and, 337­358, 401­421, 424­431; sampling variances and, 341, 402­403, 407, 409, 424, 426, 428, 431, 434­436, 443­444, 446­447, 449­450, 452­460; sharp null hypothesis and, 337; simulation and, 432, 434, 460; standard deviation and, 339, 350, 356; super-populations and, 407, 415­416, 426; theoretical properties of, 345­349; treatments and, 343, 345­350, 352, 358, 401­432; unconfoundedness and, 270, 273, 275­277, 341, 346, 361, 401­402, 404, 407, 409, 484; weighting and, 343, 432
minimum wage, 402, 404­405, 412­415, 420, 428­432
missingness, 43 model-based analysis: alwaystakers and, 562t,
563­565, 568­572, 574­579, 581, 583; analytic example and, 156­163; a priori approach and, 144n1, 175, 571, 576; assignment mechanisms and, 141­143, 151­153, 156, 177, 567, 570; assumptions and, 142, 144, 148­151, 153, 155­157, 160, 163, 165­172, 175­176, 181, 560­584; asymptotic distribution and, 174, 581; average treatment effect and, 141­142, 146­151, 156, 163­166, 168­173, 175t, 181­183, 185, 560, 565, 577­578, 581, 583; balance and, 145; Bayesian approach and, 141, 143­163, 172­174, 178, 573, 576; bias and, 142, 172; causal effects and, 141­142, 151, 153, 177­178, 560, 565, 577­578, 584; causal estimands and, 141­142, 147­148, 152, 155, 163, 170­171, 561, 569­570, 574; completely randomized experiments and, 141­186, 560, 568; compliers and, 562t, 563­565, 569­572, 575­584; conditional distribution and, 143, 144n1, 151­155, 157­158, 160, 163, 167­173, 176, 178, 182, 185, 572­574, 578; conditional independence assumption and, 568, 574; conditional mean and, 162, 176; confidence intervals and, 142, 174; control units and, 181, 583; covariance matrices and, 156, 165, 174, 180­186; covariates and, 142­144, 150­151, 153­161, 169­171, 173­176, 177t, 560­583; data augmentation (DA) methods and, 574, 577, 585; defiers and, 563­565, 574; de Finetti's theorem and, 152, 169, 178; derivations

for, 572­574; dispersion and, 141, 150, 170; empirical distribution and, 149t; estimators and, 147, 165, 174, 270­271, 563; exclusion restrictions and, 560, 562t, 563, 568­569, 572, 574­575, 579, 584; Expectation Maximization (EM) algorithm and, 577; finite samples and, 141, 172, 181, 185; Fisher's exact p-values and, 68­69, 82, 142; frequentist perspective and, 172­174; Gaussian distributions and, 152, 156, 159­160; general causal estimands and, 461, 467­468, 474; imputation and, 141, 146­163, 164t, 169­171, 177, 187­188, 209, 220, 231, 251t, 252, 270­271, 275­276, 309, 338, 387, 461, 560; influenza vaccination data and, 560­567, 577­583; inputs into, 152­153, 570­574; instrumental variables analysis and, 515­516, 530, 559­584; intention-to-treat (ITT) effects and, 562­567, 582t; interval estimators and, 142; joint distribution and, 143, 151­158, 160, 163, 165­167, 169­177, 560, 570­574, 582; least squares estimators and, 173, 179; likelihood and, 154, 158­159, 166­167, 172­174, 178, 180­183, 568, 573­577, 580­583; marginal distribution and, 153­154, 157­158, 160, 169­170, 573; matching and, 337­338, 403, 416­417; monotonicity and, 560­565, 575, 579; nevertakers and, 562t, 563­565, 568­572, 574­575, 577­579, 581, 583­584; Neyman's repeated sampling approach and, 141­142, 144n1, 169, 171, 175, 560, 565­567; overlap and, 309, 336; pairwise randomized experiments and, 220, 231­234; posterior distribution and, 144, 151­155, 158­163, 166­167, 170­172, 176­180, 183, 185, 561, 566, 570, 572­583; potential outcomes and, 141­157, 160, 163­177, 181­182, 185, 560, 563­583; pre-treatment variables and, 142, 561, 567; prior distribution and, 143­144, 152, 154­156, 158­160, 163, 166­167, 170­172, 174­176, 178­183, 185, 565-y567, 572­573, 576­577, 579­582; Project Star and, 209­211; random variables and, 141, 144, 151, 173, 179­180, 182; regression analysis and, 114, 134, 141­142, 173, 175, 179­180, 565­566, 578; regular assignment mechanisms and, 153, 567; robustness and, 142, 152, 156, 578; sampling variances and, 172, 450; simulation and, 142­144, 152, 163­165, 171, 176­180, 561, 566, 572, 574­577; stable unit treatment value assumption (SUTVA) and, 589­590; stochastic treatments and, 141­142, 162, 568, 577; stratified randomized experiments and, 187­188, 207­212; super-population and, 171­172; Taylor series and, 174; treatments and, 141­142, 145­151, 155­156, 162­166, 168-y178, 181­183, 185, 560­569, 575, 577­584; trimming and, 366­367, 378, 385, 387; two-sided noncompliance and, 560­584; unconfoundedness and, 270­271, 275­276, 484, 567, 572, 584 monotonicity: description of, 551­553; instrumental variables analysis and, 542, 551­556, 559­565, 575, 579; model-based analysis and, 560­565, 575, 579; as no-defier assumption, 542; relaxing condition of, 555­556; traditional economic methods and, 556­558

Subject Index

617

multiple units: basics of, 3, 7­10, 21; causal effects and, 3, 7­10, 21, 560­568, 578; Neyman's repeated sampling approach and, 87­92; populations and, 560­568, 578; stable unit treatments value assumption (SUTVA) and, 9­15, 21­22, 25, 33, 84, 188­189, 199, 498, 514, 516­517, 550
National Supported Work (NSW) job-training data: general causal estimands and, 462­465, 470t­471t, 473­474; model-based analysis and, 144­150, 156, 164t, 174­177, 324f, 328, 330­335, 463t­464t, 470t­471t; overlap and, 324f, 328, 330­335
nevertakers: instrumental variables analysis and, 545­546, 549­555, 562t, 563­565, 568­572, 574­575, 577­579, 581, 583­584; model-based analysis and, 562t, 563­565, 568­572, 574­575, 577­579, 581, 583­584
Neyman's repeated sampling approach: a priori approach and, 96, assumptions and, 84, 92, 94, 96, 98, 100­101, 104, 110; bias and, 83­90, 92­94, 96, 98, 101­102, 104, 108, 110, 112; bounds and, 95, 101; causal effects and, 102; causal estimands and, 84; Children's Television Workshop and, 224­228; completely randomized experiments and, 21, 25­26, 83­112; confidence intervals and, 84, 87, 92­96, 102­103; control units and, 87, 90, 94, covariates and, 84­85, 101­102, 104; development of, 83­84; Duflo-Hanna-Ryan teacher-incentive experiment and, 84­85, 87, 94­97, 102­103; estimators and, 83­84, 86­102, 104, 107­109; Fisher's exact p-values and, 63, 83, 85, 102; inference for average treatment effects and, 98­101; instrumental variables analysis and, 520, 530, 547­548, 551, 560, 565­567; interval estimators and, 83­84, 87, 102, 103; joint distribution and, 96; labor market and, 240, 245­247, 250, 253; model-based analysis and, 141­142, 144n1, 169, 171, 175, 560, 565­567; multiple-unit variance and, 89­92; normal distribution and, 93, 96; notation and, 83; null hypothesis and, 83, 93, 97­98, 102, 104, 551; observation and, 92; outliers and, 98; pairwise randomized experiments and, 219­220, 224­228, 233; populations and, 83­86, 89­90, 92­94, 110n2; post-treatment variables and, 85t, 103t; potential outcomes and, 85­96, 99­100, 106, 108; pre-treatment variables and, 85t, 102, 103t; Project Star and, 203­205; propensity score and, 297, 377, 388­390; pseudo-outcomes and, 102; randomization distribution and, 83­84, 86­88, 96, 99­100, 102, 106­107; random variables and, 88, 105; regression analysis and, 113­114, 121, 134; sampling variances and, 84, 87­104, 105­109, 438­439; sensitivity analysis and, 498; stable unit treatment value assumption (SUTVA) and, 84, 188; standard deviation and, 85; stochastic treatments and, 84, 99; stratified randomized experiments and, 187­189, 193, 201­205, 213; test statistics and, 97; treatments and, 83­112; trimming and, 363; two strata case and, 201­203; two-unit variance and, 87­89; unconfoundedness and, 259
noncompliance. See instrumental variables analysis

normalized difference: general causal estimands and, 462; matching and, 339, 350, 352, 354, 356f, 358, 404, 428; overlap and, 310­315, 318, 325, 327; propensity score and, 378­379, 386, 399; sampling variances and, 435; trimming and, 361­362, 368, 370
normalized rank, 67, 195, 221t, 242 notation: assignment mechanisms and, 32­34, 39;
classical randomized experiments and, 48, 50, 54; Dawid and, 119, 260, 520; Fisher exact p-values and, 57; Holland and, 21; instrumental variables analysis and, 516­518, 520, 524, 542, 569, 571, 575; Lord's paradox and, 17; matching and, 344, 346, 406, 409, 418, 425; model-based analysis and, 151, 569, 571, 575; Neyman and, 21, 25­26, 27, 30, 57, 83; observed outcomes and, 27­28; observed value and, 13, 30; pairwise randomized experiments and, 220­221; potential outcomes and, 23­30; propensity score and, 282, 381; regression analysis and, 114, 117, 119, 122; sampling variances and, 445; sensitivity analysis and, 503; stratified randomized experiments and, 190, 192, 199, 205, 209; unconfoundedness and, 260, 268, 483, 485 null hypothesis: Fisher's exact p-values and, 57­64, 66, 68­72, 74­81, 551; labor market and, 242­243, 249; Neyman's repeated sampling approach and, 83, 93, 97­98, 102, 104, 551; overlap and, 311; pairwise randomized experiments and, 223­224; propensity score and, 285, 287­288, 295, 298­302, 381­382, 385; regression analysis and, 130­133, 139; sensitivity analysis and, 500, 506­507; sharp, 57 (see also sharp null hypothesis); stratified randomized experiments and, 189, 195­201, 214; SUTVA and, 22; unconfoundedness and, 278, 480­481, 485­486, 495
observational study, 41 observed outcomes: assignment mechanisms and, 33,
36, 41; average, 15, 147­148, 192­193, 259, 437, 498, 536; Fisher's exact p-values and, 57­58, 60­61, 64, 67, 70, 75t, 78, 80; general causal estimands and, 464; instrumental variables analysis and, 516­517, 536, 554­556, 569, 573; labor market and, 243; matching and, 401, 415­416, 418­420, 422; model-based analysis and, 141, 147­150, 158, 162, 164t, 167, 176, 181, 569, 573; notation and, 27­28; pairwise randomized experiments and, 223­224, 225t, 229, 232­233; potential outcomes and, 23­24, 27­29; real world and, 7­8; regression analysis and, 113­114, 116, 118­119, 122, 127, 132; sampling variances and, 433­434, 437, 441, 450, 453, 460; sensitivity analysis and, 498; stratified randomized experiments and, 192­193, 195­197; SUTVA and, 13; unconfoundedness and, 259­261, 482 ordinary least squares (OLS) estimators: instrumental variables analysis and, 534, 558; matching and, 404, 418, 428; model-based analysis and, 173; potential outcomes and, 28; propensity score and, 389; regression analysis and, 113, 118, 127, 135; stratified randomized experiments and, 205 outliers: Fisher's exact p-values and, 65­67, 72­73; general causal estimands and, 466; Neyman's

618

Subject Index

outliers (cont.) repeated sampling approach and, 98; pairwise randomized experiments and, 223­224; stratified randomized experiments and, 198
overlap: ability to adjust for differences and, 317­318; a priori approach and, 313, 325, 326, 336; assignment mechanisms and, 314­316; assumptions and, 309, 314, 332; balance and, 309­333, 336; barbituate data and, 319­322; bias and, 309, 311, 318, 325, 331; causal effects and, 309, 317­318, 321, 327­333, 336; causal estimands and, 336; completely randomized experiments and, 318; conditional distribution and, 314, 316; confidence intervals and, 335­336; control distribution and, 312­313; control units and, 309, 311­313, 319, 321; covariance matrices and, 314; covariates and, 309­336; dispersion and, 310, 312, 314, 321; drug treatment and, 319, 320t; empirical distribution and, 312­313; estimators and, 314, 336; imputation and, 309; individualistic assignment and, 316; lack of, 332­336; Lalonde experimental data and, 326­327; Lalonde non-experimental data and, 328­333; lotteries and, 322­328; Mahalanobis metric and, 314; marginal distribution and, 314, 316; matching and, 309, 321, 336; model-based analysis and, 309, 336; National Supported Work (NSW) job-training data and, 324f, 328, 330­335; normal distribution and, 323f­325f; normalized difference and, 310­315, 318, 325, 327; null hypothesis and, 311; observation and, 310­312, 318; populations and, 309­317, 321, 325, 328, 332­333; post-treatment variables and, 325; potential outcomes and, 312­313, 334; pre-treatment variables and, 313, 319, 326­327, 330; propensity score and, 309­310, 314­334; randomized experiments and, 309, 312, 318, 328, 332; regression analysis and, 309, 311, 325, 331, 332­337; Reinisch barbituate exposure data and, 318­322, 325t; robustness and, 310, 317; samples and, 309­319, 325, 326, 329, 333, 336; standard deviation and, 312­313, 315, 318­321, 331; subclassification and, 309, 336; subpopulations and, 310, 316, 321, 333; subsamples and, 309­312, 326, 332, 336; test statistics and, 311, 366; treatments and, 309­311, 313­322, 325­336; unconfoundedness and, 309­310, 314, 316, 321, 332; z-values and, 321
pairwise randomized experiments: a priori approach and, 219; assignment mechanisms and, 41, 221, 223, 232; assumptions and, 226, Bayesian approach and, 232­233; bias and, 225­227, 229, 234; Children's Television Workshop and, 220­228, 231, 233t, 234; classical randomized experiments and, 47­48, 52­55; completely randomized experiments and, 219, 223, 225­226, 228, 232, 234; control units and, 221, 223­224, 225t, 229, 233; covariance matrices and, 239; covariates and, 219­222, 229­233; estimators and, 219, 224­227, 229­231, 233­234, 236, 239, 457­459; finite samples and, 222, 226, 232; Fisher's exact p-values and, 220, 222­224, 233; imputation and, 220, 231; joint distribution and, 231­232; least squares estimators and, 230­231;

matching and, 219, 234, 402, 406­407, 409­410, 425; model-based analysis and, 220, 231­234; Neyman's repeated sampling approach and, 219­220, 224­228, 233; notation and, 220­221; null hypothesis and, 223­224; observed outcomes and, 223, 225t, 229, 232­233; outliers and, 223­224; populations and, 219­220, 229­232; posterior distribution and, 232­233; potential outcomes and, 219­224, 228­232; pre-treatment variables and, 221, 233; randomization distribution and, 223, 225­226, 229­230; regression analysis and, 220, 229­234, 240­241, 247­249, 253­254; sampling variances and, 219, 225­228, 233­235, 457­459; simulation and, 232­233; standard deviation and, 233; stratified randomized experiments and, 212, 219­221, 226, 229, 231, 233­234; super-populations and, 230, 232; treatments and, 219­235; unconfoundedness and, 255­265, 271, 276, 279 Panel Study of Income Dynamics (PSID), 329, 495 partial equilibrium, 11 partial identification approach. See bounds path diagrams, 22 per protocol analysis, 514, 535­540 placebos, 11­12, 49, 115­116, 131, 528 populations, 40, 589; assignment mechanisms and, 13, 33­35, 39­41; average treatment effect and, 98­101, 454­455; causal estimands and, 18­19; classical randomized experiments and, 51, 55; covariates and, 20­21 (see also covariates); Fisher exact p-values and, 61, 72; frequentist perspective and, 172­174; general causal estimands and, 465­467, 473­474; instrumental variables analysis and, 515, 518, 520­542, 545­547, 550­556, 559­568, 578; labor market and, 240, 245­247; matching and, 338, 346, 407­408, 415­416, 426­427, 431; model-based analysis and, 141­146, 171­173, 181, 185, 560­568, 578; Neyman's repeated sampling approach and, 83­86, 89­90, 92­94, 97­102, 105­106, normalized difference and, 310­315, 318, 325, 327, 339, 350, 352, 354, 356f, 358, 361­362, 368, 370, 378­379, 386, 399, 404, 428, 435, 462; observed value and, 21; overlap and, 309­317, 321, 325, 328, 332­333; pairwise randomized experiments and, 219­220, 229­232; propensity score and, 282, 291, 298, 307, 377, 383, 387, 392, 400; regression analysis and, 113­126, 130­131, 135­136, 139; sampling variances and, 433­434, 436­441, 445­448, 454­455, 459; sensitivity analysis and, 497­500, 503; stratified randomized experiments and, 191, 193, 201­207, 211­216; subpopulations and, 16 (see also subpopulations); super-populations and, 20­21, 39­40, 83, 93, 98­99, 101, 105­106, 110n2, 113­120, 122, 124; treatments and, 15­16 (see also treatments); trimming and, 359­360, 362­363, 365­366; unconfoundedness and, 257, 259­263, 266, 268­274, 277­278, 479, 482, 485, 487­489, 493t­494t, 495 posterior distribution: causal estimand and, 155­156; derivation of, 154­155, 160­163; general causal estimands and, 467, 469, 472­473; instrumental variables analysis and, 561, 566, 570, 572­583; labor market and, 250­251, 253; likelihood

Subject Index

619

functions and, 178; missing outcomes and, 155, 160­161; model-based analysis and, 144, 151­155, 158­163, 166­167, 170­172, 176­180, 183, 185, 561, 566, 570, 572­583; pairwise randomized experiments and, 232­233; stratified randomized experiments and, 207­210 post-treatment variables, 6, 14, 17; Fisher exact p-values and, 80; matching and, 415; Neyman's repeated sampling approach and, 85t, 103t; overlap and, 325; regression analysis and, 116, 131 potential outcomes, xvii­xviii, 589­590; action-unit pair and, 4; a priori approach and, 25; assignment mechanisms and, 23­24, 27­40; assumptions and, 25­26; attributes and, 29; basics of, 3­22; bias and, 25­26; causal effects and, 14, 23­30; causal estimands and, 25, 468­472; causal language and, 3­4; classical randomized experiments and, 47, 50­52, 55­56; completely randomized experiments and, 25­26; compliance status and, 524­526; control units and, 29­30; covariates and, 27­28; dependence between, 165­169; drug treatment and, 12­16; earlier hints for physical randomizing and, 26; early uses of in social sciences, 28­29; estimated associations and, 27­28; Fisher exact p-values and, 17, 26­27, 57­80, 83; general causal estimands and, 461­474; instrumental variables analysis and, 513, 516­517, 520, 522­525, 528, 530, 532­534, 539­540, 545­546, 549, 553­554, 557, 559­560, 563­583; joint distribution and, 96 (see also joint distribution); labor market and, 250, 253; least squares estimators and, 28; Lipid Research Clinics Coronary Primary Prevention Trial (LRC-CPPT) and, 115­116, 131­133; Lord's paradox and, 16­18, 22, 28; matching and, 338, 343, 401­402, 404, 407, 409, 412, 415­417, 419, 421; model-based analysis and, 141­157, 160, 163­177, 181­182, 185, 560, 563­583; multiple block, 469, 472; Neyman's repeated sampling approach and, 83­96, 99­100, 106, 108; notation and, 23­30; observation and, 3­4, 12, 23, 27­30; observed outcomes and, 23­24, 27­28, 29; observed value and, 27­28, 30; overlap and, 312­313, 334; pairwise randomized experiments and, 219­224, 228­232; propensity score and, 378, 382­384, 392, 395­396, 399; Randomized Blocks and Latin Squares and, 27; randomized experiments and, 23­30; random variables and, 3, 25; regression analysis and, 28, 30, 113­114, 116­117, 119­121, 124­130; samples and, 25­26; sampling variances and, 433­434, 445­446, 448, 450, 457; sensitivity analysis and, 496­505; simulation methods and, 163­165; single block, 468­469; stable unit treatment value assumption (SUTVA) and, 9­15, 21­22, 25, 33; statistical model and, 27, 29; stochastic treatments and, 25; stratified randomized experiments and, 192, 195, 199­200, 202, 204, 207­210, 212, 214; subpopulations and, 190; treatments and, 24­30; trimming and, 366; unconfoundedness and, 257­272, 479­483, 487, 489 pre-treatment variables, 589; assignment mechanisms and, 32­33, 42; attributes and, 15­16; causal estimands and, 21; classical randomized

experiments and, 52­53, 55; conditioning and, 265­266; Fisher exact p-values and, 57, 64, 78­79, 81; general causal estimands and, 461, 468; instrumental variables analysis and, 527, 538, 546­547, 561, 567; labor market and, 241t, 242, 247­249; matching and, 338, 401­402, 405, 411, 415­416, 418, 424; model-based analysis and, 142, 561, 567; Neyman's repeated sampling approach and, 85t, 102, 103t; overlap and, 313, 319, 326­327, 330; pairwise randomized experiments and, 221, 233; propensity score and, 281­286, 294; regression analysis and, 113, 115­117, 122, 134; robustness and, 487­490; sampling variances and, 433­435, 437­438, 440­443, 446, 451, 453­454, 456, 460; stratified randomized experiments and, 187, 189; subpopulations and, 18; trimming and, 359­362, 368, 370; unconfoundedness and, 257­266, 279, 479­484, 487­492, 494 principal stratification, 43, 134, 514, 590 prior distribution: general causal estimands and, 468, 472; instrumental variables analysis and, 565­567, 572­573, 576­577, 579­582; labor market and, 250; likelihood functions and, 178; model-based analysis and, 143­144, 152, 154­156, 158­160, 163, 166­167, 170­172, 174­176, 178­183, 185, 566­567, 572­573, 576­577, 579­582; stratified randomized experiments and, 208­210, 232­233 probabilistic assignment: classical randomized experiments and, 48; definition of, 31, 38; propensity score and, 48; as restriction, 38, 40, 43; sensitivity analysis and, 496; strongly ignorable treatment assignment and, 39; super-populations and, 40; unconfoundedness and, 257­258, 261­262, 269, 280 Project Star, 188­189, 190t, 197­199, 201, 203, 204t, 207­209, 212 propensity score, 590; additional linear terms and, 287; a priori approach and, 281, 286, 399; assignment mechanisms and, 35­40, 377, 380; assignment probabilities and, 282; assumptions and, 282, 284, 377­378, 383, 397­398; attributes and, 385; average treatment effect and, 378, 382­383, 386­399; balance and, 258, 265­268, 273, 282­284, 286, 294­307, 314­317, 377­382, 385, 387, 396, 399; balancing scores and, 266­268; Bayesian approach and, 306; bias and, 281, 283, 285, 306, 377­378, 380­389, 392, 395, 397t, 398­399; blocking and, 293­294, 377­378, 382­383, 387, 394­396, 400; causal effects and, 281, 284­285, 297­298, 302, 306­307, 377­378, 382, 387, 392; classical randomized experiments and, 48­53; completely randomized experiments and, 282, 378, 387­388, 390; conditional mean and, 302, 316; control units and, 282, 292­293, 302, 377, 380­385, 399; covariates and, 282­308, 377­387, 390­399; dispersion and, 394; drug treatment and, 285t, 289t, 290, 291t, 301t, 304t­305t; estimated, 274­278, 281­308, 315, 317, 320, 326­327, 331, 338, 341­344, 349­350, 356­357, 360, 367­369, 372­374, 377­382, 387, 392­395, 405, 409, 432, 435, 443­444, 462, 494, 506; estimators and, 273­275, 281, 297, 307, 378­384, 386­400; finite population, 35­37; Fisher's exact p-values

620

Subject Index

propensity score (cont.) and, 297; general causal estimands and, 462­463, 469; imputation and, 378, 387; interactions and, 285­288; kernel smoothing and, 306; labor market and, 254; lasso method for, 303­306; least squares estimators and, 387­393, 397­398; likelihood and, 284­290, 306­308; lotteries and, 281, 307, 378­381, 385­386, 390­392, 395­399; matching and, 337­359, 361, 374, 383, 404­405, 409­410, 416­417, 431­432; Neyman's repeated sampling approach and, 297, 377, 388­390; normal distribution and, 293, 298­303, 306t, 308; normalized difference and, 378­379, 386, 399; notation and, 282, 381; null hypothesis and, 285, 287­288, 295, 298­302, 381­382, 385; observation and, 294­295, 387, 391, 396; overlap and, 309­310, 314­334; populations and, 282, 291, 298, 307, 377, 383, 387, 392, 400; potential outcomes and, 378, 382­384, 392, 395­396, 399; pre-treatment variables and, 281­286, 294; probabilistic assignment and, 48; pseudo-outcomes and, 297­298; quadratic terms and, 287­288; randomized experiments and, 281­282, 297, 378, 381, 387­388; regression analysis and, 284, 286­288, 298, 306­308, 378, 384­385, 387­399; regular assignment mechanisms and, 377; Reinisch barbituate exposure data and, 284­290, 294­296, 300­306; residuals and, 299, 397t; robustness and, 308, 378, 389­390, 393­395, 400; samples and, 282­285, 292­293, 295, 297­298, 300, 303, 377­399; sampling variances and, 297­298, 388­390, 395­399, 435, 442­444, 460; sensitivity analysis and, 498, 506­507; simulation and, 400; specification choice and, 288­290; split blocks and, 294; standard deviation and, 285, 386, 396, 398; strata construction and, 290­295; stratified randomized experiments and, 191, 297, 381, 388; subclassification and, 295, 377­400; subpopulations and, 298, 377; subsamples and, 277­278, 282, 285, 292­293, 295, 366­368, 379, 389­390, 417, 421, 428; super-populations and, 39­40, 282, 291, 307; test statistics and, 285, 287, 293­295, 300­302, 381­382, 385; treatments and, 281­286, 291­299, 302, 307, 377­378, 381­399; trimming and, 359­374, 377­400; true, 277, 281­283, 291­292, 306­307, 314­317, 326, 337, 343, 359, 381, 387, 395, 399, 442; unconfoundedness and, 258­259, 266­270, 273­282, 284, 377, 392, 399, 491, 494; weighting and, 270, 273­275, 281­282, 378, 392­399; z-values and, 298­303, 304t­305t, 306f
pseudo-outcomes: estimating effects on, 482­485; Neyman's repeated sampling approach and, 102; propensity score and, 297­298; testing for effects on, 490­492; unconfoundedness and, 480­485, 487, 490­493, 495
pseudo treatments:; estimating effects of, 485­486; testing for effects of, 493; unconfoundedness and, 278­279, 480­482, 485­486, 493
randomized encouragement design, 540, 560 randomization distribution: instrumental variables
analysis and, 520­521; labor market and, 243t,

249; Neyman's repeated sampling approach and, 83­84, 86­88, 96, 99­100, 102, 106­107; pairwise randomized experiments and, 223, 225­226, 229­230; regression analysis and, 117; sampling variances and, 436­437; sensitivity analysis and, 507; stratified randomized experiments and, 193­194, 197­198, 200­201, 214; unconfoundedness and, 273 Randomized Blocks and Latin Squares method, 27 randomized consent design, 540, 560 randomized encouragement designs, 540 randomized experiments, 40; assignment mechanisms and, 31­32, 35­36, 40­43; causality and, 3; classical, 20, 31­32, 40 (see also classical randomized experiments); completely, 21, 25­26, 41, 47­48, 50­82 (see also completely randomized experiments); design stage and, 32; earlier hints for physical randomizing and, 26; Fisher exact p-values and, 26­27, 57­82; general causal estimands and, 467; labor market and, 241, 253; matching and, 337, 341, 343, 349, 352, 402­403, 407, 409; model-based analysis and, 141­186; Neyman's repeated sampling approach and, 83­112 (see also Neyman's repeated sampling approach); one-sided compliance and, 513­541; overlap and, 309, 312, 318, 328, 332; paired, 53; pairwise, 219­239 (see also pairwise randomized experiments); pharmaceutical approvals and, 40; potential outcomes and, 23­30; propensity score and, 281­282, 297, 378, 381, 387­388; regression analysis and, 113­140; sampling variances and, 436, 457; sensitivity analysis and, 503, 507; stratified, 52, 187­218 (see also stratified randomized experiments); two-sided compliance and, 542­584; unbalanced, 32; unconfoundedness and, 257, 259, 264, 267, 270­275, 279 random variables, 3; Fisher exact p-values and, 72; model-based analysis and, 141, 144, 151, 173, 179­180, 182; Neyman's repeated sampling approach and, 88, potential outcomes and, 3, 25; regression analysis and, 118­119; unconfoundedness and, 271 regression analysis: assignment mechanisms and, 43; assumptions and, 113, 115­116, 118­122, 126, 128, 130, 133­134; asymptotic distribution and, 114, 135; balance and, 134; bias and, 113­114, 118­119, 122, 124­125, 128, 134; causal effects and, 113, 115, 118, 126­127, 133­134; completely randomized experiments and, 113­140; conditional mean and, 114, 117, 119, 133, 162, 176, 272, 302, 316, 346, 417, 450, 532; confidence intervals and, 120, 134; control functions and, 247, 419­420, 422t­423t, 427, 432; control units and, 127; covariance matrices and, 117, 122, 130, 135­136, 138­140; covariates and, 114­134; drug treatment and, 115­116, 131­132, 134; estimators and, 113­114, 118­122, 124­128, 130, 132, 134­135, 137; finite samples and, 113­114, 117­118, 122, 124­125, 128; Fisher's exact p-values and, 79­82, 129­130, 133t; Freedman and, 113­114; full distribution and, 114, 165, 317; general causal estimands and, 461­463, 468; heteroskedasticity and, 121, 125, 389, 450, 453t; homoskedasticity and, 120­121, 125, 196,

Subject Index

621

234, 341, 366­367, 398, 426, 452, 453t; imputation and, 113, 126­127; instrumental variables analysis and, 532­534, 557­558, 565­566, 578; intention-to-treat (ITT) effects and, 131; interactions and, 125­127; joint distribution and, 116; labor market and, 247­249; least squares estimators and, 113­114, 118­130, 134­135; limiting objective function and, 123; limits on increases in precision and, 128­129; linear, 113­114, 118­128, 131, 134, 142, 173, 175, 179, 248­249, 263, 272, 298, 309, 332­334, 336­337, 346, 378, 387­390, 417, 431­432, 494, 533; Lipid Research Clinics Coronary Primary Prevention Trial (LRC-CPPT) and, 115­116, 131­133; logistic, 128, 177t, 180, 283­288, 307­308, 343, 380, 468, 504, 565­566, 571, 578; matching and, 346, 404, 416­424, 427­428, 430­432; model-based analysis and, 114, 134, 141­142, 173, 175, 179­180, 565­566, 578; Neyman's repeated sampling approach and, 113­114, 121, 134, 141; normal distribution and, 139; notation and, 114, 117, 119, 122; null hypothesis and, 130­133, 139; observation and, 113, 118, 125, 127­129, 134; observed outcomes and, 113­114, 116, 118­119, 122, 127, 132; overlap and, 309, 311, 325, 331, 332­337; pairwise randomized experiments and, 229­234, 240­241, 247­249, 253­254; parallel, 420; populations and, 113­126, 130­131, 135­136, 139; post-treatment variables and, 116, 131; potential outcomes and, 28, 30, 113­114, 116­117, 119­121, 124­130; pre-treatment variables and, 113, 115­117, 122, 134; probit, 128, 308; propensity score and, 284, 286­288, 298, 306­308, 378, 384­385, 387­399; randomization distribution and, 117; random variables and, 118­119; residuals and, 118­121; robustness and, 121, 125, 127; samples and, 113­139; sampling variances and, 113, 120­121, 124­125, 128­129, 434­436, 442­444, 450, 453t, 456; sensitivity analysis and, 504; simulation methods and, 179­180; statistical model and, 114, 128; stochastic treatments and, 116; stratified randomized experiments and, 187­189, 205­207, 213­214, 217; subpopulations and, 131; super-populations and, 113­114, 116­120, 122, 124, 126; SUTVA violations and, 188; test statistics and, 133; transformations of outcome variable and, 127­128; treatments and, 113­134; trimming and, 362; unconfoundedness and, 263, 272­274, 276­277, 280, 494 regression discontinuity designs, 43­44, 590 regular assignment mechanisms, 20, 32, 589; implications of, 258­260; individualistic factor and, 258­259; model-based analysis and, 153, 567; observation and, 41­43; propensity score and, 377; sampling variances and, 437; sensitivity analysis and, 496; super-population perspective and, 260­261; unconfoundedness and, 258­266, 276, 279, 479 Reinisch barbituate exposure data: matching and, 338­339, 340t, 344, 345t, 349­358; overlap and, 319­322, 323t, 325t; propensity score and, 284­290, 294­296, 300­306

residuals: definition of, 119; Fisher's exact p-values and, 82; instrumental variables analysis and, 532­533, 556­558; matching and, 418; propensity score and, 299, 397t; regression analysis and, 118­121; sampling variances and, 450
right heart catheterization, 360­362, 368­373 robustness, 589; Fisher's exact p-values and, 66;
general causal estimands and, 466; instrumental variables analysis and, 578; matching and, 337­338, 341, 349, 430­432; model-based analysis and, 142, 152, 156, 578; overlap and, 310, 317; pre-treatment variables and, 487­490; propensity score and, 308, 378, 389­390, 393­395, 400; regression analysis and, 121, 125, 127; trimming and, 362, 365, 370; unconfoundedness and, 260, 270, 274­277, 481­482, 487­490, 494­495 R-programs, 280 Rubin Causal Model, 21, 540, 589
Sacerdote lottery data, 322, 378­379, 434­436, 444t, 449, 451t, 453t, 457t, 482­483, 488, 491t­494t, 497
samples: assignment mechanisms and, 31­32, 39­40; classical randomized experiments and, 50, 52­54, 56; covariate balance and, 277, 282, 300­306, 309, 316­318, 329, 336­337, 359, 380, 428­429; finite, 18 (see also finite samples); Fisher exact p-values and, 57, 59, 62­63, 66­72, 76­77, 81; full, 52, 59, 81, 85, 242­246, 277, 337, 344, 349­352, 358­361, 368­373, 378­380, 383­387, 391, 395­399, 401, 404, 417, 425, 427­428, 435, 444, 452, 462, 490, 494; general causal estimands and, 462, 464­474; instrumental variables analysis and, 516­523, 527­528, 530­532, 535, 537, 541, 544, 546­548, 555, 561, 563, 572, 575, 578­583; labor market and, 240, 242­243, 245­247, 250, 253; matching and, 337­358, 401­421, 424­431; model-based analysis and, 141­142, 144­145, 162­163, 169, 171­174, 178, 180­181, 184­186, 561, 563, 572, 575, 578­583; Neyman's repeated sampling approach and, 83­112 (see also Neyman's repeated sampling approach); overlap and, 309­319, 323, 326, 329, 332, 336; pairwise randomized experiments and, 219­220, 222, 224­230, 232­235; populations and, 20­21 (see also populations); potential outcomes and, 25­26; propensity score and, 282­285, 292­293, 295, 297­298, 300, 303, 377­399; regression analysis and, 113­139; stratified randomized experiments and, 187­190, 193­194, 196­197, 200­207, 211­213, 217­218; subsamples and, 366­368 (see also subsamples); trimming and, 359­374; unconfoundedness and, 257­262, 268­279, 490­494, 497­499, 501­502, 505, 508­509
sampling variances: affine consistency and, 434, 441­444; alternative estimators for, 456­460; assignment mechanisms and, 437; assumptions and, 437, 452; asymptotic distribution and, 447; average treatment effects and, 433­445, 450­460; Bayesian approach and, 434; bias and, 434, 436, 438­439, 445­448, 450­451, 457­459;

622

Subject Index

sampling variances: affine consistency and (cont.) blocking and, 434­435, 444t, 453t; bootstrap methods and, 434, 453t, 456, 459­460; causal effects and, 433­440; classical randomized experiments and, 56; conditional, 434, 445­452; confidence intervals and, 84, 87, 92­96, 102­103, 433, 460; control units and, 433­434, 441­443, 447­448, 451, 453, 459­460; covariates and, 434­437, 440­452, 456, 460; dispersion and, 466­467; estimand choice and, 433­434, 436­441; estimation of, 92­95; estimators and, 121, 433­460; imputation and, 434, 451; instrumental variables analysis and, 520­521, 530­531, 541, 547­548; interval estimators and, 436; joint distribution and, 434, 467; labor market and, 245­246; least squares and, 435­436, 442, 444, 456­460; lotteries and, 434­436, 443­445, 449­459; Mahalanobis metric and, 448; matching and, 341, 402­403, 407, 409, 424, 426, 428, 431, 434­436, 443­444, 446­447, 449­450, 452­460; model-based analysis and, 172, 450; Neyman's repeated sampling approach and, 84, 87­104, 105­109, 438­439; normalized difference and, 435; notation and, 445; observation and, 449t, 465; observed outcomes and, 433­434, 437, 441, 450, 453, 460; pairwise randomized experiments and, 219, 225­228, 233­235, 457­459; populations and, 433­434, 436­441, 445­448, 454­455, 459; potential outcomes and, 433­434, 445­446, 448, 450, 457; pre-treatment variables and, 433­435, 437­438, 440­443, 446, 451, 453­454, 456, 460; propensity score and, 297­298, 388­390, 395­399, 435, 442­444, 460; quantile treatments and, 465­466, 473­474; randomization distribution and, 436­437; regression analysis and, 113, 120­121, 124­125, 128­129, 434­436, 442­444, 450, 453t, 456; regular assignment mechanisms and, 437; residuals and, 450; sensitivity analysis and, 498; standard deviation and, 435, 444, 451; stratified randomized experiments and, 193­194, 196, 201­204, 206­207, 211­213, 217­218; subclassification and, 443­444, 451­452, 456­457, 460; subpopulations and, 436, 438­439, 445; subsamples and, 434­438, 459­460; super-populations and, 433­441, 445­448; treatments and, 433­447, 450­460; trimming and, 360, 363­377, 451; unconfoundedness and, 268­270, 437, 445; weighting and, 441­445, 442­444
Saturation Work Initiative Model (SWIM), 240­242, 243t, 250, 253
semi-design approach, 279, 481, 485, 493 semiparametric efficiency bound, 268­270, 280 sensitivity analysis: a priori approach and, 501;
assignment mechanisms and, 496, 499, 507; assignment probabilities and, 506­507, 509; assumptions and, 496­500, 503­506, 509; average treatment effect and, 508; bias and, 497­504; binary outcomes and, 500­508; bounds and, 496­509, 513; causal effects and, 496; causal estimands and, 496; completely randomized experiments and, 498, 503, 507; control units and, 498; Cornfield­Rosenbaum­ Rubin approach and, 496­497, 500­506,

508­509; covariates and, 496­509; estimable parameters and, 501­502; estimators and, 497; Fisher's exact p-values and, 506; lotteries and, 497­498, 500, 504­508; Neyman's repeated sampling approach and, 498; notation and, 503; null hypothesis and, 500, 506­507; observation and, 496, 506; observed outcomes and, 498; observed value and, 509; overlap and, 332­336; partial identification approach and, 496; populations and, 497­500, 503; potential outcomes and, 496­505; probabilistic assignment and, 496; propensity score and, 498, 506­507; randomization distribution and, 507; randomized experiments and, 503, 507; regression analysis and, 504; regular assignment mechanisms and, 496; Rosenbaum p-value, 506­508; sampling variances and, 498, 498; sharp null hypothesis and, 506; stable unit treatment value assumption (SUTVA) and, 498; standard deviation and, 504­505, 508; subclassification and, 497; super-populations and, 497­500, 503; treatments and, 496­509; unconfoundedness and, 279, 496­500, 503­504, 506­507, 509 Sesame Street (TV series), 220 sharp null hypothesis: as exact null hypothesis, 57; Fisher's exact p-values and, 57­83, 93, 189, 192, 195, 240, 337; matching and, 337; sensitivity analysis and, 506 simulation: Fisher's exact p-values and, 58, 72­74, 77t; instrumental variables analysis and, 561, 566, 572, 574­577; labor market and, 250; logistic regression model and, 180; matching and, 432, 434, 460; model-based analysis and, 142­144, 152, 163­165, 171, 176­180, 561, 566, 572, 574­577; pairwise randomized experiments and, 232­233; propensity score and, 400 stable unit treatment value assumption (SUTVA): alternatives to, 12­13; basic framework of causal inference and, 3, 9­15, 21­22; drug treatment and, 12­15; exclusion restrictions and, 10­13; instrumental variables analysis and, 514, 516­517, 550, 589­590; Lord's paradox and, 17­18; model-based analysis and, 589­590; Neyman's repeated sampling approach and, 84; no hidden variations, 11­12; no interference, 10­11; null hypothesis and, 22; potential outcomes and, 25, 33; sensitivity analysis and, 498; stratified randomized experiments and, 199; surgery and, 14­15; treatments and, 9­15, 21­22, 25, 33, 84, 188­189, 199, 498, 514, 516­517, 550, 589­590 standard deviation: general causal estimands and, 466, 472; instrumental variables analysis and, 561, 582; labor market and, 242, 250­253; matching and, 339, 350, 356; model-based analysis and, 149­150, 155, 163, 165, 169, 172, 174­177, 561, 581­582; Neyman's repeated sampling approach and, 85; overlap and, 312­313, 315, 318­321, 331; pairwise randomized experiments and, 233; propensity score and, 285, 386, 396, 398; sampling variances and, 435, 444, 451; sensitivity analysis and, 504­505, 508; stratified randomized experiments and, 189, 209­210; trimming and, 361, 370; unconfoundedness and, 277 STATA programs, 280, 431­432

Subject Index

623

statistic, 64 statistical model: general causal estimands and, 472;
instrumental variables analysis and, 560, 581; model-based analysis and, 142, 173­174, 177, 560, 581; potential outcomes and, 27, 29; regression analysis and, 114, 128 statistical power, 58, 64, 80 stochastic treatments, 12; Fisher's exact p-values and, 57­58; instrumental variables analysis and, 526­527, 551, 553, 568, 577; model-based analysis and, 141­142, 162, 568, 577; Neyman's repeated sampling approach and, 84, 99; potential outcomes and, 25; regression analysis and, 116; stratified randomized experiments and, 208 stratified randomized experiments: a priori approach and, 197, 208; assignment mechanisms and, 41­42, 191­192, 201­202; asymptotic distribution and, 216; balance and, 191­193; Bayesian approach and, 213; benefits of, 187; bias and, 187, 201­204, 206, 211­212, 217; causal effects and, 195, 206; causal estimands and, 208; classical randomized experiments and, 47­48, 51­55; completely randomized experiments and, 187­195, 197, 201, 204, 207, 211­212; confidence intervals and, 187, 203­204, 227­228; covariance matrices and, 216­217; covariates and, 187, 190­191, 195; design issues in, 211­212; dispersion and, 189, 198; estimators and, 201­207, 211­212, 216; finite samples and, 190, 201; Fisher's exact p-values and, 192­201; imputation and, 187­189, 209; interval estimators and, 213; joint distribution and, 207­208; J strata case and, 192, 196­197; least squares estimators and, 205­207, 214; model-based analysis and, 207­212; Neyman's repeated sampling approach and, 201­205, 213; notation and, 190, 192, 199, 205, 209; null hypothesis and, 189, 192­193, 195­201, 214; observation and, 187, 206; observed outcomes and, 192­193, 195­197; outliers and, 198; pairwise randomized experiments and, 212, 219­221, 226, 229, 231, 233­234; populations and, 191, 193, 201­207, 211­216; posterior distribution and, 207­210; potential outcomes and, 192, 195, 199­200, 202, 204, 207­210, 212, 214; pre-treatment variables and, 187, 189; prior distribution and, 208­210, 232­233; Project Star and, 188­189, 190t, 197­199, 201, 203, 204t, 207­209, 212; propensity score and, 190, 192, 205, 297, 381, 388; randomization distribution and, 193­194, 197­198, 200­201, 214; regression analysis and, 187­189, 205­207, 213­214, 217; samples and, 190, 193­194, 196­197, 200­207, 211­213, 217­218; sampling variances and, 193­194, 196, 201­204, 206­207, 211­213, 217­218; stable unit treatment value assumption (SUTVA) and, 188­189, 199; standard deviation and, 189, 209­210; stochastic treatments and, 208; structure of, 189­192; subpopulations and, 190, 211; subsamples and, 190­191, 211; super-populations and, 205, 211; test statistics and, 193­195, 197­200; treatments and, 187­198, 201­207, 210­213; two strata case

and, 189­196; unconfoundedness and, 259, 275, 279; weighting and, 194 strongly ignorable treatment assignment, 39, 43, 280 subclassification: average treatment effect and, 382­383; bias reduction and, 380­388; blocking and, 270 (see also blocking); estimators and, 382­384, 388, 394­399, 443­444, 452, 456­457, 460, 497; general causal estimands and, 464t; least squares and, 456­460; lotteries and, 385­386, 390­392; overlap and, 309, 336; propensity score and, 295, 377­400; sampling variances and, 443­444, 451­452, 456­457, 460; sensitivity analysis and, 497; unconfoundedness and, 270, 273­276, 490, 494; weighting estimators and, 392­399 subpopulations: assignment mechanisms and, 20, 35; finite samples and, 18; homogeneity and, 16; instrumental variables analysis and, 515, 523­525, 529­530, 538­539, 542, 547, 550, 554­555, 559­560, 565, 578; labor market and, 240, 245­246; matching and, 338, 427, 431; model-based analysis and, 560, 565, 578; Neyman's repeated sampling approach and, 102; overlap and, 310, 316, 322, 333; potential outcomes and, 190; propensity score and, 298, 377; regression analysis and, 131; sampling variances and, 436, 438­439, 445; stratified randomized experiments and, 191, 211; trimming and, 359, 363, 365; unconfoundedness and, 257, 259, 262, 270, 277­278, 482, 485, 487, 489, 493t­494t subsamples: Fisher's exact p-values and, 59, 66, general causal estimands and, 462, 472­473; instrumental variables analysis and, 518, 527, 541, 561; labor market and, 242­243, 245; matching and, 339­344, 350; model-based analysis and, 561; Neyman's repeated sampling approach and, 101­102; overlap and, 309­312, 326, 332, 336; propensity score and, 277­278, 282, 285, 292­293, 295, 366­368, 379, 389­390, 417, 420, 428; sampling variances and, 434­438, 459­460; stratified randomized experiments and, 190­191; trimming and, 359, 362, 365­373; unconfoundedness and, 257­259, 276­277, 493 super-populations: assignment mechanisms and, 39­40; average treatment effects and, 116­117; compliance status and, 525­526; general causal estimands and, 465, 473­474; instrumental variables analysis and, 520­521, 525-y527, 531­532, 534­536, 541, 545­547, 551­553, 560, 563­564, 566­567, 578; matching and, 346, 407, 415­416, 426; model-based analysis and, 142, 144, 171­172, 181, 560, 563­564, 566­567, 578; Neyman's repeated sampling approach and, 83, 93, 98­99, 101, 109­112; overlap and, 315; pairwise randomized experiments and, 230, 232; probabilistic assignment and, 40; propensity score and, 282, 291, 307, 377, 383, 392; regression analysis and, 113­114, 116­120, 122, 124, 126; samples and, 20­21; sampling variances and, 433­441, 445­448, 455; sensitivity analysis and, 497­500, 503; stratified randomized experiments and, 205, 211; trimming and, 360, 362, 366; unconfoundedness and, 40, 260­261, 263, 266­273, 277, 479, 482, 488­489

624

Subject Index

supporting analysis, 479, 495 surgery, 14­15, 219, 514 SUTVA see stable unit treatment value assumption
Taylor series, 174 test statistics: Fisher's exact p-values and, 57­81, 64,
66, 71, 80; Kolmogorov-Smirnov, 69­70, 81; labor market and, 242­243; Neyman's repeated sampling approach and, 97; overlap and, 311, 366; propensity score and, 285, 287, 293­295, 300­302, 381­382, 385; regression analysis and, 133; stratified randomized experiments and, 193­195, 197­200, 198 treatments, xvii­xviii; ability to adjust for differences and, 317­318; active, 4, 8, 11, 13, 16­17, 19, 33 (see also active treatments); a posteriori approach and, 3; a priori approach and, 3, 16 (see also a priori approach); assignment mechanisms and, 31­44 (see also assignment mechanisms); attributes and, 15; average treatment effect and, 19, 56­57, 63, 81, 83­93, 95, 97­108, 112, 114, 116­134, 141 (see also average treatment effect); basics of, 3­22; bias and, 85­87 (see also bias); classical randomized experiments and, 47­56; control, 4 (see also control treatments); covariate balance and, 277, 282, 300­306, 309, 316­318, 329, 336­337, 359, 380, 428­429; estimators and, 55 (see also estimators); Fisher exact p-values and, 57­82; general causal estimands and, 461­469, 472­475; ignorable assignment and, 39; inference for average effects and, 98­101; instrumental variables analysis and, 513­569, 575, 577­584; labor market and, 240­250, 253; manipulation and, 3­5, 7, 21, 263, 524; matching and, 343, 345­350, 352, 358, 401­432; model-based analysis and, 141­142, 145­151, 155­156, 162­166, 168­178, 181­183, 185, 560­569, 575, 577­584; Neyman's repeated sampling approach and, 83­112; no hidden variations of, 11­12; observation and, 4, 12 (see also observation); overlap and, 309­311, 313­322, 325­336; pairwise randomized experiments and, 219­235; post-treatment variables and, 415 (see also post-treatment variables); potential outcomes and, 24­30; pre-treatment variables and, 15­16 (see also pre-treatment variables); propensity score and, 281­286, 291­299, 302, 307, 377­378, 381­399; pseudo, 278­279, 480­482, 485­486, 493; quantile, 465­466, 473­474; Randomized Blocks and Latin Squares and, 27; regression analysis and, 113­134; samples and, 25 (see also samples); sampling variances and, 433­447, 450­460; sensitivity analysis and, 496­509; stable unit treatments value assumption (SUTVA) and, 9­15, 21­22, 25, 33, 84, 188­189, 199, 498, 514, 516­517, 550, 589­590; stochastic, 12 (see also stochastic treatments); stratified randomized experiments and, 187­198, 201­207, 210­213; strongly ignorable treatment assignment and, 39, 43, 280; trimming and, 359­374; unbiased estimation of average effect of, 85­87; unconfoundedness and, 255 (see also unconfoundedness)

trimming: a priori approach and, 368; assumptions and, 359, 361, 363, 367­368; asymptotic distribution and, 360, 363­367; balance and, 359­374; bias and, 360, 374; bounds and, 365; causal effects and, 359­360, 373­374; causal estimands and, 370; control units and, 360­361, 368, 371t­372t, 374; covariates and, 359­374; design phase and, 373; estimators and, 359­360, 363­366; inequality and, 367­368; internal validity and, 359, 365; joint distribution and, 359­360, 373; likelihood and, 368; lotteries and, 451; marginal distribution and, 367; model-based analysis and, 366­367, 378, 385, 387, 403; Neyman's repeated sampling approach and, 363; normalized difference and, 361­362, 368, 370; observation and, 359­361, 365, 373; populations and, 359­360, 362­363, 365­366; potential outcomes and, 366; pre-treatment variables and, 359­362, 368, 370; propensity score and, 359­374, 377­400; regression analysis and, 362; right heart catheterization and, 360­362, 368­373; robustness and, 362, 365, 370; samples and, 359­374; sampling variances and, 360, 363­377, 451; standard deviation and, 361, 370; subpopulations and, 359, 363, 365; subsamples and, 359, 362, 365­373; treatments and, 359­374; unconfoundedness and, 361
unconfoundedness, 20, 589­590; a priori approach and, 257, 259, 278­279, 479­481, 488, 493; assessing, 278­279, 479­495; assignment mechanisms and, 31­32, 38­43, 255­265, 271, 276, 279; assignment probabilities and, 257­259, 273; assumptions and, 257­265, 272, 278­280, 479­492, 495; asymptotic distribution and, 269; balance and, 258, 266­269, 273, 276­278; balancing scores and, 265­268; Bayesian approach and, 271; bias and, 257, 259­260, 266­268, 270, 275, 277, 279, 479­481, 487­488, 492; blocking and, 270, 274­275, 484, 490­491; bounds and, 268­270; causal effects and, 260­264, 268, 271, 276, 278, 479­495; causal estimands and, 262­263, 276­277, 479­480, 489; classical randomized experiments and, 47­48, 53; completely randomized experiments and, 257, 259, 267, 270, 273­274; conditional distribution and, 261, 271, 479, 489; conditional independence assumption and, 260, 280, 483­487; conditional mean and, 272; conditioning and, 265­266; control units and, 257, 259­260, 263, 266­267, 269, 274­279, 479­481, 488, 494; covariates and, 257­260, 262, 265­280, 479­494; definition of, 31, 38; design approach and, 276­278, 480­483, 485, 491, 493, 495; drug treatment and, 262, 265; efficiency bounds and, 268­270; estimators and, 257, 260, 268­277; general causal estimands and, 468; group, 481, 485; implementation and, 484­490; importance of, 262­265; imputation and, 270­271, 273, 275­276; individualistic assignment and, 259, 261­262; instrumental variables analysis and, 513­516, 520­521, 525­526, 530, 534­539, 543, 547, 567, 572, 584; interpretation and, 483­484, 486; joint distribution and, 260­261, 270­271, 275; latent, 514, 526; least squares estimators and, 272;

Subject Index

625

lotteries and, 482­483, 488, 490­495; marginal distribution and, 269­270; matching and, 270, 273, 275­277, 341, 346, 361, 401­402, 404, 407, 409, 484; model-based analysis and, 270­271, 275­276, 484, 567, 572­574, 578, 584; Neyman's repeated sampling approach and, 259; notation and, 260, 268, 483, 485; null hypothesis and, 278, 480­481, 485­486, 495; observation and, 257­258, 262, 264, 276, 280, 488; observed outcomes and, 259­261, 482; overlap and, 309­310, 314, 316, 321, 332; populations and, 257, 259­263, 266, 268­274, 277­278, 479, 482, 485, 487­489, 493t­494t, 495; potential outcomes and, 257­272, 479­483, 487, 489; pre-treatment variables and, 257­266, 279, 479­484, 487­492, 494; probabilistic assignment and, 257­258, 261­262, 269, 280; propensity score and, 258­259, 266­270, 273­282, 284, 377, 392, 399, 491, 494; pseudo-outcomes and, 480­485, 487, 490­493, 495; randomization distribution and, 273; randomized experiments and, 257, 259, 264, 267, 270­275, 279; random variables and, 271; regression analysis and, 263, 272­274, 276­277, 280, 494; regular assignment mechanisms and, 258­266, 276, 279, 479; robustness and, 260, 270, 274­277, 481­482, 487­490, 494­495; samples and, 257­262, 268­279, 490­494, 497­499, 501­502, 505, 508­509; sampling variances and, 268­270, 437, 445; sensitivity analysis and, 279, 496­500, 503­504, 506­507, 509; standard deviation and, 277; stratified randomized experiments and, 259,

275, 279; strongly ignorable treatment assignment and, 39: subclassification and, 270, 273­276, 490, 494; subpopulations and, 257, 259, 262, 270, 277­278, 482, 485, 487, 489, 493t­494t; subsamples and, 257­259, 276­277, 493; subset, 480­483, 487­490, 494; super-populations and, 260­261, 263, 266­273, 277, 479, 482, 488­489; supporting analysis and, 479, 495; testibility of, 261­262; trimming and, 361; weighting and, 270, 273­275 unit assignment probability, 34 University of California, xvii
Vietnam War, 543 vitamin supplements, 516­517, 520­521, 528,
538­541
weighting: average treatment effect and, 441­445; general causal estimands and, 462; Horvitz-Thompson, 282, 378, 379t, 392­400, 443; labor market and, 246; lotteries and, 443­445; matching and, 343, 432; propensity score and, 270, 273­275, 281­282, 378, 392­399; sampling variances and, 441­445; stratified randomized experiments and, 194; unconfoundedness and, 270, 273­275
Wilcoxon rank sum test, 67, 82 wishart distribution, 209
z-values, 298­303, 304t­305t, 306f, 321

