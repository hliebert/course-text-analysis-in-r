Journal of Business & Economic Statistics

ISSN: 0735-0015 (Print) 1537-2707 (Online) Journal homepage: https://www.tandfonline.com/loi/ubes20

Including Covariates in the Regression
Discontinuity Design
Markus FrÃ¶lich & Martin Huber
To cite this article: Markus FrÃ¶lich & Martin Huber (2018): Including Covariates in
the Regression Discontinuity Design, Journal of Business & Economic Statistics, DOI:
10.1080/07350015.2017.1421544
To link to this article: https://doi.org/10.1080/07350015.2017.1421544

View supplementary material

Accepted author version posted online: 15
Jan 2018.
Published online: 05 Sep 2018.
Submit your article to this journal

Article views: 471

View Crossmark data

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=ubes20

Supplementary materials for this article are available online. Please go to http://tandfonline.com/r/JBES

Including Covariates in the Regression
Discontinuity Design
Markus FRÃ–LICH
Center for Evaluation and Development (C4ED), University of Mannheim, J-PAL, L7, 3-5, D-68131 Mannheim,
Germany (froelich@c4ed.org, froelich@uni-mannheim.de)

Martin HUBER
Department of Economics, University of Fribourg, Bd. de PÃ©rolles 90, CH-1700 Fribourg, Switzerland
(martin.huber@unifr.ch)
This article proposes a fully nonparametric kernel method to account for observed covariates in regression
discontinuity designs (RDD), which may increase precision of treatment effect estimation. It is shown that
conditioning on covariates reduces the asymptotic variance and allows estimating the treatment effect at
the rate of one-dimensional nonparametric regression, irrespective of the dimension of the continuously
distributed elements in the conditioning set. Furthermore, the proposed method may decrease bias and
restore identification by controlling for discontinuities in the covariate distribution at the discontinuity
threshold, provided that all relevant discontinuously distributed variables are controlled for. To illustrate
the estimation approach and its properties, we provide a simulation study and an empirical application to
an Austrian labor market reform. Supplementary materials for this article are available online.
KEY WORDS: Causal effect; Complier; Endogeneity; LATE; Nonparametric regression; Treatment
effect.

1. INTRODUCTION

poorly in the RDD, where a good fit is only needed at the treatment threshold, see Gelman and Imbens (2018). Extrapolation
from far-away data points is also inherent in linear regression
where one linearly controls for covariates.) Consider the setup
of the RDD: D is a binary treatment indicator, Y is the outcome
variable of interest, and Z is the â€œforcing variableâ€ with a known
threshold z0 at which the treatment probability Pr(D = 1|Z) is
discontinuous. There are various motivations for accounting for
covariates, denoted by X. A first reason is variance reduction,
which is well known for the parametric case. But gains in precision can also be achieved in the nonparametric setup, as flexibly
including covariates and averaging them out in an appropriate
way reduces the asymptotic variance of the estimated treatment
effect. We show that under mild regularity conditions, incorporating covariates permits estimating the treatment effect at
the rate for one-dimensional nonparametric regression, that is,
2
nâˆ’ 5 (where n is the sample size), irrespective of the dimension of the continuously distributed elements in X. Hence,
the curse of dimensionality does not apply due to smoothing
over X.
Second, as pointed out by Imbens and Lemieux (2008),
covariates may mitigate small sample biases in cases where
the number of observations close to the threshold z0 is small
such that one has to include observations in the estimation that
are further apart and may potentially differ in X. Controlling
for X might eliminate some of the bias that is introduced by

The regression discontinuity design (RDD) has received
tremendous attention in many fields, for example, labor markets,
political economy, health, education, psychology, criminology,
as a credible approach to identifying causal effects without having to resort to fully randomized experiments. Hahn, Todd, and
van der Klaauw (2001) formalized the assumptions required to
identify causal effects in the RDD and provided nonparametric (local linear) estimators. Porter (2003) complemented their
work by alternative estimators. Lee and Card (2008) considered the case when the forcing variable is discrete. McCrary
(2008) proposed a test for the manipulation of the running variable related to the continuity of its density function. Imbens
and Lemieux (2008), van der Klaauw (2008), and Lee and
Lemieux (2010) surveyed the applied and theoretical literature on the RDD. Imbens and Kalyanaraman (2012) discussed
optimal bandwidth selection in terms of squared error loss,
while Calonico, Cattaneo, and Titiunik (2014) proposed methods for robust inference along with optimal bandwidth selection.
Dong (2014) presented an alternative to some of the identifying
assumptions in Hahn, Todd, and van der Klaauw (2001).
In this article, the regression discontinuity approach is
extended to incorporate covariates in a fully nonparametric
way. Our estimator is based on a local nonparametric regression approach, that is, kernel-based estimation, which allows
deriving closed-form expressions for bias and variance. (An
alternative approach could use global nonparametric methods
such as sieves or polynomials of increasing order. However,
such global methods, which are capable of fitting regression
curves at many points by means of extrapolation, may perform

Â© 2018 American Statistical Association
Journal of Business & Economic Statistics
XXXX 2018, Vol. 0, No. 0
DOI: 10.1080/07350015.2017.1421544
1

2

Journal of Business & Economic Statistics, XXXX 2018

observations further away from the threshold, as illustrated by
Black, Galdo, and Smith (2007). However, biases related to
unobserved characteristics cannot be accounted for.
Third, we also permit for situations where the density f (X|Z)
is discontinuous at z0 , which may point to a failure of the RDD
assumptions, see Lee (2008), such that the simple RDD estimator is generally inconsistent. Our approach nevertheless
identifies a local treatment effect in cases in which X contains
all variables that (i) are imbalanced around the threshold and (ii)
affect the outcome variable. With this respect, our contribution
distinguishes itself from a more recent article on RDD with
covariates by Calonico et al. (2018), who assume f (X|Z) to
be continuous at z0 . Under that stronger identifying condition
not needed here, Calonico et al. (2018) discussed potential
precision gains when linearly (rather than nonparametrically
as in our method) controlling for X and provided methods for
optimal bandwidth selection and robust inference.
One example for f (X|Z) being discontinuous at z0 is â€œclassical confoundingâ€ where manipulation of Z at the threshold
is selective with respect to characteristics that may also affect
the outcome, see, for instance, Urquiola and Verhoogen (2009).
If all confounding characteristics are observed in the data, our
method yields the treatment effect on compliers at the threshold.
See also van der Klaauw (2008) for confounding in the context
of dynamic treatment assignment, where observed earlier treatment eligibility or participation (X) jointly affects the (current)
forcing variable Z and Y . As a further example, consider the case
when Z not only affects D, but also further variables that affect
Y . This may occur in spatial RDDs where Z is based on distance
to geographical borders. Eugster et al. (2017), for instance, use
the (mainly French and German) language border within administrative units of Switzerland to estimate the effects of culture
on unemployment. The authors consider a measure of the â€œtaste
for leisureâ€ as one particular indicator of culture. However, in
addition to this treatment variable, further community-based
covariates that are likely affected by culture also change discontinuously at the border. Controlling for X is therefore necessary
as Z would otherwise violate the exclusion restriction with
respect to Y at the threshold through its influence on X. Identification of a causal effect is, however, only obtained if X are not
â€œbad controlsâ€ which are affected by unobservables that also
influence Y .
The remainder of this article is organized as follows.
Section 2 discusses the identification of the treatment effect in
the presence of covariates. Section 3 proposes two estimators
and examines their properties and shows that one of them
2
achieves the nâˆ’ 5 convergence rate. Section 4 provides a simulation study that (among others) illustrates the implications
of confounding related to observed covariates at the threshold
when applying RDD with and without controlling for X. Section
5 presents an empirical application to Austrian labor market
reform previously considered by Lalive (2008) to estimate the
effect of age-dependent eligibility to unemployment benefits
on unemployment duration. As employees at risk of becoming
unemployed might negotiate the exact date of dismissal with
their employers, manipulation at the age threshold is a concern.
We therefore control for a range of labor market-relevant characteristics that are potential confounders and find our results to
differ from RDD without X. Section 6 concludes.

2. RDD WITH COVARIATES
We define causal effects using the potential-outcome notation
in the framework known as the Neymanâ€“Fisherâ€“Rubin causal
model. (See Neyman (1923), Fisher (1935), and Rubin (1978).)
Following the setup of Hahn, Todd, and van der Klaauw (2001),
let Di âˆˆ {0, 1} be a binary treatment variable, let Yi0 , Yi1 be the
individual potential outcomes, and Yi1 âˆ’ Yi0 the individual treatment effect. The potential outcomes as well as the treatment
effects Yi1 âˆ’ Yi0 are permitted to vary across individuals, that is,
no constant treatment effect is assumed. Let Zi be a variable that
influences the treatment variable in a discontinuous way.
In the literature, two distinct designs are examined: the sharp
design where Di changes for everyone at a known threshold z0 ,
and the fuzzy design where Di changes only for a subset of individuals. In the sharp design (Trochim 1984), participation status
is given by a deterministic function of Z, for example,
Di = 1(Zi â‰¥ z0 ).

(1)

This implies that all individuals change program participation
status exactly at z0 . The fuzzy design, on the other hand, permits
D to also depend on other factors but assumes that the treatment
probability changes discontinuously at z0 :
lim E [D|Z = z0 + Îµ] âˆ’ lim E [D|Z = z0 âˆ’ Îµ] = 0.

Îµâ†’0

Îµâ†’0

(2)

Note that the fuzzy design includes the sharp design as a special
case when the left-hand side of (2) is equal to one. For this reason, the subsequent discussion mostly focuses on the more general fuzzy design. (Battistin and Rettore (2008) introduced the
mixed sharp fuzzy design as a special case of the fuzzy design.)
See Hahn, Todd, and van der Klaauw (2001) for more details.
Identification is feasible under the continuity of the mean
potential outcomes at z0 and relies on comparing the observed
outcomes of those individuals to the left of the threshold with
those to the right. In addition to continuity of E[Y d |Z = z] in
z at z0 for d = {0, 1}, Hahn, Todd, and van der Klaauw (2001)
considered two alternative identifying assumptions:
HTK1:

Yi1 âˆ’ Yi0 âŠ¥âŠ¥Di |Zi

for Zi near z0

(3)

or



HTK2: Yi1 âˆ’ Yi0 , Di (z) âŠ¥
âŠ¥Zi

near z0

and there exists e > 0

such that Di (z0 + Îµ) â‰¥ Di (z0 âˆ’ Îµ) for all 0 < Îµ < e. (4)

Assumption (3) is a local selection on observables assumption and identifies the average treatment effect at the threshold:
E[Y 1 âˆ’ Y 0 |Z = z0 ]. Assumption (4) is an instrumental variables assumption that identifies a local average treatment effect
(LATE) for a local group of compliers at the threshold:
lim E[Y 1 âˆ’ Y 0 |D(z0 + Îµ) > D(z0 âˆ’ Îµ), Z = z0 ].

Îµâ†’0

In the sharp design, everyone is a complier at z0 and assumption
(3) is meaningless (i.e., has no identifying power) such that one
needs assumption (4). In the fuzzy design, one typically invokes
(4), since the conditional independence assumption (3) does not
permit treatment selection based on individual gains Yi1 âˆ’ Yi0 .
It is worth mentioning that Dong (2014) recently showed that
alternatively to (4), identification of the LATE is obtained by
making a continuity assumption of Z in the neighborhood of

FrÃ¶lich and Huber: Including Covariates in the Regression Discontinuity Design

z0 . (Continuity of Z implies the smoothness of mean potential
outcomes conditional on compliance behavior and of the shares
of subgroups defined upon compliance at the threshold, which
is sufficient for identification.)
In the following, we introduce observed covariates Xi and
assume that (4) is valid conditional on X. As an example,
suppose that there exists a liberalized education market in
which schools may charge tuition fees, and that by law classes
must be split if the number of students surpasses a particular
threshold. As argued in Urquiola and Verhoogen (2009) for the
case of Chile, schools close to the threshold might adjust tuition
fees, thereby causing discontinuities in the admitted studentsâ€™
socioeconomic characteristics such as household income and
parentsâ€™ education. Assume that the latter variables also affect
the outcome of interest, for example, studentsâ€™ educational
degree, which implies a violation of HTK2 when assessing the
educational effect of class size. However, if household income,
parentsâ€™ education, and all other variables imbalanced at the
threshold and affecting the outcome are observed, (4) holds conditional on Xi . (Whether it is plausible to assume that all imbalanced covariates affecting the outcome are observed depends on
the empirical problem and the richness of data. In the context of
Urquiola and Verhoogen (2009), for instance, ambition might
(in addition to parentsâ€™ education and household income) play
a role for selectively (re)placing students into particular class
sizes. One would therefore want to condition on a rich set
of socio-economic household characteristics and personality
traits, for example, provided by means of a household survey.)
By an analogous reasoning as in HTK, and further assumptions
made precise below, it follows immediately that the treatment
effect on the local compliers conditional on X is identified as


lim E Y 1 âˆ’ Y 0 |X, D(z0 + Îµ) > D(z0 âˆ’ Îµ), Z = z0
Îµâ†’0

=

m+ (X, z0 ) âˆ’ mâˆ’ (X, z0 )
,
d + (X, z0 ) âˆ’ d âˆ’ (X, z0 )

(5)

where m+ (X, z) = limÎµâ†’0 E[Y |X, Z = z + Îµ] and mâˆ’ (X, z) =
limÎµâ†’0 E[Y |X, Z = z âˆ’ Îµ] and d + (X, z) and d âˆ’ (X, z) defined
analogously with D replacing Y .
In this article, however, we focus on identifying and estimating the unconditional effect


(6)
lim E Y 1 âˆ’ Y 0 |D(z0 + Îµ) > D(z0 âˆ’ Îµ), Z = z0 ,
Îµâ†’0

that is, the effect on all compliers without conditioning on X.
We identify this effect by first controlling for X and thereafter
averaging over X. There are at least three reasons, why estimating the unconditional effect (6) is interesting (or even more
interesting than the conditional effect (5)). First, for the purpose
of evidence-based policy-making a small number of summary
measures can be more easily conveyed to policy makers and the
public than a large number of estimated effects at every value
of X. Second, unconditional effects can be estimated more precisely than conditional effects. Third, the definition of unconditional effects does not depend on the variables included in
X. (This, of course, is only true if X exclusively contains pretreatment variables.) One can therefore consider different sets
of control variables X and still estimate the same object, which
is useful for examining robustness of the results to the set of
control variables. See also FrÃ¶lich (2007).

3

For showing identification of the unconditional effect (6), we
first introduce some further notation. Let NÎµ be a symmetric
Îµ neighborhood about z0 and partition NÎµ into NÎµ+ = {z : z â‰¥
z0 , z âˆˆ NÎµ } and NÎµâˆ’ = {z : z < z0 , z âˆˆ NÎµ }. According to their
reaction to the instrument z over NÎµ we can partition the population into four subpopulations:
Ï„i,Îµ = a

if

Di (z) = 1

âˆ€z âˆˆ NÎµâˆ’

and

Di (z) = 1

âˆ€z âˆˆ NÎµ+

Ï„i,Îµ = n

if

Di (z) = 0

âˆ€z âˆˆ NÎµâˆ’

and

Di (z) = 0

âˆ€z âˆˆ NÎµ+

Ï„i,Îµ = c

if

Di (z) = 0

âˆ€z âˆˆ NÎµâˆ’

and

Di (z) = 1

âˆ€z âˆˆ NÎµ+

Ï„i,Îµ = d

if

Di (z) = 1

âˆ€z âˆˆ NÎµâˆ’

and

Di (z) = 0

âˆ€z âˆˆ NÎµ+ .

These subpopulations are a straightforward extension of the
LATE concept of Imbens and Angrist (1994). The first group
contains those units that will always be treated (if Z âˆˆ NÎµ ), the
second contains those that will never be treated (if Z âˆˆ NÎµ ), and
the third and fourth group contains the units that are treated only
on one side of z0 . (In the appendix, we also consider a possible fifth group of indefinite units, for which no left-limit of
Di (z) may exist. We assume this group to not exist, that is, we
require that all units have well-defined left-limits of Di (z).) We
will assume that the fourth group, that is, the â€œdefiers,â€ has measure zero for Îµ sufficiently small. Note that in the sharp design,
everyone is a complier for any Îµ > 0.
Under the following assumption, we can identify the treatment effect for the local compliers, that is, for those who switch
from D = 0 to 1 at z0 . (The conditions in Assumption 1 are very
similar, but a little weaker, to a conditional-on-X version of (4).)
It is assumed throughout that the covariates X are continuously
distributed with a Lebesgue density. This assumption is made
for convenience to ease exposition, particularly in the derivation of the asymptotic distributions later on. Discrete covariates can (at the expense of more cumbersome notation) easily
be included in X, as the derivation of the asymptotic distribution only depends on the number of continuous regressors in
X, while discrete variables do not affect the asymptotic properties. In fact, identification does not require any continuous X
variables. Only Z has to be continuous near z0 , but could have
masspoints elsewhere.
Assumption 1. For a symmetric neighborhood NÎµ about z0
and for almost every X
(i) Existence of compliers
limÎµâ†’0 Pr(Ï„Îµ = c|Z âˆˆ NÎµ ) > 0
(ii) Monotonicity
limÎµâ†’0 Pr(Ï„Îµ = c|Z âˆˆ NÎµ ) + Pr(Ï„Îµ = a|Z âˆˆ NÎµ ) +
Pr(Ï„Îµ = n|Z âˆˆ NÎµ ) = 1
(iii) Independent IV
limÎµâ†’0 Pr(Ï„Îµ = t|X, Z âˆˆ NÎµ+ ) âˆ’ Pr(Ï„Îµ = t|X, Z âˆˆ
NÎµâˆ’ ) = 0 for t âˆˆ {a, n, c}
(iv) IV Exclusion
limÎµâ†’0 E[Y 1 |X, Z âˆˆ NÎµ+ , Ï„Îµ = t] âˆ’ E[Y 1 |X, Z âˆˆ NÎµâˆ’ ,
Ï„Îµ = t] = 0 for t âˆˆ {a, c}
limÎµâ†’0 E[Y 0 |X, Z âˆˆ NÎµ+ ,
Ï„Îµ = t] âˆ’ E[Y 0 |X, Z âˆˆ NÎµâˆ’ , Ï„Îµ = t] = 0 for t âˆˆ {n, c}
(v) Common support
limÎµâ†’0 Supp(X|Z âˆˆ NÎµ+ ) = limÎµâ†’0 Supp(X|Z âˆˆ NÎµâˆ’ )
(vi) Density at threshold
FZ (z) is differentiable at z0 and fZ (z0 ) > 0

4

Journal of Business & Economic Statistics, XXXX 2018

limÎµâ†’0 FX|ZâˆˆNÎµ+ (x) and limÎµâ†’0 FX|ZâˆˆNÎµâˆ’ (x) exist and
are differentiable in x with pdf f + (x|z0 ) and f âˆ’ (x|z0 ),
respectively.
(vii) Bounded moments
E[Y 1 |X, Z] and E[Y 0 |X, Z] are bounded away from Â±
infinity a.s. over NÎµ
Concerning notation, f + (x, z0 ) = f + (x|z0 ) f (z0 ) refers to the
joint density of X and Z whereas f + (x|z0 ) refers to the conditional density of X.
This assumption requires that in a neighborhood about
z0 , the threshold acts like a local instrumental variable.
Assumptions 1(i) to (iv) are instrumental variable assumptions for a binary instrument, as discussed, for example, in
Imbens (2001). The monotonicity assumption 1(ii) rules out
defiers at the threshold z0 , while 1(i) requires the existence
of compliers. We note that 1(i) and 1(ii) could be relaxed
to a local version of the compliers-defiers assumption of de
Chaisemartin (2017), which allows for defiers under particular
conditions, at the cost of identifying the effects only for a subset
of compliers (the so-called â€œcomvivorsâ€). Assumptions 1(iii)
and 1(iv) represent the exclusion restriction, conditional on X.
Assumption 1(v) requires common support because we need to
integrate over the support of X in (7). (If this assumption is not
satisfied, one can redefine (7) by restricting it to the common
support.) Assumption 1(vi) implies positive density at z0 , such
that observations close to z0 exist.
We also assume the existence of the limit density functions
f + (x|z0 ) and f âˆ’ (x|z0 ) at the threshold z0 . So far, we do not
assume anything about their continuity with respect to z. In other
words, the conditional density could be discontinuous, that is,
f + (x|z0 ) = f âˆ’ (x|z0 ), in which case controlling for X is important for identification and thus consistent estimation, or it could
be continuous, that is, f + (x|z0 ) = f âˆ’ (x|z0 ), in which case identification does not hinge on controlling for observed covariates.
The latter may, however, reduce the variance of the point estimator, as discussed below. (Note that Assumption 1 is somewhat stronger than needed for identification. Assumptions (1i)
to (1iv) could be replaced with other assumptions that identify
the local treatment effect conditional on X. For instance, if local
compliers and local defiers had the same treatment effect, one
could drop the monotonicity assumption. In addition, the existence of a density function for X is not needed.)
Assumption (1vii) requires the conditional expectation functions to be bounded from above and below in a neighborhood of
z0 . It is invoked to permit interchanging the operations of integration and taking limits via the dominated convergence theorem. (This assumption is certainly stronger than needed and
could be replaced with some other smoothness conditions on
E[Y d |X, Z] in a neighborhood of z0 .)
Theorem 1 (Identification of complier treatment effect).
Under Assumption 1, the local average treatment effect Î³
for the subpopulation of local compliers is nonparametrically
identified as


Î³ = lim E Y 1 âˆ’ Y 0 |Z âˆˆ NÎµ , Ï„Îµ = c
Îµâ†’0

 +
 +
âˆ’
m (x, z0 ) âˆ’ mâˆ’ (x, z0 ) Â· f (x|z0 )+2 f (x|z0 ) dx
= 
.
+
âˆ’
(d + (x, z0 ) âˆ’ d âˆ’ (x, z0 )) Â· f (x|z0 )+2 f (x|z0 ) dx

(7)



Proof. See the appendix.

Under Assumption 1, the treatment effect for the local
compliers is identified as a ratio of two integrals, as shown in
Theorem 1. The numerator in (7) is the intention-to-treat (ITT)
effect of Z on Y , weighted by the conditional density of X, at z0 .
(In the limit, the density of X conditional on Z being within a
+
âˆ’
symmetric neighborhood around z0 is given by f (x|z0 )+2 f (x|z0 ) .)
The denominator in (7) gives the effect of Z on D, that is, the
fraction of compliers, at z0 . Thus, the ratio of integrals gives
the ITT effect multiplied with the inverse of the number of
compliers, corresponding to the LATE at z0 .
The ratio of integrals expression in (7) is obtained by applying
iterated expectations to
E[Y 1 âˆ’ Y 0 |Z âˆˆ NÎµ , Ï„Îµ = c]
to obtain
=

E[Y 1 âˆ’ Y 0 |X = x, Z âˆˆ NÎµ , Ï„Îµ = c] Â· fX|ZâˆˆNÎµ ,Ï„Îµ =c (x) dx.

(8)
Clearly, the density f (X|Z âˆˆ NÎµ , Ï„Îµ = c) among the local compliers is not identified since the type Ï„Îµ is unobservable. However, by applying Bayesâ€™ theorem to f (X|Z âˆˆ NÎµ , Ï„Îµ = c) and
replacing the first term in (8) with ( 5) (before taking limits), several terms cancel out and we obtain after various calculations the
expression (7), which relies on observed variables only. See the
supplementary appendix for detailed derivations. We thereby
have identified the average effect. Similarly, we could identify
quantile treatment effects by combining the previous derivations
with the reasoning in FrÃ¶lich and Melly (2013) and Frandsen,
FrÃ¶lich, and Melly (2012).
So far, we have identified the treatment effect for the compliers in the fuzzy design. Without restrictions on treatment effect
heterogeneity, it is impossible to identify the effects for alwaysand never-participants since they would never change treatment
status in a neighborhood of z0 . However, in the sharp design,
everyone is a complier at z0 , that is, d + (x, z0 ) âˆ’ d âˆ’ (x, z0 ) = 1,
and the expression (7) simplifies to


lim E Y 1 âˆ’ Y 0 |Z âˆˆ NÎµ =

 +

m (x, z0 ) âˆ’ mâˆ’ (x, z0 )

Îµâ†’0

Â·

f + (x|z0 ) + f âˆ’ (x|z0 )
dx.
2

(9)

The estimand (9) in the sharp design is identical to the numerator
of (7). The following discussion focusses on the estimation of
(7), where the numerator and denominator of (7) are analyzed
separately. Therefore, the asymptotic distribution of ( 9) in the
sharp design is immediately obtained by using the results for
the numerator of (7) only. We also note that the estimands (7)
and (9) bear some resemblance to the partial means estimator of
Newey (1994). Both the numerator and denominator of (7) have
a partial means form, in that averages over the covariates X are
taken, at the left and the right limit at z0 .
Instead of generalizing assumption (4) to permit for further
covariates X, we could alternatively start from the conditional
independence assumption (3). To conserve space, we, however,
do not analyze this in much detail since most applied work
either uses a sharp design (where (3) is meaningless) or otherwise refers to (4 ). Consider an extension of (3) by including

FrÃ¶lich and Huber: Including Covariates in the Regression Discontinuity Design

covariates X:
Yi1

âˆ’ Yi0 âŠ¥âŠ¥Di |Xi , Zi

for Zi near z0 .

(10)

Analogously to the derivations in Hahn, Todd, and van der
Klaauw (2001) it follows that
E[Y 1 âˆ’ Y 0 |X, Z = z0 ] =

m+ (X, z0 ) âˆ’ mâˆ’ (X, z0 )
.
d + (X, z0 ) âˆ’ d âˆ’ (X, z0 )

Similarly to the derivations for Theorem 1, one can show that
the unconditional treatment effect for the population near the
threshold is
m+ (x, z0 ) âˆ’ mâˆ’ (x, z0 )
E[Y 1 âˆ’ Y 0 |Z = z0 ] =
d + (x, z0 ) âˆ’ d âˆ’ (x, z0 )
f + (x|z0 ) + f âˆ’ (x|z0 )
dx.
(11)
2
This expression differs from (7) and (9) in that it is an integral
of a ratio and not a ratio of integrals. The results derived in
Section 3 therefore do not apply to (11). In addition, expression (11) may be difficult to estimate in small samples as the
denominator can be close to zero for some values of x. (This
problem is of much less concern for estimators of (7) and (9)
as those are based on a ratio of two integrals and not on an
integral of a ratio. For those estimators the problem of very
small denominators for some values of X averages out.)
Instead of using (10), one might be willing to strengthen the
latter assumption to
Â·

5

spirit of Racine and Li (2004). Define Îº and ÎºÌ„ as univariate
kernel functions, where Îº is a second-order kernel (assumed
to be symmetric and integrating to one) and ÎºÌ„ is a kernel
of order Î» â‰¥ 2. The following kernel constants
for Îº will be
âˆ
âˆ
used later: Î¼l = âˆ’âˆ ul Îº (u)du and Î¼Ì„l = 0 ul Îº (u)du and Î¼Ìƒ =
Î¼Ì„2
âˆ’ Î¼Ì„21 . (With symmetric kernel Î¼Ì„0 = 12 .) Furthermore define
2
âˆ
Î¼Ìˆl = 0 ul Îº 2 (u)du. (For the Epanechnikov kernel with support
[âˆ’1, 1], that is, K(u) = 34 (1 âˆ’ u2 )1(|u| < 1) the kernel constants are Î¼0 = 1, Î¼1 = Î¼3 = Î¼5 = 0, Î¼2 = 0.2, Î¼4 = 6/70,
Î¼Ì„0 = 0.5, Î¼Ì„1 = 3/16, Î¼Ì„2 = 0.1, Î¼Ì„3 = 1/16, Î¼Ì„4 = 3/70. The
âˆ
kernel constants for ÎºÌ„ are defined as Î·l = âˆ’âˆ ul ÎºÌ„ (u)du and
âˆ l 2
Î·Ì‡l = âˆ’âˆ u ÎºÌ„ (u)du. The kernel function ÎºÌ„ being of order Î»
means that Î·0 = 1 and Î·l = 0 for 0 < l < Î» and Î·Î» = 0.)
We will consider two different choices for Kh (u) in (13). The
conventional choice would be to use a positive (i.e., second
order) and symmetric kernel
Kh (u) =

1
Îº (u).
h

(14)

However, as shown below, the use of this â€œnaiveâ€ kernel function
1
(14) leads at best to a convergence rate of nâˆ’ 3 of (13).
As an alternative, we consider a boundary kernel
1
Kh (u) = (Î¼Ì„2 âˆ’ Î¼Ì„1 |u|) Â· Îº (u)
h

(15)

in (13), and we will see that this leads to a convergence rate
2
of nâˆ’ 5 of (13), that is, the rate of univariate nonparametric
for Zi near z0 .
(12) regression. This is achieved through smoothing with implicit
Yi1 , Yi0 âŠ¥âŠ¥Di |Xi , Zi
double boundary correction. (See, for example, Jones (1993) or
This permits identifying the treatment effect as
Jones and Foster (1996) for similar boundary kernels, or Gasser

 1
0
and MÃ¼ller (1979), Gasser, MÃ¼ller, and Mammitzsch (1985),
E Y âˆ’ Y |Z = z0
MÃ¼ller (1991) or Tenreiro (2013) for a more general discussion
= (E [Y |D = 1, X = x, Z = z0 ] âˆ’ E [Y |D = 0, X = x, Z = z0 ]) on various forms of boundary kernels or boundary corrections
including the derivation of optimal boundary kernels for density
f + (x|z0 ) + f âˆ’ (x|z0 )
estimation, estimation of distribution functions, or estimation
dx,
Â·
of nonparametric curves, etc.)
2
In the following, we will refer to estimator (13) with kernel
where E[Y |D, X, Z = z0 ] can be estimated by a combination
function
(14) as Î³Ì‚naive . Estimator (13) with kernel function (15)
of the left- and right-hand side limits. This approach does not
is
denoted
as Î³Ì‚RDD . Because of the asymptotic properties derived
exclusively rely on comparing observations across the threshold
below
we
recommend
the use of Î³Ì‚RDD .
but also uses variation within either side of the threshold. The
In
either
case,
estimation
proceeds in two steps and requires
estimand has a similar structure as (7) and (9) and the estimation
nonparametric
first
step
estimates
of m+ , mâˆ’ , d + , and d âˆ’ . (In
properties derived later could easily be extended to this case.
+
âˆ’
the sharp design (9), d and d are not estimated but set to 1
and 0, respectively.) These can be estimated nonparametrically
3. ESTIMATION
by considering only observations to the right or the left of z0 ,
respectively. Since this corresponds to estimation at a boundary
A straightforward estimator of (7) is
point, local linear regression is suggested, which is known to




n
Zi âˆ’z0
+
âˆ’
i=1 mÌ‚ (Xi , z0 ) âˆ’ mÌ‚ (Xi , z0 ) Â· Kh
h
than conventional Nadarayaâ€“
(13) display better boundary behavior
Î³Ì‚ =


,
n  Ë†+
+
Ë†âˆ’ (Xi , z0 ) Â· Kh Zi âˆ’z0
(X
,
z
)
âˆ’
d
d
(x,
z
Watson
kernel
regression.
m
i
0
0 ) is estimated by local linear
i=1
h
regression as the value of a that solves
where mÌ‚ and dË† are nonparametric estimators and Kh (u) is a kern

2



nel function. For the sharp design (9) the estimator simplifies
Y j âˆ’ a âˆ’ b Z j âˆ’ z0 âˆ’ c X j âˆ’ x Â· K j I +
arg
min
j ,
to
a,b,c
0
)
(mÌ‚+ (Xi , z0 ) âˆ’ mÌ‚âˆ’ (Xi , z0 ) ) Â· Kh ( Zi âˆ’z
h
0
Kh ( Zi âˆ’z
h

)

j=1

.

For practical convenience, we will mostly work with product kernel functions below. Product kernel functions also have
the advantage that one can easily incorporate discrete X in the

(16)

where I +
j = 1(Z j > z0 ) and a product kernel is used
K j = K j (x, z0 ) = Îº

Z j âˆ’ z0
hz

Â·

L

l=1

ÎºÌ„

X jl âˆ’ xl
hx

,

(17)

6

Journal of Business & Economic Statistics, XXXX 2018

where L is the dimension of X, and Îº and ÎºÌ„ are univariate kernel
functions with Îº a second-order kernel and ÎºÌ„ a kernel of order
Î» â‰¥ 2.
A result derived later will require higher-order kernels (i.e.,
Î» > 2) if the number of continuous regressors is larger than
3. For applications with at most three continuous regressors, a
second-order kernel will suffice such that ÎºÌ„ = Îº can be chosen.
Note that three different bandwidths hz , hx , h are used. h is the
bandwidth in the matching estimator (13) to compare observations to the left and right of the threshold, whereas hz and hx
determine the local smoothing area for the local linear regression in (16), which uses observations only to the right or only
to the left of the threshold. We need some smoothness assumptions as well as conditions on the bandwidth values. (Note that
the above setup includes global linear regression for the special
case where all bandwidth values are set to infinity. In this case,
the estimator (16) corresponds to a linear regression using only
data points to the right; and analogously on the left-hand side.
While a bandwidth value of infinity minimizes variance it could
lead to a large bias if the true regression curve is nonlinear.
The estimator analyzed below seeks to minimize mean squared
error, that is, the sum of the squared bias and variance.)
Assumption 2.
(i) IID sampling: The data {(Yi , Di , Zi , Xi )} are iid from R Ã—
R Ã— R Ã— RL
(ii) Smoothness:
- m+ (x, z), mâˆ’ (x, z), d + (x, z), d âˆ’ (x, z) are Î» times continuously differentiable with respect to x at z0 with Î»th
derivative HÃ¶lder continuous in an interval around z0 ,
- f + (x, z) and f âˆ’ (x, z) are Î» âˆ’ 1 times continuously differentiable with respect to x at z0 with (Î» âˆ’ 1)th derivative HÃ¶lder continuous in an interval around z0 ,
- m+ (x, z), d + (x, z), and f + (x, z) have two continuous
right derivatives with respect to z at z0 with second
derivative HÃ¶lder continuous in an interval around z0 ,
- mâˆ’ (x, z), d âˆ’ (x, z), and f âˆ’ (x, z) have two continuous
left derivatives with respect to z at z0 with second
derivative HÃ¶lder continuous in an interval around z0 ,
(iii) the univariate Kernel functions Îº and ÎºÌ„ in (17) are symmetric, bounded, Lipschitz, integrate to one and are zero
outside a bounded set; Îº is a second-order kernel and ÎºÌ„ is
a kernel of order Î»,
(iv) Bandwidths: The bandwidths satisfy h, hz , hx â†’ 0 and
nh â†’ âˆ and nhz â†’ âˆ and nhz hLx â†’ âˆ.
(v) Conditional variances: The left and right limits of the
conditional variances limÎµâ†’0 E[(Y âˆ’ m+ (X, Z))2 |X, Z =
z + Îµ] and limÎµâ†’0 E[(Y âˆ’ mâˆ’ (X, Z))2 |X, Z = z âˆ’ Îµ] exist
at z0 .
3.1 Properties of Î³Ì‚naive
With these preliminaries, we consider the properties of Î³Ì‚naive and
Î³Ì‚RDD . The estimator Î³Ì‚naive is, in essence, a combination between
local linear regression in the first step and Nadarayaâ€“Watson
regression in the second step. Although this estimator appears
to be the most obvious one for estimating (7), it has worse statistical properties than Î³Ì‚RDD in the sense that it achieves a lower
rate of convergence. This is due to the missing boundary correction in the second step.

Proposition 1 (Asymptotic properties of Î³Ì‚naive ). Under
Assumptions 1, 2, and 3, the bias and variance terms of Î³Ì‚naive ,
which is the estimator (13) with kernel function (14), are of
order


Bias(Î³Ì‚naive ) = O h + h2z + hÎ»x
1
1
+
nh nhz

var(Î³Ì‚naive ) = O

.

For the sharp design (9), the same results apply. The exact
expressions for bias and variance are given in the appendix.
From this result it can be seen that the fastest rate of convergence possible for Î³Ì‚naive by appropriate bandwidth choices is
1
nâˆ’ 3 . (In the special case where the density is continuous, that
is, f âˆ’ (x|z0 ) = f + (x|z0 ), the bias term with respect to the band2
width h is O(h2 ) such that a convergence rate of nâˆ’ 5 is possible. In this article, we focus on the estimator proposed in the
2
next section, though, because it can obtain nâˆ’ 5 rate irrespective of whether the density is continuous or not.) It is straightforward to show asymptotic normality for this estimator, but
the (first-order) approximation may not be very useful in practice as it would be dominated by the bias and variance terms
1
). The terms corresponding to the estimation error
O(h) and O( nh
+
of mÌ‚ (x, z0 ), mÌ‚âˆ’ (x, z0 ), dË†+ (x, z0 ), dË†âˆ’ (x, z0 ) would be of lower
order and thus ignored in the first-order approximation. The bias
and variance approximation thus obtained would be the same
as in a situation where m+ (x, z0 ), mâˆ’ (x, z0 ), d + (x, z0 ), d âˆ’ (x, z0 )
were known and not estimated. Hence, such an approximation
might not be very accurate in small samples. A more useful
approximation can be obtained by retaining also the lower order
terms. However, it seems more promising to use Î³Ì‚RDD instead.
3.2 Properties of Î³Ì‚RDD
The estimator Î³Ì‚RDD is based on (13), but uses the boundary kernel (15) in the second smoothing step, instead of (14). It thereby
attains the convergence rate of a one-dimensional nonparametric
regression estimator, irrespective of the dimension of X. It thus
obtains the fastest convergence rate possible and is not affected
by a curse of dimensionality. This is achieved by smoothing
over all regressors X and by an implicit boundary adaptation
with respect to Z. (In addition, the bias and variance terms due
to estimating m+ , mâˆ’ , d + , d âˆ’ and due to estimating the density
âˆ’
+
functions f (x|z0 )+2 f (x|z0 ) by the empirical distribution functions
converge at the same rate.)
We derive the asymptotic distribution of this estimator and
show that the asymptotic variance becomes smaller the more
covariates X are included. For the optimal convergence result
further below, we need to be specific about the choice of the
bandwidth values.
Assumption 3. The bandwidths satisfy the following
conditions:
âˆš
lim nh5 = r < âˆ
nâ†’âˆ

lim

nâ†’âˆ

hz
= rz
h

with 0 < rz < âˆ

hÎ»/2
x
= rx < âˆ.
nâ†’âˆ h
lim

FrÃ¶lich and Huber: Including Covariates in the Regression Discontinuity Design

This assumption ensures that the bias and standard deviation
2
of the estimator converge at rate nâˆ’ 5 to zero, that is, at the rate
of a univariate nonparametric regression. Note that the last condition of Assumption 3 provides an upper bound on hx , whereas
Assumption (2iv) provides a lower bound on hx . Suppose that
hx depends on the sample size in the following way:

7


= (d + (x, z0 ) âˆ’ d âˆ’ (x, z0 )) Â·

f âˆ’ (x|z0 )+ f + (x|z0 )
dx
2
âˆ‚
f (xi ,z0 )
âˆ‚
f (x0 ,z0 )
âˆ‚ Î»âˆ’2 f + (x0 ,z0 ) âˆ’1
+
and
Ï‰s = { s!(Î»âˆ’s)!Â·âˆ‚xÎ»âˆ’s âˆ’
Â·(
)
Î»âˆ’1
Î»âˆ’2
âˆ‚x1
âˆ‚xl
l
Î»âˆ’1âˆ’s +
f (xi ,z0 )
âˆ‚
(Î»âˆ’2)!
}/ f + (xi , z0 ) and Ï‰sâˆ’ defined
(Î»âˆ’1)!s!(Î»âˆ’1âˆ’s)!
âˆ‚xÎ»âˆ’1âˆ’s

where

Î»âˆ’s +

analogously
and VRDD

Î»âˆ’1 +

l

hx âˆ nÎ¶ ,

â›

then the bandwidth conditions of Assumptions 2 and 3 together
require that
2
4
<Î¶ â‰¤âˆ’ .
(18)
5L
5Î»
This implies that hx converges at a slower rate to zero than h and
hz when L â‰¥ 4, that is, when X contains four or more continuous
regressors. Therefore, a necessary condition for Assumptions 2
4
2
< âˆ’ 5Î»
or equivalently Î» > L2 .
and 3 to hold jointly is that âˆ’ 5L
As further discussed below, this requires higher-order kernels
if X contains four or more continuous regressors, where as conventional kernels are sufficient otherwise. Assumption 3 is sufficient for the bias and variance to converge at the univariate nonparametric rate, which is summarized in the following theorem.

=

Î¼Ì„22 Î¼Ìˆ0

âˆ’

Ã—
+
+

âˆ’ 2Î¼Ì„2 Î¼Ì„1 Î¼Ìˆ1 +
2 4Î¼Ìƒ2 f 2 (z )
0

Î¼Ì„21 Î¼Ìˆ2

âœ1
Ã—âœ
â rz



f + (x, z0 ) + f âˆ’ (x, z0 )

2

2 2+
ÏƒY2+ (x, z0 ) âˆ’ 2Î³ ÏƒY2+
D (x, z0 ) + Î³ ÏƒD (x, z0 )
f + (x, z0 )
2 2âˆ’
ÏƒY2âˆ’ (x, z0 ) âˆ’ 2Î³ ÏƒY2âˆ’
D (x, z0 ) + Î³ ÏƒD (x, z0 )
dx
âˆ’
f (x, z0 )



m+ (x, z0 ) âˆ’ Î³ d + (x, z0 ) âˆ’ mâˆ’ (x, z0 ) + Î³ d âˆ’ (x, z0 )

2

â

 âŸ
Â· f + (x, z0 ) + f âˆ’ (x, z0 ) dxâŸ
â ,

Theorem 2 (Asymptotic distribution of Î³Ì‚RDD ).
(a) Under Assumptions 1 and 2, the bias and variance terms of
Î³Ì‚RDD , which is the estimator (13) with kernel function (15),
are of order


Bias(Î³Ì‚RDD ) = O h2 + h2z + hÎ»x
var(Î³Ì‚RDD ) = O

1
1
+
nh nhz

(b) Under Assumptions 1, 2, and 3, the estimator is asymptotically normally distributed and converges at the univariate
nonparametric rate
âˆš
nh (Î³Ì‚RDD âˆ’ Î³ ) â†’ N (BRDD , VRDD ) ,
where BRDD
=



r Î¼Ì„22 âˆ’ Î¼Ì„1 Î¼Ì„3
4Î¼Ìƒ f (z0 )
âˆ’ d âˆ’ (x, z0 )
+


m+ (x, z0 ) âˆ’ mâˆ’ (x, z0 ) âˆ’ Î³ d + (x, z0 )

 âˆ‚ 2 f +
âˆ‚2 f âˆ’
(x,
z
)
+
(x, z0 ) dx
0
âˆ‚z2
âˆ‚z2
âˆ‚ 2 m+ (x, z0 ) âˆ‚ 2 mâˆ’ (x, z0 )
âˆ’
âˆ‚z2
âˆ‚z2

rrz2 Î¼Ì„22 âˆ’ Î¼Ì„1 Î¼Ì„3
2Î¼Ìƒ

âˆ‚ 2 d + (x, z0 )
âˆ‚ 2 d âˆ’ (x, z0 ) f âˆ’ (x, z0 ) + f + (x, z0 )
dx
+
Î³
âˆ‚z2
âˆ‚z2
2 f (z0 )

L
Î»âˆ’1 s +
âˆ‚ m (x, z0 ) +
âˆ‚ Î» m+ (x, z0 )
rrx2 Î·Î»
+
Ï‰s
+
Î»
âˆ‚xls
Î»! Â· âˆ‚xl
l=1
s=1

Î»âˆ’1 s âˆ’
âˆ‚ m (x, z0 ) âˆ’ f âˆ’ (x, z0 ) + f + (x, z0 )
âˆ‚ Î» mâˆ’ (x, z0 )
dx
âˆ’
âˆ’
Ï‰s
âˆ‚xls
2 f (z0 )
Î»! Â· âˆ‚xlÎ»
s=1
âˆ’Î³

âˆ’

Î³ rrx2 Î·Î»

L

l=1

âˆ‚ Î» d âˆ’ (x, z0 )
âˆ’
âˆ’
Î»! Â· âˆ‚xlÎ»



âˆ‚ Î» d + (x, z0 )
+
Î»! Â· âˆ‚xlÎ»

Î»âˆ’1

Î»âˆ’1

âˆ‚ s d + (x, z0 ) +
Ï‰s
âˆ‚xls
s=1

âˆ‚ s d âˆ’ (x, z0 ) âˆ’
Ï‰s
âˆ‚xls
s=1



f âˆ’ (x, z0 ) + f + (x, z0 )
dx,
2 f (z0 )

where
ÏƒY2+ (X, z) = limÎµâ†’0 E[(Y âˆ’ m+ (X, Z))2 |X, Z =
+
z + Îµ] and ÏƒY2+
D (X, z) = limÎµâ†’0 E[(Y âˆ’ m (X, Z))(D âˆ’
d + (X, Z))|X, Z = z + Îµ] and ÏƒD2+ (X, z) = limÎµâ†’0 E[(D âˆ’
d + (X, Z))2 |X, Z = z + Îµ] and analogously for ÏƒY2+
2+
(X, z), ÏƒY2+
D (X, z), and ÏƒD (X, z).
For the sharp design (9), the same results are obtained but the
formulas are simpler. d + and d âˆ’ are not estimated but set to 1
and 0, respectively. This implies that = 1 and the terms ÏƒD2+ ,
2âˆ’
+
âˆ’
ÏƒD2âˆ’ , ÏƒY2+
D , ÏƒY D and all derivatives of d (x, z0 ) and d (x, z0 ) are
zero.
Note that Assumption 3 is stronger than needed for the
2
results of Theorem 3. For obtaining nâˆ’ 5 convergence weaker
rate conditions would suffice. In other words, it would not be
needed that the ratios of the bandwidths converge to a welldefined limit point. Assumption 3 permits obtaining concise
and explicit expressions for bias and variance, though. We also
see that undersmoothing is permitted: For a choice of r = 0 in
Assumption 3, the limit bias term is zero, that is, BRDD = 0.
Such undersmoothing is convenient, for example, for developing test statistics. (We thank a referee for pointing this out.)
Part (18) of Assumption 3 requires that Î» > L2 to control the
bias due to smoothing in the X dimension. If X contains at most
three continuous regressors, a second order kernel Î» = 2 can be
used. Otherwise, higher order kernels are required to achieve an
2
nâˆ’ 5 convergence rate. Instead of using higher order kernels, one
could alternatively use local higher order polynomial regression
instead of local linear regression (16). However, when the number of regressors in X is large, this could be inconvenient to
implement in practice since a large number of interaction and
higher order terms would be required, which could give rise to
problems of local multicollinearity in small samples and/or for
small bandwidth values. On the other hand, higher order kernels
are very convenient to implement when a product kernel (17) is
used. Higher order kernels are only necessary for smoothing in
the X dimension but not for smoothing along Z.

8

Journal of Business & Economic Statistics, XXXX 2018

When a second-order kernel is used and X contains at most
three continuous regressors, the bias term BRDD simplifies to
r Î¼Ì„22 âˆ’ Î¼Ì„1 Î¼Ì„3
4Î¼Ìƒ f (z0 )




m+ (x, z0 ) âˆ’ mâˆ’ (x, z0 ) âˆ’ Î³ d + (x, z0 )

 âˆ‚ 2 f +
âˆ‚2 f âˆ’
âˆ’ d âˆ’ (x, z0 )
(x,
z
)
+
(x, z0 ) dx
0
âˆ‚z2
âˆ‚z2
+

rrz2 Î¼Ì„22 âˆ’ Î¼Ì„1 Î¼Ì„3
2Î¼Ìƒ

âˆ‚ 2 m+ (x, z0 ) âˆ‚ 2 mâˆ’ (x, z0 )
âˆ’
âˆ‚z2
âˆ‚z2

f âˆ’ (x, z0 ) + f + (x, z0 )
âˆ‚ 2 d + (x, z0 )
âˆ‚ 2 d âˆ’ (x, z0 )
dx
Â·
+Î³
2
2
âˆ‚z
âˆ‚z
2 f (z0 )
L  2 +
rr2 Î¼2
âˆ‚ m (x, z0 ) âˆ‚ 2 mâˆ’ (x, z0 )
+ x
âˆ’
2
âˆ‚xl2
âˆ‚xl2
l=1
 âˆ’
âˆ‚ 2 d + (x, z0 )
âˆ‚ 2 d âˆ’ (x, z0 )
f (x, z0 ) + f + (x, z0 )
âˆ’Î³
+
Î³
dx.
Â·
2 f (z0 )
2 Â· âˆ‚xl2
2 Â· âˆ‚xl2
âˆ’Î³

It remains to be discussed how the bandwidth values h, hz ,
and hx should be chosen in practice. It is beyond the scope of
this article to develop a data-driven bandwidth selector, and we
therefore limit ourselves to a procedure that is rate optimal, that
is, satisfies Assumptions 2 and 3 as n increases to infinity. The
first part of Assumption 3 suggests to choose h proportional to
1
nâˆ’ 5 , which corresponds to the rate for univariate nonparametric
regression. A simple procedure is to choose h via (least-square)
cross-validation with respect to a nonparametric regression of
Y on Z (outside of a neighborhood around z0 ), which is known
to provide a bandwidth that converges at the desired rate. (At
the same time it is known that the bandwidth obtained by crossvalidation converges only very slowly to the true optimal bandwidth. Nevertheless, many applied researchers proceed by using
the bandwidth obtained from cross-validation and then examine
the sensitivity of the final estimation results to changes in the
bandwidth values by reestimating with various multiples and/or
fractions of the original bandwidth values.)
With an estimate for h, we can choose hz = h which is permitted by Assumptions 2 and 3. If X contains at most three continuous regressors, we can also choose hx = h. On the other hand,
if L â‰¥ 4, then hx should converge at a slower rate than h and hz .
Assumptions 2 and 3 give us some leeway in the exact choice
of hx . If we would like to make the bias small (for reasons discussed in the next section), we would choose the lower bound of
4
(18) to set hx = c1 Â· nâˆ’ 5L +Î´ for a small positive Î´ and some positive constant c1 . This contrasts with the choice for h which is
1
given as h = c2 Â· nâˆ’ 5 . We do not know the optimal c1 and c2 , but
since we only aim for a rate optimal choice, we can set c1 = c2
4
4
1
1
to obtain hx = c1 Â· nâˆ’ 5L +Î´ = c1 nâˆ’ 5L +Î´ Â· n 5 nâˆ’ 5 such that
hx = n

1âˆ’4/L+5Î´
5

Â· h.

We can thus use the bandwidth h obtained via cross-validation
1âˆ’4/L+5Î´
and multiply it with n 5
for some small Î´ to obtain the
(larger) bandwidth value for hx . Having estimated Î³Ì‚RDD with
these bandwidths, one would usually examine the robustness of
the results to the bandwidths values.

3.3 Variance Reduction Through the Use of Control
Variables
In most of the discussion so far, it was permitted that f (x|z) is
discontinuous at z0 such that controlling for X allows reducing
bias. In the case where f (x|z) is continuous, controlling for X is
still helpful: It can reduce the variance of the estimator, which
is shown in the following theorem. Suppose that the covariates
are identically distributed on both sides of the threshold (i.e.,
f (x|z) is continuous) such that Î³ is identified with and without controlling for any X. In this case, one could use Î³Ì‚RDD with
X being the empty set. This estimator is henceforth denoted
as Î³Ì‚no X . Alternatively, one could use a set of control variables
X in the estimator, which we denote as Î³Ì‚RDD as before. Suppose that both estimators are consistent for Î³ . As shown below,
Î³Ì‚no X generally has a larger asymptotic variance than Î³Ì‚RDD . (We
would like to point out that the result in Theorem 4 only refers
to the variance. While we find that covariates reduce variance,
we do not have a corresponding result for the bias. Hence, in
certain situations, asymptotic bias could possibly increase and
we, therefore, cannot rule out that the inclusion of covariates X
in certain cases could even increase MSE if in such situations
an increase in squared bias is larger than the decrease of variance due to the inclusion of X.) On the other hand, an ordering
of squared biases seems impossible under general conditions.
However, by Assumption 3 we can set r = 0, that is, choose a
bandwidth sequence such that the ratio of the squared bias to
variance converges to zero. Such undersmoothing implies that
the asymptotic bias BRDD is zero and the mean squared error is
thus identical to VRDD . With such undersmoothing, we only need
to analyze the asymptotic variance. As outlined below, there are
precision gains by controlling for X even if the RDD estimator
would be consistent without covariates.
For stating Theorem 3 in a concise way, some further notation
is required. Let w + (X, z) = limÎµâ†’0 E[Y âˆ’ Î³ D|X, Z = z + Îµ]
be the right limit of the difference between Y and Î³ D,
and w+ (z) = limÎµâ†’0 E[Y âˆ’ Î³ D|Z = z + Îµ] be the corresponding expression without conditioning on X. (This
also contains the sharp design (9) as a special case,
and
where
w+ (X, z) = limÎµâ†’0 E[Y âˆ’ Î³ |X, Z = z + Îµ]
âˆ’
|X,
Z
=
z
âˆ’
Îµ].)
Define
the
variance
of
w (X, z) = limÎµâ†’0 E[Y

w+ (X, z0 ) as V + = {w + (x, z0 ) âˆ’ w + (z0 )}2 f (x|z0 )dx. Define
w âˆ’ (X, z), w âˆ’ (z) and V âˆ’ analogously as the left limits. Theorem
3 shows that there is a reduction in variance if V + = 0 and/or
V âˆ’ = 0.
To gain some intuition, note that V + is the variance of the conditional expectation of Y given X plus the variance of the conditional expectation of Î³ D given X minus the covariance between
these two terms. Hence, V + is usually nonzero if X is a predictor
of Y and/or of D. On the other hand, V + and V âˆ’ are zero only if
X neither predicts Y nor D. (This discussion excludes the unreasonable case where it predicts
both but not Y âˆ’ Î³ D.) Define

further the covariance C as (w + (x, z0 ) âˆ’ w + (z0 ))(w âˆ’ (x, z0 ) âˆ’
w âˆ’ (z0 )) f (x|z0 )dx. For the case where V + and V âˆ’ are both
nonzero, we define the correlation coefficient R = âˆšVC+V âˆ’ . Now,
we can state the result in terms of the variances and the
correlation coefficient, which also depends on the bandwidth
sequences. The variance of Î³Ì‚RDD is a function of smoothing in
the Z dimension via h and hz . The Î³Ì‚no X estimator only depends

FrÃ¶lich and Huber: Including Covariates in the Regression Discontinuity Design

on hz since there is no smoothing in the second step. A natural choice would thus be h = hz . (The variance of Î³Ì‚RDD can be
reduced even further relative to Î³Ì‚no X by choosing hz < h, but
this would be more of a technical trick than a substantive result.)
This implies rz = 1 in Assumption 3. Using this notation, the
difference in the asymptotic variances can be written as


rz âˆ’ 2 + rz âˆ’ 2 âˆ’
V +
V âˆ’ rzC
VRDD âˆ’ Vno X =
2
2
Ã—

Î¼Ì„22 Î¼Ìˆ0 âˆ’ 2Î¼Ì„2 Î¼Ì„1 Î¼Ìˆ1 + Î¼Ì„21 Î¼Ìˆ2
2 Î¼Ìƒ2 f (z )r
0 z

V + + rz âˆ’2
Vâˆ’ âˆ’
or, if V + and V âˆ’ are both nonzero, as = { rz âˆ’2
2
2
âˆš
2
2
Î¼Ì„ Î¼Ìˆ âˆ’2Î¼Ì„ Î¼Ì„ Î¼Ìˆ +Î¼Ì„ Î¼Ìˆ
rz R V +V âˆ’ }( 2 0 2 Î¼Ìƒ22 f (z1 0 )r1 z 1 2 ), as derived in the appendix.
This implies the following.
Theorem 3. Let Î³Ì‚RDD be the estimator (13) with kernel
function (15) using the set of regressors X, and let Î³Ì‚no X be the
estimator with X being the empty set. Denote the asymptotic
variance of Î³Ì‚no X by Vno X and assume that both estimators consistently estimate Î³ and satisfy Assumptions 2 and 3. Assume
further that the distribution of X is continuous at z0 , that is,
f + (X, z0 ) = f âˆ’ (X, z0 ) a.s.
(a) If V + = V âˆ’ = 0 then
VRDD = Vno X .
(b) Under any of the following conditions
VRDD < Vno X ,
- if V + = 0 and V âˆ’ = 0 or vice versa and rz < 2
- or if V + = 0 and V âˆ’ = 0 and R â‰¥ 0 and rz < 2
- or if V + = 0 and V âˆ’ = 0 and âˆ’1 < R < 0 and
1+R
rz < 2 1âˆ’R
2.
+
- or if V = 0 and V âˆ’ = 0 and R = âˆ’1 and rz < 1.
Hence, if, in case (a) of Theorem 3, where X has no predictive
power neither for Y nor for D, the asymptotic variances are the
same. On the other hand, if X has predictive power either for
Y or for D and one uses the same bandwidths for both estimators (hz = h), the RDD estimator with covariates has a strictly
smaller variance. (In the sharp design (9), X cannot have predictive power for D (conditional on Z), hence predictive power for
Y is needed.) This holds in all cases except for the very implausible scenario where w + (X, z0 ) and w âˆ’ (X, z0 ) are negatively correlated with a correlation coefficient of âˆ’1. In most economic
applications, however, one would rather expect a positive correlation.
(Î³Ì‚RDD has a smaller variance than Î³Ì‚no X as it exploits the available information more effectively. Consider, for simplicity, the
sharp design. Î³Ì‚no X estimates the conditional mean of Y left and
right of the threshold. In terms of iterated expectations, the left
limit of the mean of Y at the threshold could be estimated as
the left limit of the mean of Y conditional on X averaged out
with respect to the distribution of X, using only data points to
the left of the threshold. In contrast, Î³Ì‚RDD estimates the left limit
of the mean of Y conditional on X, but then takes averages with
respect to the distribution of X in the neighborhood of z0 . In
the case where the distribution of X is continuous at z0 , that is,

9

f + (X, z0 ) = f âˆ’ (X, z0 ), the estimator Î³Ì‚RDD uses the data points
Xi in the left and in the right neighborhood of z0 to estimate
f (X, z0 ), whereas Î³Ì‚no X uses only the data on one side of the
threshold. This implies that Î³Ì‚RDD uses more information in the
estimation of the empirical distribution function F (X, z0 ), which
leads to the variance reductions in Theorem 3.
Theorem 3 can easily be extended to show that the RDD estimator with a larger regressor set X, that is, where X âŠ‚ X, has
smaller asymptotic variance than the RDD estimator with X.
(The proof is analogous and is omitted.) Hence, one can combine specific covariates for eliminating bias with adding further
covariates to reduce variance. The more variables are included
in X the smaller the variance will be.)
4. SIMULATIONS
This section presents a simulation study to investigate the
finite sample performance of the suggested method in the context of the sharp and fuzzy RDD. Starting with the former, we
consider the following data-generating process (DGP):
Z, U, V, W âˆ¼ N (0, 1) independently of each other,
D = I{Z > 0},

X1 = Î±D + 0.5U,

X2 = Î±D + 0.5V,

Y = D + 0.5Z âˆ’ 0.25DZ + 0.25Z 2 + Î²(X1 + X2 )
+

Î² 2
(X + X22 ) + W.
2 1

(19)

Both the running variable Z and the unobservables U, V, W ,
which affect the covariates X1 , X2 and the outcome Y , respectively, are standard normally distributed. The parameter Î±
reflects the strength of the association between the distributions
of X1 , X2 and the treatment state D. Î² determines the impact of
X1 , X2 and their higher order terms on Y . In the simulations, we
consider various combinations of Î± and Î². First, we set Î± = 0
and Î² = 0.4 such that the covariates affect the outcome, but
are balanced around the threshold. In this case, controlling for
X = (X1 , X2 ) is not necessary for the consistency of RDD, but
might reduce the variance. Second, we set Î± = 0.2 and Î² = 0.4,
implying that the distribution of X differs across treatment states
at the threshold and that X affects Y .
We run 1000 simulations and consider sample sizes of
n = 1000 and 4000 to analyze RDD estimation based on the
boundary kernel Î³Ì‚RDD , see (15). Least-square cross-validation
(CV) is used to select the bandwidths for the estimation of
m+ (x, z) and mâˆ’ (x, z) (using local linear regression) as well
as Kh (u) required in (13), (For m+ (X, Z) and mâˆ’ (X, Z), the
bandwidth selector CV only uses treated and nontreated observations, respectively.) based on the np package for the statistical
software R by Hayfield and Racine (2008). In addition, we also
make use of undersmoothing and oversmoothing by taking half
or twice the CV bandwidth, respectively (CV/2, 2CV).
We compare our method to conventional RDD estimation
without covariates as implemented in the rdd package for R by
Dimmery (2016), which is based on a local linear regression of Y
on Z. We consider several bandwidths choices, namely, the values picked by the CV procedure for Î³Ì‚RDD ; the method of Imbens
and Kalyanaraman (2012) (IK) for optimal bandwidth selection
in RDD; the robust inference approach of Calonico, Cattaneo,

10

Journal of Business & Economic Statistics, XXXX 2018

Table 1. Simulationsâ€”sharp RDD
Î³Ì‚RDD
Bandwidth

CV

CV/2

Î± = 0, Î² = 0.4
bias
sdev
rmse
Î± = 0.2, Î² = 0.4
bias
sdev
rmse

Î³Ì‚RDD

RDD without X
2CV

CV

IK

CCT

LM

CV

RDD without X

CV/2

2CV

n = 1000
0.00
0.15
0.15

âˆ’0.00
0.27
0.27

âˆ’0.00
0.17
0.17

âˆ’0.00
0.27
0.27

0.00 âˆ’0.00
0.13
0.43
0.13
0.43
n = 1000
âˆ’0.01
0.14
0.14

0.18
0.45
0.48

CV

IK

CCT

LM

âˆ’0.01
0.10
0.10

âˆ’0.00
0.08
0.08

0.17
0.10
0.20

0.17
0.08
0.19

n = 4000
0.01
0.20
0.20

0.00
0.22
0.22

âˆ’0.00
0.15
0.15

âˆ’0.00
0.09
0.09

âˆ’0.00
0.12
0.12

âˆ’0.00
0.09
0.09

0.18
0.20
0.27

0.18
0.22
0.28

0.17
0.15
0.23

âˆ’0.00
0.09
0.09

âˆ’0.00
0.13
0.13

âˆ’0.01
0.09
0.09

âˆ’0.01 âˆ’0.00
0.27
0.10
0.27
0.10
n = 4000
0.16
0.30
0.34

0.17
0.10
0.20

NOTE: â€œCV,â€ â€œCV/2,â€ â€œ2CVâ€ stands for bandwidth selection based on least-square cross-validation, as well as twice and half that value. â€œIKâ€ is the optimal Imbensâ€“Kalyanaraman
(2012) bandwidth. â€œCCTâ€ is the robust inference approach of Calonico, Cattaneo, and Titiunik (2014) (CCT). â€œLMâ€ is the local cross-validation approach of Ludwig and Miller (2007)
based on the median values of the running variable above and below the threshold. â€œbias,â€ â€œsdev,â€ and â€œrmseâ€ report the bias, standard deviation, and root mean squared error of the
respective method.

and Titiunik (2014) (CCT) as implemented as default option in
the rdrobust package for R by Calonico, Cattaneo, and Titiunik
(2015); and the local cross-validation approach of Ludwig and
Miller (2007) (LM) based on the median values of the running
variable above and below the threshold. In all estimations, the
Epanechnikov kernel is used.
Table 1 reports the bias, standard deviation, and root mean
squared error (RMSE) of the estimators for various choices of
Î±, Î² in the sharp RDD. When setting Î± = 0, Î² = 0.4, all procedures are unbiased as expected. Under either sample size,
Î³Ì‚RDD outperforms RDD without X in terms of precision when
using the same CV bandwidth for both estimators. Furthermore, Î³Ì‚RDD with CV is in most cases also more precise than
RDD without X based on the IK, CCT, and LM bandwidths.
(Under n = 1000, Î± = 0, Î² = 0.4, the means (standard deviations) of the CV, IK, CCT, and LM bandwidths for Z are
0.16 (0.06), 0.84 (0.29), 0.66 (0.11), 1.58 (0.51), respectively.
The means and standard deviations are very similar under n =
1000, Î± = 0.2, Î² = 0.4.) As expected, a smaller bandwidth
(CV/2) increases the standard deviation of Î³Ì‚RDD , while a larger

bandwidth (2CV) slightly decreases it. For n = 4000, however,
the differences in precision are quite moderate for various bandwidth choices.
When setting Î± = 0.2 and Î² = 0.4, the biases of Î³Ì‚RDD are
again close to zero, while this is no longer the case for RDD
without X. For n = 1000, Î³Ì‚RDD with CV and 2CV dominates
any RDD without X in terms of bias, standard deviation, and
root mean squared error (RMSE), while Î³Ì‚RDD with CV/2 is less
precise. Under n = 4000, all three versions of Î³Ì‚RDD have a considerably smaller RMSE than any RDD without X.
Second, we consider the case of a fuzzy RDD. We modify
the DGP by replacing D = I{Z > 0} in (19) with D = I{âˆ’1 +
2I{Z > 0} + 0.5U + Q > 0}, with Q âˆ¼ N (0, 1) independently
of any other variable. D is now endogenous even at the threshold due to U entering both the treatment and outcome equation.
The bandwidths used for the estimation of d + (x, z) and d âˆ’ (x, z)
required for the fuzzy RDD method are selected in an analogous
way as for m+ (x, z) and mâˆ’ (x, z). We also consider fuzzy RDD
estimation without covariates based on Dimmery (2016) with
CV, IK, CCT, and LM bandwidth choices, respectively. (Under

Table 2. Simulationsâ€”fuzzy RDD
Î³Ì‚RDD
Bandwidth

CV

CV/2

Î³Ì‚RDD

RDD without X
2CV

Î± = 0, Î² = 0.4

CV

IK

CCT

LM

CV

CV/2

RDD without X
2CV

n = 1000

bias
sdev
rmse
Î± = 0.2, Î² = 0.4

âˆ’0.01
0.27
0.27

0.00
0.42
0.42

âˆ’0.02
0.22
0.22

bias
sdev
rmse

âˆ’0.01
0.28
0.28

âˆ’0.00
0.52
0.52

âˆ’0.03
0.23
0.23

IK

CCT

LM

âˆ’0.01
0.16
0.16

-0.01
0.12
0.12

0.27
0.16
0.31

0.27
0.12
0.30

n = 4000

âˆ’0.05 âˆ’0.02
0.76
0.34
0.76
0.34
n = 1000
0.25
0.67
0.72

CV

0.27
0.33
0.43

âˆ’0.01
0.34
0.34

âˆ’0.01
0.24
0.24

0.01
0.16
0.16

âˆ’0.00
0.18
0.18

0.01
0.14
0.14

0.27
0.34
0.43

0.27
0.23
0.36

0.01
0.15
0.15

0.01
0.20
0.20

0.00
0.15
0.15

âˆ’0.01 0.00
0.34 0.16
0.34 0.16
n = 4000
0.25
0.39
0.46

0.28
0.16
0.32

NOTES: â€œCV,â€ â€œCV/2,â€ â€œ2CVâ€ stands for bandwidth selection based on least-square cross-validation, as well as twice and half that value. â€œIKâ€ is the optimal Imbensâ€“Kalyanaraman
(2012) bandwidth. â€œCCTâ€ is the robust inference approach of Calonico, Cattaneo, and Titiunik (2014) (CCT). â€œLMâ€ is the local cross-validation approach of Ludwig and Miller (2007)
based on the median values of the running variable above and below the threshold. â€œbias,â€ â€œsdev,â€ and â€œrmseâ€ report the bias, standard deviation, and root mean squared error of the
respective method.

FrÃ¶lich and Huber: Including Covariates in the Regression Discontinuity Design

n = 1000, Î± = 0, Î² = 0.4, the means (standard deviations) of
the CV, IK, CCT, and LM bandwidths for Z are 0.23 (0.07),
0.84 (0.29), 0.66 (0.11), 1.73 (0.59), respectively. The means
and standard deviations are very similar under n = 1000, Î± =
0.2, Î² = 0.4.) The results are reported in Table 2 and show a
qualitatively similar pattern as for the sharp RDD. However,
standard errors are generally larger as estimation is based on
the compliers only, which by the definition of the DGP make up
for about 65% of the population.

5. APPLICATION
As an empirical illustration of our method, we use data from
Lalive (2008), who studies a labor market program introduced
in June 1988 that extended the maximum duration of unemployment benefits from 30 to 209 weeks for job seekers aged
50 or older in certain regions of Austria under particular conditions. This suggests the use of a sharp RDD for assessing
the programâ€™s effect on labor market outcomes such as unemployment duration. The treatment is defined based on the age
threshold of 50. As acknowledged by Lalive (2008), however,
a concern is that employees and companies could manipulate
age at entry into unemployment, for example, by postponing a
layoff in a way that the age requirement is just satisfied. This
is a common concern in many applications. If such manipulations are selective with respect to employee characteristics that
also affect labor market outcomes, conventional RDD without
covariates fails to identify the effect of the program due to confounding related to an imbalance of the characteristics around
the threshold. In contrast, our method remains consistent if all
labor market relevant characteristics are plausibly observed in

11

the data. As a word of caution, however, we would like to point
out that this cannot be taken for granted in our application.
For instance, unobserved individual characteristics like motivation, (dis-)utility from work, and self-confidence might predict
both manipulation and labor market success. To consistently
estimate the program effect by our method, it is required that
these factors do not entail confounding conditional on the socioeconomic and employment-related characteristics available in
the data (see the discussion below).
Our analysis makes use of the Austrian social security
database, which includes information on job seekers (age,
employment, unemployment, and earnings history) and the
employers (region and industry), and the Austrian unemployment register, which contains information on the place of
residence and socio-economic characteristics. The universe of
inflows into unemployment between 1986 and 1995 is covered,
and the inflow sample can be followed up until the end of
1998. We refer to Lalive (2008) for a description of sample
adjustments made to the dataset. Specifically, we consider the
female subsample in the age bracket 46 to 53 years living in a
region where the program had been introduced, consisting of
5659 observations. The outcome variable Y is unemployment
duration, measured as weeks registered at the unemployment
office. The running variable Z is distance to the age threshold of
50, measured in months divided by 12. Table 3 reports sample
means and balancing tests at the threshold for potentially labor
market relevant characteristics, which serve as X. The tests are
based on running RDD estimations with the elements in X as
outcome variables using the â€˜rddâ€™ package, which performs
local linear regression around the threshold. Estimates, standard
errors, and p-values are reported for the IK bandwidth and half
of it. Indeed, several covariates are imbalanced around the

Table 3. Covariate sample means and balance tests at the threshold
IK

Married (binary)
Single (binary)
Education: medium (binary)
Education: high (binary)
Foreign (binary)
Replacement rate
log wage in last job
Actual to potential work experience
White collar worker (binary)
Industry: agriculture (binary)
Industry: utilities (binary)
Industry: food (binary)
Industry: textiles (binary)
Industry: wood (binary)
Industry: machines (binary)
Industry: other manufacturing (binary)
Industry: construction (binary)
Industry: tourism (binary)
Industry: traffic (binary)
Industry: services (binary)

IK/2

Sample mean

Difference

p-Value

Difference

p-Value

0.75
0.09
0.22
0.08
0.02
0.44
6.15
0.89
0.32
0.02
0.00
0.05
0.12
0.03
0.08
0.11
0.03
0.32
0.02
0.17

0.16
âˆ’0.05
0.02
0.04
0.01
âˆ’0.01
0.12
0.02
0.16
âˆ’0.01
0.00
âˆ’0.02
0.02
0.00
0.04
0.03
0.03
âˆ’0.03
âˆ’0.03
âˆ’0.05

0.00
0.05
0.51
0.03
0.37
0.01
0.00
0.06
0.00
0.65
0.32
0.31
0.54
0.82
0.05
0.31
0.03
0.46
0.07
0.14

0.16
âˆ’0.05
âˆ’0.00
0.04
0.01
âˆ’0.01
0.18
0.00
0.15
0.02
0.00
âˆ’0.03
âˆ’0.03
0.02
0.06
0.04
0.04
âˆ’0.02
âˆ’0.02
âˆ’0.03

0.01
0.13
0.99
0.14
0.59
0.03
0.00
0.77
0.00
0.20
0.32
0.44
0.38
0.20
0.06
0.33
0.02
0.73
0.37
0.50

NOTE: â€œIK,â€ â€œIK/2â€ denote the optimal Imbensâ€“Kalyanaraman (2012) bandwidth and half that value in an RDD estimation when using each of the covariates as outcome. p-Values are
based on analytic standard errors and account for clustering of age (measured in months).

12

Journal of Business & Economic Statistics, XXXX 2018

Table 4. Effect estimates
Î³Ì‚RDD
Bandwidth h
Treatment effect
Standard error
p-Value

RDD without X

0.1

0.2

0.3

0.4

0.5

0.1

0.2

0.3

0.4

0.5

115.31
4.23
0.00

112.74
4.09
0.00

110.76
4.14
0.00

109.71
4.03
0.00

108.64
4.41
0.00

134.25
9.72
0.00

143.67
12.49
0.00

141.41
9.90
0.00

137.99
8.45
0.00

132.55
8.03
0.00

NOTES: The bandwidths hx , hz for the first step estimates of m+ and mâˆ’ entering Î³Ì‚RDD (see Section 3) are picked by least-square cross-validation. For bandwidth h on the running
variable Z in Î³Ì‚RDD and RDD without X, several values are considered as indicated in the table. Standard errors are based on bootstrapping the estimate 999 times. Sample size is 5659
observations. X includes the variables given in Table 3: marital status, education, migration status, replacement rate, log wage in last job, actual to potential work experience, white collar
worker, and industry.

threshold, which concerns among others marital status, wage
in the last job, and being a white collar worker. (To control the
family-wise error rate of multiple testing in Table 3, one may
apply the (conservative) Bonferroni correction: divide the nominal level of significance by the number of tested covariates (in
our case 20) and reject an individual null hypothesis of covariate balance if the corresponding p-value is even lower. For log
wage in last job and white collar worker, the null hypothesis
is rejected under either bandwidth at the nominal 5% level of
significance.) The results therefore suggest that observations
slightly above the age threshold have somewhat more favorable
labor market relevant characteristics than those slightly below.
Our RDD estimator derived from Equation (7) controls for
differences in X by giving appropriate weights to each of these
characteristics, according to their distribution about the threshold. Consider, for example, the variable marital status, which
is significantly different in Table 3. On average, 75% of the
observations in the sample are married, but the (conditional)
probability of being married is discontinuous at the threshold:
The nonparametric estimates of the probability from the left
and right are 63.7% and 79.9%, respectively. In a symmetric
neighborhood about the threshold, the probability of being married is thus 71.8%. Our method proceeds by estimating the
outcome unemployment duration for married women left and
right of the threshold and multiplying with a weight of 0.718.
An analogous approach applies to unmarried women using a
weight of 0.282. Hence, a weighted average with respect to
the fraction of married women in a symmetric neighborhood
about the threshold is taken. This removes the discontinuity in
marital status: The 63.7% married women to the left are upweighted with 0.718/0.637, while the 79.9% married women to
the right are down-weighted with 0.718/0.799. Accordingly, the
36.3% unmarried women to the left are down-weighted with
0.282/0.363, while those 20.1% to the right are up-weighted
with 0.282/0.201. In contrast, RDD estimation not controlling
for X compares the unemployment duration left and right of the
threshold without weighting, thereby ignoring that there are, for
example, fewer married women to the left than to the right of the
threshold.
Table 4 presents the results for Î³Ì‚RDD when using crossvalidation for the bandwidth selection of hx , hz in the first-step
estimation of m+ and mâˆ’ . Different from the simulations in
Section 4, however, the covariates now contain both continuous
and discrete elements. We therefore apply the method of Racine
and Li (2004), which allows for both continuous and discrete
regressors by means of product kernels and is implemented

in the â€œnpâ€ package of Hayfield and Racine (2008). We use
the Epanechnikov, Wang and van Ryzin (1981), and Aitchison
and Aitken (1976) kernel functions for continuous, ordered
discrete, and unordered discrete covariates, respectively. We
consider several choices for bandwidth h in the Epanechnikovbased boundary kernel function for the running variable in
(13): 0.1, 0.2, . . . , 0.5. We also compare the results to RDD
regression without covariates based on the â€œrddâ€ package
with the same bandwidth choice h. The standard errors of
any method are based on nonparametrically bootstrapping the
respective estimates 999 times, that is, randomly resampling the
original data with replacement and applying the estimators to
the bootstrap samples. The Î³Ì‚RDD estimates point to a substantial
increase in unemployment duration by about 110 weeks.
The results are highly significant, as the standard errors of
roughly 4 weeks are quite moderate. When using RDD without
X, both the effect of about 140 weeks and the standard error
of about 10 weeks are substantially higher. For each bandwidth
value considered, the estimates are statistically significantly different between the methods (at the 5% level based on bootstrapping the differences in the estimates 999 times). This indicates
that there might be some confounding due to observed covariates. Also the effects reported in Table 3 columns (3) and (4) of
Lalive (2008) when omitting X and either using a global RDD
model with a higher order polynomial for the running variable or
a local linear model with a very small bandwidth are somewhat
higher than Î³Ì‚RDD (122 to 126 weeks). In contrast, the effect of
103 weeks presented in column (6) of Table 3 in Lalive (2008)
is based on linearly controlling for covariates. Our somewhat
higher (and at the 5% level statistically significantly different)
estimates (when bootstrapping the differences) are likely due to
using a more flexible specification with respect to the association of Y and X.

6. CONCLUSION
In this article, the regression discontinuity design (RDD) has
been generalized to incorporate covariates X in a fully nonparametric way. Including covariates can reduce the variance and
eliminate biases if X is discontinuously distributed at the threshold. It has been shown that the curse of dimensionality does not
apply and that the average treatment effect (on the local compli2
ers) can be estimated at rate nâˆ’ 5 irrespective of the dimension of
X. For achieving this rate, a boundary RDD estimator has been
suggested. We investigated the finite sample properties of our

FrÃ¶lich and Huber: Including Covariates in the Regression Discontinuity Design

estimator in simulations and applied it to estimate the effect of
age-dependent unemployment benefits on unemployment duration in Austrian labor market reform, where manipulation at the
threshold is a potential concern.
SUPPLEMENTARY MATERIALS
The supplementary appendix contains all proofs.
ACKNOWLEDGMENTS
This is a substantially revised version of the 2007 IZA Working Paper 3024.
The authors have benefitted from comments by three anonymous referees, the
associate editor, and the editor.

FUNDING
Markus FrÃ¶lich acknowledges financial support from the Research Center
SFB 884 â€˜Political Economy of Reformsâ€™ Project B5, funded by the German
Research Foundation (DFG).
[Received January 2015. Revised November 2017.]

REFERENCES
Aitchison, J., and Aitken, C. (1976), â€œMultivariate Binary Discrimination by the
Kernel Method,â€ Biometrika, 63, 413â€“420. [12]
Battistin, E., and Rettore, E. (2008), â€œIneligibles and Eligible Non-Participants
as a Double Comparison Group in Regression-Discontinuity Designs,â€ Journal of Econometrics, 142, 715â€“730. [2]
Black, D., Galdo, J., and Smith, J. (2007), â€œEvaluating the Regression Discontinuity Design Using Experimental Data,â€ Mimeo, University of Michigan,
USA. [2]
Calonico, S., Cattaneo, M. D., Farrell, M. H., and Titiunik, R. (2018), â€œRegression Discontinuity Designs Using Covariates,â€ Review of Economics and
Statistics, forthcoming. [2]
Calonico, S., Cattaneo, M. D., and Titiunik, R. (2014), â€œRobust Nonparametric
Confidence Intervals for Regression-Discontinuity Designs,â€ Econometrica,
82, 2295â€“2326. [1]
â€”â€”â€” (2015), â€œrdrobust: An R Package for Robust Nonparametric Inference in
Regression-Discontinuity Designs,â€ R Journal, 7, 38â€“51. [10]
de Chaisemartin, C. (2017), â€œTolerating Defiance? Local Average Treatment
Effects Without Monotonicity,â€ Quantitative Economics, 8, 367â€“396. [4]
Dimmery, D. (2016), Package â€˜rddâ€™, Manual for the Statistical Software
â€˜Râ€™,â€ The Comprehensive R Archive Network, available at https://cran.rproject.org/web/packages/rdd/rdd.pdf [9,10]
Dong, Y. (2014), â€œAn Alternative Assumption to Identify LATE in Regression
Discontinuity Designs,â€ unpublished manuscript, University of California
Irvine. [1,2]
Eugster, B., Lalive, R., Steinhauer, A., and ZweimÃ¼ller, J. (2017), â€œCulture, Work Attitudes and Job Search: Evidence From the Swiss Language
Border,â€ Journal of the European Economic Association, 15, 1056â€“1100.
[2]
Fisher, R. (1935), Design of Experiments, Edinburgh: Oliver and Boyd. [2]
Frandsen, B., FrÃ¶lich, M., and Melly, B. (2012), â€œQuantile Treatment Effects
in the Regression Discontinuity Design,â€ Journal of Econometrics, 168,
382â€“395. [4]
FrÃ¶lich, M. (2007), â€œNonparametric IV Estimation of Local Average Treatment
Effects With Covariates,â€ Journal of Econometrics, 139, 35â€“75. [3]
FrÃ¶lich, M., and Melly, B. (2013), â€œUnconditional Quantile Treatment Effects
Under Endogeneity,â€ Journal of Business and Economic Statistics (JBES),
31, 346â€“357. [4]

13

Gasser, T., and MÃ¼ller, H. (1979), â€œKernel Estimation of Regression Functions,â€
in Smoothing Techniques for Curve Estimation, Lecture Notes in Mathematics 757, eds. T. Gasser, and M. Rosenblatt, Berlin: Springer, pp. 23â€“68.
[5]
Gasser, T., MÃ¼ller, H., and Mammitzsch, V. (1985), â€œKernels for Nonparametric
Curve Estimation,â€ Journal of the Royal Statistical Society, Series B, 47,
238â€“252. [5]
Gelman, A., and Imbens, G. (2018), â€œWhy High-Order Polynomials Should Not
be Used in Regression Discontinuity Designs,â€ Business & Economic Statistics, forthcoming. [1]
Hahn, J., Todd, P., and van der Klaauw, W. (2001), â€œIdentification and Estimation of Treatment Effects with a Regression-Discontinuity Design,â€ Econometrica, 69, 201â€“209. [1,2,5]
Hayfield, T., and Racine, J. (2008), â€œNonparametric Econometrics: The np Package,â€ Journal of Statistical Software, 27, 1â€“32. [9,12]
Imbens, G. (2001), â€œSome Remarks on Instrumental Variables,â€ in Econometric Evaluation of Labour Market Policies, eds. M. Lechner, and F. Pfeiffer,
Heidelberg: Physica/Springer, pp. 17â€“42. [4]
Imbens, G., and Angrist, J. (1994), â€œIdentification and Estimation of Local Average Treatment Effects,â€ Econometrica, 62, 467â€“475. [3]
Imbens, G., and Kalyanaraman, K. (2012), â€œOptimal Bandwidth Choice for the
Regression Discontinuity Estimator,â€ The Review of Economic Studies, 79,
933â€“959. [1,9]
Imbens, G. W., and Lemieux, T. (2008), â€œRegression Discontinuity Designs: A
Guide to Practice,â€ Journal of Econometrics, 142, 615â€“635. [1]
Jones, M. (1993), â€œSimple Boundary Correction for Kernel Density Estimation,â€
Statistics and Computing, 3, 135â€“146. [5]
Jones, M., and Foster, P. (1996), â€œA Simple Nonnegative Boundary Correction
Method for Kernel Density Estimation,â€ Statistica Sinica, 6, 1005â€“1013. [5]
Lalive, R. (2008), â€œHow Do Extended Benefits Affect Unemployment Duration? A Regression Discontinuity Approach,â€ Journal of Econometrics, 142,
785â€“806. [2,11,12]
Lee, D. (2008), â€œRandomized Experiments From Non-Random Selection in
U.S. House Elections,â€ Journal of Econometrics, 142, 675â€“697. [2]
Lee, D., and Card, D. (2008), â€œRegression Discontinuity Inference With Specification Error,â€ Journal of Econometrics, 142, 655â€“674. [1]
Lee, D., and Lemieux, T. (2010), â€œRegression Discontinuity Designs in Economics,â€ Journal of Economic Literature, 48, 281â€“355. [1]
Ludwig, J., and Miller, D. L. (2007), â€œDoes Head Start Improve Childrenâ€™s Life
Chances? Evidence from a Regression Discontinuity Design,â€ The Quarterly Journal of Economics, 122, 159â€“208. [10]
McCrary, J. (2008), â€œManipulation of the Running Variable in the Regression Discontinuity Design: A Density Test,â€ Journal of Econometrics, 142,
698â€“714. [1]
MÃ¼ller, H. (1991), â€œSmooth Optimum Kernel Estimators Near Endpoints,â€
Biometrika, 78, 521â€“530. [5]
Newey, W. (1994), â€œKernel Estimation of Partial Means and a General Variance
Estimator,â€ Econometric Theory, 10, 233â€“253. [4]
Neyman, J. (1923), â€œOn the Application of Probability Theory to Agricultural
Experiments. Essay on Principles,â€ Statistical Science, 5, 463â€“480. [2]
Porter, J. (2003), â€œEstimation in the Regression Discontinuity Model,â€ Mimeo.
[1]
Racine, J., and Li, Q. (2004), â€œNonparametric Estimation of Regression Functions with Both Categorical and Continuous Data,â€ Journal of Econometrics,
119, 99â€“130. [5,12]
Rubin, D. (1978), â€œBayesian Inference for Causal Effects: The Role of Randomization,â€ Annals of Statistics, 6, 34â€“58. [2]
Tenreiro, C. (2013), â€œBoundary Kernels for Distribution Function Estimation,â€
REVSTAT-Statistical Journal, 11, 169â€“190. [5]
Trochim, W. (1984), Research Design for Program Evaluation: The RegressionDiscontinuity Approach, Beverly Hills: Sage Publications. [2]
Urquiola, M., and Verhoogen, E. (2009), â€œClass-Size Caps, Sorting, and the
Regression-Discontinuity Design,â€ The American Economic Review, 99,
179â€“215. [2,3]
van der Klaauw, W. (2008), â€œBreaking the Link Between Poverty and Low Student Achievement: An Evaluation of Title I,â€ Journal of Econometrics, 142,
731â€“756. [1,2]
Wang, M., and van Ryzin, J. (1981), â€œA Class of Smooth Estimators for Discrete
Distributions,â€ Biometrika, 68, 301â€“309. [12]

