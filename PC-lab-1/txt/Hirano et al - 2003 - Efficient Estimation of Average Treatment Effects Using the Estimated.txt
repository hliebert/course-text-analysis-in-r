Econometrica, Vol. 71, No. 4 (July, 2003), 1161–1189

EFFICIENT ESTIMATION OF AVERAGE TREATMENT EFFECTS
USING THE ESTIMATED PROPENSITY SCORE
By Keisuke Hirano, Guido W. Imbens, and Geert Ridder1

We are interested in estimating the average effect of a binary treatment on a scalar
outcome. If assignment to the treatment is exogenous or unconfounded, that is, independent of the potential outcomes given covariates, biases associated with simple treatmentcontrol average comparisons can be removed by adjusting for differences in the covariates.
Rosenbaum and Rubin (1983) show that adjusting solely for differences between treated
and control units in the propensity score removes all biases associated with differences in
covariates. Although adjusting for differences in the propensity score removes all the bias,
this can come at the expense of efﬁciency, as shown by Hahn (1998), Heckman, Ichimura,
and Todd (1998), and Robins, Mark, and Newey (1992). We show that weighting by the
inverse of a nonparametric estimate of the propensity score, rather than the true propensity
score, leads to an efﬁcient estimate of the average treatment effect. We provide intuition
for this result by showing that this estimator can be interpreted as an empirical likelihood
estimator that efﬁciently incorporates the information about the propensity score.
Keywords: Propensity score, treatment effects, semiparametric efﬁciency, sieve
estimator.

1 introduction
Estimating the average effect of a binary treatment or policy on a scalar
outcome is a basic goal of many empirical studies in economics. If assignment to
the treatment is exogenous or unconfounded (i.e., independent of potential outcomes conditional on covariates or pre-treatment variables, an assumption also
known as selection on observables), the average treatment effect can be estimated
by matching2 or by averaging within-subpopulation differences of treatment and
control averages. If there are many covariates, such strategies may not be desirable or even feasible. An alternative approach is based on the propensity score,
the conditional probability of receiving treatment given covariates. Rosenbaum
and Rubin (1983, 1985) show that, under the assumption of unconfoundedness,
adjusting solely for differences in the propensity score between treated and control units removes all biases. Recent applications of propensity score methods
1

We thank Gary Chamberlain, Jinyong Hahn, James Robins, Donald Rubin, Jeffrey Wooldridge,
four anonymous referees, seminar participants at the University of Chicago, UC Davis, the University
of Michigan, Michigan State University, UC Irvine, the University of Miami, Johns Hopkins, and
Harvard-MIT, and especially Whitney Newey for comments. Financial support for this research was
generously provided through NSF Grants SBR-9818644 and SES-0136789 (Imbens) and SES-9985257
(Hirano).
2
See Abadie and Imbens (2002) for a formal discussion of matching estimators in this context.
1161

1162

k. hirano, g. imbens, and g. ridder

in economics include Dehejia and Wahba (1999), Heckman, Ichimura, and Todd
(1997), and Lechner (1999).
Although adjusting for differences in the propensity score removes all bias, it
need not be as efﬁcient as adjusting for differences in all covariates, as shown
by Hahn (1998), Heckman, Ichimura, and Todd (1998), and Robins, Mark, and
Newey (1992). However, Rosenbaum (1987), Rubin and Thomas (1996), and
Robins, Rotnitzky, and Zhao (1995) show that using parametric estimates of the
propensity score, rather than the true propensity score, can avoid some of these
efﬁciency losses.
In this paper we propose estimators that are based on adjusting for nonparametric estimates of the propensity score. The proposed estimators weight observations by the inverse of nonparametric estimates of the propensity score, rather
than the true propensity score. Extending results from Newey (1994) to derive
the large sample properties of these semiparametric estimators, we show that
they achieve the semiparametric efﬁciency bound. We also show that for the case
in which the propensity score is known the proposed estimators can be interpreted as empirical likelihood estimators (e.g., Qin and Lawless (1994), Imbens,
Spady, and Johnson (1998)) that efﬁciently incorporate the information about
the propensity score.
Our proposed estimators are relevant whether the propensity score is known
or not. In randomized experiments, for example, the propensity score is known
by design. In that case the proposed estimators can be used to improve efﬁciency
over simply differencing treatment and control averages. With the propensity
score known, an attractive choice for the nonparametric series estimator for the
propensity score is to use the true propensity score as the leading term in the
series. The proposed estimators can also be used in the case where the propensity score is unknown. In that case they are alternatives to the previously proposed efﬁcient estimators that require nonparametric estimation of functions in
addition to the propensity score.
In the next section we lay out the problem and discuss the prior literature.
In Section 3 we provide some intuition for our efﬁciency results by examining
a simpliﬁed version of the problem. In Section 4 we give the formal conditions
under which weighting by the estimated propensity score results in an efﬁcient
estimator. Section 5 concludes.

2 the basic setup and previous results
21 The Model
We have a random sample of size N from a large population. For each unit i
in the sample, for i = 1     N , let Ti indicate whether the treatment of interest
was received, with Ti = 1 if unit i receives the active treatment, and Ti = 0 if unit i
receives the control treatment. Using the potential outcome notation popularized
by Rubin (1974), let Yi 0 denote the outcome for each unit i under control

estimation of average treatment effects

1163

and Yi 1 the outcome under treatment.3 We observe Ti and Yi , where Yi ≡
Ti · Yi 1 + 1 − Ti  · Yi 0. In addition, we observe a vector of covariates denoted
by Xi .4 Initially we focus on the population average treatment effect:
(1)

 ≡ EY 1 − Y 0

We shall also discuss estimation of weighted average treatment effects,

EY 1 − Y 0X = xgxdF x

(2)

wate ≡
gxdF x
where g· is a known function of the covariates.5 In the special case where the
weight function gx is equal to the propensity score px = PrT = 1X = x,
this leads under the unconfoundedness assumption to the average effect for the
treated:
(3)

treated ≡ EY 1 − Y 0T = 1

The central problem of evaluation research is that for unit i we observe either
Yi 0 or Yi 1, but never both. To solve the identiﬁcation problem, we maintain
throughout the paper the unconfoundedness assumption (Rubin (1978), Rosenbaum and Rubin (1983)), related to the selection-on-observables assumption
(Barnow, Cain, and Goldberger (1980)), which asserts that conditional on the
observed covariates, the treatment indicator is independent of the potential outcomes. Formally, we have the following assumption:
Assumption 1 (Unconfounded Treatment Assignment):
T ⊥Y 0 Y 1  X
Heckman, Ichimura, and Todd (1998) point out that for identiﬁcation of the
average treatment effect  this assumption can be weakened to mean independence EY tT  X = EY tX for t = 0 1. If one is interested in the average
effect for the treated, the assumption can be further weakened to only require
3
Implicit in this notation is the stability assumption or SUTVA (Rubin (1978)) that units are not
affected by receipt of treatment by others, and that there is only one version of the treatment.
4
These variables are assumed not to be affected by the treatment.
5
An alternative estimand, which we do not consider here, is the direct weighted average treatment
effect of the form

EY 1 − Y 0X = xgx dx

dwate =

gx dx

where the weighting is only over the known function gx. Note that in general F x is unknown
so that knowledge of gx does not imply knowledge of gx dF x and the other way around;
estimation strategies for the two estimands wate and dwate are in general different. Estimands of the
latter type can be ﬁtted into the framework of Robins and Ritov (1997).

1164

k. hirano, g. imbens, and g. ridder

that EY 0T  X = EY 0X. In this paper we focus on the full independence
assumption in order to be consistent with much of the literature.
Under unconfoundedness we can estimate the average treatment effect conditional on covariates, x ≡ EY 1 − Y 0X = x, because
x = EY 1 − Y 0X = x
= EY 1T = 1 X = x − EY 0T = 0 X = x
= EY T = 1 X = x − EY T = 0 X = x
The population average treatment effect can then be obtained by averaging the
x over the distribution of X  = EX. In practice, the strategy of forming
cells and comparing units with exactly the same value of X may fail if X takes
on too many distinct values.6 To avoid the need to match units on the values of
all covariates, Rosenbaum and Rubin (1983, 1985) developed an approach based
on the propensity score, the probability of selection into the treatment group:
(4)

px ≡ PrT = 1X = x = ET X = x

which is assumed to be bounded away from zero and one. Their key insight
was that if treatment and potential outcomes are independent conditional on all
covariates, they are also independent conditional on the conditional probability
of receiving treatment given covariates. Formally, as shown by Rosenbaum and
Rubin (1983), unconfoundedness implies
(5)

T ⊥Y 0 Y 1  pX

implying that adjustment for the propensity score sufﬁces for removing all biases
associated with differences in the covariates.
22 Previous Results
The model set out above, as well as related models, have been examined by a
number of researchers. In an important paper Hahn (1998), studying the same
model as we do here, calculates the semiparametric efﬁciency bounds, and proposes efﬁcient estimators, for  and treated . Hahn’s estimator for , which is efﬁcient irrespective of whether the propensity score is known, nonparametrically
estimates the two conditional expectations EY T X = x and EY 1 − T X = x
as well as the propensity score px, and then imputes the missing potential
i 0 = 
i 1 = 
EY T Xi /p̂Xi  and Y
EY 1 − T Xi /1 − p̂Xi .
outcomes as Y
Hahn shows that conditioning only on the true propensity score rather than on the
6
A related issue is whether standard asymptotic theory provides adequate approximations to the
sampling distributions of estimators based on initial nonparametric estimates of conditional means,
especially when the dimension of the conditioning variable is high. For discussions of these issues,
see Robins and Ritov (1997) and Angrist and Hahn (1999) and references therein.

estimation of average treatment effects

1165

full set of covariates does not in general lead to an efﬁcient estimator. In addition Hahn concludes that knowledge of the propensity score is informative for
estimating treated and derives efﬁcient estimators both with and without such
knowledge. A difference between Hahn’s estimators and our proposed estimators is that Hahn requires nonparametric estimation of the propensity score as
well as the two conditional means EY T X = x and EY 1−T X = x, whereas
our proposed estimator only requires nonparametric estimation of the propensity
score.
Heckman, Ichimura, and Todd (1997, 1998) and Heckman, Ichimura, Smith,
and Todd (1998) focus on treated , the average treatment effect for the treated.
They consider estimators based on local linear regressions of the outcome on
treatment status and either covariates or the propensity score. They conclude that
in general there is no clear ranking of their estimators; under some conditions
the estimator based on adjustment for all covariates is superior to the estimator
based on adjustment for the propensity score, and under other conditions the
second estimator is to be preferred. Lack of knowledge of the propensity score
does not alter this conclusion.
Rosenbaum (1987) and Rubin and Thomas (1996) investigate the differences
between using the estimated and the true propensity score when the propensity
score belongs to a parametric family. They conclude that there can be efﬁciency
gains from using the estimated propensity score. Our results show that by making
the speciﬁcation of the propensity score sufﬁciently ﬂexible, this approach leads
to a fully efﬁcient estimator.
Robins, Mark, and Newey (1992), Robins and Rotnitzky (1995), Robins, Rotnitzky, and Zhao (1995), and Rotnitzky and Robins (1995) study the related
problem of inference for parameters in regression models where some data are
Missing At Random (MAR; Rubin (1976), Little and Rubin (1987)). Rotnitzky
and Robins (1995) show that in parametric settings weighting using the estimated
rather than true selection probability can improve efﬁciency. They suggest it may
be possible to achieve full efﬁciency by allowing the dimension of the model for
the selection probability to grow with the sample size. For this missing data case
Robins and Rotnitzky (1995) also propose an efﬁcient estimator that relies on
an initial consistent, but not necessarily efﬁcient, estimator of the full population
parameters. The estimator we propose is efﬁcient (as is the estimator proposed
by Hahn), but does not require an initial consistent estimator.

3 a simple example with binary covariates
To develop some intuition for the formal results that will be presented in
Section 4, we consider the simpler problem of estimating the population average of a variable Y , 0 = EY , given a random sample of size N of the triple
Ti  Xi  Ti · Yi . In other words, Ti and Xi are observed for all units in the sample,
but Yi is only observed if Ti = 1. We provide a heuristic argument for efﬁciency
of using estimated weights, deferring formal results to Section 4.

1166

k. hirano, g. imbens, and g. ridder

The analog to the unconfoundedness assumption here is the assumption that
the Yi are Missing At Random (MAR; Rubin (1976)), or
T ⊥Y  X
The role of the propensity score is played here by the selection probability:
px = ET X = x = PrT = 1X = x. First, we restrict our attention in this
section to the case with a single binary covariate.7 Let Ntx denote the number of
observations with Ti = t and Xi = x, for t x ∈ 0 1 . Furthermore, suppose the
true selection probability is constant, px = 1/2 for all x ∈ 0 1 .8 The normalized variance bound for 0 is
(6)

Vbound = 2 · EVY X + VEY X

The “true weights” estimator weights the complete observations by the inverse
of the true selection probability:
(7)

N
N

1 
Yi · Ti
Yi · Ti
ˆ tw = 1
=

N i=1 pXi  N i=1 1/2

Its large sample normalized variance is
Vtw = 2·EVY X+VEY X+EEY X2  = Vbound +EEY X2 
strictly larger than the variance bound (6) unless EY X = 0.
The second estimator weights the complete observations by the inverse of a
nonparametric estimate of the selection probability. This estimator is the main
focus of the paper and it will be discussed in Section 4 in more general settings.
In the current setting the estimated selection probability is simply the proportion
of observed outcomes for a given value of the covariate. For units with Xi = 0 the
proportion of observed outcomes is N10 /N00 +N10 , and for units with Xi = 1 the
proportion of observed outcomes is N11 /N01 +N11 . Thus the estimated selection
probability is

N10 /N00 + N10  if x = 0
p̂x =
N11 /N01 + N11  if x = 1
The proposed “estimated weights” estimator is then
(8)
7

N

Yi · Ti
ˆ ew = 1

N i=1 p̂Xi 

An efﬁcient estimator is easily obtained by averaging the within-subsample difference of treatment/control averages. It can also be found by specializing the more general estimators in Robins
and Rotnitzky (1995) and Hahn (1998) to this simple case. The discussion here is solely intended to
convey intuition for the formal results that will be presented in Section 4.
8
Thus the missing data are Missing Completely At Random (MCAR; Rubin (1976), Little and
Rubin (1987)).

estimation of average treatment effects

1167

The normalized variance of this estimator is equal to the variance bound:
Vew = 2 · EVY X + VEY X = Vbound 
Not only does the weighting estimator with nonparametrically estimated weights
have a lower variance than the estimator using the “true” weights in this simple
case, but it is in fact fully efﬁcient. In the remainder of this section we shall provide some intuition for this result. This will suggest why this efﬁciency property
may carry over to the case with continuous and vector-valued covariates, as well
as with general dependence of the selection probability or propensity score on
the covariates.
An alternative interpretation of the estimated-weights estimator is based on
a Generalized Method of Moments (GMM) representation (Hansen (1982)).
Under the assumption that the selection probability is px = 1/2, we can estimate 0 using the single moment restriction E 1 Y  X T  0  = 0, with
1 y t x

=

y·t
y·t
− =
− 
px
1/2

The GMM estimator based on the single moment restriction 1 ·, given knowledge of the selection probability, is the true-weights estimator ˆ tw in (7).
However, this estimator is not necessarily efﬁcient, because it ignores the additional information that is available in the form of knowledge of the selection
probability. This additional information can be written in moment condition
form as ET − pXX = ET − 1/2X = 0. With a binary covariate this conditional moment restriction corresponds to two marginal moment restrictions,
E 2 Y  T  X 0  = 0, with:


x · t − 1/2
y
t
x

=

2
1 − x · t − 1/2
Estimating 0 in a generalized method of moments framework using the
moments 1 · and 2 · leads to a fully efﬁcient estimator.9 Here it is of particular interest to consider the empirical likelihood estimator (e.g., Qin and Lawless
(1994), Imbens (1997), Kitamura and Stutzer (1997), Imbens, Spady, and Johnson (1998)). Empirical likelihood estimation is based on maximization, both over
a nuisance parameter  = 1      N  and over the parameter of interest , of
the logarithm of the empirical likelihood function:
(9)

L =

N


ln i 

i=1

9

Although 2 · does not depend on the parameter of interest, 2 · is generally correlated with
·. Thus there can be efﬁciency gains from using both sets of moment conditions as in seemingly
unrelated regressions. See, e.g., Hellerstein and Imbens (1999) and Qian and Schmidt (1999).
1

1168

k. hirano, g. imbens, and g. ridder


subject to the adding-up restriction
i i = 1 and the moment conditions

ˆ el by maximizing (9) subject to the
ˆ

y

t

x


=
0.
Solving
for

and
i i
i
i
i i
restrictions leads, after some manipulation, to:

N11
− 1/2
N +N
· xi · ti − 1/2
ˆ i = 1 + 01 11
1/4
+

N10
N00 +N10

− 1/2

1/4

−1

· 1 − xi  · ti − 1/2



which in turn implies
ˆ el =

N


2 · ˆ i · Yi · Ti = ˆ ew 

i=1

equal to the estimated weights estimator.
The above discussion generalizes directly to the case with general discrete
covariates. With continuous covariates knowledge of the propensity score implies
a conditional moment restriction corresponding to an inﬁnite number of unconditional moment restrictions (e.g., Chamberlain (1987)). Using a series estimator
for the propensity score captures the information content of such a conditional
moment restriction by a sequence of unconditional moment restrictions.
The empirical likelihood interpretation suggests that moving from the trueweights estimator to the estimated-weights estimator increases efﬁciency in the
same way that adding moment restrictions in a generalized method of moments
framework improves efﬁciency. A similar ﬁnding appears in Crepon, Kramarz,
and Trognon (1998) who ﬁnd that using a reduced set of moment conditions, in
which nuisance parameters are replaced by solutions to the sample analogs of the
remaining moment conditions, is asymptotically equivalent to using the full set
of moment conditions, whereas using the true values of the nuisance parameters
may lead to efﬁciency losses. These results are also linked to the literature on
weighting in stratiﬁed sampling. Translated to this simple example, the results by
Lancaster (1990) suggest studyingthe distribution
of the various estimators con

ditional on the ancillary statistics Ti , Xi , and Ti · Xi . Conditional on those
three statistics the true-weights estimator is biased, while the estimated-weights
estimator remains unbiased. Rosenbaum (1987) discusses this issue speciﬁcally
in the context of estimated versus true propensity scores. In a general discussion
of weighted M-estimators, Wooldridge (1999, 2002) shows that weighting by the
inverse of estimated rather than population probabilities can lead to efﬁciency
gains.
4 efﬁcient estimation using estimated weights
In this section we present the main results of the paper. We discuss three
distinct cases. First, we consider the problem of estimating the population average treatment effect under the unconfoundedness assumption. This includes as

estimation of average treatment effects

1169

a special case the extension of the binary-covariate MAR example of the previous section to continuous covariates. Second, we consider estimation of weighted
average treatment effects. Finally, we consider estimation of the effect of the
treatment on the treated which, in the known propensity score case, will follow
directly from the solution to the general weighted average treatment effect case.
This discussion will shed additional light on Hahn’s (1998) interesting result that
for this parameter knowledge of the propensity score affects the efﬁciency bound,
as well as on the ﬁndings in Heckman, Ichimura, and Todd (1998) that in the
case of the average treatment effect for the treated, neither using the true nor
using the estimated propensity score dominates the other.
41 Estimating Population Average Treatment Effects
In this section we use the set up from Section 2 with a pair of potential outcomes Y 0 Y 1 for each unit and focus on efﬁcient estimation of the population average treatment effect,  ∗ = EY 1 − Y 0.10 As before, px = PrT =
1X = x is the propensity score, the probability of receiving the active treatment.
We maintain the unconfoundedness assumption. Deﬁne t x ≡ EY tX =
x and t2 x = VY tX = x to be the conditional mean and variance of
Y t respectively. Under unconfoundedness we have t x = EY T = t X = x
and t2 x = VY T = t X = x. We can characterize  ∗ through the moment
equation:
E Y  T  X  ∗  p∗ X = 0
where
(10)

y t x  px =

y·t
y · 1 − t
−
− 
px 1 − px

Given an estimator p̂x for the propensity score, we estimate  ∗ by setting the
average moment evaluated
 at the estimated selection probability equal to zero as
ˆ p̂Xi  = 0, leading to the estimator
a function of : 1/N  N
i=1 Yi  Ti  Xi  

N 
1 
Yi · Ti
Y · 1 − Ti 
ˆ =
− i
(11)

N i=1 p̂Xi 
1 − p̂Xi 
Because p∗ x is a conditional expectation, this semiparametric estimation problem directly ﬁts into the framework of Newey (1994). So we could apply his
results directly if we estimate p∗ x by a series of least squares regressions of
treatment on polynomials in the covariates. (See the working paper version,
Hirano, Imbens, and Ridder (2000).) However, because p∗ x is a probability, such an approach has the unattractive feature that it approximates a probability by a linear function. We therefore estimate p∗ x in a sieve approach
10
Whenever necessary to avoid confusion we will use a superscript ∗ to denote true (population)
values, so that  ∗ denotes the population average treatment effect and p∗ x the true (population)
propensity score.

1170

k. hirano, g. imbens, and g. ridder

(e.g., Geman and Hwang (1982)) by the Series Logit Estimator (SLE). For K =
1 2    , let RK x = r1K x r2K x     rKK x be a K-vector of functions.
Although the theory is derived for general sequences of approximating functions, the most common class of functions are power series. Let  = 1      r 
be anr-dimensional vector of nonnegative integers (multi-indices), with norm
 = rj=1 j , let k
k=1 be a sequence that includes all distinct multi-indices


and satisﬁes k ≤ k + 1, and let x = rj=1 xj j . For a sequence k
we consider the series rkK x = xk . If we denote the logistic cdf by La =
expa/1 + expa, the SLE for p∗ x is deﬁned by p̂x = LRK x ˆ K  with
ˆ K = arg max


N

Ti · ln LRK Xi   + 1 − Ti  · ln1 − LRK Xi  
i=1

In Appendix A we discuss the relevant asymptotic theory for p̂x.
In addition to the unconfoundedness assumption the following assumptions are
used to derive the properties of the estimator. First, we restrict the distribution
of X, Y 0, and Y 1:
Assumption 2 (Distribution of X):
(i) the support X of the r-dimensional covariate X is a Cartesian product of
compact intervals, X = rj=1 xlj  xuj ;
(ii) the density of X is bounded, and bounded away from 0, on X.
Assumption 3 (Distribution of Y 0 Y 1):
(i) EY 02  <  and EY 12  < ;
(ii) 0 x and 1 x are continuously differentiable for all x ∈ X.
The next assumption requires sufﬁcient smoothness of the propensity score.
Assumption 4 (Selection Probability): The propensity score p∗ x satisﬁes the
following conditions. For all x ∈ X:
(i) p∗ x is continuously differentiable of order s ≥ 7 · r where r is the dimension
of X;
(ii) p∗ x is bounded away from zero and one: 0 < p ≤ p∗ x ≤ p̄ < 1.
Finally, we restrict the rate at which additional terms are added to the series
approximation to p∗ x, depending on the dimension of X and the number of
derivatives of p∗ x.
Assumption 5 (Series Estimator): The series logit estimator of p∗ x uses a
power series with K = N  for some 1/4s/r − 1 <  < 19 .
The restriction on the derivatives (Assumption 4(i)) guarantees the existence
of a  that satisﬁes the conditions in Assumption 5. Under these conditions we
can state the ﬁrst result.

estimation of average treatment effects

1171

Theorem 1: Suppose Assumptions 1–5 hold. Then:
p
(i) ˆ −→  ∗ ;
√
d
(ii) N ˆ −  ∗  −→  0 V , where


YT
Y 1 − T 
∗
−
−

V =E
p∗ X 1 − p∗ X
2


0 X
1 X
∗
−
+
X
T
−
p
p∗ x 1 − p∗ X
= E X − 2 +

12 X
02 X

+
p∗ X 1 − p∗ X

and

(iii) ˆ reaches the semiparametric efﬁciency bound.
Proof: See Appendix B.
Remark 1: This result also covers the extension of the binary-covariate MAR
example in Section 3 to the continuous covariate case. For this case set Y = 0 if
T = 0 and set Y 0 identically equal to 0.
Remark 2: Theorem 1 establishes the result for continuous X. If X has both
continuous and discrete components, this can be dealt with in a conceptually
straightforward manner by using the continuous covariate estimator within samples homogenous in the discrete covariates, at the expense of additional notation.
Derivations presented in Appendix B show that the estimator in Theorem 1
can be represented as asymptotically linear:
ˆ =  ∗ +
where
(12)

N
√
1 
 Yi  Ti  Xi   ∗  p∗ Xi  + Ti  Xi  + op 1/ N 
N i=1

· is deﬁned in (10) and


1 x
0 x
+
· t − p∗ x
t x = − ∗
p x 1 − p∗ x

The known-weights estimator, (11) with p̂x replaced by p∗ x, is asymptotically
linear with score function ·. The function t x represents the effect on the
score function of estimating p∗ x. Its ﬁrst factor, −1 x/p∗ x + 0 x/1 −
p∗ x, is the conditional expectation of the derivative of the moment condition
y t x  ∗  p∗ x with respect to p∗ x. Hence, the score linearizes the estimator with respect to  (which is trivial since the estimator is already linear in
) and p·.
The asymptotically linear representation of ˆ implies that its asymptotic variance equals
(13)

E Y  T  X  ∗  p∗ X + T  X2 

1172

k. hirano, g. imbens, and g. ridder

shown in Appendix B to be equal to the variance expression in Theorem 1. We
estimate this variance by replacing the unknown quantities , p∗ ·, and · by
estimates and replacing the expectation by a sample average:
(14)

N

= 1
ˆ p̂Xi  + T
ˆ i  Xi 2 
V
 Yi  Ti  Xi  
N i=1

The estimation of t x requires some additional explanation. The second
factor, t − p∗ x is estimated as t − p̂x. The ﬁrst factor, −1 x/p∗ x +
0 x/1 − p∗ x, can be written as the conditional expectation of
−Y T /p∗ X2 +Y 1−T /1−p∗ X2  given X. We therefore estimate the ﬁrst
factor in t x by nonparametric regression of −Y T /p̂X2 + Y 1 − T /1 −
p̂X2  on X, using the same series approach as we used for estimating p∗ x.
Thus



N 
Y i Ti
1 
Yi 1 − Ti 
K
+
X

R
−
i
N i=1 p̂Xi 2 1 − p̂Xi 2
−1

N
1 
K
K

×
R Xi R Xi 
RK x
N i=1
with RK x the same series of approximating functions as before, is used as an
estimator for −1 x/p∗ x + 0 x/1 − p∗ x, and the function t x is
ˆ x:
estimated by t



N 
1 
Y i Ti
Yi 1 − Ti 
K
ˆ x = −
t
(15)
+
X

R
i
N i=1 p̂Xi 2 1 − p̂Xi 2

−1
N
1 
K
K

R Xi R Xi 
RK xt − p̂x
×
N i=1
The following theorem describes the formal result.
 is consistent for V .
Theorem 2: Suppose Assumptions 1–5 hold. Then V
Proof: See Appendix B.
In practice bootstrapping methods may be a valuable alternative to the above
variance estimator.
42 Estimating the Weighted Average Treatment Effect
∗
In this section we generalize the previous result to wate
, the weighted average
treatment effect for a known weight function gx. One motivation for considering this estimand is that by choosing gx appropriately, we can obtain treatment
effects for subpopulations deﬁned by X. In addition, by choosing gx equal to

estimation of average treatment effects

1173

the propensity score p∗ x, we can recover the average effect of the treatment
on the treated, as will be discussed below.
To estimate wate , we use the following moment function:


y·t
y · 1 − t
y t x wate  px = gx ·
−
− wate 
(16)
px 1 − px
leading to the estimator
ˆwate =



gXi 

i

Y · 1 − Ti 
Yi · Ti
− i
p̂Xi 
1 − p̂Xi 



gXi 

i

This estimator is asymptotically linear:
ˆwate =

N
1 
1
∗
 Yi  Ti  Xi  wate
 p∗ x
EgX N i=1
√
+ Ti  Xi  + op 1/ N 

where now



t x = −gx ·


1 x
0 x
+
t − p∗ x
p∗ x 1 − p∗ x

The asymptotic variance can be estimated as
N
1
1 
= 
ˆ i  Xi 2 
V
 Yi  Ti  Xi  ˆwate  p̂Xi  + T
 i gXi /N 2 N i=1

with an estimator for t x analogous to that for the average treatment effect:


N 
Y i Ti
1 
Yi 1 − Ti 
K
K
ˆ x = −gx
R
t
+
X
R
X

i
i
p̂K Xi 2 1 − p̂K Xi 2
N i=1

−1
N
1 
K
K

×
R Xi R Xi 
RK xt − p̂K x
N i=1
Similar reasoning to the previous results gives the following theorem:
Theorem 3: Suppose Assumptions 1–5 hold, that gx is bounded from above
and that EgX > 0. Then:
p
∗
(i) ˆwate −→ wate
;
√
d
∗
(ii) N ˆwate − wate
 −→  0 V , with
V=

1
gX2 2
∗
 X
E gX2 X − wate
2 + ∗
2
EgX
p X 1
+

 is consistent for V .
(iii) V

gX2
 2 X 
1 − p∗ X 0

and

1174

k. hirano, g. imbens, and g. ridder

The proof for this theorem follows the same line of argument as that for
Theorems 1 and 2 and is omitted.
Remark: We could weaken Assumption 4(ii), the assumption that the
propensity score is bounded away from 0 and 1, by the assumption that
gx/p∗ x and gx/1−p∗ x are bounded from above. Thus, if there is insufﬁcient overlap in the distributions of the treated and untreated units, one may
wish to choose g· to restrict attention to a subpopulation for which there is
sufﬁciently large probability of observing both treated and untreated units.
A semiparametric efﬁciency bound for wate has not been previously calculated
in the literature. The next result shows that our estimator is efﬁcient.
Theorem 4: The semiparametric efﬁciency bound for estimation of wate is
V=

gX2 2
1
 X
E gX2 X − wate 2 + ∗
2
EgX
p X 1
+

gX2
 2 X 
1 − p∗ X 0

Proof: See Appendix B.
43 Estimating the Average Treatment Effect for the Treated
Under unconfoundedness the average treatment effect for the treated (Rubin
(1977), Heckman and Robb (1985), Heckman, Ichimura, and Todd (1997, 1998))
is a special case of the weighted average treatment effect, corresponding to the
weighting function gx = p∗ x. To see this, ﬁrst note that under unconfoundedness
∗
treated
= EY 1 − Y 0T = 1 = EEY 1 − Y 0X T = 1T = 1

= EEY 1 − Y 0XT = 1 = EXT = 1
Second, the latter is equal to

EXT = 1 = xdF xT = 1
=



xp∗ xdF x



p∗ xdF x

∗
which is wate
with gx equal to p∗ x. Hence we can use the moment equation
(16) with p∗ x substituted for gx:


y·t
y · 1 − t
−
− treated 
y t x treated  px = p∗ x ·
(17)
px 1 − px

estimation of average treatment effects

1175

The estimator is the solution to


N

Yi · 1 − Ti 
Yi · Ti
∗
−
− treated 
(18)
0 = p Xi  ·
p̂Xi 
1 − p̂Xi 
i=1
with the same nonparametric series estimator p̂x as before.
The next result, which follows directly from Theorem 4, shows that this estimator achieves the efﬁciency bound calculated by Hahn (1998) for estimation of the
effect of treatment on the treated, assuming that the propensity score is known.
Corollary 1: Suppose that Assumptions 1–5 hold. Then:
p
∗
;
(i) ˆtreated −→ treated
√
d
∗
(ii) N ˆtreated − treated  −→  0 V , with
V=

1
E p∗ X2 X − treated 2 + p∗ X12 X
Ep∗ X2
+

p∗ X2 2
 X 
1 − p∗ X 0

and

(iii) ˆtreated achieves the semiparametric efﬁciency bound.
The proof for this corollary is omitted as the result directly follows from
Theorem 4.
Note that in the moment function (17) the propensity score appears in two
places, ﬁrst as p∗ x multiplying the remainder of the moment function where
it replaces the general weight function gx in (16), and second as px in the
denominator of the two terms. We only use the estimated propensity score in the
second part in the efﬁcient estimator in (18). The result of the theorem above
implies that this is more efﬁcient than using the true propensity score everywhere
and solving


N

Yi · 1 − Ti 
Yi · Ti
(19)
−
−

0 = p∗ Xi  ·
treated 
p∗ Xi  1 − p∗ Xi 
i=1
or using the estimated propensity score everywhere, which amounts to solving


N

Yi · Ti
Yi · 1 − Ti 
−
− treated 
(20)
0 = p̂Xi  ·
p̂Xi 
1 − p̂Xi 
i=1
A direct implication
 result is that the sample average of the outcomes
 of this
for the treated
i Y i Ti /
i Ti is less efﬁcient
 for ∗the population average
∗
EY 1T = 1 than the weighted average
i Yi Ti p Xi /p̂Xi /
i p Xi 
where the weights are the ratio of the true and estimated propensity score.
Another implication is that the estimators characterized by (19) and (20) cannot
in general be ranked in terms of efﬁciency as there are effects of opposite signs
(e.g., Heckman, Ichimura, and Todd (1997)).

1176

k. hirano, g. imbens, and g. ridder

If the propensity score is not known, then Hahn (1998) shows that this affects
the efﬁciency bound for the effect of treatment on the treated. Our previous
estimator ˆtreated cannot be used since it makes use of p∗ x. However, we can use
the estimated propensity score in place of p∗ x in the weighting of observations
as in (20). Call this estimator ˆte . The next theorem shows that this estimator is
efﬁcient if the propensity is not known.
Theorem 5: Suppose that Assumptions 1–5 hold. Then:
p
∗
(i) ˆte −→ treated
;
√
d
∗
(ii) N ˆte − treated  −→  0 V , with
V=

1
E p∗ XX − treated 2 + p∗ X12 X
Ep∗ X2
+

p∗ X2 2
 X 
1 − p∗ X 0

and

(iii) ˆte achieves the semiparametric efﬁciency bound for estimation of treated when
the propensity score is not known.
The proof goes along the same lines as that for Theorems 1 and 2 and is
omitted.
5 conclusion
In this paper we have studied efﬁcient estimation of various average treatment
effects under an unconfounded treatment assignment assumption. Although
weighting observations by the inverse of the true propensity score does not lead
to efﬁcient estimators, weighting each observation by the inverse of a nonparametric estimate of the propensity score does lead to efﬁcient estimators. We provide intuition for this result through connections to the literatures on empirical
likelihood estimators and choice-based sampling.
The estimators proposed in this paper require fewer functions to be estimated
nonparametrically than other efﬁcient estimators previously proposed in the literature. Which estimators have more attractive ﬁnite sample properties, and
which have more attractive computational properties, remain open questions.
The results underline the important role played by the propensity score in estimation of average causal effects.
Dept. of Economics, University of Miami, P.O. Box 248126, Coral Gables FL
33124-6550; khirano@miami.edu;
Dept. of Agricultural and Resource Economics, University of California at
Berkeley, 330 Giannini Hall, Berkeley, CA 94720-3310; imbens@econ.berkeley.edu;
http://elsa.berkeley.edu/users/imbens/; and Dept. of Economics, University of California at Berkeley, and NBER;

estimation of average treatment effects

1177

and
Dept. of Economics, University of Southern California, Kaprielian Hall, University
Park Campus, Los Angeles, CA 90089; ridder@usc.edu.
Manuscript received January, 2000; ﬁnal revision received August, 2002.
APPENDIX A: Logistic Series Estimator
In this appendix we derive the relevant properties of the logistic series estimator, which can be
interpreted as a sieve estimator (e.g., Geman and Hwang (1982)). Let r K x = r1K x     rKK x
be a K-vector of functions. The triangular array of functions r K x, K = 1 2    , is the basis for
the approximation of the propensity score. In particular, we approximate a function f R r → R
K
K
K
by K r K x. Because K r K x = K A−1
K AK r x we can also use R x = AK r x as the basis of
approximation. By choosing AK appropriately we obtain a system of orthogonal (with respect to
some weight function) functions. Speciﬁcally we choose AK so that ERK XRK X  = IK . The
properties of the series logit estimator and the proof of Theorem 1 are mostly for a general system of
approximating functions. We shall indicate where the properties
 of the speciﬁc approximating class
of functions are used. We will use the matrix norm A = trA A. Note that this is the usual
Euclidean norm if A is a column vector.11 If A is a scalar, we denote the norm by A. Deﬁne
(21)

K = sup RK x 
x∈X

In general, this bound depends on the array of approximating functions that is used. For orthonormal
polynomials Newey (1994, 1997) shows K ≤ CK. Here, and in the sequel, C denotes a generic
positive constant.12
We consider approximation of the log odds ratio by a power series. One possible choice for a
triangular sequence of powers of x is

(22)

r 1 x = 1

r 2 x =

1

x1

 
1
x 
1


r r+1 x = 
   

xr

 
1
 x1 
 


r r+1 x = 
       
 
 xr 
x12

Linear combinations of the elements of the vectors r K x are the approximating power series. A
power series with n + 1r terms has x1      xr included at least up to power n. Hence, if we use
the sequence in (22) and set K = n + 1r , then r K x has powers in all variables at least up to n.
If a function f is s times continuously differentiable and K = n + 1r , then by Theorem 8, p. 90, in
Lorentz (1986) there is a K-vector K such that for RK x = AK r K x, and on the compact set X,
(23)

s

sup f x − RK x K  < C1 n−s ≤ C2 K − r 
x∈X

11

It is useful to list some properties of this norm that will be used in the following discussion.
  
Let A and B be K × K matrices and c be a K vector. Then AB 2 = i j  k aik bkj 2 . Applying
the vector Cauchy-Schwartz inequality to
 the inner sum, we ﬁnd AB ≤ A B . By the maximum
inequality for quadratic forms Ac ≤ max A A c , where max is the largest eigenvalue, which
gives a sharp upper bound (the upper bound A c is not sharp in general). We also frequently use
the Cauchy-Schwartz
 inequality for expectations, which implies that for nonnegative random variables
X Y , EXY  ≤ EX 2 EY 2 .
12
If two constants are needed, we will use the generic notation C1  C2 .

1178

k. hirano, g. imbens, and g. ridder

To ensure that the approximation of p∗ x is between 0 and 1 we ﬁrst approximate the log odds
ratio, which is also s times continuously differentiable and which is bounded on X if the propensity
score is bounded away from zero and one. Hence by (23) there is a K such that
(24)

 




p∗ x
K

− rs

x


−
R
sup  ln
K  < CK
1 − p∗ x
x∈X

Let Lz = expz/1 + expz be the logistic cdf and L z = Lz · 1 − Lz. The series logit
estimator of the population propensity score p∗ x is p̂K x = LRK x ˆ K , where
(25)

ˆ K = arg max LN 


for
(26)

LN  =

N

Ti · ln LRK Xi   + 1 − Ti  · ln1 − LRK Xi  
i=1
p

For N →  and K ﬁxed we have ˆ K −
→ K∗ , with K∗ the pseudo true value:
(27)

K∗ = arg max Ep∗ X ln LRK X  + 1 − p∗ X ln1 − LRK X 


We also deﬁne the pseudo true propensity score: pK∗ x = LRK x K∗ .
In the proofs for the theorems we need some properties of this series logit estimator. For these
properties it is convenient to distinguish between (i) the deterministic difference between the true
propensity score and the pseudo true propensity score and (ii) the stochastic difference between the
estimated propensity score and the pseudo true value. In the remainder of this appendix we therefore
derive (i) a uniform bound on the difference between p∗ x and pK∗ x and (ii) a bound on the
sampling variance in the form of the stochastic order of ˆ K − K∗ .
Lemma 1 (Approximation of Propensity Score): Suppose that:
(i) the support X of X is a compact subset of R r ;
(ii) the propensity score p∗ x is s times continuously differentiable, with s/r ≥ 4;
(iii) the propensity score p∗ x is bounded away from zero and one on X;
(iv) the density of X is bounded away from zero on X.
Then for K in (24),
K − K∗ = OK −s/2r 
and
sup p∗ x − pK∗ x = OK −s/2r K
x∈X

Proof: From (24), and by monotonicity of L·, for all x ∈ X,
(28)

LRK x K − CK −s/r  − LRK x K  < p∗ x − LRK x K 
< LRK x K + CK −s/r  − LRK x K 

˜ =
By the mean value theorem applied to the lower and upper bound and by L RK x 
˜
˜ < 1/4 we ﬁnd that the lower and upper bound are bounded by
− Lr K x 
LRK x 1
− 14 CK −s/r and 14 CK −s/r , respectively. Hence, for the K that satisﬁes (24), we have
(29)

sup p∗ x − LRK x K  < CK −s/r 
x∈X

1179

estimation of average treatment effects
Deﬁne
Q∗  = Ep∗ X ln LRK X  + 1 − p∗ X ln1 − LRK X 
and

QK  = ELRK X K  ln LRK X  + 1 − LRK X K  ln1 − LRK X 
Then, by deﬁnition we have K∗ = arg max  Q∗ , and by the information inequality we have
K = arg max QK 


Let  = inf x∈X p∗ x · 1 − p∗ x, so that by assumption (iii)  > 0. Deﬁne




K =  ∈ R K  inf LRK x 1 − LRK x  ≥ /2 
x∈X

Because of (29), for K large enough, we have K ∈ K . Also, because LRK x  is bounded away
from zero and one for  ∈ K , it follows that ln LRK x  is bounded, and thus by (29) there is a
C1 such that
(30)

sup Q∗  − QK  ≤ C1 K −s/r 
∈K

Next, deﬁne for ﬁxed C2
(31)

K =  ∈ R K   − K ≤ C2 K −s/2r 


Because
sup

x∈X ∈
K

LRK x  − LRK x K  ≤

sup
  ˜
x∈X ∈
K

˜ K x  − K 
L RK x R

≤ sup RK x · sup  − K ≤ CKK −s/2r 
x∈X


∈
K

K ⊂ K .
it follows that for a polynomial series estimator with K ≤ CK, and for large enough K, 
K and with min A the smallest eigenvalue of A, and for large enough K so that
Thus, for  ∈ 
K ⊂ K , given that ERK XRK X  = IK , we have



 2 QK
(32)

= min EL RK x RK XRK X  ≥ /2
min −
  

Now choose the C2 in (31) to satisfy C2 > 4C1 /, for the C1 in (30). Let K be large enough so that
K , the difference Q∗ K  − Q∗ 
K ⊂ K . Then, for  such that  − K = C2 K −s/2r , i.e.,  ∈ 

satisﬁes
Q∗ K  − Q∗  ≥ QK K  − C1 K −s/r − QK  − C1 K −s/r
≥−
≥

QK
1
 2 QK
˜

− K  − 2C1 K −s/r
K  − K  −  − K 

2
  

C22  −s/r
− 2C1 K −s/r > 0
K
2

K , so that with Q∗  concave,
Hence, there is a local maximum of Q∗  in the interior of 
K , proving the ﬁrst assertion. Then
K∗ = arg max Q∗  must satisfy K∗ ∈ 
LRK X K  − LRK X K∗  ≤ RK X · K∗ − K = OKK −s/2r 
and thus by (29) and the triangle inequality we have
sup p∗ x − LRK x K∗  = OK −s/2r K
x∈X

Next we derive the stochastic order of ˆ K − K∗ as K increases with N .

QED

1180

k. hirano, g. imbens, and g. ridder

Lemma 2 (Convergence of ˆ K − K∗ ): Suppose the same four conditions as in Lemma 1 hold. In
addition, suppose that:
(v) KN  is a sequence of values of K satisfying KN  → , and KN 4 /N → 0.
Then


KN 
∗

=
O
ˆ KN  − KN
p

N
Proof: In the sequel we write K for KN . By deﬁnition of RK x,
(33)

N

K = 1
RK Xi RK Xi 
S
N i=1

has expectation equal to IK . By Newey (1997), it satisﬁes
 

K − IK = Op K K 
S
N
which converges to zero in probability by condition (v). Hence the probability that the smallest
K is larger than 1/2 goes to one.
eigenvalue of S
Next, we show that
 
K
1 LN ∗
K  = Op
(34)

N 
N
Consider


 1 LN ∗ 2
1
K
 ∗
K
 ∗
K
K


E
 N  K  = N tr ELR X K 1 − LR X K R XR X 
≤

1
tr ERK XRK X  = K/N 
N

Hence


 1 LN ∗ 2

E
 N  K  = OK/N 
and the Markov inequality implies (34).
Next, let  = inf x∈X K LRK x K∗ 1 − LRK x K∗ /8, which by conditions (i) and (iii) and
Lemma 1 is positive. For any  > 0 choose C such that for N large enough
 


 1 LN ∗ 
 < C K ≥ 1 −  
Pr 

(35)

K 
 N 
N
2
Note that,
sup
x∈X − ∗ ≤C
K



LRK x  − LRK x K∗ 
K
N

≤


sup

x∈X − ∗ ≤C
K



RK x  − K∗  ≤ KC
K
N

which goes to zero, so that for large enough N ,
inf

x∈X − ∗ ≤C
K



K
N

LRK x 1 − LRK x  ≥ 4

K

N

estimation of average treatment effects

1181

Choose N large enough so that this inequality holds, that (35) holds with probability at least 1 − /2,
K is larger than 1/2 is at least 1 − /2. Then
and that the probability that the smallest eigenvalue of S
√
the probability that both of these hold is at least 1 − . Then for every  with  − K∗ = C K/N ,
a second-order expansion gives
¯
 2 LN 
1
1 LN K∗ 
1
1
 − K∗ 
L  = LN K∗  +
 − K∗  +
 − K∗ 
N N
N
N

2N
  
√
where ¯ − K∗ ≤  − K∗ = C K/N . We have
(36)

n
¯
1 
1  2 LN 
K
¯
¯
=−
LRK Xi  1
Xi RK Xi  
− LRK Xi  R

2N  
2N i=1

K 
≤ −2S
with its eigenvalues bounded away from zero in absolute value by . Then, rearranging
(36) and
√
using the triangle inequality, with probability greater than 1 − , for  − K∗ = C K/N ,
1
1
1 LN ∗ 
L  − LN K∗  ≤
K   − K∗  −   − K∗ 2
N N
N
N 


 1 LN ∗ 
 ·  − ∗ −   − ∗ 2
≤


K
K
K
 N 





 1 LN ∗ 
K
∗

= 
 N  K  − C N ·  − K < 0
That is, we have with probability greater than 1 − ,
1
1
L  < LN K∗ 
N N
N

for all  with


 − K∗ = C

K

N

√
Since LN  is continuous, it has a maximum on the compact set   − K∗√ ≤ C K/N . By
∗
the last inequality, this maximum must occur for some ˆ K with ˆ − K < C K/N . Hence the
ﬁrst-order conditions are satisﬁed at ˆ K and by concavity of LN  ˆ K maximizes LN  over all
of R K  Because the probability of this is greater than 1 −  with  arbitrary, we conclude that ˆ K
∗
ˆ
exists
√ and satisﬁes the ﬁrst order conditions with probability approaching one, and that K − K =
Op  K/N .
Q.E.D.
APPENDIX B: Proofs of Theorems
Proof of Theorem 1: To ease the notational burden we present the proof for the special case
with Y 0 identically equal to 0. This can be interpreted as the special case where one is interested
in estimating the average outcome = EY 1, where Y 1 is missing at random conditional on the
covariates X. Thus it is the direct extension of the binary-covariate example in Section 3. Since
the average treatment effect case simply amounts to estimating two averages where in both cases
the variables are missing at random, the argument for the general case is exactly analogous, only
involving substantially longer equations. In the proof we therefore follow the missing at random set
up with the parameter of interest equal to = EY 1, making the missing at random assumption
Y 1 ⊥ T X, and with a random sample of Ti  Xi  Yi Ni=1 , where Yi = Yi 1 · Ti .
The estimated weight estimator ˆ ew is
(37)

N

Ti · Yi
ˆ ew = 1
N i=1 p̂K Xi 

with p̂K Xi  = LRK Xi  ˆ K . The key part of the proof is to show that



N 
√


Ti · Yi
 X 
 N  ˆ ew − ∗  − √1
(38)
− ∗ − ∗1 i Ti − p∗ Xi  

 = oP 1
∗
p Xi 
p Xi 
N i=1

1182

k. hirano, g. imbens, and g. ridder

This implies that ˆ ew is asymptotically linear, i.e. behaves asymptotically as a sample average, with
score function Y  T  X ∗  p∗ · + T  X, where
y t x  p· =

t ·y
− 
px

and

t x = −

1 x
· t − p∗ x
p∗ x

The ﬁrst term of the score function, ·, is equal to the score that would obtain if we substitute the
population probability p∗ for the estimator p̂K in (37). The second term, ·, gives the contribution
of estimating p∗ to the asymptotic distribution of ˆ ew . This contribution is linear in T −p∗ X. Hence,
the score linearizes the estimator with respect to and p·. The asymptotic variance of ˆ ew is equal
to the variance of Y  T  x ∗  p∗ X + T  X (note that its mean is 0). The three components
of this variance are
E Y  T  X

∗

 p∗ ·2  = E

∗

∗ 2



1 X2
− E1 X2 
p∗ X

ET  X2  = E
E Y  T  X

1 X2
 2 X
+ E 1∗
−
∗
p X
p X

 p∗ · · T  X = −E

1 X2
+ E1 X2 
p∗ X

so that
E Y  T  X

∗

 p∗ · + T  X2  = E1 X2  − 

∗ 2

 +E

12 X
p∗ X

= VEY 1X + EVY 1X/p∗ X
which is the variance in Theorem 1, specialized to the case with 0 x = 02 x = 0.
In the proof of (38) we rewrite the difference by adding and subtracting a number of terms, so
that we can bound the differences. We give the asymptotic order of all differences, which makes it
easier to understand the role of the assumptions. We have

N 
√
1 
Ti Yi
TY
TY
(39)
N  ˆ ew − ∗  = √
− ∗ i i + ∗ i i 2 p̂K Xi  − p∗ Xi 
N i=1 p̂K Xi  p Xi  p Xi 
N 
TY
1 
(40)
− ∗ i i 2 p̂K Xi  − p∗ Xi 
+√
p Xi 
N i=1

  x
1
+
p̂K x − p∗ x dF0 x
∗
X p x
√  1 x
− N
(41)
p̂K x − p∗ x dF0 x
∗
X p x
N
1 
Ti − pK Xi 
−√
˜ K Xi  
N i=1
pK Xi 1 − pK Xi 

(42)

(43)

(44)

N
1 
Ti − pK Xi 
+√
˜ K Xi  − K Xi  
N i=1
pK Xi 1 − pK Xi 
N 
1 
Ti − pK Xi 
+√
K Xi  
N i=1
pK Xi 1 − pK Xi 

Ti − p∗ Xi 
− 0 Xi  
∗
∗
p Xi 1 − p Xi 



N
1 
Ti − p∗ Xi 
T i · Yi
+√
− ∗ + 0 Xi  

∗
p Xi 
N i=1
p∗ Xi 1 − p∗ Xi 

estimation of average treatment effects

1183

In this expression F0 is the population cdf of X and
(45)
(46)
(47)

  z

1
−1 L RK x  ∗ RK x
L RK z ˜ K RK z dF0 z
K
K
∗
X p z
  z

1
L RK z K∗ RK z dF0 z−1
L RK x K∗ RK x
K x = −
K
∗
X p z

˜ K x = −

0 x = −

1 x  ∗
p Xi 1 − p∗ Xi 
p∗ x

with
k = ERK XRK X L RK X K∗ 

and

N

 = 1
RK Xi RK Xi  LRK Xi  ˜ K 

K
N i=1

and ˜ K between ˆ K and K∗ .
√
Note that (44) is equal to the linearized expression for N  ˆ ew − ∗ . To show that the estimator
is indeed asymptotically linear, we must derive bounds on the terms (39)–(43). If a bound depends
on both K and N , we derive the bound for sequences KN  that go to  with N . Because during the
derivation some restrictions on these sequences are imposed, the resulting bounds are not uniform
in K. We have seen this type of argument in the derivation of the order of ˆ KN  − KN  where
we imposed the large sample identiﬁcation condition KN 4 /N → 0.
Below we present the bounds on the terms (39)–(43). Details for the derivations for these bounds
are available from the authors (Hirano, Imbens, and Ridder (2002)). The bound for (39) is


N 
 1 

Ti Yi
Ti Yi
Ti Yi
∗
√


p̂
X

−
p
X

−
+
K
i
i
 N

∗ X 
∗ X 2
p̂
X

p
p
K
i
i
i
i=1


√
K3
s
+ OP N K2 K − r
= OP √
N

s
+ OP K5/2 K − 2r 
The bound for (40) is

  x
N 
TY
1 
1
∗
x
−
p
x
dF
x
− ∗ i i 2 p̂K Xi  − p∗ Xi  +

p̂
√
K
0
∗
p Xi 
X p x
N i=1


K2
s

= OP KK − 2r  + OP √
N
The bound for (41) is


N

 √  1 x
1 
∗
˜ K Xi   Ti − pK Xi 

− N

x
−
p
x
dF
x
−

p̂
√
K
0

∗
X p x
N i=1
pK Xi 1 − pK Xi  
√
s
= O N KK − 2r 
The bound for (42) is




N
9/2
 1 

Ti − pK Xi 
√
 = OP K
ˆ K Xi  − K Xi  

 N

1/2
N
pK Xi 1 − pK Xi 
i=1

1184

k. hirano, g. imbens, and g. ridder

The bound for (43) is


 1 
N
Ti − pK Xi 
Ti − p∗ Xi 

K Xi  
− 0 Xi  
√
∗
 N i=1
pK Xi 1 − pK Xi 
p Xi 1 − p∗ Xi 


1 s
s
= OP max K − 2 r  KK − 2r









From these ﬁve expressions we obtain
(48)


√
 N  ˆ ew −




N 

1 
Ti Yi
 X 
− √
− ∗ − ∗1 i Ti − p∗ Xi  
∗
p Xi 
p Xi 
N i=1


√

K3
s
s
+ OP N K2 K − r + OP K5/2 K − 2r
= OP √
N



√
K2
s
s
+ OP KK − 2r + OP √
+ O N KK − 2r
N




K9/2
s
s
+ OP
+ OP max K − 2r  KK − 2r
√
N


√

K9/2
s
s
= OP N K2 K − r + OP K5/2 K − 2r + OP

√
N
∗

Note that the second term of the ﬁnal expression is a bias term, the third a variance term, and the
ﬁrst a combination of a variance and bias term.
As noted K depends on the sequence of approximating functions. For power series we have
K = OK. If we consider sequences KN  = N c we can ﬁnd the range of c for which (48) is
oP 1. Substitution in the right-hand side of (48) gives that the ﬁrst term on the right-hand side
requires that c > 1/2s/r −2, the second that s/r > 5, and the third that c < 1/9. These inequalities
can be simultaneously satisﬁed if s/r ≥ 7.
Q.E.D.
Proof of Theorem 2: Deﬁne
N
1 
Yi Ti
RK Xi 
N i=1 p∗ Xi 2

(49)

K = −

(50)

N

Yi Ti
K = − 1
RK Xi 

N i=1 p̂K Xi 2

(51)

N

K = 1
RK Xi RK Xi  
S
N i=1

−1 RK x is the predicted value in a least squares series regression of −Yi Ti /p∗ Xi 2  on
Then K S
K
K
13
R Xi . This predicted value estimates −EY x/p∗ x, which is the conditional expectation (given
X = x) of the derivative of the moment condition with respect to p∗ . The usual bound for series
estimators applies:
(52)

13







K
s
−1 RK x + 1 x  ≤ C1 KN OP
sup K S
+ C2 K − r
K

∗
p x
N
x∈X

The number of terms in this series estimator need not be equal to that in the series estimator
of the propensity score. The notation can be changed to reﬂect this.

estimation of average treatment effects

1185

with s  the number of continuous derivatives of 1 x. Also


N

  

p̂K Xi  − p∗ Xi p∗ Xi  + p̂K Xi 
K
K − K  =  1


Y
T
R
X

(53)
i i
i 
N
2
∗
2
p̂K Xi  p Xi 
i=1


N  ∗



1 
 p Xi  + p̂K Xi  p̂K Xi  − p∗ Xi  · Yi  · Ti · RK Xi 
≤


2
∗
2
N i=1 p̂K Xi  p Xi 
As in the proof of Theorem 1 we have that p̂K x is bounded from 0 and 1 on X if N →  and
hence we have the following bound for (53):
(54)

C sup p̂K x − p∗ x sup RK x
x∈X

x∈X


= C1 K2 OP

N
1 
Y  + oP 1
N i=1 i


K
s
+ C2 K2 K − r 
N

We use the bounds (52) and (54) to obtain a bound on

−1 RK xt − p̂K x
K − K  S
(55)
ˆ K t x − t x = 
K

−1 RK x + 1 x t − p̂K x + 1 x p̂K x − p∗ x
+ K S
K
p∗ x
p∗ x
Under the asymptotic identiﬁcation condition
(56)







−1 RK x + 1 x 
K − K  sup RK x + C2 sup  S
sup ˆ K t x − t x ≤ C1 
 K K
p∗ x 
x∈X
x∈X
x∈X
+ C3 sup 1 x sup p̂K x − p∗ x
x∈X

x∈X

Because X is compact and 1 x is continuous, supx∈X 1 x < . Substitution of the bounds (52)
and (54), collecting terms of the same order and omitting terms of lower order gives the bound


K
sup ˆ K t x − t x ≤ C1 K3 OP
(57)
N
x∈X
s

s

+ C2 K3 K − r + C3 K − r 
It can be shown that the difference between (14) and (13) is bounded by (57) (details of these
calculations are available from the authors). Under the rates speciﬁed in Theorem 1 this bound is
Q.E.D.
op 1. Hence (14) is a consistent estimator for (13).
Proof of Theorem 4: The derivation of the efﬁciency bound follows the proof in Hahn (1998).
We consider the case where the propensity score is known. From Theorem 3, it will be evident that
the bound can be achieved without knowledge of the propensity score.
The density of Y 0 Y 1 T  X with respect to some -ﬁnite measure is
qy0 y1 t x = f y0 y1xp∗ xt 1 − p∗ x1−t f x
The density of the observed data y t x, using the unconfoundedness assumption, is
qy t x = f1 yxp∗ xt f0 yx1 − p∗ x1−t f x


where f1 ·x = f y0 ·x dy0, and f0 ·x = f · y1x dy1. Consider a regular parametric
submodel indexed by , with density
qy t x = f1 yx p∗ xt f0 yx 1 − p∗ x1−t f x

1186

k. hirano, g. imbens, and g. ridder

which equals qy t x for  = 0 . Note that  does not enter into the term p∗ x, because we are
assuming that the propensity score is known. The score is given by
d
lnqytx = sytx = t ·s1 yx+1−t·s0 yx+sx x
d
where
d
ln f1 yx 
d
d
ln f0 yx 
s0 yx  =
d
d
sx x =
ln f x
d
s1 yx  =

The tangent space of the model is the set of functions
 = t · s1 y x + 1 − t · s0 y x + sx x
for s1  s0 , and sx satisfying




s1 y xf1 yx dy = 0

∀ x

s0 y xf0 yx dy = 0

∀ x

sx xf x dx = 0

We are interested in estimating

wate ≡


gxyf1 yxf x dy dx − gxyf0 yxf x dy dx


gxf x dx

So for the parametric submodel indexed by ,

wate  ≡


gxyf1 yxf xdydx − gxyf0 yxf xdydx


gxf xdx

We need to ﬁnd a function F y t x such that for all regular parametric submodels,
wate 0 
= EF Y  T  XsY  T  X0 


First we calculate wate /. Let g ≡ gxf x dx. Then
wate 0 
1 
gxys1 yx 0 f1 yx 0 f x0  dy dx
=

g

− gxys0 yx 0 f0 yx 0 f x0  dy dx
+

1 
gx EY 1 − Y 0X = x − wate
g
× sx x0 f x0  dx 

1187

estimation of average treatment effects
The following choice for F satisﬁes the condition:
F Y  T  X =

T · gX
1 − T  · gX
Y − EY 1X −
Y − EY 0X
g · p∗ x
g · 1 − p∗ x
+

gX
EY 1 − Y 0X − wate 
g

Hence wate is pathwise differentiable. By Theorem 2, in Section 3.3 of Bickel, Klaassen, Ritov, and
Wellner (1993), the variance bound is the expected square of the projection of F Y  T  X on  .
Since F ∈  , the variance bound is
EF Y  T  X2  = E

gX2
gX2
V Y 1X + E
V Y 0X
2
∗
2
g  p X
g  1 − p∗ X

+E

gX2
EY 1X − EY 0X − wate 2 
g 2

QED

REFERENCES
Abadie, A., and G. Imbens (2002): “Simple and Bias-Corrected Matching Estimators for Average
Treatment Effects,” NBER Technical Working Paper 283.
Angrist, J. D., and J. Hahn (1999): “When to Control for Covariates? Panel-Asymptotic Results
for Estimates of Treatment Effects,” NBER Technical Working Paper 241.
Barnow, B., G. Cain, and A. Goldberger (1980): “Issues in the Analysis of Selectivity Bias,”
in Evaluation Studies, Vol. 5, ed. by E. Stromsdorfer and G. Farkas. San Francisco: Sage.
Bickel, P. J., C. A. J. Klaassen, Y. Ritov, and J. A. Wellner (1993): Efﬁcient and Adaptive
Estimation for Semiparametric Models. Baltimore: Johns Hopkins University Press.
Chamberlain, G. (1987): “Asymptotic Efﬁciency in Estimation with Conditional Moment Restrictions,” Journal of Econometrics, 34, 305–334.
Crepon, B., F. Kramarz, and A. Trognon (1998): “Parameters of Interest, Nuisance Parameters and Orthogonality Conditions: An Application to Autoregressive Error Component Models,”
Journal of Econometrics, 82, 135–156.
Dehejia, R., and S. Wahba (1999): “Causal Effects in Non-Experimental Studies: Re-Evaluating
the Evaluation of Training Programs,” Journal of the American Statistical Association, 94, 1053–1062.
Geman, S., and C. Hwang (1982): “Nonparametric Maximum Likelihood Estimation by the
Method of Sieves,” Annals of Statistics, 10, 401–414.
Hahn, J. (1998): “On the Role of the Propensity Score in Efﬁcient Semiparametric Estimation of
Average Treatment Effects,” Econometrica, 66, 315–331.
Hansen, L. (1982): “Large Sample Properties of Generalized Method of Moments Estimators,”
Econometrica, 50, 1029–1054.
Heckman, J., H. Ichimura, and P. Todd (1997): “Matching as an Econometric Evaluation
Estimator: Evidence from Evaluating a Job Training Program,” Review of Economic Studies, 64,
605–654.
(1998): “Matching As An Econometric Evaluations Estimator,” Review of Economic Studies,
65, 261–294.
Heckman, J., H. Ichimura, J. Smith, and P. Todd (1998): “Characterizing Selection Bias Using
Experimental Data,” Econometrica, 66, 1017–1098.
Heckman, J., and R. Robb (1985): “Alternative Methods for Evaluating the Impact of Interventions,” in Longitudinal Analysis of Labor Market Data, ed. by J. Heckman and B. Singer. New York:
Cambridge University Press.

1188

k. hirano, g. imbens, and g. ridder

Hellerstein, J., and G. Imbens (1999): “Imposing Moment Restrictions from Auxiliary Data by
Weighting,” Review of Economics and Statistics, 81, 1–14.
Hirano, K., G. Imbens, and G. Ridder (2000): “Efﬁcient Estimation of Average Treatment
Effects Using the Estimated Propensity Score,” NBER Technical Working Paper 251.
(2002): “Addendum to: Efﬁcient Estimation of Average Treatment Effects Using the Estimated Propensity Score,” http://elsa.berkeley.edu/users/imbens/.
Imbens, G. (1997): “One-step Estimators in Overidentiﬁed Generalized Method of Moments Estimator,” Review of Economic Studies, 64, 359–383.
Imbens, G., R. Spady, and P. Johnson (1998): “Information Theoretic Approaches to Inference
in Moment Condition Models,” Econometrica, 66, 333–357.
Kitamura, Y., and M. Stutzer (1997): “An Information-Theoretic Alternative to Generalized
Method of Moments Estimation,” Econometrica, 65, 861–874.
Lancaster, T. (1990): “A Paradox in Choice-based Sampling,” Mimeo, Department of Economics,
Brown University.
Lechner, M. (1999): “Earnings and Employment Effects of Continuous Off-the-job Training in East
Germany after Uniﬁcation,” Journal of Business and Economic Statistics, 17, 74–90.
Little, R., and D. Rubin (1987): Statistical Analysis with Missing Data. New York: Wiley.
Lorentz, G. (1986): Approximation of Functions. New York: Chelsea Publishing Company.
Newey, W. (1994): “The Asymptotic Variance of Semiparametric Estimators,” Econometrica, 62,
1349–1382.
(1997): “Convergence Rates and Asymptotic Normality for Series Estimators,” Journal of
Econometrics, 79, 147–168.
Qian, H., and P. Schmidt (1999): “Improved Instrumental Variables and Generalized Method of
Moments Estimators,” Journal of Econometrics, 91, 145–169.
Qin, J., and J. Lawless (1994): “Generalized Estimating Equations,” Annals of Statistics, 22, 300–
325.
Robins, J., S. Mark, and W. Newey (1992): “Estimating Exposure Effects by Modeling the Expectation of Exposure Conditional on Confounders,” Biometrics, 48, 479–495.
Robins, J., and Y. Ritov (1997): “Towards a Curse of Dimensionality Appropriate (CODA)
Asymptotic Theory for Semi-parametric Models,” Statistics in Medicine, 16, 285–319.
Robins, J., and A. Rotnitzky (1995): “Semiparametric Efﬁciency in Multivariate Regression
Models with Missing Data,” Journal of the American Statistical Association, 90, 122–129.
Robins, J., A. Rotnitzky, and L. Zhao (1995): “Analysis of Semiparametric Regression Models for Repeated Outcomes in the Presence of Missing Data,” Journal of the American Statistical
Association, 90, 106–121.
Rosenbaum, P. (1987): “Model-Based Direct Adjustment,” Journal of the American Statistical Association, 82, 387–394.
Rosenbaum, P., and D. Rubin (1983): “The Central Role of the Propensity Score in Observational
Studies for Causal Effects,” Biometrika, 70, 41–55.
(1985): “Reducing Bias in Observational Studies Using Subclassiﬁcation on the Propensity
Score,” Journal of the American Statistical Association, 79, 516–524.
Rotnitzky, A., and J. Robins (1995): “Semiparametric Regression Estimation in the Presence of
Dependent Censoring,” Biometrika, 82, 805–820.
Rubin, D. (1974): “Estimating Causal Effects of Treatments in Randomized and Nonrandomized
Studies,” Journal of Educational Psychology, 66, 688–701.
(1976): “Inference and Missing Data,” Biometrika, 63, 581–592.
(1977): “Assignment to Treatment Group on the Basis of a Covariate,” Journal of Educational
Statistics, 2, 1–26.
(1978): “Bayesian Inference for Causal Effects: the Role of Randomization,” Annals of Statistics, 6, 34–58.
Rubin, D., and N. Thomas (1996): “Matching Using Estimated Propensity Scores: Relating Theory
to Practice,” Biometrics, 52, 249–264.

estimation of average treatment effects

1189

Wooldridge, J. (1999): “Asymptotic Properties of Weighted M-Estimators for Variable Probability
Samples,” Econometrica, 67, 1385–1406.
(2002): “Inverse Probability Weighted M-Estimators for Sample Selection, Attrition and Stratiﬁcation,” Institute for Fiscal Studies, Cemmap Working Paper cwp11/02.

