Biometrics 73, 1199â€“1209
December 2017

DOI: 10.1111/biom.12676

A General Statistical Framework for Subgroup Identiï¬cation
and Comparative Treatment Scoring
Shuai Chen,1 Lu Tian,2 Tianxi Cai,3 and Menggang Yu1,*
1

Department of Biostatistics and Medical Informatics, University of Wisconsin, Madison, Wisconsin 53792, U.S.A.
2
Department of Biomedical Data Science, Stanford University, Palo Alto, California 94305, U.S.A.
3
Department of Biostatistics, Harvard School of Public Health, Boston, Massachusetts 02115, U.S.A.
âˆ— email: meyu@biostat.wisc.edu

Summary. Many statistical methods have recently been developed for identifying subgroups of patients who may beneï¬t
from diï¬€erent available treatments. Compared with the traditional outcome-modeling approaches, these methods focus on
modeling interactions between the treatments and covariates while by-pass or minimize modeling the main eï¬€ects of covariates
because the subgroup identiï¬cation only depends on the sign of the interaction. However, these methods are scattered and
often narrow in scope. In this article, we propose a general framework, by weighting and A-learning, for subgroup identiï¬cation
in both randomized clinical trials and observational studies. Our framework involves minimum modeling for the relationship
between the outcome and covariates pertinent to the subgroup identiï¬cation. Under the proposed framework, we may also
estimate the magnitude of the interaction, which leads to the construction of scoring system measuring the individualized
treatment eï¬€ect. The proposed methods are quite ï¬‚exible and include many recently proposed estimators as special cases.
As a result, some estimators originally proposed for randomized clinical trials can be extended to observational studies, and
procedures based on the weighting method can be converted to an A-learning method and vice versa. Our approaches also allow
straightforward incorporation of regularization methods for high-dimensional data, as well as possible eï¬ƒciency augmentation
and generalization to multiple treatments. We examine the empirical performance of several procedures belonging to the
proposed framework through extensive numerical studies.
Key words:

A-learning; Individualized treatment rules; Observational studies; Propensity score; Regularization.

1. Introduction
With increasing numbers and types of treatments for many
conditions, it is now well known that the beneï¬ts of many
treatments diï¬€er substantially across diï¬€erent patient subpopulations. A key focus of recent research is to match
patients with the most eï¬€ective treatments to improve
treatment eï¬ƒcacy when there is substantial heterogeneity
of treatment eï¬€ectiveness (Gabriel and Normand, 2012).
To optimize treatment selection for individual patients, an
important strategy is to use patientsâ€™ baseline covariates to
form a system for ranking or scoring their individualized treatment eï¬€ects (ITEs). Statistical methods for estimating ITEs
or constructing optimal individualized treatment rules (ITRs)
often require investigation of treatment by covariate interactions. These treatment-modifying covariates are known as
treatment-moderators. They need to be contrasted with prognostic covariates which lead to poorer or better outcomes
under all treatment options. For example, higher tumor stage
may be generally associated with worse prognosis for all treatments under considerations. Therefore, if the goal is only for
treatment selection, the relevant task is to identify treatmentmoderators but ignore prognostic covariates.
More concretely, let T = Â±1, Z and Y denote the
treatment assignment, baseline covariates, and outcome
of interest for a patient, respectively. Algebraically,
we can express E(Y |T, Z) = m(Z) + T(Z), where m(Z) =
Â© 2017, The International Biometric Society

0.5{E(Y |T = 1, Z) + E(Y |T = âˆ’1, Z)} is a function that
reï¬‚ects the main eï¬€ect of Z and (Z) = 0.5{E(Y |T = 1, Z) âˆ’
E(Y |T = âˆ’1, Z)} is a contrast function that reï¬‚ects treatment
eï¬€ects given Z. Therefore, modeling E(Y |T, Z) is equivalent to
modeling both m(Z) and (Z) as functions of covariates. Variables involved in m(Z) are prognostic variables, while those
in (Z) are treatment moderators.
Traditional approaches to developing optimal ITRs model
m(Z) and (Z) simultaneously to predict the outcomes and
then estimate ITEs using these model based estimates. This
approach requires correct speciï¬cation for both m(Z) and
(Z), even though in the end only the latter is used to
guide the treatment selection. In this approach, the main
eï¬€ect m(Z) becomes a nuisance parameter, whose speciï¬cation, however, may aï¬€ect the estimation of treatment contrast
function (Z). This is especially problematic since in practice there are often many prognostic variables but far fewer
treatment moderators that actually alter treatment recommendation (Kraemer, 2013). However, if our goal is ranking
ITE or developing ITR, then only ranks or signs of the contrast function (Z) matter. Hence, it is desirable to have a
robust estimate of ITEs without necessitating the estimation
of m(Â·).
Several robustness approaches to subgroup identiï¬cation
have been proposed in recent years. In the randomized clinical
trial (RCT) setting, it has been shown that mis-speciï¬cation

1199

1200

Biometrics, December 2017

of the main eï¬€ects m(Z) has limited eï¬€ects on estimating
the treatment by covariate interaction (Qian and Murphy,
2011; Lu et al., 2013; McKeague and Qian, 2014; Ciarleglio
et al., 2015), especially from the perspective of A-learning
(Murphy, 2003; Robins, 2004). In the observational study setting, double robust procedure was introduced (Zhang et al.,
2012). In addition, Vansteelandt et al. (2008) developed multiply robust estimators for interaction parameters, leaving the
main eï¬€ects unspeciï¬ed. Beyond this robustness from the
main eï¬€ect mis-speciï¬cation, it has been found that masking observation such as noninformative censoring also only
has a limited impact on subgroup identiï¬cation (Xu et al.,
2015). Shifting from the outcome prediction framework, a
modiï¬ed covariate method was proposed by Tian et al. (2014)
without the need of explicitly modeling main eï¬€ects for data
from RCTs. Furthermore, nonparametric approaches based
on the regression tree were proposed to separate the main
eï¬€ects from the covariateâ€“treatment interaction eï¬€ects, either
through sequential testing (Su et al., 2008) or prediction
strategies (Foster et al., 2011; Loh et al., 2015). Lastly, converting the subgroup identiï¬cation to a classiï¬cation problem,
outcome weighted learning methods were developed (Qian
and Murphy, 2011; Zhang et al., 2012; Zhao et al., 2012; Xu
et al., 2015).
All aforementioned methods appear to be very diverse:
some are fairly ad hoc and some are heavily model-dependent.
The validity of the latter often relies on diï¬€erent parametric or non-parametric assumptions for (Z). Furthermore,
most existing methods focus on the treatment diï¬€erence
(Z) as the metric for summarizing ITE. However, the
choice of the metric may aï¬€ect the analysis results and conclusions about ITE. For example, for non-negative Y , one
may choose to use the ratio E(Y |T= 1, Z)/E(Y |T= âˆ’1, Z) to
measure the ITE instead of the diï¬€erence E(Y |T=1, Z) âˆ’
E(Y |T=âˆ’1, Z). The patients rankings based on E(Y |T=
1, Z)/E(Y |T= âˆ’1, Z) and E(Y |T= 1, Z) âˆ’ E(Y |T= âˆ’1, Z) can
potentially be quite diï¬€erent although these two metrics
may lead to the same ITRs with patients assigned to treatment 1 when E(Y |T= 1, Z) > E(Y |T= âˆ’1, Z). On the other
hand, one may employ ITE metrics such as E{U(Y )|T=
1, Z} âˆ’ E{U(Y )|T=âˆ’1, Z} based on a monotone transformation U(Â·), which would alter both the ranking and
the optimal treatment recommendation. Although diï¬€erent methods can be developed for speciï¬c choices of the
ITE metric, we propose in this article a uniï¬ed framework
that can allow for ITEs or ITRs estimation under diï¬€erent
metrics.
Building upon the weighting approach considered in Tian
et al. (2014) for RCT, we propose both propensity score
weighting and A-learning methods for subgroup identiï¬cation that are applicable for both observational studies and
RCTs. Our framework is ï¬‚exible and includes many aforementioned estimators in the literature as special cases, despite
their clearly diï¬€erent origins. The rest of the article is organized as follows. In Section 2, we demonstrate that minimizers
of a class of convex loss functions can recover the optimal
ITR. With properly chosen loss functions, our proposed estimator can not only recover the ITR but also the magnitude
of ITE. In Section 3, we show that many recently proposed
estimators can be represented as special cases within our

frameworks. In Sections 4 and 5, we compare the ï¬nitesample properties of several estimators and their extensions
within our frameworks via simulation studies and real data
examples. Finally, we conclude the article with some discussions including extensions to multiple treatment groups in
Section 6.
2.

Methods

2.1. Notations and Assumptions
We adopt the notation based on the potential outcome framework in causal inference (Rubin, 2005). Y (1) and Y (âˆ’1) are
the potential outcomes if the patient receives a new treatment T = 1 and a standard treatment T = âˆ’1, respectively.
We also assume that only one of the potential outcomes
Y (1) and Y (âˆ’1) can be observed for each patient, that is,
Y = I(T = 1)Y (1) + I(T = âˆ’1)Y (âˆ’1) , where I(Â·) is the indicator function. We further assume that T is independent of
(Y (1) , Y (âˆ’1) ) given the covariates Z, that is, the â€œstrongly
ignorable assumptionâ€ (Rosenbaum and Rubin, 1983; Rubin,
2005). For the treatment assignment, we assume that Pr(T =
1|Z) = Ï€(Z), where the propensity score Ï€(Z) is typically
known and free of Z in randomized trials; but is unknown and
needs to be estimated (e.g., via regression modeling) in observational studies. The observed data {(Yi , Ti , Zi ), i = 1, . . . , n}
consist of n independent identically distributed (i.i.d) copies of
(Y, T, Z).
Our goal is to construct a personalized beneï¬t scoring
system f (Z) based on the covariates Z via both a weighting approach and an A-learning approach such that the
new treatment shall be recommended for the patients based
on f (Z), which is often sign{f (Z)}. We demonstrate in
Section 2.2 that the optimality of such a rule under diï¬€erent scenarios. In addition, we demonstrate in Section 2.4
that the proposed approach to estimating an optimal f (Â·)
is also useful for quantifying the magnitude of treatment
beneï¬t.
We consider a loss function M(y, v) satisfying two conditions:
A: Mv (y, v) = âˆ‚M(y, v)/âˆ‚v is increasing in v for any
given y;
B: U(y) â‰¡ Mv (y, 0) is monotone in y.
Here, condition A ensures that M(y, v) is convex in v, which
allows us to â€œorderâ€ the expected utility under the comparative treatments to form an ITR. Condition B is simply to make
the transformed quantity, that is, U(Y ), an interpretable endpoint. For example, M(y, v) can be the squared loss function
(y âˆ’ v)2 , which clearly satisï¬es aforementioned two conditions with Mv (y, v) = 2v âˆ’ 2y and U(y)
 = âˆ’2y. When
 Y only
taking non-negative values and Pr Y (t) > 0|Z = z > 0 for
t = Â±1 and any z, we may let M(y, v) = y log{1 + exp(âˆ’v)}
with U(y) = âˆ’y/2.
A â€œFisher-consistentâ€ ITR d0 (z) âˆˆ {1, âˆ’1} can be constructed via M. Speciï¬cally,
d0 (Â·) maximizes


 the value
function VU (d) = âˆ’E U(Y (1) ) âˆ’ U(Y (âˆ’1) ) d(Z) . Note that
direct maximization of VU (d) is not feasible both statistically and numerically due to the discrete nature of d(Â·),

A General Framework for Subgroup Identiï¬cation and Scoring
whereas minimization of smooth loss functions (f ) with
respect to f (Â·) overcomes such diï¬ƒculties. Here, (Â·) is constructed based on M as detailed in the next section. When
U(y) linear and decreasing in y, the maximizer of VU (d) is
the same as the maximizer of the standard value function
E[Y (1) I{d(Z) = 1} + Y (âˆ’1) I{d(Z) = âˆ’1}] employed in the literature (Qian and Murphy, 2011; Zhao et al., 2012). The
use of a broader class of M(Â·, Â·) along with its corresponding U(Â·) enables us to consider alternative metrics to quantify
treatment beneï¬ts. Throughout, we ï¬rst assume that Ï€(Z)
is known and provide discussions on estimating Ï€(Z) in
Section 2.3.
Weighting and A-Learning Approaches to Subgroup
Identiï¬cation
2.2.1. Weighting method. For a given M(Â·, Â·) and covariate level z, we ï¬rst consider the loss function W (f ) =
E{W (f, Z)} and let fW0 = argminf W (f ), where
2.2.


W (f, z) = E



M{Y, Tf (Z)}
Z=z
TÏ€(Z) + (1 âˆ’ T )/2









= E Mv {Y, âˆ’fW0 (Z)}|T = âˆ’1, Z = z .

(1)

Consequently, for a patient with a negative score (i.e.,
fW0 (z) < 0), we have
E{U(Y (1) )|Z = z} = E{Mv (Y, 0)|T = 1, Z = z}





> E Mv {Y, fW0 (Z)}|T = 1, Z = z





(2)

= E Mv {Y, âˆ’fW0 (Z)}|T = âˆ’1, Z = z
> E{Mv (Y, 0)|T = âˆ’1, Z = z}
= E{U(Y

+ E[I(T = âˆ’1)M{Y, âˆ’Ï€(Z)f (Z)}|Z = z]
= Ï€(z)E(M[Y, {1 âˆ’ Ï€(z)}f (z)]|T = 1, Z = z)
+ {1 âˆ’ Ï€(z)}E[M{Y, âˆ’Ï€(z)f (z)}|T = âˆ’1, Z = z].
Then for any z with Ï€(z) âˆˆ (0, 1), the ï¬rst order condition for
fA0 is
E(Mv [Y, {1 âˆ’ Ï€(z)}fA0 (z)]|T = 1, Z = z)
= E[Mv {Y, âˆ’Ï€(z)fA0 (z)}|T = âˆ’1, Z = z].

(4)

Hence, for a patient with negative score (i.e., fA0 (z) < 0), we
can have

(5)

= E[Mv {Y, âˆ’Ï€(Z)fA0 (Z)}|T = âˆ’1, Z = z]



(âˆ’1)

= E(I(T = 1)M[Y, {1 âˆ’ Ï€(Z)}f (Z)]|Z = z)

> E[Mv {Y, {1 âˆ’ Ï€(Z)}fA0 (Z)}|T = 1, Z = z]

We next show that d0 (Z) = sign{fW0 (Z)} maximizes the value
function VU (d). For any z, the ï¬rst order condition of the
minimization is



A (f, z) = E(M[Y, {(T + 1)/2 âˆ’ Ï€(Z)} Ã— f (Z)]|Z = z)

= E{Mv (Y, 0)|T = 1, Z = z}

+ E M{Y, âˆ’f (Z)}|T = âˆ’1, Z = z .



fA0 = argminf A (f ), where

E{U(Y (1) )|Z = z}

= E M{Y, f (Z)}|T = 1, Z = z

E Mv {Y, fW0 (Z)}|T = 1, Z = z

1201

(3)

)|Z = z}.

The inequalities in (2) and (3) follow from the fact that
Mv (y, v) is increasing in v (Condition A) and the equality
between (2) and (3) is the consequence of the ï¬rst order condition (1). Similarly, for a patient with a positive score (i.e.,
fW0 (z) > 0), we have E{U(Y (1) )|Z = z} < E{U(Y (âˆ’1) )|Z = z}.
Hence, d0 (z) = sign{fW0 (z)} is an optimal ITR that maximizes
VU (d).
2.2.2. A-learning method. We next demonstrate that the
optimal ITR can be equivalently obtained via a diï¬€erent
loss function constructed via A-learning ideas (Murphy, 2003;
Robins, 2004; Lu et al., 2013; Ciarleglio et al., 2015). Specifically, consider the loss function A (f ) = E{A (f, Z)} and let

> E{Mv (Y, 0)|T = âˆ’1, Z = z}
= E{U(Y

(âˆ’1)

(6)

)|Z = z}.

The inequalities in (5) and (7) follow from Condition A
and the equality between (5) and (6) is from the ï¬rst order
condition (4). Similarly, for a patient with a positive score, we
can have E{U(Y (1) )|Z = z} < E{U(Y (âˆ’1) )|Z = z}. Thus, the
minimizer fA0 can also be used for subgroup identiï¬cation
with d0 (Z) = sign{fA0 (Z)} also maximizing the value function
VU (d).
2.3. Implementation
In this section, we provide some details on how to implement
the proposed procedures in practice. Since most of the discussions apply for both the weighting and A-learning methods,
we use  = W and A to index these two approaches, respectively, for conciseness. To approximate the minimizer f0 with
observed data, one may ï¬rst estimate the loss functions  (f )
empirically. Speciï¬cally, it is straightforward to show that
W (f ) and A (f ) can be, respectively, estimated by
LW (f ) =
LA (f ) =

1
n

1
n

n

i=1

M{Yi , Ti f (Zi )}
Ti Ï€(Zi ) + (1 âˆ’ Ti )/2

and

(7)

n

M[Yi , {(Ti + 1)/2 âˆ’ Ï€(Zi )} Ã— f (Zi )].

(8)

i=1

Since the form of f0 is unknown, direct maximization of
L (f ) among all functional spaces is not feasible. In practice, model assumptions can be imposed to restrict the search
space of f0 (Â·). For example, a simple but useful approach
is to assume that f0 (Â·) can be approximated by a linear
combination of a set of basis functions given a priori. That

1202

Biometrics, December 2017
K

is, f0 (z) â‰ˆ k=1 Î²k Bk (z), where {Bk (z), k = 1, . . . , K} are K
basis functions such as B-spline bases (Ruppert et al., 2003).
One may then ï¬nd (Î²1 , . . . , Î²K ) to minimize the loss funcK
tion L{ k=1 Î²k Bk (Â·)} or its penalized counterpart and let
K
f (Â·) = k=1 Î²k BK (Â·) be the estimated beneï¬t score. Alternatively, one may employ machine learning algorithms such as
boosting to construct f (Â·) based on L (f ) (Hastie et al., 2009).
In many modern applications, the number of covariates
is large but typically only a small subset is relevant to the
treatment selection. Therefore, it is desirable to incorporate
variable selection in subgroup identiï¬cation using penalization approaches such as lasso (Hastie et al., 2009). For our
proposed framework, it is easy to apply appropriate regularization to minimize the penalized loss function L (f ) + Î»(f )
where the penalty term Î»(f ) can be chosen to screen out
noise features or encourage speciï¬c structure of the beneï¬t
score f (Â·).
It is also important to note that in observational studies, the propensity scores Ï€(Zi ) are unknown and need to be
replaced by their consistent estimators in constructing L (f ).
When Z is discrete or low dimensional, non-parametric estimators can be used for Ï€(Â·). When the dimension of Z is
not small, regression models such as logistic regression can be
imposed for Ï€(Â·).
To improve estimation eï¬ƒciency, we may add possible augmentation to M(Â·, Â·) function, while still preserve the same
interpretation of obtained beneï¬t scores. In Web Appendices
A and B, we provide the justiï¬cation and implementation for
the eï¬ƒciency augmentation.
Estimating the Magnitude of Individualized
Treatment Eï¬€ect
We have shown above that the beneï¬t score, deï¬ned as the
minimizer of the appropriately constructed loss function, can
be used for subgroup identiï¬cation since the sign of the score
is consistent with the direction of the treatment eï¬€ect. In
this section, via several examples, we will demonstrate that
often the value of the beneï¬t score can also be used to
approximate the size of the ITE. By choosing diï¬€erent M,
the corresponding minimizers may reï¬‚ect ITE quantiï¬ed by
diï¬€erent metrics. For example, when Y is non-negative, one
may summarize the ITE given Z as E(Y (1) |Z) âˆ’ E(Y (âˆ’1) |Z)
or E(Y (1) |Z)/E(Y (âˆ’1) |Z) (VanderWeele and Knol, 2014). Both
metrics are widely used when investigating treatment covariate interactions and the preference of one over the other seems
to be quite problem-speciï¬c (VanderWeele and Knol, 2014).
In the traditional outcome prediction approach, one needs to
employ seemingly diï¬€erent regression models to estimate such
ITEs. Here, we will show that the ITEs under diï¬€erent metrics can be naturally uniï¬ed under our proposal by considering
diï¬€erent M(Â·, Â·).
To this end, we ï¬rst consider M(y, v) = (y âˆ’ v)2 and the
corresponding propensity score weighted empirical loss function is
2.4.

LW (f ) =

1
n

i

{Yi âˆ’ Ti f (Zi )}2
.
Ti Ï€(Zi ) + (1 âˆ’ Ti )/2

(9)

Assuming that fW0 minimizes W (f ) = E{LW (f )}, the ï¬rst
order condition given in (1) leads to 2fW0 (z) = E(Y (1) |Z =

z) âˆ’ E(Y (âˆ’1) |Z = z). Hence once an estimator f (Â·) of fW0 (Â·)
is obtained, we can use 2f (Z) to approximate the ITE.
Similarly, we can consider the A-learning loss function corresponding to the quadratic loss,
LA (f ) =

1
n

[Yi âˆ’ {(Ti + 1)/2 âˆ’ Ï€(Zi )} Ã— f (Zi )]2 . (10)
i

The ï¬rst order condition (4) implies that fA0 (Â·) =
argminf E{LA (f )} = E(Y (1) |Z = z) âˆ’ E(Y (âˆ’1) |Z = z). Therefore, we also can approximate ITE by constructing
appropriate estimator for the minimizer of E{LA (f )}. Thus,
the quadratic loss M(y, v) = (y âˆ’ v)2 recovers treatment beneï¬t scores that approximate treatment beneï¬t measured by
mean diï¬€erences.
Next, we consider the exponential loss M(y, v) = y exp(âˆ’v).
The corresponding empirical loss functions are
LW (f ) =
LA (f ) =

1
n

i

1
n

Yi eâˆ’Ti f (Zi )
Ti Ï€(Zi ) + (1 âˆ’ Ti )/2

and

Yi eâˆ’{(Ti +1)/2âˆ’Ï€(Zi )}Ã—f (Zi ) .
i

Similarly, the ï¬rst order conditions (1) and (4) imply that
exp{2fW0 (Z)} = E(Y (1) |Z)/E(Y (âˆ’1) |Z)
exp{fA0 (Z)} = E(Y

(1)

|Z)/E(Y

(âˆ’1)

and

|Z),

respectively. Thus, the exponential loss leads to beneï¬t scores
that recover the ITE measured by the ratio of the expected
outcomes under two diï¬€erent treatments.
3.

A Review of Several Methods and Their
Relationship with Our Framework
Tian et al. (2014) proposed a method for RCTs, which is a
special case of our weighted loss function LW (f ) in (7). Particularly, three diï¬€erent types of M, were described in their
article for continuous, binary, and survival type of outcomes,
respectively. For continuous outcomes, M(y, v) = (y âˆ’ v)2 . For
binary outcomes, M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}]. For survival outcomes

 Ï„ 
M(y, v) = âˆ’





v âˆ’ log[E{e I(X â‰¥ u)}] dN(u) ,
v

0

 âˆ§ C, I(X
 â‰¤ C)}, X
 is the survival time,
where y = (X, Î´) = {X

C is the censoring time, N(t) = I(X â‰¤ t)Î´ and Ï„ is a ï¬xed
point such that P(X â‰¥ Ï„) > 0. However, the interpretation of
U(y) = Mv (y, 0) is trickier due to the two-dimensional outcomes and Tian et al. (2014) proved that U(y) is a monotone
 given additional conditions.
transformation of survival time X
Besides, the optimal eï¬ƒciency augmentation forms proposed
by Tian et al. (2014) can also be viewed as special cases of
our eï¬ƒciency augmentation.
For d(Z) = Â±1, an outcome weighted estimator
(OWE) ï¬nds the optimal decision rule by d opt (Z) =

A General Framework for Subgroup Identiï¬cation and Scoring
argmind E[{TÏ€(Z) + (1 âˆ’ T )/2}âˆ’1 YI{Td(Z) < 0}] (Qian and
Murphy, 2011; Zhao et al., 2012; Zhang et al., 2012).
However, since the 0-1 loss I(v < 0) is neither convex
nor continuous, it needs to be replaced by a convex and
continuous surrogate loss operationally to overcome the
computational obstacle, for example, replacing yI(v < 0) by
M(y, v) = yÏ†(v).Xu et al. (2015)
used the logistic loss func
tion Ï†(v) = log 1 + exp(âˆ’v) and Zhao et al. (2012) used
the hinge function Ï†(v) = (1 âˆ’ v)+ , where x+ = max(x, 0).
With those surrogate loss functions, it is clear that the
outcome weighted estimation procedure is equivalent to ours
based on the loss function LW (f ) with the corresponding
M(Â·, Â·). Although the aforementioned justiï¬cation of our
proposal is based on diï¬€erentiable M(Â·, Â·), we show that
it can be extended to non-diï¬€erentiable hinge function for
subgroup identiï¬cation in Web Appendix C.
Moreover, negative outcomes may cause ill-behaved
OWES. One way to deal with this problem is to shift all
outcomes to positive values. However, the estimation eï¬ƒciency may be compromised after such a shift. On the other
hand, one may employ a ï¬‚ipping transformation: for negative
outcome Y with treatment assignment T : we can change its
outcome and treatment assignment to âˆ’Y and âˆ’T, respectively. This ï¬‚ipping transformation does not change the 0-1
loss based on the original data, but in general aï¬€ects the
losses based on the surrogate function Ï†(v) with unclear
consequences in ï¬nal estimation. However, within the proposed framework, it is equivalent to using a ï¬‚ipping version
of M(Â·, Â·) function. For example, the ï¬‚ipping version for
outcome-weighted logistic loss function M(y, v) = y log{1 +
exp(âˆ’v)} used by Xu et al. (2015) is M(y, v) = |y| log[1 +
exp{âˆ’sign(y)v}] with Mv (y, v) = âˆ’y[1 + exp{sign(y)v}]âˆ’1 . It is
not hard to verify that this ï¬‚ipping version of M(Â·, Â·) satisï¬es the two conditions mentioned in Section 2 and thus can
be used to yield a valid estimator for the beneï¬t score. In
addition, we show that a doubly robust AIPWE estimator
proposed by Zhang et al. (2012) can be obtained using a
generalized augmented loss in Web Appendix F.
Lu et al. (2013) and Ciarleglio et al. (2015) proposed an
A-learning estimator for the semiparametric outcome model:
E(Y |T, Z) = m(Z) + TCG (Z; Î²), where m(Â·) is unspeciï¬ed and
Î² is a ï¬nite dimensional vector. Let f (Z) = CG (Z; Î²), their
proposed A-learning estimator is equivalent to minimizing our
A-learning type loss function LA (f ) with M(Â·, Â·) being the
squared loss M(y, v) = (y âˆ’ v)2 . According to our justiï¬cation,
this A-learning method can also be extended to other M(Â·, Â·),
and we will illustrate the logistic loss in numerical studies.

4.

Simulation

4.1. Continuous Outcomes
We conducted extensive numerical studies with both continuous and binary outcomes. We generated a p = 50 dimensional
covariate vector Z = (Z1 , . . . , Zp ) from a mean-zero multivariate normal distribution with variance 1 and covariance
Ï, where Ï is set to be either 0 for the independent setting
or 1/3 for the correlated setting. The treatment assignment
T was generated from a simple logistic regression model
logit{Ï€(Z)} = âˆ’1 + Z1 . The outcome Y was simulated from

1203

nonlinear model


Y=

Î²0 +

Î²j Zj
j=1



2

10

+T



4

Î³j Zj + 0.8Z12

Î³0 +

+ 0.8Z22

+ ,

j=1

where
 âˆ¼ N(0, 2)
and
(Î³0 , . . . , Î³4 ) = (0.4, 0.8, âˆ’0.8,
0.8, âˆ’0.8). The coeï¬ƒcients for the main eï¬€ects were
set as either (i) Î²0 = 6âˆ’1/2 , Î²1 = Î²2 = 0, Î²j = 0.5 Ã— 6âˆ’1/2 ,
j = 3, . . . , 10, representing moderate main eï¬€ects; or (ii)
Î²0 = 3âˆ’1/2 , Î²1 = Î²2 = 0, Î²j = 0.5 Ã— 3âˆ’1/2 , j = 3, . . . , 10, representing large main eï¬€ects. Throughout, we let the training
sample size n = 300 and tested the performances of methods
using an independently generated test data with a sample
size of 10,000. For each simulation scenario, results were
summarized based on 500 datasets. For all methods, we
center the outcome Y by its sample average before model
ï¬tting.
We considered two functional classes of f (Â·) when minimizing the loss functions: (i) a linear model with flin (Z) =
p
Î²0 + i=1 Î²i Zi where the lasso regularization was used to estimate the Î²i â€™s and the tuning parameter of lasso was chosen
by 5-fold cross-validation (CV); (ii) an additive model with
p
fadd (Z) = i=1 fi (Zi ), where fi (Â·), i = 1, . . . , p, are nonlinear functions to be estimated. In ï¬tting the additive model,
we ï¬rst screened the covariates by applying lasso regularization to the simple linear additive model. Then, the B-Spline
method was implemented based on the selected variables
(Ruppert et al., 2003). Operationally, we capped the maximum number of selected covariates in the ï¬rst step to meet
the requirement of R package mgcv, which was used to ï¬t
the additive model. The propensity score function Ï€(Â·) was
treated unknown and estimated by ï¬tting a lasso-regularized
logistic regression with tuning parameter also selected via
5-fold CV.
We also considered various choices of M(y, v). Speciï¬cally, we considered the following seven methods: (i) Full:
Full regression by regressing Y on Z, (T + 1)/2 and (T +
1)/2 Ã— Z and then use the estimated treatmentâ€“covariate
interaction terms to construct ITE; (ii) Wsqâˆ’L : Weighting method with the squared loss M(y, v) = (y âˆ’ v)2 and
f = flin . This is a generalization of the modiï¬ed covariate model proposed by Tian et al. (2014); (iii) Wsqâˆ’A :
Weighting method with the squared loss M(y, v) = (y âˆ’ v)2
and f = fadd ; (iv) Wï¬‚oâˆ’L : Weighting method with the ï¬‚ipping version of the outcome-weighted logistic loss M(y, v) =
|y| log[1 + exp{âˆ’sign(y)v}] and f = flin . This is a variant
of the estimator proposed by Xu et al. (2015) using ï¬‚ipping transformation; (v) Asqâˆ’L : A-learning method with the
squared loss M(y, v) = (y âˆ’ v)2 and f = flin . This is the Alearning estimator proposed in Lu et al. (2013); (vi) Asqâˆ’A :
A-learning method with the squared loss M(y, v) = (y âˆ’ v)2
and f = fadd ; (vii) Aï¬‚oâˆ’L : A-learning method with the ï¬‚ipping version of the outcome-weighted logistic loss M(y, v) =
|y| log[1 + exp{âˆ’sign(y)v}] and f = flin . This is the extended
version of the simple outcome-weighted logistic loss under the
A-learning framework.
Figure 1 shows the boxplots for the rank correlation
coeï¬ƒcients between the estimated scores and true treatment eï¬€ects (Z) in the test set. Higher rank correlation

1204

Biometrics, December 2017

Rank Correlation of Treatment Effect

coeï¬ƒcients should indicate better performance. Here, we used
(Z) = E(Y (1) âˆ’ Y (âˆ’1) |Z) as the ITE metric. We further evaluate performances regarding subgroup identiï¬cation, that
(1)
is, in identifying the subgroup of patients {i|E(Yi |Zi ) >
(âˆ’1)
E(Yi
|Zi )}. Figure 2 shows the average receiver operating characteristic (ROC) curves among 500 runs. The full
regression has the worst performance among these methods, especially with correlated covariates, and other methods
approximating the beneï¬t score with a linear function have
comparable performance. More ï¬‚exible nonlinear additive
models outperform their linear counterparts as expected.
The A-learning method with the squared loss M(y, v) =
(y âˆ’ v)2 performs slightly worse than the weighting method
with correlated covariates, while A-learning and weighting
with M(y, v) = |y| log[1 + exp{âˆ’sign(y)v}] have similar performances. When there are big main eï¬€ects, the performances of
all methods become slightly worse than the scenarios with

moderate main eï¬€ects, especially when the covariates are correlated, likely due to the fact that main eï¬€ect may mask the
interactions of interest.
We also checked the performance of eï¬ƒciency augmentation
and possible inï¬‚uence of incorrect propensity score model.
These additional results are in Web Appendix D.
4.2. Binary Outcomes
For binary outcomes, we simulated the outcome by
dichotomizing a continuous latent response: selectfont


Y =I

10

( Î²0 +

Î²j Z j ) 2 + T ( Î³0 +
j=1



4

Î³j Zj + 0.8Z12 + 0.8Z22 ) +  > 0

,

j=1

and all other settings were the same as those for continuous outcomes. To improve estimation eï¬ƒciency, we also

Big Main Eff/Cor Cov

Big Main Eff/Ind Cov

Full Wsqâˆ’L Wsqâˆ’A Wfloâˆ’L Asqâˆ’L Asqâˆ’A Afloâˆ’L

Full Wsqâˆ’L Wsqâˆ’A Wfloâˆ’L Asqâˆ’L Asqâˆ’A Afloâˆ’L

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

Rank Correlation of Treatment Effect

Method
Moderate Main Eff/Cor Cov

Moderate Main Eff/Ind Cov

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
Full Wsqâˆ’L Wsqâˆ’A Wfloâˆ’L Asqâˆ’L Asqâˆ’A Afloâˆ’L

Full Wsqâˆ’L Wsqâˆ’A Wfloâˆ’L Asqâˆ’L Asqâˆ’A Afloâˆ’L

Method
Figure 1. Boxplots for the rank correlation coeï¬ƒcients between the estimated beneï¬t scores and true treatment eï¬€ects
for continuous outcomes. Method â€œFullâ€ uses the full regression; method â€œWsqâˆ’L â€ uses the weighting method with squared
loss M(y, v) = (y âˆ’ v)2 and a linear f ; method â€œWsqâˆ’A â€ uses the weighting method with squared loss M(y, v) = (y âˆ’ v)2
and a nonparametric additive f ; method â€œWï¬‚oâˆ’L â€ uses the weighting method with ï¬‚ipping outcome-weighted logistic loss
M(y, v) = |y| log[1 + exp{âˆ’sign(y)v}] and a linear f ; method â€œAsqâˆ’L â€ uses the A-learning method with M(y, v) = (y âˆ’ v)2 and
a linear f ; method â€œAsqâˆ’A â€ uses the A-learning method with M(y, v) = (y âˆ’ v)2 and a nonparametric additive f ; method
â€œAï¬‚oâˆ’L â€ uses the A-learning method with ï¬‚ipping outcome-weighted logistic loss M(y, v) = |y| log[1 + exp{âˆ’sign(y)v}] and a
linear f .

A General Framework for Subgroup Identiï¬cation and Scoring
Big Main Eff/Ind Cov

0.2

0.4

0.6

0.8

0.8
0.6
0.4
0.2
0.0

1.0

0.0

0.2

0.4

0.6

0.8

False Positive Rate

False Positive Rate

Moderate Main Eff/Cor Cov

Moderate Main Eff/Ind Cov

0.0

0.2

0.4

0.6

0.8

1.0

False Positive Rate

1.0

0.8
0.6
0.2

0.4

Full
Wsqâˆ’L
Wsqâˆ’A
Wfloâˆ’L
Asqâˆ’L
Asqâˆ’A
Afloâˆ’L

0.0

Average True Positive Rate

1.0
0.8
0.6
0.2

0.4

Full
Wsqâˆ’L
Wsqâˆ’A
Wfloâˆ’L
Asqâˆ’L
Asqâˆ’A
Afloâˆ’L

0.0

Average True Positive Rate

Full
Wsqâˆ’L
Wsqâˆ’A
Wfloâˆ’L
Asqâˆ’L
Asqâˆ’A
Afloâˆ’L

1.0

0.0

Average True Positive Rate

0.8
0.6
0.2

0.4

Full
Wsqâˆ’L
Wsqâˆ’A
Wfloâˆ’L
Asqâˆ’L
Asqâˆ’A
Afloâˆ’L

0.0

Average True Positive Rate

1.0

1.0

Big Main Eff/Cor Cov

1205

0.0

0.2

0.4

0.6

0.8

1.0

False Positive Rate

Figure 2. ROC curves of estimated beneï¬t scores for subgroup identiï¬cation when the outcomes are continuous.
Method â€œFullâ€ uses the full regression; method â€œWsqâˆ’L â€ uses the weighting method with squared loss M(y, v) = (y âˆ’ v)2
and a linear f ; method â€œWsqâˆ’A â€ uses the weighting method with squared loss M(y, v) = (y âˆ’ v)2 and a nonparametric additive f ; method â€œWï¬‚oâˆ’L â€ uses the weighting method with ï¬‚ipping outcome-weighted logistic loss M(y, v) =
|y| log[1 + exp{âˆ’sign(y)v}] and a linear f ; method â€œAsqâˆ’L â€ uses the A-learning method with M(y, v) = (y âˆ’ v)2 and a linear f ; method â€œAsqâˆ’A â€ uses the A-learning method with M(y, v) = (y âˆ’ v)2 and a nonparametric additive f ; method
â€œAï¬‚oâˆ’L â€ uses the A-learning method with ï¬‚ipping outcome-weighted logistic loss M(y, v) = |y| log[1 + exp{âˆ’sign(y)v}] and a
linear f .

subtracted 0.5 from all Y s before the analysis for ï¬‚ipping version of outcome-weighted logistic loss. This subtraction was
used because when y = 0, M(y, v) = 0 for some choices of M.
Although subjective, this shift was quite helpful for eï¬ƒciency
gain. Parallel to the settings with continuous outcome, we ï¬rst
implemented the traditional full logistic regression with both
main eï¬€ects and interaction eï¬€ects. Secondly, we employed
both weighting and A-learning methods with logistic likelihood M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] proposed by Tian
et al. (2014), and the ï¬‚ipping outcome-weighted logistic loss
M(y, v) = |y| log[1 + exp{âˆ’sign(y)v}]. The latter case was of

particular interest since the shifted outcome may take negative values. The beneï¬t score was approximated by either
the simple linear or the nonparametric additive function. The
lasso regularization was used for feature selection. Figures 3
and 4 show the corresponding results for rank coeï¬ƒcients and
ROC curves, respectively. The nonlinear methods outperform
their linear counterparts in terms of rank correlations with
the underlying ITE but similarly based on ROC curves. On
the other hand, the A-learning method seems to perform better than the weighting method in terms of the ROC curves
but similarly based on rank correlations.

Biometrics, December 2017

Rank Correlation of Treatment Effect

1206

Big Main Eff/Cor Cov

Big Main Eff/Ind Cov

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
Full Wloâˆ’L Wloâˆ’A Wfloâˆ’L Aloâˆ’L Aloâˆ’A Afloâˆ’L

Full Wloâˆ’L Wloâˆ’A Wfloâˆ’L Aloâˆ’L Aloâˆ’A Afloâˆ’L

Rank Correlation of Treatment Effect

Method
Moderate Main Eff/Cor Cov

Moderate Main Eff/Ind Cov

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
Full Wloâˆ’L Wloâˆ’A Wfloâˆ’L Aloâˆ’L Aloâˆ’A Afloâˆ’L

Full Wloâˆ’L Wloâˆ’A Wfloâˆ’L Aloâˆ’L Aloâˆ’A Afloâˆ’L

Method
Figure 3. Boxplots for the rank correlation coeï¬ƒcients between the estimated beneï¬t scores and true treatment eï¬€ects for
binary outcomes. Method â€œFullâ€ uses the full logistic regression; method â€œWloâˆ’L â€ uses the weighting method with logistic
loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] and a linear f ; method â€œWloâˆ’A â€ uses the weighting method with logistic loss M(y, v) =
âˆ’[yv âˆ’ log{1 + exp(v)}] and a nonparametric additive f ; method â€œWï¬‚oâˆ’L â€ uses the weighting method with ï¬‚ipping outcome
weighted logistic loss M(y, v) = |y| log[1 + exp{âˆ’sign(y)v}] and a linear f ; method â€œAloâˆ’L â€ uses the A-learning method with
logistic loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] and a linear f ; method â€œAloâˆ’A â€ uses the A-learning method with logistic loss
M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] and a nonparametric additive f ; method â€œAï¬‚oâˆ’L â€ uses the A-learning method with ï¬‚ipping
outcome weighted logistic loss M(y, v) = |y| log[1 + exp{âˆ’sign(y)v}] and a linear f.
5.

Real Data Example (Mammography
Screening Study)
This is a randomized study for female participants who were
non-adherent to mammography screening guidelines at the
study baseline. One primary interest of the study was to
compare the intervention eï¬€ects of phone counseling on mammography screening (phone intervention) versus usual care at
21 months post-baseline. The outcome is whether the subject took mammography screening during this time period.
We conduct outcome shift by subtracting 0.5 from all binary
outcomes for ï¬‚ipping version of outcome weighted logistic
loss. There are 530 subjects with 259 in the phone intervention group and 271 in the usual care group. Sixteen binary
baseline covariates, including sociodemographics, health belief
variables, and stage of readiness to undertake mammography
screening, and one categorical variable, number of years had

a mammogram in past 2â€“5 years, are available in the study.
Considering the covariatesâ€™ ï¬rst and second order interactions,
there are 204 features in total.
To compare diï¬€erent methods, we randomly selected 80%
participants and set the rest as a test set to evaluate the
performance of the estimated beneï¬t scores for ITEs. Speciï¬cally, following Xu et al. (2015), we evaluate the performance
of a treatment recommendation rule d(Z) = sign{f0 (Z)} by
the enhanced treatment eï¬€ects E[{Z, t, d(Â·)}] = E(Y |d(Z) =
t, T = t) âˆ’ E(Y |d(Z) = t, T = âˆ’t), which can be estimated by
the empirical weighted averages in the test set. This quantity
measures the diï¬€erence in the outcome between participants
received the recommended intervention and those didnâ€™t. If
both E[{Z, 1, d(Â·)}] and E[{Z, âˆ’1, d(Â·)}] are positive, then
the beneï¬t score-based recommendation of the intervention
is helpful for the participants in the study population. When

A General Framework for Subgroup Identiï¬cation and Scoring
Big Main Eff/Ind Cov

0.4

0.6

0.8

0.6
0.4
0.2
0.0

1.0

0.0

0.2

0.4

0.6

0.8

False Positive Rate

False Positive Rate

Moderate Main Eff/Cor Cov

Moderate Main Eff/Ind Cov

0.0

0.2

0.4

0.6

0.8

1.0

False Positive Rate

1.0

0.8
0.6
0.2

0.4

Full
Wloâˆ’L
Wloâˆ’A
Wfloâˆ’L
Aloâˆ’L
Aloâˆ’A
Afloâˆ’L

0.0

Average True Positive Rate

1.0
0.8
0.6
0.2

0.4

Full
Wloâˆ’L
Wloâˆ’A
Wfloâˆ’L
Aloâˆ’L
Aloâˆ’A
Afloâˆ’L

0.0

Average True Positive Rate

0.8

1.0
0.2

Full
Wloâˆ’L
Wloâˆ’A
Wfloâˆ’L
Aloâˆ’L
Aloâˆ’A
Afloâˆ’L

1.0

0.0

Average True Positive Rate

0.8
0.6
0.2

0.4

Full
Wloâˆ’L
Wloâˆ’A
Wfloâˆ’L
Aloâˆ’L
Aloâˆ’A
Afloâˆ’L

0.0

Average True Positive Rate

1.0

Big Main Eff/Cor Cov

1207

0.0

0.2

0.4

0.6

0.8

1.0

False Positive Rate

Figure 4. ROC curves of estimated beneï¬t scores for subgroup identiï¬cation when outcomes are binary. Method â€œFullâ€ uses
the full logistic regression; method â€œWloâˆ’L â€ uses the weighting method with logistic loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] and
a linear f ; method â€œWloâˆ’A â€ uses the weighting method with logistic loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] and a nonparametric additive f ; method â€œWï¬‚oâˆ’L â€ uses the weighting method with ï¬‚ipping outcome-weighted logistic loss M(y, v) = |y| log[1 +
exp{âˆ’sign(y)v}] and a linear f ; method â€œAloâˆ’L â€ uses the A-learning method with logistic loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}]
and a linear f ; method â€œAloâˆ’A â€ uses the A-learning method with logistic loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] and a nonparametric additive f ; method â€œAï¬‚oâˆ’L â€ uses the A-learning method with ï¬‚ipping outcome-weighted logistic loss M(y, v) =
|y| log[1 + exp{âˆ’sign(y)v}] and a linear f.
coupled with the inverse probability weighting technique, the
enhanced treatment eï¬€ects score is still a valid measure when
the data are from observational study. The procedures were
repeated for 200 random splits and the mean enhanced treatment eï¬€ects (and estimated standard errors from these 200
splits) for diï¬€erent methods are reported in Table 1, where
larger average enhanced treatment eï¬€ect indicates better
performance of the estimator. The beneï¬t scores are approximated by simple linear functions since most features are
binary. The full regression performs the worst among all methods, and the ï¬‚ipping outcome-weighted logistic loss M(y, v) =
|y| log[1 + exp{âˆ’sign(y)v}] seems slightly better than the logistic likelihood loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}] under the

same setting, while comparable with the eï¬ƒciency-augmented
logistic likelihood loss. Additional real data analysis for
a national supported work study can be found in Web
Appendix E.
6. Discussion
In this article, we proposed a ï¬‚exible framework for treatment
scoring in both observational studies and RCTs, based on
weighting and A-learning methods. The proposed methods
are quite ï¬‚exible and many recently proposed estimators can
be represented as special cases within our frameworks.
A very practical issue of applying our proposal is the
choice of the M(Â·, Â·) and f (Â·) functions. As we demonstrate

1208

Biometrics, December 2017

Table 1
The average estimated enhanced comparative treatment eï¬€ect (standard errors) and average subgroup sizes (proportions) in
test data based on 200 random splits of mammography screening study
t=1
Method

Mean (SE)

Full
Wloâˆ’L
WloEâˆ’L
Wï¬‚oâˆ’L
Aloâˆ’L
AloEâˆ’L
Aï¬‚oâˆ’L

âˆ’0.005 (0.009)
0.008 (0.009)
0.020 (0.010)
0.014 (0.010)
0.002 (0.009)
0.021 (0.010)
0.012 (0.010)

t = âˆ’1
Subgroup size
62
53
49
52
52
49
52

(59%)
(50%)
(46%)
(49%)
(49%)
(47%)
(49%)

Mean (SE)
0.039
0.058
0.073
0.070
0.056
0.072
0.069

(0.011)
(0.011)
(0.010)
(0.010)
(0.011)
(0.010)
(0.011)

Subgroup size
44 (41%)
53 (50%)
57 (54%)
54 (51%)
54 (51%)
57 (53%)
54 (51%)

Note: â€œFullâ€ uses full logistic regression; â€œWloâˆ’L â€ uses weighted logistic likelihood loss M(y, v) = âˆ’[yv âˆ’ log{1 + exp(v)}]; â€œWloEâˆ’L â€
uses weighted eï¬ƒciency-augmented logistic likelihood loss; â€œWï¬‚oâˆ’L â€ uses weighted ï¬‚ipping outcome-weighted logistic loss M(y, v) =
|y| log[1 + exp{âˆ’sign(y)v}]; â€œAloâˆ’L â€ uses A-learning method with logistic likelihood loss; â€œAloEâˆ’L â€ uses A-learning method with eï¬ƒciencyaugmented logistic likelihood loss; â€œWï¬‚oâˆ’L â€ uses A-learning method with ï¬‚ipping outcome-weighted logistic loss.

in Section 2.4, the choices may depend on the preference
of the ITE metrics. For example, if ITE is quantiï¬ed by
E(Y (1) |Z)/E(Y (âˆ’1) |Z) instead of E(Y (1) |Z) âˆ’ E(Y (âˆ’1) |Z), suitable M needs to be constructed accordingly. We also note
that diï¬€erent M can have equivalent U(Y ) and ITR. For
example, M(y, v) = (y âˆ’ v)2 and M(y, v) = y log{1 + exp(âˆ’v)}
both have U(Y ) as a linear transformation of Y , and therefore should identify the same subgroup. However, they can
have fairly diï¬€erent performances in ï¬nite-sample studies as
demonstrated in numerical studies.
When specifying the class of functions for f , one also needs
to balance the bias variance trade-oï¬€. A simple linear form
may be appropriate for a speciï¬c data with one type of ITE
while non-linear bases functions might be needed to adequately approximate the ITE for other cases. With suï¬ƒciently
large sample size, one may use cross-validation or sample split
to select an optimal set of basis for a given dataset with a given
M. When the number of covariates or the number of basis
functions is large, one may overcome overï¬tting by employing popular lasso or elastic net regularization to help with
variable selection and stabilize model ï¬tting.
Suitable eï¬ƒciency augmentation such as outcome shift may
help to reduce the variability and enhance the robustness
of relevant estimators. Thus, it is crucial to withhold an
independent test set to objectively examine the performance
of resulting ITR estimators based on diï¬€erent combinations
of M, f , regularization procedure and eï¬ƒciency augmentation method (Zhao et al., 2013). An appropriate choice of
the estimation procedure may be made by considering the
complexity, clinical interpretability, and computational cost
associated with the estimation.
When the models for the propensity and/or f are misspeciï¬ed, the rank of the estimated beneï¬t scores can still
be informative. To account for mis-speciï¬cation in f , one
may nonparametrically calibrate the treatment eï¬€ect estimator according to the rank of the scores as in Cai et al. (2011)
and construct the corresponding ITR. Mis-speciï¬cation in the
propensity score may lead to sub-optimal estimation of the
beneï¬t scores, but one may use such scoring systems for future
clinical trials to more accurately determine ITR.

Although our framework described in earlier sections
focuses on binary treatments, the generalization to multiple treatments is feasible. In Web Appendix G, we extend
our framework to multiple treatments with an additional
assumption on M using the weighting method. Tao and Wang
(2016) proposed a method for multi-treatment selection by
generalizing the OWE to settings with more than two treatment arms. Their multi-treatment OWE could be viewed
as a special case of our generalized framework for multiple
treatments.
7. Supplementary Materials
Sample R codes for implementing the proposed method and
Web Appendices referenced in Sections 2â€“5 are available
with this article at the Biometrics website on Wiley Online
Library.

Acknowledgements
This research was supported by a Patient-Centered Outcomes
Research Institute (PCORI) Award (ME-1409-21219 for Chen
and Yu) and by grants from the National Institute of Health
(R01 HL089778-05 and U54 HG007963 for Cai and Tian).
The views in this publication do not necessarily represent the
views of the PCORI, its Board of Governors or Methodology
Committee.

References
Cai, T., Tian, L., Wong, P. H., and Wei, L. (2011). Analysis of
randomized comparative clinical trial data for personalized
treatment selections. Biostatistics 12, 270â€“282.
Ciarleglio, A., Petkova, E., Ogden, R. T., and Tarpey, T. (2015).
Treatment decisions based on scalar and functional baseline
covariates. Biometrics 71, 884â€“894.
Foster, J. C., Taylor, J. M., and Ruberg, S. J. (2011). Subgroup
identiï¬cation from randomized clinical trial data. Statistics
in Medicine 30, 2867â€“2880.

A General Framework for Subgroup Identiï¬cation and Scoring
Gabriel, S. and Normand, S. (2012). Getting the methods rightâ€”
The foundation of patient-centered outcomes research. The
New England Journal of Medicine 367, 787â€“790.
Hastie, T. J., Tibshirani, R. J., and Friedman, J. H. (2009). The
Elements of Statistical Learning: Data Mining, Inference,
and Prediction. Springer Series in Statistics. New York:
Springer.
Kraemer, H. C. (2013). Discovering, comparing, and combining
moderators of treatment on outcome after randomized clinical trials: A parametric approach. Statistics in Medicine 32,
1964â€“1973.
Loh, W.-Y., He, X., and Man, M. (2015). A regression tree approach
to identifying subgroups with diï¬€erential treatment eï¬€ects.
Statistics in Medicine 34, 1818â€“1833.
Lu, W.,Zhang, H. H., and Zeng, D. (2013). Variable selection for
optimal treatment decision. Statistical Methods in Medical
Research 22, 493â€“504.
McKeague, I. W. and Qian, M. (2014). Estimation of treatment
policies based on functional predictors. Statistica Sinica 24,
1461â€“1485.
Murphy, S. A. (2003). Optimal dynamic treatment regimes. Journal of the Royal Statistical Society, Series B (Statistical
Methodology) 65, 331â€“355.
Qian, M. and Murphy, S. A. (2011). Performance guarantees for
individualized treatment rules. Annals of Statistics 39, 1180.
Robins, J. M. (2004). Optimal structural nested models for optimal
sequential decisions. In Proceedings of the Second Seattle Symposium in Biostatistics, 189â€“326. New York, USA:
Springer.
Rosenbaum, P. R. and Rubin, D. B. (1983). The central role of the
propensity score in observational studies for causal eï¬€ects.
Biometrika 70, 41â€“55.
Rubin, D. B. (2005). Causal inference using potential outcomes:
Design, modeling, decisions. Journal of the American Statistical Association 100, 322â€“331.
Ruppert, D., Wand, M., and Carroll, R. (2003). Semiparametric
Regression. Cambridge, UK: Cambridge University Press,
1st edition.

1209

Su, X., Zhou, T., Yan, X., Fan, J., and Yang, S. (2008). Interaction
trees with censored survival data. The International Journal
of Biostatistics 4 2.
Tao, Y. and Wang, L. (2016). Adaptive contrast weighted learning
for multi-stage multi-treatment decision-making. Biometrics, DOI: 10.1111/biom.12539.
Tian, L., Alizadeh, A. A., Gentles, A. J., and Tibshirani, R.
(2014). A simple method for estimating interactions between
a treatment and a large number of covariates. Journal of the
American Statistical Association 109, 1517â€“1532.
VanderWeele, T. J. and Knol, M. J. (2014). A tutorial on interaction. Epidemiologic Methods 3, 33â€“72.
Vansteelandt, S., VanderWeele, T. J., Tchetgen, E. J., and Robins,
J. M. (2008). Multiply robust inference for statistical interactions. Journal of the American Statistical Association 103,
1693â€“1704.
Xu, Y., Yu, M., Zhao, Y.-Q., Li, Q., Wang, S., and Shao, J. (2015).
Regularized outcome weighted subgroup identiï¬cation for
diï¬€erential treatment eï¬€ects. Biometrics 71, 645â€“653.
Zhang, B., Tsiatis, A. A., Davidian, M., Zhang, M., and Laber, E.
(2012). Estimating optimal treatment regimes from a classiï¬cation perspective. Stat 1, 103â€“114.
Zhang, B., Tsiatis, A. A., Laber, E. B., and Davidian, M. (2012).
A robust method for estimating optimal treatment regimes.
Biometrics 68, 1010â€“1018.
Zhao, L., Tian, L., Cai, T., Claggett, B., and Wei, L.-J. (2013).
Eï¬€ectively selecting a target population for a future comparative study. Journal of the American Statistical Association
108, 527â€“539.
Zhao, Y., Zeng, D., Rush, A. J., and Kosorok, M. R. (2012).
Estimating individualized treatment rules using outcome
weighted learning. Journal of the American Statistical Association 107, 1106â€“1118.

Received July 2016. Revised December 2016.
Accepted January 2017.

