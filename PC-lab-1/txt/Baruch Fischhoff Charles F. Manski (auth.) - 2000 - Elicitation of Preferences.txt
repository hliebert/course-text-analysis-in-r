Journal of
Risk and
Uncertainty
Special Triple Issue on: Preference Elicitation Guest Editors: Baruch Fischhoff and Charles R Manski
Volume 19, Number 1-3, December 1999
Editors' Introduction: Elicitation of Preferences ......................... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Banteh Fischhoff and Charles R Manski 5
The Effects of Financial Incentives in Experiments: A Review and Capital-LaborProduction Framework .............. Colin R. Camerer and Robin M Hogarth 7
Commentary 1 ..................................... David V. Budescu 43 Commentary 2 ....................................... Catherine Eckel 47
Analysis of Choice Expectations in Incomplete Scenarios .... Charles R Manski 49 Commentary 1 ..................................... Kenneth L Wolpin 67 Commentary 2 ........................................ Elke U. m:ber 71
Rationality for Economists? ............................ Daniel McFadden 73 Commentary 1 ..................................... . Markl Machina 107 Commentary 2 ..................................... .Jonathan Baron 109
Anchoring and Acquiescence Bias in Measuring Assets in Household Surveys .................................................... Michael D. Hurd 111 Commentary 1 ........................................ .Arie Kapteyn 137
Construal Processes in Preference Assessment ........................... . . . . . . . . . . . . . . . . . . . . . . . . . . Baruch Fischhoff, Ned Welch and Shane Frederick 139 Commentary 1 ........................................ .Jeff Dominitz 165 Commentary 2 ................................. Timothy L. McDaniels 169
Choice Bracketing ....... Daniel Read, George Loewenstein and Matthew Rabin 171 Commentary 1 ........................................ Gideon Keren 199 Commentary 2 ....................................... David Laibson 201
Economic Preferences or Attitude Expressions?: An Analysis of Dollar Responses to Public Issues ............ Daniel Kahneman, Ilana Ritov and David Schkade 203
Commentary 1 ..................................... Steven 1 Sherman 237 Commentary 2 ........................................ Hal R. Varian 241
Measuring Constructed Preferences: Thwards a Building Code ............. . . . . . . . . . . . . . . . . . . . . .John W. Payne, lames R. Bettman and David A. Schkade 243
Commentary 1 ...................................... Norbert Schwarz 271 Commentary 2 ........................................ Robin Gregory 273

ELICITATION OF PREFERENCES
edited by
Baruch Fischhoff
Department ofSocial and Decision Sciences Carnegie Mellon University
Charles F. Manski
Department ofEconomics Northwestern University
A Special Issue of
JOURNAL OF RISK AND UNCERTAINTY Volume 19, Nos. 1-3 (1999)
SPRINGER SCIENCE+BUSINESS MEDIA, LLC

Library of Congress Cataloging-in-Publication Data

Elicitation of preferenees I edited by Barueh Fisehhoff, Charles F. Manski. p. em.
"A special issue of Joumal ofrisk and uneertainty, volume 19, nos. 1-3 (1999)."

Revised papers presented at a summer 1997 symposium organized at the University of California, Berkeley, by Daniel MeFadden, and with eommentaries added by invited psyehologists and eeonomists.

IncIudes bibliographical referenees.

ISBN 978-90-481-5776-1

ISBN 978-94-017-1406-8 (eBook)

DOI 10.1007/978-94-017-1406-8

1. Consumers' preferenees--Congresses. 2. Preferenees (Philosophy)--Congresses. 3. Eeonomies --Psyehological aspects--Congresses. 1. Fisehhoff, Baruch, 1946- II. Manski, Charles F.

HF5415.32.E485 1999 658.8'343-dc21

99-058686

Copyright ® 2000 by Springer Science+Business Media New York Originally published by Kluwer Academic Publishers in 2000
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means, mechanical, photocopying, recording, or otherwise, without the prior written permission of the publisher, Springer Seienee+Business Media, LLC.

Printed an acid-free paper.

Journal of Risk and Uncertainty, 19:1-3; 5-6 (1999) © 1999· Kluwer Academic Publishers. Manufactured in The Netherlands.
Editors' Introduction: Elicitation of Preferences
BARUCH FISCHHOFF AND CHARLES F. MANSKI
Economists and psychologists have, on the whole, exhibited sharply different perspectives on the elicitation of preferences. Economists, who have made preference the central primitive in their thinking about human behavior, have for the most part rejected elicitation and have instead sought to infer preferences from observations of choice behavior. Psychologists, who have tended to think of preference as a context-determined subjective construct, have embraced elicitation as their dominant approach to measurement.
Some psychologists and economists, ourselves among them, have been frustrated to observe that our two disciplines, despite their mutual concern with the study of human behavior, have too often failed to engage one another in a constructive manner. A necessary condition for engagement is communication. Hence we were pleased to learn, in early 1997, that Daniel McFadden would organize a symposium on Elicitation of Preferences to be held that summer at the University of California, Berkeley. Thirty years ago, McFadden's fundamental research on the econometric analysis of random utility models showed how productive it can be to blend the best elements of economic and psychological thinking. Throughout his career, McFadden has made efforts to enhance contact between psychologists and economists. If anyone would take the initiative to engage economists and psychologists on the elicitation of preferences, it would be Dan.
The Berkeley symposium generated many provocative presentations of original research and much lively discussion. Those who participated agreed that this research and discussion warrant communication to a wider audience. With this in mind, we approached the editor of the Journal of Risk and Uncertainty with a proposal for a special issue based on a selection of the papers presented at the symposium, accompanied by commentaries by invited psychologists and economists. We are pleased that the JRU accepted this proposal, and we hope that readers will share our enthusiasm.
Following the symposium, each of the articles in this issue was submitted for publication. The submissions were reviewed by many conscientious anonymous referees, who provided detailed constructive comments to the authors. Authors then revised their papers as appropriate.
Readers will find a spectrum of perspectives within. As editors who have read all of the articles and commentaries, we do not find here a grand synthesis of economics and psychology. We do, however, see a constructive engagement in the making. We hope that the publication of this issue will deepen and broaden the terms of this engagement.

6

FISCHHOFF AND MANSKI

We are grateful to the National Science Foundation for its sponsorship of the 1997 Berkeley symposium on the Elicitation of Preferences and to Paul Ruud, who co-organized the symposium with Dan McFadden. We appreciate the opportunity we have had to work with Grace Katagiri, who supervised the production of this issue with superb efficiency and much patience. We are most pleased to dedicate this issue to Dan McFadden, whose sixtieth birthday took place during the period of the Berkeley symposium.

Journal of Risk and Uncertainty, 19:1-3; 7-42 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

The Effects of Financial Incentives in Experiments: A Review and Capital-Labor-Production Framework

COLIN F. CAMERER

camerer@hss.caltech.edu

Rea and Lela G. Axline Professor of Business Economics, Division of Humanities and Social Sciences 228-77, California Institute of Technology, Pasadena, CA 91125

ROBIN M. HOGARTH
Wallace W. Booth Professor of Behavioral Science, Graduate School of Business, University of Chicago, Chicago, IL 60637

Abstract
We review 74 experiments with no, low, or high performance-based financial incentives. The modal result is no effect on mean performance (though variance is usually reduced by higher payment). Higher incentive does improve performance often, typically judgment tasks that are responsive to better effort. Incentives also reduce "presentation" effects (e.g., generosity and risk-seeking). Incentive effects are comparable to effects of other variables, particularly "cognitive capital" and task "production" demands, and interact with those variables, so a narrow-minded focus on incentives alone is misguided. We also note that no replicated study has made rationality violations disappear purely by raising incentives.
Key words: Experimental economics, rationality, bounded rationality, judgment, incentives, experimental methodology
JEL Classification: B41, D80

I. Introduction
The predicted effect of financial incentives on human behavior is a sharp theoretical dividing line between economics and other social sciences, particularly psychology. The difference is manifested in alternative conventions for running experiments. Economists presume that experimental subjects do not work for free and work harder, more persistently, and more effectively, if they earn more money for better performance. Psychologists believe that intrinsic motivation is usually high enough to produce steady effort even in the absence of financial rewards; and while more money might induce more effort, the effort does not always improve performance, especially if good performance requires subjects to induce spontaneously a principle of rational choice or judgment, like Bayes' rule.

8

CAMERER AND HOGARTH

The effect of incentives is clearly important for experimental methodology. In addition, varying incentives can tell us something about human thinking and behavior which should interest all social scientists, and may be important for judging the effects of incentives in naturally-occurring settings (e.g., compensation in firms, or public responses to taxation).
Ultimately, the effect of incentives is an empirical question. Indeed, it is an empirical question which has been partly answered, because many studies have explored the effect of varying levels of incentive in many different tasks. In this paper we summarize the results of 74 studies comparing behavior of experimental subjects who were paid zero, low or high financial performance-based incentives.
The studies show that the effects of incentives are mixed and complicated. The extreme positions, that incentives make no difference at all, or always eliminate persistent irrationalities, are false. Organizing debate around those positions or using them to make editorial judgments is harmful and should stop.
The presence and amount of financial incentive does seem to affect average performance in many tasks, particularly judgment tasks where effort responds to incentives (as measured independently by, for example, response times and pupil dilation) and where increased effort improves performance. Prototypical tasks of this sort are memory or recall tasks (in which paying attention helps), probability matching and multicue probability learning (in which keeping careful track of past trials improves predictions), and clerical tasks (e.g., coding words or building things) which are so mundane that monetary reward induces persistent diligence when intrinsic motivation wanes. In many tasks incentives do not matter, presumably because there is sufficient intrinsic motivation to perform well, or additional effort does not matter because the task is too hard or has a flat payoff frontier. In other tasks incentives can actually hurt, if increased incentives cause people to overlearn a heuristic (in problem-solving "insight" tasks), to overreact to feedback (in some prediction tasks) to exert "too much effort" when a low-effort habit would suffice (choking in sports) or when arousal caused by incentives raises self-consciousness (test-taking anxiety in education).
In the kinds of tasks economists are most interested in, like trading in markets, bargaining in games and choosing among risky gambles, the overwhelming finding is that increased incentives do not change average behavior substantively (although the variance of responses often decreases). When behavior does change, incentives can be interpreted as shifting behavior away from an overly socially-desirable presentation of oneself to a more realistic one: When incentives are low subjects say they would be more risk-preferring and generous than they actually are when incentives are increased.

ll. Capital, labor, and production
Take a subject's point of view. An experiment is a cognitive activity for which subjects volunteer (usually), somewhere between playing "charades" with friends at

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

9

a party and doing a neighbor's taxes for extra pocket money. Subjects come to the experiment with knowledge and goals. Earning more money is presumably one goal. Subjects surely have other goals as well: They may be intrinsically motivated to perform well, may want to appear intelligent by making quick decisions, sometimes try to amuse other subjects or fulfill the experimenter's implicit "demands," and may want to exhibit socially desirable behavior (like generosity and risk -taking).
In economic terms, we can think of a subject's goals as an objective function he or she is trying to maximize. Knowledge is "cognitive capital." The requirements of the task, which we call "production," are also important for determining performance. Psychologists ask: How well can subjects with particular knowledge, in a specific task, achieve their goals? Equivalently, economists ask: How well can subjects maximize their objective function, given available capital, and a particular production function?
Previous discussions in experimental economics have focussed almost exclusively on the objectives of minimizing effort cost and maximizing monetary reward, because economists instinctively assume thinking as a costly activity. For example, in Smith and Walker's (1993) "labor theory," subjects respond to increased incentive by expending more cognitive effort, which is presumed to reduce variance around responses. The simplest kind of labor theory rests on two intuitions: (1) Mental effort is like physical effort-people dislike both, and will do more of both if you pay them more; and (2) effort improves performance because, like scholars, subjects have access to a wide range of all-purpose analytical tools to solve experimental problems. This simple view ignores two important factors-intrinsic motivation (some people like mental effort, and those people disproportionately volunteer for experiments!); and the match between the analytical skills possess and the demands of the tasks they face. Effort only improves performance if the match is good. This latter omission is remedied by introducing the concepts of capital and production into the labor theory.

Capital
Cognitive psychologists distinguish "declarative knowledge"-facts about the world -from "procedural knowledge"-a repertoire of skills, rules and strategies for using declarative knowledge to solve problems. Knowing that Pasadena is northeast of Hollywood is declarative knowledge; knowing how to read a map of Los Angeles is procedural knowledge.
Experimenters are usually interested in the procedural knowledge of subjects, not the declarative knowledge. (In a sense, good instruction-writing ensures that all subjects have the declarative knowledge to understand how their decisions affect their performance.) We take procedural knowledge and "cognitive capital" to be roughly the same. 'Pieces' of capital are a variety of tricks or approaches to solving an experimental task, like the many specialized tools on a carpenter's tool belt or a

10

CAMERER AND HOGARTH

cook's knowledge of foods, kitchen utensils, and recipes. In economics experiments, cognitive capital includes heuristics like anchoring on a probability of .5 and adjusting, rules of thumb like cutoffs for rejecting ultimatum offers, analytical formulas or algorithms, personal skills or traits (e.g., unusual ability to concentrate, terrific short-term memory, perceptual skill, high 'need for achievement'), domainspecific procedures ("always wait until the end of the period to buy") and so forth.
An important feature of capital is how it is acquired. In the time horizon of a laboratory experiment, subjects probably acquire capital through learning-by-doing rather than from learning-by-thinking. As Smith (1991) wrote,
Many years of experimental research have made it plain that real people do not solve decision problems by thinking about them in the way we do as economic theorists. Only academics learn primarily by reading and thinking. Those who run the world, and support us financially, tend to learn by watching, listening and doing (p. 12).
Furthermore, useful cognitive capital probably builds up slowly, over days of mental fermentation or years of education rather than in the short-run of an experiment (1-3 hours). (Cognitive psychologists say it takes 10 years or 10,000 hours of practice to become expert at difficult tasks; see e.g., Ericcson and Smith, 1991). However, incentives surely do play an important role in inducing long-run capital formation.

Production
A task's production requirements are the kinds of capital necessary to achieve good performance. Some tasks, like clerical ones, require simple attention and diligence. (Trading in markets might be like this, but includes perhaps patience and memory.) Other tasks, like probability judgments, might use analytical skill or domain-specific knowledge. Complicated games might require special analytical devices like backward induction.
Adding capital and production to the labor theory has several general implications.
First, capital variables-like educational background, general intelligence, and experience with a task-can have effects that are as strong as the effect of financial incentives (and interact with incentives). If experimenters manipulate incentives because of a prior belief that incentive effects are large, they should spend more time measuring and manipulating capital variables as well.
Second, asking how well capital is suited to the production task at hand is important because poorly-capitalized subjects may perform worse when incentives are stronger (just as running too fast, without proper stretching or coaching, can injure muscles).

TilE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

11

Third, the nature of the production task matters because some tasks are simply easier (or have "floor effects")-that is, almost every subject has some kind of capital which enables good production-while others are hard ("ceiling effects"; few subjects have the necessary capital).
Fourth, elements of experimental design can affect the production function and alter performance systematically. Simplicity of instructions, stimulus display, opportunities for communication, and so forth, can affect performance and may also interact with incentives. (For example, tasks that are designed to be engaging may increase attention, lowering the "cost" of effort or raising intrinsic motivation, and reducing the marginal effect of higher financial incentives.)
Fifth, considering capital and production together implies that in some tasks, people should sacrifice short-run performance to learn better decision rules-to acquire cognitive capital useful for production-which raises a fresh empirical question of whether people sacrifice earning for learning optimally (see Merlo and Schotter, 1999).

lll. A review of studies
The concepts of capital, labor, and production were introduced to provide a loose framework within which empirical effects of incentives can be understood.
The empirical heart of our paper is an informal review of 74 studies comparing behavior of experimental subjects who were not paid, or were paid low or high financial incentives, according to their performance. The studies are those we knew of and which came to our attention, so the sampling is nonrandom. However, we also sampled every article which varied financial incentives published in the American Economic Review, Econometrica, Journal ofPolitical Economy, and Quarterly Journal of Economics from 1990-98. More careful surveys of studies were done by Bonner et al. (1996), Hertwig and Ortmann (1998), and Jenkins et al. (1998); we compare our conclusions with theirs below. Because of the opportunistic sampling we used, the reader is entitled to regard the paper as an informed essay or collection of conjectures, which may or may not prove true after a more careful meta-analysis of studies (and further research).
Studies were included if they satisfied two rules: (i) Incentive levels were reported and varied substantially within the study; and (ii) the study reported enough detail of the level of incentive and size of any performance effects to enable us to classify the effects of incentive. Thus, studies were excluded if they lacked a within-study control group or underreported details of incentive effects. As far as we could tell, subjects always knew the payoff functions they faced.
Studies satisfying the control and reporting criteria (i) and (ii) are summarized in Table 1. The studies are classified in several groups-incentives help mean performance, incentives hurt mean performance, incentives have no effect on mean performance, incentives affect behavior but behavior cannot be judged by a performance standard, and incentive effects are confounded with effects of other

.._.
N
Table 1. Review of experiments measuring effects on financial incentives on performance

Author (year)

Task

Incentives

Effect of higher incentives

INCENTIVES IMPROVE MEAN PERFORMANCE

Ashton (1990,

Predicting company bond ratings (four categories) 0 vs. L ($120.96

Higher number of correct ratings (4.64 vs. 5.58); lower variance

groups 1-2)

from three numerical measures of financial

each for top 2

(3.57 vs. 1.74); feedback, written justification raised number

Atkinson (1958)

performance Arithmetic, drawing tasks

of 51 S's) L ($5.10),

correct too (5.55, 5.31).
Better performance (48.37 vs. 51.96, p < .01 L vs. H); inverted

H ($1 0.20) for high U-shaped effect of probability of winning (48.03, 51.39,

score in groups of

53.21, 49.18); high "need for achievement" S's do better.

N ~ 20, 3, 2, or

top 3 of 4

Awasthi & Pratt (1990)

Judgment problems: conjunction, sample size, and sunk cost

0 vs. L ($2.42)

Slight decline in error rate (.46 vs. .41), reduced error more for S's high in "perceptual differentiation" .44 vs..21; more time

spent in L condition (4.2 vs. 5.7 min)

Camerer, Ho &

Dominance-solvable "beauty contest games"

L ($1 ;round) vs.

Slightly closer to Nash equilibrium

Weigelt (1997) Castellan (1969)

measuring levels of iterated of dominance Probability matching: sequential betting on
independent draws of events (S's should

H ($4 /round) L (3.96 cjtriai),
H (39.6 cI trial)

Shift toward maximizing trials 81-180 (58% vs. 61%, p(E) ~ .6;
83% vs. 87%, p < .01, p(E) ~ .775)

always bet on the most likely event E, which

has p(E) chance)

Cooper eta!. (in press)

Signaling games with output-quota ratchet effects; L (30 yuanjS) vs.

Chinese studentsjmanagers subjects

H (!50 yuanjS);

Higher frequency of strategic (pooling) choices (50% vs. 60% ), no difference in frequency of planner "mistakes" (66% vs.

(30 yuan ~ $3.75 at 69% ); effect diminished by experience, mimicked by

official FX; mgrs

instruction context

earn 100 yuan/day)

Drago & Heywood Choice of decision number e in piece-rate and

(1989)

rank-order labor; incentive treatment is

L (8.81 c gain from Mean closer to prediction of 37 (48.7 vs. 37.2, round 12), lower e ~ 0 toe* ~ 37) vs. variance (964 vs. 51, round 12).

Glucksberg (1962)

"flatness" of expected payoff function Easy problem-solving (with a helpful visual clue)
and recognition of familiar words

H (84.4 c gain) 0 vs. L (fastest
25% S's $23.58 each, fastest S

Problem-solving: faster (5.0 vs. 3.7 min), more solutions (26 vs. 30); word recognition: faster (47.0 vs. 34.0 sec)

i

Grether (1980, 1992 exps 1-2)

$94.34)

Probability judgments of events and choice of

0 vs. L ($10 for

most-likely events, based on sample information correct choice)

Similar non-Bayesian patterns, but incentive S's less far from Bayesian; fewer erroneous responses (12% vs. 4%).

~
~

Harrison (1994)
Hogarth et a!. (1991)

(Some use of scoring rules) Choices of gambles to test EU theory ("Allais
paradox") Prediction of stochastic outcome from two cues

0 vs. L (EV ~ $.55$6.45)
0 vs. L (1.16 cjpoint)

Small reduction in Allais paradox (35% vs.l5%, conditions APO-APl), statistically marginal (p ~ .14 two-tailed z-test)
Higher accuracy when penalty function was "lenient" (small weight on squared error in evaluation function), means 358 vs.
288 (experiment l)

tJ
::r:
0
~

Jamal & Sunder (1991)

Trading in commodity double auctions

0 vs. L (1.16-

Sharper convergence to predicted equilibrium price with

(treatments are incentives, trading experience of 2.32 cjpoint, $9.28- incentives (p = .003), solely in markets with small number of

~

subjects, and large1small number of traders)

13.91/session)

inexperienced S's.

1:!1

Kahneman& Peavler (1969)
Libby & Lipe

Remembering digit-noun pairs Recall and recognition of items on a list of

L (3.96 c) vs. H (19.8 c)
0 vs. L (11.6 cjitem

Better memory (18% vs. 55%); high incentive increased pupil dilation
Better recall (9.8 vs. 120 items), no difference in recognition

q~

(1992)

accounting controls

+ bonus for top

(15.8 vs. 16.3); more effort (1105 vs. 1281 sec)

Vl

Riedel, Nebeker & Transferring data from hand-written

5 S's) 0 vs. bonuses

Better performance in bonus groups vs. 0 (more quantity, fewer

0
"l1

Cooper (1988)
Salthouse, Rogan & Prill (1984)
Scott, Farh & Podsakoff (1988)
Siegel, Siegel &

questionnaires to scannable forms
Recall of digits and letters in a "divided attention" task: Two sequences, digits or letters. Total incentive 4 cjtrial, incentives for each of the two sequences were (x, 4-x), x from 0 to 4.
Assembly of frame-mat puzzles
Probability matching

($1.44 times 1, 2, 3, 4, 5 for exceeding 5.75/hour) 0 vs. L (5.95 cjdigit or letter)
Ovs. L ($.079jassembly)
0 vs. L (22.99 c if

errors, p < .001). No difference among levels of bonuses.
Better recall for high-incentive sequences (20% for 0, 80% for 4), experiment 1
More work done (18.5 vs. 22.3, p < .001) (0 group paid L wage
but were y "surprised" and told this only after doing the task) Shift toward maximizing (70%, 77%, 93%)

~
~
n
-f:; -n z
1:!1
~

Andrews (1964) Smith (1962)

Trading in double auctions

right), H (± 22.99 c) Ovs.L (23.58 c

Sharper convergence to competitive equilibrium prices and quantities

-di
Vl
z

Smith (1965)

Trading in double auctions with excess supply

payment/trade) pL(4 of 27 S's get

Sharper convergence to competitive equilibrium (mean

~

(competitive equilibrium gives sellers zero surplus)

paid each period) vs. L ($54.71 surplus per period

deviations $2.26 vs. $2.13 period 1, 63.3 c vs. 9.04 c period 4), smaller variance in prices ($1 0.85 vs. 67.8 c in period 4)

-1:!1
~
~

+ 22.61 c per trade)

1:!1

Smith & Walker

Bidding in first-price private-value auctions

Five levels:

More risk-aversion, lower variance of bids around linear

~

(1993)

$.58/auction times (constant relative risk-aversion) bid function; effect of 1

Vl

0, 1, 5, 10, 20

session of bidding experience equal to incentive level of 20

Wright&

Probability judgment after being given a random 0 vs. L ($371.44

Less effect of anchoring (.235 vs..160); lower standard

Anderson (1989)

"anchor"; dependent variable is difference

total for top 45

deviation (in 14 of 18 context-anchor level comparisons)

between high- and low-anchor probabilities

of 77 S's)

INCENTIVES HURT MEAN PERFORMANCE

Arkes, Dawes &

Predicting student honors from grades. (S's

0 vs. L ($.14/trial) Lower accuracy (70% vs. 64% vs. 66%, control group); incentive

Christensen

given formula with 70% accuracy)

vs. L' ($6.99 for

S's used formula less, did worse

(1986)

best of 16)

Ashton (1990)

Predicting company bond ratings (four

0 vs. L ($120.96

Lower number of correct ratings (6.38 vs. 6.04); higher

categories); subjects given decision aid (bond

each for top 2

variance (1.85 vs. 3.35)

rating score)

of 51 S's)

.w......

....... .;.. Table 1. (Continued)

Author (year)

Task

Incentives

Effect of higher incentives

Friedman (1998)
Glucksberg (1962)
Grether & Plott (1979)
Hogarth et a!. (1991)
McGraw & McCullers (1979)
Miller & Estes (1961)
Schwartz (1982)

INCENTIVES HURT MEAN PERFORMANCE

Deciding whether to switch chosen "door"' in "three-door" problem (switching is Bayesian)

L ( + $.40/ + $.10)

Less switching at higher incentives (43.9 vs. 48.7, p ~ .00 to .10

vs. H ( + $1 I - $.50) in probit regressions)

Difficult "insight" problem-solving (Duncker

0 vs. L (fastest

Problem-solving: fewer solutions (22 vs. 16), slower

candle problem) and recognition of familiar

25% S's $23.58

(7.4 vs. 11.1 min); word recognition: faster recognition for

("church") and unfamiliar ("vignette") words

each, fastest S

familiar words (47 vs. 34 sec), slower for unfamiliar words

$94.34)

(151.9 vs. 199.8)

Choice-pricing preference reversals over money gambles

0 vs. L (EV from $2.79-7.97)

Higher rate of reversals for P-bet choices (55.9% vs. 69.7%, p ~ .05) (experiment 1)

Prediction of stochastic outcome from two cues

0 vs. L

Lower accuracy when penalty function was "exacting" (high

(1.16 cjpoint)

weight on squared error in evaluation function), means 319 vs.

301 (experiment 1)

Set-breaking problem (Luchins water jug): nine

0 vs. L ($.10 +

Slower solution time on lOth problem (181 vs. 289 sec)

similar problems, followed by lOth different one;

$2.07 if all

(difference not due to extra checking time, but to slower

dependent variable is performance on lOth

answers correct)

identification of "set-breaking" solution)

Identification of visual stimuli (two faces with

0 vs. L

More errors inLand H than 0 (21 %, 32%, 34% ); no

different eyebrows)

($0 .048;trial)

difference in response times; S's were 9-year old boys

H ($2.38/triai)

Learning rules governing which sequences of

0 vs. L

Negative effect of trial-by-trial payoff from L, H (63% of rules

lever presses are rewarded

($.016 ;success)

discovered vs. 80% for 0, 83% M), for pretrained subjects only;

vs. M ($1.62 for

no effect for inexperienced subjects (95% rules discovered);

rule discovery) vs.

cf. Merlo and Schotter (in press).

H (Land M)

Bohm (1994) Bolle (1990)

INCENTIVES DO NOT AFFECT MEAN BEHAVIOR

Choice-pricing (Vickrey-auction buying price) preference reversals over future money payments (1072 Swedish kroner in 3 mo vs. 1290 SEK in 15 mol

0 vs. L 0/10 chance of getting preferred choice, or 10 S's in Vickrey

Small, insignificant reduction in overall percentage of preference reversals (choosing one claim but bidding more for another), 19% vs. 29% (Table 1, finance students only); bigger reduction in reversal for those who choose 3-month payment,

~
m
gJ

auction, high

15% vs. 63%

:;.:l

Ultimatum bargaining: offer take-it-or-leave-it part of amount X (prediction ~ offer of $.01,

bidder wins) L (2.42 DM),
H (24.2 DM),

No difference in mean offers (41 %, 36%,41%, 45%) or lowest amount accepted (38%, 33%, 28%, 32%) (note: (pL,L)

~

acceptance of any positive amount)

pL (p ~ 1/10 of

and (pH,H) have some expected payoffs but (pL,H) were

::c:

24.2 DM), pH (p ~ 1/10 of
242 DM)

more similar)

0
~

Bull, Schotter & Weigelt (1987)
Camerer (1987)
Camerer (1989)

Choices of decision numbers (simulating effort) in rank-order labor "tournaments"
Trading in double auctions for risky assets where "representativeness" judgments can bias asset prices
Choices of gambles

Camerer (1990, Ultimatum bargaining p.315)

Cox & Grether (1996)

Preference reversals: discrepancies between gamble choices and valuation (established using Becker-DeGroot-Marschak procedure or sealedbid auction, or English clock descending-price auction)

Craik & Tulving Learning to remember words

(1975)

Fehr & Tougareva Choices of wages and efforts in experimental

(1996)

labor market

Fiorina & Plott 5-person committee choices of a two-dimensional

(1978)

point (cf. Kormendi and Plott, 1980)

Fouraker & Siegel Duopoly and triopoly quantity choices (Cournot) (1963)

Forsythe et al. Ultimatum bargaining (1994)
Guth, Schmitt- Ultimatum bargaining berger & Schwarze (1982)
Hey (1982, 1987) Search: decisions about which price to accept from a sequence of prices
Hoffman, McCabe Ultimatum bargaining & Smith (1996a)

Irwin et al. (in press)

Bids for $3 ticket elicited by Beeker-DeGrootMarschak method with different penalities for suboptimality

L (0-$1.96/trial), H (0-$7.89jtrial)
L ($.475/asset) vs. H ($2.38/asset)
0 vs. L (expected value $6.30)
pL (X= $12.17) pH (X = $121.70) (p = 1/39)
0 vs. L (.5 of H) vs. H (mean $60.57 for 1-1/2 hr)
L (2.76c) M (8.29c), H (16.6c)
L (up to $1jperiod) vs. H (up to $10/period)
L (2.3-11.6 cjunit) H ($2.32$6.96/unit)
L vs. H ($37.27, 23.29, 9.32 bonus to top 3)
0 vs. L ($5 .36) vs. H ($10.73)
L (1.62 OM) H (16.2 DM)
0 vs. L (expected £8.15)
L ($10.73/pair) vs. H ($107.27/pair)
L (1 c for $1 error) vs. H (20 c for $1 error)

Decision numbers "did not differ" (fn 8, no details reported)
No difference in amount of bias (.09 vs..14 bias in 1-red samples, .10 vs..01 in 2-red samples)
No significant differences in risk-aversion or test-retest reliability
No difference in offers (39% vs. 38%) or lowest amount accepted (21% vs. 15%)
No difference between rates of predicted and unpredicted reversals using BDM (60%, 73%,46%, period 1), small difference in second-price auction (37%, 76%, 73%), opposite difference in English clock auction (93%, 79%, 47%). repetition eliminates predicted PR in second-price auction (0, 29%, 27% in round 5), English clock auction only in L,H conditions. Land H S's more risk-averse (46% vs. 54%). No difference in intransitivity (16% 0 vs. 11% for L-H)
No effect on amount of accurate recall (65%, 64%, 66%, experiment 10)
No effect on average wage, worker effort, or slope of effortwage relation (.0074 vs..0072). Average subject income $17jmonth (Russians)
Marginally significant reduction in deviation of averaged data from the core (2.5 units vs. 1, p = .08 and .11 on different dimensions by Epps-Singleton test); reduction in % of points outside near-core region (p = .06); less variance (20 vs. 7)
No difference in mean or variance of profits
No difference in offers or lowest amount accepted; less crosssession variance; mean offers 40%, 45%, 47%
No difference in offers or lowest amount accepted
No significant effect on amount of optimal stopping (25% vs. 33%) or apparent search rules
No significant difference (contest/exchange, mean offer 31% vs. 28%, mean rejected offer 20% vs. 18%; random, mean offer 44% vs. 44%, mean rejected offer 35% vs. 40%)
No significant effect on mean deviation from truthful bidding ($.62 vs. $.50) (experiment 2, full information)

~
~
0
"1
:!l
~
~
I
z
I
......
VI

-0\

Table 1. (Continued)

Author (year)

Task

Incentives

Effect of higher incentives

INCENTIVES DO NOT AFFECT MEAN PERFORMANCE

Kahneman,

Mental arithmetic: remembering four-digit strings L (8.26 c)

No effect on accuracy (88% vs. 82%); increased pupil dilation

Peavler &

and adding 0 or 1 to each digit

H (41.3 c)

in easier add-0 condition

Onuska (1968)

Loomes & Taylor Choices over 3 gamble pairs (are there regret-

0 vs. L

No difference, 21.6% cycles vs. 18.5% cycles

(1992)

induced intransitive cycles?)

(EV ~ £4.22)

McKelvey & Palfrey Choices in multi-stage "centipede games"

L ($.20-$) vs. H

No significant difference (.06 vs.. 15 equilibrium taking at

(1992)

($60-$24)

first node)

Neelin,

Sequential bargaining: subjects alternate offers

L (X ~ $6.56) vs.

No difference in mean percentage of X offered (34% vs. 34%) or

Sonnenschein &

dividing a "shrinking pie" of size X across five

H (X ~ $19.69)

mean offer rejected (26% vs. 30%)

Spiegel (1988)

rounds

Nilsson (1987)

Recall and recognition of words

0 vs. L ($13.58 for

No difference in recall (35% vs. 33%) or recognition (58% vs.

bestS, n ~ 10)

55%); incentiveS's self-reported working harder.

Roth et al.

Ultimatum bargaining

L ($11.60/pair) vs. No difference in ultimatum games (median 48-50% in rounds 1,

(1991)

H ($34.79/pair)

10 for both L,H); small, insignificant difference in "market"

Samuelson &

Buyers bidding against an informed seller

0 vs. L (+ $7.19 to

games with 9 proposers competing (median 58% vs. 78%) No effect on median, modal bid ( ~ 50, version 3, compare

Bazerman (1985) ("acquire-a-company" problem)

- $14.39)

Figs. 3, lOa).

Siegal & Fouraker Buyer-seller bargaining over price-quantity pairs L (48.5 c-77.65 c

No significant difference in mean profit (266.92 c vs. 43.68 c).

(1960)

(incentive is differential between Pareto-optimal difference) vs.

much lower variance (2426 c vs. 92.21 c)

and adjacent-quantity outcome)

H ($2.91)

Straub &

Ultimatum offers and acceptance thresholds,

pL ($10.47 pie)

No significant difference in mean offers (31% to 26% for

Murnighan (1995)

complete and partial information (responders do not know pie size)

times 1,3,5,8,10
(Prob of playing p ~ 2/1813)

multiplier 1 to 10) or mean acceptance thresholds (19% vs. 20%)

~

Wallsten, Budescu Probability judgments using numerical or verbal

& Zwick (1993)

expressions

0 vs. L (total $20 bonus for top 4 of 7 S's)

No significant difference in accuracy (measured by an incentive-compatible spherical scoring rule); some difference
in positive (P) and negative (N) conditions (P, N guarantee > 0,

~

Weber et al. (1997) Trading risky assets in double auctions with

0 vs. L (EV

< 0 payoffs for stating probability .5)
"No difference in market prices" (p. 17)

~

different endowment conditions (long, neutral, short)

.22 DMjunit) vs. H (EV 2.20 DMjunit)

:r::
0

~

ffi

Battalio, Jiranyakul & Kagel (1990)

INCENTIVES AFFECT BEHAVIOR, BUT NO PERFORMANCE STANDARD

Choice of gambles

More risk-averse

~

Beattie & Loomes Choice of gambles (1997)

0 vs. pL 0/4

No difference (q's 1-3); no difference in "common ratio effect";

chance) vs. L (EV

more risk-aversion (q 4; 36%, 22%, 8%)

@

£3 to £7.81)

0

Binswanger (1980) Choice of gambles (by poor Indian farmers)

0 vs. L (EV 86.54

More risk-aversion at higher stakes, .86, 8.65, 86.54 rupees; no

"!1

rupees ~ .2% of

difference in mean risk-aversion, hypothetical vs. real 86.54

"!1

Cubit!, Starmer & Choice of gambles

average S's wealth) rupees (p. 398); hypothetical choices more dispersed

0 vs. L (EV from

More risk-averse (50% vs. 60%, groups 3.1-3.2)

~

Sugden (1998) Edwards (1953)

Choice of gambles (p, $X) with pX held constant

£2.5 to 12) 0 vs. H (pX ~ 53c,
0,- 53c)

More risk-seeking. Larger deviations from EV and EU maximization for bets with pX ~ 53c or 0; fewer intransitivities

(")
~

Forsythe et al.

Dictator "games" (one person divides $10.73

(1994)

between self and other)

Grether & Plott

Choice of gambles

(1979)

Cummings, Harrison Choice of whether to buy consumer products

& Rutstrom (1995)

Hogarth & Einhorn Choice of gambles

0 vs. L ($5 .36) vs.

More self-interested offers (50% offer half and 15% offer 0 vs.

H ($10.73) 0 vs. L (EV from

20% offer half and 35% offer 0); means 48%, 28%, 23%
More risk-seeking (p < .01) (experiment 1)

$2.79 to 7.97)

0 vs. L (hypothetical Fewer purchases (9% vs. 31% ).

vs. actual purchase)

L (EV ~ $.12) vs.

More risk-averse (40% vs. 73% gains, 24% vs. 36% losses)

z
(")
~

(1990) Irwin, McClelland

H (EV ~ $12.10)

(experiment 3)

Vickrey auctions for insurance against risky losses 0 vs. L (.011,

More risk-averse: median bids higher, fewer zero bids and very

z

& Schulze (1992) Kachelmeier &
Shehata (1992)

- $45.06)

Choice of gambles (Canadian and Chinese students: L (1.13 yuan) vs.

67.58 yuan~ monthly income)

H (11.26 yuan)

high bids More risk-averse (certainty-equivalents higher than expected
value for L incentive); both Land H overweight low winning

~

List & Shogren (1998)
Sefton (1992)

Valuations of received Christmas gifts Dictator games

0 vs. L (4th-price

probabilities Higher valuations in actual auction ($96 vs. $137)

~

Vickrey auction for 244 gifts)

~

0 vs. pL (1/4

More self-interested offers in L condition, means $2.15, $2.06,

chance of playing) $1.23 (0, pL the same, both significantly different from L)

vs. L ($5.63/pair)

Schoemaker (1990) Choice of gambles

0 vs. pL (7/242

Slightly more risk-averse (75% vs. 77% gains, 23% vs 34%

chance of playing

losses, p ~ .20)

EV ~ $60.48,

- 60.48)

Slonim & Roth

Ultimatum bargaining

L ($1.90),

Rejection rates of percentage offers lower with increased stakes

(1998)

M ($9.70),

(44%, 19%, 13% for offers 25-40%), p (M vs. L) ~ .04,

Slovic (1969)

Choice of gambles

H ($48.4) 0 vs. L (EV $7.12)

p (H vs. L) ~ .002; bargaining in Slovak crowns (60, 300, 1500) More risk-averse (p < .01)

....... -...!

.......
00

Table 1. (Continued)

Author (year)

Task

Incentives

Effect of higher incentives

Bahrick (1954)
Baumeister (1984)
Eger & Dickhaut (1982)
Fouraker & Siegel (1963 exps 3-5)
Kroll et al. (1988) Phillips & Edwards
(1966) Slavic &
MacPhillarny (1974)
Wright & Aboull-Ezz (1988)

INCENTIVE EFFECTS ARE CONFOUNDED WITH EFFECTS OF OTHER TREATMENTS

Learning names of geometric forms; peripheral learning of colors is worse (incentive paid for

0 vs. L (max $8.55) Faster learning of forms (16.9 trials vs. 19.6); worse learning of colors (6.1 vs. 7.6)

form learning only); 0 subjects told not to try hard Physical game of hand-eye coordination: moving
two rods so a ball rolls between them, then

0 vs. L ($1.49/trial)

Worse scores in first trial (33.6 vs. 28.3), same scores in second trial (34.1 vs. 33.2); no variances reported.

dropping the ball into a slot (confound between

incentive and stated performance goal) Posterior probability judgment; searching for
evidence of "conservatism" in Bayesian updating (confound between incentive and elicitation technique; no-incentive S's give odds, incentive

0 vs. L ($64.66, $40.41, $24.25 for top 3 S's in each group of 9-10)

Reduced judgment error (conservatism), measured by slope of log odds against log Bayesian odds (.63 vs. 1.04); less error in accounting vs. abstract context

S's pick "payoffs tables" which E bets against) Buyer-seller bargaining over price and quantity
(confound between incentive and experience:

Lvs. H

No difference in mean prices or quantities; variance 1-4 times smaller

H trial was 21st of 21 trials) Investing in risky assets (confound between

Lvs. H

More risk-averse, closer to optimal portfolio, work harder

higher incentive and risk-aversion) Posterior probability judgment (confound
between incentive and use of two proper and

0 vs. L ($.44 maxjtrial)

Lower Bayesian errors (30% lower); lower cross-S variance (.005 vs..012)

one improper scoring rules) Multicue prediction with missing values (e.g.,
admitting students who each have two test scores,

0 vs. L (max $12.18) No difference in fraction of S's weighting common test more heavily (70%, 77%)

with only one test in common) (confound

between incentive and trial-by-trial feedback,

missing cue distribution information) Judgments of probability distribution of GMAT,
age, and salary of MBA students (confound between incentive and use and explanation of

0 vs. L ($157.48
total for 10 best S's, n ~ 51)

Lower mean squared error (.007 vs..004); lower cross-S variance (half in L)

scoring rule)

I
~
::r:: 0
~

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

19

treatments. The table reports the authors, task, and incentive level in each study. The rightmost column summarizes the effects of the incentive levels given in the third column. The table was constructed by the first author and every entry was checked by a research assistant.
An example will show how to read the table. In the Awasthi and Pratt (1990) study there were two performance-based incentive levels, denoted 0 and L. Zero means choices were hypothetical so there was no performance-based incentive (usually subjects were paid a few dollars for participating). L means the stakes were low (they were paid $2.42 for answering each judgment problem correctly); H denotes higher stakes. For comparability, all payments were inflated to 1997 dollars using the GDP deflator.
Note that Land H denote lower and higher levels within a study, not absolute levels. The absolute levels are generally reported as well. This reporting convention does make it difficult to compare across studies, since the L level in one study may, in absolute terms, be higher than the H level in another study. However, this convention does make it possible to tell whether, in general, raising stakes from L to H improves performance (regardless of what those levels are).
The table reports that the fraction of subjects making errors was 46% in the 0 condition and 41% in the L condition, so higher incentives reduced error slightly. The fourth column also notes that L subjects took more time to complete the task (5.7 minutes instead of 4.2), and the reduction in error caused by higher incentive, from 44% to 21%, was greatest for subjects who were high in "perceptual differentiation" (measured by a psychological test).
Rather than reviewing each study, we will describe some regularities in the several categories of results, which are summarized in Table 2.

When incentives help
There are many studies in which higher incentives do improve mean performance. Table 2 suggests that incentives appear to help most frequently in judgment and decision tasks (they also sometimes hinder performance in this class of tasks). They improve recall of remembered items, reduce the effect of anchoring bias on judgment, improve some kinds of judgments or predictions, improve the ability to solve easy problems, and also sharpen incentives to make zero-profit trades in auctions or do piece-rate clerical work.
An example is Libby and Lipe (1992), who studied recall and recognition of 28 internal firm controls which accountants might look for when auditing a firm (e.g., "spoiled checks are mutilated and kept on file"). Subjects then had to recall as many of the controls as they could (in the "recall" task) or recognize controls seen earlier, on a new list which included some spurious controls (in the "recognition" task). Some subjects were paid a flat fee ($2) for participating (the 0 condition) and others earned 10 (11.6 cents in 1997) cents for each item correctly recalled or recognized, along with a $5 bonus for each of the top five subjects. Incentives

20

CAMERER AND HOGARTII

Table 2. The number of studies exhibiting various incentive effects

Type of task
Judgments and decisions Probability judgment Binary choice (including "three door" problem) Multivariate prediction Problem solving Item recognition/recall Clerical (drawing, data transfer, assembly)
Games and markets Dominance-solvable games Tournaments Signaling games Sequential bargaining Ultimatum games

Helps Has no effect Hurts

3

2

2

2

4

2

2

3

3

1

3

1

1

1

1

2

6

Trust games (labor markets,

2

centipede)

Auctions: double

3

Auctions: private value

1

Auctions: common value

Spatial voting

Duopoly, triopoly

1

Individual choices

Dictator tasks

Risky choices

3

Non-EU choice patterns

1

1

Preference reversals

2

1

Consumer purchases

Search (wages)

1

Has an effect, but no performance standard
1 (fewer rejections of fixed-% offers at higher stakes)
1 (Vickrey for gifts, higher valuations)
2 more self-interested 8 more risk-averse, 2 more risk-seeking 1 fewer actual purchases

caused subjects to work harder (about 3 minutes longer). Incentives also caused subjects to recall more items correctly (12.0 vs. 9.8) but did not improve recognition much (16.3 vs. 15.8). Libby and Lipe suggest that incentives do induce more effort, but effort helps a lot in recalling memories, and only helps a little in recognizing an item seen previously. Their study is a glimpse of how incentive effects can depend dramatically on the kind of task a person performs.
Kahneman and Peavler's (1969) study is notable because it measures a physical manifestation of the effort induced by higher incentives-pupil dilation. Their subjects learned a series of eight digit-noun pairs from an audiotape (e.g., "3-frogs").

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

21

Then subjects were told a digit (e.g., 3) and asked to say which noun had been paired with that digit. For some digits, subjects had a low incentive to guess the noun correctly (1 cent) and others had a high incentive (5 cents). When subjects were told the incentive level on each trial, their pupils dilated (they grew wider in diameter). When incentives were high dilation was larger (pupils changed in diameter from 3.99 millimeters to 4.04) than when incentives were low (3.97 to 3.98). The difference in the amount of dilation in the low and high incentive
conditions is tiny but highly significant (t = 3.2, p < .01). High-incentive subjects
also got more nouns correct (55%) than low-incentive subjects (18%). A simple count of studies in which incentives affect average behavior (versus
those in which incentives don't matter) shows that a disproportionate number of effects result from raising the level of incentives from 0 (i.e., subjects choose hypothetically and are paid no performance-based incentive) to a low level L. Raising incentives from some modest level L to a higher level H is more likely to have no effect. This suggests that while adding some incentive to otherwise-hypothetical choices often matters, experiments which then multiply stakes by 2, 4, or 20 do not produce similar boosts in performance. It is too early to call for an end to such (expensive!) experiments but the results in Table 1 suggest little reason to think the effects of very large incentives will be substantial.

When incentives hurt
In a few tasks, incentives appear to actually hurt. All of these are judgment or decision tasks. Many of the studies establishing these negative effects are likely to be controversial, and the effects are often unclear for various methodological reasons. (Researchers itching to study incentives empirically might start by trying to replicate some of these results.)
A striking example is Arkes, Dawes and Christensen (1986). Their subjects were told grades for each of 20 students and were asked to predict whether the students won honors. In one condition, students were given a simple formula for predicting honors from grades, which was right 70% of the time. (Students were told how accurate the formula was, and were warned that outpredicting the formula is difficult.) No-incentive subjects generally used the formula and got 66% right. Incentivized subjects, paid $.10/trial ($.19 in 1997$), tended to abandon the formula and actually got fewer right (63%). While their effort was not measured directly, one can interpret the incentivized subjects' abandonment of the simple formula as an exertion of effort; but their extra effort hurt performance, rather than improved it.
Ashton (1990, groups 5-6) got the same result in a similar setting, prediction of bond ratings. This phenomenon is related to the fact that experts in many domains -law, medicine, graduate admissions, psychiatry-make worse predictions than simple formulas based on observable, quantitative predictors (see Dawes, Faust and Meehl, 1989, for a review of nearly a hundred field studies). In these domains

22

CAMERER AND HOGARTH

formulas require little effort and predict well. Increased incentives cause people to exert more effort, adding their own judgment to the formula (or ignoring it), leading to predictions which are often worse. In terms of capital and production, these sorts of judgment tasks require simple calculations focussing on only a few cues. When "too much capital" is used, it backfires.
Hogarth et al. (1991) found that when subjects were stiffly penalized for forecasting inaccurately in a two-variable "multicue learning" task, the effect of incentives was to encourage more experimentation which lowered overall performance. In two studies on 'insight' problems like the Luchins water-jug task, Glucksberg (1962) and McGraw and McCullers (1979) found that subjects were slower to have the insightful experience which gave a correct answer if they were paid. Since these problems require subjects to 'break set' and think unorthodoxly to find the answer, the negative effects of incentives means highly-incentivized subjects may be exerting more effort, but more effort blinds them to the surprising answer.
Incentives might also hurt when added incentives make people self-conscious about an activity which should be automatic (though no studies in Table 1 use these tasks). The phenomenon appears as "choking" in sports (professional basketball players sink significantly fewer free-throw shots in high-pressure playoff games than in regular-season games; see Camerer, 1998), and test-taking anxiety in education (see Baumeister, 1984), and can be traced to Yerkes and Dodson (1908).

When incentives make no difference
The most common result is that incentives did not affect mean performance. These include studies on market trading, bargaining, and some studies of risky choices.
Incentives appear to not matter when the marginal monetary return to increased effort is low. Effort returns will be low when it is either very easy to do well, or very hard to improve performance (known in psychology as "floor" and "ceiling" effects). For example, in bargaining, Camerer (1990), Forsythe et al. (1994), Guth, Schmittberger and Schwarze (1982), Neelin, Sonnenschein and Spiegel (1988), and Siegel and Fouraker (1960) found no substantial differences in average behavior. Think of bargaining behavior as a simultaneous expression of a person's degree of self-interest (or oppositely, an expression of fairness or altruism) and a person's understanding of their bargaining power in a particular situation. In making alternating offers for division of a "pie" that shrinks with each rejected offer, for example, people may make nonequilibrium offers because they are not purely self-interested, or because they cannot compute the equilibrium offer. Incentives probably make little difference in these experiments because they do not substantially alter either the degree of self-interest or a subject's understanding. The game-theoretic solutions to these games are either so transparent (a "floor," in the case of ultimatum bargaining) or so difficult to figure out (a "ceiling" for sequen-

THE EFFECfS OF FINANCIAL INCENTIVES IN EXPERIMENTS

23

tial bargaining requiring backward induction) that only specific training will induce equilibrium offers (in the case of multi-stage bargaining).
Floor and ceiling effects are common in other tasks where incentives make little difference. For example, Kahneman, Peavler and Onuska (1968) studied pupil dilation and performance in a task where subjects heard four-digit strings, then repeated back the string, adding either 0 or 1 to each number. They found that pupils dilated more when incentives were higher-a sign that subjects were working harder-but there was no increase in accuracy because subjects got 88% right even with low incentives (i.e., performance was close to a ceiling at 100% accuracy). Samuelson and Bazerman (1985) found the opposite in a study of bids in a notoriously difficult "acquire-a-company" problem. Bidding for real money did not improve performance (but did raise the variance) because discovering the optimal bid is extremely difficult.
It is worth noting that in many experiments, financial incentives might appear to have little effect because subjects are intrinsically motivated to perform well, so money adds little extra motivation. When subjects volunteer, for instance, they surely self-select for high intrinsic motivation. In extrapolating results to nonvolunteer populations, like students who are essentially forced to participate for course credit or survey respondents approached in malls or called at home, one should be careful to generalize from the results of experiments in which subjects volunteer.
In many of the studies where incentives did not affect mean performance, added incentives did reduce variation (Grether, 1981, noticed this fact early on). For example, Fiorina and Plott (1978) studied five-person committees choosing a point in a two-dimensional policy space. Each subject earned an amount of money which depended on how close the committee's point was to the point they preferred. Subjects in the committees earned 1-5 cents (low incentive) or $1-3 (high incentive) for every unit that the committee's point was closer to their preferred point. High incentives did not change the mean deviation from the core point predicted by cooperative game theory very much, but did reduce variance around the core point dramatically. Similarly, Irwin et al. (in press) found that higher incentives in the Becker-DeGroot-Marschak method for eliciting valuations did not affect the mean value elicited, but did reduce the standard deviation by half.

When incentives affect behavior, but there is no performance standard
There are quite a few studies in which incentives do affect behavior, but there is no normative standard for optimal behavior so one cannot pass judgment on whether incentives "improved" performance per se. About half these studies involve choices among gambles. In three studies incentives had no effect on risk attitudes. When there was an effect, with one exception (Edwards, 1953), the effect of actually playing gambles was to make subjects more risk-averse (see also Weber, Shafir and Blais, 1998, for a meta-analysis with the same conclusion). In studies with "dictator games"-players dictate an allocation of a fixed sum between themselves and

24

CAMERER AND HOGARTH

another subject-subjects usually kept substantially more when choices were real rather than hypothetical. Finally, there are a large number of studies comparing hypothetical choices to buy everyday products with actual choices. Only one study is included in our sample (Cummings, Harrison and Rutstrom, 1995; but see Harrison and Rutstrom (in press) for a review of forty studies, mostly in environmental valuation). In their study, subjects were asked whether they would buy a juicer, chocolate, or a calculator. About three times as many subjects said they would buy, as actually did (31% vs. 9%). Overreporting purchase intention is quite familiar in marketing studies, and in political science (people overreport both intentions to vote, and whether they actually did vote).
A related example is probability matching in binary learning experiments. In these experiments, in each of many trials subjects bet on which of two lights (say, red or green) will light up. Suppose the red light comes on 60% of the time, and each trial is independent (though subjects usually don't know that). Then the profit-maximizing strategy is to always bet red, but subjects typically choose red between 60% and 100% of the time, roughly matching the relative frequency of choosing red with the probability of red. When incentives are raised, subjects move toward the profit-maximizing prediction, choosing red more often (Siegel, Siegel and Andrews, 1964; Castellan, 1969). This behavior can be explained by a model in which subjects find the task boring (it is!) and therefore get utility from varying their response, or get added utility from winning a bet on the less likely underdog color (green). As incentives are raised, subjects consume less variation and earn more profit, accepting some boredom in exchange for more money (see Smith and
Walker, 1993). In all these cases, we can interpret subjects as having some nonfinancial
goal-to appear risk-taking (gambles) or generous (dictator games), to please the experimenter by intending to buy something (purchase experiments), or avoid the boredom of making the same choice hundreds of times (probability matching)which is partially displaced by profit-maximization when incentives are increased. This kind of incentive effect is fundamentally different from the effect of incentives in inspiring greater effort, clearer thinking, and better performance.

When incentives are confounded with other treatments
Table 1 includes a few studies which confounded incentives with another treatment variable so that it is impossible to tell whether financial incentive, or the confounded variable, caused a change in performance. In some cases confounds are deliberate; for example, in exploratory designs on market experiments, investigators often adjust "exchange rates" for converting points to money, and confound those changes with simultaneous changes in parameters. Table 1 reports only cases where confounds appear to be unnoticed. We cannot draw conclusions from these studies, but we include them for completeness and to caution experimentalists who are interested in studying incentive effects about the need for proper control. For

THE EFFECI'S OF FINANCIAL INCENTIVES IN EXPERIMENTS

25

example, Wright and Aboull-Ezz (1988) had students judge probability distributions of GMAT scores, age, and starting salaries of recent MBAs. Students in the incentive condition were paid according to an incentive-compatible scoring rule. No-incentive subjects were not told about the scoring rule. The incentivized subjects did have lower absolute errors in probability than the no-incentive subjects (.04 vs. .07), but the difference could be due to the scoring rule rather than to financial incentives per se. (To break the confound, a control group which are given scoring-rule feedback about their judgments but not given any incentive for accuracy, and a control group which is incentivized but given no scoring rule, could be compared to the first two groups.)
In Kroll, Levy and Rapoport's (1988) study of portfolio allocation, increased incentives may have increased subjects' risk-aversion, which may explain why the high-incentive subjects chose portfolios which are closer to optimal. (The optimal portfolio contained a healthy proportion of the least risky asset.) This example is particularly disturbing because their study is prominently published and has been cited as evidence that higher incentives produce better performance.

What others have said
Our paper is closely related to four others. (Very interested readers should read all four.) Smith and Walker (1993) present a formal "labor-theoretic" framework, and argue from a sample of 31 studies that increased incentives tightens the distribution of errors around the theoretical optimum. While increased incentives do seem to reliably reduce variance, we argue that the effects of incentives are perhaps more complicated than that, and add capital and production (informally) to the central solo role that effort plays in their framework.
Many of our basic conclusions were arrived at independently by Bonner, Young and Hastie (1996), who conducted a more thorough review of a wider array of research. Their review classifies results according to five types of incentive schemes -flat rates (no performance-based incentive), piece rates, variable rates (stochastic piece rates), quota systems, and tournaments.
They find little systematic difference among these types of incentive. They find frequent positive effects in domains where little skill is required and effort improves performance-pain endurance, vigilance or detection (e.g., spotting typos), and clerical or production tasks. They find weaker evidence for positive effects in memory and judgment or choice tasks, and essentially no positive effects in problem-solving. Bonner, Young and Hastie also highlight the important role of skill (or capital, in our terms), calling it "the most important, yet neglected moderator of the effects of incentives on performance" (p. 40).
Hertwig and Ortmann (in press) include a small discussion of incentive effects in a paper contrasting experimental practices in economics and psychology (cf. Camerer, 1996). Their paper includes a census of available studies (10 in number) from 1987-97 of the Journal of Behavioral Decision Making, and uses a standard

26

CAMERER AND HOGARTH

meta-analytic measure of effect size (eta) to permit comparison across studies. They conclude that increased incentives almost always have a modest effect, and call for "learning more about the specific conditions under which payoffs improve, do not matter to, or impair task performance, and investigating how payoffs (and opportunity costs) affect decision strategies and information processing."
Jenkins et al. (1998) sampled all studies in several applied psychology journals from 1975-96 which reported detailed individual-level effects of monetary incentives (with control groups). They found 47 studies and combined the results in a formal meta-analysis. Forty-one studies measured the effect of increased pay on output ("performance quantity"), generally in mundane clerical tasks such as assembling erector sets or coding items. Most studies found significant increases in output from higher incentive. Only six studies measured the quality of performance, and the effects of increased incentive in those studies are quite weak. They also found that the level of intrinsic motivation in the task did not seem to affect the size of the incentive effect, and that simple laboratory studies understated incentive effects, relative to richer laboratory simulations or field studies.

Applying the capital-labor-production metaphor
The capital-labor-production metaphor points naturally to several features of cognitive capital and production requirements which, in turn, suggest interesting new classes of experiments. (By contrast, the pure labor theory suggests only that raising incentives may produce different distributions of errors.) We mention four categories: capital-labor substitution, capital formation, task design, and capital transfer.
Capital-labor substitution. Capital and labor are substitutes in most physical production processes. Similarly, cognitive capital and effortful thinking are productive substitutes in some tasks. An example is the stagecoach problem: Find the least-cost series of nodes which connect an initial node to a destination. People can solve problems in this class labor-intensively, by enumerating all possible paths and choosing the lowest-cost one. If they know the dynamic programming principle (i.e., they have that principle in their stock of cognitive capital) they can substitute capital for labor by working backward from the destination. A high level of capital and little labor will produce an answer as cheaply and accurately as a low level of capital and lots of labor.
A familiar, general example of capital substituting for labor is experience of subjects. Several studies compare the effects on performance of experience with financial incentives. For example, Jamal and Sunder (1991) find that both experience and financial incentive increase convergence to competitive equilibrium in experimental commodity markets, and experience has a more statistically reliable effect. Smith and Walker (1993) estimate that the effect of one session of experience on the convergence of first-price auction bids around the (risk-neutral)

THE EFFECI'S OF FINANCIAL INCENTIVES IN EXPERIMENTS

27

Nash bidding function is about the same as the effect of multiplying a base incentive by ten. Cooper et al. (in press) were the first to suggest (based on their observations) that higher pay may substitute for learning in games where learning effects are large. Notice that this insight cuts both ways: It implies that paying subjects more may enable experimenters to induce faster learning (or better thinking), speeding up the rate at which subjects master tasks and permitting more complex designs. But it also implies that even poorly-motivated subjects may learn to perform well with enough learning opportunity. In any case, a more thorough exploration of experience versus incentives, going beyond the bounds of this paper, would certainly be useful.
Another example of capital-labor substitution is the effect of giving contextual labels to subjects' choices. Contextual labels enable subjects to activate domainspecific heuristics or choice rules (e.g., Sniezek, 1986). For example, logic problems like the "Wason 4-card problem," which require subjects to recognize that P ~ 0 is logically equivalent to not-0 ~ not-P, are much easier for subjects when placed in a familiar, practical context (Cheng and Holyoak, 1985), particularly one which correspond to detection of cheating (Cosmides, 1985). In economics experiments, Eger and Dickhaut (1982) report that accounting students did substantially better in a probability judgment task (roughly equal to the improvement from higher incentive) when abstract labels were replaced with an accounting context. Cooper et al. (in press) did a study of signaling games with 'ratchet effects,' in which a productive firm manager who reports high output is penalized by having an output quota ratcheted upward in the future. Using Chinese subjects (some of whom were firm managers), they found that when contextual labels described the game actions as production, quotas, etc., subjects learned some features of the pooling equilibrium more rapidly. Natural labels are largely unexplored by experimental economists, mostly out of fear that natural language creates a non-monetary utility for making choices which loosens control over incentives (e.g., fewer subjects might choose "defect" in the prisoner's dilemma than would choose a strategy blandly labelled "D" or "strategy 2"). Natural labelling certainly does run this risk, but it might also enable subjects to use cognitive capital, reducing response error and speeding up learning.
Capital formation. The capital metaphor suggests that nonfinancial determinants of capital formation might be interesting to study. Three examples are between-session "learning," communication, and instruction.
Experimental economists suspect that something important occurs between experimental sessions: Subjects "digest" their experimental experience, perhaps talk to other subjects, and articulate what they did and saw to friends who did not participate. Much of this learning may be "implicit," meaning that subjects are learning things they are not aware of (which is a well-documented phenomenon in cognitive psychology, e.g., Reber, 1989). This capital formation takes place entirely outside the lab, and is therefore beyond the control and measurement of the experimenter, but some features of the process could be measured (e.g., by

28

CAMERER AND HOGARTH

unobtrusively observing or recording subjects as they discuss an experiment during a planned break between sessions).
In most experiments, communication is restricted on the grounds that it is unrealistic, may influence social values, or weakens control over a subject's information. But if learning from others (and from 'teaching' others) are ways of building capital, and one is interested in capital-labor determinants of performance, then communication becomes a particularly interesting variable. For example, allowing subjects to work in teams would, for some tasks, be an interesting treatment variable.
Experimental instructions are unquestionably an important influence on capital formation. Experimental economists usually try to write extremely simple and clear instructions as a kind of optimal task design (see below). In some cases, however, simply instructing people about decision rules-supplying capital-is one way to measure whether those rules are used instinctively. For example, Camerer et al. (1993) were interested in whether subjects used backward induction in bargaining. One way to answer this question is to instruct some subjects about backward induction and see whether they behave differently than uninstructed subjects. They do. The difference is evidence that the backward induction analytical device was not part of uninstructed subjects' 'capital' (but could be easily acquired through simple instruction).

Task design: tailoring production requirements to capital. Instructions typically describe the details of the mapping from a subjects' choices to her payoff, without suggesting preferable strategies, because the subjects' ability to discover optimal strategies is usually the focus of inquiry. But since instructions convey production requirements to subjects, they can also influence whether subjects are able to use their capital to produce effectively. Instructions are often written with something like this kind of task design in mind. Computer displays are designed so that important information is prominently displayed and visible (minimizing attention requirements) and history is retrievable from a menu (minimizing memory requirements). Subjects are sometimes given tables enabling them to compute mapping from actions to payoffs, to simplify calculations they may not be able to do perfectly. Many experimenters do such studies, fiddling with instructions until they are "clear." For example, Smith and Walker (1993) write:

In a new experimental situation, if the experimenter finds that decision error is biased enough to contradict the theory, then the first thing to question is the experimental instructions and procedures. Can they be simplified? (p. 10)

They write that simplifying instructions "may help to reduce decision cost." In our framework, instructions can convey production requirements more clearly, minimizing the additional capital needed to perform well.

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

29

Capital transfer. The usefulness of cognitive capital in different productive tasks is an important empirical question. Put in psychological terms, how well does training in one task transfer to another?
There are many reasons to think transfer is low. Just as carpenters, chefs, and golfers use many specialized tools rather than a few all-purpose ones, evidence from cognitive psychology suggests that a lot of knowledge comes in the form of memory for domain-specific facts or decision rules customized to situations (in cognitive science this is sometimes called "modularity"). Experts tend to have lots of knowledge about facts in some domain, but the rules they infer from those facts are not easily generalized (e.g., Camerer and Johnson, 1991). Chess experts, for examples, have large 'vocabularies' of positions from famous games, and know what move to play from each position, but the high-level rules they induce from their knowledge ("defend the center," "protect your king") do not generalize well to other domains.
More generally, there is little evidence that well-educated subjects perform experimental tasks much differently than less-educated ones (see Ball and Cech, 1996). In addition, subjects trained to use a heuristic which is optimal in problems with certain surface features often fail to apply the same heuristic when faced with new problems that are structurally-identical but have different surface features. For example, Kagel and Levin (1986) found that subjects gradually reduced their bids in repeated three-person common-value auctions, so they learned to mostly avoid the "winner's curse." Then the number of bidders was changed to six. If subjects had learned the structural reason for the winner's curse-choosing the highest bid tends to select the most optimistic common-value estimate-they would reduce their bids when the number of bidders rises, but instead they raised their bids. The data suggest that what subjects learned in the three-bidder case (their cognitive capital) was customized to that situation, and did not transfer well to the six-bidder case.
A final thought: Further research on the capital-labor theory would benefit greatly from having more types of data about decision processes than experimental economists usually collect. Smith and Walker (1993) articulate a bias against studying cognitive processes which many economists share:
One can think of z as the decision cost or effort (concentration, attention, thinking, monitoring, reporting, acting) which the subject applies to the task presented by the experimenter. Like quarks in particle physics we may have no direct measures ofz, but we look for traces of its effects on the choice of y ... by manipulation of the experimental procedures that affect z and thus y. [Emphasis ours]
We disagree because one can measure decision effort (z) more directly. Studies have done precisely this using looking-up patterns (Camerer et al. 1993), response times (Wilcox, 1993), measures of recall (which proxy for the amount of decision

30

CAMERER AND HOGARTII

effort expended in the first place), verbal protocols, pupil dilation (e.g., Kahneman and Peavler, 1969), heart rate or galvanic skin response (e.g., Dickhaut et al. 1997) and so forth.

IV. Stylized facts and provocative conjectures
The results compiled in Table 1 can be summarized as stylized facts or provocative conjectures.
1. Most studies do not show a clear improvement in mean performance. The most common result is no effect on mean performance (see also Bonner, Young and Hastie, 1996, Tables 3-4). Of course, the failure to find a significant performance effect of incentive may be due to low statistical power (which is difficult to judge without making power calculations for each study). Aggregating a series of insignificant effects in a proper meta-analysis adds power and could establish collective significance where simply counting studies, as we have done, would not.
Nonetheless, it is widely believed among economists-perhaps even more so among non-experimentalists-that paying subjects will necessarily increase their effort and their performance. The underpinning of this hypothesis was carefully articulated by Vernon Smith (1976), who wrote (p. 277):
... it is often possible in simple-task experiments to get satisfactory results without monetary rewards by using instructions to induce value by role-playing behavior (i.e., 'think of yourself as making a profit of such and such when ... ') .. but such game values are likely to be weak, erratic, and easily dominated by transactions costs, and subjects may be readily satiated with 'point' profits.
The last sentence summarizes the case against using hypothetical rewards, and in favor of using money: Money is thought to be stronger in force, more reliable, and less satiable than hypothetical rewards. The extent to which any given reward mediums-money, points, grades, public announcement of scores-have these features is an empirical question. Smith was convinced about the special motivational properties of money after observing double auctions which failed to converge sharply unless subjects were paid, especially for low-profit marginal trades (Smith, 1962). But the claim that nonfinancial rewards are weak and satiable in other tasks has not been as firmly established. It may be that in double auctions, which require substantial training sessions and many periods of stationary "Groundhog Day" replication, subjects tend to get especially tired or bored, and money keeps their attention from flagging better than other rewards. However, this is not a strong argument for always using money in tasks where fatigue and boredom are less likely to set in.

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

31

The faith economists have in financial incentives is important because it influences all stages of experimental methodology, reporting, citation, and debate. For example, a search of the American Economic Review from 1970-97 did not turn up a single published experimental study in which subjects were not paid according to performance. Authors believe that referees will automatically reject a study which uses only hypothetical-payment data (and the authors are probably correct!). Furthermore, seminar participants invariably criticize experimental evidence of violations of rationality principles by conjecturing that if enough incentive were offered the violations would disappear, ignorant of the fact that this conjecture has generally proved false. For example, Aumann (1990) wrote:
It is sometimes asserted that game theory is not "descriptive" of the "real world," that people don't really behave according to game-theoretic prescriptions. To back up such assertions, some workers have conducted experiments using poorly motivated subjects, subjects who do not understand what they are about and are paid off by pittances; as if such experiments represented the real world (p. xi).
This passage implies that subjects who are motivated by more than "pittances" will be described by game theory, even if lower-paid subjects do not. In fact, there is simply no laboratory evidence for this claim, and plenty of evidence against it.
Since our review shows that payment does not always matter, we suggest a revised three-part standard for judging results: Critics can insist that researchers use substantial incentives for tasks which have shown substantial incentive effects in previous studies; authors can argue for not using incentives if previous studies have established little effect; and in cases where previous studies are ambiguous, authors must run at least one real-payment condition. (The latter requirement would also add to the body of literature establishing incentive effects, which is hardly conclusive at this point.)
2. When incentives do affect peifonnance, they often reduce the variance of responses (see Smith and Walker, 1993). Incentives often reduce variance by reducing the number of extreme outliers, probably caused by thoughtless, unmotivated subjects. Lower variance is important for three reasons:
First, the fact that incentives lower variance might provide an important clue about how incentives affect attention and reasoning, and consequently performance.
Second, if incentives reduce variation in responses, they improve statistical power and help experimenters test predictions more effectively. Used for this purpose, increased incentive is simply a way of producing higher-quality data and doing better science {like buying purer chemicals or less reactive beakers to do better chemistry). Of course, other methods might work the same magic more cheaply. Trimmed means and robust statistical methods also reduce the influence of outliers. Higher-power tests (e.g., Forsythe et al., 1994), and power-optimized

32

CAMERER AND HOGARTH

experimental designs (El-Gamal and Palfrey, in press; MUller and Ponce De Leon, 1996), increase the quality of inferences drawn from noisy data. Experimenters who use incentives purely to reduce dispersion should adopt these other techniques as well.
Third, variance reduction can change group outcomes dramatically in some tasks, when aggregate behavior is especially sensitive to decisions by outlying individuals. Creative tasks (like R & D), in which discovery of a correct answer by one person implies a group discovery, order-statistic coordination games (e.g., Van Huyck, Battalio and Beil, 1990) and asset markets in which behavior depends sensitively on common knowledge of rationality (e.g., Smith, Suchanek and Williams 1988) are examples: One unusual person might cause the group to behave unusually. If high incentives reduce individual variance they may reduce variance in group behavior even more dramatically; in those cases incentives will have a particularly strong treatment effect which should probably not be ignored.
3. Incentive effects are comparable in magnitude to other kinds of treatment effects; and incentives may be substitutes for, or complements with, other treatments. The capital-labor-production theory emphasizes that while incentives do have effects, the effects are often comparable in magnitude to the effects of capital and production variables. In a striking example, Baker and Kirsch (1991) studied pain endurance of female students who held their hands in cold water for 4-8 minutes. In an incentive condition the subjects earned $2 for lasting four minutes and $1 for each additional minute of pain they could stand. In a coping condition they were instructed in how to deal with pain. Incentives did induce the students to withstand more pain, but learning to cope increased their pain endurance as well. Coping skill is a capital variable with a positive effect comparable to the effect of incentives.
Capital and task variables may also be substitutes or complements with incentives. For example, many experimenters suspect that experience is a substitute for incentive. For example, Jamal and Sunder (1991) found that incentives reduced the variance of prices in commodity double-auctions with inexperienced subjects, but had little effect with experienced subjects. A reasonable guess is that the effect on mean performance and reduced variance from one session of experimental experience is roughly equivalent to the effect of doubling or tripling incentives. Some studies show a more dramatic experience effect. Smith and Walker (1993) estimate that one session of experience reduces the dispersion of bids around a Nash equilibrium bidding function about as much as a twenty-fold increase in incentives. McKelvey and Ordeshook (1988) report experience effects which are about equal to the effect of a hundred-fold increase in incentive in Fiorina and Plott (1978). The substitutability of experience effects and incentive effects suggests that the implicit requirement in experimental economics that subjects be paid according to performance could be replaced with a requirement that experimenters who do not pay subjects performance incentives should at least report some data from experienced subjects (which many experimenters do anyway).

TiiE EFFECfS OF FINANCIAL INCENTIVES IN EXPERIMENTS

33

Feedback is likely to be a complement with incentives because it is hard to imagine that incentives alone, without feedback about the quality of previous decisions, would have much effect; and the effect of feedback is likely to be stronger in the presence of incentives.
Incentives may interact with treatments in other ways too. Awasthi and Pratt (1991) found that subjects of a certain kind (high in "perceptual differentiation," one measure of intelligence) reduced their error rate by half with higher incentives, while other subjects did not improve at all. Glucksberg (1962) found that incentives helped performance on easy problems but hurt performance on hard problems. Schwartz (1982) found that high incentives reduced performance only for subjects who had been pretrained (and, in his interpretation, had learned a 'stereotypical' response). Atkinson (1958) found that subjects performed better if they had a high measured "need for achievement" (a proxy for intrinsic motivation). Our point is not that these types of individual differences among people or among tasks should be the main focus of economics experiments. But economists who vary incentive conditions because they presume incentives are a highly predictive variable should also pay attention to task and personal variables.
4. In tasks with no performance standard, incentives seem to induce substitution away from socially desirable or pleasurable behavior. In tasks like allocation of money (dictator games), choosing among risky gambles, and perhaps others, it appears that subjects act more generously and risk-preferring when payments are hypothetical. If they behave this way because generosity and risk-taking are seen as socially desirable, and social desirability depends to some extent on subject-experimenter interaction, then incentives may be especially useful for minimizing these kinds of "demand effects" (cf. Hoffman, McCabe and Smith, 1996b). Also, if one is interested in differences among individuals (or groups) in social preference or risk-taking, then calibrating these "tastes" by varying incentive may be a particularly effective way to use incentives (e.g., Andreoni and Miller, 1997), and a different use than to induce careful thought.
We end this list with a provocative conjecture:
5. There is no replicated study in which a theory of rational choice was rejected at low
stakes in favor of a well-specified behavioral alternative, and accepted at high stakes. The complaint that subjects were insufficiently motivated often arises when a principle of rational choice-transitivity, dominance, game-theoretic equilibrium, or perhaps self-interest-appears to be violated in favor of an alternative, more psychologically plausible, hypothesis. Critics and referees very commonly assert that if the stakes were just high enough the rationality rejection would disappear. While several studies have tried to make rationality violations disappear-in utility theory paradoxes, ultimatum bargaining, and voting experiments-none have succeeded in clearly overturning anomalies.
Because the intellectual stakes are so high when interesting anomalies are discovered, a limited number of replications aimed at testing their robustness (to

34

CAMERER AND HOGAR1H

stakes, experience, etc.) are probably still worthwhile. However, since all established anomalies have survived these kinds of hostile attacks, uninformed critics should quit talking as if simply raising the stakes would make effects disappear. So far, that hasn't proved true; and nothing in any sensible understanding of human psychology suggests that it would.

V. Conclusion
We reviewed 74 experimental papers in which the level of financial performancebased incentive given to subjects was varied. Our primary interest is in advancing the simmering debate in experimental methodology about when subjects should be paid, and why.
The data show that incentives sometimes improve performance, but often don't. This unsurprising conclusion implies that we should immediately push beyond debating the caricatured positions that incentives always help or never help. Adopting either position, or pretending that others do, is empirically misguided and scientifically counterproductive. In our view, the data show that higher levels of incentives have the largest effects in judgment and decision tasks. Incentives improve performance in easy tasks that are effort-responsive, like judgment, prediction, problem-solving, recalling items from memory, or clerical tasks. Incentives sometimes hurt when problems are too difficult or when simple intuition or habit provides an optimal answer and thinking harder makes things worse. In games, auctions, and risky choices the most typical result is that incentives do not affect mean performance, but incentives often reduce variance in responses. In situations where there is no clear standard of performance, incentives often cause subjects to move away from favorable 'self-presentation' behavior toward more realistic choices. (For example, when they are actually paid, subjects who dictate allocations of money to others are less generous and subjects choosing among gambles take less risk.)
One way to comprehend these results is a "capital-labor-production theory" of cognition (extending Smith and Walker, 1993). The capital-labor-production framework assumes that the 'labor' or mental effort subjects exert depends upon their intrinsic motivation and financial incentives. But the effect of extra effort on performance also depends on their level of cognitive 'capital'-know-how, heuristics, analytical skills, previous experience in the task, and so forth-and its productive value for a specified task. Capital and labor can substitute: For example, a few experiments suggest that one session of experimental experience has an effect roughly comparable to (at least) tripling incentives.
Capital-labor-production theory provides a language for describing why incentives matter in some tasks but not in others. Tasks which are easy require little capital, so subjects can perform well with little motivation and paying extra will not help much. Tasks which are hard require too much capital (which cannot be formed in the short run of an experiment), so the effect of labor on performance

THE EFFECfS OF FINANCIAL INCENTIVES IN EXPERIMENTS

35

can be low (or negative). Obviously, spelling out the details of the capital-labor theory is a big project for another day. The main point is that to the extent incentive effects are worth studying, the effects of capital-relevant treatment variables are worth studying too.
An obvious direction for future research is to ask about these effects in natural settings, such as inside firms. Firms casually experiment with mixtures of incentive schemes all the time and often have an implicit theory about the interplay of incentive, human capital, and task demands. There is ample field evidence that incentives do alter behavior in ways predicted by theory, but there is less evidence that firms offer the contracts they are predicted to (see Prendergast, in press, for an authoritative review). The experimental data suggest that for easy or hard jobs, and intrinsically motivated workers, marginal changes in incentives will not improve performance much. However, for boring jobs, unmotivated workers, or tasks in which variance is bad, incentives are likely to have positive effects. Of course, these generalizations abstract from phenomena which are likely to loom larger in firms than in the lab-for example, social comparison among workers to the wages of others, dynamic "ratchet" effects in motivating effects of incentives, and so forth. Another lesson from the lab is that the effects of incentive on performance are comparable in magnitude (and often less than) the effects of experience, individual differences, task difficulty, and so on. Firms might improve performance by redesigning tasks to suit human capital as much as they can improve performance by raising incentives.
Our review also suggests some revisions to experimental method. Currently it is essentially impossible to report experimental research in economics journals if subjects have not been financially motivated. We think this prohibition should be replaced by a three-part standard: (i) Referees who would reject a paper purely on the grounds that subjects were not paid must cite a preponderance of previous literature establishing that incentives affect behavior meaningfully, in a task similar to that studied in the paper under consideration. (ii) Authors could defend the practice of collecting data from unpaid subjects by pointing to previous research showing that financial incentives did not matter in their task. (iii) For the many tasks where the data are mixed, authors should be encouraged (or perhaps required) to run different incentive conditions. (The latter requirement would build up a database of systematic observations rapidly-in a sense, it would spread the economic "tax" of finding out whether incentives do matter equally to all experimentalists.) These rules should help point the debate where it should head-away from differences in implicit models of subject behavior and towards data.
An open question is what results from the laboratory tell us about incentives in naturally-occurring environments (e.g., wages in firms, taxation and subsidy for public choices). Our view is that experiments measure only short-run effects, essentially holding capital fixed. The fact that incentives often do not induce different (or better) performance in the lab may understate the effect of incentives in natural settings, particularly if agents faced with incentive changes have a chance to build up capital-take classes, seek advice, or practice. In principle,

36

CAMERER AND HOGARTH

different sorts of experiments could be conducted in which subjects return repeatedly, or have a chance to invest in capital as part of their experimental choices, to allow for long-run effects, and experimenters interested in extrapolating to the outside world might consider running such experiments.
Finally, we cannot end a casual review of this sort without several caveats. Our sampling of studies and classification of incentive levels, and effects, should certainly be done more carefully. Besides the usual problems of meta-analysis, comparing incentive effects across different experiments would benefit from putting all incentives on a single scale (say, 1997 dollars per choice) and tying response rates to incentive levels, perhaps with some kind of general stochastic choice function.
There are many other questions about uses of financial incentives in experiments which our review does not address.
The lottery ticket procedure: There is some debate about whether paying subjects in functions of units of probability (the "binary lottery" procedure) induces controlled risk tastes reliably. The procedure should work in theory, if subjects reduce compound lotteries and maximize their chance of winning a fixed prize, but it does not work in practice (e.g., Selten et al., 1995), or at best, works only for the minority of subjects who obey reduction when directly tested (Prasnikar, 1998).
Losses: Because it is generally difficult to impose losses or punishments on subjects for bureaucratic reasons-university committees that approve protocols involving human subjects strongly object to it-we do not know how earning money and losing money differ.
Paying a fraction of subjects: Another question we cannot answer is whether paying one out of N subjects a larger stake, or paying subjects for one out of N high-stakes choices, provides as much incentive as paying a lower stake for each choice. Some of the studies we reviewed do use these random-payment schemes and it appears that these are roughly equivalent, at least for simple choices (paying one out of N may even be more motivating, if subjects overweigh their chances of being selected). However, more careful exploration would be useful.
Tournaments: Finally, some experimenters use "tournament" incentives in which the returns to performance are convex in performance or status-based (e.g., only the top few performers receive large prizes). In theory, tournament incentives should induce more status-seeking and risk-taking and hence, do not lead subjects to incentive-compatibly maximize expected profit (which is why economists generally eschew them). Whether tournaments actually do have those unintended effects has not been carefully investigated.

Acknowledgments
Very helpful comments were received from Baruch Fischhoff, Reid Hastie, John Kagel, Daniel Kahneman, George Loewenstein, Rob MacCoun, Chuck Manski, Richard Thaler, two anonymous referees, and many participants in the

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

37

NSF/Berkeley Econometrics Lab conference on elicitation of preferences,
July1August 1997. Angela Hung provided meticulous research assistance.

References
Andreoni, James and John H. Miller. (1997). "Giving According to GARP: An Experimental Study of Rationality and Altruism," University of Wisconsin Department of Economics Working Paper, October.
Arkes, Hal R., Robyn M. Dawes, and Caryn Christensen. (1986). "Factors Influencing the Use of a Decision Rule in a Probabilistic Task," Organizational Behavior and Human Decision Processes 37, 93-110.
Ashton, Robert H. (1990). "Pressure and Performance in Accounting Decision Settings: Paradoxical Effects of Incentives, Feedback, and Justification," Journal ofAccounting Research 28, 148-180.
Atkinson, John W. (1958). "Towards Experimental Analysis of Human Motivation in Terms of Motives, Expectancies, and Incentives." In John W. Atkinson (ed.), Motives in Fantasy, Action, and Society. New York: Van Nostrand.
Aumann, Robert. (1990). "Foreword." In Alvin E. Roth and Marilda A. Oliveira Sotomayor (ed.), Two-Sided Matching: A Study in Game-Theoretic Modeling and Analysis, p. xi. Cambridge, UK: Cambridge University Press.
Awasthi, Vidya and Jamie Pratt. (1990). "The Effects of Monetary Incentives on Effort and Decision Performance: the Role of Cognitive Characteristics," The Accounting Review 65, 797-811.
Bahrick, Harry P. (1954). "Incidental Learning under Incentive Conditions," Journal of Experimental Psychology 47, 170-172.
Baker, S. L. and I. Kirsch. (1991). "Cognitive Mediators of Pain Perception and Tolerance," Journal of Personality and Social Psychology, 61, 504-510.
Ball, Sheryl B. and Paula-Ann Cech. (1996). "Subject Pool Choice and Treatment Effects in Economic Laboratory Research." In R. Mark Isaac (ed.), Research in Experimental Economics Vol. 6, pp. 139-292. Greenwich, CT: JAI Press.
Battalio, Raymond C., John H. Kagel, and Komain Jiranyakul. (1990). "Testing between Alternative Models of Choice under Uncertainty," Journal of Risk and Uncertainty 3, 25-50.
Baumeister, Roy F. (1984). "Choking Under Pressure: Self Consciousness and Paradoxical Effects of Incentives on Skillful Performance," Journal of Personality and Social Psychology 46, 610-620.
Beattie, Jane and Graham Loomes. (1997). "The Impact of Incentives upon Risky Choice Experiments," Journal of Risk and Uncertainty 14, 155-168.
Binswinger, Hans P. (1980). "Attitudes Toward Risk: Experimental Measurement in Rural India," American Journal ofAgricultural Economics 62, 395-407.
Bohm, Peter. (1994). "Time Preference and Preference Reversal among Experienced Subjects: The Effects of Real Payments," The Economic Journal 104, 1370-1378.
Bolle, Friedel. (1990). "High Reward Experiments without High Expenditure for the Experimenter?" Journal of Economic Psychology 11, 157-167.
Bonner, Sarah E. S., Mark Young, and Reid Hastie. (1996). "Financial Incentives and Performance in Laboratory Tasks: The Effects of Task Type and Incentive Scheme Type," Unpublished manuscript, University of Southern California Department of Accounting.
Bull, Clive, Andrew Schetter, and Keith Weigelt. (1987). "Tournaments and Piece Rates: An Experimental Study," Journal of Political Economy 95, 1-33.
Camerer, Colin F. (1987). "Do Biases in Probability Judgment Matter in Markets? Experimental Evidence," American Economic Review 77, 981-997.
Camerer, Colin F. (1989). "An Experimental Test of Several Generalized Utility Theories," Journal of Risk and Uncertainty 2, 61-104.

38

CAMERER AND HOGARTH

Camerer, Colin F. (1990). "Behavioral Game Theory." In R. Hogarth (ed.), Insights in Decision Making: Theory and Applications. Chicago: University of Chicago Press, 1990, pp. 311-336.
Camerer, Colin F. (1996). "Rules for Experimenting in Psychology and Economics, and Why They Differ." In W. Guth and E. Van Damme (eds.), Essays in Honor of Reinhard Selten. New York: Springer-Verlag.
Camerer, Colin F. (1998). "Behavioral Economics and Nonrational Decision Making in Organizations." In J. Halpern and B. Sutton (eds.), Decision Making in Organizations. Ithaca, NY: Cornell University Press.
Camerer, Colin F. (in press). "Prospect Theory in the Wild: Evidence from the Field." In D. Kahneman and A. Tversky (eds.), Choices, Values, and Frames.
Camerer, Colin F. and Eric Johnson. (1991). "The Process-Performance Paradox in Expert Judgment: Why Do Experts Know So Much and Predict So Badly?" In A. Ericsson and J. Smith (eds.), Toward a General Theory ofExpertise: Prospects and Limits, pp. 195-217. Cambridge, UK: Cambridge University Press.
Camerer, Colin F., Eric Johnson, Talia Rymon, and Sankar Sen. (1993). "Cognition and Framing in Sequential Bargaining." In K. Binmore, A. Kirman, and P. Tani (eds.), Frontiers of Game Theory, Cambridge, MA: MIT Press.
Camerer, Colin F., Teck Ho, and Keith Weigelt. (1997). Unpublished data. Camerer, Colin F. and Keith Weigelt. (1988). "Experimental Tests of a Sequential Equilibrium
Reputation Model," Econometrica 56, 1-36. Castellan, N. John. (1969). "Effect of Change of Payoff in Probability Learning," Journal of Experimental
Psychology 79, 178-182. Cheng, Patricia and Keith Holyoak. (1985). "Pragmatic Reasoning Schemas," Cognitive Psychology 17,
391-416. Conlisk, John (1989). "Three Variants on the Allais Example." American Economic Review 79, 392-407. Cooper, David J., John H. Kagel, Wei Lo, and Qingliang Gu. (in press). "An Experimental Study of the
Ratchet Effect: The Impact of Incentives, Context, and Subject Sophistication on Behavior," American Economic Review. Cosmides, Leda. (1985). "The Logic of Social Exchange: Has Natural Selection Shaped How Humans Reason? Studies with the Wason Selection Task," Cognition 31, 187-276. Cox, James C. and David M. Grether. (1996). "The Preference Reversal Phenomenon: Response Mode, Markets, and Incentives," Economic Theory 7, 381-405. Craik, Fergus I. M. and Endel Tulving. (1975). "Depth of Processing and the Retention of Words in Episodic Memory," Journal of Experimental Psychology: General104, 268-294. Cubitt, Robin P, Chris Starmer, and Robert Sugden. (1998). "On the Validity of the Random Lottery Incentive System," Experimental Economics 1, 115-132. Cummings, Ronald G., Glenn W. Harrison, and E. Elisabet Rutstrom. (1995). "Homegrown Values and Hypothetical Surveys: Is the Dichotomous Choice Approach Incentive-Compatible?" American Economic Review 85, 260-266. Dawes, R. M., D. Faust and P. E. Meehl. (1989). "Clinical versus Actuarial Judgment," Science 243, 1668-1674. Dickhaut, John, Kip Smith, Kevin McCabe, Nicole Peck, and Vijay Rajan. (1997). "The Emotional and Mental Effort Dynamics of the English Auction," University of Minnesota Working Paper, Presented at ESA Meeting, September. Drago, Robert and John S. Heywood. (1989). "Tournaments, Piece Rates, and the Shape of Payoff Function," Journal of Political Economy 97, 992-998. Edwards, Ward. (1953). "Probability Preferences in Gambling," American Journal of Psychology 66, 349-364. Edwards, Ward. (1961). "Probability Learning in 1000 Trials," Journal of Experimental Psychology 62, 385-394. Eger, Carol and John Dickhaut. (1982). "An Examination of the Conservative Information Processing Bias in an Accounting Framework," Journal ofAccounting Research 20, 711-723.

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

39

Eisenberger, R. and J. Cameron. (1996). "Detrimental Effects of Rewards: Reality or Myth?" American Psychologist, 51, 1153-1166.
EI-Gamal, Mahmoud and Thomas R. Palfrey. (1996). "Economical Experiments: Bayesian Efficient Experimental Design." International Journal of Game Theory, 25, 476-495.
Ericsson, K. Anders and Jacqui Smith. (eds). (1991). Toward a General Theory of Expertise: Prospects and Limits. Cambridge, UK: Cambridge University Press.
Fehr, Ernst and Elena Tougareva. (1996). "Do High Monetary Stakes Remove Reciprocal Fairness? Experimental Evidence from Russia," University of Zurich Working Paper.
Fiorina, Morris P. and Charles R. Plott. (1978). "Committee Decisions under Majority Rule: An Experimental Study," American Political Science Review 72, 575-598.
Forsythe, Robert, Joel L. Horowitz, N. E. Savin, and Martin Sefton. (1994). "Fairness in Simple Bargaining Experiments," Games and Economic Behavior 6, 347-369.
Fouraker, Lawrence and Sidney Siegel. (1963). Bargaining and Group Decision Making. New York: McGraw-Hill.
Friedman, Daniel. (1998). "Monty Hall's Three Doors: Construction and Deconstruction of a Choice Anomaly," American Economic Review 88, 933-946.
Glucksburg, Sam. (1962). "The Influence of Strength and Drive on Functional Fixedness and Perceptual Recognition," Journal of Experimental Psychology 63, 36-41.
Grether, David. M. (1980). "Bayes' Rule as a Descriptive Model: The Representativeness Heuristic," Quarterly Journal of Economics 95, 537-557.
Grether, D. M. (1981). "Financial Incentive Effects and Individual Decision Making," California Institute of Technology Working Paper No. 401.
Grether, D. M. (1990). "Testing Bayes Rule and the Representativeness Heuristic: Some Experimental Evidence," Journal of Economic Behavior and Organization 17, 31-57.
Grether, David M. and Charles R. Plott. (1979). "Economic Theory of Choice and the Preference Reversal Phenomenon," American Economic Review 69, 623-638.
Giith, Werner, R. Schmittberger, and B. Schwarze. (1982). "An Experimental Analysis of Ultimatum Bargaining," Journal of Economic Behavior and Organization 3, 367-388.
Harless, David W. and Colin F. Camerer. (1994). "The Predictive Utility of Generalized Expected Utility Theories," Econometrica 62, 1251-1290.
Harrison, Glenn W. (1994). "Expected Utility Theory and the Experimentalists," Empirical Economics 19, 223-253.
Harrison, Glenn W. and E. Elisabet Rutstrom. Cin press). "Experimental Evidence of Hypothetical Bias in Value Elicitation Methods." In C. R. Plott and V. L. Smith (eds.), Handbook of Experimental Economics Results.
Hertwig, Ralph and Andreas Ortmann. (in press). "Experimental Practices in Economics: A Methodological Challenge for Psychologists," Behavioral and Brain Sciences.
Hey, John D. (1982). "Search for Rules of Search," Journal of Economic Behavior and Organization 3, 65-81.
Hey, John D. (1987). "Still Searching," Journal of Economic Behavior and Organization 8, 137-144. Hoffman, Elizabeth, Kevin McCabe, and Vernon Smith. (1996a). "On Expectations and Monetary
Stakes in Ultimatum Games," Internationa/Journal of Game Theory 25, 289-301. Hoffman, Elizabeth, Kevin McCabe, and Vernon L. Smith. (1996b). "Social Distance and Other-Re-
garding Behavior in Dictator Games," American Economic Review 86, 653-660. Hogarth, Robin M. and Hillel J. Einhorn. (1990). "Venture Theory: A Model of Decision Weights,"
Management Science 36, 780-803.
Hogarth, Robin M., Brian J. Gibbs, Craig R. M. McKenzie, and Margaret A. Marquis. (1991). "Learning from Feedback: Exactingness and Incentives," Journal of Experimental Psychology: Learning, Memory and Cognition 17, 734-752.
Irwin, Julie R., Gary H. McClelland, and William D. Schulze. (1992). "Hypothetical and Real Consequences in Experimental Auctions for Insurance against Low-Probability Risks," Journal of Behavioral Decision Making 5, 107-116.

40

CAMERER AND HOGARTH

!twin, Julie, Michael McKee, Gary McClelland, William Schulze, and Elizabeth Norden. (in press). "Payoff Dominance vs. Cognitive Transparency in Decision Making," Economic Inquiry.
Jamal, Karim and Shyam Sunder. (1991). "Money vs. Gaming: Effects of Salient Monetary Payments in Double Oral Auctions," Organizational Behavior and Human Decision Processes 49, 151-166.
Jenkins, G. Douglas, Jr., Atul Mitra, Nina Gupta, and Jason D. Shaw. (1998). "Are Financial Incentives Related to Performance? A Meta-Analytic Review of Empirical Research," Journal of Applied Psychology 83, 777-787.
Johannessen, Magnus, Bengt Liljas, and Per-Olov Johansson. (1998). "An Experimental Comparison of Dichotomous Choice Contingent Valuation Questions and Real Purchase Decisions," Applied Economics, 30, 643-647.
Kachelmeier, Steven J. and Mohamed Shehata. (1992). "Examining Risk Preferences under High Monetary Incentives: Experimental Evidence from the People's Republic of China," American Economic Review 82, 1120-1141.
Kagel, John H. and Dan Levin. (1986). "The Winner's Curse and Public Information in Common Value Auctions," American Economic Review 76, 894-920.
Kahneman, Daniel and W. Scott Peavler. (1969). "Incentive Effects and Pupillary Changes in Association Learning," Journal of Experimental Psychology 79, 312-318.
Kahneman, Daniel, W. Scott Peavler, and Linda Onuska. (1968). "Effects of Verbalization and Incentive on the Pupil Response to Mental Activity," Canadian Journal of Psychology 22, 186-196.
Kroll, Y., H. Levy, and A. Rapoport. (1988). "Experimental Tests of the Separation Theorem and the Capital Asset Pricing Model," American Economic Review 78, 500-519.
Kroll, Y., H. Levy, and A. Rapaport. (1988). "Experimental Tests of the Mean-Variance Model for Portfolio Selection," Organizational Behavior and Human Decision Processes 42, 388-410.
Lepper, Mark R., David Greene, and Richard E. Nisbett. (1973). "Undermining Childrens' Intrinsic Interest in with Extrinsic Reward: A Test of the 'Overjustification' Hypothesis," Journal of Personality and Social Psychology 28, 129-137.
Libby, Robert and Marlys G. Lipe. (1992). "Incentives, Effort, and the Cognitive Processes Involved in Accounting-Related Judgments," Journal ofAccounting Research 30, 249-273.
List, John A. and Jason F. Shogren. (1998). "The Deadweight Loss of Christmas: Comment," American Economic Review 88, 1350-1355.
Loomes, Graham and Caron Taylor. (1992). "Non-Transitive Preferences over Gains and Losses," Economic Journal 102, 357-365.
McGraw, Kenneth 0. and John C. McCullers. (1979). "Evidence of a Detrimental Effect of Extrinsic Incentives on Breaking a Mental Set," Journal of Experimental Social Psychology 15, 285-294.
McKelvey, Richard and Ordeshook, Peter. (1988) "A Decade of Experimental Research on Spatial Models of Elections and Committees." In M. J. Hinich and J. Enelow (eds.), Government, Democra9, and Social Choice. Cambridge, MA: Cambridge University Press.
McKelvey, Richard and Thomas Palfrey. (1992). "An Experimental Study of the Centipede Game," Econometrica 60, 803-836.
Merlo, Antonio and Andrew Schetter. (1999). "A Surprise-Quiz View of Learning in Economic Experiments," Games and Economic Behavior 28, 25-54.
Miller, Louise B. and Betsy W. Estes. (1961). "Monetary Reward and Motivation in Discrimination Learning," Journal of Experimental Psychology 61, 501-504.
Miiller, W. G. and A. M. C. Ponce de Leon. (1996). "Optimal Design of an Experiment in Economics," Economic Journal 106, 122-127.
Neelin, Janet [now Currie], Hugo Sonnenschein, and Matthew Spiegel. (1988). "A Further Test of Noncooperative Bargaining Theory: Comment," American Economic Review 78, 824-836.
Nilsson, Lars-Goran. (1987). "Motivated Memory: Dissociation between Performance Data and Subjective Reports," Psychological Research 49, 183-188.
Phillips, Lawrence D. and Ward Edwards. (1966). "Conservatism in a Simple Probability Inference Task," Journal of Experimental Psychology 72, 346-354.

THE EFFECTS OF FINANCIAL INCENTIVES IN EXPERIMENTS

41

Prasnikar, Vesna. (1998). "How Well Does Utility Maximization Approximate Subjects' Behavior? An Experimental Study," University of Pittsburgh Department of Economics, December.
Prendergast, Canice. (in press). "The Provision of Incentives in Firms," Journal of Economic Literature. Reber, Arthur S. (1989). "Implicit Learning and Tacit Knowledge," Journal of Experimental Psychology:
General118, 219-235. Riedel, James A., Delbert M. Nebeker, and Barrie L. Cooper. (1988). "The Influence of Monetary
Incentive on Goal Choice, Goal Commitment, and Task Performance," Organizational Behavior and Human Decision Processes 42, 155-180. Roth, Alvin E., Vesna Prasnikar, Masahiro Okuno-Fujiwara, and Shmuel Zamir. (1991). "Bargaining and Market Behavior in Jerusalem, Ljubljana, Pittsburgh and Tokyo: An Experimental Study," American Economic Review 81, 1068-1095. Salthouse, Timothy A., Janice D. Rogan, and Kenneth A. Prill. (1984). "Division of Attention: Age Differences on a Visually Presented Memory Task," Memory and Cognition 12, 613-620. Samuelson, William F. and Max H. Bazerman. (1985). "The Winner's Curse in Bilateral Negotiations," Research in Experimental Economics 3, 105-137. Schoemaker, Paul J. H. (1990). "Are Risk Attitudes Related across Domains and Response Modes?'' Management Science 36, 1451-1463. Schwartz, Barry. (1982). "Reinforcement-Induces Behavioral Stereotypy: How Not to Teach People to Discover Rules," Journal of Experimental Psychology: General111, 23-59. Scott, W. E., Jing-Lih Farh, and Philip M. Podsakoff. (1988). "The Effects of 'Intrinsic' and 'Extrinsic' Reinforcement Contingencies on Task Behavior," Organizational Behavior and Human Decision Processes 41, 405-425. Sefton, Martin. (1992). "Incentives in Simple Bargaining Games," Journal of Economic Psychology 13, 263-276. Selten, Reinhard, A. Sadrieh, and Klaus Abbink. (1995). "Money Does Not Induce Risk Neutral Behavior, but Binary Lotteries Do Even Worse," University of Bonn Working Paper No. B-343. Siegel, Sidney and Lawrence Fouraker. (1960). Bargaining and Group Decision Making: Experiments in Bilateral Monopoly. New York: McGraw-Hill. Siegel, Sidney, Alberta Siegel, and Julia Andrews. (1964). Choice, Strategy, and Utility. New York: McGraw-Hill.
Slonim, Robert and Alvin E. Roth. (1998). "Learning in High Stakes Ultimatum Games: An Experiment in the Slovak Republic," Econometrica, 65, 569-596.
Slovic, Paul. (1969). "Differential Effects of Real versus Hypothetical Payoffs on Choices among Gambles," Journal of Experimental Psychology 80, 434-437.
Slovic, Paul and Douglas MacPhillamy. (1974). "Dimensional Commensurability and Cue Utilization in Comparative Judgment," Organizational Behavior and Human Performance 11, 172-194.
Smith, Vernon L. (1962). "An Experimental Study of Competitive Market Behavior," Journal ofPolitical Economy 70, 111-137.
Smith, Vernon L. (1965). "Experimental Auction Markets and the Walrasian Hypothesis," Journal of Political Economy 387-393.
Smith, Vernon L. (1976). "Experimental Economics: Induced Value Theory," American Economic Review 66, 274-279.
Smith, Vernon L. (1991). "Experimental Economics: Behavioral Lessons for Microeconomic Theory and Policy," 1990 Nancy Schwartz Lecture, KGSM, Northwestern University.
Smith, Vernon L., Gerry Suchanek, and Arlington Williams. (1988). "Bubbles, Crashes, and Endogenous Expectations in Experimental Spot Asset Markets," Econometrica 56, 1119-1151.
Smith, Vernon L. and James M. Walker. (1993). "Rewards, Experience and Decision Costs in First Price Auctions," Economic Inquiry 31, 237-244.
Sniezek, Janet A. (1986). "The Role of Variable Labels in Cue Probability Learning Tasks," Organizational Behavior and Human Decision Processes 38, 141-161.

42

CAMERER AND HOGARTH

Straub, Paul G. and J. Keith Mumighan. (1995). "An Experimental Investigation of Ultimatum Games: Information, Fairness, Expectations, and Lowest Acceptable Offers," Journal of Economic Behavior and Organization 27, 345-364.
Tversky, Amos and Daniel Kahneman. (1992). "Advances in Prospect Theory: Cumulative Representation of Uncertainty," Journal of Risk and Uncertainty 5, 297-323.
Van Huyck, John, Raymond Battalio, and Richard Beil. (1990). "Tacit Coordination Games, Strategic Uncertainty, and Coordination Failure," American Economic Review 80, 234-248.
Wallsten, Thomas S., David V. Budescu, and Rami Zwick. (1993). "Comparing the Calibration and Coherence of Numerical and Verbal Probability Judgments," Management Science 39, 176-190.
Weber, Elke, Sharoni Shafir, and Ann-Renee Blais. (1998). "Predicting Risk-Sensitivity in Humans and Lower Animals: Risk as Variance or Coefficient of Variation," Ohio State University Department of Psychology Working Paper.
Weber, Martin, Graham Loomes, Hans-Jurgen Keppe, and Gabriela Meyer-Delius. (in press). "The Impact of Endowment Framing on Market Prices-An Experimental Analysis," Journal of Economic Behavior and Organization.
Wilcox, Nathaniel. (1993). "Lottery Choice: Incentives, Complexity, and Decision Time," Economic Journal103, 1397-1417.
Wright, William F. and Mohamed E. Aboul-Ezz. (1988). "Effects of Extrinsic Incentives on the Quality of Frequency Assessments," Organizational Behavior and Human Decision Processes 41, 143-152.
Wright, William F. and Urton Anderson. (1989). "Effects of Situation Familiarity and Financial Incentives on Use of the Anchoring and Adjustment Heuristic for Probability Assessment," Organizational Behavior and Human Decision Processes 44, 68-82.
Yerkes, R. M. and J. D. Dodson. (1908). "The Relation of Strength of Stimulus to Rapidity of Habit-Formation," Journal of Comparative and Neurological Psychology 18, 459-482.

Journal of Risk and Uncertainty, 19:1-3; 43-45 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Commentary on "The Effects of Financial Incentives in Experiments: A Review and Capital-Labor-Production Framework"

DAVID V. BUDESCU Department of Psychology, University of Illinois, Champaign, TL 61820

dbudescu@s.psych.uiuc.edu

The paper by Camerer and Hogarth deals with the effects of financial incentives on the experimental study of goal-oriented behavior. The paper consists of an informal assessment of 74 studies followed by a list of stylized facts and conclusions, that are interpreted by drawing an analogy with the economic theory of capitallabor-production.
Those involved in work with human subjects often face a variety of interrelated questions: Should subjects be paid? If, yes, how much? Is payment necessary andjor important? The "conventional" answers to these questions tend to vary across disciplines: Whereas most experimental economists consider payments necessary, many psychologists tend to avoid them (see also Dawes, 1999; Hertwig and Ortman, 1998; Lopes, 1994; Zwick, Erev and Budescu, 1999 on the differences between experimental practices in psychology and economics, and their sources). Camerer and Hogarth should be congratulated for summarizing empirical evidence across disciplinary boundaries and for trying to identify the circumstances under which financial incentives matter, and those aspects of behavior that are affected by these incentives. This paper complements nicely other recent reviews (listed in their paper) and its conclusions will, undoubtedly, be used to justify design decisions in many future experiments.
Unfortunately, but not surprisingly, the studies reviewed by Camerer and Hogarth do not provide a simple, clear and unequivocal answer to their original question. However, as is often the case with similar literature reviews, their paper suggests important and interesting new research directions. I will discuss briefly two, which I consider to be especially promising.
One of the most intriguing conclusions of the paper is that incentives are comparable to, and can substitute, or complement, other experimental factors. This is an important realization that could be used to develop a typology of cases where incentives are necessary, sufficient, marginally useful, or irrelevant to behavior. It is easy to imagine a research program in which a certain target behavior (say, forecasting future events, providing certainty equivalents to risky prospects, or

44

BUDESCU

playing a certain two-person game with a unique equilibrium against a given opponent, etc.) would be examined systematically under various levels of (a) experience (the number of replications of the task without any external feedback), (b) feedback (the frequency and detail of information provided to the subject about the outcome), and (c) incentives (the payoffs associated with the various outcomes). The precise role of the incentives could be inferred by comparing their effects on behavior, and the rate of change in behavior, at various levels of experience and feedback. It would be particularly useful to relate the marginal effect of the incentives to other characteristics of the task andjor the target behavior (e.g., presence or absence of contextual cues, existence of a single normative or rational solution, etc.). To my knowledge, such a systematic research project was never undertaken in any domain, but its promise and potential usefulness are obvious!
A, somewhat surprising, result of the review is that higher incentives do not necessarily have stronger effects, i.e., there is no monotonic relationship between the amount of money subjects are paid and their behavior. On the other hand, many studies without payoffs to subjects found systematic relations between the level of hypothetical outcomes and behavior. For example, MacCrimmon and Larsson (1979) documented a monotonic relation between the hypothetical outcomes and the rate of occurrence of Allais' paradox, and Hershey and Schoemaker (1980) reported a systematic relationship between hypothetical outcomes and the rate of preference reflection (across domains). This paradoxical pattern begs for further systematic investigation. In particular it would be informative to manipulate orthogonally the stated outcomes (in experimental units) and the conversion rates (of experimental units to $)while keeping the expected payoffs (in $) fixed, and determine the marginal, and joint, effects of the two factors.

Acknowledgments
Prepared with support from the National Science Foundation under Grant number SBR-96 32448.

References
Dawes, Robin M. (1999). "Experimental Demand, Clear Incentives, Both or Neither?" In David V. Budescu, Ido Erev and Rami Zwick (eds.), Games and Human Behavior: Essays in Honor of Amnon Rapoport. Hillsdale, NJ: Lawrence Earlbaum Associates.
Hershey, John K. and Paul J. H. Schoemaker. (1980). "Prospect Theory's Reflection Hypothesis: A Critical Examination," Organizational Behavior and Human Performance 25, 395-418.
Hertwig, Ralph and Andreas Ortman. (1998). "Experimental Practices in Economics: A Methodological Challenge for Psychologists," Unpublished manuscript: Max Planck Institute for Human Development, Berlin.

COMMENTARY

45

Lopes, Lola L. (1994). "Psychology and Economics: Perspectives on Risk, Cooperation and the Marketplace," Annual Review of Psychology 45, 197-227.
MacCrimmon, Kenneth R. and Stig Larsson. (1979). "Utility Theory: Axioms versus 'Paradoxes'." In Maurice Allais and Ole Hagen (eds.), Expected Utility and the Allais Paradox. Dordrecht: D. Reidel Publishing Company.
Zwick, Rami, Ido Erev, and David V. Budescu. (1999). "The Psychological and Economical Perspective on Human Decisions in Social and Interactive Contexts." In David V. Budescu, Ido Erev, and Rami Zwick (eds.), Games and Human Behavior: Essays in Honor of Amnon Rapoport. Hillsdale, NJ: Lawrence Earlbaum Associates.

Journal of Risk and Uncertainty, 19:1-3; 47-48 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Commentary on "The Effects of Financial Incentives in Experiments: A Review and CapitalLabor-Production Framework"

CA1HERINE ECKEL

eckelc@vt.edu

Department of Economics, Virginia Polytechnic Institute and State University, Blacksburg, VA 24061

Camerer and Hogarth have produced an insightful review of the thorny issue of financial incentives in experiments. It is much more than a survey, and proposes an intriguing capitaljlabor theory of decisions in experiments.
I decided to try out their theory on data from a recent experiment, where subjects participated in a series of tasks designed to elicit their risk preferences. (Details are in Eckel, Grossman and Lutz (1999).) Two of the tasks are identical except for the frame. In one, subjects must write down a certainty equivalent (the minimum selling price) for a series of gambles, one of which is a 90% chance of $10 and a 10% chance of $0. In another task, subjects choose an egg from twenty in a basket. Two of the eggs are "bad eggs," containing a green marble; the remaining 18 are "good eggs," containing a blue marble. Subjects are given the chance to sell back their egg for a price. Good eggs pay off $10, and bad eggs $0. Both gambles have an expected value of $9. According to C & H, this intellectually-engaging framing should lower the cost of effort, acting in much the same way as an increase in incentives. Experiments generally find that subjects are less risk-seeking (or more risk-averse) in treatments with higher stakes. (Unfortunately our design does not vary incentive levels directly.)
I find evidence that C & H are correct. The average certainty equivalent differs across the treatments: the abstract gamble produces an average value of $9.18, and the egg gamble an average value of $8.73 (significantly different at p = .03): subjects appear risk-seeking for the abstract gamble, but risk-averse over the eggs. This mimics the usual effect of increased incentives on reported risk preferences. We also collect data on the grade point average of the student subjects. GPA is only weakly related to the degree of risk-aversion, but has a more interesting effect. I examined the correlation between GPA and the deviation between the two certainty-equivalents, and calculated the following simple linear regression:

DEV = 2.70

.67 *GPA

(4.44) (3.15)

DEV is the absolute value of the deviation between the abstract and egg frames, and GPA is grade point average (!-statistics in parentheses). Thus a one point

48

ECKEL

increase in GPA is associated with a $.67 decrease in the difference between the two measures. This looks like the sort of increase in precision that increased incentives normally produce.
The implications for the conduct and evaluation of experimental research are many, and can be divided into design, procedure and analysis. C & H's capitaljlabor theory suggests that our experimental designs should manipulate and measure capital: manipulate experience and framing; collect information on intelligence and motivation. Any recruiting procedure selects some student subjects over others. Since volunteers and pseudo-volunteers (such as captive subjects in classrooms, or those required to participate for credit) differ in intrinsic motivation, they may perform differently. Phil Grossman and I find that students in an experiment held during a normal class period were markedly less responsive to incentives than real volunteers (Eckel and Grossman (1999)). Selection may be an important source of bias, especially if the experiment is intended to mimic the behavior of self-selected groups with particularly high motivation, such as "captains of industry." (A recent biography of J. P. Morgan himself argues that his motivation had little to do with financial incentives-see Strouse (1999).) Finally, analysis of experimental data should routinely include controls for measurable capital. Recent experimental work has seen lots of interest in traits or types of subjects (altruists, status-seekers, women), and C & H suggest that we add experience, intelligence and motivation to the list.
At present, experiments that are conducted with low or hypothetical payments are essentially unpublishable. I am convinced by C & H's analysis that this is too narrow a position to take, and may result in much potentially-valuable research going unread. While it is important to enforce the use of proper experimental procedure, it is time for experimental economists to adopt a more flexible approach such as that recommended by C & H, based on evidence about when and how payment affects experimental outcomes.

Acknowledgment
Funding for the experiments reported in this note was provided by a grant from the John D. and Catherine T. MacArthur Foundation.

References
Eckel, Catherine and Philip Grossman. (1999). "Volunteers and Pseudo-Volunteers," Unpublished manuscript, Department of Economics, Virginia Polytechnic Institute and State University.
Eckel, Catherine, Philip Grossman, and Nancy Lutz. (1999). "Risk Aversion, Risky Behavior, and Insurance," Department of Economics, Virginia Polytechnic Institute and State University.
Strouse, Jean. (1999). "The Unknown J.P. Morgan," The New Yorker, March 29, 66-79.

Journal of Risk and Uncertainty, 19:1-3; 49-65 (1999) © 1999 K!uwer Academic Publishers. Manufactured in The Netherlands.

Analysis of Choice Expectations in Incomplete Scenarios

CHARLES F. MANSKI

cfmanski@nwu.edu

Department of Economics and Institute for Policy Research, Northwestern University, 2003 Sheridan Road, Evanston, IL 60208

Abstract
This paper studies the use of probabilistic expectations data to predict behavior in incomplete scenarios posed by the researcher. The information that respondents have when replying to questions posing incomplete scenarios is a subset of the information that they would have in actual choice settings. Hence such questions do not elicit pure statements of preference; they elicit preferences mixed with expectations of future events that may affect choice behavior. The analysis developed here assumes respondents recognize that their behavior may depend on information they do not have when expectations are elicited, and that they answer coherently and honestly given the information provided. The objective in imagining such ideal respondents is to place a logical upper bound on the predictive content of elicited choice expectations.
Key words: hypothetical choice, intentions, revealed preference, scenarios
JEL Classification: D84, C42

Introduction
Revealed preference analysis and expected choice analysis offer two approaches to prediction of choice behavior. Revealed preference analysis yields predictions by combining observations of realized choices with assumptions about underlying decision processes. Expected choice analysis, which is sometimes called hypothetical or stated choice analysis, yields predictions by combining observations of elicited choice expectations with assumptions about underlying processes of expectations formation and communication.
The two approaches should be complementary, but different disciplines concerned with the prediction of choice behavior have emphasized one or another. Economists have largely embraced revealed preference analysis and rejected analysis of elicited choice expectations. Economics students are taught routinely that a good economist believes only what people do, not what they say. Psychologists, while not rejecting revealed preference analysis on principle, have largely used expected choice analysis in practice. Some of the history of these disciplinary differences is described in Manski (1990) and in Dominitz and Manski (1999).

50

MAN SKI

A longstanding concern of research in economic theory and in econometrics has been to illuminate the formal logic of revealed preference analysis. The logic of expected choice analysis has not received comparable attention, not by economists nor by psychologists. As a consequence, the practice of expected choice analysis has lacked the rigor and coherency characteristic of applied revealed preference analysis.
This paper continues the study of the logic of expected choice analysis begun in Manski (1990). There I examined the predictive power of unconditional intentions data (responses to questions asking for unconditional point predictions of future choices) under the "best-case" hypothesis that individuals have rational expectations and that their stated intentions are best point predictions of their future choice behavior. Even under this best-case hypothesis, stated intentions generally will not be perfect predictors of future behavior. Divergences between intentions and behavior may occur whenever behavior depends on events that are not yet realized when intentions are elicited but that will be realized before behavior is determined. I went on to show that intentions data obtained from a random sample of a population of interest do not identify the future population distribution of choices. At most, such data can bound the fraction of the population who will choose any action. Contrary to a common assertion in the literature analyzing intentions, individual-level divergences between stated intentions and subsequent behavior generally do not "average-out" in the aggregate.
Whereas my earlier work examined the use of intentions data to predict unconditional choice behavior, here I study the use of probabilistic expectations data to predict behavior in scenarios posed by the researcher. To illustrate the distinctions, consider these questions eliciting fertility expectations:
Looking ahead, do you expect to have any (more) children? (Response ="yes" or "no")
Looking ahead, what is the percent chance that you will have any (more) children?
(Response = 0 to 100) Suppose that the government were to enact a child-allowance program providing women with fifty dollars per month for each dependent child. If this program were in effect, what is the percent chance that you would have any (more) children?
(Response = 0 to 100)
The first question, which has appeared in the June fertility supplement to the Current Population Survey, calls for a statement of fertility intentions. The second question calls for an unconditional probabilistic prediction of future fertility. The third question specifies a scenario and calls for a probabilistic prediction of future fertility in that scenario.
In common with my earlier work, my concern here is with the way in which incomplete information distinguishes elicited expectations from actual choices. Researchers asking expected choice questions generally pose incomplete scenarios

ANALYSIS OF CHOICE EXPECfATIONS IN INCOMPLETE SCENARIOS

51

to respondents. The information that respondents have is generally a subset of the information that they would have in actual choice settings. As a consequence, expected choice questions generally do not elicit pure statements of preference from respondents. They elicit respondents' preferences mixed with their expectations of future events that may affect choice behavior.
In order to focus on the informational aspects of expected choice analysis while abstracting from other issues, I find it useful to perform a "best-case" analysis in the spirit of my earlier work. I suppose that respondents are cooperative persons who recognize that their behavior may depend on information they do not have when their expectations are elicited. When asked for their choice expectations, they respond as coherently and honestly as possible given the information available.
As in my earlier work, my objective in imagining such ideal respondents is to place a logical upper bound on the predictive content of expectations data. Of course this bound may not be realized in practice. Real respondents may not fully cooperate with researchers or they may have cognitive biases that further reduce the predictive power of expectations data. Psychologists concerned with cognitive biases and economists concerned with strategic respondent-researcher interactions should nevertheless find the analysis of this paper to be useful. As I see it, fruitful empirical analysis of cognitive biases and strategic interactions cannot begin without a clear understanding of the informational problems that confront even coherent and cooperative respondents when their expectations are elicited.
The ideas developed here may be particularly useful to psychologists studying the manner in which persons interpret, or construe, questions posed to them. In their article on construal in this issue, Fischhoff, Welch, and Frederick (1999) write "If needed detail is missing, then people may make it up." To shed light on how people make up needed detail in practice, they deconstruct the responses given by actual respondents to specific questions that pose incomplete scenarios. I think that study of the construal problems confronting ideal respondents provides a constructive starting point for empirical study of actual construal processes.
Section 1 develops basic concepts of empirical choice analysis-individual choice functions, scenarios, and population choice probabilities-that enable formal study of the revealed preference and expected choice approaches to prediction. I expect that economists and decision theorists reading this article will find my symbolic representation of these concepts to be easily accessible if not entirely familiar. The same holds for psychologists schooled in the mathematical psychology literature on probabilistic choice analysis (e.g., Luce, 1959; Luce and Suppes, 1965; Tversky, 1972). Some readers may find my insistence on formalization uncomfortable and may question its necessity. To these I say that I do find formalization necessary, first to state and then to analyze the subtle informational problems that arise when choice expectations in incomplete scenarios are elicited.
Section 2 uses the concepts introduced in Section 1 to examine the situation of a researcher who poses an incomplete scenario and wants to predict the choice behavior that would occur if a scenario having the described features were to be

52

MAN SKI

realized. The researcher may pose an unspecified scenario, in which case the respondent should give an unconditional prediction of his or her choice behavior, or the researcher may specify some aspects of the scenario. In the latter case, there is a qualitative difference between questions that pose feasible scenarios and ones that pose counterfactual scenarios. Bayesian decision theory proposes how a coherent and cooperative respondent should reply to questions posing feasible scenarios, but does not suggest how a respondent should reply when counterfactuals are posed.
Section 3 examines the situation of a researcher who poses an incomplete scenario and wants to use the elicited choice expectations to predict choice behavior in scenarios with other features. These are extrapolation problems and, as is always the case with extrapolation, the predictions that can be made depend critically on the prior information that the researcher can bring to bear. I find that expected choice data can be used to extrapolate choice behavior if the researcher is able to maintain assumptions akin to those routinely imposed in econometric revealed preference analysis. In particular, I give conditions which enable binary probit and maximum score analysis of expected choice data.
Section 4 gives conclusions.

1. Basic concepts of empirical choice analysis
Section 1.1 introduces a set of primitives and derived constructs that enable formal study of the revealed preference and expected choice approaches to prediction. Section 1.2 characterizes econometric revealed preference analysis in terms of these concepts. Section 1.3 does the same for the traditional form of expected choice analysis eliciting point predictions.

1.1. Individual choice functions, scenarios, and population choice probabilities
The primitives of our analysis are a space of potential choice sets, a space of potential environments, and a population of decision makers. Associated with each member of the population is a choice function (or decision rule) specifying the action the person would select if he or she were to face any choice set in any environment. Each person also has some observable covariates.
A scenario is a function assigning a choice set and environment to each member of the population. If a specified scenario were to be realized, each person would apply his or her choice function to select some feasible action. The frequency with which members of the population choose a given action is the population choice probability for this action in the specified scenario. The researcher's objective is to determine population choice probabilities in scenarios of interest. What makes achievement of this objective problematic is that the researcher does not observe the choice functions of the members of the population.

ANALYSIS OF CHOICE EXPECfATIONS IN INCOMPLETE SCENARIOS

53

Formally, let A denote a universe of actions and let r be the space of non-empty subsets of A. Each element of r is a potential choice set. For
simplicity, I suppose that A has at most countably many elements. Hence choice
sets are at most countable. Let E denote the space of potential environments. It will not be necessary to
describe environments explicitly, but I do suppose that a person facing choice set
c r E in environment e E E has no choice-relevant information other than
knowledge of (C, e). A person can act only on the information available to him. Hence choice functions have domain f X E.
Let J denote the population of decision makers. Each person j E J has a choice
function yl, · ): r x E--) A and covariates xi EX. The choice function specifies
the action that person j would select if this person were to face any choice set in
any environment. Chosen actions must be feasible; hence, given any (C, e) E r X
E, y/C, e) must be an element of C. I assume that when expectations are elicited, the researcher and person j both know the value of xi. I assume that person j knows his or her choice function yi (·,·),but the researcher does not. See Section 2 for further discussion of this assumption.
A scenario s (·): J --) r X E is a function assigning a potential choice set and
environment to each member of the population. Let si = s(j) denote the choice set
and environment faced by person j in scenario s(-). Then the action that j would choose in this scenario is yi (si).
The researcher's objective is to predict behavior in scenarios of interest. It is
standard to describe the population as a measure space (1, !l, P), with P a
probability measure. This enables population choice probabilities to be defined. Given any action i E A, the population choice probability for i in scenario sO is the fraction of the population who would select i. This is

P[y(s) =i] =P[jEJ:yi(sJ =i],

(1)

assuming that this set of population members is measurable. Thus the researcher's objective is to learn P[y(s) = i]. The researcher also may want to predict the behavior of persons with given covariates x. Then the objective is to learn
population conditional choice probabilities of the form P[y(s) = i I x].
The problem of predicting choice behavior may usefully be viewed as a problem of predicting treatment response, as posed in Manski (1995, 1997) and elsewhere. In the language of the literature on treatment response, scenario s(·) is a treatment policy or program and si is the treatment received by person j under this policy. A choice function is a response function giving the outcome (here a chosen action) that a person would experience if this person were to receive any specified treatment (here a choice set and environment). The researcher's objective is to learn the population distribution of outcomes that would occur if a treatment
policy of interest were in effect. Henceforth, I use the word treatment as a
shorthand for the longer expression (choice set, environment).

54

MAN SKI

1.2. Econometric revealed preference analysis
Prediction of population choices in specified scenarios would be straightforward if the researcher were able to observe the choice functions of the members of the population. The revealed preference approach to prediction begins from the premise that, although entire choice functions are not observable, particular points on choice functions may be observable. The literature in economic theory supposes that a given person may be observed to make choices in multiple realized scenarios. The objective is to predict that person's behavior in other scenarios (e.g., Mriat, 1967; Varian, 1982). The main body of work in econometrics supposes that each member of the population may be observed to make a choice in one realized scenario. The objective is to predict the population distribution of choices in other scenarios (e.g., McFadden, 1973; Manski, 1988). I shall describe only the econometric setup here.
Let z(·): J--+ r X E denote the realized scenario. Econometric revealed prefer-
ence analysis supposes that the researcher can observe the (covariate, realized treatment, realized choice) triple [xi, zi, yi (zi)] for each member of the population, or at least for a random sample thereof. Hence the researcher can learn empirically the population distribution P[x, z, y(z)] of covariates, realized treatments, and realized choices.
The available choice data reveal the population choice probabilities P[y(z) =
i Ix] in the realized scenario but do not identify choice probabilities in other scenarios. The latent population choice probabilities P[y(s) = i Ix], s i= z can be
identified if the available choice data are combined with assumptions restricting the population distribution of choice functions and realized treatments. The econometric literature on random utility models, for example, assumes that choice functions are utility maximizing rules. Researchers applying random utility models commonly assume that realized treatments are statistically independent of utility functions, conditional on x. That is, treatment assignment is assumed to be exogenous or ignorable.

1.3. Elicitation ofpoint predictions of choices
Traditional expected choice analysis extends the analysis of intentions data from unconditional point prediction of choice to point prediction in specified scenarios. One poses a scenario to the members of the population, or at least to a random sample thereof, and elicits predictions of the choices they would make. An idealized expected choice question may seek a yesjno response to a question of this form:
Ql. In scenario s(·), would you choose action i?
or, perhaps, a response to the question "In scenario sO, what action would you
choose?" Responses are commonly interpreted as identifying the choices that

ANALYSIS OF CHOICE EXPECTATIONS IN INCOMPLETE SCENARIOS

55

respondents would make if scenario s(·) were to be realized. The fraction of the population stating that they would choose action i is interpreted as the population choice probability for this action in the scenario posed.
Formally, let hsji be person j's response to question Q1, with hsji = 1 indicating a "yes" response and hsji = 0 a "no" response. Assume that elicited choice expectations coincide with the actual choices that respondents would make if the posed scenario were to be realized. That is,
(2)

Then

P[y(s) =ilx] =P(hs;= 1lx)

(3)

for each i E A and x E X. So choice probabilities in scenario s(·) are identified. Various researchers have used expected choice data in place of, or in combina-
tion with, realized choice data to estimate random utility models. See, for example, Beggs, Cardell, and Hausman (1981), Fischer and Nagin (1981), Louviere and Woodworth (1983), Manski and Salomon (1987), and Ben-Akiva and Morikawa (1990). Such pseudo revealed preference analysis is well-grounded if assumption (2) holds but not otherwise.
The remainder of this paper concerns situations in which the researcher eliciting expectations does not provide to person j all of the information about treatment s1 that this person would have in an actual choice setting. Hence assumption (2J generally cannot hold.

2. Elicitation of probabilistic choice expectations in incomplete scenarios
In Section 1, a scenario s(·) was defined to be a function s(·): J ~ r X E assigning
a (choice set, environment) treatment to each member of the population. Let S(-) now denote a collection of scenarios. I use the term incomplete scenario to mean a collection of scenarios, each s(·) E S(·) sharing some common features.
Researchers eliciting choice expectations inevitably find it impractical to fully describe scenarios of interest to respondents. Researchers posing expected choice questions do not ask questions of the form Q1 but rather of the form
Q2. In incomplete scenario S(-), would you choose action i?
Consider, for example, voter surveys conducted in the United States early in the presidential primary campaign, before the major party nominees have been selected. Respondents may be asked a question of the form:
Suppose that persons A and B will be the presidential nominees of the Democratic and Republican Parties. Would you vote for person B in the upcoming election?

56

MAN SKI

This question does not specify the minor party candidates who will be on the ballot and, hence, does not fully describe the voting choices that respondents will have available. Nor does the question specify the economic and political environment in which the election will take place. In these and other respects, the question only partly describes an election scenario.1
Incomplete specification of scenarios creates logical problems for survey respondents and for researchers seeking to predict choice behavior. Respondents, whose choice functions are defined on the space of treatments, must somehow predict their behavior given only partial information about what treatments they will receive. Researchers must not only interpret the responses they receive but must redefine their inferential objectives.
In Section 1, I took the researcher's objective to be inference on population
choice probabilities of the form P[y(s) = i I x]. This objective is not well-defined
when a researcher poses an incomplete scenario. An objective that is well-defined is prediction of choice behavior conditional on the event that a scenario in S(·) will be realized. As in the earlier discussion of econometric revealed preference analysis, let the to-be-realized scenario be denoted z( ·). Then the population
choice probabilities of interest now have the form P[y(z) = i I x, z(·) E S(-)].
Sections 2.1 through 2.3 consider three types of incomplete scenario. In Section 2.1 the researcher leaves the scenario entirely unspecified, so respondents are asked to make unconditional predictions of their behavior. In Section 2.2 the researcher partially specifies a future scenario that possibly could occur. In Section 2.3, the researcher partially specifies a counterfactual scenario, one that conflicts with information that respondents have at the time of the survey.
The analysis below maintains certain assumptions about the information that respondents and the researcher have when expectations are elicited. When their expectations are elicited, respondents may not yet know the treatments they will realize. I assume that each respondent j expresses his or her beliefs about z(·) in the form of a subjective probability distribution, denoted Qj.
I assume that respondents do know their choice functions when their expectations are elicited. This assumption follows practices in the econometric literature on dynamic choice analysis under uncertainty, which supposes the existence of decision makers who always know their utility functions but may not, at a given point in time, yet know the choice sets and environments that they will later face. A different assumption is maintained in the psychological literature on random utility models, which hypothesizes that each person carries a distribution of choice functions from which one is drawn at random when a choice must be made. Under this hypothesis, a respondent would not know his or her own choice function when expectations are elicited. The respondent would at most know the distribution from which a choice function will later be drawn.
The analysis below assumes that the researcher has no prior information about either the distribution of response functions or the process generating realized treatments. Hence, to predict future choice behavior, the researcher must rely fully

ANALYSIS OF CHOICE EXPECTATIONS IN INCOMPLETE SCENARIOS

57

on the choice expectations elicited from respondents. This assumption will be modified in Section 3.
Throughout Sections 2 and 3, I assume that the researcher poses one expected choice question and observes the responses of all members of the population of interest, or at least those of a random sample of this population. The researcher does not observe any realized choices that would enable revealed preference analysis, nor does the researcher observe the responses to multiple expected choice questions that pose different scenarios. A researcher able to combine responses to multiple expected choice questions, or able to combine responses to expected choice questions with data on realized choices, may be able to learn more about respondents' behavior than is possible with the data assumed available here.

2.1. The unspecified scenario
The extreme form of an incomplete scenario is one that is entirely unspecified. Here S(·) is the set of all logically possible scenarios and question 02 takes the form
03. Will you choose action i?
An example is the CPS fertility question stated in the Introduction:
Looking ahead, do you expect to have any (more) children?
Responses are unconditional intentions statements. How might a person respond coherently and cooperatively to a question of the
form 03? In Manski (1990), I proposed that the person would respond as would a Bayesian decision theorist asked to make a best unconditional point prediction of a future event. The researcher having specified no scenario, the respondent would interpret the researcher as inquiring about behavior in the to-be-realized scenario z(·). The respondent would use his or her subjective scenario distribution Qj to form a subjective choice probability for action i, namely
( 4)
Required to make a point prediction, the respondent would associate losses with each of the two possible prediction errors (intention =yes, choice = no) and (intention = no, choice = yes). The respondent would state (intention = yes) if
q/i) > Ilj, where the threshold Ilj depends on the relative magnitudes of the
losses that j associates with the two prediction errors. I went on to suggest that unconditional intentions questions can be improved
upon by asking respondents for their subjective choice probabilities. Whereas intentions questions seek point predictions of choice, the researcher might instead pose probabilistic questions of the form:

58

MANSKI

04. What is the percent chance you will choose action i?

A cooperative Bayesian respondent would respond with %{i). This response is necessarily at least as informative as is an intentions statement, which uses the unobserved threshold llj and the many-to-one function "(intention = yes) if %{i)
> ll/' to map qii) into a binary response.2
Suppose that respondents faithfully report their subjective choice probabilities when asked question 04. The assumed objective of the researcher who posed this question is to learn the population choice probability P[y(z) = i]. What do the responses reveal about P[y(z) = i]?
This bottom line question has a thoroughly optimistic answer if respondents have rational expectations and if realized treatments are statistically independent across the population. Formally, the rational expectations assumption is that all respondents have a common subjective scenario distribution Q and that z(·) is a realization from Q. The statistical independence assumption is that Q has the prOdUCt form Q[z(·)] = njEJQ(zj)·
Let these assumptions hold and suppose that N survey respondents numbered n = 1, ... , N are drawn as a random sample of the population. Rational expectations implies that the subjective choice probability that respondent n reports for action i coincides with the objective probability that this respondent will realize a treatment implying choice of i. Statistical independence makes the law of large numbers applicable. Hence the sample average of the elicited subjective choice probabilities is a consistent estimate of the population choice probability. That is, letting N - oo,

p

- P[y(z) = i].

(5)

The bottom line question continues to have an optimistic answer under some departures from the assumptions of rational expectations and statistical independence. Suppose that respondents may not have rational expectations but that their subjective choice probabilities for action i are unbiased estimates of their objective probabilities of choosing this action. Suppose that the subjective probability estimates are at most weakly dependent across the population, so that the left side of (5) continues to have a probability limit as N - oo. Also suppose that realized treatments are at most weakly dependent across the population. Then equation (5) continues to hold.
Of course the question has more pessimistic answers under other assumptions. Equation (5) does not generally hold if respondents are systematically misinformed about the process generating realized treatments, so that their subjective choice probabilities are biased estimates of objective choice probabilities. Nor does it generally hold if aggregate shocks make realized treatments strongly dependent across the population. Thus, (5) need not hold in the election polling example, where the political and economic environment at the time of the election is a common event affecting the choice behavior of all voters.

ANALYSIS OF CHOICE EXPECTATIONS IN INCOMPLETE SCENARIOS

59

2.2. Feasible incomplete scenarios
I next consider incomplete scenarios that are subjectively feasible and effectively proper subsets of the set of all logically possible scenarios. Let S(·) be an
incomplete scenario and, for each person j E J, let Sj = [s(j), sO E SO] be the
set of treatments that j might receive under S(·). I say that S(·) is feasible if, for almost every person j E J, SO is on the support of the subjective scenario distribution Qj. The expression effectively proper means that a non-negligible part of the population places subjective probability less than one on realizing a scenario in S(·). Thus
(6)
Without assumption (6), there would be no effective difference between SO and the unspecified scenario discussed earlier.
Suppose that the researcher poses the probabilistic question:
05. In incomplete scenario SO, what is the percent chance you would choose action i?
How would a coherent and cooperative person respond? If S(·) is feasible, person j might reasonably think in decision theoretic terms
that the researcher is providing information about the to-be-realized scenario and is asking him or her to predict the to-be-realized choice y/zj) conditional on this information. Thus person j might reasonably respond with the conditional, or posterior, subjective choice probability
(7)
Supposing that the researcher who posed question 05 does in fact want to learn the population conditional choice probability P[y(z) = i I zO E SO], the discussion in Section 2.1 remains relevant. If respondents have rational expectations and realized treatments are statistically independent across the population, the sample average of the responses to question 05 provides the researcher with a consistent
estimate of P[y(z) = i I z(·) E S(·)]. Some weakening of these assumptions leaves
this conclusion intact, but aggregate shocks and systematic departures from rational expectations generally render it invalid.

2.3. Counterfactual incomplete scenarios
An incomplete scenario S(·) is subjectively counterfactual if S(·) is not feasible. That is, SO is off the support of Qj for some non-negligible set of respondents j.
A simple example of a counterfactual may be obtained by modifying the third fertility question posed in the Introduction. That question posed a presumably feasible incomplete scenario, stating

60

MANSKI

Suppose that the government were to enact a child-allowance program providing women with fifty dollars per month for each dependent child.
Consider instead the premise
Suppose that a child-allowance program providing women with fifty dollars per month for each dependent child has been and will continue to be in effect.
In a world with no existing such program, this is a counterfactual.
The reasoning of Section 2.2 about response to question 05 breaks down when
SO is counterfactual. The conditional subjective choice probability qj[i ISO] given
in equation (7) is well-defined only if SO is on the support of Qj. Bayesian decision theory does not suggest how a person should form a posterior subjective probability when the conditioning event has no chance of occurring under the person's prior.
A formal resolution of this problem is to suppose that respondents have lexicographic subjective probability systems, as proposed by Blume, Brandenburger, and Dekel (1991). Lexicographic subjective probability systems extend Bayesian decision theory by assuming that persons place second-order subjective probability measures on sets of events that have zero ordinary (i.e, first-order) subjective probability, third-order probability measures on sets of events that have zero second-order probability, and so on. Given an incomplete counterfactual scenario, a respondent with lexicographic subjective probabilities on treatments might reply with second-order subjective choice probabilities. Correspondingly, the researcher might define second-order rational expectations to mean that all respondents have a common second-order scenario distribution and that, in the counterfactual world, the realized scenario would be drawn from this distribution.
Assuming that respondents have lexicographic subjective probability systems suggests how respondents might coherently reply to question QS, but does not explain how respondents might form their higher order subjective probability distributions. Construction of a higher order subjective distribution seems to require that the respondent consider how the counterfactual world came to be. Whereas questions posing feasible incomplete scenarios only ask the respondent to speculate on the future, questions posing counterfactual scenarios ask the respondent to also speculate on a hypothetical past that is inconsistent with some aspect of the actual past. For now, it is not clear to me how an ideal respondent would logically go about this task.

3. Extrapolation to other scenarios
3.1. General considerations
In Section 2, I supposed that an incomplete scenario SO has been posed and I asked what probabilistic choice expectations elicited from coherent and coopera-

ANALYSIS OF CHOICE EXPECfATIONS IN INCOMPLETE SCENARIOS

61

tive respondents might reveal about choice behavior conditional on the event that
a scenario in SO is realized. In this section I ask what the elicited expectations
might reveal about choice behavior in a different incomplete scenario, say S'(·).
Thus the population choice probabilities of interest now are P[y(z) = i I x,z (-) E
S'(·)].
Extrapolating choice behavior is the raison d'etre of econometric revealed preference analysis, which uses empirical observation of choices in the realized scenario to infer population choice probabilities in unrealized scenarios. It is well appreciated in revealed preference analysis that extrapolation requires the researcher to combine the available empirical evidence on realized choices with prior information restricting the population distribution of choice functions and treatments. Similarly, extrapolation using expected choice data requires prior information.
To give some concreteness to this general point, I set out below a relatively simple class of extrapolation problems and bring to bear prior information of the sort commonly assumed in applications of econometric revealed preference analysis. The material that follows illustrates the possibilities, leaving an in-depth study to future work.

3.2. Binary probit and maximum score analysis of expected choice data
Suppose that all persons face the same binary choice set C = (i, not i). The space E of potential environments is a Cartesian product E = V X U. The researcher selects a feasible value v E V and poses this question to respondents:
06. Suppose that you must choose between i and (not i), and that the environment has attributes v. What is the percent chance that you would choose action i?
06 poses an incomplete scenario, one that specifies v but leaves unspecified the (possibly distinct) values of u that each person would realize. Suppose that the researcher who has posed 06 wants to predict choice behavior in another feasible incomplete scenario, say one in which the environment has attributes v' rather than v. This is an extrapolation problem.
Consider, for example, the third fertility question posed in the Introduction. The attribute v described to respondents is the child-allowance program providing women with fifty dollars per month for each dependent child. Other aspects of women's future environments are not described. The researcher may want to predict fertility in another incomplete scenario, perhaps one in which the child allowance would be one hundred dollars per month rather than fifty dollars per month.
To enable extrapolation, one needs to bring to bear prior information about respondents' choice functions and about their subjective distributions for the unspecified environment component u. I shall adopt the familiar assumption of

62

MAN SKI

econometric revealed preference analysis that choice functions have the threshold-crossing form

= not i otherwise.

(8)

I suppose that, at the time of the survey, both person j and the researcher know the form of the function w(·, ·):X x V ~ RK and the value of the covariates xj. The researcher describes the environmental attributes v to respondents but leaves the scalar attribute uj unspecified. Person j knows the preference parameters f3j
but the researcher does not. In this setting, person j's subjective choice probability for action i is

(9)

Equation (9) has the form of a standard econometric model of binary choice. In revealed preference applications, uj is known to person j but unknown to the researcher. Population choice probabilities are formed from the population distribution of u. Here uj is unknown to person j, who applies his or her subjective distribution of u to form a subjective choice probability.
Suppose, in particular, that each person places a standard normal subjective distribution on u. Then person j's subjective choice probability for action i has the binary probit form

(10)

where <I> is the standard normal distribution function. Alternatively, suppose only that each person places subjective median zero on u. Then person j's subjective choice probability for i satisfies the inequality
(11)

Now consider the situation of the researcher. Suppose first that the researcher has strong prior information. The researcher knows that subjective choice probabilities have the probit form (10). The researcher also knows that u is statistically independent of (x, v, {3) in the population and is distributed standard normal; thus respondents have rational expectations. Finally, the researcher knows that the preference parameters f3 are statistically independent of (x, v) and are distributed multivariate normal across the population, with unknown mean JL and covariance
matrix I.
With these maintained assumptions, the researcher can use the elicited subjective choice probabilities to estimate the mean JL and variance I of the preference distribution and then proceed to perform extrapolations. In particular, (10) implies

ANALYSIS OF CHOICE EXPECTATIONS IN INCOMPLETE SCENARIOS

63

the linear random coefficients model

(12)

Observation of the subjective choice probabilities of a random sample of respondents thus enables consistent estimation of ( JL, I), whether directly by maximum
likelihood or in stages by feasible generalized least squares. With ( JL, I) estimated,
the researcher can perform extrapolations in which the environmental attribute
value v specified in the survey is replaced by another value v 1· Let <I>*( {3 I JL, I)
denote the multivariate normal population distribution of {3. The population choice probability of interest is

P[y(z) = i Ix,v 1] = f<l>[w(x,v 1) · f3]d<l>*( /31~-t,I:),

(13)

much as in Fischer and Nagin (1981), McFadden (1976), and elsewhere. With the estimated values of ( JL, I) in place, the right side of (13) provides a consistent estimate of the left side.
Now suppose that the researcher has much weaker prior information. The researcher knows that subjective choice probabilities satisfy the inequality (11). The researcher also knows that u is statistically independent of (x, v) in the population and has median zero. Thus respondents need not have rational expectations, but their expectations about the median of u are consistent with reality. Finally, the researcher knows that the preference parameters {3 are statistically independent of (x, v) and are distributed symmetrically across the population, say with center of symmetry I-t·
With these weaker maintained assumptions, the researcher can use the elicited subjective choice probabilities to estimate IL and then proceed to perform some weak extrapolations. In particular, (11) implies the random coefficients thresholdcrossing model

(14)

= where Bj {3j - IL· The maintained assumptions imply that w(xj, v) · {) has median

zero conditional on (x, v ). Hence observation of the subjective choice probabilities

of a random sample of respondents enables consistent estimation of IL by the

maximum score method (Manski, 1975, 1985). With IL estimated, the researcher

can perform extrapolations in which the environmental attribute value v specified

in the survey is replaced by another value v 1· The maintained assumptions imply

that

w(xj, v 1)

+ · {)

u

has

median

zero

conditional

on

(x, v 1).

Hence

P[y(z) =

i I x, v 1] satisfies the inequality

P[y(z) = Ii x, V 1] ;;:: 0.5 ~ w(x, V 1) 'IL;;:: 0.

(15)

64

MANSKI

With the estimated value of JL in place, the right side of (15) provides a consistent estimate of the left side. Thus the researcher can predict whether the population choice probability in a scenario with attributes v' would be above or below 0.5.

4. Conclusion
This study of the analysis of choice expectations in incomplete scenarios carries different messages for different readers.
Readers who are comfortable with the assumptions commonly maintained in econometric revealed preference analysis and with the common economic assumption that persons have rational expectations should draw quite positive conclusions from the analysis of feasible incomplete scenarios in Sections 2 and 3. Given these assumptions, responses to expected choice questions posing feasible incomplete scenarios can be used not only to predict choice behavior in the scenarios posed but also to extrapolate to other feasible incomplete scenarios. In fact, Section 3.2 shows that familiar statistical methods for estimating preference parameters and choice probabilities can be applied.
Such readers with applied interests should want to collect probabilistic choice expectations and analyze them using the methods developed here. Those with methodological interests should want to develop further the analysis of this paper. One avenue for further development should be to determine the inferences that become possible if the researcher is able to combine responses to multiple expected choice questions or is able to combine responses to expected choice questions with data on realized choices.
Readers who think conventional economic assumptions to be implausible should draw a cautionary lesson. These readers may not want to use the analysis of Sections 2 and 3 to interpret responses to expected choice questions, but they should draw the lesson that interpretation of expected choice data requires some well-articulated set of assumptions. If the conventional economic assumptions are not maintained, then a set of alternative assumptions thought to be more plausible must be specified.
I expect that all readers will feel disquieted, as I do, by the brief discussion of counterfactual scenarios in Section 2.3. It is not clear how ideal respondents would logically interpret questions posing counterfactual scenarios, much less how actual respondents do so.

Acknowledgments
This research is supported by grant SBR-9722846 from the National Science Foundation. I am grateful to Baruch Fischhoff and the reviewers for their most constructive comments.

ANALYSIS OF CHOICE EXPECTATIONS IN INCOMPLETE SCENARIOS

65

Notes
1. Political pollsters sometimes eliminate the difference in timing between elicitation and behavior by asking a forced-choice question of the form:
Suppose that persons A and B are the presidential nominees of the Democratic and Republican Parties. If the election were held today, would you vote for person B?
This question solves the problem of not specifying the environment only by replacing the scenario of interest, a real election to be held in the future, with a different counterfactual scenario in which the timing of the election is somehow changed. Manski (1990, Section 5) shows that coherent and cooperative respondents need not give the same reply to forced-choice and intentions questions. 2. The use of probabilistic questions to elicit choice expectations was recommended over thirty years ago by Juster (1966), who argued that it would be more informative to ask consumers for their purchase probabilities than for their buying intentions. Recently, considerable empirical experience has been obtained in the elicitation of probabilistic expectations of various personal economic and health outcomes. See, for example, Quadrel, Fischhoff, and Davis (1993), Hurd and McGarry (1995), and Dominitz and Manski (1997a, 1997b).

References
Afriat, Sidney. (1967). "The Construction of a Utility Function from Expenditure Data," International Economic Review 8, 67-77.
Beggs, S., Scott Cardell, and Jerry Hausman. (1981). "Assessing the Potential Demand for Electric Cars," Journal of Econometrics 16, 1-19.
Ben-Akiva, Moshe and Thawat Morikawa (1990). "Estimation of Switching Models from Revealed Preferences and Stated Intentions," Transportation Research A 24A, 485-495.
Blume, Lawrence, A. Brandenburger, and Edward Dekel. (1991). "Lexicographic Probabilities and Choice Under Uncertainty," Econometrica 59, 61-79.
Dominitz, Jeff and Charles Manski. (1997a). "Perceptions of Economic Insecurity: Evidence from the Survey of Economic Expectations," Public Opinion Quarterly 61, 261-287.
Dominitz, Jeff and Charles Manski. (1997b). "Using Expectations Data to Study Subjective Income Expectations," Journal of the American Statistical Association 92, 855-867.
Dominitz, Jeff and Charles Manski. (1999). "The Several Cultures of Research on Subjective Expectations." In Robert Willis and James Smith (eds.), Wealth, Work, and Health Ann Arbor, MI: University of Michigan Press.
Fischer, Gregory and Daniel Nagin (1981). "Random versus Fixed Coefficient Quanta! Choice Models." In Charles Manski and Daniel McFadden (eds.), Structural Analysis of Discrete Data with Econometric Applications Cambridge, MA: MIT Press.
Fischhoff, Baruch, Ned Welch, and Shane Frederick. (1999). "Construal Processes in Preference Assessment," Journal of Risk and Uncertainty, 19, 139-164.
Hurd, Michael and Kathleen McGarry. (1995). "Evaluation of Subjective Probabilities of Mortality in the HRS," Journal of Human Resources 30, S268-S292.
Juster, F. Thomas. (1966). "Consumer Buying Intentions and Purchase Probability: An Experiment in Survey Design," Journal of the American Statistical Association 61, 658-696.
Louviere, Jordan and G. Woodworth. (1983). "Design and Analysis of Simulated Consumer Choice or Allocation Experiments: An Approach Based on Aggregate Data," Journal of Marketing Research 20, 350-367.

66

MAN SKI

Luce, R. Duncan. (1959). Individual Choice Behavior: A Theoretical Analysis. New York: Wiley. Luce, R. Duncan and Patrick Suppes. (1965). "Preference, Utility, and Subjective Probability." In R.
Duncan Luce, R. Bush, and E. Galanter (eds.), Handbook of Mathematical Psychology, Vol. 3. New York: Wiley. Manski, Charles. (1975). "Maximum Score Estimation of the Stochastic Utility Model of Choice," Journal of Econometrics 3, 205-228. Manski, Charles. (1985). "Semiparametric Analysis of Discrete Response: Asymptotic Properties of the Maximum Score Estimator," Journal of Econometrics 27, 313-333. Manski, Charles. (1988). "Identification of Binary Response Models," Journal of the American Statistical Association 83, 729-738. Manski, Charles. (1990). "The Use of Intentions Data to Predict Behavior: A Best Case Analysis," Journal of the American Statistical Association 85, 934-940. Manski, Charles. (1995). Identification Problems in the Social Sciences. Cambridge, MA: Harvard University Press. Manski, Charles. (1997). "Monotone Treatment Response," Econometrica, 65, 1311-1334. Manski, Charles and Ilan Salomon. (1987). "The Demand for Teleshopping," Regional Science and Urban Economics 17, 109-121. McFadden, Daniel. (1973). "Conditional Logit Analysis of Qualitative Choice Behavior." In Paul Zarembka (ed.), Frontiers of Econometrics. New York: Academic Press. McFadden, Daniel. (1976). "Quanta! Choice Analysis: A Survey," Annals of Economic and Social Measurement 5, 363-390. Quadrel, M., Baruch Fischhoff, and W. Davis. (1993). "Adolescent (In)vulnerability," American Psychologist 48, 102-116. Tversky, Amos. (1972). "Choice-by-Elimination," Journal of Mathematical Psychology 9, 341-367. Varian, Hal. (1982). "The Nonparametric Approach to Demand Analysis," Econometrica 50, 945-973.

Journal of Risk and Uncertainty, 19:1-3; 67-69 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.
Commentary on "Analysis of Choice Expectations in Incomplete Scenarios"
KENNETII I. WOLPIN Department of Economics, University of Pennsylvania, 3718 Locust Walk, Philadelphia, PA 19104
From many economists' perspective, the ideas advanced by Professor Manski would appear to be provocative, if not revolutionary. Economists tend to believe that subjective data are generically of little or no value. There are several reasons for this view. One is simply the belief that such data are untrustworthy; either respondents won't or can't provide "truthful" responses. For example, to continue with Professor Manski's illustrative use of fertility questions, respondents, when asked about the wantedness of a particular pregnancy after the birth of the child, may not wish to admit that a child was unwanted or may engage in ex post rationalization.1 Of course, objective data may also be inaccurate, although at least in principle such data can be externally validated. Another reason that economists are skeptical of subjective data is that they are difficult to interpret or admit to multiple interpretations. For example, should one interpret the question "How many children would you desire to have?" as representing a pure preference for children or a response that takes into account constraints (e.g., income).
The subset of subjective questions that Professor Manski discusses are those that pertain to the elicitation of choice expectations. His analysis maintains the assumption that respondents are truthful (to the best of their capabilities), the same assumption that is made about objective data. The purpose of the paper is to address the second concern of economists, that of how to interpret and make use of choice expectations data. In the last section of the paper, after the foundational apparatus is developed, Professor Manski provides an illustration of the value of choice expectations data for understanding decision processes and for policy extrapolation. As he shows, choice expectations data, as objective choice data, must be combined with a theory of behavior in order to achieve those goals.
In the beginning of the essay, Professor Manski argues that the two approaches, analysis of objective choice data and analysis of choice expectations data, should be complementary. He doesn't pursue the notion of complementarity and in the brief space I have, I'd like to explore in what sense that may be true. The issue is clearly important in the context of optimal survey instrument design, given that surveys are costly to administer and, therefore, are limited in the number of questions that can be asked of respondents. One might ask what is the optimal mix of objective choice data and choice expectations data.

68

WOLPIN

To make a start on answering that question, I will need a formal structure. For the sake of continuity, I will adopt a fertility illustration, one that is highly oversimplified but sufficient to make the necessary points.2 To take a concrete issue, suppose our ultimate goal is to determine the impact on fertility of providing a child allowance of an amount, s, that is to be determined later. Assume that women decide on whether or not to have a child according to whether the net benefit of a child (the psychic benefit minus the cost of bearing and rearing a child)
is positive. Letting the net benefit for woman i at time t be /3;t> the decision rule is to have a child whenever /3;1 > 0 and not to have a child otherwise. Assume further
that the net benefit is normally distributed in the population with mean f.Lt3 and variance u132 and that at each t the woman obtains a new independent draw (from the same distribution) that is unknown to the woman prior to that time.
Now, suppose we survey a random sample of women from the population at some time and simply ask whether or not they had a birth, say, in the last year. Assuming the reports are accurate, from the fraction of women who had a birth we
can estimate f.L13fu13 · Notice that we cannot answer the policy question, which is to
evaluate the change in the fraction of women who would have a child if each woman's net benefit, and thus the mean net benefit, was increased by s, because we cannot obtain separate estimates of the mean and variance. Consider now obtaining choice expectations data instead, namely asking each woman what is the percent chance she would have a child in the next year. Given the assumptions of the model (time periods are assumed to be separated by a year), as Professor Manski shows, the sample average percent chance would be the same as the fraction of women having a birth in the prior year up to sampling error. Thus, from that sample average, we would also obtain an estimate of f.LrJ u13 · The value of asking both the objective and the subjective question is that we essentially have twice the sample size without having to survey twice the number of women (either in the same year or by repeating the survey in the next year).3 Instead of incurring the cost of additional sample, we incur only the marginal cost of an additional question.
One might think that asking the more pointed hypothetical policy question, "What is the percent chance you will have a child if you were to receive a $50 child allowance?" instead of the objective choice question or the general choice expectations question, would provide more information on the policy of interest. However, in this case as well we can only estimate the ratio of the moments of the "new" net
benefit distribution (( f.L/3 + 50)j op ), which is also insufficient to perform extrapola-
tions. But, if we ask this question together with either of the other two, the implicit variation in the subsidy from zero to $50 provides the necessary information to identify the separate moments of the net benefit distribution. We can then perform the general hypothetical experiment that was our original goal. In this case not only do we obtain more precision, but we obtain identification and the ability to extrapolate. Of course, identification could also be achieved if we had objective data on the cost of a child that varied in the population, in which case the choice expectations data would only improve efficiency.

COMMENTARY

69

In more complex settings, for example, in studying the interactions among a number of decisions (say a behavioral model of the joint fertility, employment and welfare participation decision), choice expectations data, even those with the most incomplete scenarios, must provide efficiency gains if such data are valid. However, in those settings I would conjecture that obtaining identification through the use of choice expectations data would require relatively complete scenarios. If that is the case, then the presumption that such data are trustworthy might become an issue.

Notes
1. Rosenzweig and Wolpin (1993) provide evidence for the existence for ex post rationalization in this case.
2. Economists have developed quite sophisticated models of fertility that have been empirically implemented using objective choice data (see the review by Hotz, Klerman and Willis (1997)).
3. The possibility that there is an efficiency gain from combining choice expectations data with objective choice data has been pointed out in Wolpin and Gonul (1985) and in Vanderklaauw (1997). In his study on the career choices of teachers, Vanderklaauw finds such gains to be non-trivial.

References
Hotz, V. Joseph, Jacob A. Klerman, and Robert J. Willis. (1997). "The Economics of Fertility in Developed Countries." In Mark R. Rosenzweig and Oded Stark, (eds.), Handbook of Population and Family Economics, Vol. lA. Amsterdam: Elsevier.
Rosenzweig, Mark R. and Kenneth I. Wolpin. (1993). "Maternal Expectations and Ex Post Rationalizations: The Usefulness of Survey Data on the Wantedness of Children," Journal of Human Resources 28, 205-229.
Vanderklaauw, Wilbert. (1997). "On the Use of Expectations Data in Estimating Structural Dynamic Models: An Analysis of Career Choices," Mimeo, New York University.
Wolpin, Kenneth I. and Gonul, Fusun. (1985). "On the Use of Expectations Data in Micro Surveys," Mimeo, The Ohio State University.

Journal of Risk and Uncertainty, 19:1-3; 71-72 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.
Commentary on "Analysis of Choice Expectations in Incomplete Scenarios"
ELI<E U. WEBER Columbia University
This paper addresses an important topic in the preference elicitation field, namely the method of inferring population preference from hypothetical choice data collected from a random sample of that population. While criticized by a subset of economists who object to the hypothetical nature of the responses and put faith only in preference predictions derived from revealed preference analysis, hypothetical choice analysis is widely used in a range of economic applications that draw their data from, for example, panel studies. Manski attempts to provide a solid theoretical basis for the use of such response data. The focus of his present paper is the use of probabilistic expectations data to predict behavior in feasible or counterfactual scenarios. Given the rich context in which actual decisions are made, any choice scenario described by a researcher is bound to be incomplete. The contribution of the paper lies in its attempt to combine assumptions about respondents' preference formation with assumptions about their expectations of (unspecified) scenario details that may affect their preferences.
The paper, indirectly, addresses an issue important above and beyond the analysis of expected choice data, namely the relationship between the judgments and decisions made by individuals and behavioral predictions at the aggregate level. The field of behavioral decision theory would greatly profit from more systematic research about the conditions under which aggregation can be expected to lead to a reduction of individual-level errors (through some averaging process) and conditions under which individual-level errors can be expected to escalate at the aggregate level. Manski points out that individual-level divergences between stated intentions and subsequent behavior, for one, generally cannot be expected to average out in the aggregate.
The paper's results are based on the premise that respondents' have access to their preferences, i.e., that preferences are constant and known. This is, of course, in marked contrast to the realization of behavioral decision theory that preferences, more often than not, are constructed. Manski offers his behavioral assumptions and resultant analysis as a best-case scenario and leaves it as a challenge to other researchers to replace them with more realistic ones. His paper shows that the interpretation of responses to expected choice questions requires a well-articulated set of assumptions. More work is needed, however, to turn the best-case scenario results into results that can be used to interpret the responses of members

72

WEBER

of the general public whose cognitive and emotional limitations affect both preference elicitation and expectation formation. The literature on people's lapses of memory in the generation or evaluation of fault trees, for example, suggests that it is unlikely that respondents can generate unbiased subjective choice probabilities for described scenarios in the fashion assumed by Manski. Complicating things even more, there may well turn out to be relationships between people's systematic deviations from normative behavior in their preference assessment and in their expectation formation about future events.

Journal of Risk and Uncertainty, 19:1-3; 73-105 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Rationality for Economists?

DANIEL McFADDEN1

mcfadden@econ.berkeley.edu

Department of Economics, University of California, Berkeley 94720-3880

Abstract
Rationality is a complex behavioral theory that can be parsed into statements about preferences, perceptions, and process. This paper looks at the evidence on rationality that is provided by behavioral experiments, and argues that most cognitive anomalies operate through errors in perception that arise from the way information is stored, retrieved, and processed, or through errors in process that lead to formulation of choice problems as cognitive tasks that are inconsistent at least with rationality narrowly defined. The paper discusses how these cognitive anomalies influence economic behavior and measurement, and their implications for economic analysis.
Key words: rationality, behavioral decision theory, preferences, cognition
JEL Classification: DS

1. Introduction
Economics has always been concerned with the motivations and behavior of consumers. Rational behavior, in the broad meaning of sensible, planned, and consistent, is believed to govern most conduct in economic markets, because of self-interest and because of the tendency of markets to punish foolish behavior. However, rationality has been given a much more specific meaning in the classical theory of consumer demand perfected by Hicks and Samuelson that forms the cornerstone of courses in economic theory. In Herb Simon's words, "The rational man of economics is a maximizer, who will settle for nothing less than the best." While this model of consumer behavior dominates contemporary economic analysis, there is a long history among economists of questioning its behavioral validity and seeking alternatives.
What has come to be known as Behavioral Decision Theory had its origins in the von Neumann and Morgenstern (1947) treatise on choice under uncertainty and game theory.2 This work had two major impacts beyond its direct effect of providing a prescriptive framework for analyzing risky behavior: It made formal, axiomatic analysis fashionable in economics and psychology, and it invited laboratory experimentation to test the descriptive validity of the axioms. Most of this work concentrated on choice among lotteries, but the ideas spread to other decision-making situations. In the following two decades, behavioral science and

74

McFADDEN

cognitive psychology came of age, with the participation of notable economists such as Allais (1953), Chipman (1960), Marschak (1950), Papandreau (1960), and Simon (1959).
The rational consumer model is so deeply entwined in economic analysis, and in broad terms so plausible, that it is hard for many economists to imagine that failures of rationality could infect major economic decisions or survive market forces. Nevertheless, there is accumulating behavioral evidence against the rational model. Choice behavior can be characterized by a decision process, which is informed by perceptions and beliefs based on available information, and influenced by affect, attitudes, motives, and preferences. Figure 1 depicts these elements in the decision process and their linkages. A few brief definitions are needed. Perceptions are the cognition of sensation. I will use "perceptions" broadly to include beliefs, which are mental models of the world, particularly probability judgments. Affect refers to the emotional state of the decision-maker, and its impact on cognition of the decision task. Attitudes are defined as stable psychological tendencies to evaluate particular entities (outcomes or activities) with favor or disfavor. Technically, attitudes are often defined as latent factors that explain the variation in a battery of indicators (most commonly semantic differentials). The domain of attitudes may be very broad, including for example comparative judgments, but an attitude itself is a unitary valuation. Preferences are comparative judgments between entities. Under certain technical conditions, including completeness and transitivity, preferences can be represented by a numerical scale, or utility. Motives are drives directed toward perceived goals. The cognitive process for decision making is the mental mechanism that defines the cognitive task and the role of perceptions, beliefs, attitudes, preferences, and motives in performing this task to produce a choice.

Figure 1.

RATIONALITY FOR ECONOMISTS?

75

Neoclassical economics and psychology have radically different views of the decision-making process. First, the primary focus of psychologists is to understand the nature of these decision elements, how they are established and modified by experience, and how they determine values. The primary focus of economists is on the mapping from information inputs to choice. Preferences, or values, can be treated for most economic applications as primitives of the analysis, and the decision process as a black box. The aphorism "Economists know the price of everything and the value of nothing" correctly characterizes the discipline's scientific priorities.
Second, psychological views of the decision process are dominated by ideas that behavior is local, adaptive, learned, dependent on context, mutable, and influenced by complex interactions of perceptions, motives, attitudes, and affect. The standard model in economics is that consumers behave as if information is processed to form perceptions and beliefs using strict Bayesian statistical principles (perceptionrationality), preferences are primitive, consistent, and immutable (preference-rationality), and the cognitive process is simply preference maximization, given market constraints (process-rationality). George Anslie (1982) gives a psychologist's view of these differences:
Since ancient times people have tried to understand the nature of value, this is, how events motivate us. Two kinds of good have been described: what might be called visceral satisfactions, closely associated with the consumption of a concrete object and usually in the service of an obvious biological need; and more subtle satisfactions, such as [acquisition of] knowledge .... Quantitative description of the value of concrete objects became the science of economics. By restricting its attention to goods that trade in a cash market, this discipline has been able to describe striking regularities in how we value these goods. For all the usefulness that this may have had, it has tended to create a self-contained body of procedures without reference to the human motivational processes that actually determine value.
Is the lack of attention to the process of decision making and formation of values a fundamental failing of economics? If the standard model were always successful in explaining market behavior, and economists confined their attention solely to market data, the answer would be no. Economists might be criticized for lack of scientific curiosity, but their discipline would nevertheless sit securely on its own bottom. However, accumulating behavioral evidence that the standard model fails under some market conditions, and accelerating interest by economists in nonmarket data obtained from surveys and experiments, makes this lack of attention much more critical. Consumers may be wired differently than economic rationality in the sense of the standard model requires. While the consumer's wiring may produce patterns of market behavior that in many cases can be approximated well by the standard model, when we approach the consumer from a different angle, asking direct and unusual questions about beliefs or values, we find alarming

76

McFADDEN

variations from the standard economist's story. All these apparently normal consumers are revealed to be shells filled with books of rules for handling specific cognitive tasks. Throw these people a curve ball, in the form of a question that fails to fit a standard heuristic for market response, and the essential "mindlessness" of the organism is revealed. For most economists, this is the plot line for a really terrifying horror movie, a heresy that cuts to the vitals of our profession. To many psychologists, this is a description of the people who walk into their laboratories each day.

Economic rationality and the standard model
I will call a consumer Chicago man if he conforms to the standard economic model of perception, preference, and process rationality, since the postulated behavior includes the ubiquity of maximizing behavior associated with Becker (1993) and the structure of beliefs associated with Lucas (1987). Chicago man is associated with one-way flows from perceptions and tastes to the cognitive task of preference maximization, corresponding to the heavy arrows in Figure 1. I have four observations on the Chicago-man model:
· It is convenient. With additional assumptions, it leads to straightforward and handy procedures for empirical demand analysis and benefit-cost analysis. It has been an important tool for economic analysis and policy.
· It is successful. In applications ranging from assessing the opportunities for arbitrage in financial markets to the design of incentive schemes in contracts, it characterizes the most salient aspects of behavior in markets.
· It is unnecessarily strong. Many of the core objectives of economic analysis are attainable with weaker forms of rationality that relax perception-rationality, and permit some important deviations from preference rationality (e.g., mutable preferences) and process-rationality (e.g., bounded rationality). Both users and critics of the model sometimes interpret it in unnecessarily restrictive ways. For example, immutability of preferences does not imply that consumers are unaffected by history or incapable of learning, but only that preferences develop consistently following a "rational" template.
· It is false. Almost all human behavior has a substantial rational component, at least in the broad sense of rationality. However, there is overwhelming behavioral evidence against a literal interpretation of Chicago man as a universal model of choice behavior.
So what is it with economists and Chicago man? Why is it that when economists are confronted with behavioral evidence against this model, they shuffle their feet, mumble excuses, and go on doing what they have been doing? I believe the answer is more complicated than saying Chicago man is the street lamp under which economists search for the truth, or even that it is the "anvil on which intellectual

RATIONALITY FOR ECONOMISTS?

77

positions are hammered out." If one looks at the history of the concept of rationality, one sees two distinct ideas. The first, which might be termed 19th Century choice theory, is summed up in a quote from a principles textbook by Frank Taussig (1912):
An object can have no value unless it has utility. No one will give anything for an article unless it yield him satisfaction. Doubtless people are sometimes foolish, and buy things, as children do, to please a moment's fancy; but at least they think at the moment that there is a wish to be gratified.
In this view, preference maximization is a synonym for choice. Preferences may be volatile and context dependent; what is missing from this theory is an explanation for the process that generates this volatility. This view of rationality is virtually irrefutable until one starts to restrict and codify the manner in which preferences shift with experience in subsequent choice occasions. What is useful to note is that almost all of the elements of economic demand analysis, and of benefit-cost analysis, can be obtained by assuming little more than this. Suppose mild stationarity assumptions, so that the distribution of preferences in the population remains unchanged even though the preferences of each individual are volatile; call this stochastic rationality. A theory of social choice that looks only at the distribution of outcomes, and not the names of recipients, handles individual preference volatility in the same way that it handles heterogeneity in preferences across individuals; see McFadden (1981, 1997). Thus, rationality in an early, broad sense is sufficient to accomplish major objectives of economics, while avoiding some of the invariance properties in later restrictions and codifications of the Chicago-man model that are so easily refuted experimentally. Unfortunately, stochastic rationality is no panacea: it cannot explain cognitive anomalies that correspond to shifts in the distribution of preferences, nor is it immune to experimental refutation. For example, it implies the potentially refutable regularity property that a choice probability cannot rise when the choice set is expanded.
The second historical idea is the picture of the consumer codified in the 20th Century and elegantly summarized (with italics added) in Debreu (1959):
... A commodity is a good or a service completely specified physically, temporally, and spatially. For any economic agent a complete plan of action (made now for the whole future) is a specification for each commodity of the quantity that he will make available or that will be made available to him.
Debreu's consumer is postulated to choose his complete plan to maximize primitive rational preferences. The Debreu view of the consumer is rather Calvinistic: behavior is preordained by the consumer's genetically determined preferences over alternative life courses. This is not a perspective that most behaviorists will find appealing. However, note what it accomplishes. It allows very complex patterns of experience and learning, although in light of the consumers' postulated omni-

78

McFADDEN

science, perhaps we should call it verification or expression rather than learning. Because commodities can be contingent on future events, the theory provides a complete theory of behavior under uncertainty. The whims of 19th Century utility theory are ruled out; apparently volatile and context-dependent current preferences are simply projections of immutable strategic preferences. Because we can never measure all the aspects of the complex life-course objects the consumer is choosing among, we are never sure whether what appears to be irrational behavior in some limited time window is not part of an overarching rationality, a grand strategic design. Deaton and Muellbauer (1980) draw out a different implication on the nature of commodities:
The [preference] axioms are defined over some field of choice. In the usual presentation individual purchases of commodities are objects of choice. In principle, choice could be exercised over a much wider field, for example, over different life-styles, each embodying a preference system of its own. As it is, we shall interpret "commodities" rather widely, leaving the way open for application to leisure choice, intertemporal choice, social choice, and so on. Even so, a clear definition can be important in practice since two apparently similar choices may in fact be very different if there are unrecognized components.
Thus, commodities can be complex objects that have broad ethical and social aspects as well as more conventional physical ones. With this interpretation, propositions such as "If I go bankrupt, I will learn to enjoy the simple life" can be interpreted as aspects of objects in the field of choice. We may fail to measure all aspects of commodities, and apparent failures of rationality may arise from unrecognized but salient differences in the objects of choice.
There are very few irregularities or volatilities in observed behavior that could not be explained away by a combination of a rational template for preferences and unrecognized aspects of commodities. However, the Debreu-Deaton-Muellbauer view of rationality does impose invariance properties on preferences that in combination with other assumptions become a powerful restriction. Its most serious limitation for a behaviorist is that its panoramic view of the consumer provides an unsuitable platform for understanding the process of learning and adaptation.
The Chicago-man model in its most commonly used form is a specialization of the Debreu-Deaton-Muellbauer view of rationality in which commodities are restricted to market goods without social or ethical aspects, and the temporal structure of preferences is tightly restricted. Stripping away the robust features of the abstract version makes Chicago man a powerful but brittle model that is vulnerable to behavioral attack. Economic opinion spans the spectrum from those who believe Chicago man is the literal truth to those who believe that failures of rationality appear systematically and predictably in economic decisions. However, I believe that most economists think rationality in one of its more fundamental and robust forms is valid, and think of Chicago man as an abstraction or approximation

RATIONALITY FOR ECONOMISTS?

79

to this form of rationality. They do not really expect the approximation to work perfectly, and they do not interpret evidence against the approximation as necessarily evidence against the fundamentals. Perhaps this is a sensible way to approach economic analysis, but it may blind economists to behavioral evidence that challenges rationality at a more fundamental level. One implication of these comments is that economic rationality has many lives, and will not be felled by the silver bullet of a single experiment.

The psychology of decision-making
Psychology has developed a variety of theories and techniques for studying the process of decision-making, including decision delay times, and subject reports before, during, and after decisions are made, and has accumulated a large body of experimental evidence on the decision-making process. The leading research paradigm has been the focus of Amos Tversky and Danny Kahneman on experimental study of cognitive anomalies: circumstances in which individuals exhibit surprising departures from rationality. This work has both fascinated and dismayed economists; it has been like watching master carpenters construct the scaffold for your hanging. The studies show that individuals faced with decision-making tasks in carefully constructed experimental settings often exhibit behavior that is inconsistent with the Chicago-man model: decision makers have trouble handling information and forming perceptions consistently, use decision-making heuristics that can fail to maximize preferences, and are too sensitive to context and process to satisfy rationality postulates formulated in terms of outcomes. Cognitive anomalies are most apparent for choice among formal lotteries where probability judgments are critical, but also appear in "risk-free" choice problems.3 Here is Tversky's (1977) own commentary on these results:
... Daniel Kahneman and I have studied the cognitive processes underlying the formation of preference and belief. Our research has shown that subjective judgments generally do not obey the basic normative principles of decision theory. Instead, human judgments appear to follow certain principles that sometimes lead to reasonable answers and sometimes to severe and systematic errors. Moreover, our research shows (Tversky and Kahneman, 1974; Kahneman and Tversky, 1979a) that the axioms of rational choice are often violated consistently by sophisticated as well as naive respondents, and that the violations are often large and highly persistent. In fact, some of the observed biases, such as the gambler's fallacy and the regression fallacy, are reminiscent of perceptual illusions. In both cases, one's original erroneous response does not lose its appeal even after one has learned the correct answer.

80

McFADDEN

To gain a perspective on this research, it is useful to draw some parallels between decision-making and vision. Figure 2 is a simplified map of the wineproducing region around Bordeaux. Bordeaux appears to be closer to St. Emillion than to Margaux. However, the reader will immediately recognize that this is the classical Muller-Lyer optical illusion in which the distances are actually the same. Even after you are told this, St. Emillion looks closer. Could this illusion affect behavior? In fact, St. Emillion is more crowded than Margaux, perhaps due to other wine-lovers' illusions, but I doubt that anyone would claim that this is due to mass misreading of maps. We learn to be suspicious of our perceptions. We may see things cock-eyed, but we adopt conservative behavioral strategies, such as making it a rule to always measure distances on the map, that prevent us from deviating too far from our self-interest.4 Does this mean that there is, after all, a saving remnant of rationality? In the broad sense of rationality, perhaps so.
One can learn a great deal about how visual information is processed by studying the breakdown regions where optical illusions occur, and draw from this lessons for how "normal" vision operates. Clearly a crude "what you see is what a camera sees" model of vision is false. Nevertheless, if you are trying to predict how people react when driving, the crude model may be a better platform for forecasting than the library of optical illusions. I once asked Tversky if he thought choice behavior was similar to vision, in that one could induce cognitive illusions under specific circumstances, but for most human activity cognition is acceptably rational. He replied that his experiments on cognition were like experiments in vision, concentrating on the breakdown region that reveals how we are put together. He said that these experiments were not designed to be representative of all behavior, and should not in themselves be interpreted as broadly predictive. He went on to say,

HAUTMEDOC

PAUILLAC

SAUTERNE

GRAVES

ST. EMILLION Figure 2. Roads in the wine-producing region near Bordeaux.

RATIONALITY FOR ECONOMISTS?

81

however, that he saw little evidence from the research on cognition that would suggest that human thought is ever sufficiently divorced from context and process to produce the global invariances required by economic rationality.
The experimental results from psychology have not been codified into a "standard model" for behavioral decision theory; and many psychologists would argue it is not possible or useful to construct such a model. Nevertheless, it is possible to identify some of the major features of a psychological view of decision-making. Referring to Figure 1, the central element is the process by which the cognitive task is defined and elements such as perceptions and attitudes enter. Attitudes and affect are major factors in determining motivation and the structuring of the cognitive task. Attitudes and affect also influence perceptions. Finally, there may be feedbacks, depicted by light arrows in Figure 1, from process and choice to attitudes and perceptions, as the decision-maker reconciles and rationalizes trial choices. Preferences may play a role in the psychological view, as may maximization, but they compete with other heuristics for defining and solving the cognitive task.
Psychologists make a sharp distinction between attitudes and preferences. In this view, attitudes are multi-dimensional, with no requirement of consistency across attitudes. Preferences are viewed as constructed from more stable attitudes by a context-dependent process that determines the prominence given to various attitudes and the tradeoffs between them; see Kahneman, Ritov, and Schkade (1998) and Payne, Bettman, and Johnson (1992). Technically, a utility index can be interpreted as an attitude scale, and may be defined over a broad field of objects, not just concrete outcomes. The hypothesis that a utility index is less stable than other attitude scales has some plausibility in light of experimental evidence that cognitive anomalies arise in forming trade-offs, but it is difficult to formulate and test this hypothesis satisfactorily because there is no consensus on what the stable attitudes are, and because attitude scales that have been proposed seem themselves to be sensitive to context. At bottom, the differences between psychologists and economics on the attitude/preference dimension are almost theological: the psychologists' decision-maker is driven by many demons, the economists' decisionmaker by the one "devil that made me do it."
Choice tasks are distinguished by their complexity and familiarity, from quick and largely automatic or impulsive decisions on one hand to complex, planned decisions on the other; see Azjen (1987), Garling (1992, 1998). An example of an "automatic" decision is choosing to change lanes when driving. An example of a "planned" decision, which may also contain "impulsive" elements, is choice of occupation, where the alternatives have to be elicited or created, and the task requires problem-solving to clarify attributes and goals. Psychologists emphasize the importance of affect on decisions, with emotion not only inducing "hot" or "impulsive" decisions, but also coloring perceptions; see Lowenstein (1996).
There may be feedbacks from the decision process to perceptions, particularly through affect and attitudes, with perceptions becoming an instrument to facilitate

82

McFADDEN

the cognitive decision process. Svenson (1979, 1996) describes a decision process in which simple heuristics are used to produce a preliminary choice, using markers and editing to simplify and group information; see Kahneman and Tversky (1979) and Coupey (1994). Then, the decision-maker engages in a process of differentiating the test choice from the alternatives, through an internal dialogue in which ambiguity about tastes is resolved so that features where the test choice has an advantage are emphasized, through sharpening of perceptions of the favorable attributes of the test choice and unfavorable attributes of alternatives, and through restructuring of the choice situation by adding or resurrecting alternatives. There may also be consolidation of perceptions following choice, to reduce dissonance and promote development of rules and principles for future decisions.
Outside a relatively narrow domain where choices are driven by the goal of satisfying visceral needs, psychologists argue that decisions are often the result of application of attitudes and moral principles. In this view, humans often approach decisions as problem-solving tasks, seeking exemplars that suggest simple choice rules and reduce cognitive effort; see Payne, Bettman, and Johnson (1992). Even in the emotional realm, where "out of control" behavior appears anything but rational, affect may operate, internally and externally, as a device to promote self-interest; see Frank (1990). The proverb "Learn to complain without suffering" illustrates use of a meta-rational rule for manipulation of affect.
Psychologists use the terms problem-solving, reason-based, or rule-driven to refer to behavioral processes that override cost-benefit calculations, relying instead on principles or analogies to guide choice. Drazen Prelec (1991) distinguishes this view of decision-making from utility-maximization models by the cognitive processes involved: "Decision analysis, which codifies the rational model, views choice as a fundamentally technical problem of choosing the course of action that maximizes a unidimensional criterion, utility. The primary mental activity is the reduction of multiple attributes or dimensions to a single one, through specification of value trade-offs. For rule-governed action, the fundamental decision problem is the quasi-legal one of constructing a satisfying interpretation of the choice situation. The primary mental activity involved in this process is the exploration of analogies and distinctions between the current situation and other canonical choice situations in which a single rule or principle unambiguously applies." Prelec goes on to conclude: "The purpose of rules must be derived from some weakness of our natural cost-benefit accounting system, and one might expect to find rules proliferating in exactly those choice domains where a natural utilitarianism does not
produce satisfactory results." Prelec identifies situations where cost-benefit calculations get into difficulty as
ones where there is a mismatch between cost and benefits in terms of time, saliency, or scale. Consider the question of whether to fasten one's seat belt when driving. A Chicago man at the start of a trip will compare the time-cost of buckling up with the probabilities of avoiding injury, given driving conditions. The difficulty with the utilitarian calculation is that one is trading off a small immediate time cost

RATIONALITY FOR ECONOMISTS?

83

against an improbable large future loss that is difficult to anticipate and evaluate; see Fredrickson and Kahneman (1993), Kahneman, Fredrickson, Schreiber, and Redelmeier (1993), Lowenstein (1988), and Lowenstein and Schkade (1998). This creates a saliency mismatch where errors in handling uncertainty or evaluating the tradeoff between minor inconvenience now and injury in the future may lead to tactical choices that clearly contradict strategic self-interest. A "sensible self' might decide that this calculus is too tedious, or too prone to misjudgment, and adopt the rule "always fasten your seat belt." Going further, seat belt laws can be interpreted as social recognition that rules are needed to override deficient individual cost-benefit calculations.
There is nothing in rule-driven behavior per se that is inconsistent with the Debreu-Deaton-Muellbauer view ofthe economically rational consumer; rules may simply facilitate the consumer's life-course strategic preference maximization. This could be true even if rule-driven behavior is apparently inconsistent with the Chicago-man model. For example, suppose you look at whether consumers buckle up on trips of various descriptions. You might be led to conclude that consumers are irrational, either overestimating small probabilities because they always buckle up, or underestimating them because they rarely buckle up. However, strategically optimal behavior will appear tactically non-optimal precisely when the purpose of strategy is to avoid tactical decisions that have dangerous long-run implications.
The psychological view of rule-driven procedures is that they come not from overarching strategic rationality, but rather are learned via the process in which children acquire self-control, learning to delay gratification, until in normal adults some degree of abstinence and control becomes an end in itself. Processes of precommitment, particularly adoption of rules or principles, become an important part of behavior. Conduct in an abstract choice situation is likely to be determined by deciding which principles apply. In this view, there is no reason for choices in different situations to be mutually consistent.
To test for the presence of rule-driven behavior, an experiment you can try at home is to ask a friend for the payment they would require today to give up their right to vote (WTA) in the next election, and alternately the maximum poll tax they would pay today to have the right to vote (WTP) in this election. For most people, WTA is much larger than WTP. A utilitarian rationalization, requiring that each individual's indifference curve be kinked at one vote no matter what his circumstances, is implausible. A more plausible explanation is that consumers are guided by two principles, "voting is a fundamental entitlement; you should not have to pay for it," and "it is immoral to sell a fundamental entitlement."
Since many of the features of the psychological views of decision making just described are rooted in the work of Kahneman and Tversky, I will call this view the K-T man. Beyond the obvious scientific question of where the truth lies between Chicago man and K-T man, there is a natural question for economists to ask: How deeply do cognitive anomalies infect economic market behavior and economic data, and how much of the edifice of economic analysis, particularly demand

84

McFADDEN

forecasting and project evaluation, can be preserved? The answer will depend critically on how rationality fails. It is possible that the standard model of rationality works well in some circumstances, where repetition and the experience of market rewards train consumers to adopt behavior rules that are consistent with rationality. It is also possible that consumers conform to the rational model at some points in the decision process, but not in others. For example, it may be the case that perceptions are particularly susceptible to cognitive illusions, but the evolution of preferences follows a rational template. In this case, behavior may be inconsistent with the Chicago-man model, even in some market situations, but fundamentals exist that form a basis for economic analysis.

2. Experimental evidence on rationality
I will summarize some of the evidence for the conclusion that the Chicago-man model is false, and offer my own assessment of the sources, scope, and significance of this failure. There are excellent surveys of behavioral decision theory by Camerer (1998), Machina (1989), Rabin (1997), and Thaler (1991); to reduce overlap, I abbreviate my discussion of the areas of choice under uncertainty and behavior in games which are emphasized in these surveys. Table 1 lists major cognitive anomalies, and gives a capsule description of each. Calling these phenomena "anomalies" does not necessarily mean that they are uncommon, or that they are inconsistent with rationality at some level of abstraction.
The text expands some of the descriptions in Table 1 that are incomplete and overly general. The list is divided somewhat arbitrarily into four major areas dealing with information processing and formation of perceptions (Context, Reference Point, Availability, and Superstition) and two major areas dealing with the process of structuring the cognitive task (Process and Projection). The list is incomplete, and has considerable overlap. For example, prominence, availability, and status quo effects may all be manifestations of a phenomenon that less accessible information is discounted or ignored; temporal and rule-driven anomalies are two faces of the ways humans deal with time perception and delayed gratification.

Context effects
The anomalies in this group arise because the presentation of information influences how it is processed. Framing refers to the format in which alternatives, particularly lotteries, are presented. In a Kahneman and Tversky (1984) experiment, subjects are told that a new disease is expected to kill 600 people, and then given the choice between alternatives A and B in the table below, or in a second

RATIONALITY FOR ECONOMISTS?

85

Table 1. Cognitive anomalies

Effect

Description

CONTEXT

Anchoring

Judgments are influenced by quantitative cues contained in the statement

of the decision task

Context

History and presentation of the decision task influence perception and

motivation

Framing

Equivalent lotteries, presented differently, are evaluated differently

Prominence

The format in which a decision task is stated influences the weight given

to different aspects

Saliency

Subjects are inconsistent in selecting and weighting the information

judged salient to a decision task

REFERENCE POINT

Asymmetry

Subjects show risk aversion for gains, risk preference for losses, and weigh

losses more heavily

Reference point

Choices are evaluated in terms of changes from an endowment or status

quo point

Status Quo/Endowment Current status and history are favored relative to alternatives not

experienced

AVAILABILITY

Availability

Responses rely too heavily on readily retrieved information, and too little

on background information

Certainty

Sure outcomes are given more weight than uncertain outcomes

Focal

Quantitative information is retrieved or reported categorically

Isolation

The elements of a multiple-part or multi-stage lottery are evaluated

separately

Primacy and Recency Initial and recently experienced events are the most easily recalled

Regression

Idiosyncratic causes are attached to past fluctuations, and regression to

the mean is underestimated

Representativeness

High conditional probabilities induce overestimates of unconditional

probabilities

Segregation

Lotteries are decomposed into a sure outcome and a gamble relative to

this sure outcome

SUPERSTITION

Credulity

Evidence that supports patterns and causal explanations for coincidences

is accepted too readily

Disjunctive

Consumers fail to reason through or accept the logical consequences

of actions

Superstition

Causal structures are attached to coincidences, and "quasi-magical"

powers to opponents

Suspicion

Consumers mistrust offers and question the motives of opponents,

particularly in unfamiliar situations

PROCESS

Rule-Driven

Behavior is guided by principles, analogies, and exemplars rather than

utilitarian calculus

Process

Evaluation of outcomes is sensitive to process and change

Temporal

Time discounting is temporally inconsistent, with short delays discounted

too sharply relative to long delays

PROJECTION

Misrepresentation

Subjects may misrepresent judgments for real or perceived strategic

advantage

Projection

Judgments are altered to reinforce internally or project to others a

self-image

86

McFADDEN

experiment, between alternatives C and D:

Experiment 1 (N = 152)
A: 200 people saved
B: 600 saved with probability 1/3 0 saved with probability 2/3

Choice
72% 28%

Experiment 2 (N = 155)
C: 400 people die
D: Odie with probability 1/3 600 die with probability 2/3

Choice
22% 78%

The alternatives A and C have identical outcomes, as do the alternatives B and D. Nevertheless, changing the frame from lives saved to lives lost significantly alters choice. The conclusion of Kahneman and Tversky is that humans think differently about gains and losses from the status quo, and if one frames a decision task in a way that alters the perceived status quo, then one can alter choice behavior; see also Tversky and Kahneman (1981) and Sonnemans, Schram, and Offerman (1994).
Context refers more generally to the current and historical setting in which a choice is offered. For example, Simonson and Tversky (1992) report an experiment involving microwave brands A and B, and a more expensive model A' of brand A. They found that the proportion of consumers choosing A was higher from the choice set {A, A', B} than from the choice set {A, B}, a violation of the regularity property of stochastic preference maximization. Apparently, the presence of the expensive model A' in the choice set made A appear to be a bargain, and thus more attractive; see also Huber, Payne, and Puto (1982). Unlike the canonical setting for rational choice, the consumers in these experiments are presented with alternatives that in themselves involve uncertainty about their true attributes. Consumers arefaced with the statistical exercise of drawing inferences about these attributes. Context effects might appear as the result of such inference, even if information processing is "rational." For example, in choice among appliances, consumers are aware that price is usually correlated with quality, but that brands of a given quality may also vary in price. Observed price alone is not sufficient to identify the quality of a product, and whether it is a bargain at this price. Additional information, such as the information that the manufacturer of A sells another model A' with more features at a considerably higher price, might lead the consumer to infer that A is in fact a bargain. Simonson and Tversky anticipated this problem, and circumvented it by giving consumers a catalogue to read at the start of the experiment that contained information on all the appliance brands. Thus the information available to the consumer remains the same, even when the choice set is altered. Then, the experiments indicate that the inconsistencies that consumers show arise because the context alters the saliency of available
information. In a related finding, Tversky, Sattath, and Slavic (1988) show that the decision
format can change the prominence given to different attributes of alternatives. In

RATIONALITY FOR ECONOMISTS?

87

choice among products, price is given more weight in a direct choice task than it is when consumers are asked to specify an attribute level (such as price) that makes two alternatives indifferent. The preference reversal phenomenon in choice among lotteries may arise from the effect of format on prominence; see Delquie (1993), Grether and Plott (1979), Machina (1989), and Tversky, Slavic, and Kahneman (1990). Obviously, marketers can frame their presentations to take advantage of such systematic biases.
Anchoring describes a family of effects observed in many psychological studies of beliefs about uncertain quantities, such as the length of the Amazon or the height of the tallest redwood; see Tversky and Kahneman (1974). Subjects in these studies are asked to judge whether a particular value (the anchor) is higher or lower than the uncertain quantity, before stating their own estimate. A robust result is that subjects start from the anchor, and fail to adjust fully to their base beliefs, so that their estimates are pulled toward the anchor. Even an explicitly uninformative prompt, such as the output of a random device, can operate as an anchor. The usual explanation for the phenomenon of anchoring is that the anchor value creates, at least temporarily, the possibility that the quantity to be estimated could be near this value. It is possible to construct models of rational anchoring in which subjects behave as Bayesian statisticians who treat the anchor as a datum that with some probability is valid and can be used to update a prior distribution of possible values. However, the fact that anchoring occurs even when the anchor value is explicitly random indicates that much of the effect comes from how humans handle uncertainty, rather than from rational statistical processing of information.
In an experimental study analyzed by Green, et al. (1996), anchoring effects were investigated for both estimation tasks and public project valuation tasks. An initial sample of subjects were asked unprompted open-ended questions. Then a second sample was recruited, and asked referendum (yesjno) questions as to whether their estimates exceed specified anchors; the anchors were picked by experimental design from specified quantiles of the first sample responses. The finding was that, compared to the first sample, the anchoring provided by the referendum cue value increased minority "YesjNo" responses (e.g., an anchor corresponding to the 90 percent quantile of the open-ended responses would yield 20 percent rather than 10 percent "Yes" referendum responses). Consequently, anchors located in the upper tail of a skewed distribution of unprompted open-ended responses produce a dramatic upward shift in the apparent distribution of responses when it is deduced from referendum data alone.
A large panel study, the Asset and Health Dynamics of the Oldest Old (AHEAD) survey, is tracking the economic and health status of elderly households. To reduce serious non-response problems, consumers who respond "Don't Know" to economic questions are asked to give "YesjNo" responses to an unfolding series of values that bracket the individual's economic value. This elicitation procedure, called the unfolding bracket method, is very successful in increasing response rates, but responses may be influenced by anchoring effects. Hurd et al. (1997) analyzed an experimental module in this survey that varied the levels and sequence of prompts, and found that there is indeed economically significant anchoring, with

88

McFADDEN

estimated mean household consumption varying by as much as a factor of two depending on the sequence of prompts. Hurd (1999) finds significant anchoring in a similar experiment conducted in a panel of consumers approaching retirement. These studies conclude that except for idiosyncrasies in tasks caused by responses at focal points, anchoring effects are systematic and largely predictable across a spectrum of tasks, economic and non-economic. The studies recommend varying anchors by experimental design so that their impact can be identified and compensated for.
In addition to economic household surveys where one would expect to see anchoring effects very similar to those found in psychological experiments, anchoring may affect market transactions involving complex commodities. For example, houses and automobiles are typically sold by bargaining, starting from initial price quotes. It would be surprising if perceptions were not colored by the initial quote. An implication for economic analysis is that one should be cautious in taking market data at face value in project evaluation.

Reference point effects
A reference point is a base position or alternative from which changes are assessed. In particular, in consumer behavior under uncertainty, the reference point is the consumer's position before entering the market for lotteries. For a classically rational economic consumer, only final allocations matter, and the reference point is irrelevant. However, Kahneman and Tversky (1979, 1984) find that in choice among lotteries, the pain of marginal losses apparently exceeds the benefit of comparable gains. Consequently, consumers display loss aversion, leading them to reject some actuarially favorable lotteries even at small scale, contrary to the implications of expected utility maximization. Another interpretation is that the consumer gives the status quo a privileged position, and may refuse to trade away from it. This effect also appears when there is no uncertainty, in the form of a gap between willingness-to-accept (WTA) less of a commodity and willingness-to-pay (WTP) for more of this commodity, starting from the consumer's initial position. Thaler (1980) calls this the endowment effect; see also Kahneman, Knetsch, and Thaler (1991) and Samuelson and Zeckhauser (1988).
Experiments by Thaler and Johnson (1990) and Kahneman, Knetsch, and Thaler (1990) establish that endowment effects are not only pervasive and substantial, but also almost instantaneous, so that they are not coming from sentimental attachment to long-term possessions. There are economic factors that will induce some differences between WTA and WTP, arising from diminishing marginal rates of substitution or from income effects. However, the magnitude of the endowment effect and features built into the experiments eliminate these as plausible explanations.
One of the implications of the endowment effect is that consumers will refuse to trade away from an endowment point for a range of relative prices. As a conse-

RATIONALITY FOR ECONOMISTS?

89

quence, fewer market transactions will occur than the usual calculus of marginal utilities would suggest. There are some conventional economic arguments for a paucity of transactions: the transactions cost of monitoring and completing small trades, and asymmetric information, or fear of asymmetric information, between traders. If market trades are viewed as having uncertain outcomes, above and beyond lottery risk, due to the potential perfidy of trading partners, then there are "rational" reasons to avoid trades that promise only modest gains. The reference point effect for lotteries, the endowment effect for "risk-free" objects, and mistrust of trades may all be facets of the same process of learning to be suspicious of market offers.

Availability effects
The anomalies in this group arise from the way humans process information to form beliefs. Tversky and Kahneman (1971) and Kahneman and Tversky (1973, 1982) have documented several persistent errors that are made in handling probabilities: a representativeness effect in which subjects fail to use Bayes' law, and instead overestimate the unconditional probability of an event A when the conditional probability of A given B is high, even though the probability of B is low; an availability effect in which consumers place too much weight on easily accessible or salient information, and too little on base rates, and fail to account properly for sampling variation; and a regression effect in which subjects interpret observed changes as idiosyncratic shifts in the underlying structure rather than random fluctuations, and fail to anticipate regression to the mean. These biases appear to carry over to choice situations where consumers infer properties of the alternatives from their presentation; see Kahneman, Slovic, and Tversky (1982).
Several other cognitive illusions are related to the effort required to retrieve various pieces of information; these might all be referred to as availability effects. Examples are primacy and recency effects, in which initial or most recent experiences are more readily recalled than ones in between, saliency effects in which the information that seems most relevant at the moment is overemphasized relative to other information, and status quo effects in which historical experience is more easily retrieved than hypothetical alternatives. Framing and anchoring phenomena may be related to availability as well, with the question itself providing immediately accessible information. The possible impacts on economic survey responses are obvious: information on social security income is more accessible than asset income, so the former may provide an internal anchor for the latter; beliefs about mortality may be unduly influenced by the ages attained by relatives and friends, to the exclusion of baseline information from life tables; recent changes in health status may be weighed too heavily in predicting future health status, with insufficient allowance for regression to the mean.
Focal effects occur when categorical approximations are used to minimize recall and reporting effort; see Poulton (1989, 1994). Mentally, we may retrieve quantita-

90

McFADDEN

tive memory via a series of referendum queries, or even organize quantitative information in a hierarchical, categorical format, so that focal responses are more available than non-focal ones. Open-ended responses on many economic variables exhibit the focal phenomenon, with responses piled up at rounded off numbers. For example, travel times are usually reported in five minute intervals, willingness to pay for a public good in multiples of $5, etc. Hurd et al. (1997) found in AHEAD data that focal responses are more common among the cognitively impaired, and that the probabilities of giving focal responses are correlated across questions.5 The focal response phenomenon can have significant impacts on analysis of economic data. Since focal responses concentrate at rounded-off dollar amounts, growth or inflation are captured mostly through switches between focal points, rather than marginal adjustments. "No change" may be a focal point in expectations questions. Focal effects interact with context, as changing reporting periods or units changes the natural focal points.
Let (x1, p 1; x2 , p 2; ··· , xk, Pk) denote a lottery that has payoff xk with probability Pk· By convention, omit xk,Pk if xk = 0, and omit Pk if Pk = 1. Then the lottery that pays $100 with probability 0.4 and zero otherwise is denoted (100,0.4), and a sure payoff of $100 is denoted (100). There are a number of cognitive anomalies specific to evaluation of lotteries. The classic anomaly is the Allais paradox, illustrated by the following experiment of Kahneman and Tversky (1979a):

Experiment 1 (N = 95)
A:
Lottery (4000,0.8)
B:
Sure(3000)

Choice
20% 80%

Experiment 2 (N = 95)
C: Lottery (4000,0.2)
D: Lottery (3000,0.25)

Choice
65% 35%

A statistically significant number of subjects choose B over A and C over D. Expected utility maximization using the objective probabilities and a utility of outcomes v(x) scaled with v(O) = 0 implies from the first experiment that
v(3000)jv(4000) > 0.8 for a majority of subjects. The second experiment implies
the opposite inequality for a majority of subjects, a contradiction of the substitution axiom in von Neumann-Morgenstern utility theory.
A stylized summary of choice behavior among lotteries, deduced from this experiment and others, is that consumers display (i) a reference point effect, evaluating lotteries as changes from a reference point that may be sensitive to framing, (ii) an asymmetry effect in which the consumer is more sensitive to losses than to gains, displaying risk aversion for gains and risk seeking for losses, (iii) a certainty effect in which sure outcomes are overvalued relative to lotteries, (iv) an isolation or cancellation effect in which common aspects of alternative lotteries are ignored when they are compared, and (v) a segregation effect in which a riskless component of a lottery is evaluated separately from the risky component.

RATIONALITY FOR ECONOMISTS?

91

Kahneman and Tversky (1979a) and Tversky and Kahneman (1992) have formulated a partial theory of risky choice that accommodates these experimental findings; they call this prospect theory. This theory postulates that choice is achieved by maximization of a weighted value function of gains and losses: The shape of the value function conforms to the asymmetry effect. The weighting function overweights improbable events and underweights probable events. An important psychological part of the theory is that consumers first engage in an editing process that determines the reference point and the perception of lottery outcomes as gains or losses. Segregation and isolation effects lead to different evaluations of lotteries that mix positive and negative outcomes from those that have only non-negative (or non-positive) outcomes. Prospect theory is partial in that it does not spell out except via anecdotes the operation of the editing process to determine the critical reference point and the perception of lotteries, particularly complex or multi-stage lotteries.
Let v(x) denote the value function and 7T(p) the weight function from prospect theory, with v(O) = 0. The operation of the theory can be illustrated by application to an experiment reported by Tversky and Fox (1995). The table below gives the median net willingness-to-pay w(X, P) for a lottery that pays X with probability P, and zero otherwise; X can be either positive or negative. The experimental results show the asymmetry effect, with risk aversion for gains and risk seeking for losses, reversed for small probabilities due to overweighting.

Probability
Low
(E payoff = ± 5)
High
(E payoff = ± 95)

Gain
w(100,0.05) = 14 (risk seeking)
w(100,0.95) = 78 (risk aversion)

Loss
w( -100,0.05) = -8 (risk aversion)
w(- 100,0.95) = - 84 (risk seeking)

Kahneman and Tversky argue that when asked to pay a net amount W for a lottery
(x, p ), consumers segregate the certain payment Wand the lottery, evaluating each in isolation, without adjusting their reference point for the payment of W. Thus, an
offer of the lottery ticket (x, p) at price W is not evaluated the same way as a free lottery ticket (x - W, p; - W, 1 - p). In the experiment above, the median re-
sponse w(100,0.05) = 14 implies 7T(0.05) · v(lOO) + v( -14) = 0. The experimental
outcomes are easily represented by the prospect theory model, say by postulating 7T(0.05) = 0.2, 7T(0.95) = 0.9, and a piecewise linear v(x) function through the points given below:

X

-100

-78

-14

0

8

84

100

v

-200

-180

-40

0

20

90

100

On the other hand, Mark Machina has pointed out that if the payment W and the lottery ticket (x, p) were evaluated the same as the simple lottery (x - W, p; W, 1 - p ), as expected utility theory would require, then the experimental results

92

McFADDEN

are inconsistent with a monotone increasing value function, even if one allows for the possibility of biased weighting of probabilities.
A possible explanation for the certainty effect is that consumers suspect that unforeseen events may occur to prevent completion of a lottery. Thus, they may seek to postpone booking sure losses in the hope that an unforeseen event might reverse them, and seek to immediately book sure gains for the same reason. Certainty and asymmetry effects are sharpened if consumers mistrust their trading partners, and suspect that unforeseen events in which they lose are more likely than those in which they gain. For example, a consumer whose decisions are consistent with the prospect theory model just described is vulnerable to a mugs' game in which he would purchase the lottery ticket (100,0.05) at the apparently favorable price of $13, and once this is in his pocket and part of his reference point, would sell this lottery ticket at the apparently favorable price of $7. The consumer then ends up where he started, but $6 poorer. A strategic defense is to mistrust one's perceptions and make a rule to avoid gambles; a psychological defense is to reduce dissonance by attributing losses to cheating by opponents.

Superstition effects
One of the implications of almost any model of rational economic choice under uncertainty is that two consumers who have different beliefs about the probability that an event will occur should find it mutually advantageous to wager on this event. Hildreth (1974) noted that this mutual advantage does not seem to translate into ubiquitous betting:
Ordinary conversations suggest that different opinions on future events are common and it is not hard to think of people who must surely have widely different relative needs in particular events. With the multitude of possible people-event combinations in any large community, it would seem at first glance that there must be many potential mutually favorable bets. Why is more betting by the general public (as opposed to habitual gamblers) not observed?
In a response, McFadden (1974) suggests some cognitive factors that are consistent with the Kahneman and Tversky findings, and provide one possible interpretation for some of the observed behavior:
Professor Hildreth has suggested that when individuals consider wagers against the background of the 'grand lottery of life', they may not view as independent the events determining the outcomes of the 'grand' lottery and the wager. We first ask whether it is likely that personal probabilities would tend to display this non-independence; in particular, more likely than 'objective' probabilities determined by relative frequencies. An examination of human psychology suggests an affirmative answer. Chance jolts the harmony of conscious belief; relief from

RATIONALITY FOR ECONOMISTS?

93

this dissonance is gained by imposing an order over chaos, weaving a fabric of cause and effect, out of the jumbled coincidences of random events. The mind accepts and emphasizes those coincidences which reaffirm the perceived order of the universe, ignores and forgets inconsistent data.
This comment goes on to cite evidence from Festinger (1957) and Davidson and Suppes (1957) that personal probabilities will fail to reflect the independence properties of 'objective' probabilities, instead exhibiting correlations between events which are in fact independent. Tune (1964) and Kahneman and Tversky (1972) document experimentally that individuals intuitively reject randomness when they see recognizable patterns or streaks, systematically underestimating the probability that these can occur by chance. These biases reinforce the influence of random coincidences on beliefs and behavior. Selective memory in which coincidences of favorable or unfavorable events are remembered more readily than non-coincidences may be a cognitive mechanism that induces subjective correlation between objectively independent events, and induces belief in "streaks" of good or bad luck. Individuals may also seek "emotional and spiritual sustenance" by searching selectively for confirmation of current beliefs; see Sterman (1994). Paraphrasing Umberto Eco, if two things don't fit, a credible individual may nevertheless believe both, thinking that somewhere, hidden, must be a third thing that connects them. Both selective memory and selective search cause individuals to be superstitious, perceiving correlation between their own actions and outcomes of random events even when such correlation is implausible. Superstition appears irrational, but may in fact be consistent with a complex non-ergodic world view in which a Bayesian never accumulates sufficient objective data to rule out a mental model in which Nature is conspiratorial and personal.
Shafir and Tversky (1992) have examined experimentally the tendency of consumers to behave as if they believe that opponents in games have an edge in information. They ask subjects to play the one-shot prisoner's dilemma game below:

SUBJECT

Cooperate Compete

OPPONENT

Cooperate S: 75,0:75 S: 85,0:25

Compete S: 25,0:85 S: 30,0:30

When subjects are told in advance that their opponent has chosen to compete, virtually all subjects (97%) choose to compete. When they are told in advance that their opponent has chosen to cooperate, the rational response is to compete. In fact, 84% choose to compete; the remaining 16% apparently make an ethical judgment that cooperation should be met with cooperation. When the opponent's choice is not announced in advance, one would expect a division intermediate between these cases, since there is less ethical imperative to cooperate when the

94

McFADDEN

opponent's action is unknown than when it is known to be cooperative. However, in this case 37% of the subjects choose to cooperate. Thus, uncertainty changes behavior even if there is a single optimal action when uncertainty is removed. Shafir and Tversky call this a disjunctive effect, in which subjects do not reason through the consequences of the removal of the uncertainty, a violation of the sure-thing principle; see Tversky and Shafir (1992). These authors find that this effect is enhanced when subjects are told that the opponent has been very accurate in predicting what people are going to do and in matching their action; subjects often play cooperatively, even if the opponent's move is explicitly made and sealed in advance, so that this is never rational. Thus, subjects behave as if their opponents know more than themselves about their own behavior, or as if they can by setting an example influence the behavior of their opponent. Shafir and Tversky term this "quasi-magical" thinking, since subjects may consciously reject the idea that the opponent has supernatural powers or that current actions could influence earlier moves of the opponent, and yet superstitiously avoid actions that could give a bad outcome if there were such powers or linkages.
Superstition, in the form of mental models containing causal structures that are not supported by objective frequentist evidence, or in the form of suspicion that opponents have "quasi-magical" inside information, is a phenomenon that may explain a variety of anomalies such as reference point or status quo effects and the certainty effect. There are two, subtlety different, sources for superstition. One is a true bound on rationality arising from limited, selective memory, or from a confirmation bias that selectively seeks evidence to support beliefs. This leads to biased subjective probabilities that highlight coincidence and support occult causal theories even in the face of logical inconsistency. The second is suspicion, beliefs learned from being burned by sharp traders that opponents may have inside information or hidden control even when it appears causally impossible. Suspicion may be a rational rule that provides a defensive against tactically attractive but unsafe actions. Both superstition and suspicion may be psychologically stable states, in that information acquisition, experience, and memory may provide continual reinforcement. Further, the market is ineffective in inducing fully rational behavior, as opposed to defensive behavior induced by superstition and suspicion.

Process effects
The anomalies in this group arise from the ways consumers approach choice problems. Limits on human computational and information processing ability may lead to the adoption of boundedly rational heuristics. Consumers may adopt problem-solving modes and heuristics that at least on the surface are quite different than the process of forming tradeoffs and maximizing utility; see Tversky and Kahneman (1974), Kahneman and Tversky (1979), and Schkade and Payne (1994). Process effects arise because consumers establish aspiration levels or refer-

RATIONALITY FOR ECONOMISTS?

95

ence points and set goals relative to these benchmarks; derive benefits and losses from the decision-making process itself; and respond to perceived interactions between the process and other activities and rules of conduct (including ethical and superstitious beliefs). Thus, an element in the attractiveness of a lottery ticket is the "action" in the random event; other elements are the personal interaction required to pay off or collect on the lottery, and ethical attitudes and superstitious beliefs toward gambles. These benefits and losses need not lie outside the conventional theory of utility maximization. However, behavior inconsistent with rationality can result if process looms too large relative to outcomes in the consumer's consciousness.
Rule-driven choice may lead to behavior that is inconsistent with maximization of current preferences, perhaps because the "sensible self' adopts principles that establish precommitments to prevent the "indulgent self' from excesses that have undesirable consequences latter. However, most behaviorists will argue that ethical systems are assembled by accretion and differentiation, rather than being developed from a rational template. There is evidence that consumers develop commitments to their rules, and view them as more than just devices to regulate tactical behavior; see Baron (1994). Further, there are large individual differences in the rules that consumers state that they follow, and consumers with limited rule systems often fare better than those with complex and rigid rule systems; see Larrick (1993). Money is a prime example of an abstract good for which individuals develop what appear to be elaborate and not necessarily consistent rules or heuristics for how it is accounted for, acceptable and unacceptable uses, and the process as well as the outcome of exchanges of money; see Thaler (1985, 1990) and Prelec and Lowenstein (1997). The homily "Neither a borrower nor a lender be" is a principle for conduct, not an instruction for rational behavior.
Temporal anomalies arise because consumers are inconsistent in time discounting, failing to discount events in the distant future consistently with short-term discounting. The explanation is that short-term gratification delays have a strong effect, while long-term benefits and costs are difficult to perceive now on the same basis as immediate benefits and costs. The argument is that immediate visceral satisfactions are easy to experience (or difficult to not experience), but that humans have difficulty previewing the experience of future gains and losses, particularly if they are uncertain; see Frank (1992), Hoch (1991), and Lowenstein (1988). Temporal anomalies may also arise because of the psychophysical perception of time; see Hermstein and Prelec (1991).

Projection effects
When an experimenter presents a choice task within a limited context, the subject may interpret the problem within a broader, strategic context. Then, responses that are consistent or rational in the broader context may appear irrational when viewed narrowly. The "anomalies" in this group have this form, and in contrast to

96

McFADDEN

the previous groups arise from the experimentalist's failure to correctly assess the context adopted by the subject rather than the cognitive function of the subject.
Economic theory suggests that when subjects anticipate a possible connection between their response and some psychological or economic outcome in which they have an interest, they may have strategic incentives to misrepresent information. To illustrate, subjects asked about their interest in nursing home insurance may overstate their willingness-to-pay (WTP) if they believe a large response will increase the probability they will have this service as an option without committing them to this cost. On the other hand, they may understate WTP if they believe that their actual cost would be tied to their response. In practice, most standard economic surveys have no linkage from response to subsequent economic events that would create incentives for misrepresentation. Further, there is at least fragmentary evidence that subjects are usually truthful when there are no positive incentives for misrepresentation, and even in some circumstances where there are such incentives; see Bohm (1972) and Smith (1979).
There are some areas where there may be strong non-pecuniary incentives for projection of a misleading image. For example, subjects asked questions like "How often do you go to church?" or "How much did you contribute to charity last year?" may give biased responses in order to project a more favorable image to the interviewer and to themselves; see Quattrone & Tversky (1986). In public good valuation surveys, this phenomenon is sometimes called the "warm glow" motivation for overstating WTP for public goods. There are some elementary precautions in economic survey design that decouple responses from economic consequences, and eliminate obvious sources of economic incentives for misrepresentation. One way to control misrepresentation arising from non-pecuniary incentives is to present subjects with tasks that are "ethically neutral." For example, subjects may have no incentive to misrepresent trade-offs between different public goods, even when "warm glow" distorts their stated trade-off between public goods and personal private goods.

Summarizing the behavioral evidence
When one looks at the whole body of experimental studies of cognition and choice over the past twenty-five years, what stands out is that humans fail to retrieve and process information consistently, and this generates a variety of cognitive anomalies, including behavior that makes consumers vulnerable to exploitation in markets. Available, salient information looms too large, and beliefs are distorted because attention to new information is selective. These failures may be fundamental, the result of the way human memory is wired. I conclude that perceptionrationality fails, and that the failures are systematic, persistent, pervasive, and large in magnitude.
There is also substantial experimental evidence that process-rationality fails, with humans adopting a variety of problem-solving modes, rules, and heuristics

RATIONALITY FOR ECONOMISTS?

97

rather than monolithic utility maximization. Many psychologists take the view that preferences are temporary, changing each time the choice problem is reframed. and would argue that even if humans have a rational template for preferences at some deep level, it is so far removed from the problem-solving tools actually used that it is not useful for explaining behavior. An alternative view accepts the proposition that individuals are miserable statisticians who systematically mishandle information and misjudge probabilities, but attributes process anomalies to decision heuristics that preference-rational consumers learn as defense against sharp traders. Which of these views is right matters to economics, since in the second case there may be stable preferences that can be uncovered and used for economic policy analysis. If Tversky's (1977) assessment of human psychology is right, economists will eventually lose this point. Nevertheless, my view of the experimental record is that this coffin has not yet been nailed shut. It is difficult to exclude failures of perception rationality as sources of many observed anomalies. In particular, the evidence against preference rationality is primarily circumstantial, based on the adaptability and malleability of human cognition in general, and on failures of preference axioms for Chicago man in experimental situations that, arguably, do not control for all the unrecognized aspects of objects that can matter to an abstractly preference-rational consumer.

3. Implications for economic survey data
Confronted with the accumulated experimental evidence, economists must recognize that the Chicago-man model does not apply universally, or even regularly, to choices made in non-market contexts. Economic surveys and laboratory experiments present decision tasks that closely resemble those in psychological experiments, and are likely to produce similar cognitive anomalies. This has important implications for non-market data, such as reported assets in household interviews.
Nowhere has this been more evident than in economist's attempts to value non-use public goods, such as endangered species or wilderness areas. A large literature documents the attempts by economists, in the end largely unsuccessful, to treat responses to such questions at face value, without psychometric correction; see Baron (1997), Bishop and Heberlein (1979), Boyle (1989), Boyle et al. 1985, 1993), Carson et al. (1994), Cameron and Huppert (1991), Desvousges et al. (1994), Diamond and Hausman (1994), Harrison (1992), Holmes and Kramer (1995), Hutchinson et al. (1995), Kahneman and Knetsch (1992), McFadden (1994), Siep and Strand (1992), Silberman and Klock (1989), and Whittington et al. (1992). A question on the value of a public good may invoke a rule-driven response rather than a utilitarian one. Examples might be rules that say "be agreeable when it does not threaten self-interest," or "no matter how desirable the cause, it is not my responsibility." When consumers are unclear about the public good, or unsure about the benefits of the proposed action, contextual features that suggest analogies to familiar exemplars may receive particularly high weight. Further, valuation

98

McFADDEN

questions may be posed in ways that make them vulnerable to rule-driven responses. Asking for a trade-off between public goods and money may invoke principles regarding the desirability of protecting the environment, and principles regarding the treatment of money and its appropriate use. Valuation tasks may be affected by the particular rules that consumers use when they put values in dollars, and different patterns might emerge if trade-offs were requested in goods that are more alike in terms of scale and saliency. Good survey design can identify and reduce these effects; it is less clear that it can eliminate them.

4. Implications for economic market behavior
One objection that economists have raised to the applicability of the Tversky and Kahneman results to economic decisions is that systematic departures from rationality, say in the form of intransitivity induced by sensitivity of preferences to context or reference point, will be punished through the actions of arbitragers. In this view, traders will devise mugs' games to exploit irrationalities, and as a result the market will teach consumers to avoid the obvious manifestations of irrationality; see Russell and Thaler (1988). This argument is not without merit, but it has two limitations. First, arbitragers are pervasive only in a limited number of highly organized markets, such as financial markets. It is by no means clear that the consumer is sufficiently engaged in many markets, or that the potential arbitragers in these markets are active and aggressive enough, to provide the discipline required to eradicate irrational behavior: "There is a fool reborn every minute." Second, not all departures from rationality will open opportunities for arbitrage. Specifically, reluctance to trade, whether induced by reference point or endowment effects, or otherwise, will tend to protect the consumer from arbitragers, and may in addition shelter other irrationalities that by themselves would be vulnerable to arbitrage. The casual observation that consumers participate in only a limited number of the available markets, and are suspicious of attractive but unfamiliar opportunities, may be a large-scale manifestation of strategic defensive behavior. Reluctance to gamble may be the specific result of the ease with which arbitragers can exploit irrationalities in these markets; see McFadden (1974) and Camerer (1987).
What are the economic implications of cognitive illusions that survive market forces? First, the way consumers process price information is part of the folklore of marketing, and plays a role in determining the products the consumer sees in the marketplace. For example, restaurateurs know that consumers use price as a guide to quality of wines, and that the second lowest priced wine is usually the best seller on the wine list. This effect is enhanced if a clearly lower quality wine is offered at a price only slightly below the targeted seller, making the targeted wine appear to be a good buy. Similarly, supermarkets will typically carry a low-quality generic brand priced slightly below the house brand, making the latter seem like a better deal. Second, marketers are aware of the importance of establishing and consoli-

RATIONALITY FOR ECONOMISTS?

99

dating habits, and design product launches to achieve and sustain feasible levels of market penetration. By reframing product descriptions, product perceptions can be changed; see Gourville (1996). Thus, these biases in consumer behavior are recognized, and alter the consumer's market environment. Economics needs to catch up to marketing to understand the extent to which the mix and presentation of products reflects anomalies in consumer behavior.

5. Conclusions
Chicago man is an endangered species. Behavioral decision theory has accumulated experimental evidence that severely restricts his maximum range, and he is not safe even in markets for concrete goods where he was once thought secure. His limits are determined primarily by failures of perception and process rationality. The experimental evidence provides no support for preference rationality, although the evidence contradicting preference rationality is mostly circumstantial. More seriously, failures of perception and process rationality may render behavior so erratic that even if they exist, preferences are largely irrelevant to the explanation of observed behavior.
Faced with this evidence, what should economists do? The challenge is to evolve Chicago man in the direction of K-T man, adopting those features needed to correct Chicago man's most glaring deficiencies as a behavioral model, and modifying economic analysis so that it applies to this hybrid. This is a challenging task, but not an impossible one: many economic propositions hold under much weaker rationality assumptions than the Chicago-man model, and K-T man obliges us by using rules and heuristics that in many cases do not drift too far from Chicago-man behavior. Both theoretical and empirical study of economic behavior would benefit from closer attention to how perceptions are formed and how they influence decision-making. If the cognitive anomalies that do appear in economic behavior arise mostly from perception errors, then much of the conventional apparatus of economic analysis survives, albeit in a form in which history and experience are far more important than is traditionally allowed. Even social choice theory will work, in an interpretation that makes welfare comparisons relative and produces social optima that are dependent on history and path. In economic measurement, particularly in non-market forms but also in market data, economists should be sensitive to the impact of cognitive anomalies on observed responses, and seek methods to minimize these response errors.
How far will economics have to travel to reach solid behavioral ground? Some psychologists suspect that in seeking to measure deeply held, stable preferences, there is no "there" there; that preferences are illusionary, the temporary product of rule-driven processes and problem-solving constructions. If so, more elaborate surveys will simply generate more complex, but no more fundamental, stated preferences and choices. On the other hand, evolution and learning may condition consumers to adopt broad strategic principles that are not so "irrational" as to

100

McFADDEN

endanger survival, and which in some rough-and-ready sense promote "happiness." Behavior in markets, surveys, and experiments may generally conform to these principles, with "superficial" errors caused by perceptual biases and mistakes in formulating the cognitive tasks. Then, careful attention to the processes that consumers use to define tasks (see Fischhoff, Welch, and Frederick, 1999) and construct preferences (see Payne, Bettman, and Schkade, 1999) may allow one to look behind the superficial errors to uncover stable principles, attitudes, and preferences upon which a new economic analysis might be built.

Notes
1. This paper is dedicated to the memory of Amos Tversky, whose brilliant life profoundly influenced psychology and economics. In the subject known as Behavioral Decision Theory, Tversky's hand appears everywhere, through his papers, and through his ingenious and defmitive experiments that have made clear the importance of heuristics and judgment in human cognition. He will be counted among the great minds of the 20th Century. It was a delight and an education to have been his friend. Early versions of this paper were presented at the European Meetings of the Econometric Society, Istanbul, 1996, and at the NSF Symposium on Eliciting Preferences, University of California, Berkeley, July 1997. I have benefitted from discussions and comments from Moshe Ben-Akiva, Baruch Fischhoff, Tommy Garling, Danny Kahneman, Mark Machina, Charles Manski, John Payne, and Drazen Prelec. Research support from the E. Morris Cox Fund, and assistance for preparation of the paper from the Santa Fe Institute, are gratefully acknowledged.
2. There is an early history of economic thought on risk-taking behavior, in the work of Bernoulli (1736), Fisher (1930), Keynes (1921), Menger (1934), Knight (1921), and Ramsey (1931), as well as important developments by Friedman and Savage (1948), Marschak (1950), and Arrow (1951) that parallel the von Neumann-Morganstern contribution.
3. Some degree of uncertainty surrounds any decision, due to uncertainty about the attributes of alternatives, conditions under which delivery will occur, and indirect social and strategic implications of the choice.
4. Recognizing and compensating for one's limits are called meta-cognition and calibration 5. Cognitive impairment is measured using a battery of questions to test several domains of cognition:
immediate and delayed word recall, counting backwards, and naming of public figures, dates, and objects; see Herzog and Wallace (1997). No attempt is made to distinguish physical and psychological sources of impaired cognitive performance.

References
Ajzen, I. (1987). "Attitudes, Traits, and Actions: Dispositional Prediction of Behavior in Personality and Social Psychology." In L. Berkowitz (ed.), Advances in Experimental Social Psychology, Vol. 20, pp. 1-63. San Diego: Academic Press.
Allais, A. (1953). "Le Comportement de !'Homme Ratione! Devant le Risque, Critique des Postulates et Axioms de !'Ecole americaine," Econometrica 21, 503-546.
Anslie, G. (1982). "Beyond Microeconomics: Conflict among Interests in a Multiple Self as a Determinant of Value." In J. Elster (ed.), The Multiple Self. Cambridge, UK: Cambridge University Press.
Arrow, K. (1951). "Alternative Approaches to the Theory of Choice in Risk-Taking Situations," Econometrica 19, 404-37.

RATIONALITY FOR ECONOMISTS?

101

Baron (1994). "Nonconsequentialist Decisions," Behavioral and Brain Sciences 17, 1-42. Baron, J. (1997). "Biases in the Quantitative Measurement of Values for Public Decisions," Psychologi-
cal Bulletin 122, 72-88. Becker, G. (1993). "The Economic Way of Looking at Behavior," Journal of Political Economy, 101,
385-409. Bernoulli, D. (1738). "Specimen Theoriae Novae th Mensura Sortis," Commentarii Academiae Scien-
tiarnm Imperiales Petropolitanae 5, 71-192. Bishop, R. and T. Heberlein. (1979). "Measuring Values of Extra-Market Goods: Are Indirect
Measures Biased?" American Journal ofAgricultural Economics 61, 926-930. Bohm, P. (1972). "Estimating Willingness to Pay: An Experiment," European Economic Review 3,
111-130. Boyle, K. (1989). "Commodity Specification and the Framing of Contingent-Valuation Questions,"
Land Economics 65, 57-63. Boyle, K., R. Bishop, and M. Welsh. (1985). "Starting Point Bias in Contingent Valuation Bidding
Games," Land Economics 61, 188-94. Boyle, K., M. Welsh, and R. Bishop. (1993). "The Role of Question Order and Respondent Experience
in Contingent-Valuation Studies," Journal of Environmental Economics and Management 25, (Part 2), S80-S99. Camerer, C. (1987). "Do Biases in Probability Judgment Matter in Markets? Experimental Evidence," American Economic Review 77, 981-997. Camerer, C. (1998). "Progress in Behavioral Game Theory," Journal ofEconomic Perspectives, forthcoming. Carson, R. et a!. (1994). "Contingent Valuation and Revealed Preference Methodologies: Comparing the Estimates for Quasi-Public Goods," University of California, San Diego Department of Economics Working Paper 94-07. Cameron, T. and D. Huppert. (1991). "Referendum Contingent Valuation Estimates: Sensitivity to the Assignment of Offered Values," Journal of the American Statistical Association 86, 910-918. Chipman, J. (1960). "The Foundations of Utility," Econometrica 28, 193-224. Coupey, E. (1994). "Restructuring: Constructive Processing of Information Displays in Consumer Choice." Journal of Consumer Research 21, 83-89. Davidson, D. and P. Suppes. (1957). Decision Making. Stanford, CA: Stanford University Press. Deaton, A. and J. Muellbauer. (1980). Economics and Consumer Behavior. Cambridge, UK: Cambridge University Press. Debreu, G. (1959). Theory of Value. New York: Wiley. Delquie, P. (1993). "Inconsistent Trade-offs between Attributes: New Evidence in Preference Assessment Biases," Management Science 39, 1382-1395. Desvousges, W., R. Johnson, R. Dunford, K. Boyle, S. Hudson, and N. Wilson. (1992). Measuring Nonuse Damages using Contingent Valuation: An Experimental Evaluation ofAccuracy. Research Triangle, NC: RTI Monograph 93-1. Diamond, P. and J. Hausman. (1994). "Contingent Valuation: Is Some Number Better Than No Number?" Journal of Economic Perspectives 8, 45-64. Festinger, L. (1957). A Theory of Cognitive Dissonance. Stanford, CA: Stanford University Press. Fisher, I. (1930). The Theory of Interest. New York: Macmillan. Fischoff, B., N. Welch, and S. Frederick. (1999). "Construal Processes in Preference Assessment," Journal of Risk and Uncertainty, this issue. Frank, R. (1992). "The Role of Moral Sentiments in the Theory of Intertemporal Choice." In G. Loewenstein and J. Elster (eds.), Choice over Time. New York: Russell Sage Foundation. Frank, R. (1990). "Rethinking Rational Choice." In R. Friedland and A. Robertson (eds.), Beyond the Marketplace: Rethinking Economy and Society, pp. 53-87. Sociology and Economics: Controversy and Integration Series. New York: Aldine de Gruyter. Fredrickson, B. and D. Kahneman. (1993). "Duration Neglect in Retrospective Evaluations of Affective Episodes," Journal of Personality and Social Psychology 65, 45-55.

102

McFADDEN

Friedman, M. and L. Savage. (1948). "The Utility Analysis of Choices Involving Risk," Journal of Political Economy 56, 279-304.
Garling, T. (1992). "The Importance of Routines for the Performance of Everyday Activities," Scandinavian Journal of Psychology 33, 170-177.
Garling, T. and R. Gillholm. (1998). "When Do Stated Preferences (SP) Predict Actual Behavior?" Working Paper, Goteborg University.
Gourville, J. (1996). "Pennies a Day: Increasing Consumer Compliance Through Temporal Re-Framing," Harvard University Working Paper.
Green, D., K. Jacowitz, D. Kahneman, and D. McFadden. (1998). "Referendum Contingent Valuation, Anchoring, and Willingness to Pay for Public Goods." Energy and Resources Journal.
Grether, D. and C. Plott. (1979). "Economic Theory of Choice and the Preference Reversal Phenomena," American Economic Review 69, 623-638.
Harrison, G. (1992). "Valuing Public Goods with the Contingent Valuation Method: A Critique," Journal of Environmental Economics and Management 23, 248-57.
Herrnstein, R. and D. Prelec. (1991). "Melioration: A Theory of Distributed Choice," Journal of Economic Perspectives 5, 137-156.
Hertzog, R. and R. Wallace. (1996). "Measures of Cognitive Functioning in the AHEAD Study," Journal of Gerontology 52B, 37-48.
Hildreth, C. (1974). "Ventures, Bets, and Initial Prospects." In M. Balch et al. (eds.), Essays on Economic Behavior Under Uncertainty, pp. 99-122. Amsterdam: North Holland.
Hoch, S. (1991). "Time-Consistent Preferences and Consumer Self-Control," Journal of Consumer Research 17, 492-507.
Holmes, T. and R. Kramer. (1995). "An Independent Sample Test of Yea-Saying and Starting Point Bias in Dichotomous-Choice Contingent Valuation," Journal of Environmental Economics and Management 29, 121-32.
Huber, J., J. Payne, and C. Puto. (1982). "Adding Asymmetricaly Dominated Alternatives: Violations of Regularity and the Similarity Hypothesis," Journal of Consumer Research 9, 90-98.
Hurd, M. (1999). "Anchoring and Acquiescence Bias in Measuring Assets in Household Surveys," Journal of Risk and Uncertainty, 19, 111-136.
Hurd, M., D. McFadden, H. Chand, L. Gan, A. Merrill, and M. Roberts. (1998). "Consumption and Savings Balances of the Elderly: Experimental Evidence on Survey Response Bias," in D. Wise (ed.) Frontiers in the Economics of Aging 353-387, University of Chicago Press: Chicago.
Hutchinson, G., S. Chilton, and J. Davis. (1995). "Measuring Non-Use Value of Environmental Goods Using the Contingent Valuation Method: Problems of Information and Cognition and the Application of Cognitive Questionnaire Design Methods," Journal ofAgricultural Economics 46, 97-112.
Kahneman, D., D. Fredrickson, C. Schreiber, and D. Redelmeier. (1993). "When More Pain Is Preferred to Less," Psychological Science 4, 401-405.
Kahneman, D. and J. Knetsch. (1992). "Valuing Public Goods: The Purchase of Moral Satisfaction," Journal of Environmental Economics and Management 22, 57-70.
Kahneman, D., J. Knetsch, and R. Thaler. (1990). "Experimental Tests of the Endowment Effect and the Coase Theorem," Journal of Political Economy 98, 1325-1348.
Kahneman, D., J. Knetsch, and R. Thaler. (1991). "The Endowment Effect, Loss Aversion, and Status Quo Bias," Journal of Economic Perspectives 5, 193-206.
Kahneman, D., I. Ritov, and D. Schkade. (1998). "Economists Have Preferences, Psychologists Have Attitudes: An Analysis of Dollar Responses to Public Issues," Princeton University Working Paper.
Kahneman, D., P. Slovic, and A. Tversky (eds.) (1982). Judgment Under Uncertainty: Heuristics and Biases. Cambridge, UK: Cambridge University Press.
Kahneman, D. and A. Tversky. (1972). "Subjective Probability: A Judgment of Representativeness," Cognitive Psychology 3, 430-451.
Kahneman, D. and A. Tversky. (1973). "On the Psychology of Prediction," Psychological Review 80, 237-251.

RATIONALITY FOR ECONOMISTS?

103

Kahneman, D. and A. Tversky. (1979). "Intuiti\<e Prediction: Biases and Corrective Procedures," Studies in Management Science 12, 313-327.
Kahneman, D. and A. Tversky. (1979a). "Prospect Theory: An Analysis of Decisions Under Risk," Econometrica 47, 263-291.
Kahneman, D. and A. Tversky. (1982). "On the Study of Statistical Institutions," Cognition 11, 123-141. Kahneman, D. and A. Tversky. (1984). "Choices, Values, and Frames," American Psychologist 39,
341-350. Keynes, J. (1921). A Treatise on Probability. New York: Macmillan. Knight, F. (1921). Risk, Uncertainty, and Profit. New York: Houghton-Mifflin. Larrick (1993). Organizational Behavior and Human Decision Processes. Lowenstein, G. (1988). "Frames of Mind in Intertemporal Choice," Management Science 34, 200-214. Lowenstein, G. (1996). "Out of Control: Visceral Influences on Behavior," Organizational Behavior and
Decision Processes 65, 272-92. Lowenstein, G. and D. Schkade. (1998). "Wouldn't It Be Nice? Predicting Future Feelings." In E.
Diener, N. Schwartz, and D. Kahneman (eds.), Hedonic Psychology: Scientific Approaches to Enjoyment, Suffering, and Well-Being. New York: Russell Sage Press. Lucas, R. (1987). "Adaptive Behavior and Economic Theory." In R. Hogarth and M. Reder (eds.), Rational Choice: The Contrast between Economics and Psychology. Chicago: University of Chicago Press. Machina, M. (1989). "Dynamic Consistency and Non-Expected Utility Models of Choice Under Uncertainty," Journal of Economic Literature 32, 1622-1668. Marschak, M. (1950). "Rational Behavior, Uncertain Prospects, and Measurable Utility," Econometrica 18, 111-141. McFadden, D. (1974). "On Some Facets of Betting." In M. Balch et a!. (eds.), Essays on Economic Behavior Under Uncertainty, pp. 126-31. Amsterdam, North Holland. McFadden, D. (1981). "Econometric Models of Probabilistic Choice." In C. Manski and D. McFadden (eds.), Structural Analysis of Discrete Data with Econometric Applications. Cambridge, MA: MIT Press. McFadden, D. (1994). "Contingent Valuation and Social Choice," American Journal of Agricultural Economics 76, 689-708. McFadden, D. (1997). "Computing Willingness-to-Pay in Random Utility Models." In R. Hartman and J. Moore (eds.), Essays in Honor ofJohn Chipman, forthcoming. Menger, K. (1934). "Das Unsicherheitsmoment in der Wertlehre betrachtungen im Anschluss an das sogenannte Petersburger Spiel," Zeitschrift fuir Nationalokonomis, Band V, Heft 4, pp. 459-485. Papandreou, A. (1960). "Economics and the Social Sciences," Economic Journal 60, 715-723. Payne, J., J. Bettman, and E. Johnson. (1992). "Behavioral Decision Research: A Constructive Process Perspective," Annual Review of Psychology 43, 87-131. Payne, J., J. Bettman, and D. Schkade. (1999). "Measuring Constructed Preferences: Towards a Building Code," Journal of Risk and Uncertainty, 19, 243-270. Poulton, E. (1989). Bias in Quantifying Judgment. Hillsdale, NJ: Lawrence Erlbaum. Poulton, E. (1994). Behavioral Decision Theory: A New Approach. New York: Cambridge University Press. Prelec, D. (1991). "Values and Principles: Some Limitations On Traditional Economic Analysis." In A. Etzioni and P. Lawrence (eds.), Perspectives on Socioeconomics. London: M. E. Sharpe. Prelec, D. and G. Lowenstein. (1997). "The Red and the Black: Mental Accounting of Savings and Debt," MIT Working Paper. Quattrone, G. and A. Tversky. (1986). "Self-Deception and the Voter's Illusion." In J. Elster (ed.), The Multiple Self. Cambridge University Press. Rabin, M. (1996). "Psychology and Economics," Journal of Economic Literature, forthcoming. Ramsey, F. (1931). "Truth and Probability," In The Foundations of Mathematics and Other Logical Essays, Paul, Trench, Trubner.

104

McFADDEN

Russell, T. and R. Thaler. (1988). "The Relevance of Quasi-Rationality in Competitive Markets." In D. Bell, H. Raiffa, and A. Tversky (eds.), Decision Making: Descriptive, Normative, and Prescriptive Interactions. Cambridge University Press.
Samuelson, W. and R. Zeckhauser. (1988). "Status Quo Bias in Decision Making," Journal of Risk and Uncertainty, 1, 7-59.
Schkade, D. and J. Payne. (1994). "How People Respond to Contingent Valuation Questions: A Verbal Protocol Analysis of Willingness to Pay for an Environmental Regulation," Journal of Environmental Economics and Management, 26, 88-109.
Seip, K. and J. Strand. (1992). "Willingness to Pay for Environmental Goods in Norway: A Contingent Valuation Study with Real Payment," Environmental and Resource Economics 2, 91-106.
Shafir, E. and A. Tversky. (1992). "Thinking Through Uncertainty: Nonconsequential Reasoning and Choice," Cognitive Psychology 24, 449-474.
Silberman, J. and M. Klock. (1989). "The Behavior of Respondents in Contingent Valuation: Evidence on Starting Bids," Journal of Behavioral Economics, 18, 51-60.
Simon, H. (1959). "Theories of Decision-Making in Economics and Behavioral Science," American Economic Review 49, 253-283.
Simonson, I. and A. Tversky (1992). "Choice in Context: Tradeoff Contrast and Extremeness Aversion," Journal of Marketing Research 29, 281-295.
Smith, V. (1979). "An Experimental Comparison of Three Public Good Decision Mechanisms," Scandinavian Journal of Economics, 81, 198-215.
Sonnemans, J., A. Schram, and T. Offerman. (1994). "Public Good Provision and Public Bad Prevention: The Effect of Framing," University of Amsterdam Working Paper.
Sterman, J. (1994). "Learning In and About Complex Systems," System Dynamics Review 10, 291-330. Svenson, 0. (1979). "Process Descriptions of Decision Making," Organizational Behavior and Human
Performance 23, 86-112. Svenson, 0. (1996). "On the Modeling of Human Choices in Descriptive Behavioral Decision Theory,"
Stockholm University Working Paper. Taussig, F. (1912). Principles of Economics. Macmillan. Thaler, R. (1985). "Mental Accounting and Consumer Choice," Marketing Science 4, 199-214. Thaler, R. (1990). "Savings, Fungability, and Mental Accounts," Journal of Economic Perspectives 4,
193-205. Thaler, R. (1991). Quasi-Rational Economics. Russell Sage Foundation. Thaler, R.; Johnson, E. (1990). "Gambling with the House Money and Trying to Break Even: The
Effects of Prior Outcomes on Risky Choice," Management Science, 36, 643-660. Tune, G. (1996). "Neglect of Stimulus Information in a Two-choice Task," Journal of General Psychology
74,231-236. Tversky, A. (1977). "On the Elicitation of Preferences: Descriptive and Prescriptive Considerations." In
D. Bell, R. Kenney, and H. Raiffa (eds.), Conflicting Objectives in Decisions. New York: Wiley. Tversky, A. and C. Fox. (1995). "Weighing Risk and Uncertainty," Psychological Review 102, 269-283. Tversky, A. and D. Kahneman. (1971). "Belief in the Law of Small Numbers," Psychological Bulletin 76,
105-110. Tversky, A. and D. Kahneman. (1974). "Judgment under Uncertainty: Heuristics and Biases," Science,
185, 1124-1131. Tversky, A. and D. Kahneman. (1981). "The Framing of Decisions and the Psychology of Choice,"
Science 211, 453-458. Tversky, A. and D. Kahneman. (1991). "Loss Aversion in Riskless Choice: A Reference-Dependent
Model," Quarterly Journal of Economics 107, 1039-1061. Tversky, A. and D. Kahneman. (1992). "Advances in Prospect Theory: Cumulative Representations of
Uncertainty," Journal of Risk and Uncertainty 5, 297-323. Tversky, A., P. Slovic, and D. Kahneman. (1990). "The Causes of Preference Reversal," American
Economic Review 80, 204-217.

RATIONALITY FOR ECONOMISTS?

105

Tversky, A and E. Shafir. (1992). "The Disjunction Effect in Choice Under Uncertainty," Psychological Science 3, 305-309.
Tversky, A, S. Sattath, and P. Slovic. (1988). "Contingent Weighting in Judgment and Choice," Psychological Review 95, 371-384.
von Neumann, J., 0. Morgenstern. (1947). Theory of Games and Economic Behavior. Princeton, NJ: Princeton University Press.
Whittington, D., et a!. (1992). "Giving Respondents Time to Think in Contingent Valuation Studies: A Developing Country Application," Journal of Environmental Economics and Management 22(3), 205-225.

Journal of Risk and Uncertainty, 19:1-3; 107-108 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

A Challenge To The "Econoclasts": A Commentary on "Rationality for Economists?"

MARK J. MACHINA

mmachina@ucsd.edu

Department of Economics, 0508, University of California, San Diego, La Jolla, CA 92093-0508

When a researcher of such outstanding accomplishment in the theory and empirics of the classical economic model as Daniel McFadden presents such a thoughtful and extensive survey of the difficulties with this model, every economist is obliged to stop and think.
My own view has always been to treat the classical model as fundamentally correct, and examine how robust it may be to the phenomena reported by McFadden. This involves both checking the robustness of its analytical concepts to departures from its axioms, as well as treating new variables (such as a problem's "frame") as additional independent variables, and then asking whether the old economic variables still work right when the new variables are held constant. I am still confident of this approach, although McFadden is beginning to make me nervous ...
But to those behavioral researchers who argue that the classical economic model is fundamentally wrong and should be abandoned, let me issue a challenge in the form of a suggested new phase in their research program. Put briefly: It's time for the strongest critics of the classical model to drop it as their "reference point," and to start searching for and describing what's really happening instead.
Economists often look to the physical sciences for guidance or analogy, and I believe it's worth doing so now. The classic circular, geocentric view of planetary motion suffered its own share of empirical "anomalies," which were accommodated by adding "epicycles" to the system. After several layers of epicycles, it was reasonable to doubt the validity of the model. Even Copernicus' heliocentric revision postulated uniform circular orbits, and thus needed (and had) epicycles, though fewer ones. Yet anyone who sought to critique the "circular orbit model" by studying, reporting and predicting the location and radii of such "epicyclic violations" would have been going down the wrong path. All of their "systematic, replicable effects" would be swept away as artifacts, once Kepler reorganized the data into elliptical orbits.
This data reorganization was a necessary step in arriving at the ultimate explanation. Kepler himself did not explain why a planet elliptically orbits the sun, or why it sweeps out equal areas in equal time intervals. Yet his purely descriptive move of dropping circularity as the base model proved crucial to Newton's

108

MACHINA

subsequent explanation by the inverse-square law. Even Newton could not have generated the phenomenon of epicycles from the principle of universal gravitation. My challenge to the "Econoclasts" is thus twofold:
1. Describe empirical findings in their own right, not as flaws in the classical model: Those who feel that the classical economic model is fundamentally missing the point should not code their findings in terms of how behavior departs from the classical model. Rather, these findings should be described and studied with a fresh eye, as important empirical clues as to whatever really is going on-and hopefully, without reference to the classical model at all.
2. Search for connections between the findings, and for underlying principles: Once the circular orbit model was abandoned, data that had been viewed as evidence of epicycles had to be completely reinterpreted. It is possible that, when viewed in a perspective not preconditioned by the classical model, the twenty-five effects in McFadden's Table 1 will take very different forms, or be replaced by simpler, more encompassing regularities.
In other words, "Don't study the epicycles-piece together the ellipse." I appreciate that it is much easier to make such suggestions than to follow them.
But if the economic model is not the right way to think about human decision making, then it seems that only the above type of approach will get us to what really is.

Journal of Risk and Uncertainty, 19:1-3; 109-110 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

What's the Problem?: A Commentary on "Rationality for Economists?"

JONATHAN BARON

baron@psych.upenn.edu

Department of Psychology, University of Pennsylvania, 3815 Walnut St., Philadelphia, PA 19104-6196

Daniel McFadden's article raises many interesting questions about the implications of psychology experiments for economic theory. How serious is the problem? I stand roughly with McFadden on the continuum of answers to that question. Specifically, people's decisions are often systematically inconsistent with rationality, but not so much as to force to abandon the assumption that people do have "preferences," which I interpret to mean objectives, or criteria for evaluating outcomes. (The term could also mean "tendencies to choose one thing over another," which is not the same.) Economic theory speaks with many voices about the requirements of rationality, but most of them echo the utilitarian foundations of the field: what is rational is to maximize the all-things-considered achievement of goals or objectives, i.e., to maximize utility. People are systematically irrational, and it is meaningful to say so. That is, we need not give up the idea that people are deviating from something real.
What are the most serious deviations from rationality? McFadden speaks of all sorts of different deviations, from consumer choices to investments to survey responses. I suggest that the deviations are most serious in survey responses and, more generally, in political behavior (both action and inaction). I include here all behavior directed at influencing policy choices that affect many others aside from the decision maker. The reason for this is that such behavior is motivated largely by moral intuitions. Compared to investing and consumer behavior, political decisions do not benefit from feedback. Each person's influence is small, and actors almost never attribute outcomes to their own decisions. All decisions are influenced by the kind of intuitive responses that McFadden describes.
If people were thoughtful utilitarians, they would engage in political behavior out of an understanding that the small size of their effect is compensated by the large population affected (Baron, 1997). But political behavior seems to be motivated by the desire to express moral opinion, or, we might say, moralistic opinion (Brennan and Lomasky, 1993). (Moralistic opinion concerns effects on others, regardless of their own self-interest.)
Perhaps most serious of all the effects McFadden describes is the status-quo effect, which is explained in terms of loss aversion. People are unwilling to endorse changes that involve both losses and gains even when the gains clearly outweigh the losses (Baron, 1998). Since almost all reforms, from changes in environmental

110

BARON

protection to changes in trade protection, involve losses as well as gains, the status-quo wins, over and over. Almost all negotiation among interest groups involves such trades of gains and losses, so the same effect makes political negotiation break down. (In commercial negotiation, the prospect of a breakdown focuses the mind because self-interest is more involved.)
An additional impediment to political agreement is the feeling that the values on one's own side are absolute (Baron and Spranca, 1996).

References
Baron, Jonathan. (1997). Political action vs. voluntarism in social dilemmas and aid for the needy. Rationality and Society 9, 307-326.
Baron, Jonathan. (1998). Judgment Misguided: Intuition and Error in Public Decision Making. New York: Oxford University Press.
Brennan, Geoffrey, and Loren Lomasky. (1993). Democracy and Decision: The Pure Theory of Electoral Politics. Cambridge, UK: Cambridge University Press.
Baron, Jonathan, and Mark Spranca. (1997). Protected values. Organizational Behavior and Human Decision Processes 70, 1-16.

Journal of Risk and Uncertainty, 19:1-3; 111-136 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.
Anchoring and Acquiescence Bias in Measuring Assets in Household Surveys
MICHAEL D. HURD RAND, SUNY, Stony Brook, NBER
Abstract
Cognitive psychology has identified and studied extensively a number of cognitive anomalies that may be important for the assessment of the economic status of individuals and households. In particular the use of brackets to elicit information about income and assets in surveys of households can interact with acquiescence bias and anchoring to cause bias in the estimates of the distributions of income and assets. This paper uses data from the Health and Retirement Study and the Asset and Health Dynamics Study to find that, as predicted by psychology, bracketing can produce bias in population estimates of assets.
Key words: assets, anchoring, acquiescence bias
JEL Classification: C42, C81
Introduction
Cognitive psychology has identified and studied extensively a number of cognitive anomalies that may be important for the assessment of the economic status of individuals and households. In particular the use of unfolding brackets to elicit information about income and assets in surveys of households can interact with cognitive anomalies to cause bias in the estimates of the distributions of income and assets. In an unfolding bracket sequence, a component of income or of assets such as the value of a house or of common stocks is assigned to an interval or bracket by a series of yes-no questions. A sequence would begin by asking owners of common stocks about the value of their holdings as in the following example from the Health and Retirement Study: "Would it amount to $25,000 or more?" A follow-up question would depend on the answer. If the respondent answered "yes," the next question would be "Would it amount to $100,000 or more?" If the respondent answered "no," the next question would be "Would it amount to $5,000 or more?" The questions would continue until the value of the asset was placed in one of the brackets 0-$4,999, $5,000-$24,999, $25,000-$99,999, $100,000-$499,999 or $500,000 or more. Cognitive research has shown, however, that the initial entry point of the bracketing sequence ($25,000 in this example) can act as a point of reference or anchor, and that the measured distribution of stock holdings in a population could depend on the entry point: increasing the entry point will increase the frequency of responses in the higher brackets.

112

HURD

Cognitive psychology and survey methodology have found that in some circumstances individuals have an acquiescence bias, a tendency to agree with statements. The format of the bracketing question in this example is unbalanced: "yes" responses lead to greater stock holdings values so that acquiescence bias will increase the frequency of responses in the higher intervals, causing the estimated distribution of stock values to shift to the right.
National surveys of individuals and households typically ask respondents for actual dollar amounts of income and asset components, which would seem to make these considerations irrelevant. However, either from an unwillingness to reveal sensitive information or uncertainty about what is requested or about the true dollar value, the response rate to such open-ended questions can be rather low. Then, bracketing can be used to reduce the harm to data quality caused by non-response. For example, in the 1993 Survey of Income and Program Participation just 53% of married respondents who reported owning common stocks gave a value for their stock holdings, and 34% of single respondents gave a value (Haynes, Hurd and Chand, 1998). In most cases researchers will want to aggregate income components and assets components to obtain measures of total income and total assets, which will necessitate the imputation of missing income and asset components. Although covariates which are predictive of income or asset holdings can increase the accuracy of imputation somewhat, imputation for missing asset values is not very satisfactory because the covariates can explain a rather small fraction of variance.1 The true stock holdings of a household are likely to be far from the imputed value.
The Health and Retirement Study (HRS) and the Asset and Health Dynamics Study (AHEAD) are large nationally representative panel surveys of individuals aged 51-61 and 70 or over respectively at baseline and their spouses. The HRS and AHEAD and a number of other major household surveys such as the Panel Study of Income Dynamics and the Survey of Consumer Finances use bracketing to help impute missing values. A respondent will be asked about ownership of an asset such as common stocks. At this stage the response rate is very high: for example in the AHEAD baseline it was 98.1%. However, the response rate about the value of stock holdings is much lower, just 54% among owners of stocks in AHEAD. In HRS and AHEAD the nonrespondents were then asked a series of bracketing questions, which because these surveys are mainly administered over the telephone, are in the form of unfolding bracketing questions. Of course, knowing the bracket in which the value lies is not as good as knowing the actual value, but knowledge of the bracket can substantially improve the accuracy of imputation. For example, using the bracket information only for imputation typically yields an R2 of about 0.80 in the logarithm of stocks whereas covariates alone would yield an R2 of about 0.20.2 Therefore, even a simply hot-deck imputation within brackets would give much better individual imputations than could be obtained without the brackets.3
While the value of bracketing to improve imputation is substantial, the initial entry point into the bracketing sequence is likely to act as an anchor, and the

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

113

question format may lead to higher values because of acquiescence bias. Overall the effect of imputation based on unfolding brackets may be to reduce variance at the individual level at the cost of bias both at the individual level and in population measures.
A method of investigating anchoring effects and acquiescence bias based on the data from waves 1 of HRS and AHEAD would be to compare for each asset the distribution of responses among those that gave a continuous response (actual value) with the distribution among those that were bracketed. Evidence for anchoring effects would be that the distribution of the bracketed responses is systematically related to the entry point relative to the distribution of the continuous responses. However, there is good evidence that self-selection into the bracketing sequence affects the estimated distribution: in particular bracketed respondents who self-select in HRS or AHEAD have different characteristics than the respondents who gave actual dollar values. For example in AHEAD wave 1 those who gave a "Don't know" (DK) response when asked about asset values had lower cognitive scores, were less likely to be married, and more likely to be very old than those who gave actual dollar values, all of which are associated with lower asset holdings (Hoynes, Hurd and Chand, 1998).4 Thus the effects of anchoring and the effects of selection are confounded, and differences between the continuous and imputed distributions could be true differences due to selection or induced differences, the result of anchoring. The relative magnitudes of anchoring and selection effects are likely to vary from asset to asset because of differences in uncertainty, which is thought to influence anchoring, and in the rate of nonresponse, which helps to determine selection effects. The varying mix of effects will obscure any systematic anchoring effects.
Acquiescence bias cannot be studied in the HRS or AHEAD data both because of self-selection and because the question format was always unbalanced.
The objective of this paper is to find evidence about anchoring and acquiescence bias in HRS asset data in a way that controls for selection. The evidence will be of two types. Between wave 1 and wave 2 of HRS many of the bracketswere changed and in a number of cases the entry point was also changed.5 The change in entry point has similarities to an experiment. The population in wave 1 was presented with a set of entry points, one for each type of asset, and the distributions of their assets measured. In wave 2 the population, which was almost the same, was presented with a different set of entry points and the distributions of their assets measured. The experimental question is whether the changes in the distribution of each type of asset are related to the changes in the entry points. Provided the change in entry point is not related to any other factors that would change the distribution of assets, the effect of changing the entry point can be found from the change across waves in the associated holdings of bracketed assets.
The second type of data come from an experiment about housing value that was administered as part of HRS wave 3. To control for selection, subjects were randomly assigned to bracketing sequences with differing entry points and with differing question formats. The distribution of responses will be used in this paper

114

HURD

to quantify the effects of anchoring and of question format. Cognitive psychology indicates that uncertainty on the part of subjects will lead to anchoring and acquiescence, but as far as I know that hypothesis has not been tested on the kind of economic data in HRS and AHEAD. Because some respondents are known a priori to have greater knowledge of housing value than others, one can find how anchoring and acquiescence bias vary with the level of respondent uncertainty.
It is obvious that if we want good estimates of the assets of individuals and of a population we need to understand any bias introduced by unfolding brackets. It is somewhat less obvious why we need to investigate acquiescence bias: if an unbalanced question format might cause bias, the solution would be to use a balanced format such as "Would the value be less than $$$ or more than $$$?" In this format subjects cannot answer "yes" but must make a choice. However, the unbalanced format is less wordy and therefore more efficient particularly in a telephone survey. A survey with many unfolding bracket questions would be significantly faster to administer with an unbalanced format and cause less respondent burden. If acquiescence bias proves to be negligible, the unbalanced format would be preferred.
This paper is not directly about eliciting preferences, the topic of the Berkeley conference and this volume. However, experimental questions that are meant to uncover preferences such as rates of time preference or risk aversion will often have anchors, and their formats may induce acquiescence bias. Finding anchoring and acquiescence in data about asset holdings, which have an objective reality, should provide a warning that questions about preferences, which do not have an objective reality, need to be examined for biases arising from anchoring and acquiescence.

1. Background
1.1. Anchoring
In their landmark paper, Tversky and Kahneman (1974) reported on a number of cognitive anomalies, one of which was anchoring. In an experimental design that has been used many times, subjects are asked to make a comparison and then an absolute judgment. The comparison is of the following form: "Would it be greater or less than X," where "it" might be the length of the Amazon river or the number of African states in the United Nations. The subject would then be asked for an absolute judgment: "How long (many) would it be?" A very robust finding is that the average of the absolute responses is influenced by the value of X: in a typical psychological experiment X is randomly assigned a high or a low value, and the average of the absolute values is found to vary directly with X. Because of this X is called an anchor, and the variation of the average with X is called an anchoring effect. Cognitive psychologists have varied this basic experimental design in many ways.

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

115

No anchoring is found when the comparison item is different from the absolute item, for example, when the comparison item is the length of the Amazon river and the absolute item is the number of African nations in the U.N.6 The anchoring effect depends on the knowledge subjects have about the quantity assessed (Wilson et al., 1996; Jacowitz and Kahneman, 1995; Chapman and Johnson, 1994) or on the confidence they have about their knowledge (Kruglanski and Freund, 1983). Strack and Mussweiler (1997) speculate that there would be no anchoring if subjects had absolutely certain knowledge, but apparently that hypothesis has not been tested. The actual anchoring processes are poorly understood (Jacowitz and Kahneman, 1995), so a good deal of the research has led to experiments that aim to reveal different aspects of the mechanism.
Possibly as a result, there has been only limited quantification of anchoring effects. An exception is Jacowitz and Kahneman (1995) who introduced a metric, the change in the median of the absolute judgments divided by the change in the anchors. This metric varied in a number of anchoring experiments from 0.00 to 0.93, and the quantity was inversely related to the confidence the subjects had in their judgment. The implication is that the informational content in anchored responses cannot be ascertained ex ante: it can be high as in the case where the Jacowitz and Kahneman metric was 0.00 and it can be practically zero as in the case where the metric was 0.93.
Apparently there have been no experiments in which there was an attempt to find the true or underlying distribution of beliefs, where here "true" means beliefs prior to cuing from the anchor.
For the purposes of understanding the effects of unfolding brackets on the distribution of responses to questions about economic variables, the important findings are the following: First, anchoring is pervasive, so that one should anticipate that the unfolding brackets would act as anchors; that is, the null hypothesis should be that there is anchoring, not the reverse. Second, unfolding brackets are somewhat different from the typical experiment in cognitive psychology: the follow-up to the first bracketing question is not a query about an absolute amount but another bracketing question. Thus, the experiments from psychology provide guidance, but the results are not directly applicable. Third, the aim of the psychological experiments is different: they are designed to learn about the cognitive processes that lead to anchoring whereas the aim of unfolding brackets is to learn about individual and population quantities. Fourth, the economic quantities are personal information about which the subject has some knowledge; but the subject may be uncertain either about the actual amount or about the quantity that is being requested. For example, a subject may be uncertain about whether a response about checking accounts should include the value of money market accounts that have check-writing privileges. Fifth, some subjects may be certain about the quantity, but reluctant to reveal the information, and this may induce anchor-like effects: out of impatience the subject may bracket early in the sequence to avoid further questions, and of necessity this would be a bracket close to

116

HURD

the anchor. Even in this case, however, the subject may be cued as to what is a usual value, and may be reluctant to deviate far from that value.
The conclusion is that we should expect anchoring in unfolding brackets, that the effect will vary with uncertainty, and therefore, with the item that is queried. Anchoring may vary across individuals as some people are generally more alert and have more information than others, and some are reluctant to reveal information.

1.2. Acquiescence bias
Acquiescence or agreement bias refers to the tendency of subjects to agree with statements that are presented to them (Schuman and Presser, 1981). Of course, subjects may agree with a statement because they agree with the content of the statement, but acquiescence bias results from a response style where the subject has a preference for agreeing or finds it easier to agree than to disagree.
The study of acquiescence bias has a long history in cognitive psychology, and a concise summary is that " ... response acquiescence is wide-spread and pervasive over a wide variety of item content and most pronounced when content is highly ambiguous or imaginary" (Jackson and Messick, 1958, p. 244). The tendency to acquiesce has been called a personality trait (Couch and Keniston, 1960), and as such it could be studied as any other personality trait. In a heterogeneous population where some subjects may have the trait and some may not, measured acquiescence bias would be an average over those with and without the trait.7 If the tendency to acquiesce is not a trait, however, but a response style in the face of ambiguity, then acquiescence bias would vary with questionnaire content in that some content is more ambiguous than others (Ray, 1983). From this point of view the magnitude of acquiescence bias will depend both on the particular subpopulation that is sampled and on the questionnaire items.
Acquiescence bias has been studied as a subject of survey methodology. Surveys often query individuals about their attitudes, personal characteristics or beliefs, asking them to agree or disagree with statements. If acquiescence bias is quantitatively important, wording a question as positive or negative will influence the measured rate of agreement in a population.
Survey methodology offers several explanations for acquiescence bias. The tendency to agree may be a manifestation of deference to authority, and the tendency will be related to indicators of low status. Such deference might be called social acquiescence or yea-saying, and in a pure form it would not lead to a change in the subject's beliefs, only in the manifestation of those beliefs. A second explanation is that subjects who are not well informed or are poorly educated will be unduly influenced by sweeping statements, causing a change in actual beliefs. This can be explained as confirmatory hypothesis testing (Klayman and Ha, 1987): when presented with the hypothesis that some statement is true, subjects desire to confirm the hypothesis and they do so by selectively reviewing evidence that supports the hypothesis. This process can change actual beliefs.8 A somewhat more

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

117

mechanistic explanation for agreement bias is that the form of the question provides an appropriate answer: In asking a subject "Would you agree that ... " the subject is cued that "yes" is an acceptable answer. In this view, agreement bias would disappear were questions completely clear to the respondent (Schuman and Presser, 1981).
Testing among these explanations is difficult: For example, subjects with low status are likely not to be well educated and not well informed. They probably have more difficulty understanding questions. Thus, education cannot be used as a covariate to test among these explanations.
The implication for HRS and AHEAD of the findings from cognitive psychology and survey methodology is that an unbalanced format, such as was used in HRS and AHEAD, could lead to an upward bias in measured assets, particularly if selection into brackets is a reflection of a respondent's uncertainty about the meaning of the question or the value of the asset. There are, however, substantial differences between the types of statements that result in acquiescence bias in psychology and survey methodology and the statements in HRS. The content of the psychology and survey experiments that have demonstrated acquiescence bias have been about attitudes, personality or beliefs, which generally have no objective reality. In HRS and AHEAD the content is about the asset holdings of households, which have an objective reality. Furthermore, in addition to providing an opportunity to agree, the unbalanced format may provide an anchor that is not present in attitudinal or personality questions which are typically the basis for psychological studies. Suppose, for example, that in a balanced format the entry point conveys information about a summary statistic of the population distribution such as the median: that is, subjects believe the entry in the balanced format to be the median in the population, and partially adjust their beliefs toward the median. Then to ask a respondent if his asset holdings are greater than $$$ as in the unbalanced format is to suggest that the median, although unspecified, is greater than $$$, causing even someone with initial beliefs at the entry point to adjust upward. Therefore both anchoring theory and acquiescence bias would predict greater values compared with the balanced format.
In summary, although the findings from cognitive psychology and survey methodology provide a warning about possible effects from an unbalanced format, the quantitative effects in data from the HRS and AHEAD are not known. It is likely that they will vary from asset to asset.

1.3. Investigations of anchoring and acquiescence bias in economic data
Locander and Burton (1976) conducted an experiment about eliciting income brackets via telephone interviewing. Subjects were assigned to one of four treatments that varied by entry point into a bracketing sequence and by format. Because of a design flaw, however, acquiescence bias cannot be deduced from the data. The experiment was well designed to uncover anchoring effects and they are

118

HURD

strong. For example, of subjects entered the bracketing sequence at $5,000 (1974 income), 37.5% reported income more than $15,000; of subjects entering the sequence at $25,000, 63.7% reported income more than $15,000.
The first two waves of HRS and the first wave of AHEAD used unfolding brackets in a way that could have caused anchoring and acquiescence bias. Recognizing the potential importance of anchoring, the managers of HRS and AHEAD designed and fielded two experiments in AHEAD wave 2 to provide data with which to study the effects of anchoring. The experiments were placed in experimental modules, each one of which is 2-3 minutes of speculative, experimental or one-time questions asked at the end of an interview. In the experiments individuals were assigned at random to one of a number of experimental modules, and each module had a different sequence of bracketing questions with different entry points.
Subjects were queried about the value of savings accounts and the value of monthly consumption. In the first anchoring experiment, those subjects who had savings accounts were assigned to a bracketing sequence without being allowed to give a dollar (continuous) response. The forced bracket eliminated self-selection as a confounding factor.
If there were no anchoring the distribution of responses across the brackets would be the same regardless of entry point. However the actual distributions were shifted to the right as the entry point increased (Hurd et al., 1998). For example, among those that entered the bracketing sequence at $5 thousand the estimated median was $11.6 thousand. Among those that entered at $10 thousand the estimated median was $19.1 thousand, and at $50 thousand it was $24.7 thousand. These are very large changes in the estimated median.
The second experiment in AHEAD 2 was about consumption. Respondents were asked: "About how much did you and your household spend on everything in the past month?" Specifically mentioned were rent, mortgage loan payments, utility and other bills, food, clothing, transportation, entertainment, and any other. By random assignment, about half (50.4%) of the respondents were given a forced bracketing sequence with random entry point of one of $500, $1000, $2000 or
$5000.9 The following table has the estimated medians and means of consumption as a
function of the entry point among those presented with a forced bracket.

Monthly consumption: estimated medians and means (forced brackets)

Entry point

500

1000

2000

5000

Median Mean

895

1146

1415

1455

1311

1508

1946

2161

Source: Hurd et a!., 1998. Note: nonparametric estimates

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

119

The elasticity of the median with respect to the anchor is very large near plausible true values.10 For example the elasticity associated with a change in the entry point from 500 to 2000 evaluated at the entry point 1000 is about 30%. The anchoring effects are small at implausible values of consumption: in this population real consumption of five thousand is rather implausible as it implies annual consumption of 60 thousand yet average income is about 22 thousand. Thus, the median for the entry point of five thousand is almost the same as at two thousand.
Consumption is intrinsically difficult to measure in a survey, and subjects are likely to have considerable uncertainty both about what should be included and about how much they spent even in well-defined categories. The fact that the anchoring elasticities are so large reinforces the findings from cognitive psychology about the interaction of subject uncertainty with the anchor. As far as I know these results provide the first evidence, although somewhat suggestive, that uncertainty affects anchoring in economic data.

2. Asset change between waves 1 and 2 of HRS
The HRS is a biennial panel. At baseline in 1992 it surveyed 12,654 communitydwelling persons in the U.S. representing the cohorts of 1931-1941 and their spouses. Its main substantive domains are labor market behavior, economic status and health, including cognition and mood (Juster and Suzman, 1995). It placed particular emphasis on a complete inventory of income and assets and their careful measurement.
Table 1 shows the reported rate of asset ownership in each wave, and among owners the distribution of types of answers about the value of the asset.U For example, 27.1% of households reported owning stocks in wave 1. Among the owners of stocks, 73.1% gave a continuous response (actual number) to the query about value, 20.9% were bracketed and 6% did not give a continuous answer and would not answer the bracketing questions. The number bracketed was 459.
Ownership rates were rather stable, with modest increases in stocks and IRAs and modest declines in certificates of deposit and treasury bills. The rate of continuous responses declined for about half of the asset categories. Some of this decline is due to the use of a range card in wave 1: the interview in wave 1 was face-to-face which allowed some respondents who refused to give a continuous amount to give a bracket interval from a range card. The bracket intervals in the range card were different from the bracket intervals in the unfolding brackets. Furthermore, there is no comparable entry point which would act as an anchor, so that a meaningful comparison with wave 2 bracketed responses cannot be made. 12 For this reason I treated range card respondents in wave 1 as continuous responses.13 The percentage refusing to give a bracket generally declined between the waves, possible reflecting increased confidence among respondents in the survey.

120

HURD

Table 1. Reported asset ownership rate and distribution of type of response about value of asset

%Owners

Continuous

Among owners (%) Bracketed Not bracketed

Total

Number bracketed

Stocks

Wave 1

27.1

73.1

20.9

Wave2

30.2

68.2

26.8

Checking

Wave1

78.9

79.1

15.8

Wave2

79.4

80.3

15.5

CDs, T-bills

Wave 1

25.9

78.1

15.3

Wave2

22.0

75.2

17.7

Bonds

Wave 1

6.0

78.4

12.0

Wave2

5.3

70.9

19.2

IRAs

Wave 1

37.9

79.1

15.8

Wave2

40.9

77.1

19.4

Real estate

Wave1

24.3

80.3

16.2

Wave2

25.2

79.3

18.5

Business

Wave 1

16.7

70.4

24.4

Wave2

16.6

63.6

32.1

Transportation

Wave 1

100.0

89.8

8.4

Wave2

99.6

91.2

8.0

6.0

100.0

459

5.0

100.0

608

5.1

100.0

1003

4.2

100.0

923

6.6

100.0

320

7.1

100.0

292

9.6

100.0

59

9.9

100.0

76

5.1

100.0

486

3.5

100.0

597

3.5

100.0

320

2.2

100.0

349

5.2

100.0

330

4.3

100.0

398

1.8

100.0

683

0.8

100.0

604

Source: Author's calculations based on HRS waves 1 and 2. Counts and percentages are unweighted.

Table 2 shows the bracket boundaries and the entry points (shaded) for the eight asset categories.14 In a number of cases the upper boundary was increased so that fewer households would fall in the open-ended bracket. The initial entry point changed substantially for a number of assets including checking and savings accounts, and certificates of deposit and treasury bills.
Separately by asset category, by wave and by bracket, I imputed the bracketed observations by hot-deck. That is, an asset value was assigned to a bracketed respondent by making a random drawing from the pool of continuous reporters in the same bracket interval. On average, therefore, the difference between the distributions of assets of the continuous reporters and the bracketed reporters is only due to the frequency of responses in each bracket.15 Table 3 has the median and mean in each wave for the eight asset categories.
In wave 1 the median value of common stocks among continuous reporters was $18 thousand, and the entry point into the bracketing sequence was $25k. If the entry point acts as an anchor and subjects adjust partially to the anchor through a

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

Table 2. Bracket boundaries and entry points (thousands)

Wave1

Stocks

5

25*

100

500

Bonds

5

25*

100

500

Checking/saving

1

5*

10

50

CD's, T-bills

1

5*

10

50

Transportation

2

10*

25

Other

2

10*

25

Real estate

5

50*

150

Business

10

50*

500

IRA/KEOGH

5

25*

50

100

*Initial entry points.

121
Wave2
2.5 25* 125 400 2.5 10* 100 400 5 50* 150 300 2.5 25* 125 250 5 25* 200 10 75* 250 2.5 125* 500 1000 10 100* 1000 10 25* 100 400

process such as numerical averaging (Poulton, 1989), the median among the bracketers would be greater than the median among continuous reporters because the anchor was greater than the median (Hurd, 1997). This is found in the table. By wave 2, median stock holdings among continuous reporters grew to $26k, but the entry point remained at $25k. In that the anchor was approximately the same as the median, partial adjustment would suggest that the median among bracketers would not be affected by the anchor, and, therefore, it would be the same as the median among continuous reporters. This is also what the table shows. As a

122

HURD

Table 3. Asset holdings by continuous reporters and bracketed reporters (thousands)

Entry point

Median

Continuous

Bracketed

Mean Continuous Bracketed

Stocks

Wave 1

25

18

20

59

73

Wave2

25

26

25

66

74

Checking

Wave1

5

5

5

16

21

Wave2

50

5

10

16

30

CDs, T-bills

Wave1

5

8

10

27

45

Wave2

25

8

20

24

64

Bonds

Wave 1

25

12

20

48

73

Wave2

10

20

20

69

69

IRAs

Wave1

25

20

25

45

45

Wave2

25

28

30

55

60

Real estate

Wave1

50

45

75

149

219

Wave2

125

50

90

98

229

Business

Wave 1

50

25

95

168

294

Wave2

100

55

75

112

197

Transportation

Wave1

10

7

10

13

22

Wave2

25

8

10

12

18

Source: Author's calculations based on HRS 1 and HRS 2.

consequence the median among continuous reporters grew by 44% and among bracketers it grew by 25%. The situation is similar for the mean.
The distribution of checking and savings accounts was very stable across waves as measured by the continuous reports: both the median and mean were unchanged at $5k and $16k respectively. However, the entry point increased from $5k to $50k, the median of the bracketers doubled, and the mean increased by 43%, suggesting substantial anchoring effects. The situation is similar for certificates of deposit and
treasure bills. The entry point for bonds decreased between the waves, and although the
continuous median and mean increased substantially, the bracketed median and mean were practically unchanged. This suggests there were two offsetting effects: the true distribution shifted to the right which would have caused the bracketed median to increase, but the change in anchoring effects was negative. The result was a small net effect.
For these four categories of assets the pattern is the same: if the entry point increased more than the increase in the median among continuous reporters both

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

123

the median and the mean among the bracketers increased more than among the continuous reporters; if it increased by less the median and mean increased by less. For holdings of IRAs, real estate, business and transportation there are some violations of this pattern. For example, mean IRA holdings increased by 22% among continuous reporters, but by 33% among bracketers even though the anchor remained constant. There is a similar violation of the pattern for mean real estate value, and for business value.
There is no suggestion of an anchoring effect for transportation holdings, possibly reflecting greater knowledge among respondents about the value of their automobiles.
A way to find the average change in imputed assets induced by the changes in the entry points comes from the following assumption. Suppose that the median of a bracketed asset is given by,
ILb = 1L + t( a, s)
where ILb is the median of the bracketed distribution, IL is the median of the true distribution, a is the entry point and s is the effect of selection. We would like to
know at1aa which would be expected to vary from asset to asset. We observe ILb
and IL at waves 1 and 2 of HRS for each type of asset. Then approximately
ilp,2 - ilp,1 = -aaaitla + -aasitls
for each type of asset where ilp,2 = ILb - IL in wave 2 and similarly for ilp,1·
Figure 1 shows ilp,2 - ilp,1 and ila for the eight types of assets, where to
control for scale effects the changes are all in percentages. If ils were zero the
slope from the origin to each of the point would be at1aa.
The figure generally shows positive slopes implying that an increase in the entry is associated with an increase in the bracketed median. However, the effect does not appear to be linear: very large increases in the entry point seem to have little additional effect. This is in agreement with findings by Hurd et al. (1998) where very large anchors in the elicitation of savings accounts had less effect than merely large anchors. The implication is that an anchor must have some plausibility to have an effect (Strack and Mussweiler, 1997).
If ils is not zero the regression of ilp,2 - ilp,1 on ila will estimate the average of at1aa as long as ila and ils are orthogonal. In that ila is the result of setting
the entry points in waves 1 and 2, it should be orthogonal to ils because the entry points were chosen for reasons that had nothing to do with selection. Figure 1 shows the estimated regression slope and standard error. The slope has the interpretation of an average elasticity of the bracketed median with respect to the entry point.16 It is within the general range that comes out of the experiments on AHEAD wave 2, but it is less than the elasticity of responses about housing value to be reported later in this paper.

124

HURD

Change in medians (percent)

-

100

I

50

I

2 ob ervations

- 1\. 1

0

' ·yl

-50
-100 -

·/ I
II
I

I

-150

-200

0

1-
y· .... / v
--

r

I

v

I

v
/

I /\.,.~ . I

I~

I

II

slope = 0.188

I (0.071) I

·

200

400

600

Percent change in anchor

I
800

t-
I
1000

Figure 1. Change in medians (percent).

Although selection may have changed between the waves, the regression shows a systematic relationship between the change in the anchor and the differential change in the medians that cannot be explained by a change in self-selection: any such change in self-selection would affect the differential change, but there is no reason that it should be associated with the change in the anchor. That is, change in self-selection would decrease the explanatory power of the anchor change by causing unexplained variation in the left-hand variable, but not the magnitude of the effect.
3. Experimental data on housing value
Wave 3 of HRS was administered in 1996, when the age-eligible respondents were about 55-65. It included nine experimental modules designed to provide data to study anchoring and acquiescence. The modules were administered following the main survey. I will use 7387 observations about housing value from the nine modules.

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

125

Following an initial question that ascertained ownership, owners were asked about housing value in the following way:
"About how much could you sell your home for in today's housing market?"
Respondents were not allowed to give a continuous answer but were asked forced unfolding bracket questions in one of the three formats
1. "Would it be more than $$$?"(unbalanced, strictly greater) 2. "Would it be $$$ or more?" (unbalanced, weakly greater) 3. "Would it be less than $$$ or more than $$$?" (balanced)
where $$$ was one of $50k, $lOOk, $150k. Follow-up questions in the initially assigned format bracketed housing value into one of the intervals with boundaries of $50k, $lOOk and $150k.
The experimental design called for interactions among the three entry points and the three formats, so that there were nine combinations or treatments. Individuals were assigned at random to one of the treatments.
In the main part of the survey, questions about income and assets are answered by the financial respondent, who in the case of a couple, is the spouse that is judged by the respondents themselves to be most knowledgeable about the financial situation of the household. The financial respondent would have been asked about housing value as a dollar amount just 10-15 minutes before the experimental modules. In the experimental modules housing value is requested of both the financial and nonfinancial respondent but in a bracketed format. Because anchoring and acquiescence effects are thought to increase with the uncertainty of the respondent, we would expect little if any effects among financial respondents regardless of the accuracy of their actual knowledge of housing values. To bracket themselves accurately in the experimental module financial respondents simply had to remember the answer they gave a short time earlier. We would expect moderate amounts among nonfinancial respondents because most people probably have a good, but not certain, idea of housing value.

3.1. Anchoring effects in HRS wave 3 experiments
Because the results based on the balanced format illustrate the overall findings about anchoring, I will begin with them. As a point of reference, Table 4 shows the distribution of actual responses, which are based on the actual dollar amounts reported by married financial respondents in the main surveyP The rest of the table shows the distribution of responses by nonfinancial respondents from the experimental modules. If there were no anchoring or acquiescence effects or other sources of systematic misinformation, the distributions should be the same because all nonfinancial respondents are married, and each was represented in the main

126

HURD

Table 4. Distribution of housing value: actual and balanced question format among nonfinancial respondents

Interval

50,000-

100,000-

N

<50,000 ""50,000 100,000 ""100,000 150,000 ""150,000 > 150,000

Actual Entry point
50k lOOk 150k

4679
295 262 219

0.184
0.166 0.164 0.169

0.041
0.044 0.050 0.064

0.330
0.319 0.336 0.228

0.055
0.061 0.057 0.059

0.143
0.153 0.187 0.155

0.042
0.064 0.023 0.014

0.205
0.193 0.183 0.311

Source: Author's calculations based on HRS wave 3. "Actual" is from financial respondents among couples in the main survey.

survey by a married financial respondent.18 In the discussion I will consider the actual distribution to be the true distribution.
Both the actual distribution and the experimental distributions show probability masses at 50k, lOOk and 150k. For example, 4.1% of reported actual values were at 50k. It is likely that this happens because these values act as focal points, and, even when giving actual dollar amounts, a substantial number of respondents round to them.19 In the balanced question format when presented with the choice of less than $$$ or greater than $$$ some subjects would volunteer "about $$$." Thus when the entry point was 50k about 4.4% of subjects volunteered about 50k.20
The actual distribution and the distribution with entry at 50k are very similar, including the frequency at the focal points. There is little difference between those distributions and the distribution with entry at lOOk, and therefore between the distributions with entry at 50k and at lOOk. From these distributions we see no evidence for anchoring. An explanation is that 50k is not a credible value for most homeowners. Nonfinancial respondents may not know the actual value but they know it could not be so small as 50k, and therefore 50k will not act as an anchor. If that is the case the follow-up at lOOk would act as the anchor for subsequent questions, leading to the same distribution as lOOk entry-point distribution.
This interpretation is bolstered by the 150k entry-point distribution. The fraction less than 50k is about the same as with the other entry points: apparently subjects are able to distinguish whether their home is worth less than 50k regardless of the entry point. However, there are substantial differences in the higher intervals, particularly the fraction greater than 150k.
These effects can be seen more easily from the complement of the cumulative distribution (CCDF), which is shown in Figure 2 and with standard errors in Table 5. To make the presentation more clear the probability mass at each focal point has been allocated to the adjacent open intervals according to the relative probability masses in the lower and upper interval. For example, in Table 4 the probability

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

127

----.. 0.8

""'

!
~

~

i

r\

0.6 0.4

~ ~ entry 150k
I'"~"'~" ~~

i
T

~~~

0.2

'~~ ~
~ ~ -...._ ---"-..

-~ ~ ~

0

10

100

1000

House value

--actual -entry 50k ---- entry 100k- entry 150k
Figure 2. CDF of house value Balanced format and actual

mass of 0.041 at SOk in the actual distribution has been allocated to (0, SOk) and
(50k, lOOk) at the rates of 36% (0.184/(0.184 + 0.330)) and 64% respectively.
These calculations and the "actual" distribution in Figure 2 and Table 5 are based on the actual distributions of Table 4; that is, they only use the true interval
probabilities, the same type of information that is available from the experiments. Figure 2 shows the distributions in the logarithms of household value. It shows
almost no differences among the actual, 50k entry-point and lOOk entry-point

Table 5. Probability housing value exceeds bracket points: bracketed nonfinancial respondents and actual values among couples (balanced format)

Entry N

Estimated median

50,000 Probability Std Err

Bracket point 100,000
Probability Std Err

150,000 Probability Std Err

Actual 4679

50k

295

lOOk 262

150k 219

88.2 91.0 89.4 100.9

0.801 0.819 0.820 0.804

0.006 0.022 0.024 0.027

0.407 0.430 0.414 0.503

0.007 0.029 0.030 0.034

0.230 0.229 0.195 0.320

0.006 0.024 0.024 0.032

Note: "Actual" is from financial respondents among couples on the main survey. Medians estimated by linear interpolation of distributions in logs. True median among couples is 90k.

128

HURD

distributions. However, the 150k entry-point distribution is shifted to the right at lOOk, and substantially shifted at 150k. Based on linear interpolation in the logarithms of house values, the estimated medians can be read off of the graph at the 0.5 probability point.
These medians are shown in Table 5. The estimated median labeled "actual" (88.2k) is from the linear interpolation of the bracket probabilities. Evidence that the interpolation is reasonable is that the true median is 90.0k. As would be suggested by Figure 2, the estimated medians in the first three lines are similar, but the median associated with the 150k entry point is substantially larger. The elasticity of the median with respect to an increase in the anchor from lOOk to 150k is 26%.
Table 5 shows that at none of the bracket boundaries do the probabilities differ significantly among the actual, the 50k entry-point and the lOOk entry-point distributions. However, at the bracket boundary 150k all of those distributions differ significantly from the 150k entry-point distribution. Even at lOOk, the actual and the 150k entry-point distribution differ significantly at the 5% level.
Table 6 shows the CCDF averaged over question format. For example, the probability that house value was greater than or equal to 50k was 0.861 averaged over the balanced format and the weakly unbalanced format, and the probability that it was greater than 50k was 0.821 averaged over the balanced and strictly unbalanced formats. The lines labeled P100 - P50 and P150 - P100 show the difference in probability associated with a change in the entry point. For example entering the bracketing sequence at lOOk rather than at 50k increased the probability that house value is greater than 50k by 0.023, and the standard error of the difference is also 0.023. Evidence for anchoring effects is that the probability differences are positive as in this example.

Table 6. CCDF of housing value and the change in CCDF associated with a change in entry point: nonfinancial respondents

Entry point and comparison

~50k

>50k

~lOOk

>lOOk

~150k

>150k

50k lOOk 150k
Pwo- Pso Standard error
Ptso- P10o Standard error

0.861 0.859 0.870
-0.003 0.020
0.011 0.020

0.821 0.843 0.816
0.023 0.023
-0.027 0.024

0.488 0.483 0.579
-0.005 0.029
0.096 0.029

0.435 0.447 0.485
0.012 0.030
O.Q38 0.032

0.287 0.247 0.358
-0.039 O.Q25
0.111 0.027

0.212 0.223 0.286
0.011 0.025
0.063 O.Q28

Note: Entries are the CCDF averaged over format types, and the change in the CCDF for a change in entry points with the standard errors of the differences. Thus P 100 - P50 is the second line minus the first line.

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

129

The line labeled P100 - P50 shows no such systematic difference, and no difference is significant. This is the same finding as in Table 5 which was only based on the balanced format. Apparently 50k is not a plausible value for the great majority of subjects and so the entry point is discounted as an anchor and the first relevant anchor point would be lOOk.
The plausibility of this view is increased by a comparison of the distribution when the entry point is lOOk with the distribution when the entry point is 150k. There is no difference in the classification at the bracket point 50k again suggesting that most people are rather certain whether their house value is less than or greater than 50k. However, the classification into the intervals ~ lOOk, >lOOk, ~ 150k and > 150k show anchoring effects: all four of the differences are positive and three are significant. For example when the entry was 150k the probability that housing value is greater than or equal to lOOk is 0.579 compared with 0.483 when the entry is lOOk. These results show that anchoring effects are not necessarily the same or even consistent over all parts of the distribution.
The hypothesis that anchoring will disappear if subjects are certain of the value being queried (Strack and Mussweiler, 1997) can be tested by examining anchoring among financial respondents. If each correctly remembers what he or she said earlier and chooses the correct bracket there will be no anchoring effects. Table 7 summarizes the anchoring effects among financial respondents. It is constructed in the same way as the bottom part of Table 6, so anchoring effects will appear as positive probability changes. It is apparent that P100 - P50 shows no evidence for anchoring. As with nonfinancial respondents P150 - P100 generally has positive signs, but no difference is significant, and the magnitudes are at most one-third of those among nonfinancial respondents.

3.2. Effect of question format
I will study the effects of question format by holding constant the entry point and comparing the bracket probabilities as a function of question format. The relevant comparison is between the balanced format and the strictly-greater-than format or

Table 7. Change in CCDF associated with a change in entry point: financial respondents

Entry comparison

:2:50k

>50k

:2:100k

>lOOk

:2::150

150k

P10o- Pso Standard error
P1so- P10o Standard error

-0.008 0.010
0.027 0.018

-0.008 0.022
-0.004 0.022

-0.030 0.024
0.030 0.025

-0.024 0.026
0.021 0.026

-0.026 0.022
0.024 0.022

0.008 0.022
0.024 0.023

Note: Entries are the change in CCDF averaged over format types for a change in entry points and the standard errors of the differences.

130

HURD

between the balanced format and the weakly-greater-than format. The two unbalanced formats cannot be directly compared with each other because of the probability mass at the focal points.
The first two lines of Table 8 show the CCDF of house value evaluated at lOOk for the balanced format question at each of the entry points 50k, lOOk and 150k and the standard errors of the estimated probabilities. For example when the entry was 50k, about 41% of nonfinancial respondents selected into brackets of more than lOOk. The next two lines show the CCDF and standard error when the strictly-greater format was used.21 The following two lines have the difference in the probabilities, thus removing any additive anchoring effect, and the standard error of the difference. For all three entry points the probability that house value is greater than lOOk is greater when the question format is unbalanced and the difference is significant at the 5% level in one of the three cases. The last column shows the average of the differences, and it is significant at the 5% level. The average difference of 0.056 means that an additional5.6% of respondents reported a housing value greater than lOOk when the question format was unbalanced. It is a little difficult to judge whether this is a large or small effect, but a rough translation into an effect on the median will show that it is fairly large. Because lOOk is approximately the median of the distribution of housing value a rough estimate of the effect of question format on the median can be made from Figure 2, which shows the shift in the distribution when the entry point increased from lOOk to 150k. At about the midpoint of the distribution a change in the probability of 0.089 is associated with about an 11.5k change in the median,22 which suggests that a change of 0.056 would be associated with a change of about 7.2k. This is a rather large effect, about 8%.

Table 8. Effect of question format on distribution of house value: nonfinancial respondents

Format

Entry

50k

lOOk

150k

All

Balanced Standard error Greater than Standard error Change in probability Standard error
Balanced Standard error Greater than or equal to Standard error Change in probability Standard error

0.410 0.029

Probability house value greater than lOOk

0.393

0.479

0.030

0.034

0.427 0.018

0.459 0.030

0.500 0.032

0.490 0.032

0.483 0.018

0.049

0.107

0.011

0.056

0.042

0.044

0.046

0.026

Probability house value greater than or equal to lOOk

0.471

0.450

0.539

0.487

0.029

0.031

0.034

0.018

0.504 0.033

0.515 0.021

0.619 0.030

0.546 0.016

0.033 0.044

0.065 0.037

0.080 0.045

0.059 0.024

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

131

The second panel has a comparison between the balanced format and the weakly-greater-than format.23 In this format a positive response could include those who believe their house value is about equal to the bracketing point as well as those who believe it is greater, so the appropriate comparison is with the probability that housing value is greater than or equal to a bracketing point in both the balanced and unbalanced formats. Thus in the balanced format about 47% indicated a house value of about lOOk or more when the entry point was 50k.
The next lines show the distribution and standard error when the format is unbalanced. The probabilities are all greater than with the balanced format, and, although the differences are all positive, none is significant at the 5% level. The average change in the probability is 0.059, which is almost the same as in the comparison in the first part of the table. Apparently either form of the unbalanced format causes about the same amount of acquiescence bias.
Table 9 summarizes the effects of the unbalanced format: it shows the average difference between the probability distributions at the points 50k, lOOk and 150k, where the averages are over all three entry points. For example, the entries in the column "lOOk" are the same as the average differences in the column labeled "All."
The table shows that at the three points of the probability distribution the unbalanced format has the expected effect of increasing the likelihood of a large response, and that the effects are significant in five of the six cases. The effects, which are approximately six percentage points, are substantial in that a change of that magnitude at the midpoint of the distribution is associated with an important change in the median.
Just as anchoring effects are thought to depend on a subject's uncertainty about the quantity that is queried, so format effects should depend on uncertainty. Table 10 offers a test of this proposition: it has summary differences in the distribution of house value as reported by the financial respondent. In the first line of Table 10 the differences are positive meaning that more subjects reported house value

Table 9. Change in the probability distribution of house value due to change in question format: nonfinancial respondent

Unbalanced question format

House value

50k

lOOk

150k

Greater than Greater or equal

0.091 0.019
0.059 0.017

0.056 0.026
0.059 0.024

0.023 0.022
0.069 0.022

Note: Entries are the change in the probability distribution of house value associated with a change from the balanced format to an unbalanced format. Estimated standard errors underneath probability differences.

132

HURD

Table 10. Change in the probability distribution of house value due to change in question format: financial respondent

Unbalanced question format

House value

50k

lOOk

150k

Greater than Greater or equal

0.043 0.018
0.024 0.015

0.025 0.022
0.006 0.020

0.013 0.018
-0.011 0.018

Note: Entries are the change in the probability distribution of house value associated with a change from the balanced format to an unbalanced format. Estimated standard errors underneath probability differences.

greater than the bracket points under the unbalanced format than under the balanced format. The positive signs are consistent with an acquiescence bias; however, the magnitudes are much smaller than in Table 9, and only one of the three is significant at the 5% level. The third line, first column, shows that under the unbalanced format 2.4% more subjects reported house value greater than or equal to 50k than under the balanced format, which is consistent with an acquiescence bias, but at lOOk the difference is essentially zero and at 150k it has the wrong sign. The overall conclusion is that there is little, if any, evidence for acquiescence bias among financial respondents.
This finding is consistent with the view that acquiescence will " ... decrease or even disappear entirely as questions are seen by respondents to be clear and meaningful in terms of previously crystallized attitudes" (Schuman and Presser, 1981, p. 205). In this experiment financial respondents had previously in the survey given their estimates of housing value, and so they would simply have to remember their answer and correctly choose the right category to avoid acquiescence bias. Any residual acquiescence bias would have to be the result of social acquiescence.

4. Conclusion
Both the nonexperimental data on eight asset categories and the experimental data on housing values show anchoring effects. Both types of results are useful and offer different and complementary perspectives. HRS 1 and 2 have actual asset data as reported by the financial respondents. Users of asset data care about anchoring in these data, and although the results cannot control for other influences on asset change it is important to show that the actual field data include anchoring effects. The factors that can change asset holdings in the actual data are controlled in the experimental data, but the subjects are the nonfinancial respondents, and only one asset is studied. The fact that both types of data show anchoring makes the conclusion about its importance more solid.

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

133

As indicated in the housing experiment, the anchoring effect seems to vary with the uncertainty of the respondent, confirming speculation in the cognitive psychology literature. The relationship between anchoring and uncertainty opens the way for measures of population uncertainty through anchoring experiments. Rather than asking subjects about the certainty they have about quantities, which are difficult questions to formulate and to answer, the anchoring effects can be measured by randomly varying the entry point into a bracketing sequence. Large effects would indicate population uncertainty.
The anchoring effect apparently varies with the relationship between the anchor and the true distribution. In that both the distribution of an asset and the uncertainty about the value of the asset change over time, it is unlikely that the anchoring effect would be constant over time even were the anchor to remain constant. For example, the entry points for stocks and for IRAs were unchanged from wave 1 to wave 2; yet the medians among the continuous reporters increased by 44% and 40% respectively while the medians among the bracketers increased by 25% and 20%. Under this interpretation the anchoring effect biased downward measured change in the values of these assets. However, these quantitative assessments for each separate asset rely on the assumption that the effects of self-selection remained constant, which is not likely to be the case for all measures of asset change. The only reliable method to separate out change in self-selection from change in anchoring in individual assets is to have random entry into the bracketing sequence.
Acquiescence bias led to a right-ward shift of about six percentage points in the distribution of housing values. This is about the same general magnitude as the anchoring effects induced by the 150k entry point. However, acquiescence bias was found over the entire measured range of the distribution, whereas anchoring effects were not found in the comparison of the SOk and lOOk entry-point distributions. If acquiescence bias and anchoring are both caused by respondent uncertainty, these results are difficult to reconcile: if subjects whose housing value is in the range of SOk are certain enough about the value that they are not anchored, why should they show acquiescence bias? That the differential result is not caused by some other aspect of question format such as yea-saying is shown by the general absence of acquiescence bias among financial respondents: as an initial assumption, financial and nonfinancial respondents are likely to have similar personalities on average and have the same amount (if any) of deference.
Cognitive psychology alerted the designers and users of household surveys of economic variables about cognitive anomalies that could affect the measurement of those variables. This paper found that the magnitudes of both anchoring effects and effects from acquiescence bias are large enough that they should be taken into account when estimating population distributions of assets. It is likely that such effects will be found in the measurement of other economic variables.
I suggest that cognitive psychologists may want to use HRS and AHEAD data in their own research. The sample sizes are large and the data are population representative. They contain measures of cognition and mood, occupation and

134

HURD

education, health and background measures. When used with the experimental data on anchoring and acquiescence, they should be capable of supporting tests of hypotheses about the causes of cognitive anomalies.

Acknowledgments Financial support from the National Institute on Aging is gratefully acknowledged.

Notes
1. Typically, imputation of an asset value would be based on a regression estimated over subjects who reported actual values. The expected value conditional on covariates would be imputed to those with missing values.
2. The R2 from bracketed imputations is calculated by using an actual reported value to generate a bracket interval, imputing the value based only on the bracket and then comparing the imputed value to the actual value.
3. In hot-deck imputation, a stock value is imputed to an individual who has been bracketed to an interval by making a random draw from the reports of actual dollar values in that interval and assigning the value to the individual.
4. There is a further difference between those who responded DK and those that refused (RF): the bracketed distribution of RF responses is shifted to the right, implying greater asset values. However, the distinction between RF and DK is not sharp because subjects who say they would rather not report asset value will be coded as RF, when, in fact, some would not have understood the question.
5. The brackets were changed through a procedure called "bracket optimization." The aim of the procedure was to choose the best bracket boundary points where "best" is defined by the objective of maximizing a fitted sum of squares in imputation. The procedure often called for increasing the top boundary point and changing the other boundary points, one of which acts as the entry point into the bracketing sequence.
6. However, some research has shown what are called basic anchoring effects: judgments are influenced by an anchor that is completely uninformative (Wilson et a!., 1996).
7. Some subjects may even have a disagreeing trait. 8. Thanks to Norbert Schwarz for pointing out this distinction. 9. The other half were allowed to give a continuous response (dollar response). Their responses cannot
be used in a straightforward way because of self-selection into the bracketing sequence. 10. Median consumption among those 70 or over was about $1224 in the Consumer Expenditure Survey
(Hurd et a!., 1998). 11. These rates are calculated as cross-sectional rates; thus, the sample composition differs in the two
waves. 12. The range card will, nonetheless act as an anchor because respondents tend to give answers from
the middle of the categories. Thus the distribution of responses will differ as the range and boundaries of the brackets in the range card are varied. 13. According to Smith (1995) the percentage of respondents that used the range card varied from 0.4 (bonds) to 4.0 (checking). 14. Housing value is not analyzed because it was not bracketed in wave 1.

BIAS IN MEASURING ASSETS IN HOUSEHOLD SURVEYS

135

15. In AHEAD wave 1 the brackets effectively controlled for observable differences in the characteristics of continuous reporters and of bracketed reporters: adding covariates to asset imputations made little difference in the distributions of assets once the brackets were used (Hoynes, Hurd and Chand, 1998).
16. The estimated elasticity of the mean with respect to the anchor is 0.075 (0.032). 17. The main survey question was "What is its present value? I mean, about what would it bring if it
were sold today?" 18. Any selection effects in the main survey will be minimal because of the very high response rate,
92%. 19. An alternative explanation is that the focal points are realistic because houses do sell for round
numbers such as lOOk. 20. Such volunteering is a valuable feature of the balanced format because it improves considerably the
accuracy of imputation for those cases. 21. "Would it be more than $$$?" 22. Based on a linear interpolation in the logs. 23. "Would it be $$$ or more?"

References
Chapman, G. B. and E. J. Johnson. (1994). "The Limits of Anchoring," Journal of Behavioral Decision Making 7, 223-242.
Couch, Arthur and Kenneth Keniston. (1960). "Yeasayers and Naysayers: Agreeing Response Set as a Personality Variable," Journal ofAbnonnal and Social Psychology 60(2), 151-174.
Hoynes, Hilary, Michael Hurd, and Harish Chand. (1998). "Household Wealth of the Elderly under Alternative Imputation Procedures." In David Wise (ed.), Inquiries in the Economics of Aging, pp. 229-254. Chicago: University of Chicago Press.
Hurd, Michael D. (1997). "A Model of the Effects of Anchoring on Population Distributions," Mimeo, RAND.
Hurd, Michael D. et a!. (1998). "Consumption and Saving Balances of the Elderly: Experimental Evidence on Survey Response Bias." In D. Wise (ed.), Frontiers in the Economics of Aging, pp. 353-387. Chicago: University of Chicago Press.
Jackson, Douglas N. and Samuel Messick. (1958). "Content and Style in Personality Assessment," Psychological Bulletin 55(4), 243-252.
Jacowitz, K. E. and Kahneman, D. (1995). "Measures of Anchoring in Estimation Tasks," Personality and Social Psychology Bulletin 21, 1161-1166.
Juster, F. Thomas and Richard Suzman. (1995). "An Overview of the Health and Retirement Study," Journal of Human Resources 30, S7-S56.
Klayman, Joshua and Young-Won Ha. (1987). "Confirmation, Disconfrrmation, and Information in Hypothesis Testing," Psychological Review 94(2), 211-228.
Kruglanski, A. W. and T. Freund. (1983). "The Freezing and Unfreezing of Lay-Inferences: Effects on Impressional Primacy, Ethnic Stereotyping, and Numerical Anchoring," Journal ofExperimental Social Psychology 19, 448-468.
Locander, William B. and John P. Burton. (1976). "The Effect of Question Form on Gathering Income Data by Telephone," Journal of Marketing Research, XIII, 189-192.
Poulton, E. C. (1989). Bias in Quantifying Judgements, Hove (U.K.) and London: Lawrence Erlbaum Associates.
Ray, John J. (1983). "Reviving the Problem of Acquiescent Response Bias," The Journal of Social Psychology 121, 81-96.

136

HURD

Schuman, Howard and Stanley Presser. (1981). Questions and Answers in Attitude Surveys. New York: Academic Press, Inc.
Smith, James P. (1995). "Racial and Ethnic Differences in Wealth," Journal of Human Resources 30, S158-S183.
Strack, Fritz and Thomas Mussweiler. (1997). "Explaining the Enigmatic Anchoring Effect: Mechanisms of Selective Accessibility," Journal of Personality and Social Psychology, 73(3), 437-446.
Tversky, A. and D. Kahneman. (1974). "Judgment Under Uncertainty: Heuristics and Biases," Science 185, 1124-1131.
Wilson, T. D. eta!. (1996). "A New Look at Anchoring Effects: Basic Anchoring and Its Antecedents," Journal of Experimental Psychology: General125, 387-402.

Journal of Risk and Uncertainty, 19:1-3; 137-138 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Commentary on "Anchoring and Acquiescence Bias in Measuring Assets in Household Surveys"

ARIE KAPTEYN

a.kapteyn@kub.nl

Center for Economic Research, Warandelaan 2, P.O. Box 90135, 5000 LE Tilburg, The Netherlands

The paper provides a careful analysis of the effects of anchoring and acquiescence bias, using the HRS.
Regarding asset changes between waves 1 and 2, observed changes appear to be overestimates of the true changes if the brackets used in the questions increase more than the true changes, whereas underestimation of change occurs if the brackets change less than the true distribution. This conclusion is based on a comparison of the observed distribution obtained through unfolding brackets with the distribution obtained from continuous answers. As a graphical illustration, Figure 1 is quite useful. I must admit that it took me a while to understand exactly how the figure was constructed. At first sight, one would think that the quantity ILb which is the median of the bracketed distribution, would be unobservable. After all, one only observes relative frequencies within brackets. I take it that the bracketed distribution has been made observable by the hot-deck method, which essentially assumes that within a bracket the distribution of true values is identical for the continuous responses and the bracketed responses. Although this may be a defensible assumption, it would have been of interest to also perform an analysis that only uses the relative frequencies in the various brackets and explains shifts in frequencies in a similar way.
I am not convinced by the argument that da and ds must be orthogonal "because the entry points were chosen for reasons that had nothing to do with selection." The issue at stake here is one of correlation, not of causation. Imagine that for some reason in the second wave the respondents with high values of asset holdings always give a bracketed response, whereas in the first wave, the bracketed respondents were mainly to be found in the lower ranges of asset holdings. Also imagine that in the second wave the entry points are uniformly higher than in the first wave, then we will find an artificially strong effect of anchoring. This would be an example of positive correlation between selection and entry point levels, even though this is completely unintended. Having said this, I am perfectly willing to accept that such correlation between entry points and selection is negligible. But this is still an assumption, and not something that follows from the way the entry points were set. Of course, the fact that the experimental module of HRS wave 3 yields very similar answers reinforces the belief that the assumption is reasonable or at least not very harmful.

138

KAPTEYN

I find the analysis of the effect of question format quite convincing and I have nothing to add.
The remaining question is, where does all this leave us? Clearly, if we want to use the insights of the paper to devise reliable measures of assets or other quantities at an individual level, we have to have an accurate model of the size of all relevant effects. Building such a model is still something that requires more thought. For example, acquiescence biases and anchoring effects depend on how certain respondents are about the true values that we try to measure. Hence, in principle one would need to know how certain a respondent is about the value of an unknown quantity before we can apply a quantitative model of anchoring and acquiescence bias. However, it may be a lot harder to measure such uncertainty than to ask for the unknown quantity directly.
Michael Hurd's suggestion to turn things around and use observed anchoring effects and acquiescence bias to gauge uncertainty in the population is a creative one. The crucial assumption underlying this suggestion appears to be homogeneity of the population. If some respondents are much more certain than others about the true value of the quantity we would like to measure, it is not yet clear to me how observations of bracketed responses could be sufficient to identify the amount of certainty of each respondent.
The paper is extremely useful in pointing out the importance of various biases introduced by the way we measure things. Although one may tempted to use a model of these biases to somehow "adjust" responses, it may still be more fruitful to aim at measurement methods that are free of systematic biases.

Journal of Risk and Uncertainty, 19:1-3; 139-164 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Construal Processes in Preference Assessment

BARUCH FISCHHOFF, NED WELCH AND SHANE FREDERICK

baruch@cmu.edu

Department of Social and Decision Sciences, Carnegie Mellon University, Pittsburgh, PA 15213-3890

Abstract
Interpreting people's preferences requires understanding how they have constrned their tasks, interpreting the proposed alternatives in the context where the evaluation is being made. With stylized experimental or survey choices, researchers' challenge is typically identifying the features that people add in order to make their task real enough to answer (i.e., how they read between the lines). With rich "real world" choices, researchers' challenge is typically identifying the features that people neglect, as they reduce their task to manageable complexity (i.e., which lines they choose to read). In either case, if people misunderstand or mistrust the stated transaction, they may evaluate a different offer than the one that was proposed. Such misconstruals are a nuisance for investigators, insofar as dealing with them delays the measurements that motivated the research. However, they can also provide an opportunity, by focusing attention on how people give meaning to choice situations. This article describes procedures for studying construal processes, strategies for getting people to answer the questions that interest researchers, and options for interpreting responses when people construe questions differently than was intended.
Key words: Preferences, eliciation, construal, values, environment

Introduction
Before people can express their preferences, they must figure out what their options are. Inevitably, that requires a construal process, in which people interpret the terms of a proposed transaction, considering the context in which it is offered. That process may involve accepting some details as stated, reinterpreting others, and inferring still others. Construal processes can arise both when people have well-articulated values (e.g., "My answer depends on whether there's a warranty. I'll assume that there is.") and when they lackthem (e.g., "I suppose they're telling me everything I need to know.").
Construal processes can create both problems and possibilities for researchers. On the one hand, misunderstanding people's construal processes means misinterpreting their preferences. On the other hand, understanding those processes means learning about a fundamental aspect of preference expression. This article offers a strategy for dealing with construal processes, including (a) a task analysis of possible construals, (b) methods for revealing those processes, and (c) analytical approaches for promoting intended construals and addressing unintended ones.

140

FISCHHOFF, WELCH AND FREDERICK

The concluding section describes the collaborative research needed to implement this approach.

Problems and possibilities
Integrating theoretical and methodological concerns over preference elicitation is a special case of a general strategy in the social sciences. Often, they advance by discovering that people interpret tasks in simpler, more complicated, or just different ways than investigators had assumed. Indeed, the history of psychology has been described as a process of converting such "artifacts" into "main effects," worthy of study in their own right (McGuire, 1969), in addition to their value for improving research design. Two examples might illustrate this process:
(A) Survey researchers often instruct interviewers to maintain a neutral demeanor, hoping to focus respondents entirely on the literal content of the questions being asked. However, people are naturally attuned to social cues, even when none are intended. As a result, respondents may treat the interviewer as part of the stimulus, when they decide how to interpret the interaction. Faced by an impassive stranger, employed by an unfamiliar institution, respondents might interpret the interviewer's demeanor as hostility, disinterest, or deception-or as a sign that the interviewer really wants to know what they, personally, believe. Because interviewers have to have some demeanor, respondent construals are inherent to survey research. Over time, pursuit of this topic evolved from the narrow study of "interviewer effects" to the broader study of nonverbal communication (Ekman, 1985; National Research Council, 1982; Rosenthal and Rosnow, 1969). That broader view allows survey researchers to draw on theories and results from related areas (e.g., perceptions of honesty, cues to emotion, body language). As a result, survey researchers now have other scientists working on their problem, probing the questions that people ask about those who ask them questions. Sometimes, that research provides solutions, showing how to create an intended impression; sometimes, it just documents continuing problems (e.g., respondents' unpredictable second guessing of political pollsters).
(B) Experimenters often present stimuli in random order, hoping to elicit independent judgments of each stimulus. However, subjects still spontaneously generate expectations about coming stimuli, which often deviate from randomness (Peterson and Beach, 1967; Tune, 1964). The most familiar example is the gambler's fallacy: expecting, say, a head after four consecutive tails. These response biases have long been known to experimental psychologists. However, they were poorly understood as long as they were treated as a methodological nuisance, and addressed with ad hoc procedures. In time, though, these response biases acquired intrinsic interest-for what they revealed about judgment under uncertainty (Gilovich, Vallone, and Tversky, 1985; Lopes, 1982; Tversky and Kahneman, 1974). Although the theories arising from these studies lost direct contact with the experimental design issues that prompted them, they still provide an evolving

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

141

research base for such design. For example, these theories show that sequences look more random when they have more alterations and shorter runs than are statistically expected. Gold (1997) found that changing the data generator helps as well (e.g., using a new coin eliminates "memory" for the sequence and reduces gamblers fallacy).
Of course, there is much still to learn about both nonverbal communication and interpretations of randomness. Waiting for complete understanding of such methodological issues would be a formula for paralysis. On the other hand, in the absence of such basic research, design choices can be defended only by appeals to intuition and convention. When colleagues have different intuitions, research may be unfairly rejected. When colleagues see things similarly, research may be accepted uncritically, creating a body of work with shared errors. Continued reliance on ad hoc designs increases the risk of disciplines diverging from one another (because they have different conventions) and diverging from the truth (because they consistently view behavior through a distorted lens).
The rest of this article proposes a hybrid approach to dealing with construal processes. It includes ways to stimulate new research, to exploit existing research, and to assess the residual uncertainty in how tasks have been construed. For addressing construal processes in general, it applies approaches developed by psychologists, anthropologists, linguists, and others (Frazier and Charles, 1995; Grice, 1975; Hilton, 1990; Schwarz, 1997). For addressing the construal of specific tasks, it applies standard frameworks for task specification. These frameworks are intended to facilitate pooling results across tasks and drawing upon general research, conducted without preference elicitation in mind. We hope that the combination provides a common perspective for efforts that many researchers are already pursuing in one way or another.
Examples are drawn primarily from our own research, because it is accessible and can be criticized without offending anyone else. Some examples deal with contingent valuation (CV) (Mitchell and Carson, 1989). In part, this choice reflects CV's familiarity, making it a good place to examine general issues, even for those who never want to see another CV study. In part, this choice reflects our belief that fundamental disagreements about the construal of CV tasks prevent the convergence of rival programs for eliciting preferences among nonmarket goods. Identifying the empirical conditions for convergence might help to put researchers on the same page. We focus here on expressed preferences elicited in the staged circumstances of surveys and experiments. Analogous issues arise in the staged circumstances of market choices, and in researchers' interpretation of the preferences that they reveal.

A task analysis of construal processes
People must construe a proposed transaction before they can evaluate it. That evaluation could involve the straightforward "read out" of a previously derived

142

FISCHHOFF, WELCH AND FREDERICK

value. Or it could require a "constructive" process, inferring the implications of basic values for a novel task (Fischhoff, 1991; Fischhoff, Slavic, and Lichtenstein, 1980; Gregory, Lichtenstein, and Slavic, 1993; Payne, Bettman, and Schkade, 1999). In either case, construing a preference task involves two interrelated steps. The first is deciding which features might matter, thereby providing structure. The second is deciding how to interpret each potentially relevant feature, thereby providing substance to that structure.1
Construal and evaluation can be iterative processes. For example, initially selected features may prove unimportant, once examined in context (e.g., "I always check the price tag, but prices here are similar enough that I'll ignore them."). Conversely, the evaluation process may show the importance of seemingly irrelevant features (e.g., "If it's that cheap, I had better check the fine print-which I had ignored up to now.").
Figure 1 depicts the tasks faced in construing a proposed transaction. The first branch reflects respondents' construal of the process used to assess their preferences, namely, has the transaction has been offered in good faith, even if it is not entirely clear? The subsequent branches involve construal of its structure and

Statement of Proposed Transaction

Process Construal

Trust

Mistrust [detail same as left branch]

Outcome Construal

Construe as intended

Misconstrue

Structure
/~

Substance
/"'\

Add Feature Figure 1. Task analysis of construal processes.

Neglect Feature

Misunderstand

Embellish

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

143

substance, thereby determining its outcome value (i.e., what one expects to give and get if the transaction is accepted). The work of construal determines the process value of engaging in such a social relationship. Accepting a transaction as presented can create positive process value, by affirming one's relationship with the proposer. Distrust may create negative process value, by incurring uncomfortable social relations. For example, consumers sometimes discount a product rebate, realizing that they may not send in the coupon. That makes its perceived outcome value different than the stated one. The associated process value is, however, quite different for consumers who reflect ruefully on their own disorganization and for consumers who think angrily about the merchant's exploiting their personal foible; such individuals would fall on the left- and right-hand branches of Figure 1, respectively.
Outcome and process value can also affect one another. For example, trust should increase respondents' faith that a stated commitment will be honored, with any ambiguities being resolved to mutual satisfaction. Such predictability should increase proposals' outcome value. Even trusting individuals may, however, still misconstrue a transaction, adding or neglecting some details, misunderstanding or embellishing others. For example, respondents may be so busy managing the social side of the interaction that they overlook critical features, however carefully their instructions have been crafted. Trust may even encourage misinterpreting those features that are noticed, insofar as respondents uncritically accept their initial impressions without clarifying the terms. Conversely, suspicion may add meaning where none was intended. For example, surveys typically begin by naming their sponsors, experiments by presenting informed consent forms. For investigators, these details are routine aspects of ethical research practice, unrelated to the task. Respondents, though, may seize on them for help in construing the terms of the transaction and, hence, its outcome value.
Distrust (the right-hand branch) can lead to analogous processes. It creates pressure for a transaction so precise that no construal is possible, thereby fixing the outcome value. Distrust can lead people to add new features or to suspiciously discount presented ones. It should reduce outcome value, if it increases uncertainty about whether a proposal will be honored.
Construal processes can be more and less deliberate. People may labor to decode an unfamiliar bidding game, but effortlessly reinterpret an advertiser's appeal-or vice versa. How hard they work may itself influence evaluations. People may resent having to ferret out details; or they may pride themselves on not needing everything spelled out. Actively adding personally relevant details may help people to savor the pleasure of potential positive outcomes and internalize the fear of potential negative ones. One challenge in value elicitation is matching subjects' effort level to what they would invest in the real world. A subject's exegesis on a jar of peanut butter may not predict market behavior any better than a focus group predicts intimate sexual behavior.
As mentioned, construal processes are a necessary part of everyday life. People often do not (and, sometimes, cannot or even should not) specify every detail of a

144

FISCHHOFF, WELCH AND FREDERICK

proposed transaction. Problems arise when respondents invent more of a transaction than is realized by its proposer-so that they are, in effect, evaluating a different proposal than the one being offered.2 As a result, they may wander down any of the tracks in Figure 1, changing structure or substance, with an overlay of trust or distrust. Unfortunately, as investigators, we often study transactions that require elaborate construal processes. We care about real-world choices whose rarity ensures their unfamiliarity (e.g., housing purchases, retirement planning, medical emergencies).3 We invent laboratory tasks whose originality reflects our own creativity. When we guess wrong about construal processes, we both misinterpret the expressed preferences and miss an opportunity to learn how people shape them.

Methods of assessing construals
The previous sections raised many possible differences between questions asked and questions answered. The present section considers ways to determine which of them become realities. Although imperfect, these fairly simple procedures offer some protection against naive assumptions. They also provide the raw materials for more systematic accounts, the topic of the following section. In effect, this section looks for artifacts, while the next looks for ways to tum them into main effects.

Concurrent verbal protocols
Investigators naturally worry about how respondents will construe their tasks However, mere reflection may not be enough. Professional training is designed to make scientists see the world differently than do laypeople.4 A standard approach for confronting investigators with lay perspectives is asking respondents to "think aloud" as they derive their answers (e.g., Schriver, 1989). Table 1 shows sample instructions for eliciting such concurrent verbal protocols. Table 2 shows the kinds of issues that they can raise. It is the first section of an attempt to envision the transaction posed by Tolley et al. (1986), in a CV study eliciting monetary valuations for changes in atmospheric visibility. What might one conclude regarding the adequacy of this introduction and the meaning of the preferences that it begins to shape, for an individual who provided these comments?
This individual takes the task seriously, showing the sort of intense involvement that investigators often hope to evoke. However, that involvement has revealed or evoked confusion over the precise meaning of "household." That confusion is problematic if the outcome depends on the choice of definition or if the frustration reduces process value (or simply makes it harder to take the task seriously). As a result, such a respondent could be pushed down various branches in Figure 1.
The protocol also shows that the respondent cares enough about the study's sponsorship that mentioning it creates a temptation to respond strategically. This

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

145

Table 1. Typical instructions for a think-aloud protocol
As I read each question aloud, please think out loud as you answer it. So that I can understand your reasoning, please tell me everything that you can about your answer. I am interested in why you chose that answer, any difficulty that you had in answering, any questions that crossed your mind, and so on. Thankyou ....
[Use the following prompts if they say too little, or their rate of comments slacks off:
· Talk out loud as you think your answer, OK? · What's going on in your head? Tell me about it. · Is that all you were thinking about? ·Anything else?
Use the prompts extensively at the beginning and then for any subsequent set of questions where they are silent-since some kinds of questions may be more difficult than others. That's more important than pressing them for each subset of questions, where it would be a hassle.]
Source: Pretest of expectations questions for National Longitudinal Study of Youth Expectations Module (Investigators: Manski, Dominitz, Fischhoff).

sensitivity shows that researchers have fulfilled their ethical responsibility to communicate their funding source. Being seen to level with respondents should increase the transaction's process value. The assumptions made about that sponsor will affect outcome value, but in more predictable ways than had respondents had to guess.

Table 2. Fragments from a (hypothetical) think-aloud protocol

An Actual Survey

Hello, I'm

from the University of Chicago. We are visiting with people in Atlanta, as

part of a research study about environmental quality. Since we're talking with a scientifically selected sample of Atlanta residents, the viewpoint of your household is very important to us (Tolley,

Randall, et al., 1986).

A Possible Construal They say that they're from a university. Assuming that's true, does that mean that this is just to satisfy their scientific curiosity? Or, are my answers going to affect governmental policy? If it's just a matter of curiosity, I might as well tell the truth, but I probably don't need to work all that hard. If it's going to make a difference, then I really ought to think about what I want and whether there are any opportunities to slant the results in the direction of policies that I want.

What does it mean that they're interested in the "viewpoint of my household?" Am I supposed to tell them what I think, as a representative of the household, even if others in the family think differently? Or, am I supposed to average, in some way, what I think everybody in the house thinks? If so, then what weight am I supposed to give to each of those bodies? For example, are the kids' opinions worth less because they can't vote, haven't thought as much about environmental issues, and won't be directly paying the bill? Or, are their opinions worth more because they'll be living with the environment for longer than us old folks and because they're the ones we're trying to protect? What if they haven't really thought about these questions? What if I haven't? This is confusing.

Source: Fischhoff and Furby (1986).

146

FISCHHOFF, WELCH AND FREDERICK

If this protocol were collected during pretests, one could reformulate the instructions, trying again to create the desired construal. Additional pretests could determine whether these problems were resolved, without creating new ones. A latter section considers a systematic approach to such proactive design. If this protocol were taken from an actual interview, one would have to live with these imperfections. The section on Reactive Analysis considers what to do then. In either case, one must decide how seriously to take the thought processes revealed in protocols.
Fortunately, verbal protocols have been studied extensively (e.g., Ericsson and Simon, 1994; Hasher and Zachs, 1984; Nisbett and Wilson, 1977; Wilson et al., 1993). Some relevant results include: (1) People can report fairly well on their thought processes, as those occur. As a result, there is reason to believe what people say in concurrent verbal protocols. (2) Some task features affect behavior so automatically that they elude people's powers of introspection (e.g., an option's place in a physical or temporal array, the reference point, the effects of previous exposure). (3) Forcing people to reflect deeply on their options sometimes reduces satisfaction with their choices-as though any decision can become conflicted, if one thinks about it enough. As a result, pretest subjects should work as hard as actual subjects, if their experience is to be predictive.

Manipulation checks
Well-executed pretests should reduce the variability in respondents' construals. However, they are unlikely to eliminate it. Words may just mean different things to different people, such that no single version will uniformly evoke the desired construal. For example, explicitly guaranteeing that a promised good will be delivered may reassure some respondents, but make others suspicious.5 Providing many explicit details may satisfy some respondents, while overloading others.
Manipulation checks are another standard procedure for determining how closely respondents' construals match the intended ones. The simplest versions just ask respondents how they interpreted a task, immediately after completing it. Neutral wording is used to avoid inducing artificial skepticism or acceptance. For example, in a brief phone survey, we elicited willingness-to-pay judgments for cleaning up either 30 or 1000 miles of Pennsylvania rivers (Fischhoff et al., 1993). The brevity of the task was intended to reduce respondents' memory load, at the price of increasing their construal load (i.e., the less we said, the more respondents had to infer). At the end, we asked respondents to recall several task details. Their reports suggest what such checks can reveal:
How many miles of river would be cleaned up? Respondents were offered three ranges (0-100, 101-1000, and 1001-10000). Despite this hint, 52% of respondents gave wrong answers or none at all. If these reports reflect respondents' beliefs when they produced their valuations, then over half of the expressed preferences misrepresent respondents' values for the described good.6

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

147

How effective would the clean-up be? Although the program had been described as one that would "eliminate the problem," only 27% of respondents endorsed the "eliminate completely" option. Almost half (48%) said that it would just "make good headway," 7% said that it would not do much and 15% said that they had not thought about its effectiveness. Thus, most respondents' values for the described good should be higher than their expressed WTPs (which referred to but a fraction of the promised clean-up).
How would the program be paid for? Although the task specified "higher prices on goods and services," only 28% of respondents chose that option. More than twice as many chose "taxes," while 25% chose "donations" and the remainder other ways (more than one choice was allowed). If people care about the payment vehicle, then these WTPs do not apply to the described task. The same price may mean something different if achieved through taxes or through companies internalizing environmental costs.
Who will pay? Even though the project description said nothing explicitly about this topic, almost all subjects chose one of the options that we offered. The most common choice (60%), "all PA taxpayers," was consistent with the modal belief in taxes as the payment vehicle. For these respondents, this feature effectively went without saying.
When respondents report something other than what was stated, several interpretations are possible. They may not have understood the original statement. They may have understood, but rejected it. Or, they may have understood and accepted it, but forgot those details between performing the task and answering the manipulation check. If so, then their information processing was fairly shallow, even if it settled on the desired specification.
One measure of the depth of processing is the internal consistency of judgments and manipulation checks, or their degree of construct validity. For example, subjects reporting a small clean-up program were twice as likely to expect it to be completed as subjects reporting a large clean-up (35% vs. 18%), a sensitivity to practicality that suggests coherent beliefs. Two other consistent reports were that respondents expected taxes to be the payment vehicle and taxpayers to bear the burden. Responses were very similar with two versions of the task, varying in ways that should not affect construals (whether the river clean-up was compared to using cleaner coal technology or to limiting forest development). Such coherent response patterns provide grounds for trusting these manipulation checks-even if they showed a consistent failure to construe the task as we had intended.
In principle, one could also ask respondents to describe their own thought processes and examine the construals that those reflect. Unfortunately, such retrospective verbal protocols have proven to be questionable indicators of actual thought processes (Fischhoff, 1975; Nisbett and Wilson, 1977). They can be distorted by people's intuitive cognitive theories (i.e., how they that think they think), by self-presentation effects (i.e., how they would like to think), and by subsequently acquired knowledge (i.e., what they now think). In addition, many

148

FISCHHOFF, WELCH AND FREDERICK

different thought processes can lead to the same choices, making it hard to validate any particular description (Dawes and Corrigan, 1974; Slovic and Lichtenstein, 1971). Although researchers sometimes ask respondents how important different task features were to them, these responses are better treated as describing the task than the thought processes.

Construal frameworks
Our interpretation of the river clean-up study was made easier by having some basic science about eliciting and evaluating verbal reports. Our interpretation was handicapped, by our treating the substance of the preference task in an ad hoc way. We made no reference to other studies of how people deal with river clean-ups, nor how they think about public goods or payment schemes, nor what confidence they place in institutions that manage the environment (or that conduct social research). Other scientists make a living studying these topics (Gardner and Stem, 1996). Invoking their work could have constrained our speculations, even when it did not provide complete answers. For example, it would have been nice to know when taxes come to mind, how legitimate they seem, what determines expectations of clean-up success, and so on.
If people have relatively constant tastes, across situations (Becker, 1976), then it should be possible to create general accounts of construal processes. That is, other things being equal, the features that matter to people in one context should matter to them in another. Ideally, we would have empirically grounded theories of construal for each domain of preference elicitation. Those theories would tell us what features concern people and what they presume about missing (or incomprehensible or suspicious) details.
There should be a natural coincidence of interests between researchers for whom understanding construal processes is a means and those for whom it is an end. The latter should welcome having others work on how best to present tasks. The former should welcome seeing their topics incorporated in choice tasks. The remainder of this section describes two approaches to creating this bridge. Each involves creating a general framework, incorporating features occurring in a large class of tasks. That framework allows pooling whatever has been learned about the construal of each feature. If recurrent patterns emerge across tasks, then one can extrapolate them to new situations. If general patterns do not emerge, then one must measure construals in each specific context. The first of the two frameworks deals with evaluating transactions. The second deals with evaluating the consequences of risk behaviors (e.g., smoking, drinking); a complementary framework would consider construing the benefits of such behaviors. Although we have some fondness for these particular frameworks, the logic of their construction and use applies to any functionally equivalent ones.

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

149

Investigator-driven frameworks: construing transactions
Our framework (Fischhoff and Furby, 1988) for transactions arose from a secondary analysis of studies eliciting evaluations of atmospheric visibility/ Some were contingent valuation studies; others were studies of preferences, conducted by environmental psychologists and landscape architects; still others were attitude surveys. Characterizing these tasks revealed great variability in the details that different investigators chose to specify. Although such variability might reflect careless design, this seemed unlikely, considering the effort invested in many studies and the emphasis on task specification in the CV literature (Mitchell and Carson, 1989). Rather, we concluded that the details varied because investigators had different intuitive theories of their respondents' construal processes. Features that some investigators thought went without saying (e.g., that the good will definitely be provided, should the payment be promised), others thought required explicit description, lest respondents produce their own alternative construals.
Table 3 presents the framework. Although illustrated with visibility examples, it is intended to apply more generally, to any opportunity for receiving a good in exchange for a payment, in a social context capable of influencing the transaction's outcome or the process value. People may not care about each substantive feature in the transaction specification (e.g., visual range). However, if they do, then they should care about the formal aspects of its definition (its quantity, the certainty of its provision, the payment period's duration, etc.). Thus, for example, someone who values visual range should be willing to pay more (or campaign harder) for a transaction that promises greater visual range, over a longer time period, or a larger geographical region.
The first feature in the framework, "attribute of visibility," reports four aspects of atmospheric pollution that have been found to affect aesthetic judgments. These are plausible candidates for features that might interest subjects in tasks eliciting visibility preferences. When investigators specify these features, differences in them may account for differences in valuations across studies. When the features are ambiguous, differences in subjects' construals may account for differences in valuations within studies. Our secondary analysis asked whether differences in task specification could account for differences in preferences. However, so many task features varied across studies that no clear signal was possible. However, in future studies, it should be possible to circumscribe those aspects of visibility that matter to people-as an end in itself and as a tool to managing task construal.
The final formal feature for specifying the good is the certainty of its provision (if the transaction is accepted). The manipulation checks for the river clean-up study revealed that respondents were skeptical about our promise to deliver the clean-up, if they provided the payment. If other preference elicitation studies used comparable manipulation checks, we could determine the generality of this finding. Those results could be integrated with basic research into intuitive theories about the trustworthiness of promises (which might be informed by results from manipulation checks in preference elicitation studies).

150

FISCHHOFF, WELCH AND FREDERICK

Respondent-driven frameworks: construing risk behavior choices
The framework in Table 3 was initially derived from the features mentioned explicitly in existing studies. These features reflect those investigators' intuitions about what matters to their subjects (or their sponsors' stipulation of features that they wanted to have mentioned). We supplemented them with features drawn from the social science literatures on decision making and responses to environmental changes.
The alternative strategy is initially to derive a framework from lay beliefs. We have done this with a pair of convergent procedures. The first asks respondents to think aloud as they read deliberately underspecified questions. That protocol uses a "funnel" design, with increasingly specific prompts. Respondents are asked, initially, just to express their thoughts. Then, as the interview progresses, they are asked what they mean by those thoughts, which missing details would have helped them to answer, and what assumptions they made (e.g.,"Oh, when I hear drinking and driving, I always think about what happened to my friend Jeff, who ... ").
Table 4 shows the result of applying this approach to adolescents' evaluations of possible negative consequences of risk behaviors, like drinking and smoking. It

Table 3. Components for defining transactions (with examples from visibility valuation)
The Good (e.g., visibility) Substantive Definition Attribute(s) Haze intensity Visual range Plume (color) Light extinction Context Natural or built Judged uniqueness Associated activities (e.g., hiking, viewing, playing) Significance (e.g., religious, culture, historical) Source of Change Predominantly natural (e.g., vegetation, forest fires, dust storms, humidity) Predominantly human (e.g., power plant, other factories, field burning, slash burning, motor vehicles) Formal Definition Reference and Target Levels Magnitude and direction of change Statistical summary Representation (mode, richness, organization) Extent of Change Geographical Temporal (existence, direct enjoyment) Timing of Change Certainty of Provision

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

151

Table 3. Continued
The Value Measure (e.g., money, time, discomfort, effort) Substantive Definition Attribute(s) Leisure, work (for time) Physical, emotional (for discomfort) Context Electric bill, sales tax, income tax, park entry fee, environmental fund (for money) When convenient, when demanded (for time) When rested, when exhausted (for effort) Constituency Formal Definition Reference and Target Levels Magnitude and direction of change Statistical summary Elicitation (response mode, response format, cues, feedback) Extent Frequency Duration Timing of Payment Certainty of Payment The Social Context Other People Involved Provider of the good Others present Resolution Mechanism Determining parties Iterations Constraints Other Stakes Externalities Precedents Legitimacy of process
Source: Fischhoff and Furby (1988).

groups features into Behavior (expressed in terms of dose determinants), Other Behaviors (affecting the expression and effects of the behavior), the Actor, Context, and the Outcome. The subfactors are general statements of ones that might seem relevant to a given risk domain. They are illustrated with examples for drinking and driving.
We conducted such interviews with 61 adolescents, drawn from diverse backgrounds. They thought aloud, while answering questions like "What is the probability that someone who drinks and drives will get into an accident?" Most (49) of these young people wanted to know how much driving was involved (categorized as "amount" under Behavior). One-quarter (15) wanted to know something about the kind of driving (categorized under "potency").8 And so on. Research design is simplest when some features appeared in most individuals' construals of most

152

FISCHHOFF, WELCH AND FREDERICK

Table 4. Coding framework Framework element BEHAVIOR OTHER BEHAVIORS ACTOR
CONTEXT RISK OUTCOME
Source: Fischhoff (1996).

Risk factor categories
Amount Potency Method Risk Buffers Risk Amplifiers Time-Related Place-Related Physical Cognitive Social-Psychological Material Spiritual Skill Character Age Gender Genetic History Status Luck Motivation Self Other Social General, cultural
Family Peers, others Environmental Social Reactions Personal Effects Physical Psychological Cognitive-Physiological Cognitive-Psychological Material Accidents Lifestyle Complex Effects on Others Behaviors Severity, type when measured

Example variables drinking-and-driving question
Amount of alcohol consumed
Amount of food eaten Other drugs consumed Night or day; day of the week Where alcohol was consumed Tolerance to alcohol Awareness of effects of alcohol Mood Wealth Faith Driving skill Responsible; mature
Drinking norms Family approval Peer approval Road conditions Get in trouble
Injury Worry, guilt Kill brain cells Can't think Lose car, lose license Get in a wreck while high Become a bum Get high Hurt your friends, family Use more, do heavier drugs

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

153

tasks, while other features seldom arise. Then researchers could specify just the focal features, revealed by studies like this one. For example, most teens' construals of most events included the amount of the risk behavior; thus, investigators should always assume that they need to specify that feature, lest respondents invent a value.9 The salience of other features was more variable across our 9 risk behaviors (e.g., when the effects were measured, how potent each exposure was, how it was administered). As a result, the salience of these features must be studied for each risk.
The second, converging procedure in this approach uses structured questionnaires to see whether people actually use the factors evoked during the open-ended interviews. The questionnaires present almost fully specified tasks, including all but one of the features mentioned by any significant portion of interview respondents. Questionnaire subjects evaluate this complex stimulus once, then repeat the task after receiving a value for the missing feature. They also receive values for two other missing features-but ones rarely mentioned in the open-ended interviews. If people have stable construal processes, then questionnaire subjects should be more sensitive to learning about a factor cited often in the open-ended interviews than to learning about a factor that was seldom cited. This was the case in our study. Furthermore, youths drawn from high-risk and low-risk settings (e.g., juvenile detention centers, swim teams) responded similarly. As a result, similarly specified questions could be used with these diverse populations.10·11

Construal-sensitive preference elicitation
Investigators can respond to construal processes either proactively or reactively. That is, they can try to control construal processes, by focusing respondents on the specific questions that they want answered. Or, they can deal with the residue of uncontrolled construal processes, somehow translating elicited preferences into the ones of interest. Implementing either strategy requires knowing what question is intended and what question has been answered. This section considers these options.

Proactive design
Ideally, one would control respondents' construal processes by fully specifying tasks, in terms that respondents will readily understand and accept. The empirical study of construal processes can guide that specification, by identifying the features that typically matter and features that can be ignored (because people are indifferent to them). The next section describes a study that relied heavily on existing research to apply a full specification strategy. The section after it describes a study clarifying the construal of a feature that might concern many respondents in many studies: how the results will be used.

154

FISCHHOFF, WELCH AND FREDERICK

BTU tax: implementing a fuU scenario. Several years ago, we followed a proactive strategy in eliciting preferences among the tradeoffs embodied in the BTU tax proposed early in the first Clinton Administration. Although complex, the BTU tax lent itself to proactive design for several reasons. One is that the Administration's proposal provided the details for specifying most elements in the transaction framework (Table 3)_12 Moreover, these details were derived from a more or less common conception; having a transaction with a relatively high degree of coherence increases the amount of detail that can be conveyed without cognitive overload. A second reason is that members of our climate research group had modeled the tax's impacts, allowing us to answer respondents' questions on issues like distributional effects (Dowlatabadi and Morgan, 2000). Third, we had just developed a brochure explaining climate change, allowing us to present the relevant science relatively clearly (Bostrom et al., 1994; Morgan, 1995; Read et al., 1994).
In a situation that clearly called for constructed preferences, we used a group format to discuss issues, with the moderator working to bring the full specification to participants' attention. However, the preferences used in data analyses were collected privately, at several points in the proceedings-so that they would represent individuals' personal values, not just the ones that they felt comfortable expressing publicly, in this arbitrary group of people (see also Morgan et al., 1996).
Our experience provided some reason for optimism about this approach: (a) Participants seemed to take their task seriously and be glad to be involved, consistent with other experiences in value-focused thinking (Keeney, 1992; National Research Council, 1996). (b) Their questions required drawing on our prepared information. (c) There were few overt expressions of confusion or protest responses. (d) On various measures, participants reported satisfaction with the procedure. (e) The preferences that they expressed seemed reasonable and sensitive to task details. (f) Respondents evaluated variants on the Administration's proposal similarly, except for strongly preferring it as part of an international agreement (consistent with other research on perceived equity; Earle and Cvetkovich, 1995). Overall, respondents were split about evenly regarding the tax, with supporters holding their views more strongly than opponents at the beginning, and strongly less at the end.
Unfortunately, events caught up with us before we could collect a full sample: The Administration withdrew the proposal, in so public a fashion that we discontinued the study. Nonetheless, this example shows what proactive design demands: fully specified tasks, technical analysis of policy issues, tested methods for explaining the science, and opportunities for participants to moot them (Fischhoff, 1997). How heavily the design must rely on intuition depends on how much of the needed research is already in place.
Monongahela clean-up: determining the bounds of a scenario. With the BTU tax, the Administration specified the proposed transaction. Our task was to translate it into framework terms, then present it comprehensibly. Often, though, knowing what to

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

155

include is less clear. One common issue is what to say about a study's purpose. A common philosophy is to say nothing beyond "we want your true preferences," hoping to discourage strategic responses. However, if respondents care about this aspect of the transaction's social context, they are likely to assume something. The investigators' silence may then evoke distrust, as well as leaving a vacuum-affecting both outcome and process value.
Deciding what to say is partly a matter of principle. Scientists disagree about the legitimacy of withholding such information and about how it affects a task's incentive compatibility. The importance of these disagreements depends on how much of a difference the disputed information makes. In a recent study (Welch and Fischhoff, 1999), we examined the impact of telling about the contingent valuation method, on responses to a CV-like study. Specifically, we asked Pittsburgh-area residents (e.g., Rotarians) for their willingness to pay to reduce acid mine drainage (AMD), into the Monongahela River.U At one point in the process, respondents were told about CV, either in brief or with a set of reasons supporting and opposing its use as a public policy tool. In different conditions, respondents evaluated the good with and without knowledge of CV; they also evaluated CV with and without having evaluated the good.
Our respondents showed a mixture of sensitivity and insensitivity to this aspect of social context. Their median WTP was always $50, whenever they were asked and whatever they had been told about CV. However, in both between- and within-subject comparisons, the more respondents knew, the less happy they were. Only 55% of those who had both performed the evaluation task and been told about the CV context said that they would agree to participate in such a study, compared with 79% of those who had had neither experience. Having evaluated the good slightly decreased how convincing respondents found the reasons favoring CV (from 3.7 to 3.5 on a 1-5 scale), while somewhat increasing how convincing they found the reasons opposing it (from 2.8 to 3.3). Ratings of CV's legitimacy predicted respondents' sensitivity to task-specification problems if they had evaluated the good, but not if they had not.
If these results are robust, then we can fulfill our ethical obligation to describe the purpose of CV studies (and perhaps other tasks), without affecting expressed preferences. Some other aspects of these results were also encouraging for CV proponents: respondents were somewhat more persuaded by the reasons legitimating CV than by the reasons opposing it. Most were willing to have their responses used in setting public policy. However, respondents' support declined, as they learned more about their task (both from being told about it and from trying to perform it). Perhaps better proactive design could increase support.

Reactive Analysis
However clear a task's specification, and however diligent its presentation, there will often be gaps between the question being asked and the question being

156

FISCHHOFF, WELCH AND FREDERICK

answered. What should be done with the residual imperfections? For example, how do we treat the preferences of respondents who reported evaluating 10 miles of river clean-up, when we stated 1000, or those who reported expecting less than the promised full clean-up (i.e., "good headway" or "not much"). Presumably, their value for the stated amount is larger than their response indicates. Should we act as though these people answered our question, when they did not?
There are three possible strategies for addressing these residual imperfections: disqualification (eliminating respondents whose construals have strayed too far from the intended one), adjustment (modifying observed preferences to those that would have followed from the intended construal), and accommodation (living with the problems, and reflecting them in the study's conclusions). The choice among these strategies depends on the data and on one's data-treatment philosophy.
Disqualification. Historically, social scientists have been very reluctant to discard respondents. In this sense, the CV literature is unusual in using practices such as "alpha-trimming" (disqualifying some percentage, alpha, of the highest and lowest responses) and omitting "protest responses." As a result, respondents may unwittingly disqualify themselves by expressing extreme valuations.14 Nonetheless, some methodologists argue that sciences needlessly handicap themselves by including all data no matter how deviant (Wilcox, 1998).
Rejecting respondents on the basis of deviant manipulation checks, however, raises different philosophical questions. For example, few respondents in the river clean-up study passed all four manipulation checks. Many got all four wrong. One might argue that it is dishonest to pool the responses of individuals who are answering fundamentally different questions. Moreover, extensive misconstrual need not mean carelessness. A thoughtful individual could have a coherent reinterpretation of an entire task. On the other hand, one might want to preserve just such misconstruals, if they parallel those to be expected in the real world (e.g., when voters misread the meaning of an election).
A4justment. When people misconstrue the formal features of a transaction, and investigators know (or can conjecture) basic structural properties of respondents' preferences, systematic adjustment may be possible. Assume, for example, that "good headway" on the river clean-up means 50% completion. Then WTP for the "complete clean-up" might be roughly double the WTP expressed by a respondent who construed it as meaning just good headway. Similar logic could be used to adjust WTP values for respondents who misconstrued the river lengths (although that value might not be linear with length, as it should be linear with probability of completion).
Such adjustments may be less feasible when substantive features are misconstrued. For example, some ways of paying may be more legitimate than others, hence command a larger WTP (reflecting their greater process value). Dedicated studies might estimate the conversion factor for going, say, from "WTP with taxes"

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

157

to "WTP with higher prices for goods and services."15 If that conversion factor is similar for different goods, then this result could to be reused, providing an empirical estimate for that element in the transaction framework.
Accommodation. Adjustment and disqualification can be controversial practices. An alternative strategy is to accommodate these problems in a fuller reporting of all data-aggregating responses corresponding to qualitatively similar construals. Thus, readers would be told such things as (a) what percentage of respondents passed each (and all) manipulation check(s), (b) which misconstruals occurred frequently and what they suggest about how people view the topic, (c) how evaluations varied with construals, (d) how well respondents felt that their judgments represent their preferences, and (e) how different adjustment and disqualification procedures affect the overall picture.
Such full reports would allow a reader to see how respondents thought about their task, in addition to what they said about their preferences. Readers would get a feeling for what respondents meant by their answers, and how seriously they want to (or should) be taken. Complex accounts may still allow practical and theoretical conclusions (e.g., if most respondents who take the task seriously express similar preferences, if preferences differ in ways consistent with construals). Full accounts may, however, frustrate those hoping to reduce preferences to simple numbers suited to mechanical aggregation.

Conclusion
Taking construal processes seriously can be troublesome in the short run. It introduces an unwanted dimension of complexity into task design. It opens the door to alternative interpretations of responses. It slows the pace at which studies can be run. It is only natural to want to handle construal processes as expeditiously as possible, by reusing familiar tasks, trusting one's intuitions, or conducting minimal pretests. Sometimes, these practices will suffice. Where they don't, shortterm expediency can mean long-term inefficiency, if fundamental problems are persistently neglected.
As a reflection on where we stand, Table 5 offers excerpts from think-aloud protocols conducted with two California residents. Each was asked to express willingness to pay for the Long Beach Harbor clean-up, using instructions from the NOAA benchmark study (Carson et al., 1994). Participant 1 seems initially to accept the scenario at face value, but then to have second thoughts, once a higher cost is suggested. Indeed, this within-subject manipulation of the "referendum" price apparently calls the entire clean-up program into question. As a result, it is unclear whether this individual's expressed preference refers to the specified clean-up, or just to some portion of it. Participant 2 has serious questions about the quality of the science underlying the clean-up program. Initially, she explains her

158

FISCHHOFF, WELCH AND FREDERICK

$1 WTP response as a gesture, rather than as a value for the good. Further reflection leads, not only to abandoning that response, but to a demand to be compensated for the "clean-up," which she now sees as environmentally destructive. Given the great effort invested in the Long Beach study, these construals suggests a need to move beyond the current state of the art in creating tasks with the intended meanings.
We propose here such an approach, based around standard frameworks for specifying tasks, like those in Tables 3 and 4. These frameworks are complex, so much so that it is small wonder if researchers worry, "Could any CV study meet all the criteria ... set out by Fischhoff and Furby (1988)?" (Schkade and Payne, 1993, p. 289). The complexity of the framework, however, reflects the richness of the construal processes that people naturally undertake when confronted by tasks with too many or too few details. A framework can make that complexity more tractable by providing a way to coordinate empirical research on particular construal processes. For example, there is an extensive literature on environmental psychology that might inform the elicitation of preferences regarding environmental goods

Table 5. Two think-aloud protocols, evaluating a Long Beach Harbor clean-up
Participant 1 At present, the program to speed up covering of the contaminated sediment is estimated to cost your household a total of $80. Your household would pay this as a special one-time tax added to next year's California income tax. If an election were being held today and the total cost to your household would be a one-time additional tax of $80, would you vote for the program or would you vote against it?
I would have to think about it. I'm into the environment, but I don't know right now. I couldn't say. I probably would vote for it, but I don't know. If it came up on the ballot, I probably would vote for it. I'm sure, though, that the money could be spent on schools-towards education. I'm not happy with my kids' education. So, if it came to this program here or schooling, I would vote for the schooling.
It is possible that the final engineering cost estimates would be higher than this. If it turns out to be the case and your household would have to pay a one-time tax of $140 instead of $80, would you vote for or against the program?
I'd say that I'd have to vote against it then. You see, that's something, too. It always seems thatthey always say it's going to be $80, but it ends up being $140 anyway. That's why I say I don't know right now-I would have to hear more about the program.
When you voted, did you think your household would have to pay the special tax for 1 year or more than one year?
That's what I was saying before. The government tells you one thing, but then it always tends to be more than what they told you. So, it wouldn't surprise me if it did get voted for and we did have to pay the tax, that it could end up as more than $80 per household. That wouldn't surprise me at all.
Do you believe that DDT and PCB could cause the problems I described.
If they've checked into it and they say that's what the problem is, then yeah, I'd say 'sure.'

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

159

Table 5. Continued
Participant 2 Do you have any questions about how [the clean-up process] would work? Where has it been done elsewhere? How did they determine whether it was successful? Is the sediment they are going to dump, exactly like the sediment on the bottom of the ocean? And also dumping all this stuff in the ocean could affect something they don't foresee. And what about other species? Does the absence of these birds affect other species, like bobcats, or animals that live in the mountains?
At present, the program .... Would you vote for the program or would you vote against it? Against.
What is the most that you would pay? $1 How did you arrive at that figure? I just figure the program would give some people some jobs, and I could part with a dollar. But I kind of think it's a foolish idea. I'm still worried about the effects of the program. [Such as?] Well, the organisms on the ocean floor and the plant life could possibly be harmed by all the dumping. I don't think this is a good idea at all. [But earlier you said you would pay to support the program.] That's a very good point. I guess I should pay to not have program occur, according to what I just said.
Source: Light type taken from (Carson et al., 1994); boldface from interviews conducted in Oakland, CA, July 24-25, 1997.

(e.g., Stokols and Altman, 1987), another literature on people's sensitivity to social context (e.g., Earle and Cvetkovich, 1995), and yet another on measurement artifacts in interview and experimental settings (Rosenthal and Rosnow, 1969). Studies of lay beliefs and intuitive theories show the factors likely to evoke construal processes in specific domains (Fischhoff, 1992; Fischhoff et al., 1997; Furnham, 1989).
Thus, a construal framework shows where to look for relevant research and offers a way to use what is found. It facilitates comparisons across tasks, by characterizing them in common terms. It encourages coordinating research from across the social sciences. In time, the designers of a task could just look up the results pertaining to a particular feature and be able to anticipate its construal. For their part, preference elicitation studies often involve imaginative, involving tasks. Studying how people construe them might produce valuable insights for domain researchers. For example, the responses to our Mon clean-up study could inform studies of social trust, just as studies of that topic informed our design.

160

FISCHHOFF, WELCH AND FREDERICK

How intensely to seek this ideal should depend, in part, on who pays the price for untreated misconstruals. With studies motivated by purely scientific concerns, investigators bear the costs of error. Poor measurement reduces the power of their designs and increases the chance of artifactual results. With applied science, respondents may bear the risk. The implicit warranty accompanying a study is that the investigators know what questions respondents have answered. When that is not case, respondents have been misrepresented and their informed consent violated.

Acknowledgments
The support of the Environmental Protection Agency and by the U.S. National Science Foundation through the Center for the Integrated Assessment of the Human Dimensions of Global Change at Carnegie Mellon University, cooperative agreement number SBR-9521914.

Notes
1. Table 3, discussed below, presents examples of structural and substantive features, when evaluating changes in atmospheric visibility.
2. The doctoral proposal raises a familiar variant on these processes. Not all details can be specified. Indeed, innovative work means having freedom to follow promising new directions, as they arise. When candidate and committee belong to the same intellectual community, they will agree on whether the resulting work represents a plausible construal of the dissertation "contract." Painful mismatches can occur when candidates are less completely socialized than they, or their advisors, realized.
3. With real-world transactions, elements of people's preferences may be embedded in the relationship between the parties. One of us (BF) once received an anxious call from the real-estate editor of a major newspaper, concerned because he had made a Sunday morning bid on a house, while still hung over from the night before. The editor did not notice, and could not remember, many features of his own real-estate transaction, including ones that he routinely stressed to his readers. In our conversation, we pieced together just how many of his values were already incorporated in the procedures that determined the set of houses that his agent would show him and those that would follow making the offer (e.g., inspections, credit checks).
4. Some professions (e.g., history, clinical psychology, anthropology) require apprenticeships, designed to reintroduce a sort of disciplined naivete. Their graduates hope to decipher lay construals, freed of preconceptions. Belonging to relatively atheoretical disciplines may help them to see a wide range of construals.
5. If the variability in respondents' interpretations is predictable, it might justify "audience segmentation," providing stimuli that are functionally equivalent, although literally different (e.g., by using the terms most familiar to each audience). Alternatively, one could allow respondents to ask clarifying questions, the answers to which would tailor the presentation to their personal needs. Such departures from standardization make some researchers nervous. Their fears over communicating unintended messages outweigh their concerns over leaving respondents confused and appearing uncooperative.

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

161

6. In this case and others, some respondents may have tried to evaluate the good as described, even if they did not believe the description.
7. Including the one in Table 2. 8. The other questions dealt with the chances of smoking cigarettes leading to cancer, smoking
cigarettes leading to addiction, using cocaine leading to health problems, using cocaine leading to addiction, using marijuana leading to health problems, drinking alcohol leading to addiction, sex leading to AIDS, and sex leading to pregnancy. 9. The one exception is that the teens in this study did not consider the amount of sex, when estimating the risks of AIDS and pregnancy as possible consequences. Such dose (or scope) insensitivity has been found in other contexts as well (e.g., Linville et al., 1993; Shaklee and Fischhoff, 1990). It suggests that teens (and adults) may evaluate similarly the risks associated with different amounts of sex. As a result, with the sex-related questions, a researcher would be in the strange circumstances of having descriptive grounds for omitting a normatively relevant feature. 10. The connection between the two frameworks is as follows: voluntarily engaging in a risk behavior means accepting a transaction. The payment includes accepting the risks of negative outcomes, like those in Table 4. For an individual who cares about them, these outcomes are substantive features in the "value measure" of the transaction (as are the monetary costs of drugs, sex, alcohol, etc.). The Behavior information in Table 4 partially determines the formal features of the transaction (i.e., the probability and extent of the substantive features). 11. A list structure, like Tables 3 and 4, is, of course, not the only possible representation for a set of factors. In studies of lay understanding of health and environmental risks, we have represented features with influence diagrams (Clemen, 1991; Howard, 1989). We create them with a combination of investigator- and respondent-driven approaches. An "expert" model is created, summarizing the scientific literature. It structures subsequent think-aloud protocols using a funnel design, gradually focusing lay respondents on topics in the expert model (e.g., Bostrom et al., 1994; Fischhoff, in press; Fischhoff et al., 1998; Morgan et a!., 1992). 12. In this way, it was quite different from a CV study, in which investigators typically have little guidance on how to specify many elements of the transaction. 13. We had wanted to replicate the Mon River CV study conducted by Desvousges et al. (1987), in the early 1980s. However, we discovered that the river was much cleaner than it had been back then (e.g., the Point, in downtown Pittsburgh, has been rated one of the top 10 fishing spots in Western Pennsylvania). This happy discovery led us to change the environmental good to one that is more pertinent (and the subject of occasional local news coverage, usually associated with the sort of major breaches that the proposed program would alleviate). 14. It might, of course, be possible to bias the distribution of legitimate responses without looking directly at their values. If some misconstruals tend to be associated with particularly high (or low) evaluations, they could be disqualified on misconstrual grounds, indirectly changing the distribution of evaluations. 15. In addition to evoking real preferences, the payment vehicle can also have an artifactual impact, by suggesting the magnitude of the expected payment (e.g., changes in income tax may be larger than changes in user fees). Such anchoring effects have been studied extensively by psychophysicists, whose literature is a place to start an analysis of adjustment factors (Poulton, 1989; Schwarz, 1999).

References
Becker, G. (1976). The Economic Approach to Human Behavior. Chicago: University of Chicago Press. Bostrom, A., M. G. Morgan, B. Fischhoff, and D. Read. (1994). "What Do People Know about Global
Climate Change? Part 1. Mental models," Risk Analysis 14, 959-970.

162

FISCHHOFF, WELCH AND FREDERICK

Carson, R. T., W. M. Hangmann, R. J. Kopp, J. A. Krosnick, R. C. Mitchell, S. Presser, P. A. Rudd, and V. K Smith. (1994). "Prospective Interim Lost Use Value Due to DDT and PCB Contamination in the Southern California Bight," NOAA Contract No. 50-DGNC-1-D0007.
Clemen, R. (1991). Making Hard Decisions: An Introduction to Decision Analysis. Boston: PWS-Kent. Dawes, R. M. and B. Corrigan. (1974). "Linear Models in Decision Making," Psychological Bulletin, 81,
95-106. Desvousges, W. H., V. K Smith, and A. Fisher. (1987). "Option Price Estimates for Water Quality
Improvement: A Contingent Valuation Study for the Monongahela River," Journal of Environmental Economics and Management 14, 248-267. Dowlatabadi, H. and M. G. Morgan, (2000). /CAM: Integrated Assessment of Global Change, book manuscript in preparation. Earle, T. C. and G. T. Cvetkovich, (1995). Social Trust. Westport, CT: Praeger. Ekman, P. (1985). Telling Lies. New York: W. W. Norton. Ericsson, A. and H. Simon. (1994). Verbal Reports as Data, 2nd ed. Cambridge, MA: MIT Press.
Fischhoff, B. (1975). "Hindsight + foresight: The Effect of Outcome Knowledge on Judgment under
Uncertainty," Journal ofExperimental Psychology: Human Perception and Performance, 104, 288-299. Fischhoff, B. (1991). "Value Elicitation: Is There Anything in There?" American Psychologist 46,
835-847. Fischhoff, B. (1992). "Giving Advice: Decision Theory Perspectives on Sexual Assault," American
Psychologist, 47, 577-588. Fischhoff, B. (1996). "The Real World: What Good Is It?" Organizational Behavior and Human Decision
Processes 65, 232-248. Fischhoff, B. (1997). "What Do Psychologists Want? Contingent Valuation as a Special Case of Asking
Questions." In W. Pommerehne, N. Schwarz and R. Kopp (eds.), Determining the Value of Nonmarketed Goods, pp. 189-217. New York: Plenum. Fischhoff, B. (in press). "Why (Cancer) Risk Communication Can Be Hard," Journal ofNational Cancer Institute. Fischhoff, B., A. Bostrom, and M. J. Quadrel. (1997). "Risk Perception and Communication." In R. Detels, J. McEwen, and G. Omenn (eds.), Oxford Textbook of Public Health, pp. 987-1002. London: Oxford University Press. Fischhoff, B., J. Downs,and W. Bruine de Bruin. (1998). "Adolescent Vulnerability: A Framework for Behavioral InteiVentions," Applied and Preventive Psychology 7, 77-94. Fischhoff, B. and L. Furby. (1986). "A Review and Critique of Tolley, Randall et al. "Establishing and Valuing the Effects of Improved Visibility in the Eastern United States," ERI Technical Report 86-8. Eugene, OR: Eugene Research Institute. Fischhoff, B. and L. Furby. (1988). "Measuring Values: A Conceptual Framework for Interpreting Transactions," Journal of Risk and Uncertainty 1, 147-184. Fischhoff, B., M. J. Quadrel, M. Karnlet, G. Loewenstein, R. Dawes, P. Fischbeck, S. Klepper, J. Leland, and P. Stroh. (1993). "Embedding Effects: Stimulus Representation and Response Modes," Journal of Risk and Uncertainty, 6, 211-234. Fischhoff, B., P. Slovic, and S. Lichtenstein. (1980). "Knowing What You Want: Measuring Labile Values." In T. Wallsten (ed.), Cognitive Processes in Choice and Decision Behavior, pp. 117-141. Hillsdale, NJ: Erlbaum. Frazier, L. and C. Charles. (1995). Construal. Cambridge, MA: MIT Press. Fumham, A. (1989). Intuitive Theories. London: Plenum. Gardner, G. T. and P. Stem. (1996). Environmental Problems and Human Behavior. Needham Heights, MA: Allyn and Bacon. Gilovich, T., R. Vallone, and A. Tversky. (1985). "The Hot Hand in Basketball: On the Misperception of Random Sequences," Journal of Personality and Social Psychology 17, 295-314. Gold, E. (1997). "The Gambler's Fallacy," Ph.D. dissertation, Carnegie Mellon University.

CONSTRUAL PROCESS IN PREFERENCE ASSESSMENT

163

Gregory, R., S. Lichtenstein, and P. Slovic. (1993). "Valuing Environmental Resources: A Constructive Approach," Journal of Risk and Uncertainty 7, 177-197.
Grice, H. P. (1975). "Logic and Conversation." In D. Davidson and G. Harman (eds.), The Logic of Grammar. Encino, CA: Dickenson.
Hasher, L. and R. T. Zacks. (1984). "Automatic and Effortful Processes in Memory," Journal of Experiment Psychology: General108, 356-388.
Hilton, D. J. (1990). "Conversational Processes and Causal Explanation," Psychological Bulletin 107, 65-81.
Howard, R. A. (1989). "Knowledge Maps," Management Science 35, 903-922 Keeney, R. K. (1992). Value-Focused Thinking. Cambridge, MA: Harvard University Press. Linville, P. W., G. W. Fischer, and B. Fischhoff. (1993). "AIDS Risk Perceptions and Decision Biases."
In J. B. Pryor and G. D. Reeder (eds.), The Social Psychology ofHW Infection, pp. 5-38. Hillsdale, NJ: Erlbaum. Lopes, L. (1982). "Doing the Impossible," Journal of Experimental Psychology: Learning Memory and Cognition 8, 626-663. McGuire, W. (1969). "Suspiciousness of Experimenter's Intent," In R. Rosenthal and R. L. Rosnow (eds.), Artifact in Behavioral Research. New York: Academic Press. Mitchell, R. C. and R. T. Carson. (1989). Using Surveys to Value Public Goods: The Contingent Valuation Method. Washington, DC: Resources for the Future. Morgan, M. G. (1995). "Climate Change: A Citizens Guide," Department of Engineering and Public Policy, Carnegie Mellon University. Morgan, M. G., B. Fischhoff, A. Bostrom, L. Lave, and C. J. Atman. (1992). "Communicating Risk to the Public," Environmental Science and Technology 26, 2048-2056. National Research Council. (1982). Survey Measure of Subjective Phenomena. Washington, DC: National Academy Press. National Research Council. (1996). Understanding Risk. Washington, DC: National Academy Press. Nisbett, R. E. and T. D. Wilson. (1977). "Telling More Than We Know: Verbal Reports on Mental Processes," Psychological Review 84, 231-259. Payne, J. W., J. R. Bettman, and D. A. Schkade. (1999). "Measuring Constructed Preferences: Towards a Building Code," Journal of Risk and Uncertainty 19, 243-270. Peterson, C. R. and L. R. Beach. (1967). "Man as an Intuitive Statistician," Psychological Bulletin 69(1), 29-46. Poulton, E. C. (1989). Bias in Quantifying Judgment. Hillsdale, NJ: Lawrence Erlbaum. Read, D., A. Bostrom, M.G. Morgan, B. Fischhoff, and T. Smuts. (1994). "What Do People Know about Global Climate Change? Part 2. Survey Studies of Educated Laypeople," Risk Analysis, 14, 971-982. Rosenthal, R. and R. L. Rosnow. (eds.) (1969). Artifact in Behavioral Research. New York: Academic Press. Schkade, D. A. and J. W. Payne. (1993). "Where Do the Numbers Come From? How People Respond to Contingent Valuation Questions." In J. A. Hausman (ed.), Contingent Valuation: A Critical Assessment, pp. 271-293. Boston: Elsevier. Schkade, D. A. and J. W. Payne. (1994). "How People Respond to Contingent Valuation Questions: A Verbal Protocol Analysis of Willingness to Pay for an Environmental Regulation," Journal of Environmental Economics and Management 26, 88-109. Schriver, K. A. (1989). "Evaluating Text Quality: The Continuum from Text-Focused to Reader-Focused Methods," IEEE Transactions on Professional Communication 32, 238-255. Schwarz, N. (1997). Context Effects in Survey Research. Hillsdale, NJ: Lawrence Erlbaum Associates. Schwarz, N. (1999). "Self-Reports: How the Questions Shape the Answers," American Psychologist, 54, 93-105.
Shaklee, H. and B. Fischhoff. (1990). "The Psychology of Contraceptive Surprises: Judging the Cumulative Risk of Contraceptive Failure," Journal ofApplied Psychology 20, 385-403.

164

FISCHHOFF, WELCH AND FREDERICK

Slavic, P. and S. Lichtenstein, (1971). "Comparison of Bayesian and Regression Approaches to the Study of Information Processing in Judgment," Organizational Behavior and Human Performance, 6, 649-744.
Stokols, D., and I. Altman, (eds.) (1987). Handbook of Environmental Psychology, 2 Vols. New York: Wiley.
Tolley, G., A. Randall, et al. (1986). "Establishing and Valuing the Effects of Improved Visibility in the Eastern United States," Report to the Environmental Protection Agency.
Tune, G. S. (1964). "Response Preferences: A Review of Some Relevant Literature," Psychological Bulletin, 61, 286-302.
Tversky, A., and D. Kahneman, (1974). "Judgment under Uncertainty: Heuristics and Biases," Science 185, 453-458.
Welch, N. and B. Fischhoff, (1999). "Social Context and Environmental Valuations," Manuscript under
editorial review. Wilcox, R. R. (1998). "How Many Scientific Discoveries Have Been Lost by Ignoring Modem Statistical
Methods?" American Psychologist, 53, 300-314. Wilson, T. D., D. J. Lisle, J. W. Schooler, S. D. Hodges, K. J. Klaaren, and S. J. LaFleur. (1993).
"Introspecting About Reasons Can Reduce Post-Choice Satisfaction," Personality and Social Psychology Bulletin 19, 331-339.

Journal of Risk and Uncertainty, 19:1-3; 165-167 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Commentary on Fischhoff et al., "Construal Processes in Preference Assessment"

JEFF DOMINlTZ

Dominitz@resecon.com

Resolution Economics LLC, 9250 Wilshire Blvd., Suite 400, Beverly Hills, CA 90212

Suppose a naive researcher has decided to study risk preferences. This researcher first approaches an economist and inquires about the best empirical methods for studying preferences. The economist replies that the best approach is to study existing data on individual choices (e.g., investment behavior) or perhaps to pose a series of choice problems (e.g., choice among lotteries) in an experimental setting. The economist argues that, after observing the choices individuals actually make, preferences may be inferred. In contrast, when the researcher questions a cognitive psychologist, the advice is to ask hypothetical choice questions or perhaps qualitative survey questions eliciting responses on a seven-point scale.
What is the naive researcher to infer from the responses provided by the economist and the cognitive psychologist? He or she could infer, for example, that the economist has considered and rejected the verbal methods for eliciting preferences described by the psychologist. Similarly, the psychologist may have considered and rejected the revealed preference approach.
However, what if the economist has assumed that the researcher is an economist? Then one may infer that the economist simply believed that any method other than revealed preference analysis is unlikely to be valued in the profession and therefore other approaches were not even considered. The cognitive psychologist, working under the assumption that the researcher is instead a cognitive psychologist, may have behaved similarly. Thus, if both respondents construed the question to be: "What is the best method for someone in your profession?" then the responses may be misinterpreted.
How then should this researcher identify the best empirical methods for studying preferences? Some might argue that the correct approach is to forget about asking other researchers what they think is best to do and instead investigate what they actually do. Such an approach would probably involve an extensive literature search over many relevant disciplines. This study would be quite time intensive and would ultimately rely upon (1) a model in which the best methods are asserted to be those that have led to publication and (2) a judgment by the researcher as to which among the published methods is actually best. It would seem that much time and effort could be saved by simply devoting more attention to the interview

166

DOMINITZ

method. Of course, in practice, any good researcher, economist or otherwise, will actually utilize both methods when beginning a new topic of study.
As revealed in this journal and in the conference on which it is based, many economists are interested in utilizing methods of learning about preferences other than revealed preference analysis. What then can this paper do to help these economists and other researchers who are new to eliciting subjective reports? I believe its main contribution is to focus attention on the so-called construal process as an inherently interesting subject of study, not simply because variation among respondents leads to variation in responses and mistaken inferences, but because these processes are a critical element of decision making in many arenas. Increased understanding of how individuals process information in the context of a survey interview may, for instance, lead to increased understanding of how they process information when comparison shopping, be it in a grocery store or an election booth. As the authors argue, "Construal processes are a necessary part of everyday life."
The paper could be more helpful to economists and others, however, if it modeled the respondent as explicitly facing a choice problem. Providing a more formal structure may allow readers to more easily understand and compare the findings from the case studies, anecdotes, and hypothetical statements discussed in this paper.
As an example, consider the controversial subject of contingent valuation (CV). When asked about the value of cleaning up a river, the respondent must engage in what the authors refer to as a "constructive" process, as opposed to "the straightforward 'read out' of a previously derived value." In other words, the respondent is uncertain about his or her valuation of the project should the hypothetical situation actually arise.
How should the respondent choose to answer the CV question? As an economist, I would attempt to model the respondent's problem in terms of expected utility maximization. Arguments in the utility function may include the effort required to formulate the response and various attributes of the organization or individual asking the question. These factors are considered in this paper, as well as elsewhere in this journal. For the moment, however, suppose that expected utility is maximized by simply reporting the best assessment of the subjective monetary value of the project, where "best" is as yet undefined. The respondent is uncertain about this value, so the task may be recast in terms of a prediction problem. That is, the respondent attempts to answer the question: "Given what I know now, what
is my best guess at the value I would be willing to pay1accept were I to actually be
faced with such a decision?" To answer a question of this form, the respondent may be modeled as first
considering the range of possible values and their associated probabilities conditional on the information at hand. The relevant information includes that offered by the interviewer and prior information possessed by the respondent. This prior information includes not only knowledge about his or her own preference ordering

COMMENTARY

167

-presumably the subject of interest to the investigators-but also information on how to interpret the information provided by the interviewer-the process of interest in this paper. If we replace the word interoiewer with advertiser, political candidate, or used car salesman, it becomes clear that similar issues arise in many cases of choice under uncertainty; that is, "Construal processes are a necessary part of everyday life."
Once the respondent has formed his or her expectations, as described by the subjective probability distribution, the "best guess" may be modeled as the value that minimizes an expected loss function. The decision rule may be to minimize squared or absolute loss, yielding a report of the subjective mean or median, respectively. Perhaps an asymmetric loss function is implicit, potentially yielding a much lower or higher value. This decision process is certainly influenced by question wording, such as "willingness to pay" versus "willingness to accept." Perhaps economists and others interested in decision making will find this type of problem to be worthy of study.

Journal of Risk and Uncertainty, 19:1-3; 169-170 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

(Mis) Construal Processes for Contingent Valuation Questions: A Commentary on "Construal Processes in Preference Assessment"

TIMOTHY L. McDANIELS University of British Columbia, Vancouver, BC, V6T JZ3, Canada

timmcd@unixg. ubc.ca

When Jones asks Smith a question, does Smith comprehend it in the way Jones expects? Fischhoff, Welch, and Frederick (1999) explore this fundamental yet under-appreciated aspect of social science methods, in the context of contingent valuation transactions. For those who elicit public preferences as input for policy decisions, this paper is both troublesome (in the flags it raises) and instructive (in the framework it offers).
It may be dangerous, in a post-modern world, to expect that Jones and Smith could ever perceive an object, experience an event or interpret a question in similar ways. Yet contingent valuation efforts assume that common understanding is solid enough to provide Smith with all the information needed for responsible judgments regarding hypothetical transactions for public goods. If one accepts that preferences must be constructed rather than uncovered (Gregory, Lichtenstein, and Slavic, 1993), then a clear blueprint is needed to guide Smith's efforts. Fischhoff, Welch and Frederick (1999) explain what Jones should include in the blueprint and how Smith may misconstrue what Jones had in mind. They consider the social science tools Jones could use to diagnose Smith's misconstruals and some ideas about how to shape what Smith perceives about the task. These are important and worthy steps. They put more methodological substance in the hands of those who recognize that preferences must be constructed in the value elicitation process. The biggest contribution of this piece may be the mindset it implies for preference elicitation: take nothing for granted, and expect persistent misconstrual in these difficult judgment tasks.
Figure 1 of Fischhoff, Welch and Frederick (1999) outlines the structure of a theory of misconstrual. Researchers could in the future refine and elaborate this structure. What conditions are likely to lead to construal differences between Jones and Smith about the tasks? When will the differences be so severe they call into question the judgment results? One might guess at some of these refinements, gleaned from others and offered here as first steps:

170

McDANIELS

(i) the more demanding the level of measurement in the tasks posed by Jones, the more likely Smith will seek cognitive shortcuts that misconstrue the tasks (Fischhoff and Cox, 1985; Schkade and Payne, 1994);
(ii) the more the judgment tasks require explicit tradeoffs for "protected" values (Baron and Spranca, 1997), the more the cognitive dissonance engendered by the judgment tasks;
(iii) the more the cognitive dissonance, the more likely Smith will attempt to reshape (and misconstrue) the judgment tasks to avoid making explicit tradeoffs (MacCrimmon and Wehrung, 1986);
(iv) the more the value judgment tasks are abstracted from a context meaningful for Smith, the more Smith will find them difficult to comprehend.
Good practice in contingent valuation already seeks to avoid some of these conditions, while others are accepted features of the paradigm. The future of valuation efforts for non-market goods will see ongoing attempts to better avoid these sources of misconstrual.
Fischhoff, Welch and Frederick (1999) have recast the lexicon of valuation studies, developed a framework for characterizing construal in preference assessment, and placed construal processes more squarely in sight. For that, readers should thank them, however more awkward that may make valuation efforts. Readers should not misconstrue the merits of this article, by thinking they have seen the tables and thus the arguments before. Taken together, the concepts provide a solid if meandering framework for understanding how Smith may misconstrue what Jones had in mind, and what Jones could do in response.

References
Baron, J. and M. Spranca. (1997). "Protected Values," Organizational Behavior and Human Decision Processes, 70, 1-16.
Fischhoff, B. and L. A. Cox, Jr. (1985). "Conceptual Framework for Benefits Assessment." In J. Bentkover, V. Covello, and J. Mumpower (eds.), Benefits Assessment: The State of the Art. Dordrecht: Kluwer, D. Reidel.
Fischhoff, B., N. Welch, and S. Frederick. (1999). "Construal Processes in Preference Assessment," Journal of Risk and Uncertainty 19, 139-164.
Gregory, R., S. Lichtenstein, and P. Slavic. (1993). "Valuing Environmental Resources: A Constructive Approach," Journal of Risk and Uncertainty 7, 177-197.
MacCrimmon, K and D. Wehrung. (1986). Taking Risks. New York: Free Press. Schkade, D. A. and J. W. Payne. (1994). "How People Respond to Contingent Valuation Questions: A
Verbal Protocol Analysis of Willingness to Pay for an Environmental Regulation," Journal of Environmental Economics and Management 26, 88-109.

Journal of Risk and Uncertainty, 19:1-3; 171-197 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Choice Bracketing
DANIEL READ Leeds University Business School, Leeds, UK LS2 9/T
GEORGE LOEWENSTEIN Department of Social and Decision Sciences, Carnegie Mellon University
MATIHEW RABIN Department of Economics, University of California-Berkeley

dr@lubs.leeds.ac.uk.

Abstract
When making many choices, a person can broadly bracket them by assessing the consequences of all of them taken together, or na"owly bracket them by making each choice in isolation. We integrate research conducted in a wide range of decision contexts which shows that choice bracketing is an important determinant of behavior. Because broad bracketing allows people to take into account all the consequences of their actions, it generally leads to choices that yield higher utility. The evidence that we review, however, shows that people often fail to bracket broadly when it would be feasible for them to do so. In addition to documenting the diverse effects of bracketing, we also discuss factors that determine whether people bracket narrowly or broadly. We conclude with a discussion of normative aspects of bracketing and argue that there are some situations in which narrower bracketing results in superior decision making.
Key words: Decision framing, simultaneous and sequential choice addiction, procrastination, risk attitude
If we do not accustom ourselves to look upon war, and the single campaigns in a war, as a chain which is all composed of battles strung together, one of which always brings on another; if we adopt the idea that the taking of a certain geographical point, the occupation of an undefended province, is in itself anything; then we are very likely to regard it as an acquisition which we may retain; and if we look at it so, and not as a term in the whole series of events, we do not ask ourselves whether this possession may not lead to greater disadvantages hereafter.
Clausewitz, On War

1. Introduction
The consequences of choices can rarely be fully appreciated in isolation. Even seemingly trivial decisions, such as whether or not to indulge in desert, save small amounts of money, or purchase lottery tickets, can have profound cumulative

172

READ, LOEWENSTEIN AND RABIN

effects on our physical and material well-being. When we make choices without considering these effects, we can do to ourselves what the bad general can do to his army-make a series of local choices that each appear to be advantageous but which collectively lead to a bad global outcome.
In this paper we introduce the concept of choice bracketing, a term which designates the grouping of individual choices together into sets. A set of choices are bracketed together when they are made by taking into account the effect of each choice on all other choices in the set, but not on choices outside of the set. When the sets are small, containing one or very few choices, we say that bracketing is na"ow, while when the sets are large, we say that it is broad. Broad bracketing allows people to consider all the hedonic consequences of their actions, and hence promotes utility maximization. Narrow bracketing, on the other hand, is like fighting a war one battle at a time with no overall guiding strategy, and it can have similar consequences.
To illustrate the effects of choice bracketing, consider the decision to smoke or abstain. If choices are made one cigarette at a time, the expected pleasure from each cigarette can easily seem to outweigh its trivial health consequences, so lighting up may appear to be the best choice. But if 7,300 single-cigarette choices (one year's worth, for a pack-a-day smoker) are combined, the health consequences may appear less trivial, and might well outweigh the pleasure. The individual who makes 7,300 individually inconsequential decisions to smoke, therefore, makes an aggregate choice that might have been rejected had all the decisions been bracketed together. Whether someone who likes cigarettes ends up as a lifetime smoker may thus depend in part on how she brackets her choices.
In recent years, the distinction between narrow and broad bracketing, under the guise of different more-or-less synonymous labels, has been a frequent object of research. Simonson (1990) used sequential and simultaneous choice; Kahneman and Lovallo (1993) used na"ow and broad decision frames; Herrnstein and Prelec (1992a, 1992b) used isolated and distributed choice; Rachlin (1995) used decision making based on acts and patterns; and Heyman (1996) used local and overall value functions. Thaler (in press) argues that many choice errors are the result of myopic loss aversion which he contrasts to more global forms of utility maximization. All of these researchers have used these terms in the way that we use choice bracketing-to distinguish between choices made with an eye to the local consequences of one or a few choices (narrow bracketing), or with an eye to the global consequences of many choices (broad bracketing).
We argue that bracketing effects are central to understanding a great deal of human choice. Moreover, the distinction between broad and narrow bracketing is one that is often overlooked, even by economists. Economic theory assumes that people bracket broadly by maximizing well-defined global utility functions. Yet, specific economic analyses often rationalize puzzling behavior by showing how it is rational within narrow brackets. For instance, most formal models of risk attitudes assume that they are defined over aggregate wealth levels, and hence that consumers judge each risky choice according to the impact it will have on aggregate long-term risk. Yet specific economic analyses of activities that involve risk, such as

CHOICE BRACKETING

173

insurance purchases, treat consumers' individual decisions as if they were the only decisions that they make.
An example is Cicchetti and Dubin's (1994) analysis of consumer's purchases of insurance to protect themselves against the possibility of malfunctions in their home telephone wiring. The authors explain the frequency of purchases of wiring insurance, which is actuarially extremely unfair, using a standard account of risk aversion as the desire to avoid variation in wealth. In their data set, people pay 45 cents each month to insure against an expected loss of 26 cents a month, reflecting a 1/200 chance of losing $55. Looked at from the narrow month-by-month frame, by either the consumers themselves or the readers of the article, such risk aversion may seem reasonable. But from the perspective of risk to lifetime consumption power, the magnitude of the risk these people are facing is miniscule. Risk aversion over such small stakes makes sense only if we think of each choice in isolation, which is precisely how such examples are presented by authors. Consumers seem to bracket the decision narrowly, which is why they purchase the insurance. But economists also adopt narrow brackets when analyzing those choices, without recognizing that they are violating a bedrock assumption of economics.
In what follows, we provide a broad review of bracketing phenomena. In Section 2, we elaborate on the concept of choice bracketing, by placing it in the context of two other varieties of choice partitioning: outcome editing and joint versus separate evaluation of alternatives. In Section 3, we provide a rough classification of bracketing effects, and document these with many examples, both from related existing literature and some new research of our own. Section 4 offers some hypotheses concerning why and when people bracket narrowly rather than broadly. Section 5 examines the normative question of when narrow or broad bracketing lead to superior decisions. We show that, although broad bracketing should and perhaps typically does produce better decisions, there are some situations in which narrow bracketing is better. We conclude in Section 6.

2. Choice bracketing in context
Choice bracketing can be distinguished from two closely-related forms of choice partitioning. Outcome editing refers to whether the outcomes associated with a particular alternative are aggregated or segregated. Joint versus separate evaluation refers to whether the alternatives of a particular choice are evaluated one-at-a-time or comparatively. After defining choice bracketing, we elaborate on each of these other types of partitioning effects.

2.1 Choice bracketing
Consider the choices: {x1, y 1} and {x2 , h} . Under narrow bracketing, each choice is made separately. Under broad bracketing, a choice is made between the four possible alternative-pairs of the two choices-i.e., from the set {x 1x 2 , x 1h,

174

READ, LOEWENSTEIN AND RABIN

y 1x 2 , y 1y2}. A bracketing effect occurs whenever the outcomes chosen under narrow bracketing differ from those chosen under broad bracketing. For instance, if x is chosen over y for both narrowly bracketed choices, then bracketing matters if anything other than x1x2 is chosen under broad bracketing. The special, but common, case of temporal bracketing applies when the sequencing of choices is important. In narrow temporal bracketing, the individual first chooses between x1 and y 1 (subscripts now designate time) without consideration of the subsequent choice between x 2 and y2, and then chooses between x 2 and y2· Again, bracketing effects occur when narrow bracketing leads to a different final outcome than broad bracketing. In practice, choices are usually made sequentially, and therefore most bracketing effects are probably cases of temporal bracketing.
Choice bracketing is illustrated by responses to the following classic problem, due to Tversky and Kahneman (1981):
Imagine that you face the following pair of concurrent decisions. First examine both decisions, then indicate the options you prefer:
Choice (I) Choose between: A. a sure gain of $240. B. 25% chance to gain $1000 and 75% chance to gain nothing.
Choice (II) Choose between: C. a sure loss of $750. D. 75% chance to lose $1000 and 25% chance to lose nothing.
When the two choices were presented in this way, a large majority of subjects chose A and D. This is because people are loss-averse-a loss of x is far more aversive than a gain of x is pleasurable-and because they give disproportionate weight to outcomes that are certain relative to those that are uncertain (Kahneman and Tversky, 1979). Consequently, subjects were risk averse when making Choice I (they chose the sure gain), and risk seeking when making Choice II (they chose the uncertain loss). When B and C are combined, however (giving a 25% chance to gain $250 and a 75% chance to lose $750), they dominate outcomes A and D (a 25% chance to gain $240 and a 75% to lose $760). Tversky and Kahneman's subjects apparently bracketed the two choices separately and treated each choice as if it had no connection to the other. That they would want something different if they had bracketed broadly was demonstrated when the outcomes from each choice pair were explicitly combined: nobody chose the dominated AD pair.

2.2 Outcome editing
Outcome editing (Kahneman and Tversky, 1979; Thaler, 1985) refers to how outcomes (or attributes) are integrated or segregated when their utility is evaluated. If an alternative has multiple outcomes, such as a compensation package that

CHOICE BRACKETING

175

includes both a long-term raise in salary and a bonus, then decision makers can either evaluate each outcome separately, then compute the value of the alternative as the sum of these separate values, or they can first combine the outcomes and then compute the value of the composite outcome. Imagine an alternative x with two attributes, r and s. In a simple case, integrated outcomes are first combined
and then valued, as in v(r + s), whereas segregated outcomes are first valued and then added, v(r) + v(s ). The hedonic consequences of the set of outcomes can
vary depending on which editing procedure is used. The distinction between choice bracketing and outcome editing can be illus-
trated using the example from Tversky and Kahneman described above. Decision makers can either treat each choice in isolation (narrow bracketing) or combine them (broad bracketing). Broad bracketing confronts the decision maker with four alternatives: AC, AD, BC and BD. Within these alternatives, the individual outcomes can be segregated or integrated. Thus, under broad bracketing the alternative AD could be expressed in a segregated form:
a sure gain of $240; combined with a 25% chance to lose $1000 and 75% chance to lose nothing,
or in an integrated form:
a 75% chance to lose $760 and a 75% chance to gain $240.
Choice bracketing and outcome editing are close relatives and in many cases, such as the example just presented, the distinction depends on the point at which editing occurs. If the effect reported by Tversky and Kahneman is due to a failure to transform the problem into the four-alternative representation, then it is a bracketing effect. If people do achieve that representation, but then fail to integrate the outcomes, then it is an illustration of outcome editing. Many problems, such as this one, may turn out to be ambiguous concerning when the editing occurs. We suggest, however, that for the problem described above and for the great majority of other situations revealing a failure to integrate outcomes across choices, the problem is not that decision makers combine the choices into a composite choice and then fail to integrate the outcomes (i.e., broad bracketing followed by outcome segregation), but that the decision maker views each choice as a separate choice to be evaluated on its own merits (narrow bracketing). As will be seen in many of the examples cited below, when experimenters turn separate choices into single choice, subjects readily integrate the outcomes.

2.3 Joint versus separate evaluation of alternatives
A third type of partitioning effect, which Hsee et al. (in press) refer to as joint versus separate evaluation, occurs between the alternatives offered within a single choice rather than between choices. Separate evaluation occurs when each alternative in a choice is first evaluated without reference to its neighbors, and then one

176

READ, LOEWENSTEIN AND RABIN

of the alternatives is chosen based on the outcome of these evaluations. In joint evaluation, people choose between alternatives by making explicit comparisons between them. Numerous studies show that whether people evaluate alternatives jointly or separately can have a major impact on choice (e.g., Kahneman and Ritov, 1994; Nowlis and Simonson, in press). In one study (Hsee, 1996), for example, participants were asked to assume that as the owner of a consulting firm they were looking for a computer programmer who could write in a special computer language-KY language. The two candidates, who were both new graduates, differed on two attributes: experience with the KY language and undergraduate GPA (on a 5-point scale):

Candidate J: Candidate S:

Experience 70 KY programs in last 2 years 10 KY programs in last 2 years

GPA 3.0 4.9

In the joint evaluation condition, participants were presented with the information on the two candidates as listed above. In the separate evaluatio)l--eondition, participants were presented with the information on only one of thecandidates. In all conditions, respondents were asked what salary they would be willing to pay the candidate(s). The result revealed a significant preference reversal between the two modes of evaluation: the salary offered to candidate J was higher (Ms = $33.2k for J and $31.2k for S) in joint evaluation; but lower in separate evaluation (Ms = $32.7k for S and $26.8k for J). Since the evaluation scale was identical in both conditions, the reversal could only have resulted from the difference in evaluation mode.

3. A review of bracketing effects
Bracketing effects occur because broad bracketing facilitates the consideration of choice factors that are either not perceived or given relatively less weight in narrow bracketing. These include:
Emergent properties. Alternatives can combine into options that have features that are not part of the alternatives taken by themselves. Sets of options that give rise to such gestalts are more likely to be recognized in broad bracketing.
Adding-up effects. Alternatives that are chosen repeatedly have trivial or even non-noticeable costs or benefits when considered individually. When choices are bracketed together, however, the aggregated costs or benefits can exceed a threshold so that they play a greater role in choice.
Taste change. What we choose now can change our tastes, and thus influence what we will want in the future. When choices are bracketed together, we are more likely to recognize how a choice of one alternative will influence our desire for future alternatives. Taste change effects are specific to temporal bracketing.

CHOICE BRACKETING

177

Trade-oft's. When making many choices between multidimensional alternatives, it may be possible to find 'integrative solutions' in which the good parts of some alternatives compensate for the bad parts of others. Again, these trade-offs are easier to see when choices are bracketed together.
These factors embrace what we believe to be the majority of bracketing effects. They are not, however, mutually exclusive, and even in the examples we discuss below there is scope for controversy about where they fit into the framework. The first two factors are the most general, and describe the 'essential' differences between broad and narrow bracketing. Broad bracketing reveals global patterns and magnifies local consequences that can be missed or ignored under narrow bracketing. Taste change can be viewed either as a special kind of emergent property that unfolds over time, or as an adding-up effect involving endogenous changes. Trade-offs are also emergent properties, but these are unique to situations in which choices involve allocating limited resources to alternatives. In the remainder of this section we elaborate on these four factors, and give examples of their operation.

3.1 Emergent properties
When combined, alternatives can have set-level or emergent features that do not exist as features of any single alternative. An illustrative emergent feature is representativeness. A representative sample (the result of a sequence of sampling decisions) has properties that reflect those of its population, yet no single element in the sample can be said to be representative; nor can the representativeness of the sample be inferred from one element. Analogously, in some situations the outcome of many choices must be combined for emergent features to be recognized, and this can only be accomplished through broad bracketing.
We consider three ways in which broad bracketing can highlight properties of alternatives that might otherwise not be apparent. First, people often prefer sets of goods (e.g., clothes, books, movies) that are diverse rather than homogeneous. They are more likely to pay attention to this diversity when they bracket multiple choices together (e.g., by purchasing several books in one trip to the bookstore) than when they bracket them separately (e.g., in a series of single-book purchases). Second, people like to have their pleasures and pains distributed over time in specific ways: they like to spread them out rather than getting them all at once, and they like things to improve over time rather than to get worse. They can only know which choices will achieve these goals when they schedule many experiences simultaneously. Finally, people like to avoid risk-especially the risk of loss-and one way to reduce risk is to combine many risky choices. Consequently, the attractiveness of a portfolio of gambles, when perceived with the benefit of broad bracketing, may be greater than the sum of the attractiveness of its constituents

178

READ, LOEWENSTEIN AND RABIN

Diversity. When making many separate choices between goods, people tend to choose more diversity when the choices are bracketed broadly than when they are bracketed narrowly. This was first demonstrated by Simonson (1990), who gave students their choice of one of six snacks during each of three successive weekly class meetings. Some students chose all three snacks in the first week (broad bracketing; Simonson called this simultaneous choice), although they didn't receive their chosen snack until the appointed time. Other students chose each snack on the day that they were to receive it (narrow bracketing; sequential choice). Under broad bracketing, fully 64% chose a different snack for each week, as opposed to only 9% under narrow bracketing. In a follow-up study using supermarket scanner data, Simonson and Winer (1992) showed that consumers displayed an analogous pattern; they chose proportionally more rare flavors when they bought several containers of yogurt than when they bought only one or two. In other words, those who bought one or two containers at a time restricted themselves to their favorites (e.g., strawberry and blueberry), but if they chose several at once they 'spread their wings' a bit and chose more novel items like piiia colada and vanilla.
Read and Loewenstein (1995) replicated Simonson's diversification effect (they called it the diversification bias) for snacks in several experiments. In one study conducted at two adjacent houses on Halloween they presented trick-or-treaters with two piles of candy bars. Children in the broad-bracketing condition were told to 'take two candies-whichever two you like.' Those in the narrow-bracketing condition were told to take one candy, then were given the same choice when they came to the second house. The broad-bracketing children always chose two different candies, while more than half of the narrow-bracketing children chose the same candy at both houses. Other studies (Read, Loewenstein and Kalyanaraman, in press; Read et al., 1999) have demonstrated the diversification bias for choices of lottery tickets and audio tracks.
Scheduling future experiences: the desire for improvement and spreading. When experiences are distributed over time, the utility of each experience is influenced by what has gone before and what is to come. Improving sequences are experienced as a series of gains, while declining sequences are experienced as a series of losses. Like diversity, improvement is a gestalt property of experiences that is not apparent under narrow bracketing. Indeed, when people schedule experiences one at a time, they typically choose to have the best experiences as soon as possible, and to delay the worst ones, thus ending up with a declining sequence. Loewenstein and Prelec (1993), for example, asked one group to choose between having dinner at a fine French restaurant on a Friday in one or two months. Most chose to have the French dinner in one month. Another group was asked whether they preferred to eat at home on Friday in one month and at the French restaurant on Friday in two months or to consume the two meals in reverse order with the French dinner first. The majority now wanted the French dinner in two months. For both groups, dinner at home was the most likely alternative to the French

CHOICE BRACKETING

179

dinner, but it was only when the two dinners were expressed as a sequence that the desire for improvement became a basis for decision.
Loewenstein and Prelec (1993) also described a second common preference for sequences: a desire for spreading multiple desirable or undesirable experiences out over time. For example, most people do not want to consume two fine meals on successive evenings, or to receive two pieces of bad news on the same day. Linville and Fischer (1991) attribute this to a limited capacity for coping with bad experiences or appreciating good ones. As with the desire for improvement, the desire for spreading only applies when scheduling more than one activity.
We investigated the role of bracketing in the scheduling of pleasant and unpleasant experiences. Subjects were asked to schedule four activities over two weekends, one unpleasant and one pleasant gardening task, and one unpleasant and one pleasant reading task. In the narrow bracketing condition, they scheduled the reading and gardening tasks separately, while in the broad bracketing condition the two decisions were combined. The task was described in the following way:
Imagine that on the next two Saturdays you must plan when to do some reading and some gardening. On one Saturday you will spend two tedious hours reading the Pennsylvania driver's manual in preparation for your licensing exam. On the other Saturday you will spend two pleasant hours reading a new novel by your favorite author.
In addition to reading, on one Saturday you will spend two boring hours weeding dandelions from your garden. On the other Saturday you will spend two enjoyable hours planting flower bulbs.
As expected, a majority of narrow bracketing subjects chose an improving sequence for both activities. They thus ended up weeding and reading the driver's manual on the first Saturday, and then planting flowers and reading a novel on the second Saturday. Broad bracketing subjects, however, who were exposed to both scheduling decisions before they made any choices, spread out the good and bad by taking one pleasant and one unpleasant task for each Saturday. Spreading, which was a feature that could emerge only from the combination of two alternatives, was only seen as an option under narrow bracketing.
Risk aggregation. When several positively valued but risky gambles are combined, the perceived risk from the super-gamble can be less than the risk from any individual gamble. Consequently, a decision maker who refuses a single gamble may nonetheless accept two or more identical ones. This is especially true when the risks from the different gambles are uncorrelated or (even better) negatively correlated, but even when risks are positively (but imperfectly) correlated, a portfolio of individually unacceptable gambles can be quite attractive. Thus, decision makers may accept several gambles when they are bracketed broadly, but reject them if they are bracketed narrowly.

180

READ, LOEWENSTEIN AND RABIN

Risk aggregation, in this context, was first discussed by Samuelson (1963), who asked a colleague if he would accept equal odds to win $200 or lose $100. The colleague refused but stated that he would accept 100 such bets.1 This pattern of preference is driven by a combination of loss aversion (people's extreme distaste for losses) and narrow bracketing. Imagine that Samuelson's colleague had a loss-averse piecewise-linear value function with a slope of 1 in the domain of gains, but a slope of 2.5 in the domain of losses. Although he would refuse a single bet-since
.5 X 2.5 X -(100) + .5 X 200 = -25-he would have willingly played a portfolio of two bets-since their value would be .25 X 2.5 X (- 200) + .5 X 100 + .25 X 400 = 25. Bracketing many choices together can, therefore, transform undesirable
prospects into desirable ones. Thaler (in press) adapted Samuelson's question for a course on decision making
that he taught to 25 executives from a single firm, including its CEO. When Thaler asked the non-CEO executives whether they would accept a project for their division that offered an even chance of losing $1 million or gaining $2 million, only three stated that they would. However, when the CEO was asked whether he would like his subordinates to undertake the project, he enthusiastically nodded. The CEO, unlike his subordinates, was in a position to bracket all of the 'gambles' together. He realized that if they were all accepted, the profits would most likely be stupendous, and there was almost no chance of any loss at all. While this difference in preference may be due to factors other than loss aversion, such as the reluctance of the subordinates to make a decision that would prematurely end their careers, it is consistent with a large body of similar evidence in contexts where such considerations are absent (see Kahneman and Lovallo, 1993).
In another application of the same idea, Benartzi and Thaler (1995) attributed the equity premium puzzle-the low rate of return for bonds relative to stocks-to myopic loss aversion, which is their term for a combination of narrow bracketing and loss aversion shown by investors who invest in fixed income securities in preference to equities despite the much higher historical rate of return to equities.2 Benartzi and Thaler argue that investors dislike stocks because they look at their portfolios frequently-perhaps once a month-even though the average investor is saving for a distant retirement. Over brief periods, stock prices are almost as likely to fall as to rise. For loss averse investors, the falls will be extremely painful and the rises only mildly enjoyable, so the overall experience might not be worth undertaking. By this logic, if people could resist looking at their portfolios for longer periods-i.e., bracket their investment choices more broadly-the likelihood that they would see such losses would diminish, and the clear benefits of stocks would emerge. While we can never be sure that U.S. investors during this period had correct expectations about the scale of risk, Gneezy and Potters (1997) and Thaler et al. (1997) have conducted experiments that support Benartzi and Thaler's interpretation. In Thaler et al.'s (1997) study, for example, subjects made investment decisions between stocks and bonds at frequencies that simulated either 8 times a year, once a year, or once every five years. Subjects in the two

CHOICE BRACKETING

181

long-term conditions invested the large majority of their funds in stocks, while those in the frequent evaluation condition invested the majority in bonds.

3.2 Adding-up effects
Bracketing effects due to adding-up occur when the perceived costs of alternatives accumulate at a different rate than their benefits. The costs or benefits from a single act may be so low as to fall below a threshold of consideration, while the cumulative costs or benefits of many such acts can be momentous. Consider, for example, the health consequences of one cigarette, the girth added by one slice of cake, or the effects on one's grades of a single decision to 'skip class.' In each of these examples, the anticipated cumulative benefit from indulging on multiple occasions seems to increase much more slowly than the cumulative costs. We suspect, for example, that the magnitude of the anticipated pleasure from 100 desserts does not even approach 100 times the pleasure from a single dessert, whereas the anticipated growth in your waistline is (if anything) greater than that from a single dessert. The same is true for cigarettes and skipping class. If people bracket narrowly and consider the costs and benefits of a single action, then the balance of costs and benefits will likely favor the benefits, while if they bracket broadly the balance can be reversed.
The failure to take tiny but cumulative effects into account has been implicated in many apparently suboptimal patterns of choice. Sabini and Silver (1982), for example, attribute procrastination to a combination of narrow bracketing and the apparently trivial amount of work that can be accomplished on a project in a short period:
Imagine you have two days to write a paper. You believe it will take about six hours. To avoid being rushed, you decide to get to work. . . . Now suppose you had to decide what to do for the next five minutes-either work on the paper or play one game of pinball . . . In the short run, five minutes of pinball is far more pleasurable than five minutes of paper writing, and after all, how much of a paper can you do in five minutes? Pinball is the obvious choice. The game is over so you must decide about the next five minutes. The situation is only trivially changed, so you will reach the same result. Once you've fragmented your night into five minute intetvals, you may be doomed to play until you run out of money, the machine breaks, or someone meaner than you wants to play.... One of the ways of being irrational and procrastinating is to act on rational calculations for intetvals that are irrationally short .... A model that would capture rational action must not only show how means are fit to goals, but also how appropriate intetvals for calculation are picked (Sabini and Silver, 1982, p. 133).

182

READ, LOEWENSTEIN AND RABIN

Sabini and Silver's discussion highlights another context in which bracketing effects have received considerable attention-that of self-control (see, for example, Ainslie, 1992; Heyman, 1996; Rachlin, 1995). Heyman's view is typical in that he suggests that self-control (in this case, avoiding or recovering from addiction) can be accomplished by putting preference 'under the control of global value functions.' The problem of addiction is considered in the next section. For now, we note only that those global value functions are equivalent to the 'appropriate intervals' for utility calculation described by Sabini and Silver: only when those intervals are
large is self-control possible.3 Another consequence of narrow bracketing is the peanuts effect, in which
repeated and seemingly inconsequential transactions can add up to significant total expenditures. Markowitz (1952) argued that the value function for money, both in the domain of gains and losses, is s-shaped. The initial flat segment reflects the observation that small amounts of money are treated as peanuts-i.e., underweighted or ignored. Because people view $1.00 as peanuts, a large fraction would prefer, for example, a 0.1 chance of $10 over $1 for sure, but would also prefer $100 for sure over a 0.1 chance of $1,000. A consequence of this underweighting of small money amounts is that people may spend disproportionate amounts on trivial items. Two dollars may not seem like much for the daily cappuccino, nor five
dollars for a hot lunch, but the pleasureI cost calculus can look different if these
expenditures are aggregated over time, and especially if we consider alternative uses for the money. Personal financial advisors often advise clients to keep track of expenses over some period (e.g., a week or month). They report that many clients are surprised at what a large fraction of the total results from very small expenditures. Rent-to-own companies capitalize on this effect by offering people durable goods, such as computers or stereos, for 'only' $25 per week over a period of three years or more (Swagler and Wheeler, 1989; Walden, 1990).
The 'pennies a day' technique for eliciting charitable donations also plays on the peanuts effect (Gourville, 1998).4 Many organizations, such as public radio stations, plead for contributions by reminding potential donors that it will only cost them a small amount per day, perhaps 'no more than a cup of coffee.' When many days are aggregated, however, the opportunity cost of a large amount of money may seem greater than the benefit from the good in question; imagine the response to the plea that your donation will cost 'only $350 dollars per year, no more than the cost of a small refrigerator.'

3.3 Taste change
Taste change occurs when choosing an option at one time affects that option's future utility, and hence the likelihood of choosing it again. Bracketing is important because if individuals bracket narrowly, taking each choice separately, they will not take into account these internalities (Herrnstein et al., 1993)-i.e., impacts of earlier choices on the utilities associated with later choices. Herrnstein (1982;

CHOICE BRACKETING

183

Herrnstein and Prelec, 1992a) argues that the tendency to ignore internalities, which he calls melioration, can account for a wide range of suboptimal patterns in repeated choice. The most important taste change effects are habit formation and satiation.
Habit formation. If choosing an option increases its utility in future encounters, then a habit is being formed. Many acquired tastes are unpleasant when they are first encountered, but become more attractive than their alternatives once they have been tried a few times. For many, caviar, opera and exercise fit this description. To recognize that the early displeasure will be repaid by later pleasure, one has to bracket early experiences together with later ones. If we bracket narrowly, therefore, we will never acquire these tastes.5
Just as narrow bracketing can prevent people from forming good habits, it might also lead them to form bad habits and become addicted (e.g., Heyman, 1996; Herrnstein and Prelec, 1992b). If we define x as taking a drug and y as abstaining, then harmful addiction occurs when the individual repeatedly takes a drug (x, x, x, ... ) but would be better off not taking it (y, y, y, ... ). Although taking the addictive drug in the first period decreases the utility obtained from both taking it (due to habituation) and not taking it (due to withdrawal) in the second period, it actually increases the value of taking the drug relative to that of not taking it. That is, in the second period neither x nor y is as good as they were, but x is preferred more strongly to y than it was in the first period. Addiction can result from narrow bracketing when the effects of taking a drug on one's future preferences and well-being are ignored. According to Heyman (1996, p. 571),
When preference is under the control of the overall value functions [broad bracketing]. . . just the right amount of drug will be consumed, which may be moderate amounts or none. . . . However, when preference is under the control of local value functions [narrow bracketing], drug use will increase. . . . Thus, a switch from overall to local value functions, in someone with a history of heavy drug use, will trigger a relapse or an increase in drug consumption beyond that which was intended.
Although it is difficult to demonstrate that real-world cases of harmful addiction result from narrow bracketing, experiments in stylized addiction-like settings have shown that the choice behavior of both humans and animals more closely approaches the optimum when choices are bracketed broadly. In a prototypical study, subjects make sequential choices between pairs of alternatives whose payoffs depend on which alternatives were chosen before. Just as with real addiction, the payoff to both alternatives x and y are negatively related to the number of times x has been chosen in the past, yet, regardless of the choice history, on every trial the payoff is greater for x than for y. If y is chosen every time, however, the subject gets the highest overall payoff, while if x is chosen every time, the subject gets the lowest payoff. Alternative x is like a drug which is always better than anything else

184

READ, LOEWENS1EIN AND RABIN

but which gets less enjoyable with repeated consumption and simultaneously worsens the quality of every other aspect of life. To recognize the 'trap,' the experimental subject (and the addict) has to recognize the interdependence between the choice of x and the returns to both x and y (cf., Ainslie, 1975, 1992). Manipulations that increase awareness of the internality (e.g., Herrnstein et al., 1993) reduce the frequency of x choices. The experiments most directly pertinent to choice bracketing have been conducted by Kudadjie-Gyamfi and Rachlin (1996). Their subjects made choices like those just described, except that one group made the choices in clusters of three, while control groups made non-clustered choices. Kudadjie-Gyamfi and Rachlin anticipated that the clustered choice group would treat each choice in a cluster as part of a single set (i.e., they would bracket broadly) while the non-clustered groups would treat each choice in isolation. As predicted, when the choices were clustered, subjects were more likely to choose the y alternative, and they obtained a significantly higher payoff.

3.4 Tradeoffs across choices
When two parties negotiate over many issues simultaneously they can look for integrative agreements, which are settlements in which one party concedes on a dimension that it values less than the other in exchange for a reciprocal concession on a dimension that it values more. A union, for instance, may be willing to concede on wage increases (which management values more) in exchange for job security (which the union values more). In this way both sides end up with an agreement which they prefer to the one which would have come from making separate concessions on wages and job security. Integrative agreements are possible only when more than one issue is negotiated simultaneously. Analogously, individual decision makers can reach integrative agreements with themselves if they take into account the possibility of trade-offs across the many choices that they face. Just as with union and management, such an intrapersonal integrative solution can only be reached if the decision maker brackets more than one choice together.
In this section we examine cases that illustrate the impact of bracketing on the exploitation of opportunities for intrapersonal tradeoffs. First, we look at how people trade off the amount of the time they spend working across days that offer different wage rates; then we examine how people trade off across categories of consumption; and finally we consider people's notions of a just division of resources, and how they allocate resources between different people who value those resources differently.
Trade-off between labor and leisure. Many workers, such as salespeople, fishermen, academics and artists daily choose how much time to spend working, and how much time relaxing. Moreover, the return to each hour of work varies from day-to-day. On some days there are many fish, while on other days there are few.

CHOICE BRACKETING

185

Likewise, artists and academics have days when the muse is resident, and days when she is painfully absent. In such situations, the most efficient way for workers to organize their time is to work long hours when the return to time spent is high, and take leisure when the return is low. This commonsensical integrative solution to the work hour problem is the prediction of basic economic theory.6
Camerer et al. (1995) tested this prediction in a study of the daily work-hour decisions of New York City cab drivers. Cab drivers can decide when to quit work each day, and also face wage rates that are relatively stable during the span of a day but which fluctuate, and are largely uncorrelated, across days. The authors found that, contrary to economic theory, drivers quit early on good days, and worked late on bad days. The drivers seemed to have adopted the strategy of working each day until they made a fixed amount of money (perhaps enough to pay for cab rental and living expenses plus a 'little extra') and then quitting. This pattern suggests that the cab drivers are making their labor supply decision 'one day at a time' which is almost the worst possible earning strategy. The authors calculated that if the cabbies had worked the same total number of hours, but allocated equal hours to each day, they would have increased their net take-home pay by about 10%, and that if they had optimized by working longer hours on good days and shorter hours on bad days, they would have earned about 20% more.6
Trade-o.ffs across purchase categories. Another area in which there is a well-documented tendency to think narrowly, and thus fail to make optimal trade-offs across choices, is household and mental budgeting. Budgeting involves earmarking money for specific categories of expense. A household, for instance, might allocate fixed portions of its income to utilities, transportation, food and clothing. The money so earmarked is spent on that category of expense, and on nothing else. Budgeting can be a useful shortcut for ensuring that vital expenses are met, but if budget boundaries are too restrictive-that is, if there is a reluctance to transfer money from one account to another-they can prevent the decision making unit, whether household or individual, from making beneficial trade-offs.
A budget contains three elements: a category of expense, an amount budgeted, and a fiscal period. Accounting conventions dictate that money in the account be spent only on that category and within that fiscal period. A series of experiments by Heath and Soli (1985) demonstrate that people are quite strict about their budgets. Money saved in one category will be recycled into that category: money saved on free theater tickets, for example, is used to buy more entertainment, such as CDs or sports tickets. The specificity of such budgets can be striking: subjects in a study conducted by O'Curry (1995) reported that they would use a category-wide reduction in beer prices to buy better quality beer. As Heath and Soli (1995) observe, because budget decisions are made relative to categories, they can lead to simultaneous feelings of wealth ('I didn't spend all my clothing allowance, so now I can buy that gaudy hat ... ') and poverty ('but I've spent enough on books this week').
Research into household budgeting has focused on how people use categories, and no one has investigated how choices are influenced by changing the scope of

186

READ, LOEWENSTEIN AND RABIN

the mental account. We might expect, for example, that if people could be induced to keep an "entertainment and clothing" account, then shoes and theater tickets would become substitutes. We investigated this prediction by manipulating another aspect of the budget-the fiscal period. The fiscal period demarcates the interval during which a particular budget allocation is to be used. Two groups of Carnegie Mellon students responded to the following question:
Imagine that you are a poor student, and you set aside $25 per week [$100 per month] for entertainment. It is the last day of the week [7th of the month] and you have already spent $25 on entertainment. Tonight there is a concert that you would like to attend, but the tickets cost $15. Will you go?
In terms of the consequences to the student, the fiscal period is just window-dressing. The student attending the concert has spent more than planned, but will have enjoyed a concert. Changing the fiscal period, however, had the expected effect. Students were more likely to attend the concert if their fiscal period was one
month rather than one week (39% vs. 8%; x2(1) = 7.7, p < .005). At least in this
case, budgeting decisions were altered by changing the domain of choices bracketed within a budget.
Fair divisions. Bracketing also seems important in understanding what people think is a fair allocation of resources. In particular, narrow bracketing of resourceallocation decisions-i.e., allocation on a case-by-case basis-is likely to lead to more equal, but less efficient, splits of resources than broad bracketing. Suppose that $10 worth of money or other goods must be split between two people. How would the average person, acting as a third party, decide to split the surplus between the two? One possible allocation rule is to give it all to the poorer person, or (for non-money goods) to the one who values the goods more. But research shows that, rather than maximizing the total welfare gain of the two individuals, disinterested people often prefer an allocation that equalizes welfare gains (Yaari and Bar-Hillel, 1984). Because people who value a resource less require more of it to increase their utility by a given amount, equalizing welfare gains typically implies that more of any given resource should be allocated to those who value it less.
While we have no comment on the moral soundness of this Rawlsian maximin criterion as an ultimate principle of justice, its implications can be strikingly different depending on whether the allocation decisions are bracketed narrowly or broadly. Imagine, for example, that the same two people are the subject of repeated allocation decisions, and that our goal is to maximize the minimum welfare gain that will result from these decisions. Imagine further that the goods being allocated are just as often more valued by one party as the other party. If we bracket very few decisions together, it is most likely that for each allocation the best (maximin) decision will be to maximize the sum of the two parties' benefits.
For example, suppose that we have to make two allocation decisions for two people, Johnny and Keanu. The first is to distribute 12 grapefruits and the second

CHOICE BRACKETING

187

is to distribute 12 avocados. Johnny values grapefruits twice as much as Keanu, and Keanu values avocados twice as much as Johnny. If we bracket narrowly, the maximin criterion would lead us to first give 4 grapefruits to Johnny and 8 to Keanu, and then to give 8 avocados to Johnny and 4 to Keanu-equating their benefits in each separate distribution. If we bracket broadly, however, we would give all the grapefruits to Johnny and all the avocados to Keanu. Both ways of allocating gives equal welfare gains to both, but those gains are 50% greater under broad bracketing. If one imagines larger numbers of individual allocation decisions, it becomes clear that maximizing the addition to total welfare on each choice is likely to be the best policy even if one wants to pursue the maximin criterion in the aggregate.7

4. Determinants of bracketing
In the previous section, we summarized the results of numerous studies that document the important consequences of bracketing choices narrowly or broadly. We did not directly address what causes people to bracket the way they do, in part because very few studies have addressed this question. Undoubtedly, many bracketing choices result from a wide range of subtle and unconscious factors that influence the way we categorize the world. For example, putting on one's shoes could be construed as: putting on each of two shoes; putting on a pair of shoes; part of getting dressed; part of preparing to leave the house; or, perhaps somewhat far-fetched, part of furthering one's career. Our lack of insight into the factors that influence bracketing even in mundane choices suggests that developing a theory of how people bracket is a crucial direction for future research. Despite our comparative ignorance on this issue, we provide a preliminary analysis of four factors that we suspect are important.
Cognitive capacity limitations. Cognitive limitations-in perception (Miller, 1956), attention (Kahneman, 1973), memory (Baddeley, 1986), and analytical processing (Simon, 1957), etc.-are one important determinant of bracketing. Such limitations sharply constrain our ability to simultaneously consider multiple decisions. As the number of choices-or the number of alternatives per choice-increases, the cognitive cost of broad bracketing will undergo a combinatorial explosion. To take an abstract example, narrowly bracketing two choices {x1, y1} and {x2 , y2} involves two binary comparisons; broadly bracketing the choice so that it is made between the composite alternatives {x1x2 , x1y2 , y1x2 , y1y2} involves at least three and as many as six binary comparisons. If there are three choices, the composite choice can involve up to 28 binary comparisons. This does not take into account the resources needed to evaluate what will rapidly become exceedingly complex alternatives.
Cognitive inertia. Cognitive limitations are probably very important in the real world, and even in some experimental demonstrations of bracketing. In Kahneman and Tversky's (1981) twin-gamble dominance violation illustration, described ear-

188

READ, LOEWENSTEIN AND RABIN

lier, subjects might not integrate the gambles (despite being advised that the decisions are concurrent) because doing so would be cognitively taxing. But not all bracketing effects can be explained in this way. Many are due simply to the fact that people usually deal with problems in the way that they are presented to them. If choices come to them one at a time, they will bracket them narrowly, and if choices come to them collectively, they will bracket more broadly.
This was elegantly illustrated by Redelmeier and Tversky (1992) in the domain of gambles. Given a choice, people will usually prefer a larger number of gambles (assuming they have a positive expected value and are independent) to a smaller number (e.g., Keren and Wagenaar, 1987). Their study involved two groups, each of whom chose between five or six gambles. Most of the first group, who made a direct choice, took six gambles. A second group made two choices. First they chose between zero gambles or five. Most chose the five. Then they were offered one more gamble, which amounted to a choice between the original five gambles or six gambles. Most refused the sixth gamble. Indeed, the proportion taking the sixth gamble was identical to that taking a single gamble when the choice was between one or zero. The second group had bracketed narrowly, by treating the single gamble choice as separate from the earlier choice of five gambles. Only when the choices were explicitly bracketed together, as they were in the first group, did subjects recognize that the five gambles influenced the desirability of the sixth.
In a modification of Redelmeier and Tversky's study, we asked 143 Carnegie Mellon students to
Imagine that on each of 5 days you will be allowed to choose between the following:
A): 50-50 chance of losing $25 or winning $40; B): Do not gamble.
The students then made separate choices for each day. In the narrow bracketing condition, subjects chose for only the first day, while in the broad bracketing condition subjects made the decision for all 5 days. All subjects knew that they would be making five choices, so the only difference between groups was that single-day subjects would have more flexibility in their choices since they weren't precommitted to a pattern of gambles. They did not, however, take this view. While 50% of the broad-bracketing subjects gambled on the first day, only 32% of the
narrow-bracketing subjects did ( x2(1) = 4.57, p < .05). Note that cognitive limita-
tions cannot account for results such as these. Rather, the difference between broad and narrow bracketing apparently involves a shift-in-viewpoint, and not more processing power.
Narrow bracketing attributable to cognitive inertia may also contribute to the embedding effect (Kahneman and Knetsch, 1992)-the tendency for respondents in contingent valuation studies to report approximately equal willingness to pay to correct problems that differ dramatically in scope. Respondents, for example, might agree to pay as much to clean the pollution from one lake in Ontario as to clean all of the lakes in Canada. In a verbal protocol study, Schkade and Payne

CHOICE BRACKETING

189

(1994) found that when people estimate their willingness to pay to correct a particular environmental problem, they spend almost no time thinking about other uses for the money. Rather, they take the problem as it comes and think about how much they can afford to pay in general, and do not think about things like what proportion of their scarce resources they can spend on this cause as opposed to other causes. When respondents in Schkade and Payne's study were reminded that there were other causes as well, many indicated that their earlier statements of willingness to pay were too high.
Pre-existing heuristics. Bracketing decisions can also be determined by socially acquired heuristics and decision rules. For example, in our work-oriented society, it is common to divide the week into two intervals of unequal length-the work-week, and the weekend; periods of eating are labeled "meals," and food intake occurring between these designated times is referred to as "snacking"; and so on. All of these conventions, many or most of which exist for good reasons, influence the way that people bracket decisions.
In a study that illustrates both the arbitrariness and consequentiality of such divisions, we asked visitors to the Pittsburgh International Airport to state how much fattening bread pudding they would want during a week-long conference in Ohio:
You are attending a conference at a hotel in Ohio for a week (Monday morning through Monday morning). You eat all your meals at the conference hotel. The specialty of the hotel dining room is New Orleans Bread Pudding, which is delicious, but heavy on the fat and calories. However, you can have the bread pudding with dinner at no extra cost.
Broad bracketing respondents were induced to make the entire week's choices together by being asked "On which day(s), if any, would you like to eat a bread pudding?" They then checked off their decision for each day. The remaining respondents were induced to bracket more narrowly. Again, they made separate decisions for each day, but this time the week was divided into two subperiods: weekdays and weekend. Subjects chose to eat many more puddings when they were broken down into weekdays and weekend days (.57 per day) then when the days of
the week were expressed as one block (.35 per day; t(44) = 4.00, p < .05).
Motivated bracketing. People sometimes adopt a particular bracket to accomplish some goal-most typically to overcome problems of self-control. Much of social guidance regarding bracketing is clearly motivated to counteract otherwisetempting misbehavior. For example, abstinent alcoholics are instructed to take it "one day at a time," presumably because taking it one year at a time makes their task seem overly daunting.8 Narrow bracketing may also facilitate self-control when people are budgeting time, money, or calories. Eating only 14,000 calories per week is a rule that is much easier to fudge on than 2,000 calories per day, even if, or perhaps precisely because, the former allows for more flexible and thus efficient scheduling. Those who get the urge to binge, for example, might be able to

190

READ, LOEWENSTEIN AND RABIN

persuade themselves that today is the beginning of a new week. Similarly, spending is much easier to restrict on an entertainment budget of $10 per day rather than $70 per week, and spending two hours with one's child per day is more difficult to shirk on than spending at least 14 hours per week.9 This might be one reason why the taxi drivers in Camerer et al.'s (1997) study employed a daily earnings target; if they had, for example, picked a weekly target they might have been tempted to quit early on any given day while assuring themselves that they could make up the deficiency later in the week.
Because narrow bracketing can make goals seem easier to attain, it can also increase motivation. This may be an additional reason for a lot of seemingly short-sighted behavior, such as that shown by the cab drivers. By setting a goal of earning a fixed amount per day, they had something realistic to work toward. Indeed, such a feasible performance-based goal may have enabled them to get more work done in less time than an alternative strategy such as 'work 8 hours per day.' Anthony Trollope (1883/1980, p. 119) attributed his remarkable productivity to a work schedule that explicitly recruited severe narrow-bracketing in the service of long-term goals:
When I have commenced a new book, I have always prepared a diary, divided into weeks, and carried on for the period which I have allowed myself for the completion of the work. In this I have entered, day by day, the number of pages I have written, so that if at any time I have slipped into idleness for a day or two, the record of that idleness has been there, staring me in the face, and demanding of me increased labour, so that the deficiency might be supplied .... In the bargains I have made with publishers I have . . . undertaken always to supply them with so many words, and I have never put a book out of hand short of the number by a single word.
Trollope's strategy was exactly the same as the one used by the cab drivers. On days when he was very productive he was able to quit early, and on days when the writing was slow he worked longer hours-or else, as indicated in the text, paid a price. Trollope produced at least three major novels a year, many of which are still widely read, while successfully holding a responsible position in the English postal service. It is difficult to fault him for bracketing too narrowly.
Broad bracketing can also serve motivational purposes. Both Rachlin's (1995) and Heyman's (1996) accounts of self-control and addiction are based on the premise that broad bracketing leads to superior choices and that people have some control over the type of brackets they adopt. Ainslie and Haslam (1992, p. 188) likewise posit that people may use broad bracketing of choices as a self-control device:
Imagine a person on a weight-reducing diet who has been offered a piece of candy. The person knows that the calories in one piece of candy will not make any noticeable difference in weight, and yet he is apt to feel that he should not

CHOICE BRACKETING

191

eat the candy. What would it cost him? Common experience tells us: his expectation of sticking to the diet. He will face many chances to eat forbidden foods, and if he sees himself eating this one, it will not seem likely to him that he will refuse the others
By bracketing dieting choices together, and by viewing rejection or acceptance of the single piece of candy as a larger choice between diet versus no diet, this person increases the chance of adherence to his diet. Although the evidence is not clear concerning whether bracketing as a framing strategy is a successful means of self-control, the widespread existence of rigid rules of conduct and the explicit claims that these rules are self-control devices suggest that it has some beneficial effect.

5. Is Broad Bracketing Always Better Than Narrow Bracketing?
The underlying premise of this article is that broad bracketing usually leads to better outcomes than narrow bracketing. By "better" we mean that people will usually gain more happiness from making the choices dictated by the broader bracketing than the narrow one. An examination of the studies cited above should make this clear: people who buy stocks will be wealthier than those who buy bonds; dieters who bracket their dining decisions broadly will eat fewer desserts than those who consider each day separately; and consumers who bracket all their purchases together without setting up inviolable budgets will be able to make efficient trade-offs across purchase categories. The general principle is that broad bracketing allows people to pursue maximization of their global well-being. However, broad bracketing is not an unalloyed good, and there may be cases where it is actually better to bracket narrowly. We see at least four caveats to the broader-isbetter view of bracketing.
First, as is no doubt clear from many of our examples, choices made under broad bracketing often involve putting up with small discomforts or annoyances in order to achieve long-term gains. For example, people who invest all of their retirement funds in stocks, as they might do if they bracket broadly, may be wealthier when they retire, but at the cost of ongoing anxiety during the intervening period. A priori, it is impossible to determine whether the expected gain is adequate compensation for the anxiety. Likewise, for cab drivers to attempt to bracket more broadly-e.g., by attempting to maximize their weekly earnings while minimizing hours driven-might require more self-control and more careful record-keeping, burdens which could offset the benefits derived from greater efficiency. In order to be able to determine whether broadly or narrowly bracketed choices are better in a particular situation, we need some way of comparing the overall or total utility (Kahneman, Wakker and Sarin's (1997) term) of a lifetime of small annoyances against the big gains from broad bracketing. Ironically, it may tum out that narrow bracketing is sometimes better because it enables us to take little annoyances into

192

READ, LOEWENSTEIN AND RABIN

account (such as the pain of record keeping) that have a significant effect on total utility but which can be ignored when one takes the long view.
The second caveat is that, because broad bracketing facilitates the consideration of factors that are given little weight during narrow bracketing, it can exacerbate errors people make in anticipating the role these factors play in their experienced well-being. A possible case in point is the diversification bias, already discussed. Although people like diversity when they choose sets of goods, it is by no means certain that they are always more satisfied with diverse experiences. That is, diversity may influence their choices, but not the pleasure they get from what they choose. In one study, Read and Loewenstein (1995) found that people who chose a diverse set of snacks under broad bracketing often wanted to change their minds if given a chance-and usually changed their minds in the direction of less diversity. In another study, Read et al. (1999) found that people who chose more variety, whether under broad or narrow bracketing, retrospectively evaluated their choices as being less enjoyable than did those who chose less variety, suggesting that the tendency to diversify under broad bracketing may lead people to make poor choices. We suggest that the larger principle is that broad bracketing can lead to superior choices only when there are genuine and important preference interactions between alternatives. Broad bracketing will be worse than narrow bracketing when it leads people to either exaggerate trivial preference interactions or to imagine nonexistent ones.
The third caveat to the superiority of broad bracketing has already been discussed under the heading of 'motivated bracketing.' When people have self-control problems, broad bracketing might undermine the motivation to embark on a long chain of difficult choices. Broad bracketing, in this situation, can make the task seem overwhelming. In such cases, treating each choice in isolation may be the best strategy. In negotiation, this is known as a "salami tactic" (Fisher, 1969), in which a big problem is sliced up like a salami and dealt with one slice at a time. Salami tactics are one way that a planner can convince a doer (to use Shefrin and Thaler's (1981) terminology) to undertake a long series of connected choices that would seem unpalatable if they had to make them all at once. Many self-control programs, such as Alcoholics Anonymous, emphasize the importance of taking small steps towards the goal of recovery. While it may be feasible to desist from drinking for a single day, the prospect of not drinking for the rest of one's life might be so alarming that it becomes a reason to drink rather than to abstain. Of course, these examples are not straightforward cases of the superiority of narrow bracketing. The decision to undertake the task in the first place, and then to bracket each choice separately, is made by an 'executive' decision maker who presumably brackets broadly to begin with but then uses the salami strategy to get its untrustworthy self to accomplish the task.
The fourth and final problem with broad bracketing is that it is not free. As we have already observed, there are cognitive costs involved with attempting to integrate many choices together, and these costs have to be balanced against the benefits of broad bracketing. For trivial everyday decisions, and perhaps for

CHOICE BRACKETING

193

not-so-trivial but complicated ones, it may be that the costs exceed the benefits or that broad bracketing simply exceeds the individual's cognitive capacities. When narrow bracketing is inevitable, whether due to cognitive constraints or other reasons, a natural follow-up question is whether people employ decision rules that are "constrained optimal"-i.e., optimal given their narrow bracketing of choices. In the domain of risky choice, for example, if people do bracket narrowly then it will be optimal for them to be virtually risk neutral over moderate-stake gambles; a very simple heuristic-to always maximize expected return except on huge gambles -would make people better off than the (more complicated) procedures they actually do use on their narrowly-bracketed choices. Similarly, NYC cab drivers could be better off driving a fixed number of hours each day rather than aiming for a fixed level of take-home pay.

6. Concluding Comments
Bracketing is different from other familiar sources of decision suboptimalities in that it seems to play an interactive or enabling role. Many established causes of decision errors only exert an influence under narrow bracketing. Loss aversion, for example, would have little impact on decision making if people aggregated multiple decisions together. This is because loss aversion only matters for decisions that can lead to either gains or losses. But in many domains, the likelihood that any individual decision will shift the decision maker from one side of the divide to the other is exceedingly small. Hence, it is often not loss aversion alone, but the combination of loss aversion and narrow bracketing, that causes problems. This is illustrated by the case of Samuelson's colleague. If he played 100 gambles, the marginal effect of any single gamble on the overall payoff would be negligible, and the likelihood that by itself it would make a winning portfolio into a losing one is essentially zero.
Narrow bracketing generally shifts people's attention from the macro level to the micro level-a level at which many of the most pernicious patterns of decision making seem to occur. Many researchers claim that dieters and drug addicts are defeated by small, but frequent, indulgences (Herrnstein and Prelec, 1992a, 1992b). Others have argued that lapses of morality rarely happen all-at-once, but more typically involve a series of cascading misbehaviors (e.g., Lifton, 1990). Narrow bracketing exacerbates problems like these by shifting attention from the big picture to localized, isolated, decisions-from the campaign that is our life to the skirmish that is today.

Acknowledgments
We are grateful to Colin Camerer, Erik Eyster, Drazen Prelec, Shane Frederick and Richard Thaler for useful comments on an earlier draft, and to Baruch

194

READ, LOEWENSTEIN AND RABIN

Fischhoff, Chuck Manski, and two anonymous referees for very thorough comments. The paper was completed while Read was visiting the Rotterdam Institute for Business Economic Studies, and Loewenstein and Rabin were visiting the Center for Advanced Study in the Behavioral Sciences. We acknowledge support from NSF grants# SBR-960123 (to the Center), support for Loewenstein from the Center for Integrated Study of the Human Dimensions of Global Change at Carnegie Mellon University, and support for Rabin from the Sloan, MacArthur, and Russell Sage Foundations.

Notes
1. Samuelson's (1963) paper has stimulated a lively ongoing debate, as well as empirical research. See, e.g., Lopes (1981, 1996); Tversky and Bar-Hillel (1983); Redelmeier and Tversky (1990); Wedell and Bockenholt (1990, 1994); Keren and Wagenaar (1987); and Keren (1991).
2. Since 1925, equities have consistently outperformed bonds by a wide margin: stocks have had an average annual real return of 7%, while bonds have averaged less that 1%.
3. We should be cautious about implicating narrow bracketing in all failures of self-control. Smoking, overeating, and procrastination have all been explained by researchers as resulting from hyperbolic time-discounting (Ainslie, 1992; Laibson, 1997; Loewenstein and Prelec, 1992; O'Donoghue and Rabin, 1997, in press-a; Read and Van Leeuwen, 1998). In these models, the pursuit of immediate gratification does not arise because people fail to recognize the global consequences of their actions, but rather because they have different preferences at different times: right now they care equally about (say) next Monday and next Tuesday, but come next Monday they care much more about Monday than Tuesday. Because hyperbolic discounting has been so firmly established by behavioral evidence (e.g., Kirby, 1997), determining whether bracketing is also implicated in these phenomena is difficult. Hence, hyperbolic discounting tells us that broad bracketing itself is not always sufficient to induce good long-run behavior: even when people do bracket broadly, often cannot control themselves sufficiently and behave as if they are bracketing narrowly. All dieters, for instance, know that small lapses add up (one dieter's expression is 'a moment on the lips, a lifetime on the hips'), yet they face a constant and often losing battle to prevent lapses from occurring.
4. Gourville does not, in fact, attribute the pennies-a-day phenomenon to peanuts effects, but rather to mental accounting conventions that cause pennies-a-day expenditures to be classified into mental accounts containing small items.
5. A second situation in which melioration can lead to suboptimal choices is when the choice of an option decreases its utility in the future. Ideally, in such circumstances, people should ration-i.e., reduce their consumption of-that option to take account of its marginal cost on future choices. However, consistent with melioration with narrow bracketing, Herrnstein and Prelec (1992a) argue that people tend to ignore or underweight negative internalities. As a consequence, they will tend to overconsume highly attractive, but rapidly satiating rewards.
6. The basic economic theory of labor supply predicts that the supply response to a change in wage depends on the relative strength of the income effect and the substitution effect. The income effect captures the intuition that, as people become wealthier, they tend to work less because they have less need to earn money (their marginal utility of consumption is lower). The substitution effect captures the intuition that when wages are high there is an incentive to work longer hours because the return (in terms of consumption) per hour worked is high. If a particular worker gets a permanent wage increase, according to this theory, whether he will supply more or less labor depends on the relative strength of the income and substitution effects. When wages fluctuate from day to day, however, as is true in a small number of occupations, the theory makes a strong prediction: people should work longer hours on high wage days and quit early on low wage days.

CHOICE BRACKETING

195

This is because any one day's wage has a negligible effect on wealth, so there should be no wealth effect and the substitution effect should dominate. The worker who behaves in this way can maximize earnings while minimizing total hours worked. 7. Observe that treating an individual allocation decision in isolation is something of a fiction; every choice of allocation to two people is surely concatenating some additional resources to resources they already have, so that a maximin criterion should designate that we give all the resources to the person most in need-and be virtually impervious to any additional efficiency or distributional arguments. 8. By contrast, not-yet-addicted drug users are urged to take a broader view of their drug use-lest each day of drug use appear to have inconsequential costs. 9. Thaler and Shefrin's (1981) emphasis on the relationship between mental accounting and the self-control problems in their planner-doer model reflects this insight. See Laibson (1994) for a simple principal-agent model along these lines that is also suggestive of budgeting as a self-control mechanism.

References
Ainslie, G. (1975). "Specious Reward: A Behavioral Theory of Impulsiveness and Impulse Control," Psychological Bulletin 82, 463-496.
Ainslie, G. (1992). Picoeconomics: The Strategic Interaction of Successive Motivational States within the Person. New York: Cambridge University Press.
Ainslie, G. and Haslam, N. (1992). "Self-Control." In G. F. Loewenstein and J. Elster (eds.), Choice Over Time. New York: Russell Sage Foundation.
Baddeley, A. D. (1986). Working Memory. Oxford: Oxford University Press. Benartzi, S. and R. H. Thaler. (1995). "Myopic Loss Aversion and the Equity Premium Puzzle," The
Quarterly Journal of Economics 73-92. Camerer, C., L. Babcock, G. Loewenstein, and R. Thaler. (1997). "Labor Supply of New York City Cab
Drivers: One Day at a Time," The Quarterly Journal of Economics 112, 407-441. Cicchetti, C. and J. Dubin. (1994). "A Microeconometric Analysis of Risk Aversion and the Decision to
Self-Insure," Journal of Political Economy 102, 169-186. Clausewitz, C. von (1832/1982). On War. Harmandsworth, UK: Penguin Books. Fisher, R. (1969). Basic Negotiating Strategy: International Conflict for Beginners. London: Allen Lane. Gneezy, U. and J. Potters. (1997). "An Experiment on Risk Taking and Evaluation Periods," Quarterly
Journal of Economics 112, 631-645. Gourville, J. T. (1998). "Pennies-a-Day: The Effect of Temporal Re-Framing on Transaction Evalua-
tion," Journal of Consumer Research 24, 395-408. Heath, C. and J. Sol!. (1996). "Mental Budgeting and Consumer Decisions," Journal of Consumer
Research 23, 40-52. Herrnstein, R. J. (1982). "Stimuli and the Texture of Experience," Neuroscience and Biobehavioral
Reviews 6, 105-117. Herrnstein, R. J., G. F. Loewenstein, D. Prelec, and W. Vaughan, Jr. (1993). "Utility Maximization and
Melioration: Internalities in Individual Choices," Journal of Behavioral Decision Making 6, 149-185. Herrnstein, R. J., and D. Prelec. (1992a). "Melioration." In G. F. Loewenstein and J. Elster (eds.),
Choice Over Time. New York: Russell Sage Foundation. Hermstein, R. J. and D. Prelec. (1992b). "A Theory of Addiction." In G. F. Loewenstein and J. Elster
(eds.), Choice Over Time. New York: Russell Sage Foundation. Heyman, G. M. (1996). "Resolving the Contradictions of Addiction," Behavioral and Brain Sciences 19,
561-610. Hsee, C. K. (1996). "The Evaluability Hypothesis: An Explanation of Preference Reversals between
Joint and Separate Evaluations of Alternatives," Organizational Behavior and Human Decision Processes 46, 247-257.

196

READ, LOEWENSTEIN AND RABIN

Hsee, C. K., G. Loewenstein, S. Blount, and M. Bazerman. (in press). "Preference Reversals between Joint and Separate Evaluations of Options: A Theoretical Analysis," Psychological Bulletin.
Kahneman, D. (1973). Attention and Effort. Englewood Cliffs, NJ: Prentice Hall. Kahneman, D. and J. Knetsch. (1992). "Valuing Public Goods: The Purchase of Moral Satisfaction,"
Journal of Environmental Economics and Management 22, 57-70. Kahneman, D. and D. Lovallo. (1993). "Timid Choices and Bold Forecasts: A Cognitive Perspective on
Risk Taking," Management Science 39, 17-31. Kahneman, D. and I. Ritov. (1994). "Determinants of Stated Willingness to Pay for Public Goods: A
Study in the Headline Method," Journal of Risk and Uncertainty 9, 5-38. Kahneman, D. and A. Tversky. (1979). "Prospect Theory: An Analysis of Decisions under Risk,"
Econometrica, 47, 263-291. Kahneman, D., P. Wakker, and R. Sarin. (1997). "Back to Bentham? Explorations of Experienced
Utility," The Quarterly Journal of Economics 112, 375-406. Keren, G. (1991). "Calibration and Probability Judgments: Conceptualization and Methodological
Issues," Acta Psychologica 77, 217-273. Keren, G. and W. A. Wagenaar. (1987) "Violation of Utility Theory in Unique and Repeated Gambles,"
Journal of Experimental Psychology: Learning, Memory and Cognition 13, 387-391. Kirby, K. N. (1997). "Bidding on the Future: Evidence against Normative Discounting of Delayed
Rewards," Journal of Experimental Psychology: General126, 54-70. Kudadjie-Gyambi, E. and H. Rachlin. (1996). "Temporal Patterning Choice among Delayed Outcomes,"
Organizational Behavior and Human Decision Processes 65, 61-67. Laibson, D. (1994). "Hyperbolic Discounting and Consumption," Dissertation, MIT. Laibson, D. (1997). "Golden Eggs and Hyperbolic Discounting," Quarterly Journal of Economics, 112(2),
443-477. Lifton, R. J. (1990). The Nazi Doctors: Medical Killings and the Psychology of Genocide. New York: Basic
Books. Linville, P. and G. W. Fischer. (1991). "Preferences for Separating or Combining Events," Journal of
Personality and Social Psychology 60, 5-23. Loewenstein, G. and D. Prelec. (1992). "Anomalies of Intertemporal Choice," Quarterly Journal of
Economics 107(2), 573-597. Loewenstein, G., and D. Prelec. (1993). "Preferences for Sequences of Outcomes," Psychological Review
100, 91-108. Lopes, L. (1981). "Decision Making in the Short Run," Journal of Experimental Psychology: Human
Learning and Memory 7, 377-385. Lopes, L. (1996). "When Time Is of the Essence: Averaging, Aspiration and the Short Run," Organi-
zational Behavior and Human Decision Processes 65, 179-189. Markowitz, H. (1952). "The Utility of Wealth," Journal of Political Economy 60, 151-158. Miller, G. A. (1956). "The Magical Number Seven Plus or Minus Two: Some Limits on Our Capacity for
Processing Information," Psychological Review 63, 81-97. Nowlis, S. M. and I. Simonson. (in press). "Attribute-Task Compatibility as a Determinant of Consumer
Preference Reversals," Journal of Marketing Research. O'Curry, S. (1995). "Income Source Effects," Working Paper, Department of Marketing, DePaul
University, Chicago IL. O'Donoghue, E. and M. Rabin. (1997) "Incentives for Procrastinators," Working Paper, Department of
Economics. University of California, Berkeley. O'Donoghue, E. and M. Rabin. (in press-a). "Doing It Now or Later," American Economic Review. O'Donoghue, E. and M. Rabin. (in press-b). "The Economics of Immediate Gratification," Journal of
Behavioral Decision Making. Rabin, M. (1997). "Risk Aversion, Diminishing Marginal Utility, and Expected Utility: A Calibration
Theorem," Working Paper, Department of Economics. University of California, Berkeley. Rachlin, H. (1995). "Self-Control: Beyond Commitment," Behavioral and Brain Sciences 18, 109-59.

CHOICE BRACKETING

197

Ratner, R., B. Kahn, and D. Kahneman. (1998). "Choosing Less-Preferred Experiences for the Sake of Variety," Working Paper.
Read, D. and B. van Leeuwen. (1998). "Predicting Hunger: The Effects of Appetite and Delay on Choice," Organizational Behavior and Human Decision Processes 76, 189-205.
Read, D., and G. Loewenstein. (1995). "Diversification Bias: Explaining the Discrepancy in Variety Seeking between Combined and Separated Choices," Journal ofExperimental Psychology: Applied 1, 1, 34-49.
Read, D., G. Loewenstein, and S. Kalyanaraman. (in press). "Mixing Virtue and Vice: The Combined Effects of Hyperbolic Discounting and Diversification," Journal of Behavioral Decision Making.
Read, D., L. Van den Ouden, H. Trienekens, and G. Antonides. (1999). "Diversification Bias in Choice for Consecutive Consumption," Working Paper, Leeds University Business School.
Redelmeier, D. A. and A. Tversky. (1992). "On the Framing of Multiple Prospects," Psychological Science 3, 191-193.
Sabini, J. and M. Silver. (1982). Moralities of Everyday Life. Oxford: Oxford University Press. Samuelson, P. (1963). "Risk and Uncertainty: A Fallacy of Large Numbers," Scientia 98, 108-113. Schkade, D. A. and J. W. Payne. (1994). "How People Respond to Contingent Valuation Questions-A
Verbal Protocol Analysis of Willingness-to-Pay for an Environmental-Regulation," Journal of Environmental Economics and Management 26, 88-109. Simon, H. A. (1957). Models of Man: Social and Rational. New York: Wiley. Simonson, I. (1990). "The Effect of Purchase Quantity and Timing on Variety Seeking Behaviour," Journal of Marketing Research 32, 150-162. Simonson, I. and R. S. Winer. (1992). "The Influence of Purchase Quantity and Display Format on Consumer Preference for Variety," Journal of Consumer Research 19, 133-138. Slovic, P., B. Fischhoff, and S. Lichtenstein. (1978). "Accident Probabilities and Seat Belt Usage: A Psychological Perspective," Accident Analysis and Prevention 10, 281-285. Swagler, R. M. and P. Wheeler. (1989). "Rental-Purchase Agreements: A Preliminary Investigation of Consumer Attitudes and Behaviors," Journal of Consumer Affairs 23, 145-160. Thaler, R. H. (1985). "Mental Accounting and Consumer Choice," Marketing Science 4, 199-214. Thaler, R. H. (in press). "Mental Accounting Matters." In D. Kahneman and A. Tversky (eds.), Choices, Values and Frames. Cambridge, UK: Cambridge University Press. Thaler, R. and H. Shefrin. (1981). "An Economic Theory of Self-Control," Journal of Political Economy 89, 392-410. Thaler, R., A. Tversky, D. Kahneman, and A. Schwartz. (1997). "The Effect of Myopia and Loss Aversion on Risk Taking: An Experimental Test," Quarterly Journal of Economics 112, 647-661. Trollope, A. (1883/1980). An Autobiography. Oxford: Oxford University Press. Tversky, A. and M. Bar-Hillel. (1983). "Risk: The Long and the Short," Journal of Experimental Psychology: Learning, Memory and Cognition 9, 713-717. Tversky, A. and D. Kahneman. (1981). "The Framing of Decisions and the Psychology of Choice," Science 211, 453-458. Walden, M. L. (1990). "The Economics of Rent-to-Own Contracts," The Journal of Consumer Affairs 24, 326-337. Wedell, D. H. and U. Bockenholt. (1994). "Contemplating Single Versus Multiple Encounters of a Risky Prospect," American Journal of Psychology 107, 499-518. Wedell, D. H. and U. Bockenholt. (1990). "Moderation of Preference Reversals in the Long Run," Journal of Experimental Psychology: Human Perception and Performance 16, 429-438. Yaari, M. and M. Bar-Hillel. (1984). "On Dividing Justly," Social Choice and Welfare 1, 1-24.

Journal of Risk and Uncertainty, 19:1-3; 199-200 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

The Explanatory Power of Choice Bracketing: A Commentary on Read et al., "Choice Bracketing"

GIDEON KEREN Eindhoven University of Technology

g.b.keren@tm.tue.nl

Modeling choice behavior has been a major challenge for decision theory since its inception, and remains so until this day. Utility theory has been conceived as providing a general framework for choice behavior from both normative and descriptive viewpoints. Accumulating empirical evidence, however, suggests that utility theory does not provide an adequate account for many phenomena of choice behavior. Evidently, choice behavior is vulnerable to different types of framing and does not satisfy the fundamental assumption of procedure invariance (Kahneman and Tversky, 1984).
Despite the large number of empirical demonstrations of procedure invariance and framing effects, they remain isolated and unrelated instances of violations of utility theory. The concept of bracketing, proposed by Read et al. (1999), is a stimulating attempt to provide a unifying framework for various kinds of framing and procedure invariance phenomena. The analogy of bracketing is an interesting and appealing one: As in mathematics, where the same equations yield different results depending on how segments of an equation are bracketed, so in choice behavior different groupings of alternative options in the choice problem may result in different choices. How far can the analogy of bracketing be driven when applied to choice behavior? In the following I briefly discuss two major impediments.
One issue concerns the normative facet: For any choice problem, there are no normative guidelines that would prescribe the best or optimal brackets to be employed. Narrow and broad brackets are not exclusive options but rather define a continuum. Take, for example, an investor who considers an investment: What time span (i.e., brackets) should she adopt: A month, a year, ten years, or perhaps even more? There is no normative principle that would prescribe the optimal time perspective, and the evaluation of whether the "appropriate" brackets have been employed can only be done in hindsight.
The authors propose that broad bracketing may generally lead to better outcomes than narrow bracketing, though they are careful to qualify their recommendation. Not only are the concepts of "narrow" and "broad" imprecise, but in many contexts they will be judged on a relative scale depending on the adopted reference point (i.e., reference brackets).

200

KEREN

The second issue is descriptive in nature. The question is whether the concept of bracketing provides additional insight into choice behavior, above and beyond what is offered, for instance, by the concept of framing. Like in the case of framing, we still lack an adequate theoretical framework for bracketing. What are the conditions under which one will adopt a specific bracketing over another? What are the cognitive mechanisms underlying bracketing? In short, what are the determinants of bracketing? These questions may be worthwhile to study, but until we have at least partial answers to these questions, it will be difficult to make any predictions which brackets a decision-maker will use. In the absence of predictive power, bracketing may remain a post-hoc account.
A final comment relates to both the normative and the descriptive aspects of bracketing. The choice of brackets may be highly correlated with risk and uncertainty. Generally, it seems to me that wider brackets often imply more uncertainty (because wider brackets entail that information is more diffuse). If this is indeed the case, it may be beneficial to examine choice behavior as consisting of two elements: The choice of the "appropriate" brackets (which may not always be conscious) and the actual choice (after the brackets have been determined).

References
Kahneman, D. and A. Tversky. (1984). "Choices, Values, and Frames," The American Psychologist 39, 341-350.
Read, D., G. Loewenstein, and M. Rabin. (1999). "Choice Bracketing," Journal of Risk and Uncertainty, this issue.

Journal of Risk and Uncertainty, 19:1-3; 201-202 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Commentary on "Choice Bracketing" by Read,
Loewenstein and Rabin

DAVID LAIBSON

dlaibson@harvard.edu

Deparlment of Economics, Littauer M-14, Haroard University, Cambridge, MA 02138

Daniel Read, George Loewenstein, and Matthew Rabin adopt the phrase "narrow bracketing" to describe the tendency to make decisions in "isolation" from each other. From the perspective of classical economics, such isolation may be achieved by distorting preferences or the budget constraint. An individual may overlook complementaritiesjsubstitutabilities among different types of consumption. An individual may subdivide his budget into multiple nonfungible accounts. Both of these distortions enable decision-makers to take complex integrated problems and tum them into relatively simple separable problems.
Consider the decision to see the new Star Wars movie. Seeing this movie may be a complement or substitute with a seemingly infinite number of past and future activities-e.g., seeing another current science fiction movie, renting videos of old science fiction movies, reading a science fiction novel, visiting a science museum, buying a telescope, traveling to Cape Canaveral to see a Space Shuttle lift-off, etc ...
It is impossible to catalog all of the complementary;substitutable activities that could in principal be relevant for my decision to see the new movie. Since I necessarily overlook almost all of these related activities, I effectively narrowly bracket my decision to see the movie. The authors point out that such narrow bracketing isn't generally irrational; narrow bracketing is a necessary operation when cognitive resources are scarce.
A person may also simplify a decision by distorting his budget constraint. I may decide that I will spend no more than $15 on entertainment this month. Hence, a decision to see the new Star Wars movie this weekend, may imply that I "won't be able" to go to a concert next weekend. Strict budgets create artificial tradeoffs that can potentially lower welfare, but strict budgets also simplify decision problems and facilitate self-regulation.
The authors describe experiments in which the degree of narrow bracketing is exogenously varied through framing manipulations. When subjects are manipulated to integrate decisions, then those subjects are said to use "broad bracketing." Such broad bracketing might be expected to lead to normatively superior outcomes, but in practice this is not always the case. For example, in many of the experiments discussed in this paper, broad bracketing inappropriately exaggerates particular complementaritiesjsubstitutabilities, leading to normatively worse decisions than

202

IAIBSON

narrow bracketing. Simonson (1990) has demonstrated that when a sequence of future snacks is chosen today, the subjects may overestimate the substitutability of eating a Snickers candy bar this week and next week.
Bracketing is a central aspect of cognition and choice. By identifying and describing this phenomenon, the authors of the current paper have made an important and valuable contribution to the fields of economics and decision theory. This paper paves the way for the development of a formal model of narrow bracketing. Such a model will have two interrelated components: a theory of bracket formation; and a theory of bracket-constrained decision-making.
Bracket formation is driven by several different factors: cognitive capacity limitations, cognitive inertia, pre-existing heuristics, and self-regulation (or motivated bracketing). While these mechanisms are carefully discussed in the current paper, the authors do not discuss the next step in the decision process: How does an individual make a choice once the bracket has been chosen? More specifically, how can we represent the bracketed, or simplified decision problem?
For some decisions, such a theory of bracketed choice is already available. For example, Prospect Theory provides a framework for the evaluation of gambles that are isolated from the rest of the consumer's asset portfolio. However, in many other cases, we have no theory of isolated choice. For example, how should we represent the consumer decision to see the new Star Wars movie? How does one partially isolate this decision from the rest of one's consumption decisions? Does the decision simply involve an estimate of current movie-watching pleasure reduced by some generic shadow cost of time and money? And if so, where do these shadow costs come from? Alternatively, does the consumer identify some alternative benchmark activity (e.g., "reading a novel"), and then pick the new Star Wars movie only if it generates value greater than the benchmark activity? How do we identify such benchmark activities? A complete theory of bracketing will model these mechanisms. The current paper moves us much closer to that goal.

Journal of Risk and Uncertainty, 19:1-3; 203-235 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.
Economic Preferences or Attitude Expressions?: An Analysis of Dollar Responses to Public Issues
DANIEL KAHNEMAN Woodrow Wilson School of Public Policy, Princeton University, Princeton, NJ 08544
lLANA RITOV Hebrew University, Jerusalem
DAVID SCHKADE University of Texas, Austin
Abstract
Participants in contingent valuation surveys and jurors setting punitive damages in civil trials provide answers denominated in dollars. These answers are better understood as expressions of attitudes than as indications of economic preferences. Well-established characteristics of attitudes and of the core process of affective valuation explain several robust features of dollar responses: high correlations with other measures of attractiveness or aversiveness, insensitivity to scope, preference reversals, and the high variability of dollar responses relative to other measures of the same attitude.
Key words: preferences, attitudes, contingent valuation, psychology and economics, utility assessment
JEL Classification: DOD, HOO
Introduction
Economics and psychology offer contrasting perspectives on the question of how people value things. The economic model of choice is concerned with a rational agent whose preferences obey a tight web of logical rules, formalized in consumer theory and in models of decision making under risk. The tradition of psychology, in contrast, is not congenial to the idea that a logic of rational choice can serve double duty as a model of actual decision behavior. Much behavioral research has been devoted to illustrations of choices that violate the logic of the economic model. The implied claim is that people do not have preferences, in the sense in which that term is used in economic theory (Fischhoff, 1991; Slavic, 1995; Payne, Bettman and Johnson, 1992). It is therefore fair to ask: if people do not have economic preferences, what do they have instead? Does psychology provide theoretical notions that can account, at least in some contexts, both for apparent violations of the rational model of preference and for the regularities of observed

204

KAHNEMAN, RITOV AND SCHKADE

choices? Behavioral research has documented several psychological processes that provide partial answers to this question, including concepts such as mental accounting, loss aversion and hyperbolic discounting. To this set of conceptual tools the present treatment adds the concept of attitude, which we borrow from social psychology, and the core process-we label it affective valuation-which determines the sign and the intensity of the emotional response to objects.
The main topic that we discuss in this paper-the valuation of environmental public goods-is far from the core of economic discourse. It is an unusual case in which some economists have proposed to use responses to hypothetical questions as a measure of economic preference. In the contingent valuation method (CVM), survey respondents are asked to indicate a stated willingness to pay (SWTP) for public goods, including goods from which they derive no personal benefit, such as the continued existence of obscure species and the maintenance of pristine lakes in inaccessible areas. The proponents of CVM have argued that properly elicited statements of WTP reveal genuine economic preferences, to which consumer theory applies (Mitchell and Carson, 1989; Hoehn and Randall, 1987; Smith, 1992).
We develop here an argument made earlier (Kahneman and Ritov, 1994) that statements of WTP are better viewed as expressions of attitudes than as indications of economic preferences. The conflicting views of the nature of SWTP lead to different interpretations of apparently anomalous features of CVM results, such as the low sensitivity to variations of scope and the discrepancy between the estimates of SWTP derived from open-ended and from referendum questions. The supporters of CVM have sometimes dismissed these anomalies as artifacts of poor technique (Carson and Mitchell, 1993; Smith, 1992), or explained them in terms of standard economic concepts, such as incentive compatibility and substitution and income effects (Hanemann, 1994; Randall and Hoehn, 1996; Smith, 1992). In contrast, the thesis of the present paper is that the anomalies of CV are inevitable manifestations of known characteristics of attitudes and attitude expressions.
To demonstrate the generality of the analysis of SWTP in terms of attitudes, we draw on an experimental study of the setting of punitive damages in product liability cases (Kahneman, Schkade and Sunstein, 1998). The tasks faced by a respondent to a CV survey and by a juror have little in common in the context of an economic analysis; consumer theory may apply to the former but surely not to the latter. In the framework that we propose, however, the two tasks are very similar. Both require the individual to express an attitude-to an environmental problem or to a defendant's actions-by using a dollar scale. The striking parallels between the findings in the two situations strongly support the attitude model.
The evidence that we present is drawn exclusively from studies of verbal answers to hypothetical questions about public issues. It is perhaps not surprising that, on this favorable terrain, the concepts of attitude and affective valuation provide a useful account of the data. It is early to say whether these concepts will prove equally useful in other domains to which the theory of economic preference is usually applied. On current evidence, it is possible to accept an attitude model for hypothetical CV responses while retaining the idea that the standard model of

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

205

rational choice applies to more consequential decisions. This appears to be the position of economists who have criticized CVM (e.g., Diamond and Hausman, 1994). We believe, however, that the idea that actions are often interpretable as relatively direct expressions of an affective valuation is likely to prove useful in the analysis of many economically significant behaviors.
The paper is organized in two parts. The first part, which includes sections 1-4, introduces the concepts of attitude and affective valuation and explores some contrasts between attitudes and economic preferences, with examples from studies of contingent valuation and of punitive damages. Sections 5 and 6 apply a psychophysical analysis of dollar responses to explain both the unpredictability of jury awards and some important results of CV research. Section 7 discusses implications and Section 8 concludes.
This article covers much ground and asserts many claims with relatively little documentation. To facilitate a separate assessment of the claims and of their associated evidence, we present our argument in the form of a series of propositions, with brief discussion of each proposition in turn.

1. Introduction to valuation
1-1) The concept of attitude has been defined as "a psychological tendency that is expressed by evaluating a particular entity with some degree offavor or disfavor" (Eagly and Chaiken, 1996). The core of an attitude is a valuation, which assigns to the entity an affective value that can range from extremely positive to extremely negative.1
1-2) Affective values vary in sign (positive or negative) and in intensity. The intensity of valuation is relative: an attitude object considered on its own is implicitly compared to a set of objects of the same general kind. (see section 4).
1-3) The concept of attitude has a considerably broader range of application than the standard concept of economic preferences. In contrast to economic preferences, which are about commodity bundles (Varian, 1984), objects of attitudes include anything that people can like or dislike, wish to protect or to harm, want to acquire or to reject. People have attitudes toward abstract concepts, individual persons and social groups, events in their personal past and historical figures. Expressions of attitude are also diverse: they include smiles and frowns, verbal statements of approval or abuse, physical assault, charitable contributions, answers to survey questions, and many others. The valuation component of attitudes is assumed to be automatic and to facilitate a broad range of responses that express positive or negative affect (Fazio, Sanbonmatsu, Powell, and Kardes, 1986; Pratto, 1994; Tesser and Martin, 1996).
1-4) People's attitudes to objects and to activities that affect these objects are usually consistent. For example, a positive affective response to dolphins is likely to be associated with a positive valuation of actions that protect members of this species.

206

KAHNEMAN, RITOV AND SCHKADE

The link between attitudes and actions is often far from perfect, however (Eagly and Chaiken, 1993).
1-5) The objects of attitudes and valuations are mental representations, not objective states of affairs. Valuations are therefore subject to framing effects and violate the logic of extensionality. In an example much discussed by philosophy students, an individual may have different attitudes to the evening star and to the morning star, although they are the same star. People can also have different attitudes to the same packaged meat depending on whether it is described as containing 5% fat or as being 95% fat-free. The latter example is a framing effect, in which two descriptions evoke different valuations although they are transparently co-extensional-they refer to the same state of the world. Many large and robust framing effects have been identified by students of individual decision making (e.g., Tversky and Kahneman, 1986) and students of political attitudes (Bartels, 1998; Quattrone and Tversky, 1984; Zaller, 1992). Framing effects violate a condition of extensionality (Arrow, 1982) or invariance (Tversky and Kahneman, 1986), which is commonly taken for granted in economic analyses of preference. The psychological analysis of attitudes and valuations explicitly rejects the extensionality assumption.
1-6) The following is a partial list of the properties of attitudes and of the ways they differ from preferences. (i) Attitudes are defined by the affective value of objects considered one at a time, not by choices. (See sections 2 and 4.) (ii) Attitudes violate extensionality. The same object may evoke different valuations depending on its description and on the context in which it is evaluated. (iii) The separate attitudes to two objects do not necessarily predict the outcome of a choice or direct comparison between them: reversals can occur when the comparison alters the relative salience of some attributes (Hsee, 1996), or when the objects belong to different categories. (See section 4.) (iv) The attitude to a set of similar objects is often determined by the affective valuation of a prototypical member of that set. The size of the set is neglected in this mode of valuation, which violates the logic ofpreferences. (See section 3.) (v) Alternative measures of attitudes differ in their precision, statistical efficiency and susceptibility to biasing influences. Dollar measures are inferior on all three counts. (See sections 5 and 6.)

2. The evaluation factor
A central claim of the present treatment is that diverse responses to an object often express the same affective valuation. Consequently, the answers to ostensibly different questions are expected to yield similar rankings of attitude objects. The present section provides some evidence for this hypothesis. The data that we consider for each object are averages of attitude measures obtained from different samples of respondents. The correlations that we discuss in this section answer the following question: do different ways of probing average attitudes to a set of objects yield similar attitude orders?

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

207

2-1) The affective value of an object is the major determinant of many responses to it, which are called attitude expressions. A correlational analysis of the responses to a set of objects normally yields a strong evaluation factor, which captures the commonality among diverse expressions of the same attitude. The classic set of studies that introduced the semantic differential technique (Osgood, Suci and Tannenbaum, 1957) still provides the best illustration of this proposition. Participants in SD studies are presented with a series of objects or concepts. Their task is to rate each object in tum on a set of seven-point scales defined by bipolar adjectives, such as GOOD-BAD, KIND-CRUEL, BEAUTIFUL-UGLY, LARGE-SMALL, STRONG-WEAK, MASCULINE-FEMININE, IMPORTANT-UNIMPORTANT, and others. The range of objects to which this technique can be applied is hardly constrained: it includes particular objects, events, abstract ideas, activities, and nonsense figures. The participants are instructed to work quickly and to rate each object on every scale, regardless of whether or not it applies literally. Thus, 'wisdom' and 'Paris' could both be rated on the scales LARGE-SMALL and HOT-COLD-most people will rate wisdom as larger and colder than Paris.
For our purposes here, the most important conclusion of studies of the semantic differential is that the factorial structure of SD data is surprisingly simple. The same structure has been confirmed in many studies. The largest factor to emerge is invariably an evaluation factor, so labeled because the highest loadings are on scales such as GOOD-BAD, KIND-CRUEL and BEAUTIFUL-UGLY. The evaluation factor typically accounts for about 50% of the variance in scale responses. The scales that define the evaluation factor are not perfectly correlated, of course, and the differences among them are meaningful. For example, 'justice' is likely to be rated higher on the GOOD-BAD scale than on the KIND-CRUEL scale. Large discrepancies are rare, however, and the different evaluation scales generally yield similar orderings of the objects of judgment.
2-2) Attitudes can be expressed on a scale of dollars, as well as on rating scales. Valuations expressed in dollars are highly correlated with those expressed on rating scales. Willingness to pay for environmental goods-e.g., the maintenance of species-is one possible expression of attitudes to these goods, and to interventions that affect them. Similarly, attitudes to defendants in civil trials can be expressed by an amount of punitive damages. Studies in both domains have examined the following two hypotheses: (i) different measures of the valuation of issues are highly correlated, as in the semantic differential; (ii) dollar measures belong to the cluster of attitude measures.
Kahneman and Ritov (1994) studied the valuation of 37 topics, including a wide array of environmental problems and other public issues. The issues were presented as headlines, in which a brief description of a problem was followed by a single sentence describing a proposed intervention. An example was "THE PEREGRINE FALCON IS THREATENED BY POLLUTION. Intervention: Support special program to protect the Peregrine falcon." Several measures were used: SWTP for the proposed intervention, degree of political support for the interven-

208

KAHNEMAN, RITOV AND SCHKADE

tion, personal satisfaction expected from making a voluntary contribution (both on a 0-4 rating scale), and a rating of the importance of the problem as a public issue, on a 0-6 rating scale. The participants in the study were visitors at the San Francisco Exploratorium. Each participant used only one of these four response scales to evaluate anywhere from 9 to 19 assigned of the problems. The total sample was 1441, and the number of respondents to any particular version of a problem was 50-115.
The 37 problems were ranked by the sample means for each of the response measures. Rank correlations between these means are shown in Table 1. The numbers on the diagonal represent measures of reliability, obtained by a bootstrapping procedure. Table 1 indicates that the rankings of the issues by the different measures were quite similar. Indeed, the correlations between orders derived from different measures were not substantially lower than the reliabilities of the individual measures.
What do ratings of importance, predictions of moral satisfaction, statements of political support and indications of willingness to pay have in common? Our answer is that these expressions share a common affective core, which is so prominent that it allows the public attitude order over objects to be measured almost interchangeably by ostensibly diverse responses.
Payne et al. (1999) observed a similar result in a study of 190 citizens who responded to five CV surveys of realistic length and detail. The topics were air quality in the Grand Canyon, oil spill prevention, and preservation of wolves, salmon, and migratory waterfowl. Each respondent expressed an evaluation of each commodity in SWTP and on four 0-10 rating scales-importance compared to other problems in society, seriousness compared to other environmental problems, use value and existence value. Respondents came for two separate two-hour sessions, scheduled two weeks apart. In the first session a given respondent responded to all five commodities on either SWTP or the four rating scales. In the second, they again responded to all five surveys, but using the response mode(s) they did not use in the first session. The results showed rank correlation levels between response modes similar to those of Table 1 (ranging from .67 to 1.00), despite the many differences in stimuli and procedure from the Kahneman and Ritov study.

Table 1. Rank correlations between mean evaluations of 37 issues

SWTP

Support

Importance

SWTP

(.87)

Support

.84

(.85)

Importance

.76

.84

(.88)

Satisfaction

.84

.87

.85

From Kahneman and Ritov, 1994.

Satisfaction (.90)

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

209

Our next example is drawn from a study which employed a similar design to study the psychology of punitive damages. Kahneman, Schkade, and Sunstein (1998) constructed 28 vignettes of cases in which a firm was found liable for compensatory damages in a product liability case. Each participant responded to a subset of 10 of these cases. Separate groups of respondents were asked to answer one of three questions about each scenario: "how outrageous was the defendant's behavior?" (on a 7-point scale), "how severely should the defendant be punished?" (on a 7-point scale), or "how much should the defendant be required to pay in punitive damages?" (in dollars). The respondents were 899 jury-eligible adults. An average of 107 respondents responded to each different case-question combination. The 28 cases were ranked by the mean ratings of outrage and punitive intent, and by the median dollar award. The correlations between these rankings are shown in Table 2.
Here again, we may ask what the three responses have in common that results in such high correlations. The outrage rating appears to be a rather direct measure of the affect evoked by cases of personal injury. The high correlations indicate that the same affective valuation also dominates ratings of punitive intent and judgments of punitive damages in dollars. The hypothesis that expressions of attitude are dominated by a shared affective reaction-in this case, by a degree of outrage -is again strongly supported.
The results shown in Tables 1 and 2 are correlations between averages of large samples, computed over objects. It is important to note that these correlations are not necessarily representative of the results that would be obtained within the data of individual respondents (Nickerson, 1995). As in the case of other summary statistics, it is possible for group results to be dominated by a few individuals who (i) produce more variance than others, and (ii) have an atypical pattern of responses. These hypotheses are readily testable (e.g., by examining the effects of standardizing the data of each individual), and we are satisfied that they did not apply to the data reported in this section.2
2-3) Each expression of attitude also has its specific and distinctive determinants, but these account for less variance than the core affective value. The example of justice being GOOD but not necessarily KIND was used earlier to show that different expressions of the evaluation factor in the semantic differential are not interchangeable. The same conclusion applies to the factor of affective valuation that

Table 2. Rank correlations between mean evaluations of 28 cases

$Awards

Outrage

$ Awards (median)

(.89)

Outrage

.80

(.96)

Punishment

.92

.86

From Kahneman, Schkade and Sunstein, 1998.

Punishment (.98)

210

KAHNEMAN, RITOV AND SCHKADE

could be extracted from diverse responses in the data of Tables 1 and 2. It is convenient to analyze an expression of affective valuation as the sum of three separable components:

X=A+S+e

(1)

where A is the shared affective valuation, S is a response-specific component, and e is an error term. The high correlations shown in the previous section indicate that the first of these components accounts for much more variance than the second. The shared affective value dominates the diverse expressions of attitudes. As the following examples illustrate, however, the specific content associated with different responses is both interesting and important.
Kahneman, Schkade and Sunstein (1998) offered an outrage model to account for both the similarities and the differences between the measures of outrage, punitive intent and punitive awards. They examined the differences in two experiments. The first experiment demonstrated that rated outrage was the same regardless of whether harm was severe or mild. This result is intuitively plausible: a behavior can be judged as more or less outrageous without knowing its consequences. In contrast, ratings of punitive intent and assessments of punitive damages were both sensitive to the severity of harm. Punishment involves a retributive intent, which depends on the consequences of the act that is to be punished; this is the intuition that justifies treating murder and attempted murder as distinct crimes. A second experiment showed that the size of the defendant firm had a large effect on the amount awarded in punitive damages, but no effect whatsoever on either outrage
or punitive intent. This result is also plausible: a payment that constitutes 'very severe' punishment for a small firm may be quite insignificant for a larger one. As in the early studies of the semantic differential, we observe a pattern of meaningful differences among highly correlated expressions of the same affective valuation. Detailed examinations of responses to public goods also reveal systematic discrepancies between highly correlated measures (Kahneman and Knetsch, 1992). As the high correlations in these studies suggest, however, the discrepancies between measures are small in magnitude, relative to the large common influence of the underlying affective valuation.

3. Valuation by prototype and the scope problem
The evidence reviewed in the preceding section confirmed the similarity between the rankings of objects by different measures of attitude, and provided suggestive evidence that the core of attitude is an affective valuation. In this section we argue that the affective valuation of a prototypical exemplar often determines the global attitude to sets of objects. We show that this process can explain an important finding of contingent valuation research: the inadequate sensitivity of SWTP to the quantitative aspects of problems and solutions.

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

211

3-1) People hold stored prototypes of many categories. They also form prototypes or representative exemplars of new categories and sets that they encounter. The prototypes of tables, of birds and of Harvard MBA's are widely shared among members of the relevant culture. People also form ad hoc representations of a typical day of a seaside vacation, or of a typical resident of a city they visit. These representations of prototypes are evoked in the service of thinking about concepts and classes (Barsalou, 1992).
3-2) In judgment by prototype, a global judgment of a category or set is determined primarily by the relevant properties of its prototype. The principle of judgment by prototype extends the older idea that a representativeness heuristic is involved in many intuitive judgments about uncertain events (Kahneman and Tversky, 1972, 1973; Tversky and Kahneman, 1971, 1983).
3-3) When the size of the set is logically relevant to its valuation, judgment by prototype leads to a bias of extension neglect: Unless attention is specifically directed to it, the size of the set has little or no influence on its valuation. This pattern has been obseroed in different contexts, in which extension neglect takes different forms (Kahneman, 1995). To illustrate the generality of the phenomenon of extension neglect, we briefly describe three examples:
(i) Intuitive statistical inferences are often made by assessing the similarity between the statistic of a sample and the parameter of a population. The sample and the population are both ensembles, but the judgment about them is based mainly on the relation between the prototypes that represent them. Intuitive inferences based on such reasoning are characterized by extreme lack of sensitivity to sample size, which is the form that extension neglect takes in this task (Griffin and Tversky, 1992; Kahneman and Tversky, 1972; Tversky and Kahneman, 1971).
(ii) In a familiar paradigm for the study of intuitive prediction, subjects judge the probability that an individual is a member of a specified social category (defined by a profession or an avocation) on the basis of a personality sketch (Kahneman and Tversky, 1973; Tversky and Kahneman, 1982). Probability is judged by the similarity of the individual's personality to the stereotype of the target category. For example, an individual described as "argumentative, flashy, self-confident and competitive" will be judged more likely to be a lawyer than to be an engineer, because the description resembles the stereotype of the former profession more than that of the latter. In this paradigm, extension neglect takes the form of inadequate sensitivity to the base rates of outcomes (Kahneman and Tversky, 1973; see also Koehler, 1996; Novemsky and Kronzon, 1999).
(iii) Extension neglect has also been observed in a paradigm in which participants are exposed for some time to an unpleasant experience. The participants provide a continuous report of current discomfort, using an 'affect meter.' Later they provide a global judgment of the entire episode. Various experiences have been studied, including unpleasant films (e.g., of an amputation), immersion of the hand in cold water, exposure to loud noise, and painful medical procedures (see Kahneman, Wakker and Sarin (1997) for a review). For our purposes, an episode of

212

KAHNEMAN, RITOV AND SCHKADE

discomfort can be construed as a set of unpleasant moments. The duration of the episode is the measure of extension. Valuation by prototype implies that participants will construct or remember a typical moment of the episode, and evaluate the episode as a whole by the level of unpleasantness associated with the prototypical moment-the duration of the episode will be neglected. The hypothesis of duration neglect has been confirmed in several experiments, with both ratings and choices as dependent variables (Kahneman, Wakker and Sarin, 1997).
In all three situations, judgment by prototype and extension neglect can cause violations of monotonicity. People commonly underestimate the strength of evidence provided by 'weak' results in a large sample, compared to stronger results in a small sample (Tversky and Kahneman, 1971). They assign a higher probability to the statement 'Linda is a bank teller and a feminist' than to the statement 'Linda is a bank teller,' if the description of Linda resembles the stereotype of a feminist but not the stereotype of a bank teller (Tversky and Kahneman, 1982). Because the prototypical moment of an episode of discomfort is strongly influenced by how the episode ends, adding a period of diminishing pain to an episode makes it less aversive, in violation of dominance (Kahneman et al., 1993).
3-4) In some applications of contingent valuation, a problem or a solution is specified by the quantity of a homogeneous good. In such cases, extension neglect takes the form of insensitivity to scope: the quantitative attribute has little weight in the valuation, which is determined mainly by the affective response to a prototypical instance of the good. Economic theory imposes stringent constraints on the response to variations in the quantities of a good. Diamond and his colleagues (Diamond et al., 1993; Diamond, 1996) have formulated these constraints as a simple add-up test for SWTP in CV surveys: after allowing for an income effect, SWTP for the conjunction of two parts should equal the sum of SWTP for one part, plus SWTP for the second part conditional on already having the first part. It is generally agreed that adequate sensitivity to scope is essential to the acceptability of CVM (NOAA panel on Contingent Valuation, 1993).
Sensitivity to scope has been studied in several research paradigms (see section 3-6). We are concerned here with a particular variant, the quantity design, in which participants indicate their willingness to pay for a specified amount of a relatively homogeneous good.3 The amount of the good is varied across groups of respondents. A well known example of this experimental design is due to Desvousges et al. (1992). The question these authors put to their respondents can be paraphrased as follows: "(2,000, or 20,000, or 200,000) migrating birds die each year by drowning in uncovered oil ponds, which the birds mistake for bodies of water. These deaths could be prevented by covering the oil ponds with nets. How much money would you be willing to pay to provide the needed nets?"
The principle of valuation by prototype applies in straightforward fashion to this example. The story constructed by Desvousges et al. probably evokes for many readers a mental representation of a prototypical incident, perhaps an image of an exhausted bird, its feathers soaked in black oil, unable to escape. The hypothesis of

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

213

valuation by prototype asserts that the affective value of this image will dominate expressions of the attitude to the problem-including the willingness to pay for a solution. Valuation by prototype implies extension neglect. Although the number of birds that die in oil ponds is surely a relevant consideration, we would expect that-unless the respondents' attention is specifically directed to it-the number of bird deaths will have little effect on SWTP or on other measures of attitudes. Indeed, mean SWTP was $80, $78 and $88, respectively, for saving 2,000 birds, 20,000 birds or 200,000 birds annually (Desvousges et al., 1992).
Similar results have been obtained in other applications of the quantity design. In an early study using this design, Kahneman and Knetsch (see Kahneman, 1986) found that Toronto residents were willing to pay only a little more to clean up all the polluted lakes in Ontario than to clean up polluted lakes in a particular region of Ontario. McFadden and Leonard (1993) reported that residents in four western states were willing to pay only 28% more to protect all 57 wilderness areas in those states than to protect a single area. Jones-Lee et al. (1995) found that the SWTP of UK respondents for a program to reduce the risk of non-fatal road injuries increased by only 29% when the number of prevented injuries was increased by a factor of three. Laboratory studies show similar insensitivity to the quantity of the good. Baron and Greene (1996, experiment 8), for instance, found no effect on SWTP of varying the number of lives saved by a factor of 10.
There is research in which the effects of quantitative variations appear to be larger, though certainly not enough to satisfy economic theory. For example, Carson and Mitchell (1995) describe an unpublished study of the value of reducing the risk associated with chlorination of drinking water. They report that an increase of risk from .004 to 2.43 annual deaths per 1,000 (a factor of 600) yielded an increase of SWTP from $3.78 to $15.23 (a factor of 4). This result does not contradict the general conclusion of other research in this area: the response to variations of scope is so slight that it is not explicable in the standard terms of economic analysis.
Explanations of insensitivity to scope in terms of an income effect are implausible, because the amounts are so small. Explanations in terms of substitution effects are equally unattractive. Several studies have shown that reminding subjects of substitutes or of their prior endowment does not substantially change their response (Loomis et al., 1994; Neill, 1995; Ritov, Baron and Hershey, 1993). An interpretation in terms of substitution effects, if it were taken seriously, would be potentially disastrous for the environment. It would indeed be good news for polluters if the public's demand for clean lakes in Ontario could be satisfied by cleaning up a small subset of its lakes.
Our aim in this section was not to deal with the details of the heated controversy concerning sensitivity to scope (see, for example, Carson and Mitchell, 1995; Frederick and Fischhoff, 1998). Our goal is both simpler and more ambitious: we hope to have shown that inadequate sensitivity to scope in CV surveys that employ the quantity design is inevitable, because this phenomenon is an instance of a broad

214

KAHNEMAN, RITOV AND SCHKADE

class of similar effects that have been observed in diverse contexts and are explained by a single psychological principle.
3-5) Extension neglect is neither universal nor absolute. When extension information is both salient and readily interpretable an additive extension effect is observed: the effects of the valuation of the prototype and of the size of the relevant set are additive. This pattern violates normative rules that require non-linear combination of the two types of information. In the situations we have discussed, the relevance of extension may be obvious if the quantity mentioned in the problem is readily classified as high or low. Under such circumstances, responses will show some sensitivity to extension. For example, even naive respondents will appreciate that an annual death rate of .0004% from chlorinated water is very low, because of the impressively large number of leading zeros. However, there are situations in which the quantitative information is less easily interpreted: unless the two numbers are seen together, for example, the subjective difference between two large quantities such as 20,000 or 200,000 birds dying in oil ponds is not very impressive (Hsee, 1996). These are the conditions under which complete neglect of scope may be observed.
Studies of extension neglect in other domains have shown that multi-trial experiments in which extension varies from trial to trial have two effects: they draw attention to extension as a relevant feature, and they provide a standard that helps the subject assess values of the extensional attribute as high or low. Extension is not completely neglected under these conditions. Indeed, significant effects of extension have been found in within-S experiments in all the domains we have mentioned. When the base-rate of outcomes is varied from trial to trial, people pay attention to it (Novemsky and Kronzon, 1999). When the duration of episodes that are to be evaluated varies from trial to trial, duration neglect is imperfect (Schreiber and Kahneman, 2000; Varey and Kahneman, 1992). Sample size also affects judgments in within-subject experiments (Griffin and Tversky, 1992).
A remarkable regularity appears in these experiments: the valuation of the prototype and the extension of the set (base-rate or duration) contribute in strictly additive fashion to the global judgment (see also Anderson, 1996, p. 253). The participants in these experiments appear to reason as follows: "this medical procedure is quite painful, but it is short" or "this medical procedure is quite painful, and it is also long." In contrast to the logic of global evaluation, which requires multiplicative or quasi-multiplicative effects of extension, the size of the set is used as an extra feature in this reasoning.
The additive extension effect is also found in the valuation of environmental goods. Kahnell}an and Ritov (unpublished research) presented several groups of respondents messages such as the following: "the population of Dolphins in a coastal preserve has declined by 50%." The species mentioned ranged widely in emotional appeal, and the population decline was also varied. Some respondents rated the importance of the problem. Others indicated, for each species, how much of a contribution of $40 to a general environmental fund they would divert to restore the population of the species in the nature preserve. Figures 1a and 1b

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

215

5

cCD
i 4.5
D::

ucCll
~4
c0 .
.5

cca
Cll

3.5

::E

High
Medium
Low Species Popularity

3 0

30

--~
c 25

;0

...·.:;as:
c

20

0

0

cca

Q) 15

::E

20

40

60

80

100

Population Decline (percent)

(a)

High

Medium
Low
Species Pooularitv

10~------~----------------~--------~------~

0

20

40

60

80

100

Population Decline (percent)

(b)

Figure 1. a. Mean importance ratings, by species popularity and degree of population decline. b. Mean contributions, by species popularity and degree of population decline.

present the results for both response measures. The striking feature of these data is that both the dollar measure and the rating of importance exhibit nearly perfect additivity of the effects of species popularity and size of population decline. Precisely the same pattern of results has been observed in studies of individual prediction (Novemsky and Kronzon, 1999), and of the global evaluation of episodes

216

KAHNEMAN, RITOV AND SCHKADE

(Schreiber and Kahneman, 1999). A related result was obtained by DeKay and McClelland (1996), who found that the species attributes and the probability of survival were combined additively in people's ranking of programs to preserve endangered species.
We draw several conclusions from this research. First, some effect of extension can be obtained by a procedure, such as the within-subject experimental design, which simultaneously draws attention to the quantitative variable and provides a frame of reference for responding to it. Second, a demonstration that people can be responsive to extension and scope under some conditions is not sufficient to support the conclusion that they always use extension in accordance with the relevant logic. Third, and most important, we again find that the anomalies observed in studies of the value of public goods do not remain either puzzling or unique when they are viewed in the context of similar phenomena in other domains.
3-6) Several different designs have been used to test sensitivity to scope. The designs are psychologically different, but the normative pattern defined by the add-up test (Diamond, 1996) is unlikely to be satisfied in any of them. Sensitivity to scope has been examined in two designs other than the quantity design that was discussed in previous sections. (i) In the explicit list design, respondents in different groups value nested lists of heterogeneous goods. For example, one group may assess the value of saving both the birds and the fish in a region, while other groups value the birds or the fish in isolation. (ii) In the embedding design, SWTP for a good (e.g., saving dolphins) is obtained in two ways: (a) by a direct question (b) by a sequence of questions, first eliciting SWTP for an inclusive good, then the fraction of that amount that should be allocated to a specified good (e.g., SWTP for saving marine mammals, then an allocation to dolphins).
The various tests of scope are equivalent in an economic analysis, and Diamond's add-up test is applicable to all three. In a psychological analysis, however, the designs differ in important ways. The quantity design involves a set or category of elements that are similar in essential respects (e.g., polluted lakes, or different members of the same species). In contrast, the two other designs involve heterogeneous elements, which are not readily represented by a single prototype (Rosch and Lloyd, 1978). There is some evidence that a process of judgment by maximum operates in the valuation of heterogeneous categories and lists (Levav, 1996). A related result was reported by Rottenstreich and Tversky (1997) in a study of judgments of frequency for explicit lists (e.g., "How many Stanford students major in either English or Geography?" Judgment of the total frequency of an explicit disjunction were barely higher than judgments of its maximum. Judgment by maximum, of course, violates the add-up rule.
Carson et al. (1994) reported a study using an explicit list design, which they described as a demonstration of sensitivity to scope. Unfortunately, a basic flaw of their study invalidates their conclusions. The study was concerned with the valuation of the damage that deposits of DDT in the soil of LA Harbor has caused to

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

217

the reproductive ability of two salient species of birds (Peregrine Falcon, American Bald Eagle) and two relatively obscure species of fish (White Croaker, Kelp Bass). The authors observed higher SWfP when the description of the problem involved all four species than when it involved only the fish. Of course, the results are equally consistent with the hypothesis that WTP to restore two important species of endangered birds is higher than WTP to restore two relatively obscure species of fish. The hypothesis of judgment by maximum suggests that the value attached to the four species would not be much higher than the value attached to the most important of these species. The results of an informal replication of the LA Harbor study, using ratings of importance, were generally consistent with this hypothesis (Levav, 1996). There is no reason to expect that the results of CV using explicit lists will satisfy the add-up test (see also Frederick and Fischhoff, 1998).
The findings obtained in the embedding design unequivocally violate the add-up rule. For example, Kemp and Maxwell (1993) found that SWTP for protection from oil spills off the coast of Alaska was $85 when the good was considered on its own, but only $0.29 when it was derived as an allocation of SWTP for a more inclusive category (environmental protection programs). Kahneman and Knetsch (1992) reported similar findings.
The central point of this section has been that inadequate sensitivity to scope is not a surprise. On the contrary, it would be a major surprise to observe measures of SWfP that reliably conform to the add-up test. This conclusion is relevant to the frequently expressed hope that the scope problem might be overcome by improved instructions, exhortation or added information. Insensitivity to scope is the inevitable result of general rules that govern human judgment. It is naive to expect broad psychological laws to be overcome by minor methodological adjustments.

4. Context-dependence and valuation reversals
A preference reversal is said to exist when two strategically equivalent methods for probing the preference between objects yield conflicting results (see, e.g., Hsee, 1996; Tversky and Thaler, 1992). Preference reversals simultaneously challenge two basic tenets of the standard economic analysis of choice: the existence of a preference order, and the assumption of extensionality. One of the crucial differences between the concepts of economic preference and attitude is that preference reversals are anomalous only for the former, not for the latter. In this section we discuss preference reversals that arise from the context dependence of attitudes and affective valuations. Norm theory (Kahneman and Miller, 1986) provides the theoretical background for this discussion.
4-1) An object that is considered in isolation evokes a comparison set of similar objects. The valuation of the object is relative to the set that it evoked. Features that are common to the evoked set play no role in relative judgments and valuations. For an illustration of the relativity of judgment to an evoked set, consider the following

218

KAHNEMAN, RITOV AND SCHKADE

two questions: "Is a subcompact car BIG or SMALL?", "Is a bald eagle BIG or SMALL?" The plausible answers are that a subcompact is small and a bald eagle is big. The categories of cars and birds are spontaneously evoked by the mere mention of their members, and these categories provide the norm for a relative judgment of size. The conventions of language allow the entire range of size adjectives, from 'tiny' to 'enormous' to be applied to cars and to birds, to countries and to bacteria.
As we show later, expressions of attitudes show a similar relativity. Furthermore, casual observation indicates that affective values-not only the words used to describe them-are themselves relative. Thus, a guest's rude behavior at a party can arouse intense outrage and anger. Murder is much worse than rudeness, of course, but murder is not part of the evoked context that determines the emotional response to a rude remark. The relativity of affective value explains why people often seem to care intensely about matters that they can also view as trivial when the context changes.
4-2) Explicit comparison of several objects imposes a shared context for their judgment and valuation. When the objects belong to different categories, comparisons and isolated valuations can yield discrepant results. Differences between the modes of valuation are found both in dollar measures and in ratings. Table 3 presents preliminary tests of this hypothesis, drawn from two different studies. The same pair of issues was used in both studies: damage to coral reefs caused by cyanide fishing in Asia, and increased incidence of multiple myeloma among the elderly. We surmised that the latter issue would be perceived as a fairly minor public health problem, whereas a threat to coral reefs would appear significant in an ecological context. We also surmised that public health problems would be assigned a higher general priority than ecological problems, but that this priority would only become relevant in a direct comparison.

Table 3. Responses to an ecological and a public health problem, by presentation order

Study 1

Moral satisfaction

First

Second

Importance

First

Second

Coral Reefs

3.54

3.24

Myeloma

2.84

4.18

3.78

3.62

3.24

4.26

Study 2

Moral satisfaction

First

Second

SWTPa

First

Second

Coral Reefs

3.47

3.05

Myeloma

2.98

3.76

$45

$59

$69

$109

a All values of WTP in excess of $500 were adjusted to $500.

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

219

The procedure of the two studies was similar. The participants were first asked to evaluate one problem; they were then shown the other problem and were asked to respond to it, with an explicit instruction to consider both problems before responding. The independent variable was the order of presentation of the two problems. The participants in Study 1 were 100 visitors at the San Francisco Exploratorium. They were asked to rate the importance of each problem and the satisfaction they would expect to get from making a contribution to its solution (both on a 0-6 scale). The data for Study 2 are drawn from a larger study, in which participants were jury-eligible residents of Austin. Some participants (N = 130) provided ratings of satisfaction as in Study 1. Others (N = 261) indicated their WTP to contribute to a solution; when they encountered the second problem they were instructed to treat it as the only cause to which they would be asked to contribute.
Our hypothesis about the role of context in judgments predicts a statistical interaction effect in each of the panels of Table 3: the difference between the valuations of the myeloma and coral reefs problems is expected to be larger when these items appear in the second position than in the first. The rationale for this prediction is that the difference between the categories of ecological and human problems is only salient when the issues are directly compared, not when they are
valued in isolation. The predicted interaction is highly significant (p < .001) in each
of the four panels of Table 3. The context effect observed in SWTP is especially noteworthy, because the
linguistic convention that allows words such as 'important' or 'satisfying' to be understood in a relative sense does not apply to the dollar scale. To appreciate the difference between scales that allow relativity and scales that do not, consider the questions: "What is the size of an eagle, in meters?", "What is the size of a subcompact, in meters?" Of course, there is no reason to expect any effect of category on answers to this question. A context effect on a size judgment expressed in absolute units indicates a visual illusion-a change in the underlying perception, not in the language used to describe it. By the same logic, the finding of a context effect on a dollar measure implies that the evaluation itself, not only the expression of it, is altered by the comparison.
Kahneman, Schkade and Sunstein (unpublished data) investigated the effects of a comparison context on punitive damage awards. The study was motivated by the observation that the highest punitive awards are commonly found in cases involving large financial harm, probably because the size of the compensatory damages provides a high anchoring value. Punitive damages are generally lower in cases of personal injury, where compensatory damages are also lower. We surmised, however, that cases that result in personal injury are, as a class, more outrageous than cases in which the only losses involve money. Of course, no jury ever considers cases of the two types at the same time, but we predicted that forcing jurors to do so in an experiment would alter or reverse the usual pattern of punitive awards. A sample of 114 jury-eligible citizens provided a punitive damage assessment for either a personal injury case adapted from Kahneman, Schkade and Sunstein

220

KAHNEMAN, RITOV AND SCHKADE

(1998): (a child seriously hurt because of a flawed child-safety cap), a financial harm case (business fraud), or both. Participants were told that compensatory damages had already been awarded, in the amount of $500,000 for the personal injury and $10 million for the financial harm. As predicted, respondents who judged only one case assessed greater punitive damages in the financial case (median = $5 million) than in the personal injury case (median = $2 million). However, a strong majority (75%) of respondents who judged the two cases together assessed larger awards in the personal injury case, resulting in a striking reversal of median awards ($2.5 million for the personal injury; $0.5 million for the financial harm). More recent data indicate similar effects in ratings of outrage and punitive intent. The same interpretation applies to these results and to the findings summarized in Table 3. Cases of personal injury and of financial harm, when considered in isolation, are apparently compared to very different evoked contexts. Here again, the conclusion that the context alters the underlying emotion is justified by the finding of an effect on a dollar measure. A financial transgression that appears outrageous on its own apparently arouses much less outrage when directly compared to an action that causes a child to suffer a severe injury (Kahneman, Schkade, Ritov and Sunstein, 1999).
4-3) Choice is a special case of comparative valuation, whereas pricing (or the setting of WTP) is normally done by considering a problem in isolation. The different contexts of choice and pricing explain some preference reversals between the two tasks. The analysis of context effects in the preceding section helps explains preference reversals between choice and SWTP that were reported by Kahneman and Ritov (1994). Seven critical pairs of items were constructed, each including one ecological issue and one public health problem. The responses of two groups of respondents were compared. One group encountered both items in a questionnaire that elicited statements of WTP for interventions to alleviate each of several (12-14) problems, which the respondents were instructed to consider independently. Other respondents were asked to make a choice between two items from the same list. They were told that "It sometimes happens that budget constraints force a choice between two desirable projects. One has to be given up, at least for now, so that the other can go forward." The respondents were then asked which of the two interventions they would retain, if they had to make this choice.
Robust reversals of preference were obtained. On average, only 41% of the respondents who stated different WTP for the two items indicated greater willingness to pay for the public health problem.4 However, 66% of responses favored the public health issues in the choice condition. The difference between the two conditions was statistically significant separately for each of the seven pairs of items. A different pattern was observed in five other pairs of issues, in which the two issues were drawn from the same category. In these control pairs, the proportions favoring one issue over another were quite similar in choice and in SWTP.

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

221

4-4) The context dependence of valuations suggests three observations: (i) the hope of measuringpreferences by SWTP is unrealistic; (ii) a suitable choice of context may help improve the rationality ofelicited preferences; (iii) there is no general attitude order, but modeling context-dependent affective valuations is feasible in principle. The finding of preference reversals between SWTP and choice implies that willingness to pay does not provide a stable measure of the position of an object in a preference order-in our view, because there is no stable preference order to be measured. Like the scope problem that was discussed in the preceding section, the context dependence of SWTP is an unavoidable consequence of basic cognitive and evaluative processes. It is not a result of defective procedures, and it will not be eliminated by improved survey methods.
The reversals of valuation that we have observed in both SWTP and punitive damages raise a significant prescriptive question: When different methods for eliciting attitudes yield conflicting results, which method should be used? In general, of course, decisions that are based on a richer setof considerations and on a broader context are more likely to be stable and to satisfy standards of rationality. This principle suggests that asking people for choices may be better than asking them to consider issues in isolation. We have seen, for example, that the priority of public health over ecological concerns is effectively suppressed in the SWTP measure, and only becomes evident when respondents must compare items from the two categories. Similarly, the difference in the outrageousness of actions that cause physical or financial damage was suppressed when cases were considered in isolation, and only revealed by a direct comparison. The benefits of improved rationality are more likely to be achieved if the context of comparison is truly broad, and if it has been selected impartially. Mere exhortations to consider many possibilities (NOAA panel, 1993) are not likely to be effective.
Our findings provided further evidence for a simple negative conclusion: there is no comprehensive and coherent 'attitude order.' This is not a message of despair. The phrase "Individual I likesjdislikes to extent X the description D of object 0, considered in context C" is, at least in principle, subject to measurement, verification and modeling. We already know, for example, that different measures of liking will yield similar estimates of X, and that if two objects spontaneously evoke the same context C, measurements of their relative preference by liking and by choice will probably be consistent. Attitudes do not lack structure, but their structure is vastly more complex than the structure that economic analysis attributes to human preferences.

5. The psychophysics of valuation
The results of section 2 demonstrated that average dollar responses for large groups yield much the same ranking of attitude objects as do other measures of attitudes. To the proponents of contingent valuation or to the supporters of the jury system this is faint praise, because they need much more than a ranking of

222

KAHNEMAN, RITOV AND SCHKADE

objects. The goal of asking survey respondents to assess a public good or of asking jurors to assess punitive damages is to obtain a dollar value that is meaningful in absolute terms, not only in relation to other objects. Can this goal of absolute measurement be realized? In this section we draw on psychophysical research to examine the measurement properties of the dollar scale, and to compare it to other measures of affective valuation.
5-1) The attitude expressions elicited in surveys can be classified as category scales or magnitude scaks. These terms are borrowed from the field of psychophysics, the study of the functions that relate quantitative expressions of subjective reactions to physical variables. For example, the perceived loudness of tones that vary in amplitude can be measured on a bounded category scale (e.g., from 'not loud at all' to 'very very loud'). Loudness can also be measured on a magnitude scale by presenting the subject with a series of tones, with the instruction to assign a given number (known as the modulus) to a specified standard tone, and to assign numbers to other tones relative to this common modulus. The defining characteristics of a magnitude scale are that it is unbounded, has a meaningful zero, and expresses the ratios of the relevant underlying variable.
In terms of this classification of scales, the normal practice of survey research is to use category scales, such as numerical ratings on a bounded scale. However, attitudes can also be measured using magnitude scales (Lodge, 1981; Stevens, 1975). For example, Stevens (1975) reported judgments of the severity of crimes, and also of the severity of different legal punishments, using an unbounded magnitude scale.
5-2) Studies of magnitude scaling in the context of psychophysical measurement have yielded several generalizations, which apply as well to the domain of attitude measurement (Stevens, 1975). (i) There is a fair degree of agreement among observers on the ratios of the magnitudes that they assign to the sensations evoked by particular stimuli. (ii) In the absence of a designated common modulus, there are large individual differences in the mean values of judgments: some observers assign generally high numbers to all stimuli, others assign low numbers. (iii) The distribution of responses to any stimulus is positively skewed; a log-normal distribution often provides an adequate fit. (iv) The standard deviation of the judgments of different stimuli is approximately proportional to their means; this relationship holds both when the same individual judges each stimulus several times and when the judgments are contributed by different observers. In contrast, category scales are characterized by a negligible correlation between the mean and the standard deviation of judgments. (v) In general, magnitude judgments of sensory intensity are a power function of the relevant physical variable: for example, brightness is a power function of luminance and loudness is a power function of sound amplitude (both with an exponent of approximately 1/3). (vi) Magnitude scales are generally related by a power function to category scales of the same stimuli.

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

223

5-3) The elicitation of dollar responses is a special case of magnitude scaling without a modulus. The scale of dollars is unbounded and its zero is a meaningful response; the respondents (participants in CV surveys or jurors in civil cases) are not provided with a standard problem to which a specified dollar amount must be assigned (i.e., a modulus). The defining characteristics of scaling without a modulus are therefore satisfied. The results obtained with dollar scales are similar to the results that are observed with magnitude scales in psychophysical studies. In particular, the distribution of dollar responses is positively skewed, both within the responses of each individual and within the responses to any given problem. The distribution of the mean dollar judgments of individual respondents is also highly skewed. Finally, the high correlation between the mean and the standard deviation of individuals, which is expected for magnitude scales, was observed both by Kahneman and Ritov (1994; r = .93) and by Kahneman, Schkade and Sunstein (1998; r = .90).
5-4) As expected for an application of magnitude scaling without a common modulus, dollar responses are statistically less efficient than category scale measures of the same attitudes. We have seen that the averages of different attitude expressions in large samples yield similar rankings of objects (see Tables 1 and 2). However, dollar responses produce much lower signal-to-noise ratios than do rating scales. Tables 4 and 5 present results from separate analyses of variance for each of the response measures used in the two studies. The analysis partitions the variance of responses into three components: (i) Object (signal): the variance associated with differences among objects of judgments (e.g., public goods that differ in value, personal injury cases that vary in the outrageousness of the defendant's actions). (ii) Respondents: the variance associated with individual differences in the mean level of responses, over objects (e.g., some respondents state generally higher WTP than others, some experimental jurors are generally more severe than others). (iii) Noise: the residual variance, which combines the effects of individual differences in variability, idiosyncratic responses of some respondents to some objects or topics, and various sources of measurement error.
Tables 4 and 5 document a striking discrepancy in the strength of the signal (as indicated by the proportion of variance explained) between dollar measures and

Table 4. Proportion of variance explained by problems

Raw

Ranks

Support Importance Satisfaction SWTP

.08

.26

.16

.28

.12

.26

.04

.23

From Kahneman and Ritov, 1994.

224

KAHNEMAN, RITOV AND SCHKADE

Table 5. Proportion of variance explained by scenarios

Raw

Ranks

Outrage Punishment $Awards

.29

.42

.49

.58

.06

.51

From Kahneman, Schkade and Sunstein, 1998.

attitude expressions measured on standard bounded scales. The proportion of Object variance (i.e., signal) was 2 to 4 times larger for rating scales than for SWTP in Kahneman and Ritov (1994). The advantage of the rating scales was even more pronounced in responses to product liability cases, where the amount of Object variance was 5 to 8 times higher for ratings than for dollar responses (Kahneman, Schkade and Sunstein, 1998).
The low signaljnoise ratio of dollar awards implies poor agreement among individuals, and even among juries. Kahneman, Schkade and Sunstein (1998) used Monte Carlo techniques to assess the average rank-correlation between dollar awards across cases for simulated "juries" of size 12: the estimated reliability (.42) appears unacceptably low.5
5-5) Some transformations of dollar responses improve statistical efficiency, by reducing the effects of the skewness of magnitude scales and of the large individual differences in moduli. For example, logarithmic and rank transformations of each individual's dollar responses both yield substantial improvements of signaljnoise ratio. Transforming SWTP responses to a logarithmic scale doubled the percentage of Object variance (from 4% to 8%), to a level comparable to the other measures. Logarithmic transformation of punitive awards yielded even more dramatic improvement (Object variance increased from 6% to 42%). As shown in Tables 4 and 5, a ranking transformation also yielded a substantial increase in the relative amount of Object variance in both studies. The success of these transformations is due to the fact that the effect of individual differences in the use of the dollar scale is reduced by the logarithmic transformation and eliminated by the ranking transformation. The good performance of the transformed measures also demonstrates that the dollar response contains useful information about respondents' attitudes. If the objective of research is to rank order a set of objects, the dollar response-suitably transformed, and with a sufficiently large sample-provides as much information as other expressions of affective evaluation. Of course, the proponents of CV and of the current jury system hope for much more, since their goal is to obtain an exact dollar amount.
5-6) Individual differences in the use of the dollar scale are large, and may be arbitrary to a substantial extent. In psychophysical research, magnitude scaling without a common modulus yields large individual differences in the responses to stimuli, because subjects spontaneously adopt quite different moduli. If two subjects who

AN ANALYSIS OF DOllAR RESPONSES TO PUBLIC ISSUES

225

share the same underlying psychophysical function adopt different moduli, their responses to all stimuli will differ by a constant of proportionality, which is the ratio of their individual moduli.
In the psychophysical laboratory, differences in moduli are usually considered to be entirely arbitrary, a mere source of statistical noise. Except for very unusual circumstances (e.g., deafness), there is little reason to believe that an individual who consistently assigns low numbers to the loudness of tones actually experiences less loudness than an individual who assigns higher numbers. Are the moduli that CV respondents and jurors apply in assigning dollar responses also arbitrary? A positive answer to this question would remove the rationale for any procedure in which the absolute values that people state are taken seriously, including contingent valuation and the setting of monetary punishments by juries.
There are several ways of testing whether individual differences in the use of the dollar scale are meaningful or arbitrary. (i) Prediction of behavior. Several studies have examined the correlation between hypothetical responses to WfP questions and actual behavior (e.g., Cummings, Harrison and Rutstrom, 1995; Foster, Bateman and Harley, 1997; Seip and Strand, 1992). The data indicate a substantial upward bias in hypothetical responses. (ii) Search for co"elated variables. If the difference between high-SWTP and low-SWI'P respondents is real, it should be correlated with other characteristics of these individuals, such as income, or other indications of involvement in environmental issues. These correlations have been examined in some studies, and are usually low or nonexistent. Kahneman, Schkade and Sunstein (1998) also failed to find significant correlations between the average size of the awards set by individual respondents and several relevant predictors, including demographic attributes and individuals' ratings of the importance that they attached to different features of the cases, such as the degree of malice or the amount of harm suffered by the plaintiff. (iii) Susceptibility to anchoring. The large anchoring effects that we discuss in the next section indicate that dollar responses are very labile, both in CV surveys and in punitive awards. Arbitrary numbers that are mentioned in a question have considerable influence on responses-much as arbitrary moduli do.
We do not yet have the data needed to evaluate the relative size of the arbitrary and of the meaningful components in the variability of dollar responses. The available evidence, however, hardly justifies reliance on the absolute values of judgments denominated in dollars. There is at present no reason to believe that dollar responses contain useful information that cannot be obtained more simply and accurately by using other expressions of attitudes.

6. Anchoring effects
The procedure of asking people to state their maximal WTP for a good has been largely supplanted in CV practice by a protocol in which respondents are asked how they would vote in a hypothetical referendum that would guarantee the

226

KAHNEMAN, RITOV AND SCHKADE

provision of public good at a specified cost to the household. Different groups of respondents face different proposed payments, and the cumulative frequency distribution of positive responses is used to estimate the parameters of the underlying distribution of WTP. The estimates of WTP that are generated by this estimation technique are substantially higher than the estimates obtained by an open-ended question, such as "what is the maximum amount of payment for which you would still support the proposition?" (Desvousges et al., 1992; McFadden, 1994). The referendum format has been defended on grounds of its supposedly superior incentive compatibility (Hanemann, 1994; Hoehn and Randall, 1987). We do not directly debate this claim here (see Green et al., 1998). Following the broad strategy of this article, we show instead that the discrepancy between the two types of WTP questions can be parsimoniously explained by a well-understood process of anchoring, which produces similar effects in contexts to which the incentive compatibility idea does not apply.
6-1) Tasks in which respondents indicate a judgment or an attitude by producing a number are susceptible to an anchoring effect: the response is strongly biased toward any value, even if it is arbitrary, that the respondent is induced to consider as a candidate answer. Anchoring effects are among the most robust observations in the psychological literature. In a striking demonstration Wilson and his collaborators induced an anchoring effect by the following procedure: they required subjects to write the last four digits of their SSN, then to state whether they thought that the number of physicians and surgeons listed in the local yellow pages was higher or lower than that number. Finally, the subjects provided an open-ended estimate of the number of physicians and surgeons. The estimates that different subjects offered were strongly correlated with their social security number (Wilson et al., 1996). The necessary and apparently sufficient conditions for the emergence of anchoring effects are (i) the presence of some uncertainty about the correct or appropriate response, and (ii) a procedure that causes the individual to consider a number as a candidate answer. A vast literature has documented anchoring effects in estimation tasks (see, e.g., Strack and Mussweiler, 1997; Wilson et al., 1996), as well as in other settings, including negotiations (Ritov, 1996), and the setting of both compensatory (Chapman and Bomstein, 1996) and punitive awards (Hastie, Schkade and Payne, 1999).
Jacowitz and Kahneman (1995) proposed an index of the size of anchoring effects, which they applied to estimation tasks. They first obtained a distribution of answers to open-ended questions about quantities such as the length of the Amazon or the height of the tallest redwood, and observed the 15th and 85th percentiles of the estimates for each quantity. These values were used as anchors for two additional groups. Respondents in these anchored groups first answered a binary question such as "is the height of the tallest redwood more or less than X?", where the value of X was either the high or the low anchor for that problem. The anchoring index was defined as a ratio. The numerator is the difference between the median estimates of the anchored groups; the denominator is the

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

227

difference between the high and low anchors. By this measure, the anchoring effects were very large: the median anchoring index in a set of 20 problems was .49.
6-2) Anchors have a suggestive effect on the answers to binary questions. With scales bounded on one side (such as the dollar scale) this effect causes an upward bias in binary answers, relative to corresponding open-ended responses. In the context of CV surveys, this bias explains the discrepancy previously observed between estimates of WTP from referendum questions and from open-ended questions. The design employed by Jacowitz and Kahneman (1995) allows a comparison between two proportions: (i) the proportion of respondents in the original group (unanchored) who spontaneously offered an estimate higher than an anchor; (ii) the proportion of respondents in the anchored group who stated that the same anchor was lower than the true value of the quantity. In the absence of bias, the two proportions should be the same. However, the results showed a pronounced bias: on average, respondents in the anchored group judged the high anchor to be lower than the true value on 27% of occasions, very significantly more than the 15% expected from the responses of the unanchored group. Furthermore, there was a pronounced asymmetry in the bias: the low anchors were judged to be too high on only 14% of occasions. The asymmetry was due to the prevalence of estimation problems in which the range of possible answers is bounded by zero, e.g., the height of the tallest redwood. The result of this bias, of course, is that the estimates inferred from the binary question were generally much higher than the estimates obtained directly from open-ended questions. The discrepancy between the two response modes is similar to the discrepancy observed in CV research between estimates of WTP derived from open-ended and from referendum questions (Desvousges et al., 1992; McFadden, 1994).
The similarity between the effects of anchors on estimates of uncertain quantities and on SWTP were explored in a study reported by Green et al. (1998). Visitors at the San Francisco Exploratorium were recruited to answer five questions, including estimates of three quantities (height of the tallest redwood in California, average monthly gasoline used by car owners, annual rainfall in wettest spot on earth) and two WTP questions (save 50,000 off-shore seabirds each year from dying in oil spills, reduce auto accidents in California by 20%). The first and the last questions in each questionnaire were WTP questions. As in the JacowitzKahneman study, a calibration group provided open-ended answers to all five questions. Five anchored groups answered a binary question about each quantity before estimating it. The anchors used in the binary question were chosen to be at the percentiles 25, 50, 75, 90 and 95 of the distribution of open-ended responses.
As expected, comparison of the anchored open-ended responses to the responses of the unanchored groups revealed a large anchoring effect, in both estimation and WTP questions. For example, the mean estimate of the height of a tallest redwood ranged from 282 feet (with 180 ft as an anchor) to 844 ft (with an anchor of 1,200 ft). Similarly, mean SWTP to save 50,000 birds annually ranged from $20.30 (with a $5 anchor) to $143.12 (with a $400 anchor).

228

KAHNEMAN, RITOV AND SCHKADE

An anchoring effect was also observed in answers to binary questions, for both estimates and SWTP. On average, there were 4.3% of answers exceeding the highest anchor in the calibration group, but 21.6% of respondents in the anchoring condition judged the same anchor to be too low. The pattern for low anchors was quite different: 21.5% of unanchored answers were lower than the low anchor, but the same anchor was judged to be too high on only 15.8% of occasions. As in the earlier study, high anchors induced a much larger bias. As a consequence of this asymmetric anchoring effect, the cumulative distribution derived from binary questions stochastically dominated the distribution of open ended answers. Over the five questions, the average ratio of the mean of the distribution inferred from binary questions to the unanchored mean was 3.43 (2.97 for the three estimation questions, 4.13 for the two WTP questions).6
This study again illustrates the benefits of searching for parallel phenomena across domains. The psychological analysis reveals that the tasks of estimating positive quantities and of determining a willingness to pay are deeply similar to each other, in both their open-ended and binary versions. They yield similarly skewed distributions of responses, are susceptible to similarly asymmetric anchoring effects, and therefore produce the same discrepancy between the parameters estimated from open-ended and from binary questions. In light of these observations, an explanation of the discrepancy in estimates of WTP in terms of incentive compatibility has little appeal, because it cannot be applied to the identical finding in another task.

7. Applications
The central claim of this paper has been that people are better described as having attitudes than preferences-perhaps in every domain, but certainly in the domain of public concerns. In contrast, CVM is rooted in the assumption that conventional consumer theory applies to public goods, including non-use goods such as the continued existence of the whooping crane. At least in principle, the dollar value of such a good could be read off an individual's preference order. The assumption of an inclusive preference order appears to be widely shared among economists, including critics of CVM (e.g., Diamond and Hausman, 1994) and among rationalagent theorists in political science (see Bartels (1998) for a discussion). In this theoretical framework, the main question to be asked about contingent valuation is the accuracy of measurement that it provides.
The problem with CVM, in our view, is not imprecise measurement but an incorrect theory. If consumer theory does not capture the nature of people's value for environmental goods, there can be no more hope of measuring the economic value of the whooping crane than there is of measuring the physical properties of the ether. Of course, many people do value the whooping crane and will even pay to preserve it. We have described these people as having a positive affective

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

229

valuation of whooping cranes, which induces a positive attitude to interventions that will preserve this species. These valuations can be expressed in many ways, including statements of WTP, actual payments, and votes in both simulated and real referenda. Attitude objects can be ordered reliably by sample averages of diverse expressions of valuation, including SWTP. As we have seen, however, these valuations lack some of the essential properties that economic theory requires of preferences. In particular, expressions of affective valuation are susceptible to framing effects (Bartels, 1998; Zaller, 1992), inadequately sensitive to scope and severely context dependent. Moreover, dollar measures of valuation are especially susceptible to the effects of anchors and of arbitrary moduli.
The extreme context-dependence of attitudes undermines the most compelling rationale that has been offered for the contingent valuation method. As Hanemann (1994) pointed out, the referendum question presents the respondent with a realistic task of formulating a voting intention, and answers to such survey questions have often been found to predict voting outcomes with fair accuracy. However, the only permissible inference from this argument is that CVM results predict the outcome of a real referendum that precisely mimics the context and framing of the survey question (Payne, Bettman and Schkade, 1999). The results do not provide reliable information about the voting outcomes that would be obtained with different wording of the question, or if the target proposition were embedded in a particular list of propositions. The evidence that SWTP diminishes steadily when several causes are considered in sequence (Carson and Mitchell, 1995; Payne et al., 1999) is another illustration of context dependence and another demonstration that CVM results are not sufficiently robust to provide a basis for policy.
Our pessimism about the validity of CVM does not imply despair about the possibility of using public attitudes as an aid to policy making. The affective value that people attach to issues probably conveys useful information about their possible reactions to policy proposals or to actual outcomes. More formal approaches to the elicitation of priorities are also possible, if they are developed with adequate respect for the psychology of valuation. For example, a scale of value for environmental damage could be developed by constructing a small set of hypothetical benchmark scenarios, covering a broad range of damage magnitude and commodity importance. Two criteria for including scenarios in the scale would be: (i) high consensus in the attitudes of the public to the scenario; and (ii) a hope of achieving professional and political consensus on appropriate dollar values. Public attitudes would be one input into this process, but probably not the only one. We expect that experts would bring in relevant considerations that lay judgment is prone to neglect, such as the scope and duration of the damage. The objective of the scaling effort would be to provide a mapping from attitudes and other relevant factors to dollar values for a particular class of environmental commodities.
Once a scale is established, a real issue that arises could be valued by survey in which respondents would explicitly compare the current problem to the benchmark scenarios. The measures of attitude used in this comparison would be chosen by

230

KAHNEMAN, RITOV AND SCHKADE

psychometric criteria: measures of judged importance and political support would probably be preferred to SWTP. A dollar value would be assigned based on the rank of the target issue among the benchmark scenarios of the standard scale. One advantage of this proposal is that the difficult conceptual problems of anchoring the dollar value of public goods in the preferences and opinions of the citizenry would be addressed just once, in the process of constructing the initial scale linking monetary value to attitude. Clearly, professional and political consensus is more likely to be achieved in dealing with hypothetical questions constructed for this purpose than in evaluating real goods in the context of litigation. Rutherford, Knetsch and Brown (1998) make a similar argument and propose that damage schedules be developed to replace ad hoc valuation based on SWTP responses.
The other domain that we have discussed, the setting of punitive damages, is a descendant of an old tradition which requires a small group of citizens to express their attitudes in dollars. It is remarkable that the jury system appears designed to enhance rather than minimize the deficiencies of human judgment: juries are instructed to consider cases one at a time, using a dollar measure without a modulus. Not surprisingly, dollar awards are erratic, in spite of a high level of agreement on ratings of outrage and punitive intent. Sunstein, Kahneman and Schkade (1998) provide a detailed analysis of possible reforms of the jury's task, which would require jurors to do what they can do well, not what they can do poorly. The determination of what jurors can do well combines normative evaluations with empirical facts. For example, if a normative analysis concludes that juror's intuitions about appropriate severity of punishment are valid, but their ability to translate these intuitions into dollars is weak-a plausible conclusion in view of the data reported here-the system could be reformed by requiring jurors to provide graded verbal statements of the severity of punishment that they consider just, leaving to the judge the task of translating this intent into a dollar amount.
Taken together, the examples of CV and punitive damages show that the debate about the nature of preferences and about the rationality of agents is not merely theoretical. The procedures that lead to some significant societal decisions may take different forms, depending on whether the decisions of individual citizens are best understood as a reflection of attitudes or of standard economic preferences.

8. Concluding remarks
The stereotyped role of the psychologist in the inter-disciplinary conversation about the nature of human choice is that of a critic, engaged in the construction of counter-examples to the economist's rational models. We have attempted to expand this role here, by focusing on the power and generality of psychological principles, rather than on the limitations of rational choice theory. Our theme has been that phenomena that appear anomalous from the perspective of standard preference models are in fact predictable-indeed, inevitable-consequences of well-established rules of judgment and valuation, which apply in domains that are

AN ANALYSIS OF DOLlAR RESPONSES TO PUBLIC ISSUES

231

beyond the reach of choice theory. The alternative to rational choice as a descriptive model is neither chaos nor an endless list of ad hoc claims. It is a manageable set of concepts and testable propositions, which often predict surprising parallels between ostensibly different behaviors in different domains.
The evidence that we have discussed in this article was restricted to hypothetical questions. However, the progression of ideas from the explanation of hypothetical questions to the understanding of economically consequential behavior has an encouraging history, albeit a brief one (much of it is collected in Thaler, 1992). An example is the notion of loss aversion (Tversky and Kahneman, 1991), which was originally formulated in the context of hypothetical choices between gambles, further developed in market experiments with real stakes, and eventually extended to significant economic phenomena. The idea that some actions are expressions of affective valuations is, in our view, a candidate for a similar trajectory.

Acknowledgments
The U.S.-Israel Binational Science Foundation, the National Science Foundation and the Environmental Protection Agency provided support for the preparation of this article. Shelley Chaiken, Jack Knetsch, Kristine Kuhn and Barbara Mellers provided valuable comments.

Notes
1. The terms 'valuation' and 'affective value' are not standard in the attitude literature, but the position we take is widely shared.
2. Within-subject correlations were computed in the study of Payne et a!. (1999) and they were quite high: the median correlation between rating scales was .69, and the median correlation between rating scales and individual SWTP was .51. The lower value of the correlations with SWTP is due to the high degree of noise in dollar responses (see section 5).
3. In the currently most popular variant of CVM, known as the referendum format, respondents are not required to state their maximal SWTP, but only to answer a yes-no question about their willingness to pay a specified amount. The distribution of SWTP is then inferred from the responses to various amounts. We discuss the referendum method in section 6.
4. SWTP was the same for the two issues in about 40% of the cases-most often because both responses were zero.
5. The higher value shown in Table 2 (.89) was obtained with "juries" of 107 members. 6. These results are based on a parametric estimation procedure described in detail by Green et a!.
(1998). A non-parametric estimation procedure yielded similar ratios: 2.14 for uncertain quantities, 2.22 for SWTP.

References
Anderson, Norman. (1996). A Functional Theory of Cognition. Mahwah, NJ: Erlbaum. Arrow, Kenneth. (1982). "Risk Perception in Psychology and Economics," Economic Inquiry 20, 1-9.

232

KAHNEMAN, RITOV AND SCHKADE

Baron, Jonathan and Joshua Greene. (1996). "Determinants of Insensitivity to Quantity in Valuation of Public Goods: Contribution, Warm Glow, Budget Constraints, Availability, and Prominence," Journal of Experimental Psychology: Applied 2, 107-125.
Barsalou, Lawrence. (1992). Cognitive Psychology: An Overoiew for Cognitive Scientists. NJ: Erlbaum. Bartels, Larry M. (1998). "Democracy With Attitudes," Paper presented at the annual meeting of
American Political Science Association, Boston. Carson, Richard, Michael Hanemann, Raymond Kopp, John Krosnick, Robert Mitchell, Stanley Presser,
Paul Ruud, and V. Kerry Smith. (1994). Prospective Interim Lost Use Value Due to DDT and PCB Contamination in the Southern California Bight. La Jolla, CA: Natural Resource Damage Assessment. Carson, Richard and Robert Mitchell. (1993). "The Issue of Scope in Contingent Valuation Studies," American Journal ofAgricultural Economics 75, 1263-1267. Carson, Richard and Robert Mitchell. (1995). "Sequencing and Nesting in Contingent Valuation Surveys," Journal of Environmental Economics and Management 28, 155-173. Chapman, Gretchen, and Brian Bornstein. (1996). "The More You Ask for the More You Get: Anchoring in Personal Injury Verdicts," Applied Cognitive Psychology 10, 519-540. Cummings, Ronald, Glenn Harrison, and Elizabeth Rutstrom. (1995). "Homegrown Values and Hypothetical Surveys: Is the Dichotomous Choice Approach Incentive-Compatible?" American Economic Review 85, 260-266. DeKay, Michael and Gary McClelland. (1996). "Probability and Utility Components of Endangered Species Preservation Programs," Journal of Experimental Psychology: Applied 2, 60-83. Desvousges, William, F. Reed Johnson, Richard Dunford, Kevin Boyle, Sarah Hudson, and K. Nicole Wilson. (1992). Measuring Non-Use Damages Using Contingent Valuation: An Experimental Evaluation ofAccuracy. Research Triangle Institute Monograph 92-1. Diamond, Peter. (1996). "Testing the Internal Consistency of Contingent Valuation Surveys." Journal of Environmental Economics and Management 30, 337-347. Diamond, Peter, John Hausman, Gregory Leonard, and Michael Denning. (1993). "Does Contingent Valuation Measure Preferences? Experimental Evidence." In J. A. Hausman (ed.), Contingent Valuation: A Critical Assessment. Amsterdam: North-Holland. Diamond, Peter and John Hausman. (1994). "Contingent Valuation: Is Some Number Better Than No Number?" Journal of Economic Perspectives 8, 45-64. Eagly, Alice and Shelley Chaiken. (1993). The Psychology ofAttitudes. Fort Worth, TX: Harcourt Brace. Eagly, Alice and Shelley Chaiken. (1996). "Attitude Structure and Function." In Gilbert, D., S. Fiske, and G. Lindzey (eds.), The Handbook of Social Psychology, 4th ed. New York: McGraw-Hill. Fazio, Russell, David Sanbonmatsu, Martha Powell, and Frank Kardes. (1986). "On the Automatic Activation of Attitudes." Journal of Personality and Social Psychology 50, 229-238. Fischhoff, Baruch. (1991). "Value Elicitation: Is There Anything in There?" American Psychologist 46, 835-847. Foster, Vivien, Ian J. Bateman, and David Harley. (1997). "Real and Hypothetical Willingness to Pay for Environmental Preservation: A Non-Experimental Comparison," Journal of Agricultural Economics 48, 123-138. Frederick, Shane and Baruch Fischhoff. (1998). "Scope (ln)Sensitivity in Elicited Valuations," Risk Decision and Policy 3, 109-123. Green, Donald, Karen Jacowitz, Daniel Kahneman, and Daniel McFadden. (1998). "Referendum Contingent Valuation, Anchoring, and Willingness to Pay for Public Goods." Resource and Energy Economics 20, 85-116. Griffin, Dale and Amos Tversky. (1992). "The Weighing of Evidence and the Determinants of Confidence," Cognitive Psychology 24, 411-435. Hanemann, Michael. (1994). "Valuing the Environment Through Contingent Valuation," Journal of Economic Perspectives 8, 19-43. Hastie, Reid, David Schkade, and John Payne. (1999). "Juror Judgments in Civil Cases: Effects of Plaintiffs Request and Plaintiffs Identity on Punitive Damage Awards." Law and Human Behavior 23, 445-470.

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

233

Hoehn, John and Alan Randall. (1987). "Too Many Proposals Pass the Benefit Cost Test," American Economic Review 79, 544-551.
Hsee, Chris. (1996). "The Evaluability Principle: An Explanation for Preference Reversals between Joint and Separate Evaluations of Alternatives," Organizational Behavior and Human Decision Processes 67, 247-257.
Jacowitz, Karen and Daniel Kahneman. (1995). "Measures of Anchoring in Estimation Tasks," Personality and Social Psychology Bulletin 21, 1161-1166.
Jones-Lee, Michael, Graham Loomes, and P. Philips. (1995). "Valuing the Prevention of Non-Fatal Road Injuries: Contingent Valuation vs. Standard Gambles," Oxford Economic Papers 47, 676-695.
Kahneman, Daniel. (1986). "Valuing Environmental Goods: An Assessment of the Contingent Valuation Method." In R. Cummings, D. Brookshire, and W. Schulze (eds.), Valuing Environmental Goods: An Assessment of the Contingent Valuation Method. Totowa, NJ.
Kahneman, Daniel. (1995). "Extension Neglect and Violations of Monotonicity in Judgment and Preference: Three Examples," Bartlett Lecture to the Experimental Psychology Society (UK).
Kahneman, Daniel, Barbara Fredrickson, Charles Schreiber, and Don Redelmeier. (1993). "When More Pain Is Preferred to Less," Psychological Science 4, 401-405.
Kahneman, Daniel and Jack Knetsch. (1992). "Valuing Public Goods: The Purchase of Moral Satisfaction," Journal of Environmental Economics and Management 22, 57-70.
Kahneman, Daniel, Jack Knetsch, and Richard Thaler. (1991). "The Endowment Effect, Loss Aversion, and Status Quo Bias," Journal of Economic Perspectives, 5, 193-206.
Kahneman, Daniel and Dale Miller. (1986). "Norm Theory: Comparing Reality to Its Alternatives," Psychological Review 93, 136-153.
Kahneman, Daniel and Ilana Ritov. (1994). "Determinants of Stated Willingness to Pay for Public Goods: A Study in the Headline Method," Journal of Risk and Uncertainty 9, 5-38.
Kahneman, Daniel, David Schkade, Elana Ritov and Cass Sunstein. (1999). "Reversals of judgement;
The effect of cross-category comparisons intendedly absolute scales," manuscript order review. Kahneman, Daniel, David Schkade, and Cass Sunstein. (1998). "Shared Outrage and Erratic Awards:
The Psychology of Punitive Damages," Journal of Risk and Uncertainty 16, 49-86. Kahneman, Daniel and Amos Tversky. (1972). "Subjective Probability: A Judgment of Representative-
ness." Cognitive Psychology 3, 430-454. Kahneman, Daniel and Amos Tversky. (1973). "On the Psychology of Prediction." Psychological Review
80, 237-254. Kahneman, Daniel and Amos Tversky. (1979). "Prospect Theory: An Analysis of Decision under Risk,"
Econometrica 47, 263-291. Kahneman, Daniel, Peter Wakker, and Rakesh Sarin. (1997). "Back to Bentham? Explorations of
Experienced Utility," Quarterly Journal of Economics 112, 375-405. Kemp, Michael and Christopher Maxwell. (1993). "Exploring a Budget Context for Contingent Valua-
tion." In Hausman (ed.), Contingent Valuation: A Critical Assessment. Amsterdam: North-Holland. Koehler, Jonathan. (1996). "The Base-Rate Fallacy Reconsidered: Descriptive, Normative, and Method-
ological Challenges." Behavioral and Brain Sciences 19, 1-53. Levav, Jonathan. (1996). "Questioning Contingent Valuation: Maximality and Violations of Monotonic-
ity in Willingness-to-Pay for Public Goods," Unpublished undergraduate thesis, Princeton University. Lodge, Milton. (1981). "Magnitude Scaling: Quantitative Measurement of Opinions." In J. Sullivan
(ed.), Quantitative Applications in the Social Sciences, Vol. 25. Beverly Hills, CA: Sage Publications. Loomis, John, Armando Gonzalez-Caban, and Robin Gregory. (1994). "Do Reminders of Substitutes
and Budget Constraints Influence Contingent Valuation Estimates?" Land Economics 70, 499-506. McFadden, Daniel. (1994). "Contingent Valuation and Social Choice," American Journal ofAgricultural
Economics 76, 689-708. McFadden, Daniel. (1999). "Rationality for Economists," Journal of Risk and Uncertainty 19, 73-106. McFadden, Daniel and Gregory Leonard. (1993). "Issues in the Contingent Valuation of Environmental
Goods: Methodologies for Data Collection and Analysis." In Hausman (ed.), Contingent Valuation: A Critical Assessment. Amsterdam: North-Holland.

234

KAHNEMAN, RITOV AND SCHKADE

Mitchell, Robert and Richard Carson. (1989). Using Surveys to Value Public Goods. Washington, DC: Resources for the Future.
Neill, Helen. (1995). "The Context for Substitutes in CVM Studies: Some Empirical Observations," Journal of Environmental Economics and Management 29, 393-397.
Nickerson, Carol. (1995). "Does Willingness-to-Pay Reflect the Purchase of Moral Satisfaction? A Reconsideration of Kahneman and Knetsch," Journal of Environmental Economics and Management 28, 126-133.
NOAA panel report. U.S. Department of Commerce, National Oceanic and Atmospheric Administration. (1993). "Natural Resource Damage Assessments under the Oil Pollution Act of 1990," Federal Register 58, 4601-4614.
Novemsky, Nathan and Shirit Kronzon. (1999). "How Are Base-Rates Used, When They Are Used: A Comparison of Bayesian and Additive Models of Base-Rate Use," Journal of Behavioral Decision Making 12, 55-69.
Osgood, Charles, George Suci, and Percy Tannenbaum. (1957). The Measurement of Meaning. Urbana: University of Illinois Press.
Payne, John, James Bettman, and Eric Johnson. (1992). "Behavioral Decision Research: A Constructive Processing Perspective." Annual Review of Psychology 43, 87-131.
Payne, John W., James R. Bettman, and David A Schkade. (1999). "Measuring Constructed Preferences: Towards a Building Code." Journal of Risk and Uncertainty 19, 243-270.
Payne, John, David Schkade, William Desvousges, and Chris Aultman. (1999). "Valuation of Multiple Environmental Programs: A Psychological Analysis," Unpublished manuscript, Duke University.
Pratto, F. (1994). "Consciousness and Automatic Evaluation." In Paula M. Niedenthal and Shinobu Kitayama (Eds.), The Heart's Eye: Emotional Influences in Perception and Attention. Academic Press, Inc, San Diego, CA.
Quattrone, George and Amos Tversky. (1984). "Causal Versus Diagnostic Contingencies: On Self-Deception and the Voter's Illusion," Journal of Personality and Social Psychology 46, 237-248.
Randall, Alan and John Hoehn. (1996). "Embedding in Market Demand Systems," Journal of Environmental Economics and Management 30, 369-380.
Ritov, Ilana, Jonathan Baron, and John Hershey. (1993). "Framing Effects in the Evaluation of Multiple Risk Reduction," Journal of Risk and Uncertainty 6, 145-159.
Ritov, Ilana. (1996). "Anchoring in a Simulated Competitive Market Negotiation," Organizational Behavior and Human Decision Processes 67, 16-25.
Rosch, Eleanor and Barbara Lloyd. (1978). Cognition and Categorization. Hillsdale, NJ: Erlbaum. Rottenstreich, Yuval and Amos Tversky. (1997). "Unpacking, Repacking, and Anchoring: Advances in
Support Theory," Psychological Review, 104, 406-415. Rutherford, Murray, Jack Knetsch, and Thomas Brown. (1998). "Assessing Environmental Losses:
Judgments of Importance and Damage Schedules," Harvard Environmental Law Review, 22, 51-101. Schreiber, Charles and Daniel Kahneman. (2000). "Beyond the Peak and End Hypothesis: Exploring
the Relation between Real-Time Pleasure and Retrospective Evaluations," Journal of Experimental Psychology. Seip, Kalle and Jon Strand. (1992). "Willingness to Pay for Environmental Goods in Norway: A Contingent Valuation Study with Real Payment," Environmental and Resource Economics 2, 91-106. Slovic, Paul. (1995). "The Construction of Preference," American Psychologist, 50, 364-371. Smith, V. Kerry. (1992). "Arbitrary Values, Good Causes, and Premature Verdicts," Journal of Environmental Economics and Management 22, 71-89. Strack, Fritz and Thomas Mussweiler. (1997). "Explaining the Enigmatic AnchoringEffect: Mechanisms of Selective Accessibility," Journal of Personality and Social Psychology 73, 437-446. Stevens, Stanley S. (1975). Psychophysics. Introduction to Its Perceptual, Neural, and Social Prospects. Wiley: NY. Sunstein, Cass, Daniel Kahneman, and David Schkade. (1998). "Assessing Punitive Damages," Yale Law Journal 107, 2071-2153.

AN ANALYSIS OF DOLLAR RESPONSES TO PUBLIC ISSUES

235

Tesser, Abraham and Leonard Martin. (1996). "The Psychology of Evaluation." In E. T. Higgins, and A. Kruglanski (eds.), Social Psychology: Handbook of Basic Principles, pp. 400-432. New York: Guilford Press.
Thaler, Richard. (1992). The Winner's Curse: Paradoxes and Anomalies ofEconomic Life. New York: The Free Press.
Tversky, Amos and Daniel Kahneman. (1971). "Belief in the Law of Small Numbers," Psychological Bulletin 76, 105-110.
Tversky, Amos and Daniel Kahneman. (1982). "Evidential Impact of Base Rates." In D. Kahneman, P. Slovic, and A. Tversky (eds.), Judgment under Uncertainty: Heuristics and Biases. New York: Cambridge University Press.
Tversky, Amos and Daniel Kahneman. (1983). "Extensional vs. Intuitive Reasoning: The Conjunction Fallacy in Probability Judgment," Psychological Review 90, 293-315.
Tversky, Amos and Daniel Kahneman. (1986). "Rational Choice and the Framing of Decisions," Journal of Business 59, 251-278.
Tversky, Amos and Richard Thaler. (1992). "Preference Reversals." In R. H. Thaler (ed.), The Winner's Curse: Paradoxes of Economic Life. New York: The Free Press.
Varey, Carol and Daniel Kahneman. (1992). "Experiences Extended Across Time: Evaluation of Moments and Episodes," Journal of Behavioral Decision Making 5, 169-185.
Varian, Hal. (1984). Microeconomic Analysis. New York: Norton. Wilson, Thomas, Christopher Houston, Kathryn Etling, and Nancy Brekke. (1996). "A New Look at
Anchoring Effects: Basic Anchoring and Its Antecedents," Journal of Experimental Psychology: General125, 387-402. Zaller, John. (1992). The Nature and Origins of Mass Opinion. Cambridge, UK: Cambridge University Press.

Journal of Risk and Uncertainty, 19:1-3; 237-239 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.
Commentary on "Economic Preferences or Attitude Expressions?: An Analysis of Dollar Responses to Public Issues" by Kahneman, Ritov and Schkade
STEVEN J. SHERMAN Indiana University, Department of Psychology, 1011 E. lOth St., Bloomington, IN 47405-7007
Attitude has been the central construct for social psychology over the past 60 years. During this time, this construct has been conceived of in many different ways, measured by a variety of techniques, and used for a number of different purposes. Attitudes have been conceived as implicit responses (Doob, 1947), as the outcomes of both classical (Staats and Staats, 1958) and operant conditioning (Insko, 1965), and as the result of logical reasoning (Ajzen and Fishbein, 1973). Most recently, attitudes have been conceived as having implicit (Fazio, et al., 1995; Greenwald, McGhee, and Schwartz, 1998) as well as explicit form, with perhaps little correspondence between the two. Attitudes have been measured by traditional paper and pencil scales, by physiological techniques, and by behavioroid techniques. And the attitudes measured in these ways have been employed to predict a wide variety of judgments, preferences, and behaviors.
The current paper uses the attitude construct in yet another way-to better understand the responses that are given in contingent valuation surveys and in the assignment of punitive damages in civil trials. By viewing these responses as expressions of attitudes rather than as indicators of economic preferences, the authors have been able to understand violations of the rational model of preference and yet give a plausible account for the regularities of responses. In this view, attitudes are dominated by the valuation of prototypes and are subject to extension neglect, preference reversals, and anchoring. Most important, the paper goes beyond the usual "bashing" of economic theory by demonstrating irrationalities of judgment, and instead provides a clear and compelling framework for understanding the responses under consideration.
Perhaps the linchpin of the framework is the notion that the objects of attitudes are mental representations rather than objective realities. This means that attitudes are subject to framing effects, that they are context-dependent concepts. In my terms, this simply means that attitudes are floppy. And floppiness is an extremely important feature of social psychological constructs. For years, it was assumed that there was a core self-concept that guided responses independently of context, motivation, or goals. A more flexible or floppy view of the self has

238

SHERMAN

produced a far better understanding. Similarly in the area of attitudes. It was once assumed that people had stable attitudes toward objects, and that these attitudes guided responses in a consistent way. Attitudes proved to be far more floppy, as their expression depended on even subtle changes in contexts (Bern, 1967; Salancik and Conway, 1975). More recently, it was assumed that such floppiness was true only of explicit measures of attitudes. If good implicit measures could be developed (based, for example, on latency of response), we could get at these core and stable attitudes. Yet work in our own laboratory (Sherman, Presson, and Chassin, 1998) has demonstrated that even implicit measures exhibit a good deal of floppiness. For example, we find that the implicit attitudes of smokers toward cigarettes depend very much on their state of nicotine deprivation and the specific context in which the cigarettes are embedded. Importantly, and as pointed out by the authors, these context effects are not simply rating scale effects. Rather, the context is assumed to change the underlying perception of and emotion attached to the object in question.
Thus, I stand in agreement with the authors that only a floppy concept, such as that of attitude, as opposed to a rigid and fixed concept such as economic preference, can adequately account for the responses of people to CVSs, to the setting of punitive damages, and to a myriad of other economically relevant judgments. The gains to be achieved through viewing people as having attitudes rather than economic preferences are many. And yet, the authors must be very careful in the strength of their conclusions. As was made clear, the primary evidence used for the arguments came from responses to hypothetical questions. The relationship between these kinds of responses and real-world, on-line behaviors may not be so strong. What people say they will do, believe they will do, and predict they will do is often a far cry from what they do when an actual situation is at hand (Johnson and Sherman, 1990). It is only when these kinds of data are available that we shall truly be able to judge the potential of the current approach.

References
Ajzen, leek and Martin Fishbein. (1973). "Attitudinal and Normative Variables as Predictors of Specific Behaviors," Journal of Personality and Social Psychology 27, 41-57.
Bern, Daryl J. (1967). "Self-Perception: An Alternative Interpretation of Cognitive Dissonance Phenomena," Psychological Review 54, 135-156.
Fazio, Russell H., Joni R. Jackson, Bridget C. Dunton, and Carol J. Williams. (1995). "Variability in Automatic Activation as an Unobtrusive Measure of Racial Attitudes: A Bona Fide Pipeline?" Journal of Personality and Social Psychology 69, 1013-1027.
Greenwald, Anthony G., Debbie E. McGhee, and Jordan L. K. Schwartz. (1998). "Measuring Individual Differences in Implicit Cognition: The Implicit Association Test," Journal of Personality and Social Psychology 74, 1464-1480.
Insko, Chester A. (1965). "Verbal Reinforcement of Attitude," Journal of Personality and Social Psychology 2, 621-623.

COMMENTARY

239

Johnson, Marcia K. and Steven J. Sherman. (1990). "Constructing and Reconstructing the Past and the Future in the Present." In E. Tory Higgins and Richard M. Sorrentino (eds.), Handbook of Motivation and Cognition. New York: Guilford Press.
Salancik, Gerald R. and Mary Conway. (1975). "Attitude Inferences from Salient and Relevant Cognitive Content about Behavior," Journal of Personality and Social Psychology 32, 829-840.
Sherman, Steven J., Clark C. Presson and Laurie Chassin. (1998). "Implicit and Explicit Attitudes toward Cigarette Smoking," Paper presented at the European Association of Experimental Social Psychology, Mirano, Italy.
Staats, Arthur W., and Carolyn K. Staats. (1958). "Attitudes Established by Classical Conditioning," Journal ofAbnormal and Social Psychology 57, 37-40.

Journal of Risk and Uncertainty, 19:1-3; 241-242 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Commentary on "Economic Preferences or Attitude Expressions: An Analysis of Dollar Responses to Public Issues" by Kahneman et al.

HAL R. VARIAN

hal@sims.berkeley.edu

School of Information & Management and Systems, 102 South Hall #4600, University of California, Berkeley, California 94720-4600

Talk is cheap and economics is concerned with scarcity. Perhaps this is why economists have little faith in concepts like "stated willingness to pay." If there are some who hold that there may yet be some residual meaning to such a concept, the paper by Kahneman et a!. should set them straight.
However, the authors do not limit themselves to demolishing the meaning of stated willingness to pay, but also suggest that the underlying concept of willingness to pay is not itself valid. "If consumer theory does not capture the nature of people's value for environmental goods, there can be no more hope of measuring the value of the whooping crane than there is of measuring the physical properties of the ether." Or, elsewhere: "The results of the research that we have reviewed in this section suggest that willingness to pay does not provide a stable measure of the position of an object in a preference order-in our view because there is no stable preference order to be measured." Here I would part company with them.
Consumer theory is, certainly, an idealization. We can't expect that it holds exactly, especially for exotic choices like saving whooping cranes. A theory that may work reasonably well in describing the demand for tomatoes at the supermarket may easily be inadequate for hypothetical choices over public goods. In the supermarket, we rarely have to agonize over our "exact" willingness to pay, we only have to make the binary decision as to whether a tomato is worth the price. Watch someone at the market hesitate before their purchase, examine the tomato closely, and pick it up and put it back-there is someone who is determining their willingness to pay. If a simple choice of buying a tomato can involve that much apparent effort, think how much effort must be involved in a serious determination of the value of a whooping crane! There is little incentive to invest in that effort for a hypothetical choice.
Nevertheless, I agree with Kahneman et a!. when they say that "asking people for choices may be better than asking them to consider issues in isolation." Indeed, the most standard interpretation of the economist's claim that "A is preferred to B" by some consumer is that the consumer would choose A if offered a single choice out of the set (A, B). The closer that the experimental design can come to a binary choice, the better chance the theory has of making sense.

242

VARIAN

The advantage of a pure binary choice experiment is that is forces a choice to be made, just like the choice of buying or not buying the tomato. Ultimately, society must make choices about how many tomatoes to produce and how many whooping cranes to save. If consumer preferences are to be of any use at all in making such decisions, the experimental design should look as much as possible like the actual choice the consumer or society is confronting.

Journal of Risk and Uncertainty, 19:1-3; 243-270 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.
Measuring Constructed Preferences: Towards a Building Code
JOHN W. PAYNE JAMES R. BETIMAN Fuqua School of Business, Duke University, Box 90120, Durham, NC 27708-0120
DAVID A. SCHKADE Department of Management, University of Texas, Austin, TX 78712-1174
Abstract
A "building code" for preference measurement is needed in a world in which many expressions of preference are constructed when people are asked a valuation question. Construction of preferences means that preference measurement is best viewed as architecture (building a set of values) rather than as archaeology (uncovering existing values). We describe potential faults in the process of preference construction, offer guidelines for measuring constructed preferences (a "building code") to mitigate these faults, and discuss how the code must be sensitive to the purpose of the valuation (design vs. prediction).
Key words: constructive preferences, value measurement, decision aiding
JEL Classification: D80
Introduction
Imagine that you are a member of a management team at the Environmental Protection Agency (EPA) charged with allocating scarce resources to alternative environmental management interventions. As part of your efforts, you need to establish the value of potential natural resource benefits achieved from different proposed interventions. To help in that valuation exercise you seek information about public values for different levels of these natural resources; obtaining citizen inputs is a natural extension of the principles of democratic governance (see Gregory et al. (1997) for a discussion of this position). One method that you consider for getting such information about public values is to conduct a contingent valuation (CV) study of peoples' preferences for different levels of an environmental resource (for a general review of CV studies, see Mitchell and Carson, 1989). Those expressions of preferences will be used as inputs to design and select among alternative environmental management interventions.

244

PAYNE, BETTMAN AND SCHKADE

Alternatively, imagine that you are the marketing manager for a new product and have been asked to generate a prediction regarding the likely sales of that product. The need to make such predictions is becoming both more important and more difficult because of rapid changes in technology and shortened product lives. You consider asking a sample of consumers to express their preference for your product in comparison to other competitor products that are, or might be, in the marketplace. Those expressions of preference will be used to predict future sales of your product.
How the EPA administrator or market manager approaches the measurement of preferences depends on the assumptions made about those preferences. One common viewpoint is that well-defined preferences exist for most objects, and therefore the task is to uncover (reveal) those preferences. Gregory, Lichtenstein, and Slavic (1993) have likened this task to an archaeological project, i.e., uncovering values that may be hidden but are assumed to exist. An alternative viewpoint is that preferences are generally constructed-not revealed-at the time a valuation question is asked. The measurement of constructive preferences is then more like a form of architecture, i.e., building a sturdy and "defensible" value or set of values, than archaeology (Gregory et al., 1993).1 We argue below that a constructive view of preference expression requires a fundamentally different approach to the measurement of preferences than that implied by the view of preference expression as revealing well-defined values. That is, it matters greatly whether preference measurement is seen as a form of archaeology, uncovering values that are already there, or as a form of architecture, building some defensible set of values.
We believe that enough knowledge has been gained about decision processes to begin to develop a set of guidelines (a "building code") for measuring constructed preferences. These building code guidelines should help avoid (or at least mitigate) some of the common faults that can occur in preference construction. In illustrating the development of such a code, we consider both the nature of the information that might be provided to the decision maker (the construction materials) and useful tools for thinking (the construction procedures). We also consider how these "building code" guidelines should vary depending upon whether the purpose of the exercise is to guide (design) future decisions (e.g., the EPA manager's task) or is to predict individuals' future responses (e.g., the marketing manager's task).
The remainder of this paper is organized as follows. First, we briefly discuss the two perspectives on preferences. Then we consider how to define a well-constructed preference and principles for good preference construction. Next we discuss the stages of constructing a preference, outline the types of "faults" that are likely to occur in each stage, and provide guidelines for measuring constructed preferences that seek to mitigate these common faults at each stage. We initially focus on design tasks and then consider prediction situations. Finally, we discuss when our suggested remedies are most likely to be needed and provide some words of caution about developing a "building code" for measuring constructed preferences.

TOWARDS A BUILDING CODE

245

1. Expressions of preference
1.1. Stable, coherent, and known preferences
Although it is clear that economists vary in terms of the degree to which they believe well-defined preferences exist (McFadden, 1999), a common assumption in economics is that "each individual has stable and coherent preferences" (Rabin, 1998, p. 11). In addition, it is often assumed that "people know their preferences" (Freeman, 1993, p. 7), that they have the ability or skill in computation to identify (calculate) the option that maximizes received value, and that they will choose accordingly.
Under such assumptions, the task involved in a valuation exercise is to uncover (reveal) these well-defined, pre-existing preferences. However, there can be great difficulties in uncovering even such pre-existing values. For example, a key problem is to be sure that the good to be valued has been defined properly, so that the "right" preferences are being uncovered. Mitchell and Carson (1989) provide an impressive list of the potential biases that may result when the respondent in a valuation study views the good in a way that was not intended by the researcher (sometimes called the problem of "scenario misspecification"). The researcher must also attempt to design the valuation study so that the respondent is motivated to research his or her preferences and respond truthfully (i.e., not strategically misrepresent his or her preferences).
This approach to preference measurement, which assumes a decision maker with existing, well-defined preferences, has contributed greatly to the prediction and understanding of decisions. However, an increasing number of researchers believe that the assumption of well-articulated preferences is tenable only when people are familiar and experienced with the preference object, and that an alternative, constructive view of preferences is needed in most situations.2

1.2. Constructive preferences
Two major tenets of the constructive perspective on preferences are that 1) expressions of preference are generally constructed at the time the valuation question is asked and 2) the construction process will be shaped by the interaction between the properties of the human information processing system and the properties of the decision task (Payne, Bettman, and Johnson, 1992; Slovic, 1995), leading to highly contingent decision behavior. That is, we assume that people do not have existing well-defined values for many objects; in addition, when asked a valuation question, they will selectively use information that is part of the immediate task description, as well as information that is drawn selectively from memory, to construct a response on the spot. The constructive view also asserts that preferences are not necessarily generated by applying some invariant process such as expected utility maximization; instead, a wide variety of heuristics (strategies)

246

PAYNE, BETIMAN AND SCHKADE

may be used in constructing a preferential response (Simon, 1955). Individuals may construct preferences because they lack the cognitive resources needed to compute and store well-defined preferences for many situations (March, 1978) or because they bring multiple, potentially conflicting processing goals to a decision problem (e.g., maximizing accuracy, minimizing effort, minimizing negative emotion, or maximizing ease of justification; see Bettman, Luce, and Payne, 1998).3
The constructive viewpoint does not necessarily mean that there is no "true" value to be measured. Expressed preferences (measured values for decision objects), in our view, generally reflect both a decision maker's basic values for highlighted attributes (e.g., more money is preferred to less) and the particular (contingent) heuristics or processing strategies used to combine information selectively in order to construct the required response to a particular situation. That is, in addition to random error, expressed preferences include two different sources of systematic variance-stable values associated with the attributes of the object being evaluated that are relatively constant across situations and a situation-specific component that is the joint effect of the task and context contingencies that are present. We believe that the situational component will often be large, perhaps much larger than either the random error or stable value components. The focus of this paper is on measuring preferences when the situational component is a major determinant of observed choice and judgment responses.
As suggested above, an important implication of the constructive nature of preferences (and evidence for such construction) is that decisions and decision processes are highly contingent upon a variety of factors characterizing decision problems. The major findings from the past two decades of behavioral decision research support that conclusion. It is beyond the scope of the present paper to review this evidence in detail; for reviews of the extensive evidence in support of the constructive view of decision behavior, see Payne, Bettman, and Johnson (1992, 1993), Bettman, Luce, and Payne (1998), Fischhoff (1991), Slavic (1995), and McFadden (1999). Instead, we will briefly summarize some of the major conclusions of that research.
First, choice among options is context (or menu) dependent; the relative value of an option depends not only on the characteristics of that option, but also upon characteristics of other options in the choice set. As noted by Tversky (1996), such context dependence indicates that "people do not maximize a precomputed preference order, but construct their choices in light of the available options" (p. 17). Second, preference among options also depends upon how the valuation question is asked; strategically equivalent methods for eliciting preferences can lead to systematically different preference orderings. Preference reversals due to response mode persist even in the face of substantial monetary incentives (see Grether and Plott, 1979). Third, choice among options depends upon how the choice set is represented (framed) or displayed, even when the representations would be regarded as equivalent by the decision maker upon reflection. As noted by Kahneman, Ritov, and Schkade (1999), "framing effects violate a condition of extensionality (Arrow, 1982), which is commonly taken for granted in economic analyses of

TOWARDS A BUILDING CODE

247

preference" (p. 206). Finally, the process used to make a choice depends on the complexity of the decision task; the use of simple (heuristic) decision processes increases with task complexity. Thus, people construct preferences using a variety of methods (strategies), with such usage contingent upon characteristics of the
choice problem. Clearly not all expressions of p:t;.eference are constructed at the time the
valuation question is asked; at times the expression of values reflects a reference to a well-defined value in memory. However, expressed preferences are likely to be constructed in a wide variety of situations in which we are interested in preference measurement. Therefore, a "building code" for measuring constructed preferences is likely to be widely applicable. We provide a more extensive discussion of the conditions leading to constructed preferences later in the paper.
In the following sections of the paper we address issues in measuring constructive preferences. Our initial focus is on preference measurement for design purposes, i.e., tasks similar to those facing the EPA administrator in our example above. Later in the paper we address assessing preferences for prediction problems such as those faced by the marketing manager in our example.
In design problems there is no obvious "correct" preference. Therefore, before we can address the measurement issues inherent in design problems, we first need to consider criteria for assessing the effectiveness of a preference construction and principles for good preference construction. Then we consider the process of preference construction, separating that process into several interrelated stages. For each stage we examine the possible "faults" in preference construction that might occur at that stage and suggest how those "faults" may be remedied or mitigated.

2. Assessing the effectiveness of preference construction
2.1. Defining a well-constructed preference
We believe that it is possible to judge the quality of a preference construction. For example, people express dismay when they learn that their preference orders vary as a function of how the question was asked (Tversky, Sattath, and Slovic, 1988). People also do not think it is a good idea to violate principles of coherent decision making such as dominance or transitivity of choices. Beyond coherence in decisions, we believe that the processes (methods) leading to an expression of preference can, and should, be judged in terms of quality. That is, we accept that "truth ultimately resides in the process" of the decision (Slovic, 1995, p. 369). This tradition of evaluating human reasoning according to standards applied to the reasoning itself rather than to its conclusions can be traced back at least as far as Socrates, Aristotle, and Plato. It also has a long tradition in psychology (see Baron (1988) for further discussion). Recently, Yankelovich (1991) has also argued that

248

PAYNE, BETTMAN AND SCHKADE

mindfulness of the consequences of an opinion should be a key component in judging the quality of an expressed opinion.
Sunstein (1990) makes a related argument about the importance of judging the quality of decision processes in the case of public decisions. He argues that not all preferences should be treated equally in a democracy and that more weight should be given to preferences that are reached "with a full and vivid awareness of available opportunities, with reference to all relevant information, and without illegitimate or excessive constraints on the process of preference formation" (p. 11).4
Obviously, quality must be defined in terms of the goals of a preference measurement exercise, e.g., measuring values as inputs to a public environmental protection decision or measuring values as a prediction of future market shares. In the latter case, the distinction between a better or more poorly constructed expression of preference may not matter as long as the measured preference corresponds to actual preferential behaviors such as buying a product. When measuring preferences for the purpose of designing better public or private decisions, however, we think that the focus should be on the processes leading to a well-constructed expression of preference. In part, this reflects the fact that the processes of preference construction are to some extent, at least, controllable
ex ante. What characteristics of the construction process should be used to assess
effectiveness? Along with many others, we argue that a well-constructed expression of preference is based on thorough processing of information (reason and reflection) that is transparent and in proportion to the importance of the question at hand (e.g., Baron, 1988; Frisch and Clemen, 1994; Janis and Mann, 1977; Slovic, 1995; for an alternative view of the effects of increased thought, see Wilson and Schooler, 1991). Such processing should include consideration of a range of alternative courses of action, consideration of the full range of objectives to be fulfilled, thorough consideration of the information most critical to the individual, the making of tradeoffs, and careful review of responses to detect inconsistencies. Thus, we argue that an expression of preference based on highly selective use of information, avoidance of tradeoffs, and which is not endorsed upon reflection is not well-constructed. Further, we believe that well-constructed expressions of preference should be sensitive to manipulations that should affect them, given the purposes of measurement, e.g., the quantity of the good provided, and should be insensitive to manipulations that should not affect them, e.g., framing effects (Baron, 1997; Fischhoff, 1997; also see Hammond (1996) for a general discussion of
how one judges the quality of a decision).5

2.2. Principles for good preference constmction
In the following sections of the paper we suggest some specific tools, procedures, and tests that might be used to mitigate some of the faults in the construction of

TOWARDS A BUILDING CODE

249

preferences. In other words, we outline some of the specifications in materials (information) and procedures (construction processes) that mi~ht make up a building code for the measurement of preferences. The procedures often involve greater work in the measurement of preferences, with a focus on doing more tasks with fewer respondents. This reflects the belief that it is systematic effects (e.g., the effects of the choice context or complexity) rather than random error that have the greatest impact on most constructed expressions of preference. The procedures also require a greater sensitivity to the psychology of preference construction in our measurement efforts, e.g., requiring of people only those types of judgments that they can do well (Norman, 1988; Kahneman, Schkade, and Sunstein, 1998).

3. Stages of preference construction, their faults, and proposed remedies
We are far from a complete theory of preferential decision making; however, there is general agreement that decision processes can usefully be viewed in terms of multiple, interacting stages (e.g., Hogarth, 1987). Generally, the stages include the initial cognitive representation of the decision problem, information acquisition and interpretation, information combination leading to an evaluation, and an expression or mapping of that valuation onto a response, e.g., a choice or willingness-to-pay amount.
Next, we briefly describe and discuss the faults and building code implications for each of these stages. Given space limitations, we only focus on what we believe are some of the most critical faults and possible remedies. For a summary of major faults and remedies at each stage, see Figure 1.

3.1. Problem representation
Our thought is controlled by mental models and frames, typically portrayed as associative networks of concepts interconnected by relationships of varying degrees of strength. Key components of a mental model for a decision (a decision frame) include the options to be considered, the states of nature to be evaluated, and the criteria used to measure the relative attractiveness of consequences. In addition, a decision frame affects both the boundaries one puts on a problem, such as whether prior costs (outcomes) are considered, and the reference points used to code a consequence as good or bad (Russo and Schoemaker, 1989).
When individuals construct mental models of a situation, they often make explicit as little information as possible in order to minimize the cognitive load. Such mental models affect what information we pay attention to and what we ignore. In particular, there is often a focusing phenomenon in which thoughts are restricted to what is explicitly represented in the mental model (Legrenzi, Girotto, and Johnson-Laird, 1993). At other times, the focal information will depend on past experiences (knowledge) that an individual brings to the problem. In either

250

PAYNE, BETIMAN AND SCHKADE

Faults at Stages of the Preference Construction Process and Proposed Remedies

Stage Problem Representation

Fault Myopic decision frames

Remedies
· Explicitly encourage considerationof multiple options, events, and objectives Expand set of options, use value ladders Encourage consideration of multiple futures Construct a value tree Clarify the distinction between fundamental and proxy values

Information Acquisition and Interpretation

Using an inappropriate problem representation
Inappropriate selectivity and the focusing illusion

· Use extensive pretesting, focus groups · Use manipulation checks
· Provide important information using formats which make it salient and easy to process

Information combination

Lack of comprehension of the information provided
Avoidance of tradeoffs

· Use manipulation checks · Use common, anchored scale formats · Explicitly present range information
· Provide time and thinking tools such as multiattribute utility analysis or judgment policy analysis
· Assess swing weights · Decompose complex judgments · Use tools to help improve attribute
weighting

Expression or Mapping of Preferences

Influences of scale compatibility

· Triangulation (ask questions in multiple ways) · Use lability as an asset- ask for reconciliation of inconsistencies

Biases in scale usage

· Use explicit scale anchors, e.g., behaviorally anchored scales
· Use less sensitive, more robust scales

All Stages

· Increased use of sensitivity analysis

Figure 1. Faults at stages of the preference construction process and proposed remedies.

case, the highlighting of some elements of a decision problem, while downplaying others, is very important in the context of a valuation exercise. For example, in assigning a value to "air quality," many evaluative dimensions of that concept can come to mind, e.g., visibility and health effects. Which components of air quality figure most strongly in the evaluation will depend on the mental frame adopted for

TOWARDS A BUILDING CODE

251

the valuation exercise (Irwin et al., 1990). Finally, once a mental model has been constructed or retrieved that seems to work for the task at hand, people tend not to consider alternatives (Legrenzi et al., 1993).
As noted above, we believe that a well-constructed preference should be based upon consideration of a range of options and those objectives most critical to the individual. Two major faults related to the problem representation stage concern failures to meet these standards. First, decision makers often focus on too narrow a range of options or objectives (often only one); i.e., they adopt a myopic decision frame (problem representation). Second, decision makers may use an inappropriate representation, i.e., they may try to solve the wrong problem using options or objectives that would not be most critical to them upon reflection.
3.1.1. Myopic decision frames. Although simplification of decision problems is generally required, given limited information processing capacity, the extent to which myopic problem representations are adopted is probably the major fault at the problem representation stage. For instance, people often focus on a single option, a single objective or attribute, or a single assumed state of the world when reasoning about a decision problem (Eisenhardt, 1989; Nutt, 1998; Shepard, 1964). This focusing is particularly acute when the decision is made under stressful conditions such as time pressure or heavy information load (e.g., Payne, Bettman, and Johnson, 1988). In the context of our example of the EPA administrator, the recent NOAA panel on CV studies (National Oceanic and Atmospheric Administration, 1993) highlighted this concern and emphasized being explicit about substitutes (i.e., multiple alternative courses of action) in well-designed CV studies. We believe that people generally will not consider alternative goods of the same type as the good evaluated unless explicitly reminded; see Baron (1997) for a similar argument.
3.1.2. Remedies for myopic decision frames. Remedies for this decision fault explicitly encourage people to think of multiple alternatives, multiple states of nature, and multiple attributes or objectives. First, it is important to expand the set of options considered. There should be at least two or more viable options considered when solving any decision problem if the goal is to make better decisions. Bazerman and Neale (1992, p. 69) capture this idea with their advice about house hunting: "fall in love with three, not with one." In group decision making, there is a similar recommendation that each individual in a group be responsible for thinking of at least two valid solutions to the problem early in the process; this encourages critical thinking about the decision problem.
Keeney (1996) suggests making explicit how much money is spent on alternative public goods in order to encourage people to recognize alternatives in the context of a valuation of a specific public policy option, e.g., putting money into an environmental protection project. This technique might be thought of as a "value" ladder in the same way that "risk" ladders have been used to help communicate risks to people (Smith and Desvousges, 1987). A related idea in the CV literature is the use of "benchmark" amounts intended to "remind respondents that they are

252

PAYNE, BETIMAN AND SCHKADE

already paying for many public goods and to provide a general idea of the magnitude of those payments" (Mitchell and Carson, 1989, p. 243). While there is an obvious danger that explicit benchmark amounts will provide an anchor for responses, we believe that the need to encourage consideration of alternative uses of resources when making decisions argues for making options as explicit as possible. This is particularly true when it is unlikely that people will retrieve options from memory in the normal course of solving a novel or complex valuation problem.
Does increasing the mental availability of options help in valuation? Although limited in quantity, research suggests that the answer is yes. For example, Baron and Greene (1996) found that explicitly reminding people of other goods helped reduce such problematic valuation effects as the adding up effect, where the value of good A assessed separately plus the value of good B assessed separately often exceeds the value of goods A and B when valued together. Another study by Posavac, Sanbonmatsu, and Fazio (1997) shows that the consistency between attitudes and decisions is higher when alternatives are made salient (explicit) in the decision context. This is most important when people are unlikely to generate (retrieve from memory) the complete set of options on their own. Finally, Nutt (1998) reports that consideration of more than one alternative course of action is associated with greater success in strategic decision making.
A second recommendation is to encourage consideration of multiple futures, because it is clear that people often fail to consider multiple uncertain futures when assessing preferences. One technique which can be used to address this problem is scenario generation (Schoemaker, 1991). The focus of most scenario exercises is not to list all possible futures but to generate at least two, three, or four different future states of the world so that people will be more cognizant of the possible range of uncertainties when making decisions.
Third, individuals should develop a multi-attribute problem representation. One of the basic tools used in decision analysis to help people consider multiple objectives or attributes when making a decision is the construction of a value tree (Keeney, 1992), particularly as an early step in a decision process. A critical issue related to such a representation of objectives is the distinction between fundamental and means objectives or between fundamental values and proxy values (Keeney, 1992). Proxy values reflect means to an end and reflect beliefs about the extent to which satisfying the proxy value will satisfy more fundamental values. Baron (1997, p. 83) suggests that "the failure to make respondents consult their fundamental values seriously may be the largest source of error in valuation of natural resources, as practiced." One solution to this problem mentioned by Baron is to provide respondents with expert opinions regarding which dimensions should be considered in assessing a value for an object (see DeKay and McClelland, 1996).
3.1.3. Inappropriate decision frames. A second class of faults at the problem representation stage is using an inappropriate representation. For example, a person may use an inappropriate analogy in generating a representation. One type of

TOWARDS A BUILDING CODE

253

inappropriate problem representation is from the perspective of the decision maker himself or herself; that is, a person may construct a preference (answer) for a different problem than that which he or she would endorse upon reflection. Inappropriate can also mean that a person is using a different frame than that intended by the researcher, i.e., the problem of scenario misspecification. More generally, use of a frame different from that intended by the researcher is a critical problem in any form of attitude research.
As an example, individuals sometimes use the analogy of charitable giving in constructing an answer to a contingent valuation task (Schkade and Payne, 1994). As a result, the WTP amounts that are expressed are often similar to the amounts given by the respondent to charities, e.g., $25 or $50 for a "worthwhile" cause. Clearly, the retrieval and use of a response to a situation perceived to be similar can be an efficient solution to a difficult problem. However, there can be costs associated with such solutions. For example, in solving a decision problem through the use of analogies, respondents may not be properly sensitive to important characteristics of the good being valued, e.g., the quantity of the good (Baron and Greene, 1996). Also, as noted earlier, once a mental model has been retrieved that seems to work for the task at hand, people may not consider alternatives (Legrenzi, Girotto, and Johnson-Laird, 1993) and therefore not appreciate what is omitted from the particular problem representation that they are using.
3.1.4. Remedies for inappropriate decision frames. Mitchell and Carson (1989) suggest that the use of inappropriate representations can be minimized in a contingent valuation study by an intensive program of questionnaire development, including the use of focus groups. In their words, "if the study is well designed and carefully pre-tested, the respondents' answers to the valuation questions should represent valid WTP responses" (p. 3).
We believe that in addition to careful pre-testing, manipulation checks should be used to confirm the representation respondents are using. In fact, we feel that one obvious property of a well-designed preference measurement process is the use of manipulation checks to ensure that the information presented was understood by the respondent in sufficient detail to have confidence in his or her responses. Fischhoff et al. (1993) provide an example of the manipulation checks used in answering questions about the value of cleaning up rivers near Pittsburgh. Unfortunately, as noted by Fischhoff et al. (1993), the use of manipulation checks is not as common as it should be among valuation researchers. We argue that a minimum standard for a building code dealing with the measurement of preferences should be the use of manipulation checks (for a discussion of probing procedures developed by survey researchers, see DeMaio and Rothgeb, 1996).
Other methods for probing respondents' thought processes can also be useful as manipulation checks. For example, the researcher can take a verbal protocol from the respondent during the construction of a preference (e.g., Schkade and Payne, 1994). The reasoning processes used by the respondent can then be checked to see if the respondent was answering the question as the researcher understood it.

254

PAYNE, BETIMAN AND SCHKADE

3.2. Infonnation acquisition and interpretation
In most situations of importance to an individual, a great deal of information may be available from many sources. Some of these sources are external to the individual (e.g., catalogues and brochures, special magazine issues, guidebooks, or opinions from friends for a college choice), and some information is internal, in the individual's memory. Once acquired, information is then interpreted in light of the representation that has been adopted for the decision task. One key component of this interpretation is the coding of potential outcome information in terms of a gain or loss relative to some reference value.
Even though a great deal of information may be available, human processing limitations require selectivity. That is, only a subset of the available information will be examined. Aspects of the individual's information environment can influence selectivity by affecting the salience of various pieces of information. For example, the organization of an information display can make some piece of information either more salient or easier to process (e.g., Bettman, Payne, and Staelin, 1986; Kleinmuntz and Schkade, 1993; Russo, 1977). There is a general "concreteness principle" in information acquisition (Slavic, 1972): people will tend to use only explicitly displayed information and will use it untransformed from the form in which it is displayed. A related point is that respondents may use conversational norms to infer that the information presented (and not other, unmentioned information) is the appropriate focus (Schwarz, 1996). Thus, individuals will of necessity be selective; the important issue is how the individual chooses to be selective.
We have stated above that a well-constructed preference should be based upon thorough consideration of the range of information most critical to the individual. Two of the major faults at the information acquisition and interpretation stage that impede attaining this objective are inappropriate selectivity and lack of information comprehension.

3.2.1. Inappropriate selectivity. Selective acquisition of information is related to the focusing phenomenon in constructing mental representations of problems, and therefore many of the faults of these two stages are similar. Thus, one of the major faults of the information acquisition stage is that individuals are too selective and do not acquire and consider enough relevant information. This problem can be compounded by the fact that the information that is most salient (the focus of attention) in a task environment can be uncorrelated or even negatively correlated with the diagnosticity or importance of the information for the individual's goals. Of course, it is also possible that individuals may seek to examine too much information, while not paying enough attention to the subset of information that is most important. A similar problem can occur when a decision maker is overloaded with too much information.

TOWARDS A BUILDING CODE

255

3.2.2. Remedies for inappropriate selectivity. One approach for generating well-constructed preferences, therefore, is to give people high quality information to be used in constructing a preference. For example, many CV researchers argue for the use of in-person interviews, at least in part because it is easier to convey a good deal of high quality information, such as pictures and other visual aids, in such interviews. Urban et al. (1997) have also emphasized the use of various multimedia tools to accelerate the learning of preferences about novel products through extensive, and hopefully more realistic, information provision.
However, as noted by Fischhoff and Furby (1988), the provision of information is not as straightforward a task as might be imagined. Although one does not want to leave out important information from the description of the valuation problem given to a respondent, providing all the relevant information for a valuation task can be a formidable task in itself. For example, Fischhoff and Furby give a checklist of the many components of a contingent valuation task that may need to be explained to the respondent in order for the respondent to generate a well-defined preference. As noted above, it is also clearly possible to overload the respondent with too much information; consequently, comprehension may be affected and various simplifying heuristics may be used as a way to deal with the stress caused by the information load (Payne, 1976). As noted below, we generally need to provide cognitive reasoning tools to help individuals cope with such information load problems.
Given the tension between providing too much information and too little, it is important to consider how one might make information easier to process so that individuals are more likely to examine the information most critical to them. There is a good deal of research suggesting that careful design of information display formats can be extremely useful. A classic example of such an information format effect is Russo's (1977) demonstration that the use of unit price information by consumers was affected by simple changes in how information was made available to the consumer (by presenting unit prices ranked in a list instead of on individual shelf tags). Guidelines also have been developed for such tasks as providing warnings on product labels (e.g. Bettman, Payne, and Staelin, 1986).
3.2.3. Lack of information comprehension. A second major fault at the information acquisition and interpretation stage is that individuals simply may not comprehend the information available or comprehend it in ways not intended by the researcher. Comprehension failures can be due to confusing presentation, lack of knowledge, or other factors (Fischhoff, Welch, and Frederick, 1999). For example, Hsee et al. (1999) review a growing body of research demonstrating that it is more difficult for individuals to evaluate the desirability of values on some attributes than on others. Hsee et al. also make clear that a more difficult to evaluate attribute will be given less weight when options are evaluated separately than when these options are evaluated jointly, which can lead to preference reversals. More generally, if the individual does not understand the object of the preference assessment, then we cannot expect meaningful responses (Fischhoff et al., 1993).

256

PAYNE, BETIMAN AND SCHKADE

3.2.4. Remedies for lack of information comprehension. We can attempt to ensure that individuals understand the information presented by using manipulation checks and by attempting to make the meaning of the information clear. As stressed earlier, one feature of a well-designed preference measurement process for design purposes should be the use of manipulation checks to ensure that the information presented was understood by the respondent in sufficient detail to have confidence in his or her responses.
Selective attention and comprehension faults due to information format also can be avoided by making the formats of the information as comparable as possible (e.g., using a common format to the extent possible) and by making the meaning of the information as clear as possible. In addition, decision analysts often attempt to make information more easily interpretable by explicitly presenting range information, such as mileage ranges for cars. They often do this by using a common scale such as 0 to 100 for the values of various attributes and anchoring the endpoints of the scales for each attribute by the worst (0) and best (100) attribute values provided by the alternatives in the choice set. Thus, the car in a choice set offering the best gas mileage (e.g., 30 MPG) would be given a value of 100, while the car offering the poorest gas mileage (e.g., 14 MPG) would be given a value of 0. The use of both absolute scale information, i.e., MPG numbers, and relative scale information (0 to 100) in combination may help in interpreting attribute information. The use of meaningful endpoints for scales also helps in the expression stage of preference construction, discussed below.

3.3. Information combination
How people combine information and make tradeoffs has been a focal point of research on preferences. For many, this stage is the heart of the preferential decision making process. It is in making tradeoffs between more of one thing and less of another that one's values are most often revealed to oneself and to outside observers; according to Freeman (1993), the tradeoff ratios between pairs of goods that matter to people are at the core of the economist's concept of value. Many have argued that making tradeoffs is a crucial aspect of high-quality, rational decision making (e.g., Frisch and Clemen, 1994).
It is clear that people do make tradeoffs. Much of market research, for example, has been aimed at measuring tradeoffs using a variety of techniques such as conjoint analysis (e.g., Green and Srinivasan, 1990) and direct methods for assessing exchange rates between attributes (e.g., Aaker, 1991). Similarly, asking people to make tradeoffs explicitly is a key part of decision analysis techniques (e.g., Clemen, 1996). However, the major fault of the information combination stage is that decision makers often avoid making explicit tradeoffs, relying instead on an array of non-compensatory decision heuristics.

TOWARDS A BUILDING CODE

257

3.3.1. Tradeoff avoidance. The avoidance of tradeoffs by individuals is reflected in behaviors such as the selection of the status quo option, the expression of a "protest" zero in CV studies, delaying choice, or selection based on choice set context, violating menu-independence (Luce, 1998). As noted above, the major fault of the information combination stage clearly is avoidance of tradeoffs.
Decision makers may avoid tradeoffs for several reasons. One explanation for tradeoff avoidance is simply that making tradeoffs is a cognitively demanding task that people will try to minimize (Payne, Bettman, and Johnson, 1993). Thus, one observes frequent use of decision heuristics that emphasize comparing alternatives on just one (or a few) attributes as tasks become more complex (i.e., lexicographictype heuristics; Payne, 1976).
Another explanation is that tradeoffs can be difficult for emotional as well as cognitive reasons (Hogarth, 1987; Luce, Payne and Bettman, 1999). It can be emotionally trying to think about giving up something one values. Values that people are relatively unwilling to trade off have been called "protected" values (Baron and Spranca, 1997), and decisions involving such difficult tradeoffs have termed "cruel choices" (Russell, 1990). Keeney (1996) suggests that public policy decision-makers "rarely" make explicit tradeoffs between costs and the non-economic impacts of programs.
3.3.2. Remedies for tradeoff avoidance. We believe that multiple approaches should be used to help individuals make explicit tradeoffs. Because thinking about tradeoffs is difficult for people, providing more information may be necessary, but not sufficient, for helping people think more deeply about their tradeoffs. As a general building code principle, we suggest that providing cognitive tools can help a respondent think about tradeoffs.
Some simple cognitive techniques for improving the making of tradeoffs have already been mentioned. For instance, expanding the set of options and thinking in terms of two or more alternatives helps people to appreciate that every option is likely to have some advantages and disadvantages. However, there are even more sophisticated thinking tools to facilitate making explicit tradeoffs, such as multiattribute utility analysis (MAUA) and judgment policy analysis.
Thinking tools like MAUA incorporate ways to avoid, or at least minimize, some of the more common faults in thinking about tradeoffs. For example, one of the most important errors identified by decision analysts is the failure to consider an adequate range of levels for particular attributes when deciding tradeoffs. A simple technique for helping people to do a better job of considering attribute ranges is the assessment of swing weights. Typically, the respondent compares alternatives that "swing" between the worst and best levels represented in the given (or plausible) set of alternatives for each attribute and assesses the extent to which the swings in each attribute contribute to overall value differences.
Another feature or characteristic of thinking aids for the making of tradeoffs is the decomposition of complex value judgments into a series of less complex judgments. A simple model like the additive model of preferences is then used to

258

PAYNE, BETIMAN AND SCHKADE

combine the simpler judgments into an overall valuation. Consistent with the idea that cognitive capacity constraints are a source of error in value construction, decomposing a complex judgment into a series of smaller judgments and then combining those judgments mechanically can improve judgment performance (see Jako and Murphy, 1990; Kleinmuntz, 1990; Einhorn, 1972).
Other thinking tools are available that may help in the construction of preferences through improving attribute weighting. Social judgment theory (Hammond et al., 1975), for instance, provides feedback to an individual about his or her judgment policy and the relative weights apparently placed on various attributes of value. The individual can then use that knowledge to decide how much, if at all, to change the weighting of attributes. Harris, Tinsley, and Donnelly (1988) discuss how judgment policy analysis might be applied to the valuation of natural re-
sources. However, as noted above, tradeoffs may be avoided for emotional as well as
cognitive reasons. Even providing cognitive tools may not be sufficient to overcome individuals' emotional and moral reasons for avoidance. Therefore, an important area for future research is understanding the emotional costs of making tradeoffs and developing techniques which help to both alleviate such costs and encourage reasoned tradeoffs. For example, one advantage of the judgment, feedback, learn, and respond procedure of judgment policy analysis is that it might help overcome the emotional reaction to making even more explicit tradeoffs, although this needs to be investigated.

3.4. Expression or mapping ofpreferences
The essence of the expression or mapping stage is that an individual must take an internal preferential response and express that response using some specified response mode (e.g., a choice or a scale). However, even when a person has in mind a well-constructed preference, it is not always the case that he or she will be able to translate that preference or value easily and without error (bias) into the response called for in a valuation task (Kahneman, Ritov, and Schkade, 1999). The outcome of the expression or mapping stage should be a response that best reflects the individuals' values and is free of inconsistencies. Two major faults that hinder reaching this goal are influences of scale compatibility and biases in scale usage.
3.4.1. Influences of scale compatibility. One major fault at the preference expression stage is the influence of scale compatibility. Expressions of preference are likely to be overly influenced by the compatibility between an attribute of the stimulus and the response scale or mode. For example, the weight of an attribute whose values are expressed in monetary terms is generally enhanced if the required response is also in monetary terms (Tversky, Sattath, and Slavic, 1988). Similarly, Gregory et al. (1993) have suggested that although a person may hold a strong value for an environmental resource, that value is unlikely to be represented in memory in

TOWARDS A BUILDING CODE

259

dollar terms. Consequently, in attempting to translate such a value into a monetary equivalent, the person may exhibit systematic errors.
3.4.2. Remedies for influences of scale compatibility. We can attempt to overcome scale compatibility effects via triangulation of responses. When the goal of preference measurement is design, one important building code principle is that a preference question should not be asked in just one way; instead, questions about values that are likely to be the result of a constructive process should be asked in multiple ways (see Huber et al., 1993 for evidence of the effectiveness of such an approach). Differences in responses to different but strategically equivalent forms of a value question provide insight into the extent to which the expressed preference is constructed. In addition, one can then ask the respondent to consider the inconsistencies implied by his or her responses. Thus, lability of responses can provide an opportunity for the decision maker to think carefully about the inconsistencies and thereby gain greater insight into the decision (von Winterfeldt and Edwards, 1986). A related point is that asking for multiple types of responses allows different task orders; as suggested by a reviewer, different task orders should in fact be used and any resultant order effects can be used as a source of insight into the construction process.
3.4.3. Biases in scale usage. A second set of expression or mapping faults is due to a number of classic psychophysical phenomena. For example, there are biases such as the tendency to use the center of the scale. It is also likely that any response scale will suffer from anchoring effects. Finally, scale use is affected by the meaningfulness of the scale's labels. If scale labels are vague and do not provide a context for the evaluation, expressed preferences may have little stability. For example, in a study that has implications for an area of debate in public policy, Kahneman, Schkade, and Sunstein (1998) have shown that unpredictability in punitive damage awards may result from the difficulty that people have in mapping their preference for the degree of severity of punishment onto an unbounded dollar scale. This difficulty can be traced to the well-known difficulties people have with magnitude estimation scales in psychophysics. Kahneman, Ritov, and Schkade (1999) provide further discussion of psychophysical phenomena related to valuation tasks.
3.4.4. Remedies for biases in scale usage. A general principle of our proposed building code for the measurement of preferences is that it is better to be explicit about anchors rather than leave the anchors implicit; this helps avoid large individual differences in the implicit anchors used by respondents. Scale usage and the ease of interpretation of a scale can also be improved by using meaningful anchors. For instance, it is recommended in performance appraisal that scales be behaviorally anchored. That is, rather than simply using the term "excellent" on a performance rating scale, one would provide an explicit example of excellent task performance, e.g., responding to a customer's service complaint.

260

PAYNE, BETI'MAN AND SCHKADE

There also may be times when it is better to use a less sensitive, but more robust, response scale. Kahneman, Schkade, and Sunstein (1998) have suggested that one solution for the problem of unpredictability in punitive damage awards is for jurors to use a less sensitive category-type scale (e.g., a seven category scale ranging from no punishment to extremely severe punishment) on which jurors can make more reliable and robust judgments. Those responses might then be converted into punitive damage amounts using a formula. This suggestion of Kahneman et al. is consistent with the general building code principle of only asking people to do those things that they can do well (Norman, 1988).

3.5. A more prominent role for sensitivity analysis
A final suggestion for better measurement cuts across the various stages of the preference construction process. Sensitivity analysis provides insight into the robustness of a decision to changes in the parameters and values used to define it. In our experience, one of the major factors in the increasing use of decision aiding techniques to solve real-world problems has been the ability of computer-based decision support tools to easily do, and display, the results of sensitivity analyses. The presence of an irreducible arbitrariness in measured preferences makes sensitivity analysis an essential tool in the construction of a defensible expression of value, particularly when the value is going to be used as an input for the design and selection of a public policy option.
Typically, sensitivity analysis is done after the problem structuring and valuation stages of a decision. However, given that expressed values may be constructed, we propose that in some cases it may be useful to start the analysis of a decision with a sensitivity analysis. For example, in looking for public values to be used as inputs into a policy decision about environmental protection levels, the decision maker might start by asking under what values a decision would shift. If the value of a natural resource must be above $X in order to warrant the cost of some action to improve or protect the environment, then the decision maker might use that knowledge to directly ask whether the constructed value is likely to be above or below $X. Of course, there is a danger that the values assessment could be directed by the decision maker to either support or not support an expression of value greater or less than $X; however, we suggest that the danger can be ameliorated by making the assessment process as explicit as possible and by including other anchors that are above or below $X.
Until now, when reviewing construction faults and possible remedies for those faults, we have emphasized situations in which the goal of the measurement task is to design or select a future course of action, particularly in the public domain. When the task is to predict rather than design preferences, another set of construction guidelines is called for, presented next.

TOWARDS A BUILDING CODE

261

4. Measuring preferences for prediction: context matching of information environments
When the goal of measurement is prediction, the "quality" of the measurement is determined by how well the measured preference corresponds to preferential behaviors of interest (e.g., buying a product). The basic building code principle for achieving such correspondence is context matching. That is, one attempts to match the task environment (the context) presented to the respondent for purposes of preference measurement as closely as possible to the task environment that the decision maker will actually face. In implementing context matching, the analyst attempts to determine the relevant factors that might influence preferences in the individual's environment and then matches the values of those factors in the measurement environment (Simmons, Bickart, and Lynch, 1993; Wright and Kriewall, 1980). For example, we now know from behavioral decision research that such factors as the response mode, the number of options and attributes, time pressure, information display, the context provided by competing options (choice set), and others can affect choices (Payne, Bettman, and Johnson, 1992). The environment in which preferences are elicited should attempt to approximate the individual's environment on all these factors, particularly if the individual has little familiarity with the decision. The predictive validity of the preference data supplied by a respondent depends crucially on his or her constructing the same preference during the staged measurement episode as he or she will when coming to grips with the real choice (Wright and Weitz, 1977; see also Marder (1997) for a similar idea, the congruence principle). In sum, the measurement situation should attempt to mimic to the extent possible the major factors that affect how people deal with the actual decision problems that are the predictive focus.
Context matching thus demands a thorough knowledge of the properties of choice environments, which requires a fairly complete task analysis of the situations an individual will face when making the actual marketplace or public policy choice. This may not be an easy task to accomplish (see Huber (1997), however, for an attempt to relate properties of market environments to properties of evaluation tasks). First, individuals may not have detailed knowledge of the situations for which they are predicting (Fischhoff, 1991). In addition, in some cases factors may differ systematically across choice environments (e.g., the set of available options may vary). In that case, measurements may need to be taken for each of the major variants of the choice environment and then aggregated based upon the relative frequency of those variants. This will be more difficult to the extent that these variants change over time and hence must also be predicted. Finally, it may be virtually impossible to match on all aspects of the environment. How can we determine which dimensions are most important to match on? As noted above, behavioral decision research has provided evidence for a set of plausible candidate properties (e.g., response mode); perhaps effect sizes from this prior research could be used as broad guidelines for selecting the most critical aspect of the environment on which to match.

262

PAYNE, BETIMAN AND SCHKADE

5. Discussion
Fischhoff (1997) notes that psychology "is still grappling with how to handle situations in which people might not know what they want" (p. 209). We would extend that view and say that researchers interested in the measurement of preferences are grappling with what it means to measure values in a world of constructed preferences. The purpose of this paper is to begin a dialogue that will hopefully lead to agreement on at least some elements of a building code for the measurement of preferences. We believe that enough research now exists to identify some common "faults" in the construction of preferences that can, and should be, addressed. As noted above, many of our suggestions for addressing preference construction faults involve the provision of tools as well as information (i.e., the materials) for thinking about values. Our suggestions also involve greater effort devoted to the measurement of preferences, with a focus on doing more tasks with fewer respondents. In the next section we consider the conditions under which such efforts should be undertaken.

5.1. When is a building code needed?
Given that our guidelines often involve substantial effort on the part of respondents, it is important to consider when such guidelines are necessary. Just as housing construction codes often vary depending upon the type or purpose of a building (e.g., whether for a high-rise office, a residence, a school, or a hospital) and the location of the building (e.g., whether the area is prone to earthquakes), we believe that the application of our building code should be contingent on characteristics of the measurement situation. In particular, we believe that the building code should be applied when preferences are more likely to be constructive and to the degree that the decision for which the preferences are relevant is more critical or important. We consider each of these two aspects of a measurement situation next.
5.1.1. When are preferences likely to be constructed? Clearly not all expressions of preference are constructed at the time the valuation question is asked. There are occasions when the expression of values reflects a reference to a well-defined value in memory. For example, for the first two authors of this paper, asking for the name of their favorite college basketball team would yield a quick preferential response from memory, i.e., Duke. In Bayesian terms, there are times when individuals have strong priors.
Fischhoff, Slavic, and Lichtenstein (1980), argue that "people are most likely to have clear preferences regarding issues that are familiar, simple, and directly experienced" (p. 118). Experience allows a person to obtain feedback on the

TOWARDS A BUILDING CODE

263

outcomes of prior judgments and choices and thus to learn preferences. In the field of attitude research, clear preferences have been called "crystallized" values (Schuman and Presser, 1981). Crystallized values are more likely when a person has had the opportunity to think about andjor obtain experience with a good prior to being asked a valuation question (Irwin et al., 1990). Thus, when the objects to be valued are ones with which the respondent is familiar and has directly experienced, the common assumptions of economics are more likely to be justified, i.e., preferences exist to be uncovered.6
However, even if a preference is stored in memory, it may not always be retrieved; thus, preferences may be partially constructed even when there has been prior experience. The likelihood that a particular prior preference or value will be retrieved from memory is a positive function of (a) the accessibility in memory (i.e., ease of retrieval) of the prior valuation and (b) the perceived diagnosticity of the prior valuation (i.e., the perceived degree to which that prior value aids the person in achieving his or her goals). On the other hand, the probability of a particular value's being retrieved will be a negative function of the (c) accessibility and (d) diagnosticity of alternative values available in memory (Feldman and Lynch, 1988). Accessibility can be influenced by a variety of factors, including various priming effects, information format, prior usage of the information, and so on (e.g., Alba and Chattopadhyay, 1985; Simmons, Bickart, and Lynch, 1993).
When the object to be valued has any novelty or complexity, e.g., valuing a change in an environmental resource, a retrieved value or preference may simply serve as a starting point or anchor for a more elaborate inferential process in which existing values are related to the problem at hand (Fischhoff and Furby, 1988). The more the valuation exercise requires inferences to be drawn from past situations to a current problem and the more unfamiliar the terms and issues (e.g., the sustainability of an ecological system), the more the expression of preference is likely to reflect a constructive process. Also, the greater the conflict among existing values that might exist, e.g., environmental protection versus economic development, the greater the uncertainties about the future, and larger the number of options to be considered, the more the expression of preferences is likely to reflect a constructive process. Thus, expressed preferences are likely to be constructed in a wide variety of situations.

5.1.2. When does a decision problem warrant use of the guidelines? We have only begun to examine how the building code guidelines should vary according to properties of the measurement situation, e.g., the purpose of the valuation exercise. We have characterized the differences between the measurement of preferences for the two different purposes of decision design and prediction. However, as suggested in several places in this paper, one might also want different "building code" guidelines for different situations involving decision design. Obviously, one would want to make more extensive use of the guidelines the more important the

264

PAYNE, BETIMAN AND SCHKADE

decision. One might also want to use the guidelines more extensively the greater the degree to which the expression of preference by one individual might impact the consequences experienced by another. The problem of the EPA administrator clearly fits into the category of situations in which we think a more complete building code approach is needed. The characterization of when the guidelines should be used to a greater or lesser extent is a major topic for future research.
One final issue to be addressed is which guidelines are the most critical to implement when a decision to use the building code has been made. We believe that the following guidelines are the most critical: ensuring consideration of multiple decision frames and options, using manipulation checks to ensure understanding, encouraging explicit tradeoffs, use of more than one response mode, and the use of sensitivity analysis.
In the next section we consider a learning perspective on the construction of preferences that presents another view of the guidelines. Then we provide some words of caution for using the building code.

5.2. A learning perspective on the construction ofpreferences
One way to view the construction of preferences is from a learning perspective. That is, one could view the construction of a preference as a process by which a decision maker comes to "learn" his or her value for an object (see Plott (1996) for a somewhat similar view). From such a perspective, a building code guideline can be seen as a method to encourage more effective learning. For example, facilitating explicit tradeoffs through the use of matching tasks (Tversky et al., 1988) can be viewed as a method for encouraging people to think (learn) about values through the making of tradeoffs. Similarly, the use of multimedia tools to provide complex information (e.g., Urban et al., 1997) is a way to accelerate the learning of preferences. Finally, we argue that helping people learn and consider the distinction between means and fundamental objectives is a critical learning step in the construction of a well-formed preference. However, the contingencies of decision making make clear that the learning of preferences can be highly path-dependent, i.e., what is learned can depend on initial anchor values. Further, convergence on a preference may, at best, be a slow process. Thus, the building code guidelines suggested above represent suggestions for helping people to follow better and perhaps quicker paths in learning their preferences.

5.3. Words of caution
A number of cautions need to be expressed. First, we are sensitive to the danger of overreaching when one talks about differentially treating better and more poorly constructed preferences. However, we argue that the more that measured prefer-

TOWARDS A BUILDING CODE

265

ences are to play a role in an important decision, e.g., a public policy decision, the greater the weight that should be given to the better constructed preferences. As noted earlier in the paper, we make this argument cognizant that there are situations in which an individual's preferences must be given weight, no matter how poorly constructed they may be.
A related point is that some of the suggestions for improving preference measurement appear paternalistic. We do not intend to imply that the analyst should impose values on the individual. Nevertheless, we believe that providing procedures and tools that help individuals discover their own preferences is in the best interests of those individuals, even through this may also influence those preferences. A reviewer made the cogent and related point that the influence of the measurement process on values may be subtle enough that it does not arouse respondents' defenses and hence may lead to "persuading" the respondents.
Second, not all examples of contingencies in decision making should necessarily be viewed as faults in the construction of preferences. For instance, coding an outcome as a gain or a loss relative to a particular reference value may reflect how that outcome in fact will be experienced by the decision maker and hence need not be a fault. Again, however, we argue that clarity in the use of a reference value should be a principle of a building code for preference measurement.
Third, to the extent that a measured preference today is really a prediction about a future preference, there is some research suggesting that people often get it wrong when predicting future preferences (Kahneman, 1994; Huber et al., 1997; Loewenstein and Schkade, 1998). People fail to fully appreciate, for example, the impact of adaptation on the experience of outcomes over time. One implication of a more dynamic view of preferences is that the closer the measurement of preferences is to the likely consumption experience the better. Another implication is that special instructions may be needed to help make the salience of time intervals greater (e.g., Read and Loewenstein, 1995). More generally, the guidelines for what constitutes a well-constructed preference may need to be modified when preferences develop substantially over time and people have great deficiencies in their ability to predict how future outcomes will be experienced.
Fourth, one reviewer expressed a caution about "protected" values or preferences (Baron and Spranca, 1997). Is it appropriate to even try to cause people to rethink such values during a design process? We argue that the importance of considering explicit tradeoffs must be very carefully weighed against the possible emotional costs that may be incurred by the respondent. We suspect that in at least some cases the benefits from making the tradeoffs will in fact outweigh these emotional costs.
Finally, we have suggested a number of ways in which preferences might be better constructed. Each of the suggested methods for improvement has a foundation in the research on human judgment and choice; however, some of the suggested methods reflect much more research than do others. Thus, there is much need for research that would verify that the methods we suggest for improving the construction of preferences are in fact likely to lead to better expressions of values.

266

PAYNE, BETIMAN AND SCHKADE

6. Conclusion
We argue that there is a need for a "building code" for preference measurement in a world in which many expressions of preference are constructed by people at the time they are asked a valuation question. As in the case of the historical development of building codes, much of the impetus for a building code for constructed preferences comes from an awareness of faults in the processes typically used in preference construction. We have sought to begin the development of a building code for preference measurement by identifying some principles and techniques for preference construction and measurement that should mitigate some of the most common and important construction faults. Many of our suggestions for addressing preference construction faults build on the work of others and involve the provision of tools for thinking about values as well as providing information (i.e., the materials) for thinking about a given expression of preference. This reflects our belief that many construction faults and associated difficulties in the measurement of preferences are frequently due to cognitive limitations interacting with novel and complex task demands. We have also tried to begin a discussion of how a building code's guidelines should vary as a function of the purposes of the valuation exercise. Clearly, an architectural, constructive view of expressed preferences requires a fundamentally different approach to the measurement of preferences than that which is implied by an archaeological, well-defined existing preferences view.

Acknowledgment
Preparation of this paper was supported by grants from the National Science Foundation and from the Environmental Protection Agency.

Notes
1. The notion of constructed preferences is consistent with the "philosophy of basic values," which holds that people lack well-differentiated values for all but the most familiar evaluation tasks. The notion of well-defined preferences, on the other hand, is consistent with the "philosophy of articulated values," which assumes that people have values for all (most) valuation questions and the trick is just to ask the question in the right way (Fischhoff, 1991).
2. Lucas (1986, p. S402) has argued that economists tend "to focus on situations in which the agent can be expected to 'know' or to have learned the consequences of different actions so that his observed choices reveal stable features of his underlying preferences." In a similar vein, Plott (1996) has argued that individuals have a consistent set of preferences but that such preferences only become known to the individual (are "discovered") through thought and experience.
3. See Sen (1997) for a different but related discussion of how preferences are sensitive to choice processes and the goals evoked by those processes.
4. Clearly there are situations in which an individual's preferences must be given weight no matter how poorly constructed they may be. There are sometimes "rights" to preferences; see Sunstein (1990) for a further discussion of this point.

TOWARDS A BUILDING CODE

267

5. Other properties of a well-constructed preference might include such things as high levels of test-retest reliability (stability); however. as noted by one reviewer, stability may result from the repeated use of similar information and processes in the construction process, and should not be taken as a sufficient indicator of the retrieval of a well-defined preference (see Sudman, Bradburn, and Schwartz, (1996) for a related discussion).
6. However, even such crystallized values can still be subject to task and context effects (Krosnick and Schuman, 1988). For a further discussion of such effects, see Kahneman, Schkade, and Sunstein (1998).

References
Aaker, David A. (1991). Managing Brand Equity. New York: The Free Press. Alba, Joseph W. and Amitava Chattopadhyay. (1985). "Effects of Context and Part-Category Cues on
Recall of Competing Brands," Journal of Marketing Research 22, 340-349. Arrow, Kenneth J. (1982). "Risk Perception in Psychology and Economics," Economic Inquiry 20, 1-9. Baron, Jonathan. (1988). Thinking and Deciding. Cambridge, England: Cambridge University Press. Baron, Jonathan. (1997). "Biases in the Quantitative Measurement of Values for Public Decisions,"
Psychological Bulletin 122, 72-88. Baron, Jonathan and Joshua Greene. (1996). "Determinants of Insensitivity to Quantity in Valuation of
Public Goods: Contribution, Warm Glow, Budget Constraints, Availability, and Prominence," Journal of Experimental Psychology: Applied 2, 107-125. Baron, Jonathan and Mark D. Spranca. (1997). "Protected Values," Organizational Behavior and Human Decision Processes 70, 1-16. Bazerman, Max H. and Margaret A. Neale. (1992). Negotiating Rationally. New York: The Free Press. Bettman, James R., Mary Frances Luce, and John W. Payne. (1998). "Constructive Consumer Choice Processes," Journal of Consumer Research 25, 187-217. Bettman, James R., John W. Payne, and Richard Staelin. (1986). "Cognitive Considerations in Designing Effective Labels for Presenting Risk Information," Journal of Marketing and Public Policy 5, 1-28. Clemen, Robert T. (1996). Making Hard Decisions, 2nd edition. Belmont, CA: Duxbury Press. DeKay, Michael L. and Gary H. McClelland. (1996). "Probability and Utility Components of Endangered Species Preservation Programs," Journal of Experimental Psychology: Applied 2, 60-83. DeMaio, Theresa J. and Jennifer M. Rothgeb. (1996). "Cognitive Interviewing Techniques: In the Lab and in the Field." In Norbert Schwarz and Seymour Sudman (eds.), Answering Questions: Methodology for Determining Cognitive and Communication Processes in Survey Research. San Francisco: Jossey-Bass. Einhorn, Hillel J. (1972). "Expert Measurement and Mechanical Combination," Organizational Behavior and Human Performance 7, 86-106. Eisenhardt, Kathleen M. (1989). "Making Fast Strategic Decisions in High Velocity Environments," Academy of Management Journal 32, 543-575. Feldman, Jack M. and John G. Lynch, Jr. (1989). "Self-Generated Validity and Other Effects of Measurement on Belief, Attitude, Intentions, and Behavior," Journal of Applied Psychology 73, 421-435. Fischhoff, Baruch. (1991). "Value Elicitation: Is Anything in There?" American Psychologist 46, 835-847. Fischhoff, Baruch. (1997). "What Do Psychologists Want? Contingent Valuation as a Special Case of Asking Questions." In Raymond J. Kopp, Werner W. Pommerehne, and Norbert Schwartz (eds.), Determining the Value of Non-Marketed Goods: Economic, Psychological, and Policy Relevant Aspects of Contingent Valuation Methods. Boston: Kluwer Academic Publishing. Fischhoff, Baruch and Lita Furby. (1988). "Measuring Values: A Conceptual Framework for Interpreting Transactions with Special Reference to Contingent Valuation of Visibility," Journal of Risk and Uncertainty 1, 147-184.

268

PAYNE, BETIMAN AND SCHKADE

Fischhoff, Baruch, Marilyn Jacobs Quadrel, Mark Kamlet, George Loewenstein, Robyn Dawes, Paul Fishbeck, Steven Klepper, Jonathan Leland, and Patrick Stroh. (1993). "Embedding Effects: Stimulus Representation and Response Mode," Journal of Risk and Uncertainty 6, 211-234.
Fischhoff, Baruch, Paul Slovic, and Sarah Lichtenstein. (1980). "Knowing What You Want: Measuring Labile Values." In Thomas S. Wallsten (ed.), Cognitive Processes in Choice and Decision Behavior. Hillsdale, NJ: Lawrence Erlbaum.
Fischhoff, Baruch, Ned Welch, and Shane Frederick. (1999). "Construal Processes in Preference Assessment," Journal of Risk and Uncertainty 19, 139-176.
Freeman, A Myrick, III. (1993). The Measurement of Environmental and Resource Values. Washington, DC: Resources for the Future.
Frisch, Deborah and Robert T. Clemen. (1994). "Beyond Expected Utility: Rethinking Behavioral Decision Research," Psychological Bulletin 116, 46-54.
Green, Paul E. and V. Srinivasan. (1990). "Conjoint Analysis in Marketing: New Developments with Implications for Research and Practice," Journal of Marketing 45, 33-41.
Gregory, Robin, James Flynn, Stephen M. Johnson, Theresa A Satterfield, Paul Slovic, and Robert Wagner. (1997). "Decision-Pathway Surveys: A Tool for Resource Managers," Land Economics 73, 240-254.
Gregory, Robin, Sarah Lichtenstein, and Paul Slovic. (1993). "Valuing Environmental Resources: A Constructive Approach," Journal of Risk and Uncertainty 7, 177-197.
Grether, David M. and Charles R. Plott. (1979). "Economic Theory of Choice and the Preference Reversal Phenomenon," American Economic Review 69, 623-638.
Hammond, Kenneth R. (1996). Human Judgment and Social Policy: Irreducible Uncertainty, Inevitable Error, Unavoidable Injustice. New York: Oxford University Press.
Hammond, Kenneth R., Thomas R. Stewart, Berndt Brehmer, and D. 0. Steinmann. (1975). "Social Judgment Theory." In M. F. Kaplan and S. Schwartz (eds.), Human Judgment and Decision Processes. New York: Academic Press.
Harris, Charles C., Howard E. A Tinsley, and Dennis M. Donnelly. (1988). "Research Methods for Public Amenity Resource Valuation: Issues and Recommendations." In George L. Peterson, B. L. Driver, and Robin Gregory (eds.), Amenity Resource Valuation: Integrating Economics With Other Disciplines. State College, PA: Venture Publishing.
Hogarth, Robin M. (1987). Judgment and Choice, 2nd ed. New York: John Wiley. Hsee, Christopher H., George F. Loewenstein, Sally Blount, and Max H. Bazerman. "Preference
Reversals between Joint and Separate Evaluations of Options: A Review and Theoretical Analysis," Psychological Bulletin 125, 576-590. Huber, Joel. (1997). "What We Have Learned from 20 Years of Conjoint Research: When to Use Self-Explicated, Graded Pairs, Full Profiles or Choice Experiments." In 1997 Sawtooth Conference Proceedings. Sequim, WA: Sawtooth Software. Huber, Joel, John G. Lynch, Jr., Kim P. Corfman, Jack Feldman, Morris C. Holbrook, Donald R. Lehmann, Bertrand Munier, David A Schkade, and !tamar Simonson. (1997). "Thinking About Values in Prospect and Retrospect: Maximizing Experienced Utility," Marketing Letters 8, 323-334. Huber, Joel, Dick R. Wittink, John A. Fiedler, and Richard Miller. (1993). "The Effectiveness of Alternative Preference Elicitation Procedures in Predicting Choice," Journal of Marketing Research 30, 105-114. Irwin, Julie R., David Schenk, Gary H. McClelland, William D. Schulze, Thomas Stewart, and Mark Thayer. (1990). "Urban Visibility: Some Experiments on the Contingent Valuation Method." In C. V. Mathai (ed.), Vzsibility and Fine Particles. Pittsburgh, PA: Air and Waste Management Association. Jako, Robert A and Kevin R. Murphy. (1990). "Distributional Ratings, Judgment Decomposition, and Their Impact on Interrater Agreement and Rating Accuracy," Journal of Applied Psychology 75, 500-505. Janis, Irving L. and Leon Mann. (1977). Decision Making. New York: The Free Press. Kahneman, Daniel. (1994). "New Challenges to the Rationality Assumption," Journal of Institutional and Theoretical Economics 150, 18-36.

TOWARDS A BUILDING CODE

269

Kahneman, Daniel, Ilana Ritov, and David A Schkade. (1999). "Economic Preferences or Attitude Expression?: An Analysis of Dollar Responses to Public Issues," Journal of Risk and Uncertainty 19, 203-236.
Kahneman, Daniel, David A Schkade, and Cass R. Sunstein. (1998). "Shared Outrage and Erratic Awards: The Psychology of Punitive Damages," Journal of Risk and Uncertainty 16, 49-86.
Keeney, Ralph L. (1992). Value-Focused Thinking: A Path to Creative Decisionmaking. Cambridge, MA: Harvard University Press.
Keeney, Ralph L. (1996). "Valuing Billions of Dollars," In Richard J. Zeckhauser, Ralph L. Keeney, and James K. Sebenius (eds.), Wise Choices: Decisions, Games, and Negotiations. Boston: Harvard Business School Press.
Kleinmuntz, DonN. (1990). "Decomposition and the Control of Error in Decision-Analytic Models." In Robin M. Hogarth (ed.), Insights in Decision Making: A Tribute to Hillel J. Einhorn. Chicago: University of Chicago Press.
Kleinmuntz, Don N. and David A Schkade. (1993). "Information Displays in Decision Making," Psychological Science 4, 221-227.
Krosnick, Jon A and Howard Schuman. (1988). "Attitude Intensity, Importance, and Certainty and Susceptibility to Response Effects," Journal of Personality and Social Psychology 54, 940-952.
Legrenzi, P., V. Girotto, and P. N. Johnson-Laird. (1993). "Focusing in Reasoning and Decision Making," Cognition 49, 37-66.
Loewenstein, George and David A Schkade. (1998). "Wouldn't It Be Nice? Predicting Future Feelings," In Ed Diener, Norbert Schwartz, and Daniel Kahneman (eds.), Hedonic Psychology: Scientific Approaches to Enjoyment, Suffering, and Well-Being. New York: Russell Sage Foundation.
Lucas, Robert E., Jr. (1986). "Adaptive Behavior and Economic Theory," Journal of Business 59, S401-S426.
Luce, Mary Frances. (1998). "Choosing to Avoid: Coping with Negatively Emotion-Laden Consumer Decisions," Journal of Consumer Research 24, 409-433.
Luce, Mary Frances, John W. Payne, and James R. Bettman. (1999). "Emotional Trade-Off Difficulty and Choice," Journal of Marketing Research 36, 143-159.
March, James G. (1978). "Bounded Rationality, Ambiguity, and the Engineering of Choice," Bell Journal of Economics 9, 587-608.
Marder, Eric. (1997). The Laws of Choice. New York: Free Press. McFadden, Daniel. (1999). "Rationality for Economists," Journal of Risk and Uncertainty, 19, 73-106. Mitchell, Robert C. and Richard T. Carson. (1989). Using Surveys to Value Public Goods: The Contingent
Valuation Method. Washington, DC: Resources for the Future. National Oceanographic and Atmospheric Administration. (1993). "Report of the NOAA Panel on
Contingent Valuation," Federal Register 58, 4602-4614. Norman, Donald A (1988). The Psychology of Everyday Things. New York: Basic Books. Nutt, Paul C. (1998). "How Decision Makers Evaluate Alternatives and the Influence of Complexity,"
Management Science 44, 1148-1166. Payne, John W. (1976). "Task Complexity and Contingent Processing in Decision Making: An Informa-
tion Search and Protocol Analysis," Organizational Behavior and Human Performance 16, 366-387. Payne, John W., James R. Bettman, and Eric J. Johnson. (1988). "Adaptive Strategy Selection in
Decision Making," Journal ofExperimental Psychology: Learning, Memory, and Cognition 14,534-552. Payne, John W., James R. Bettman, and Eric J. Johnson. (1992). "Behavioral Decision Research: A
Constructive Processing Perspective," Annual Review of Psychology 43, 87-131. Payne, John W., James R. Bettman, and Eric J. Johnson. (1993). The Adaptive Decision Maker.
Cambridge, England: Cambridge University Press. Plott, Charles R. (1996). "Rational Individual Behaviour in Markets and Social Choice Processes," In
Kenneth J. Arrow, Enrico Colombatto, Mark Perlman, and Christian Schmidt (eds.), The Rational Foundations of Economic Behavior. New York: St. Martins Press. Posovac, StevenS., David M. Sanbonmatsu, and Russell H. Fazio. (1997). "Considering the Best Choice: Effects of the Salience and Accessibility of Alternatives on Attitude-Decision Consistency," Journal of Personality and Social Psychology 72, 253-261. Rabin, Matthew. (1998). "Psychology and Economics," Journal of Economic Literature 36, 11-46.

270

PAYNE, BETTMAN AND SCHKADE

Read, Daniel and George Loewenstein. (1995). "Diversification Bias: Explaining the Discrepancy in Variety Seeking Between Combined and Separated Choices," Journal of Experimental Psychology: Applied 1, 34-49.
Russell, Milton. (1990). "The Making of Cruel Choices." In P. Brett Hammond and Rob Coppock (eds.), Valuing Health Risks, Costs and Benefits for Environmental Decision Making: Report of a Conference. Washington, DC: National Academy Press.
Russo, J. Edward. (1977). "The Value of Unit Price Information," Journal of Marketing Research 14, 193-201.
Russo, J. Edward and Paul J. H. Schoemaker. (1989). Decision Traps. New York: Fireside. Schkade, David A. and John W. Payne. (1994). "How People Respond to Contingent Valuation
Questions: A Verbal Protocol Analysis of Willingness-to-Pay for an Environmental Regulation," Journal of Environmental Economics and Management 26, 88-109. Schoemaker, Paul J. H. (1991). "When and How to Use Scenario Planning: A Heuristic Approach with Illustration," Journal of Forecasting 10, 549-564. Schuman, Howard and Stanley Presser. (1981). Questions and Answers in Attitude Surveys: Experiments on Question Form, Wording, and Context. New York: Academic Press. Schwarz, Norbert. (1996). Cognition and Communication: Judgmental Biases, Research Methods, and the Logic of Conversation. Mahwah, NJ: Lawrence Erlbaum. Sen, Amartya. (1997). "Maximization and the Act of Choice," Econometrica 65, 745-779. Shepard, Roger N. (1964). "On Subjectively Optimum Selection among Multiattribute Alternatives." In Maynard W. Shelley and Glenn L. Bryan (eds.), Human Judgments and Optimality. New York: Wiley. Simmons, Carolyn J., Barbara A. Bickart, and John G. Lynch, Jr. (1993). "Capturing and Creating Public Opinion in Survey Research," Journal of Consumer Research 20, 316-329. Simon, Herbert A. (1955). "A Behavioral Model of Rational Choice," Quarterly Journal ofEconomics 69, 99-118. Slovic, Paul. (1972). "From Shakespeare to Simon: Speculations-and Some Evidence-About Man's Ability to Process Information," Oregon Research Institute Bulletin 12. Slovic, Paul. (1995). "The Construction of Preference," American Psychologist 50, 364-371. Smith, V. Kerry and William Desvousges. (1987). "An Empirical Analysis of the Economic Value of Risk Changes," Journal of Political Economy 95, 89-114. Sudman, Seymour, Norman M. Bradburn, and Norbert Schwarz. (1996). Thinking About Answers: The Application of Cognitive Processes to Survey Methodology. San Francisco: Jossey-Bass. Sunstein, Cass R. (1990). "Preferences and Politics," Philosophy and Public Affairs 20, 3-34. Tversky, Amos. (1996). "Contrasting Rational and Psychological Principles in Choice." In Richard J. Zeckhauser, Ralph L. Keeney, and James K. Sebenius (eds.), Wzse Choices: Decisions, Games, and Negotiations. Boston: Harvard Business School Press. Tversky, Amos, Shmuel Sattath, and Paul Slovic. (1988). "Contingent Weighting in Judgment and Choice," Psychological Review 95, 371-384. Urban, Glen L., John R. Hauser, William J. Qualls, Bruce D. Weinberg, Jonathan D. Bohlmann, and Roberta A. Chicos. (1997). "Information Acceleration: Validation and Lessons from the Field," Journal of Marketing Research 34, 143-153. Von Winterfeldt, Detlof and Ward Edwards. (1986). Decision Analysis and Behavioral Research. Cambridge, England: Cambridge University Press. Wilson, Timothy D. and Jonathan W. Schooler. (1991). "Thinking Too Much: Introspection Can Reduce the Quality of Preferences and Decisions," Journal of Personality and Social Psychology 60, 181-192. Wright, Peter L. and Mary Ann Kriewall. (1980). "State-of-Mind Effects on the Accuracy with Which Utility Functions Predict Marketplace Choice," Journal of Marketing Research 17, 277-293. Wright, Peter L. and Barton Weitz. (1977). "Time Horizon Effects on Product Evaluation Strategies," Journal of Marketing Research 14, 429-443. Yankelovich, Daniel. (1991). Coming to Public Judgment: Making Democracy Work in a Complex World. Syracuse, NY: Syracuse University Press.

Journal of Risk and Uncertainty, 19:1-3; 271-272 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Defensible Preferences and the Public: Commentary on "Measuring Constructed Preferences Towards a Building Code" by Payne, Bettman and Schkade

NORBERT SCHWARZ

nschwarz@umich.edu

Institute for Social Research, University of Michigan, Ann Arbor, Ml 48106-1248

The adoption of Payne et al.'s proposed building code for preference construction would indeed be likely to result in more "defensible" valuations-yet, unfortunately, more defensible valuations may not resolve the EPA administrator's problem. Suppose that research participants carefully consider the complex information presented by the researcher, including information they may otherwise never think of, make all the relevant trade-offs they may otherwise never make, and report valuations that clearly favor project A over project B. Based on this information, the administrator allocates scarce resources to project A-only to encounter an outcry of public protest. Chances are that the defensible valuations obtained under optimal conditions will often not be the valuations that the general public arrives at haphazardly, under less informed conditions, or in response to a public discourse driven by interest groups. The recommendation, "the more that measured preferences are to play a role in an important decision, e.g., a public policy decision, the greater weight should be given to the better constructed preferences" (p. 35), highlights a thorny issue of democratic process: Should we ignore citizens' preferences because we trust they wouldn't hold them if they only had thought about the issue more carefully, as evidenced by the defensibly constructed preferences reported by our research participants?
The archeological approach to preference assessment, geared towards "uncovering values that may be hidden but are assumed to exist" (p. 4) tries to describe the preference distribution "out there." Hence, survey researchers are worried about instrument effects that may "distort" citizen inputs. In contrast, the constructive approach to preference assessment deliberately uses features of the research instrument to guide respondents in the construction of "defensible" values, values that do not reflect the distribution of preferences in a population that was never exposed to the research instrument. An overwhelming body of psychological research documents that preferences are nearly always constructed, thus rendering the archeological project futile and lending credence to a constructive approach: When preferences are constructed anyway, shouldn't we ensure that their construction is defensible? Yet, a program that lends respondents a helpful hand in figuring

272

SCHWARZ

out what their input into a public decision process ought to be raises questions of democratic process that go far beyond psychological theorizing. These questions are compounded by the fact that most influences of the research instrument are subtle enough to escape respondents' awareness, moving responses in ways that cannot be achieved by explicit persuasive arguments (Schwarz, 1996).
There are no easy answers to these issues. Facing similar problems with regard to potential biases in survey questionnaires, some researchers have obtained the input of opposing interest groups to legitimate their research instruments (cf. Schuman, 1986). No matter how carefully balanced our instruments are, however, the "defensible preferences" obtained by following Payne et al.'s building code are likely to deviate from the preference distribution in the public at large. If more defensible preferences are also more defensible inputs into a public decision process is therefore not only a question of their architectural quality, but a value question of democratic process. Unfortunately, the latter may eventually cause the EPA administrator more nightmares than the former.

References
Schuman, Howard. (1986). "Ordinary Questions, Survey Questions, and Policy Questions," Public Opinion Quarterly 50, 432-442.
Schwarz, Norbert. (1996). Cognition and Communication: Judgmental Biases, Research Methods and the Logic of Conversation. Hillsdale, NJ: Erlbaum.

Journal of Risk and Uncertainty, 19:1-3; 273-275 (1999) © 1999 Kluwer Academic Publishers. Manufactured in The Netherlands.

Commentary on "Measuring Constructed Preferences: Towards a Building Code" by Payne, Bettman and Schkade

ROBIN GREGORY Decision Research, 1124 W 19th St., N. Vancouver V7P JZ9, Canada

rgregory@interchange.ubc.ca

Few would disagree with the basic premise of this paper: preferences are tough to express for items (goods, actions, policies, programs) that are novel or unfamiliar and better guidance is sorely needed to distinguish good decision processes from poor. Payne, Bettman, and Schkade are leaders in this search and their paper asks thoughtful questions that are designed to encourage discussion of this important topic. For this reason alone its publication merits close attention from a broad and interdisciplinary readership.
The paper draws its provocative title from the analogy that constructed preferences place the elicitator in the position of an architect, helping to build a preference expression in the course of assisting a respondent to complete a choice or valuation task. The building code therefore anticipates problems in the preference construction process and proposes remedies intended to enhance the quality of the resulting verbal or written expression. The length of the relevant set of judgmental problems and suggested remedies (shown in Figure 1), as well as the diversity of its contents, succeed in providing ample testimony to the difficulty of the challenge and the appeal of the paper's context and organization.
In other ways, however, the success of this paper is less obvious. The fundamental purpose of most building codes is to increase the safety and long-term satisfaction of those proceeding with a construction effort. How much better off is the EPA administrator or market manager, as described in the introduction, who reads this paper and seeks to adopt a constructed-preferences code?
A first question is: Who needs this code? Just as housing codes vary for high-rise offices vs. residences and are more important in areas prone to earthquakes or floods, preference-based codes presumably are more critical for certain types of complex or consequential decisions. The paper says only a little about when the code is most needed, and that guidance-when choice situations are novel and there is conflict across values-applies to many personal decisions and a high percentage of policy options. It's not clear, for example, what types of decisions should require the use of explicit trade-off techniques, such as the recommended swing-weighting procedure. When is it necessary to decompose more complex value judgments? Are individual decisions different from public policy choices, or deci-

274

GREGORY

sions with only near-term consequences different from those with impacts over time? Giving the topic of code enforcement more attention would lead to a closer linking of preference codes and actual decision problems.
A specific example of this concern is the discussion of people's tendency to avoid trade-offs, which is highlighted as a weakness in how individuals typically combine information. Several cognitive techniques are suggested for making value trade-offs explicit, ranging from the introduction of options to clarifying importance weights using multiattribute utility techniques. These suggestions are sound, but they ignore the more fundamental question: if trade-offs are so important to value expression and measurement, why are they so often neglected? It is worth recalling in this context that building inspectors are not universally loved; generally, they are more popular in the abstract than when they require someone to spend more of their money and time on their own house or office. Facing tough trade-offs can be difficult on many dimensions, and a successful building code for preferences will need to provide tools for addressing cognitive limits that pose problems to potential users and recognizing emotional and moral reasons for the avoidance of tradeoffs.
Learning also plays a key role in the construction of preferences, which suggests that the code might explicitly want to encourage processes that facilitate adaptive learning (a subject these authors know well). This point arises in the introductory discussion of expressed preferences, which include three components: stable values associated with the object being evaluated, a situation-specific component, and random error. Preference construction is said to be most important when the situational component is significant. What happens, however, to the balance among these three components if the choice task is repeated (e.g., evaluations of several risk policies are made over time)? Does the situational component quickly decline in importance, thereby allowing an individual's stable values to come to the fore? Would this be a good thing (i.e., are repeated judgments also higher quality judgments, as some experimental economists have suggested)? If so, when does learning to be a better decision maker in one context carry over to improved decision processes in other contexts?
Perhaps most difficult for incorporation into the building code are values packed with affect or values considered basic to our fundamental purpose (akin to Ralph Keeney's concept of "strategic" objectives). Are these values also subject to construction or are they somehow different and relatively immune to construction? Will an alternative framing or better decision technique facilitate re-consideration of a value that is basic to our sense of well-being? Or is there, as Daniel Kahneman has suggested, a set of "bedrock" values that may be resistant to construction? If so, is it right for an analyst to even try to reframe such values? The authors note the need to balance the insights of explicit tradeoffs against the "possible emotional costs" incurred by the respondents, but there is little in the paper to serve as a guide to analysts for knowing when to push on and when to back off.
Throughout, more examples would help to make the logic of the paper more clear. From a practical perspective, it also would be helpful if a short list could be

COMMENTARY

275

made of things that one should always do to make sure that the constructed house of preferences will stand. The discussion suggests that this list might contain steps such as identifying objectives, or considering a range of alternatives, or addressing trade-offs (incidentally, many benefit-cost studies would fail even this simple test!). If the specified steps were not taken, perhaps, then the resulting outcome (anything from an individual's decision to eat in a specific restaurant to a government's decision to fund a health-care plan) could and should be questioned because the preference-expression process failed to go through the minimum steps required by the code.
These comments are not intended to undermine the many accomplishments of this paper. To take the next steps in operationalizing a building code is a tall order. It is a tribute to this fine contribution by Payne, Bettman, and Schkade that the revolutionary concept of developing a workable code is even contemplated.

