Specification Tests for the Propensity Score
Pedro H. C. Sant’Anna∗

Xiaojun Song†

arXiv:1611.06217v2 [stat.ME] 7 Feb 2019

February 11, 2019

Abstract
This paper proposes new nonparametric diagnostic tools to assess the asymptotic validity of diﬀerent treatment eﬀects estimators that rely on the correct speciﬁcation of the
propensity score. We derive a particular restriction relating the propensity score distribution of treated and control groups, and develop speciﬁcation tests based upon it. The
resulting tests do not suﬀer from the “curse of dimensionality” when the vector of covariates
is high-dimensional, are fully data-driven, do not require tuning parameters such as bandwidths, and are able to detect a broad class of local alternatives converging to the null at
the parametric rate n−1/2 , with n the sample size. We show that the use of an orthogonal
projection on the tangent space of nuisance parameters facilitates the simulation of critical
values by means of a multiplier bootstrap procedure, and can lead to power gains. The ﬁnite
sample performance of the tests is examined by means of a Monte Carlo experiment and
an empirical application. Open-source software is available for implementing the proposed
tests.
JEL: C12, C31, C35, C52.
Keywords: Empirical Processes; Integrated Moments; Multiplier Bootstrap; Projection;
Treatment Eﬀects.

∗

Department of Economics, Vanderbilt University, VU Station B #351819, 2301 Vanderbilt Place, Nashville,
TN 37235-1819, USA. Email: pedro.h.santanna@vanderbilt.edu
†

Department of Business Statistics and Econometrics, Guanghua School of Management and Center for Statistical Science, Peking University, Beijing, 100871, China. Email: sxj@gsm.pku.edu.cn

1

1

Introduction

The propensity score, which is deﬁned as the conditional probability of receiving treatment given
covariates, is one of the most widely used tools for causal inference. Part of its popularity can be
credited to the seminal result of Rosenbaum and Rubin (1983): if the treatment assignment is
independent of the potential outcomes conditional on a vector of covariates, then one can obtain
unbiased and consistent estimators of diﬀerent treatment eﬀect measures by adjusting for the
propensity score alone, greatly reducing the dimensionality of the underlying problem. Several
methods that exploit this important insight are now an essential part of the applied researcher’s
toolkit. Examples include matching, see e.g. Rosenbaum and Rubin (1985), Heckman et al.
(1997) and Abadie and Imbens (2016); inverse probability weighting (IPW), see e.g. Rosenbaum
(1987), Hirano et al. (2003) and Donald and Hsu (2014); regression methods, see e.g. Hahn
(1998) and Firpo (2007); and many others. For literature reviews, see Heckman and Vytlacil
(2007) and Imbens and Wooldridge (2009).
Despite their popularity, a main concern of these methods is that the propensity score is
usually unknown, and therefore has to be estimated. Given the high dimensionality of available
covariates, researchers are usually coerced to adopt a parametric model for the propensity score
since nonparametric estimation methods suﬀer from the “curse of dimensionality”, implying that
the resulting treatment eﬀect estimators can have considerably poor properties, even for large
sample sizes. Such a common practice raises the important issue of model misspeciﬁcation.
Indeed, as shown by Frölich (2004), Millimet and Tchernis (2009), Huber et al. (2013) and
Busso et al. (2014), propensity score misspeciﬁcations can lead to misleading treatment eﬀect
estimates.
In this paper we propose new speciﬁcation tests for parametric propensity score models. Our proposal builds on the common practice of comparing the density of the propensity
score between treated and control groups to determine the covariate overlap region, see e.g.
Heckman, Ichimura, Smith and Todd (1998). However, instead of comparing conditional densities, we focus on comparing conditional cumulative distribution functions (CDFs). In particular,
we derive a restriction between the propensity score CDFs among treated and control groups
that gives information on overlapping1 , show that such a restriction is equivalent to a particular
inﬁnite number of unconditional moment conditions, and develop tests based upon it.
1 We thank an anonymous referee for making this suggestion.

2

In contrast to existing proposals, our tests are fully data-driven, do not require user-chosen
tuning parameters such as bandwidths, and are able to detect a broad class of local alternatives
converging to the null at the parametric rate n−1/2 , with n the sample size. Furthermore, our
tests do not suﬀer from the “curse of dimensionality” when the vector of covariates is of high
dimensionality, and have greater power than competing tests for many alternatives. Of course,
such power gains do not come without a cost: there exist some classes of alternative hypotheses
against which our tests have trivial power. Nonetheless, we believe that such a compromise is
reasonable since, as pointed out by Janssen (2000) and Escanciano (2009a), achieving reasonable
power over all possible directions seems hopeless.
The proposal closest to ours is Shaikh et al. (2009). Despite using a similar characterization
of the null hypothesis as Shaikh et al. (2009), our proposal greatly diﬀers from theirs. Whereas
Shaikh et al. (2009) adopts the local smoothing approach, see e.g. Hardle and Mammen (1993),
Zheng (1996), Fan and Li (1996) and Li and Wang (1998), we adopt the integrated conditional
moment (ICM) approach, see e.g. Bierens (1982, 1990), Bierens and Ploberger (1997), Stute
(1997) and Escanciano (2006a). As a consequence, our approach inherits some advantages of
ICM when compared to Shaikh et al. (2009). First, our tests do not require delicate bandwidth
choice, unlike Shaikh et al. (2009)’s test whose performance can be sensitive to it. Second, in
contrast with Shaikh et al. (2009), our approach has power against local alternatives converging
to the null at the parametric rate.
Another popular procedure to assess misspeciﬁcation of the propensity score model is to
use “balancing” tests. Initially proposed by Rosenbaum and Rubin (1985), these tests consist
of assessing if each covariate is independent of the treatment assignment, conditional on the
propensity score. This is often implemented examining whether moments (usually just the
mean) of the observable characteristics between the two “matched” or “weighted” groups are
the same; see e.g. Dehejia and Wahba (2002) and Smith and Todd (2005). One should bear
in mind that because “balancing” tests are usually based on a ﬁnite number of orthogonality
conditions, there are uncountably many directions of misspeciﬁcation that cannot be detected
with these tests. Furthermore, as shown by Lee (2013), balancing tests may have size distortions
due to the “multiple testing problem”, the failure to account for the estimation eﬀect of the
propensity score, and poor covariate overlap. Such drawbacks put at stake the reliability of
many of these procedures. Our proposal, on the other hand, does not suﬀer from these.
Our paper also contributes to the literature on ICM tests. What appears distinctive to
3

our approach is that (i) we exploit the dimension-reduction coming from our derived restriction between propensity score CDFs, and (ii) we acknowledge our lack of knowledge of the
“true” correct speciﬁcation of the propensity score, by means of an orthogonal projection onto
the tangent space of nuisance parameters. The result of (i) and (ii) is a test with improved
power properties, and with a simple bootstrap implementation. The power improvement due
to the dimension reduction has been noticed by Stute and Zhu (2002), Escanciano (2006a) and
Shaikh et al. (2009), whereas the power improvement due to the use of orthogonal projections
has been noticed in diﬀerent contexts, see e.g. Neyman (1959), and more recently, Bickel et al.
(2006) and Escanciano and Goh (2014). To the best of our knowledge, our proposal is the ﬁrst
to incorporate both procedures.
As mentioned above, our paper is related to the relatively scarce literature on projectionbased speciﬁcation tests, see e.g. Escanciano (2009b) and Escanciano and Goh (2014) for two
notable exceptions. Escanciano (2009b) proposes a simple bootstrap testing procedure for conditional moment restrictions that acknowledges speciﬁcally the fact that the nuisance parameters
are unknown and introduces the projection methodology, while Escanciano and Goh (2014)
propose a projection-based testing procedure for linear quantile regression using a related projection weight function. Our proposal builds on these papers, with the important diﬀerence
that our test statistics also exploit the dimension-reduction property of the propensity score.
The rest of the paper is organized as follows. In Section 2 we present the testing framework
and derive the restriction upon which our tests are based. The asymptotic properties of our
tests are established in Section 3. We next examine the ﬁnite sample properties of our tests
by means of a Monte Carlo study in Section 4. We provide an empirical illustration of our
procedures in Section 5. Section 6 concludes. Mathematical proofs are gathered in an appendix
at the end of the article.
Finally, all proposed tests discussed in this article can be implemented via open-source R
package pstest, which is freely available from GitHub (https://github.com/pedrohcgs/pstest).

2
2.1

Testing Framework
Background

Let D be a binary random variable that indicates participation in the program, i.e. D = 1 if
the individual participates in the treatment and D = 0 otherwise. Deﬁne Y (1) and Y (0) as the
4

potential outcomes under treatment and control, respectively. The realized outcome of interest
is Y = DY (1) + (1 − D) Y (0), and X is an observable d × 1 vector of pre-treatment covariates.
Denote the support of X by X ⊆Rd and the propensity score p (x) = P (D = 1|X = x). We

n
have a random sample (Yi , Di , Xi′ )′ i=1 of size n ≥ 1 from (Y, D, X ′ )′ . Throughout the rest of
this article, all random variables are deﬁned on a common probability space (Ω, A, P) .

The main goal in causal inference is to assess the eﬀect of a treatment D on the outcome of interest Y . The most popular parameters of interest include the average treatment
eﬀect, AT E = E [Y (1) − Y (0)], and the average treatment eﬀect on the treated, AT T =
E [Y (1) − Y (0) |D = 1]. Note that such parameters of interest depend on potential outcomes
Y (1) and Y (0) which cannot be jointly observed for the same individual, precluding estimating
AT E and AT T using their sample analogues. One of the most popular identiﬁcation strategies in policy evaluation that resolves such diﬃculty is to assume that selection into treatment
is solely based on observable characteristics, the so-called unconfoundedness setup, see e.g.
Rosenbaum and Rubin (1983). Formally, the unconfoundedness setup requires the following
assumptions:
Assumption 2.1 (Y (1) , Y (0)) ⊥
⊥ D|X.
Assumption 2.2 ∀x ∈ X , 0 < p (x) < 1.
As shown by Rosenbaum (1987), under Assumptions 2.1-2.2, AT E and AT T are identiﬁed
by

AT E = E



 
D
(1 − D)
−
Y
p (X) 1 − p (X)

E
and AT T =



p (X) (1 − D)
D−
1 − p (X)
E [D]

 
Y

,

respectively. This result motivates the two-step procedure in which one ﬁrst estimates the
propensity score, computes its estimated values p̂ (Xi ), and then uses the analogy principle to
estimate AT E and AT T , that is,
 
n 
X
(1 − Di )
Di
−
Yi ,
p̂ (Xi ) 1 − p̂ (Xi )
i=1
 

Pn
p̂ (Xi ) (1 − Di )
−1
Yi
n
Di −
i=1
1 − p̂ (Xi )
P
.
n−1 ni=1 Di

[
AT
E n = n−1

[
AT
Tn =

Alternatively, one could estimate AT E and AT T using propensity score matching, see e.g.
Rosenbaum and Rubin (1983), Heckman, Ichimura and Todd (1998) and Abadie and Imbens
5

(2016).
In order to ensure that such estimators are well-deﬁned and stable, it is important to
assess the overlap between the distribution of the propensity score among treatment and
control groups, i.e. to check whether the propensity score is bounded away from zero and
one, and if the support of the propensity score in both groups are nearly the same, see e.g.
Heckman, Ichimura, Smith and Todd (1998), Smith and Todd (2005), Crump et al. (2009) and
Khan and Tamer (2010). Following Heckman, Ichimura, Smith and Todd (1998), it is now routine to compare kernel density estimates of the propensity score among treated and control
samples to determine the common support region. In cases where there is strong overlap
one proceeds as described above, otherwise, one usually considers trimmed samples, see e.g.
Crump et al. (2009) and Sasaki and Ura (2018).
Although kernel density estimators are popular, they involve choosing tuning parameters
such as bandwidths and often suﬀer from boundary bias. Of course such inconveniences can
be easily avoided if one focuses on CDFs instead of densities. In the following we show that
propensity score overlap implies a particular set of restrictions between the CDFs of treated and
control groups, and that these restrictions can form the basis for testing the correct speciﬁcation
of propensity score models.
Assume that the propensity score p (X) has a density with respect to a dominating measure,
and that the density is bounded away from zero and inﬁnity uniformly over its support. The
following lemma builds on Shaikh et al. (2009) and formalizes the above discussion.
Lemma 1 Let α = P (D = 0) /P (D = 1) and assume that 0 < P (D = 1) < 1. If 0 < p (X) <
1 a.s., then

p (X)
1 {p (X) ≤ u} |D = 0 , ∀u ∈ [0, 1] .
E [1 {p (X) ≤ u} |D = 1] = α E
1 − p (X)


(2.1)

Furthermore, (2.1) holds if and only if
E [(D − p (X)) 1 {p (X) ≤ u}] = 0, ∀u ∈ [0, 1] .

(2.2)

Lemma 1 implies that, when the propensity score is correctly speciﬁed, one can expect
that the sample analogue of (2.1) should hold. Thus, (2.1) provides a graphical diagnostic
tool for propensity score misspeciﬁcation; see Lemma 3.2 of Sloczyński and Wooldridge (2018)
for a result related to (2.1). Perhaps more importantly, note that (2.2) provides an inﬁnite
number of simple unconditional moment restrictions that can be used to formally test whether
6

a parametric model for the propensity score is correctly speciﬁed or not.
Motivated from Lemma 1, we seek to test whether a parametric putative model for p (x) is
correctly speciﬁed based on
H0 : E[(D − q(X, θ 0 ))1{q(X, θ 0 ) ≤ u}] = 0 for some θ0 ∈ Θ and for all u ∈ Π,

(2.3)

where Θ ⊂ Rk , Π = [0, 1] is the unit interval, and q (X, θ) : X ×Θ 7→ [0, 1] is a family of
parametric functions known up to the ﬁnite dimensional parameter θ. Common speciﬁcations
for q (X, θ) in empirical applications are the Probit, Φ (X ′ θ) , and the Logit, Λ (X ′ θ), where
Φ (·) and Λ (·) are the normal and logistic link functions, respectively.
Note that (2.3) can be equivalently written as
H0 : E [D − q (X, θ 0 ) |q (X, θ 0 )] = 0 a.s. for some θ0 ∈ Θ,

(2.4)

see e.g. Stute (1997)2 . Thus, in order to assess H0 , one can either use the inﬁnite number of
unconditional moment restrictions in (2.3), or the conditional moment restriction in (2.4). In
this article we use (2.3) whereas Shaikh et al. (2009) exploits (2.4). More precisely, Shaikh et al.
(2009) consider a test statistic based on

V̂n (hn ) =

1
n (n − 1)

n
X

n
X

i=1 j=1,j6=i




 
   
−
q
X
,
θ̂
q
X
,
θ̂
j n
i n
1 
 εi θ̂n εj θ̂n ,
K
hn
hn

(2.5)

 


√
where εi θ̂n = Di − q Xi , θ̂n , θ̂n is a n−consistent estimator of θ 0 under H0 , hn is a

positive scalar bandwidth parameter converging to zero at a suitable rate as n → ∞, and K (·) is

a kernel function. Note that, in addition to the estimation of θ0 under H0 , Shaikh et al. (2009)’s
procedure requires local smoothing of the data, implying that its ﬁnite sample properties rely
on the adequate choice of the smoothing parameter hn , a task that is far from trivial in testing
problems. Since our approach is based on (2.3) and only involves unconditional expectations,
our testing procedure is free of tuning parameters such as bandwidth sequence hn .
Tests based on a continuum of unconditional moment restrictions such as (2.3) fall into the
ICM approach, see González-Manteiga and Crujeiras (2013) for a review. Nonetheless, our tests
have two main diﬀerences with respect to the standard ICM tests. First, (2.3) depends on X only
through the propensity score model under H0 , a one-dimensional (though unknown) function.
As a consequence, the ICM in (2.3) is insensitive to the dimension d of the explanatory variables
2 Alternative representations of H0 are also possible, see e.g. Bierens and Ploberger (1997), Escanciano (2006b)
and a previous version of this article.

7

X, avoiding the so-called “curse of dimensionality”. Second, in contrast to the standard ICM
tests, we explicitly acknowledge that θ0 is a nuisance parameter in testing (2.3) by proposing
to use orthogonal projections on the tangent space of nuisance parameters. As discussed in
the Introduction, the use of orthogonal projections leads to important advantages. In the
next subsection we describe how we construct such projection-based tests, paying particular
attention to the role played by the orthogonal projection; see also Escanciano (2009b) and
Escanciano and Goh (2014) for related results in diﬀerent contexts.
Remark 1 Although the identiﬁcation of treatment eﬀect parameters such as the AT E relies
on both Assumptions 2.1 and 2.2, the results in Lemma 1 (and the null hypothesis (2.3)) do
not involve outcome data and are therefore well motivated even when Assumption 2.1 may
not hold. This situation may arise in decomposition exercises, see e.g. Fortin et al. (2011)
for a review of decomposition methods in economics. With respect to Assumption (2.2), we
note that it allows propensity scores to be arbitrarily close to zero and one and hence it is
not very restrictive. In fact, given that the unconditional moment condition in (2.2) does not
involve random denominators, weak covariate overlap does not play a major role in our testing
procedure. However, weak covariate overlap may lead to irregular treatment eﬀect estimators,
see e.g. Khan and Tamer (2010).

2.2

Projection-based specification tests

Recall that εi (θ) = Di − q (Xi , θ) . For all u ∈ Π, deﬁne
Pn 1 {q(X, θ) ≤ u} = 1 {q(X, θ) ≤ u} − g ′ (X, θ)∆−1
n (θ) Gn (u, θ) ,

(2.6)

where g(x, θ) = ∂q(x, θ)/∂θ is the score function of q(x, θ),
n

1X
Gn (u, θ) =
g(Xi , θ)1 {q(Xi , θ) ≤ u} ,
n
i=1

and

n

∆n (θ) =

1X
g(Xi , θ)g′ (Xi , θ).
n
i=1

Given a random sample



n
(Di , Xi′ )′ i=1 ,

our test statistics are based on continuous functionals

of the projection-based empirical process R̂np (u),
n

R̂np (u)

n
o
1 X
εi (θ̂n )Pn 1 q(Xi , θ̂ n ) ≤ u ,
≡√
n
i=1

8

(2.7)

where θ̂n is a

√

n−consistent estimator for θ0 under H0 . Two popular examples of such func-

tionals are the Cramér-von Mises-type and Kolmogorov-Smirnov-type functionals,
CvMn =

Z

Π

R̂np (u)

2

n

Fn (du) =

i2
1 Xh p  
,
R̂n q Xi , θ̂n
n

(2.8)

i=1

KSn = sup R̂np (u) ,

(2.9)

u∈Π

respectively, where Fn (u) = n−1


(EDF) of q Xi , θ̂ n , 1 ≤ i ≤ n.



 
≤
u
is the empirical distribution function
1
q
X
,
θ̂
i n
i=1

Pn

At this point, one may wonder why our test statistics are based on the empirical process

R̂np (u) (2.7) instead of the usual sample analogue of (2.3),
n
n
o
1 X
R̂n (u) ≡ √
εi (θ̂ n )1 q(Xi , θ̂ n ) ≤ u) ,
n

(2.10)

i=1

i.e. the “unprojected” analogue of R̂np (u). To answer such a query, note that under H0 and
some weak regularity conditions given in Section 3.1, the unprojected process R̂n (u) can be
decomposed as
n

1 X
εi (θ 0 )1 {q(Xi , θ0 ) ≤ u)} −
R̂n (u) = √
n
i=1

√

n(θ̂n − θ0 )′ E [g(X, θ 0 )1 {q(X, θ 0 ) ≤ u)}] + op (1) , (2.11)

uniformly in u ∈ Π, see Lemma A.4 in the Appendix. The asymptotic representation in (2.11)
implies that the eﬀect of replacing θ0 by θ̂n is non-negligible, and therefore the asymptotic null
distributions of tests based on (2.10) are sensitive to the estimator θ̂n being used. As a consequence, for a given parametric speciﬁcation p (x) = q(X, θ 0 ), the asymptotic null distributions of
tests based on (2.10) will depend on whether one estimates θ0 using maximum likelihood (ML),
nonlinear least squares (NLS), or generalized method of moments (GMM), even though the
underlying speciﬁcation for the propensity score is the same across these estimation methods.
The projection-based process R̂np (u), on the other hand, avoids such drawback since
E [g(X, θ 0 )P1 {q(X, θ 0 ) ≤ u)}] ≡ 0

(2.12)

almost everywhere in u ∈ Π, where
P1 {q(X, θ) ≤ u)} = 1 {q(X, θ) ≤ u)} − g ′ (X, θ)∆−1 (θ) G (u, θ) ,

9

(2.13)

with
G(u, θ) = E [g(X, θ)1 {q(X, θ) ≤ u}] ,
and


∆ (θ) = E g(X, θ)g ′ (X, θ) .

The intuition behind (2.12) is simple. First, note that ∆−1 (θ) G (u, θ) is the vector of linear projection coeﬃcients of regressing 1 {q(X, θ) ≤ u} on g(X, θ). Thus, it follows that g(X, θ)′ ∆−1 (θ) G (u, θ)
is the best linear predictor of 1 {q(X, θ) ≤ u} given g(X, θ), and that (2.13) is nothing more than
the associated projection error, which is by deﬁnition orthogonal to g(X, θ). As a consequence
of (2.12), it follows that under some weak regularity conditions, uniformly in u ∈ Π,
p
R̂np (u) = Rn0
(u) + op (1) ,

where

n

1 X
p
εi (θ 0 )P1 {q(Xi , θ 0 ) ≤ u)} ,
Rn0
(u) = √
n

(2.14)

i=1

see Theorem 1 in Section 3.1. Thus,

R̂np (u)

is (asymptotically) invariant to the choice of estima-

tor θ̂n . Furthermore, as we discuss in Section 3.3, the above asymptotic representation of R̂np (u)
p
in terms of Rn0
(u) allows for a multiplier-type bootstrap procedure that greatly simpliﬁes the

computation of asymptotically valid critical values.
In summary, by focusing on the projection-based process R̂np (u) instead of the more traditional process R̂n (u), our proposed test statistics are (a) invariant to the choice of estimator θ̂n ,
and (b) allow for simpliﬁed bootstrap implementation. In addition, tests based on R̂np (u) acknowledge that deviations in the direction of the score function g(x, θ) cannot be distinguished
from deviations within the parametric model, and therefore do not “waste” power in such directions. As a result, tests based on R̂np (u) can have higher power when compared to tests based
on R̂n (u), though in general none of them is strictly better than the other uniformly over the
space of alternatives. We defer the discussion of these power properties to Section 3.2.

3

Asymptotic theory

In this section, we establish the asymptotic behavior of the projection-based empirical process
R̂np (u) under the null hypothesis H0 , under the ﬁxed alternative hypothesis H1 , which is the
negation of (2.3), and under a sequence of local alternatives H1n that converges to H0 at the

10

parametric rate n−1/2 , n being the sample size. We also characterize classes of alternative
hypotheses against which our tests have no power, and argue that such classes are rather
exceptional. Finally, we show that critical values can be computed with the assistance of a
multiplier-type bootstrap that is easy to implement.

3.1

Asymptotic null distribution

The asymptotic null distributions of our tests are the limiting distributions of continuous functionals of R̂np (u) under H0 . To derive the asymptotic results, we adopt the following notation.
For a generic set G, let l∞ (G) be the Banach space of all uniformly bounded real functions on
G, equipped with the uniform metric kf kG ≡ supz∈G |f (z)|. We study the weak convergence of
R̂np (u) and its related processes as elements of l∞ (Π), where Π ≡ [0, 1]. Let “⇒” denote weak
convergence on (l∞ (Π) , B∞ ) in the sense of J. Hoﬀmann-Jφrgensen, where B∞ denotes the
corresponding Borel σ-algebra - see e.g. Deﬁnition 1.3.3 in van der Vaart and Wellner (1996).
We assume the following regularity conditions. Let Θ0 be an arbitrarily small neighborhood
around θ0 such that Θ0 ⊂ Θ. For any d1 × d2 matrix A = (aij ), let ||A|| denote its Euclidean
norm, i.e. ||A|| = [tr(AA′ )]1/2 .
Assumption 3.1 (i) The parameter space Θ is a compact subset of Rk ; (ii) the true parameter
θ0 belongs to the interior of Θ; and (iii) θ̂ n − θ0 = Op (n−1/2 ).
Assumption 3.2 The parametric propensity score function q(x, θ) is twice continuously differentiable in Θ0 for each x ∈ X , with its first derivative g(x, θ) = ∂q(x, θ)/∂θ = (g1 (x, θ), . . . , gk (x, θ))′
satisfying E[supθ∈Θ0 ||g(X, θ)||] < ∞ and its second derivative satisfying E[supθ∈Θ0 ||∂g(X, θ)/∂θ||] <
∞. Furthermore, the matrix ∆(θ) ≡ E[g(X, θ)g ′ (X, θ)] is nonsingular in Θ0 .
Assumption 3.3 The function Fθ (u) = P(q(X, θ) ≤ u) satisfies supu∈Π |Fθ1 (u) − Fθ2 (u)| ≤
C||θ1 − θ2 ||, where C is a bounded positive number, not depending on θ 1 and θ2 .
Assumptions 3.1-3.3 are weaker than related conditions in the literature. For instance,


√ 
√ 
Assumption 3.1 only requires n θ̂n − θ0 = Op (1) , but does not require n θ̂n − θ0 to
admit an asymptotically linear representation. Assumption 3.2 is a condition concerning the

degree of smoothness of the propensity score q(x, θ), and is satisﬁed for standard parametric
models such as the Probit and the Logit speciﬁcations. It also only requires ﬁnite ﬁrst moment
of g(X, θ), instead of more than four moments as in Shaikh et al. (2009). Assumption 3.3 simply
imposes a Lipschitz type continuity condition on the CDF of the parametric propensity score.
11

Remark 2 Assumption 3.3 is used to prove that the class of functions F = {x 7→ 1 {q(x, θ) ≤ u} :
u ∈ Π, θ ∈ Θ} is Donsker, see Lemma A.2 in the Appendix. Such assumption is similar to condition (5.8) in Lee et al. (2011). Alternatively, if Fθ = {x 7→ q(x, θ) : θ ∈ Θ} is a VC class of
functions, the aforementioned Donsker result also follows even without Assumption 3.3, see e.g.
Example 2.1 in van der Vaart and Wellner (2007).
Next, we derive the asymptotic behavior of the projection-based empirical process R̂np (u)
under H0 . We do this in two steps. First, we show that, under H0 , R̂np (u) is asymptotically
p
equivalent, with respect to the supremum norm on Π, to the process Rn0
(u) given in (2.14).

From this result it follows that the weak convergence under H0 of the process R̂np (u) can be
p
conveniently established from that of Rn0
(u). More importantly, the limiting null behavior of

R̂np (u) does not depend on θ̂n nor how θ̂ n is obtained.
Theorem 1 Let Assumptions 3.1-3.3 hold. Then, under H0 , we have that
p
sup R̂np (u) − Rn0
(u) = op (1),

u∈Π

and
p
R̂np (u) ⇒ R∞
,
p
where R∞
denotes a Gaussian process with mean zero and covariance structure given by

K p (u1 , u2 ) = E [q(X, θ 0 ) (1 − q(X, θ 0 )) P1 {q(X, θ 0 ) ≤ u1 } P1 {q(X, θ 0 ) ≤ u2 }] .

(3.1)

Theorem 1 and the continuous mapping theorem (CMT), see e.g. Theorem 1.3.6 in van der Vaart and Wellne
(1996), yield the asymptotic null distributions of continuous functionals of R̂np (u), including the
test statistics CvMn and KSn given in (2.8) and (2.9), respectively.
Corollary 1 Under the assumptions of Theorem 1 and H0 , for any continuous functional Γ(·)
from l∞ (Π) to R, we have
d

p
Γ(R̂np ) −
→ Γ(R∞
).

Furthermore,
d

CvMn −
→ CvM∞ :=

Z

Π

p
|R∞
(u)|2 dFθ 0 (u),

where Fθ0 (u) = P (q (X, θ 0 ) ≤ u) denotes the cumulative distribution function of q (X, θ 0 ), and
d

p
(u)| .
KSn −
→ KS∞ := sup |R∞
u∈Π

12

Note that the integrating measure in CvMn is a random measure, but Corollary 1 shows
that the asymptotic distribution is not aﬀected by this fact. Further details can be found in
the Appendix A.

3.2

Asymptotic power

Now, we investigate the power properties of tests based on continuous functionals Γ(R̂np ), like
CvMn and KSn in (2.8) and (2.9), respectively. We consider ﬁxed alternatives, and a sequence
of local alternatives H1n that converges to H0 at the parametric rate n−1/2 .
3.2.1

Power against fixed alternatives

Next theorem analyzes the asymptotic properties of our tests under ﬁxed alternatives of the
type
H1 : E[(D − q(X, θ))1{q(X, θ) ≤ u}] 6= 0 for all θ ∈ Θ and for some u ∈ Π,

(3.2)

where Π = [0, 1] is the unit interval. Note that H1 is simply the negation of H0 in (2.3).
Theorem 2 Suppose Assumptions 3.1-3.3 hold. Then, under the fixed alternative hypothesis
H1 in (3.2), we have that
1
sup √ R̂np (u) − E [(p (X) − q (X, θ 0 )) P1 {q (X, θ 0 ) ≤ u}] = op (1) .
n
u∈Π
From Theorem 2, we see that test statistics of the form of Γ(R̂np ) are not consistent against all
ﬁxed alternative hypotheses in (3.2), but only those not collinear to the score function g(X, θ 0 ).
To see this, note that
E [(p (X) − q (X, θ 0 )) P1 {q (X, θ 0 ) ≤ u}] =
E [(p (X) − q (X, θ 0 )) 1 {q (X, θ 0 ) ≤ u}] −


E (p (X) − q (X, θ 0 )) g′ (X, θ 0 ) ∆−1 (θ0 ) G (u, θ 0 )
is equal to zero under (3.2) if p (X) − q (X, θ 0 ) and g(X, θ 0 ) are collinear almost surely. We do
not see this as a limitation. First, when one estimates θ 0 using the NLS method, the population
ﬁrst order condition for θ0 sets E [(D − q (X, θ 0 )) g′ (X, θ 0 )] = 0, implying that, for some u ∈ Π,
E [(p (X) − q (X, θ 0 )) P1 {q (X, θ 0 ) ≤ u}] = E [(p (X) − q (X, θ 0 )) 1 {q (X, θ 0 ) ≤ u}] 6= 0.

13

As a consequence, our projection-based tests would be consistent against all alternative hypotheses of the type of (3.2), avoiding the aforementioned problem.
Second, and perhaps more importantly, even when one does not use NLS to estimate θ0 , we
argue that the lack of power against alternatives collinear to the score function g(X, θ 0 ) is not a
main concern. As shown by Escanciano (2009a), every test based on ICM approach has trivial
local power against these alternatives, and as a consequence, the global power of all ICM tests
in the direction of the score function will also be low, see e.g. Strasser (1990). In fact, instead
of considering this as a limitation one may consider this property as a feature of our tests: by
acknowledging that such alternatives cannot be powerfully detected, our projection-based test
statistics do not waste power in such directions, and therefore may have higher power against
other, perhaps more important, alternatives; see Section 4 for an illustration.
The above discussion raises the question: are there other classes of ﬁxed alternative hypotheses that our speciﬁcation tests are not able to detect? As ﬁrst pointed out by Shaikh et al.
(2009), the answer is yes. Because our test statistics depend on X only through the propensity score q(X, θ 0 ), our tests will have trivial power against the class of misspeciﬁed propensity
scores, where
E [D − q (X, θ 0 ) |X] = p (X) − q (X, θ 0 ) 6= 0
in a set of positive probability, but
E [D − q (X, θ 0 ) |q (X, θ 0 )] = 0 a.s.,
where θ0 now is the probability limit of θ̂n . In other words, tests based on (2.3) (or equivalently
on (2.4)), will have trivial power against alternatives such that p (X) is diﬀerent from q (X, θ 0 )
but
E [p (X) |q (X, θ 0 )] = q (X, θ 0 ) a.s..

(3.3)

The leading case of such a class of alternatives is when the propensity score is correctly speciﬁed
for a subvector of X, but not for the entire vector X, see e.g. Shaikh et al. (2009). Given
the nonlinear nature of p (X), one may consider such a class of alternatives rather exceptional.
However, they can still arise in practice under some particular circumstances as we will illustrate
below.
Consider the case where X = (X1 , X2 ) and that both covariates are relevant for the propensity score, i.e., p (X) = p (X1 , X2 ). Suppose that a researcher considers a Probit model for

14

the p (·) but only included X1 as a covariate, i.e., the researcher assume the model q (X, θ 0 ) =
Φ (θ00 + θ01 X1 ), with Φ (·) the normal link function. Of course, p (X) 6= q (X, θ 0 ) since q (X, θ 0 )
only includes a subset of relevant covariates. Thus, in light of (3.3), our tests will have no power
if there exists θ0 = (θ 00 , θ 01 )′ ∈ Θ ⊂ R2 such that E [p (X1 , X2 ) |X1 ] = Φ (θ00 + θ01 X1 ) a.s..
The existence of such θ0 depends on the underlying conditional distribution of X2 given X1 ,
and also on the form of true unknown propensity score p (X1 , X2 ). For instance, assume that
the true propensity score is a Probit, e.g., p (X1 , X2 ) = Φ (X1 + X2 ), and that X2 given X1
follows a normal distribution with conditional mean µ (X1 ) and conditional variance σ 2 (X1 ).
In this case, we can show that
E [ Φ (X1 + X2 )| X1 ] = Φ

X + µ (X1 )
p1
1 + σ 2 (X1 )

!

.

Thus, if µ (X1 ) = a + bX1 and σ 2 (X1 ) = c for some constants a, b and c with b 6= −1 and c > 0,
we have that

1+b
a
+√
X1 .
=Φ √
E [ Φ (X1 + X2 )| X1 ] = Φ
1+c
1+c
′
√
√
Thus, in this particular case such θ0 does exist with θ0 ≡ a/ 1 + c, (1 + b)/ 1 + c and our


X1 + a + bX1
√
1+c





tests would have trivial power. On the other hand, if µ (X1 ) is nonlinear in X1 and σ 2 (X1 )

is a nontrivial function of X1 , no such θ0 exists and therefore (3.3) is ruled out. Thus, it is
clear that the conditional distribution of X2 given X1 plays an important role in the “empirical
relevance” of alternative hypotheses like (3.3).
The role played by the functional form of the true propensity score in the “empirical relevance” of (3.3) can be illustrated by assuming that the true propensity score is a Logit instead
of a Probit, e.g., p (X1 , X2 ) = Λ (X1 + X2 ), with Λ(·) the logistic link function. In this case,
because of the nonlinear nature of Λ, there exists no θ0 ∈ Θ such that E [Λ (X1 + X2 ) |X1 ] =
Φ (θ01 + θ01 X1 ) a.s., ruling out (3.3)3 .
In summary, the above discussion shows that our projection-based tests are consistent
against a broad range of alternatives, though not all. This is the main drawback of our proposal when compared to the standard ICM speciﬁcation tests. However, in our simulations that
follow we show that, for the alternatives considered, our projection-based tests are the best or
comparable to the best tests in terms of power in ﬁnite samples. Thus, from a practical point

3 In practice, however, the power against this particular alternative can be low since the Logit and Probit
specifications are relatively “close” to each other.

15

of view, the beneﬁts of using our procedure can outweigh the costs in many relevant situations.
3.2.2

Power against local alternatives

Next, we study the performance of our projection-based tests under a sequence of local alternative hypotheses converging to the null at the parametric rate n−1/2 given by
H1n : E [D − q(X, θ 0 )|q(X, θ 0 )] =

r (q(X, θ 0 ))
√
n

a.s.

(3.4)

for some θ0 ∈ Θ, where r (q(X, θ 0 )) represents directions of departure from H0 , and n−1/2
indicates the rate of convergence of H1n to H0 . The function r : [0, 1] → R is required to satisfy
the following assumption.
Assumption 3.4 The function r(q) is continuous in q and satisfies E|r(q(X, θ 0 ))| < ∞.
Theorem 3 Suppose Assumptions 3.1 -3.4 hold. Then, under the local alternatives H1n given
by (3.4), we have
p
R̂np (u) ⇒ R∞
+ ∆r ,
p
where R∞
is the same Gaussian process as defined in Theorem 1, and ∆r is a deterministic

shift function given by
∆r (u) ≡ E [r (q (X, θ 0 )) P1 {q(X, θ 0 ) ≤ u}] .
Note that, in general, the deterministic shift function ∆r (u) 6= 0 for at least some u ∈ Π,
implying that tests based on continuous even functionals of R̂np (·) will have non-trivial power
against local alternatives of the form in (3.4). A situation in which our tests will have trivial
local power against such alternatives is when directions r(q (x, θ0 )) are a linear combination
of score function g(x, θ 0 ), i.e. r(q(x, θ 0 )) = βg(x, θ 0 ) for some β. In such a case, the limiting
distribution of R̂np (u) under H0 and H1n is the same so that H1n cannot be detected. On the
other hand, note that tests based on the local smoothing approach such as Shaikh et al. (2009)
are not able to detect alternatives of the form (3.4).

3.3

Computation of critical values

From the above theorems, we see that the asymptotic distribution of continuous functionals
 
Γ R̂np depend on the underlying data generating process and of course on Γ (·) itself. Fur-

thermore, the complicated covariance structure of K p (·, ·) given in (3.1) does not allow for a
16

p
simple representation of R∞
in terms of a well-known distribution-free Gaussian process for

which critical values are readily available. To overcome this problem, we propose to compute
critical values with the assistance of a multiplier bootstrap. The proposed procedure has good
theoretical and empirical properties, is computationally easy to implement, and does not require
computing new parameter estimates at each bootstrap replication.
More precisely, in order to estimate the critical values, we propose to approximate the
asymptotic behavior of R̂np (u) by that of
n


o
n 
1 X
εi (θ̂ n )Pn 1 q Xi , θ̂ n ≤ u Vi ,
R̂np∗ (u) ≡ √
n

(3.5)

i=1

where {Vi }ni=1 is a sequence of i.i.d. random variables with zero mean, unit variance and bounded
support, independent of the original sample {(Di , Xi′ )′ }ni=1 . A popular example involves i.i.d.
√
√
Bernoulli variates {Vi } with P (V = 1 − κ) = κ/ 5 and P (V = κ) = 1 − κ/ 5, where κ =
√

5 + 1 /2, as suggested by Mammen (1993).
 
With R̂np∗ (u) at hands, the bootstrapped version of our test statistics Γ R̂np is simply


given by Γ R̂np,∗ . For instance, the bootstrapped versions of CvMn and KSn in (2.8) and
(2.9), respectively, are given by

n

CvMn∗ =

i2
1 X h p∗  
,
R̂n q Xi , θ̂ n
n
i=1

KSn∗ = sup R̂np∗ (u) .
u∈Π

The asymptotic critical values are then estimated by
o
o

n 
n
Γ ∗
∗
cn,α ≡ inf cα ∈ [0, ∞) : lim Pn Γ R̂np,∗ > cα = α ,
n→∞

∗

where Pn means bootstrap probability, i.e. conditional on the original sample {(Di , Xi′ )′ }ni=1 . In
 

Γ ∗
practice, cn,α is approximated as accurately as desired by Γ R̂np,∗
, the B (1 − α) −th
B(1−α)

 oB

n 
of Γ R̂np,∗ .
order statistic from B replicates
Γ R̂np,∗
l l=1

The next theorem establishes the asymptotic validity of the multiplier bootstrap procedure

proposed above.
Theorem 4 Assume Assumptions 3.1-3.3. Then,
p
R̂np∗ ⇒ R∞
∗

a.s.,

p
where R∞
is the Gaussian process defined in Theorem 1, and ⇒ denotes the weak convergence
∗

17

under the bootstrap law, i.e. conditional on the original sample {(Di , Xi′ )′ }ni=1 . Additionally,


d
p
) a.s. under
for any continuous functional Γ(·) from l∞ (Π) to R, we have Γ R̂np,∗ → Γ (R∞
∗

the bootstrap law.

4

Monte Carlo simulation study

In this section, we conduct a series of Monte Carlo experiments in order to study the ﬁnite
sample properties of our proposed projection-based tests. In particular, we compare our Cramérvon Mises and Kolmogorov-Smirnov tests CvMn and KSn given in (2.8) and (2.9) to (i) the
Shaikh et al. (2009)’s test,
Tn (hn ) =
where V̂n (hn ) is given in (2.5) and
Σ̂n (hn ) =

2
n (n − 1)

n
n
X
X

i=1 j=1,j6=i

r

1/2

n − 1 nhn V̂n (hn )
q
,
n
Σ̂n (hn )




 
   
−
q
X
,
θ̂
q
X
,
θ̂
j
n
i
n
1 2
2

K
εi θ̂n ε2j θ̂n ;
hn
hn

the analogues of CvMn and KSn based on either (ii) the unprojected process R̂n (u) given in
(2.10)4 , or on (iii) the traditional empirical process
n

1 X
R̂ntrad (x) = √
εi (θ̂n )1 {Xi ≤ x} .
n

(4.1)

i=1

We also compare our proposal with (iv) balancing tests based on the normalized IPW estimators
n

1X
j
[
AT E n X =
n
i=1



w0,i
w1,i
−
w̄1,n w̄0,n



Xij ,

(4.2)






where w1,i = Di /q Xi , θ̂ n , w0,i = (1 − Di ) / 1 − q Xi , θ̂ n , w̄d,n is the sample mean of wd,i ,

d = {0, 1}, and X j is the j-th element of d-dimensional vector X = (X1 , . . . , Xd )′ . We consider
two diﬀerent test statistics for the balancing tests: the Wald test, and the maximum of the d
marginal two-sided t-tests.
Critical values (CVs) for the CvMn and KSn tests are obtained using the multiplier bootstrap procedure described in Section 3.3, whereas for the ICM tests in (ii) and (iii) we use
the bootstrap procedure described in Stute et al. (1998). For Tn (hn ) test, we use one-sided
CVs from the standard normal distribution. CVs for the Wald test are from the chi-squared
4 For conciseness, we do not discuss the asymptotic properties of tests based on the unprojected empirical process
R̂n (u) in the main text. However, most of the asymptotic properties follow from arguments analogous to those
we used to study R̂np (u).

18

distribution with d degrees of freedom. For the t-test, we consider Bonferroni corrected CVs
based on the standard normal distribution. Note that the Bonferroni correction is necessary to
address the multiple testing problem.
We consider sample sizes n equal to 100, 200, 400, 600, 800 and 1, 000. For each design, we
consider 1, 000 Monte Carlo experiments. The {Vi }ni= used in the bootstrap implementations
√
√
are independently generated as V with P (V = 1 − κ) = κ/ 5 and P (V = κ) = 1 − κ/ 5,
√

where κ =
5 + 1 /2, as proposed by Mammen (1993). The bootstrapped critical values are
approximated using B = 999 bootstrap replications. To compute Shaikh et al. (2009)’s test, we
use the standard normal kernel
 2
u
1
.
K (u) = √ exp −
2
2π
Following Shaikh et al. (2009), the bandwidth sequence hn is chosen to be equal to cn−1/8 for c
equal to 0.01, 0.05, 0.10 and 0.15. We choose diﬀerent c’s to assess how sensitive Shaikh et al.
(2009)’s test may be with respect to the bandwidth hn .

4.1

Simulation 1

We ﬁrst consider the following data generating processes (DGPs):
DGP 1. D ∗ =

(X1 + X2 )
− ε;
3

(X1 + X2 + X1 X2 )
− ε;
3

X12 − X22
∗
DGP 3. D = −0.2 +
− ε;
2

DGP 2. D ∗ = −1 +

DGP 4. D ∗ =

(0.1 + X1 /3)
− ε;
exp ( (X1 + X2 )/ 3)

DGP 5. D ∗ =

(−0.8 + (X1 + X2 + X1 X2 ) /3)
− ε.
exp ( 0.2 + (X1 + X2 )/ 3)

√
For each of these ﬁve DGPs, D = 1 {D ∗ > 0} , ε ⊥
⊥ (X1 , X2 ), where X1 = Z1 , X2 = (Z1 + Z2 ) / 2,
and Z1 , Z2 , and ε are independent standard normal random variables. All the DGPs considered
have the propensity score bounded away from zero and one. Finally, for each of these DGPs we
consider the potential outcomes
Y (1) = 2m1 (X) + u (1)

and

19

Y (0) = m1 (X) + u (0) ,

where m1 (X) = 1 + X1 + X2 , u (1) and u (0) are independent normal random variables with
mean zero and variance 0.1. The observed outcome is Y = DY (1) + (1 − D) Y (0), and the true
AT E is 1. Although these outcome equations are not necessary to assess the size and power
properties of the tests, they can be used to assess the utility of our proposed tests to distinguish
between “good” and “bad” estimates of the AT E.
Let X = (1, X1 , X2 )′ . For DGP 1 − DGP 5, the H0 considered is



H0 : ∃θ0 = (β 0 , β 1 , β 2 )′ ∈ Θ : E D|Φ X ′ θ0 = Φ X ′ θ0 a.s.,
where Φ(·) is the cumulative distribution function (CDF) of the standard normal distribution.
We estimate θ0 using the Probit ML, i.e.
θ̂n = arg max
θ∈Θ

n
X

Di ln Φ Xi′ θ

i=1



+ (1 − Di ) ln 1 − Φ Xi′ θ



.

Clearly, DGP 1 falls under H0 , whereas DGP 2 − DGP 5 fall under H1 . Note that D follows a
heteroskedastic Probit model in DGP 4 and DGP 5.
The simulation results are presented in Table 1. We report empirical rejection frequencies
at the 5% signiﬁcance level. Results for 10% and 1% signiﬁcance levels are similar and are
available upon request. We also report the bias of the normalized IPW estimator
n

1X
\
AT
En =
n
i=1



w0,i
w1,i
−
w̄1,n w̄0,n



Yi ,

(4.3)

and the average length and coverage of its estimated 95% conﬁdence interval based on its
asymptotically normal approximation (assuming that the propensity score model is correctly
speciﬁed).
We ﬁrst analyze the size of our test. From the results of DGP 1, we ﬁnd that the actual
ﬁnite sample size of both KSn and CvMn tests is close to their nominal size, even when the
sample size is as small as 100. The same holds for the other ICM-type tests. On the other
hand, we ﬁnd that Shaikh et al. (2009)’s test is, in general, conservative, and sensitive to the
choice of bandwidth. For instance, when c = 0.15, the empirical size is close to zero even with
n = 1, 000. On the other hand, with c = 0.01, the empirical size of Shaikh et al. (2009)’s
test is closer to the nominal value. In terms of traditional balancing tests, we ﬁnd that Wald
test and Bonferroni-corrected t-test do not control size. Such a drawback is due to the random
denominator being relatively close to zero: when we trim observations with estimated propensity
score outside the [0.05, 0.95] range, we ﬁnd that classical balancing tests can control size. We
20

report these results in Table B.1 in the Appendix B. Finally, note that when the propensity score
\
is correctly speciﬁed, the bias of the AT
En estimator in (4.3) is small, the length of the 95%
conﬁdence interval reduces as sample size increases, but the coverage probability is smaller than
its nominal value even when n = 1, 000. However, as we show in Table B.1 in the Appendix B,
such undercoverage disappears when we trim observations with extreme estimated propensity
scores.
Note that when the propensity score is misspeciﬁed in DGP 2 − DGP 5, the AT E estimator
(4.3) can be severely biased, and its conﬁdence interval can be “too small” when the propensity score is misspeciﬁed, leading to severe undercoverage5 . Thus, detecting propensity score
misspeciﬁcations can prevent misleading inference about AT E. Our proposed KSn and CvMn
tests perform admirably well in such a task, particularly in moderate sample sizes. In these
scenarios, CvMn performs slightly better than KSn . Looking at the results from Shaikh et al.
(2009)’s test, we note that bandwidth choices can play an important role, and the choice of the
“best” bandwidth hn via c varies across DGPs. Perhaps, what is more important to emphasize
in terms of power is that in all alternative hypotheses and sample sizes analyzed, our projection based tests have higher power than Shaikh et al. (2009)’s test, regardless of the bandwidth
choice. Our proposed tests also dominate the balancing tests, as balancing tests have little to
no power in all DGPs considered but DGP 2, even with n = 1, 000. Finally, the results in Table
1 show that projection-based tests perform either better or as well as the other ICM tests in
the DGPs considered. Among the considered DGPs, DGP 3 is the only one where some existing
speciﬁcation testing has higher power than our proposed procedure. For this particular DGP,
ICM type tests KSntrad and CvMntrad based on (4.1) have higher power than our proposed tests
when sample size n is large. Given the discussion in Section 3.2 and the fact that none of the
ICM tests are strictly better than the others uniformly over the space of alternatives, such a
ﬁnding does not come with a surprise.

4.2

Simulation 2

In this simulation, we push forward the dimensionality of the covariates to see how our proposed
tests and the other alternative tests perform in scenarios with 10 continuous covariates. To

5 In DGP 3, the bias, confidence interval length, and coverage of the AT E estimator are good. However, it is
important to have in mind that we consider only one particular DGP for the AT E, and that such “robust”
results may not translate to other DGPs.

21

Table 1: Monte Carlo results under designs DGP 1-DGP 5

22

DGP

n

CvMn

KSn

Tn (0.01)

Tn (0.05)

Tn (0.10)

Tn (0.15)

Max-t

W ald

CvMnunp

KSnunp

CvMntrad

KSntrad

Bias

CI length

Coverage

1
1
1
1
1
1
2
2
2
2
2
2
3
3
3
3
3
3
4
4
4
4
4
4
5
5
5
5
5
5

100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000

5.00
4.40
5.10
5.20
5.30
5.00
28.90
61.50
90.60
98.90
99.70
100.00
32.80
59.10
69.20
79.70
81.00
83.30
15.20
35.00
64.70
85.30
92.50
96.50
11.00
16.40
26.70
35.80
45.00
56.00

5.60
4.60
5.80
5.70
4.30
5.90
26.40
55.30
84.30
96.30
99.10
100.00
26.10
49.90
64.10
74.60
77.70
81.30
12.20
27.00
53.80
75.40
86.70
93.80
7.80
13.70
23.00
32.80
39.30
49.20

4.90
4.90
4.10
4.30
4.50
4.50
6.70
7.30
18.50
33.60
50.40
67.40
6.20
18.70
38.40
56.60
63.40
71.00
4.40
5.10
8.10
13.40
19.00
29.80
5.00
4.90
5.90
5.30
5.70
7.80

2.30
2.30
2.40
1.80
1.50
2.90
7.60
17.30
44.60
66.60
83.50
93.90
5.30
16.50
28.60
40.90
42.30
48.90
1.50
7.30
17.20
33.00
50.00
63.20
2.20
2.70
5.70
8.70
11.80
17.00

0.80
0.60
1.10
0.70
0.50
1.20
7.70
20.80
50.40
74.00
89.20
96.10
1.50
6.40
9.20
14.70
15.20
17.70
1.10
6.50
21.10
39.00
60.40
74.00
1.30
2.30
4.70
9.90
14.30
20.70

0.20
0.20
0.40
0.40
0.40
0.80
6.20
18.70
50.40
75.80
89.70
96.80
0.40
1.10
2.40
3.80
4.10
3.90
0.50
3.50
17.00
35.70
59.40
75.40
0.60
1.60
3.90
8.40
12.90
19.30

8.90
8.80
12.10
13.20
13.80
13.50
14.00
13.80
41.60
75.50
88.40
95.80
0.10
0.00
0.00
0.00
0.00
0.10
0.30
1.10
4.10
8.10
9.50
12.80
22.40
29.10
24.10
18.50
17.50
16.60

6.90
8.70
12.40
14.50
16.30
15.10
26.80
27.00
45.00
75.50
89.50
96.00
0.10
0.00
0.00
0.00
0.00
0.00
0.30
0.60
2.20
5.20
7.40
10.00
22.40
32.40
29.60
24.50
21.80
21.70

5.40
4.00
4.70
5.00
4.90
5.10
17.90
41.60
79.80
94.90
99.10
99.90
33.60
59.00
69.70
80.10
81.30
82.90
15.60
37.50
70.30
88.30
94.80
97.60
9.20
13.80
23.50
35.20
44.00
57.20

5.00
4.50
5.30
5.30
4.50
4.90
18.70
42.60
74.80
93.40
98.00
99.90
25.00
49.60
63.70
75.30
77.80
81.00
12.00
26.80
51.20
72.50
85.00
92.00
6.90
9.70
15.80
21.70
28.60
38.30

5.40
4.40
4.70
4.60
6.20
5.70
16.10
35.50
71.50
89.80
97.70
99.40
15.90
40.80
83.00
98.70
99.70
100.00
20.00
42.00
74.60
90.50
96.70
99.20
9.20
13.00
22.70
32.40
38.80
52.40

6.10
3.90
4.80
5.50
4.70
5.00
16.80
30.50
60.60
82.80
93.80
98.40
18.10
38.80
80.30
97.10
99.70
100.00
11.40
25.10
46.30
69.90
83.70
90.40
5.70
7.80
11.10
15.50
19.10
27.00

0.11
0.02
0.01
0.01
0.01
0.01
-1.76
-2.75
-3.50
-3.95
-4.14
-4.30
0.01
-0.01
0.00
0.00
0.00
0.00
0.17
0.16
0.16
0.16
0.16
0.16
0.04
-0.31
-0.72
-0.93
-1.02
-1.06

1.36
1.04
0.76
0.64
0.56
0.52
6.48
6.39
5.97
5.84
5.78
5.44
0.87
0.57
0.39
0.32
0.27
0.24
0.90
0.60
0.42
0.34
0.29
0.26
2.70
2.74
3.04
3.26
3.23
3.21

85.60
90.00
90.80
87.20
89.50
90.70
89.00
78.70
29.30
9.80
3.60
0.80
95.90
94.70
94.70
95.70
96.20
95.80
90.70
80.60
69.20
55.50
41.90
32.50
68.30
68.00
72.60
77.40
77.80
76.30

Note: Simulations based on 1,000 Monte Carlo experiments. “CvMn ” and “KSn ” stand for our proposed Cramér-von Mises and Kolmogorov-Smirnov tests. “Tn (c)” stands for
Shaikh et al. (2009)’s test, with bandwidth hn = cn−1/8 . “Max-t” and “W ald” stand for, respectively, the Bonferroni-corrected Max-t-test, and Wald balancing test based on

[
AT
E n X j deﬁned in (4.2). “CvMnunp ” and “KSnunp ” are the Cramér-von Mises and Kolmogorov-Smirnov tests based on the unprojected empirical process R̂n (u) deﬁned in (2.10),
whereas “CvMntrad ” and “KSntrad” are deﬁned analogously, but based on R̂ntrad (x) as deﬁned in (4.1). Finally, “Bias”, “CI length’, and “Coverage” stands for the average simulated
\
bias, estimated 95% conﬁdence interval length, and 95% coverage probability for the AT E estimator AT
En as deﬁned in (4.3). All entries are proportions of rejections at 5% level,
in percentage points, except “Bias” ,“CI length”, and “Coverage” (measure in percentage points), which are as described above. See the main text for further details.

investigate further this issue, we consider the following ﬁve DGPs:
P10
j=1 Xj
∗
− ε, ;
DGP 6. D = −
6
P10
X1 X2
j=1 Xj
∗
DGP 7. D = −1 −
+
− ε, ;
10
2
P10
P
X1 5k=2 Xk
j=1 Xj
∗
DGP 8. D = −1 −
+
− ε, ;
10
4
P10
P10
X2
j=1 Xj
∗
+ k=1 k − ε;
DGP 9. D = −1.5 −
6
10
P5
−0.1 + 0.1 j=1 Xj
 − ε, ,

DGP 10. D ∗ =
P
exp −0.2 10
k=1 Xj
where X1 , X2 and ε are deﬁned as before, {Xi }10
k=3 are independent standard normal random
variables, D = 1 {D ∗ > 0} , and ε ⊥
⊥ X, with X = (1, X1 , X2 , . . . , X10 )′ . For each of these DGPs
we consider the potential outcomes
Y (1) = 2m2 (X) + u (1)
where m2 (X) = 1 +

P10

j=1 Xj ,

and

Y (0) = m2 (X) + u (0) ,

u (1) and u (0) are independent normal random variables with

mean zero and variance 0.1. The observed outcome is Y = DY (1) + (1 − D) Y (0), and the true
AT E is 1.
For DGP 6 − DGP 10, the H0 considered is



H0 : ∃θ0 = (β 0 , β 1 , β 2 , . . . , β 10 )′ ∈ Θ : E D|Φ X ′ θ0 = Φ X ′ θ0 a.s..

(4.4)

We estimate θ 0 by ML. Note that DGP 6 falls under H0 , whereas DGP 7-DGP 10 fall under H1 .
The simulation results for DGP 6-DGP 10 are presented in Table 2.
As before, we ﬁrst discuss the size properties of the tests. From the results of DGP 6, we
ﬁnd that KSn and CvMn tests are oversized when n = 100, but as sample size n increases,
the empirical size gets closer to its nominal value. The same holds true for ICM tests based on
the unprojected process (2.10). Shaikh et al. (2009)’s test tends to be conservative (with the
exception when c = 0.01), and sensitive to the bandwidth choice. The traditional balancing
tests, and the ICM tests based on (4.1) are conservative, reﬂecting the “curse of dimensionality”.
Finally, note that when the propensity score is correctly speciﬁed, the ﬁnite sample properties
of the AT E estimator (4.3) are good: the bias and the length of the 95% conﬁdence interval
get smaller when sample size increases, and the coverage probability is relatively close to its
23

nominal value. When one trims observations with extreme estimated propensity score, these
properties further improve; see Table B.2 in the Appendix B.
Note that when the propensity score is misspeciﬁed, the AT E estimator (4.3) can be severely
biased, and inference can be unreliable. Thus, tests with higher power to detect such misspeciﬁcations can prevent one to make misleading conclusions about the eﬀectiveness of a given policy.
What is clear from Table 2 is that, regardless of the sample size and bandwidth considered,
Shaikh et al. (2009)’s test seems to have little to no power to detect the alternatives described
in DGP 7, DGP 9, and DGP 10. For DGP 8, the maximum power for their test is approximately
55% when n = 1, 000 and c = 0.1. However, with c = 0.01, the power of Shaikh et al. (2009)’s
test reduces to approximately 30%, highlighting again how important (and non-trivial) is to
“appropriately” choose the bandwidth. In sharp contrast with Shaikh et al. (2009)’s test, note
that for moderately sized samples, our proposed KSn and CvMn tests have non-trivial power
to detect all the alternatives. Our projection-based tests seem to dominate the other tests in
the scenarios considered. Note that the traditional balancing tests have no power to detect
the alternatives considered. Finally, ICM tests based on the traditional empirical process (4.1)
have substantially less power than our proposed tests, reﬂecting the cost of the “curse of dimensionality”. The power gains from using the projection-based process (2.7) instead of the
unprojected process (2.10) can also be noted.
Overall, the simulation results highlight that the proposed projection-based tests perform
favorably compared to other alternative testing procedures in terms of size and power. Importantly, the simulations illustrate that the gains in power can be credited to each distinguished
feature of our tests, that is, (i) the avoidance of smoothing parameters by using the ICM
approach, (ii) the dimension-reduction coming from considering 1 {q (X, θ 0 ) ≤ u} instead of
1 {X ≤ u}, and (iii) the use of orthogonal projections. Given these attractive features, we
believe that our tests can be of great use in practice.

5

Empirical Illustration

In this section, we provide an empirical illustration of our testing procedure. We revisit the
analysis of Frankel and Rose (2005) and Millimet and Tchernis (2009), and study the eﬀect of
trade on the environment. More speciﬁcally, following Millimet and Tchernis (2009), we assess
the eﬀect of a country being a member of the General Agreement on Tariﬀs and Trade (GATT)

24

Table 2: Monte Carlo results under designs DGP 6-DGP 10

25

DGP

n

CvMn

KSn

Tn (0.01)

Tn (0.05)

Tn (0.10)

Tn (0.15)

Max-t

W ald

CvMnunp

KSnunp

CvMntrad

KSntrad

Bias

CI length

Coverage

6
6
6
6
6
6
7
7
7
7
7
7
8
8
8
8
8
8
9
9
9
9
9
9
10
10
10
10
10
10

100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000

8.50
5.70
5.60
5.00
5.40
4.90
9.50
15.40
26.40
37.20
49.50
57.20
9.50
18.30
46.50
66.30
79.90
87.00
10.00
15.10
30.40
44.10
57.60
70.50
7.50
10.00
19.20
36.20
50.20
64.30

9.40
6.10
6.00
5.20
5.20
6.00
10.60
14.90
24.20
33.00
46.50
52.90
10.60
18.70
41.80
62.10
74.40
82.10
12.00
15.10
26.80
36.10
50.20
57.50
8.30
10.10
16.70
28.10
38.90
51.70

5.80
4.00
5.10
4.90
5.10
4.50
4.10
5.10
5.40
9.10
9.90
11.90
5.70
4.40
8.10
15.80
23.30
31.30
3.50
4.70
4.50
5.70
6.60
5.30
4.10
5.10
5.20
4.60
7.70
8.20

2.50
2.50
2.40
1.70
2.70
2.80
1.60
3.30
6.60
10.70
16.70
22.90
1.30
4.20
16.00
27.50
42.70
52.70
2.40
3.70
3.10
6.10
8.80
11.30
1.30
1.80
3.80
7.30
11.30
18.20

1.00
1.00
0.90
0.60
1.40
1.10
0.70
2.00
6.80
11.10
17.00
24.30
0.80
3.60
15.80
28.10
45.60
55.00
0.40
1.80
2.80
6.70
11.00
15.70
0.60
0.80
2.80
6.80
13.20
22.30

0.20
0.40
0.30
0.20
0.70
0.50
0.00
1.10
5.20
8.70
13.90
21.60
0.20
2.80
11.60
24.20
40.00
51.20
0.20
0.80
2.90
6.00
10.40
16.60
0.30
0.30
1.80
4.80
11.10
18.90

1.10
0.90
2.80
3.40
5.10
4.90
0.60
0.70
0.60
0.10
0.10
0.20
2.00
1.00
0.50
0.20
0.50
2.10
1.70
1.60
0.80
0.50
0.70
0.80
0.00
0.00
0.00
0.10
0.10
0.10

1.60
0.30
0.70
1.60
3.40
5.20
5.30
1.20
0.30
0.00
0.00
0.20
14.30
4.40
0.90
0.50
0.60
0.30
6.80
4.10
2.70
3.30
3.00
2.40
0.00
0.00
0.00
0.00
0.00
0.00

7.80
5.70
5.80
3.70
4.60
5.70
6.80
13.60
23.00
33.70
46.40
55.60
8.20
14.80
41.70
60.60
74.90
82.40
10.10
12.40
21.30
32.50
46.80
59.30
6.80
10.30
20.60
37.70
52.80
67.00

9.40
6.50
6.30
5.00
5.00
5.80
8.40
13.90
19.90
30.10
37.70
47.50
9.90
15.50
37.10
54.20
68.30
77.70
12.40
12.00
17.00
25.30
35.60
45.60
8.70
9.30
14.90
27.70
38.80
51.40

1.10
2.30
3.30
3.80
2.60
3.70
2.50
2.70
4.60
8.30
13.80
17.70
2.20
3.40
9.10
20.80
30.90
42.20
1.20
4.00
8.50
17.10
25.40
35.60
4.00
4.40
6.90
10.10
15.20
21.00

1.70
3.90
4.50
3.70
4.20
5.40
3.80
6.00
7.90
9.30
13.70
16.20
3.70
5.30
9.10
16.10
22.30
25.40
2.50
7.10
12.00
20.10
29.30
39.80
3.90
4.90
8.60
8.20
12.60
13.90

-0.29
-0.08
-0.02
-0.02
-0.01
-0.01
0.22
0.59
0.61
0.56
0.59
0.60
0.61
1.12
1.36
1.33
1.34
1.30
0.06
0.60
0.97
1.00
1.03
1.07
-0.09
-0.10
-0.10
-0.11
-0.12
-0.12

3.71
2.10
1.41
1.11
0.97
0.84
6.97
4.43
2.66
1.97
1.69
1.51
10.68
6.58
4.44
3.42
2.91
2.51
7.76
5.02
3.70
3.01
2.63
2.45
2.37
1.26
0.81
0.65
0.55
0.49

89.40
91.00
91.90
90.00
93.30
92.30
96.60
99.10
99.10
96.60
89.30
78.10
96.20
99.40
98.50
88.30
66.00
44.00
88.30
94.60
97.30
89.20
78.60
67.90
97.30
96.50
93.60
91.40
87.50
83.10

Note: Simulations based on 1,000 Monte Carlo experiments. “CvMn ” and “KSn ” stand for our proposed Cramér-von Mises and Kolmogorov-Smirnov tests. “Tn (c)” stands for
Shaikh et al. (2009)’s test, with bandwidth hn = cn−1/8 . “Max-t” and “W ald” stand for, respectively, the Bonferroni-corrected Max-t-test, and Wald balancing tests based on

[
AT
E n X j deﬁned in (4.2). “CvMnunp ” and “KSnunp ” are the Cramér-von Mises and Kolmogorov-Smirnov tests based on the unprojected empirical process R̂n (u) deﬁned in
(2.10), whereas “CvMntrad ” and “KSntrad” are deﬁned analogously, but based on R̂ntrad (x) as deﬁned in (4.1). Finally, “Bias”, “CI length’, and “Coverage” stands for the average
\
simulated bias, estimated 95% conﬁdence interval length, and 95% coverage probability for the AT E estimator AT
En as deﬁned in (4.3). All entries are proportions of rejections
at 5% level, in percentage points, except “Bias” ,“CI length”, and “Coverage” (measure in percentage points), which are as described above. See the main text for further details.

or World Trade Organization (WTO) on 5 diﬀerent measures of environmental quality: per
capita CO2 emissions, average annual deforestation rate for 1990-1996, energy depletion, rural
access to clear water and urban access to clear water.
As Millimet and Tchernis (2009), we use three diﬀerent covariates to model the probability
of being a GATT/WTO member: real per capita GDP, land area per capita, and polity, which
is a measure of how democratic (versus autocratic) is the structure of the government. The
motivation to include these three covariates is to increase the plausibility of Assumption 2.1
as discussed by Frankel and Rose (2005). GDP per capita is associated with the probability
of being member of the GATT/WTO and at the same time may have eﬀects on diﬀerent
measures of environment quality, for instance, via the environmental Kuznetz curve. Land
area per capita is another potential confounder since higher population density may lead to
environmental degradation and “larger” countries are more likely to trade more, aﬀecting the
probability of being member of he GATT/WTO. Finally, as noted by Frankel and Rose (2005),
low-democracy countries tend to have lower measures of environmental quality, and can also
confound the eﬀect of GATT/WTO membership. In what follows and in the same spirit of
Millimet and Tchernis (2009), we assume that Assumption 2.1 holds after controlling for these
three confounding factors6 .
The unbalanced country-level panel data we use follows from Millimet and Tchernis (2009),
and includes observations from 1990 (before the WTO) and 1995 (after the WTO). However, it
is important to have in mind that treatment is deﬁned as being a GATT/WTO member, and
therefore there are countries who were treated in both times, and others who were treated only
in 1995. Table 3 provides summary statistics and more detailed description of the variables.
Finally, we highlight that the data we analyze is from an unbalanced country-level panel and
instead of only considering the “always observed” countries, we follow Millimet and Tchernis
(2009) and run a separate analysis for each outcome. For further details, see Section 4.1 of
Millimet and Tchernis (2009).
The main goal of this section is to assess the “reliability” of diﬀerent treatment eﬀect measures by analyzing if diﬀerent propensity score models are correctly speciﬁed or not. Given that
the sample constitutes of an unbalanced panel, we estimate separate propensity score models

6 If one finds the plausibility of this assumption rather low, all the estimates presented below should be interpreted
as associations/correlations and not as causal effects. In light of Remark 1, however, Assumption 2.1 plays no
role in our specification tests.

26

Table 3: Summary statistics and variable descriptions
Variable

Mean

Standard deviation

N

Description

Per capita CO2
Deforestation
Energy depletion

3.82
0.68
3.13

4.73
1.28
7.43

232
223
223

Rural water access
Urban water access
GATT/WTO membership
Real GDP per capita
Polity
Area per capita

51.20
76.28
0.78
7.30
3.17
51.6

27.42
21.76
0.41
7.47
6.85
89.56

137
140
232
232
232
232

Carbon dioxide emissions, industrial, in metric tons per capita
Annual deforestation, average percentage change, 1990-1995
In percent of GDP, equal to the product of unit resource rents and the
physical quantities of fossil fuel energy extracted
Access to clean water, percentage of rural population, 1990-1996
Access to clean water, percentage of urban population, 1990-1996
Member country of GATT/WTO: 1 if member, 0 otherwise
Real (1990) gross domestic product per capita, in thousands of dollars
Index, ranging from-10 (strongly autocratic) to 10 (strongly democratic)
Land area divided by population

Note: Same data used by Millimet and Tchernis (2009). We thank Prof. Millimet for sharing the data with us. Original source is Environmental indicators and country-level controls are from Frankel and Rose (2005), whereas GATT/WTO membership data are from Rose (2004). N = number of
observations. For further details, see the aforementioned papers.

for each outcome subsample. More speciﬁcally, for each outcome, we model the probability of
a country being a GATT/WTO member (D = 1 if member, D = 0 otherwise) by a standard
Probit model and consider two diﬀerent speciﬁcations:
Spec1: X includes real per capita GDP, land area per capita, and polity.
Spec2: X is deﬁned as in Spec1 but adds pairwise interaction terms between each covariate.
For each of these speciﬁcations, we test the null hypothesis



H0 : ∃θ0 ∈ Θ : E D − Φ X ′ θ0 |Φ X ′ θ0 = 0 a.s.,
against H1 , which is simply the negation of H0 . Table 4 reports the testing results for each
speciﬁcation, together with normalized IPW estimator for the AT E based on (4.3). We also
consider the normalized IPW estimator for the AT T ,
n

1X
[
AT
Tn =
n
i=1

treat
treat
w0,i
w1,i
−
treat
treat
w̄1,n
w̄0,n

!

Yi ,

(5.1)


 


treat is the sample
treat = D , w treat = (1 − D ) q X , θ̂
, and w̄d,n
/
1
−
q
X
,
θ̂
where w1,i
i n
i
i
i n
0,i

treat , d = {0, 1}. The associated standard errors and p-values are in parenthesis
mean of wd,i

and brackets, respectively. Following Millimet and Tchernis (2009), we trim observations with
estimated propensity score outside the interval [0.05, 0.95] to avoid denominators arbitrarily
close to zero. Bootstrapped p-values for our proposed speciﬁcation tests are based on 100,000
bootstrap draws7 .
At the 5% level we ﬁnd that, based on the CvMn test statistic (2.8), Spec1 is rejected for
per capita CO2 , deforestation and energy depletion, but is not rejected for rural and urban
7 Note that the variables in Spec1 and Spec2 are all functions of the same three covariates: real per capita GDP,
land area per capita, and polity. As so, Spec1 and Spec2 have the same information content with respect to
the reliability of Assumption 2.1.

27

accesses to clean water. The evidence of propensity score misspeciﬁcation is weaker when using
the KSn test statistic (2.9). Spec2, on the other hand, is not rejected for any outcome at the
usual signiﬁcance levels, using either CvMn or KSn test statistic. Thus, our tests suggests that
Spec2 should be preferred when analyzing per capita CO2 , deforestation and energy depletion,
whereas for urban and rural water access, our tests do not favor either speciﬁcation.
Table 4: Eﬀect of GATT/WTO membership on environmental quality
Per capita CO2

Deforestation

Energy Depletion

Rural water access

Urban water access

Spec1

Spec2

Spec1

Spec2

Spec 1

Spec2

Spec1

Spec2

Spec1

Spec2

\
AT
En

-1.29
(0.58)
[0.025]

-1.00
(0.49)
[0.039]

0.26
(0.20)
[0.203]

0.34
(0.21)
[0.105]

-3.35
(1.35)
[0.013]

-3.39
(1.38)
[0.014]

3.07
(4.84)
[0.526]

2.89
(4.79)
[0.547]

-5.21
(3.75)
[0.165]

-4.62
(3.72)
[0.213]

\
AT
Tn

-0.81
(0.68)
[0.234]

-0.56
(0.59)
[0.338]

0.14
(0.20)
[0.500]

0.22
(0.21)
[0.287]

-2.16
(1.30)
[0.097]

-1.62
(1.34)
[0.228]

1.74
(5.02)
[0.730]

1.33
(4.98)
[0.790]

1.74
(4.19)
[0.679]

-3.34
(4.16)
[0.422]

CvMn
KSn

0.01
0.12

0.28
0.24

0.01
0.17

0.45
0.57

0.01
0.12

0.35
0.43

0.53
0.70

0.26
0.52

0.49
0.63

0.23
0.28

\
\
Note: Spec1 and Spec2 are diﬀerent speciﬁcations of the propensity score. AT
En and AT
Tn are the estimators for AT E and AT T
in (4.3) and (5.1), respectively, but with observations with estimated propensity score outside [0.05, 0.95] trimmed. Standard errors
are in parenthesis, and p-values in brackets. “CvMn ” and “KSn ” respectively stand for the bootstrapped p-values of our proposed
Cramér-von Mises and Kolmogorov-Smirnov tests based on 100,000 bootstrap draws. See the main text for further details.

Next we comment on the consequences of propensity score misspeciﬁcation. For per capita
CO2 , our results suggest that the overall eﬀect of GATT/WTO membership on emissions is
negative and statistically signiﬁcant at the 5% level under both propensity score speciﬁcations.
On the other hand, we ﬁnd the eﬀect of GATT/WTO membership on per capita CO2 is not
statistically signiﬁcant among the treated sub-population using either speciﬁcation. In terms
of point estimates, however, there are important diﬀerences. For example, the AT E point
estimate under Spec1 (misspeciﬁed propensity score) is 30% higher (in absolute terms) than
under Spec2. Note that the 0.3 diﬀerence in AT E represents roughly 8% of the overall per
capita CO2 emissions.
When we analyze the eﬀect of GATT/WTO on deforestation and energy depletion, our results again highlight the consequences of propensity score misspeciﬁcations. We ﬁnd that the
AT E point estimate for the eﬀect of GATT/WTO membership on deforestation is 30% larger
under Spec2 than under Spec1, and the AT T point estimate for the eﬀect of GATT/WTO
membership on energy depletion is 25% smaller under Spec2 than under Spec1. Such large
diﬀerences are economically signiﬁcant, as the 0.08 diﬀerence in AT Es on deforestation represents nearly 12% of the mean annual deforestation, and the 0.46 diﬀerence in AT T s on energy
28

depletion represents nearly 15% of the mean energy depletion among countries in the sample.
Interestingly, the AT T on energy depletion is statistically signiﬁcant at 10% level under Spec1,
but not under Spec2, highlighting that propensity score misspeciﬁcations can also lead to invalid
inference. Finally, we note that although our tests do not detect propensity score misspeciﬁcation for the rural and urban water access, the results suggest that GATT/WTO membership is
not statistically signiﬁcant using either propensity score speciﬁcation, perhaps because of the
relatively high standard errors due to the limited sample size.
Overall, we ﬁnd that propensity score misspeciﬁcations can aﬀect both the economic and
statistical conclusions about the eﬀect of GATT/WTO membership on environmental quality.
When the propensity score is correctly speciﬁed, our results suggest that GATT/WTO membership is associated with improved environmental performance in terms of CO2 and energy depletion but not in terms of rural and urban water access. We also ﬁnd that GATT/WTO membership is associated with higher deforestation, though the statistical evidence is relatively weaker.
Furthermore, our results uncover interesting heterogeneity, as the aforementioned results are
statistically signiﬁcant for the overall population (AT E) but not for the treated-subpopulation
(AT T ).

6

Conclusion

In this article, we have shown that, when propensity scores are correctly speciﬁed, a particular
restriction between the propensity score CDFs of treated and control groups must hold. Based
on such restriction, we propose new nonparametric projection-based tests for the correct speciﬁcation of the propensity score. In contrast to other proposals, our tests are not severely aﬀected
by the “curse of dimensionality”’, are not sensitive to the diﬀerent estimation methods used to
estimate the propensity score under the null, do not rely on the potentially ad hoc choice of
bandwidths, and enjoy some optimal power properties against particular classes of alternative
hypotheses. We have derived the asymptotic properties of the proposed tests, and have proved
that they are able to detect local alternatives converging to the null at the parametric rate, and
that critical values can be easily computed via a simple multiplier bootstrap procedure. Our
Monte Carlo simulation study illustrates that, for a large class of alternatives, our projectionbased tests perform better in ﬁnite samples than existing tests, though there are some classes
of alternatives in which our tests have trivial power. All these ﬁnite sample ﬁndings are in line

29

with our asymptotic results. Finally, our empirical application concerning the eﬀect of trade
on the environment shows the feasibility and appeal of our tests in relevant scenarios. Given
that the validity of many policy evaluation procedures relies on the correct speciﬁcation of the
propensity score, we argue that the tests proposed in this article are important additions to the
applied researchers’ toolkit.
We would like to mention that, in general, our tests should be seen as a “model validation”
and not a “model selection” procedure. Once a propensity score model is selected, our speciﬁcation tests can provide evidence of its reliability or lack thereof. In case the putative propensity
score model is rejected, one can consider more ﬂexible speciﬁcations. For instance, one can add
additional interaction terms into the original model, consider semiparametric single-index or
partially linear models, among other possible strategies. Having said so, we emphasize that if
one uses our testing procedure as a “model selection” device, one must bear in mind that standard inference procedures for treatment eﬀects may be invalid if one treats the resulting selected
propensity score as the “true” one, see e.g. Leeb and Pötscher (2005). Thus, in case one uses
our proposal for model selection, one must account for the model selection step in order to make
valid inference about the treatment eﬀect, see e.g. Belloni et al. (2014), Chernozhukov et al.
(2016), and Belloni et al. (2017). A full discussion of this procedure is beyond the scope of this
article and we leave it for future research.
Finally, we note that results in Lemma 1 can also be used for estimating the propensity score
such that, for a given speciﬁcation q (X, θ 0 ), condition E [D − q (X, θ 0 ) |q (X, θ 0 )] = 0 a.s. is directly imposed. One could use the minimum distance method described in Dominguez and Lobato
(2004) to estimate θ0 , for example. A detailed discussion of this estimator is beyond the scope
of this article and is deferred to future work.

Appendix A: Mathematical Proofs
We provide the proofs of our main theoretical results in this appendix. We ﬁrst prove Lemma
1.
Proof of Lemma 1: To begin, let F (u) = P (p (X) ≤ u), and for d = {0, 1}, Fd (u) =
P (p (X) ≤ u|D = d) . Denote the density of F (u), F1 (u) and F0 (u) by f (u), f1 (u), and f0 (u).
The proof of (2.1) follows from Lemma 3.1 in Shaikh et al. (2009), as they proved that, for all

30

0 < u < 1 inside the support of the propensity score p (X),
f1 (u) = α

u
f0 (u) .
1−u

(A.1)

Thus, (2.1) follows from integrating both sides of (A.1).
Next, we prove (2.2). By straightforward manipulation of (2.1), we have that, for all u ∈
(0, 1),

p (X)
1 {p (X) ≤ u} |D = 0
E [1 {p (X) ≤ u} |D = 1] P (D = 1) = P (D = 0) E
1 − p (X)


p (X)
E [D1 {p (X) ≤ u}] = E (1 − D)
1 {p (X) ≤ u}
1 − p (X)


(D − p (X))
1 {p (X) ≤ u} = 0.
(A.2)
E
1 − p (X)


Note that
E




(D − p (X))
1 {p (X) ≤ u}
1 − p (X)
E



(D − p (X))
p (X)
1 − p (X)



=

0 a.e. in u ∈ (0, 1)

⇐⇒
=

0 a.s.,

(A.3)

see e.g. Lemma 1 in Escanciano (2006b). Given that p (X) is bounded away from one, we have
that (A.3) is equivalent to (2.2). Finally, because 0 < p (X) < 1 a.s., we can trivially include
the two boundary points u = 0 and u = 1, concluding our proof. 
Next, we state and prove several auxiliary lemmas that help us prove our main theorems.
Let us ﬁrst introduce some notation. Let Y be a generic random variable with cumulative
distribution function F . Recall the deﬁnition of the quantile function F −1 associated with F ,
namely, F −1 (u) = inf {y ∈ R : F (y) ≥ u} for 0 ≤ u ≤ 1, and let F (a−) ≡ limy↑a F (y) .
Lemma A.1 Let A = {a} denote the set of atoms of F , and let V be independent of Y and
uniformly distributed on [0, 1]. Set

U=



 F (Y ) ,

if Y 6∈ A,


 F (a−) + F {a} V,

if Y = a f or a ∈ A,

where F {a} ≡ F (a) − F (a−). Then, it follows that
(i) U is uniformly distributed on [0, 1];
(ii) Y = F −1 (U ) a.s.;

31

(iii) 1 {Y ≤ y} = 1 {U ≤ F (y)} a.s. for all y ∈ R.
Proof of Lemma A.1: This lemma follows directly from Proposition 3.2 in Chapter 7
of Shorack (2000); see also Lemma 2.8 in Stute and Wang (1993) for an earlier use of such
quantile transformation. For completeness, we give a short proof of part (i) below. Part (ii)
follows directly from the construction of U and the deﬁnition of the quantile function, and part
(iii) is a consequence of parts (i) and (ii).
Without loss of generality, let us denote A = {a1 , a2 , . . .}, with −∞ ≤ a1 < a2 < · · · < aJ ≤
∞ and P (Y = al ) = F {al } = F (al ) − F (al −) > 0 for l = 1, 2, . . . , J (note that J can be ∞).
P
Without loss of generality, assume that 0 < Jl=1 F {al } < 1, so Y is not purely discrete. The
P
case of Jl=1 F {al } = 0 or 1 is trivial.
For u ∈ [0, 1], the CDF of the distribution of U is
P (U ≤ u) = P (U ≤ u, Y 6∈ A) +

X
l

P (U ≤ u|Y = al ) P (Y = al ) ,

with

u − F (al −)
P (U ≤ u|Y = al ) =P V ≤
F {al }
u − F (al −)
=
1 {F (al −) ≤ u < F (al )} + 1 {F (al ) ≤ u ≤ 1} .
F {al }


We obtain
P (U ≤ u) =P (U ≤ u, Y 6∈ A)
X
+
[(u − F (al −)) 1 {F (al −) ≤ u < F (al )} + F {al } 1 {F (al ) ≤ u ≤ 1}] .
l

Four cases then stand out. Let j be some generic integer such that 2 ≤ j ≤ J − 1.
Case 1: If u ∈ [F (aj −), F (aj )),

P (U ≤ u, Y 6∈ A) = P Y ≤ F −1 (u), Y 6∈ A = F (aj −) − F {aj−1 } − . . . − F {a1 },
and, noting that the intervals [F (al ), 1] for 1 ≤ l ≤ j − 1 always contain the interval [F (aj ), 1],
X
l

[(u − F (al −)) 1 {F (al −) ≤ u < F (al )} + F {al } 1 {F (al ) ≤ u ≤ 1}]

= (u − F (aj −)) + (F {a1 } + . . . + F {aj−1 }) .
As a result, we ﬁnd P (U ≤ u) = u when u ∈ [F (aj −), F (aj )).
32

Case 2: If u ∈ [F (aj−1 ), F (aj −)), similar arguments as in Case 1 yields
P (U ≤ u) = (u − F {aj−1 } − . . . − F {a1 }) + (F {a1 } + . . . + F {aj−1 }) = u.
Case 3: If u ∈ [0, F (a1 )), obviously,
P (U ≤ u) = u.
Case 4: If u ∈ [F (aJ ), 1], obviously,
P (U ≤ u) = (u − F {aJ } − . . . − F {a1 }) + (F {a1 } + . . . + F {aJ }) = u.
Thus, it follows that U is uniformly distributed on [0, 1]. 
Lemma A.2 Under Assumptions 3.1 and 3.3, F = {x 7→ 1 {q(x, θ) ≤ u} : u ∈ [0, 1] , θ ∈ Θ} is
a Donsker class of functions.
Proof of Lemma A.2:

From Lemma A.1, simply letting Y = q(X, θ), we have that

1 {q(X, θ) ≤ u} = 1 {U ≤ Fθ (u)} for all u ∈ [0, 1], i.e., we can exploit the quantile transformation and express each indicator function 1 {q(X, θ) ≤ u} through U via the time transformation Fθ . In light of this quantile transformation, it suﬃces to study the class of functions
Fcdf = {ū 7→ 1 {ū ≤ Fθ (u)} : u ∈ [0, 1] , θ ∈ Θ} .
Let N[ ] (ǭ, Fcdf , L2 (P)) be the bracketing number of the class Fcdf with respect to the underlying probability P, which by deﬁnition is the minimal number of ǭ-brackets under L2 (P)
metric that cover Fcdf . Henceforth, we deﬁne the underlying probability P as the probability
measure of U . By Theorem 2.5.6 in van der Vaart and Wellner (1996), the Donsker property is
implied by
Z

0

∞q

log N[ ] (ǭ, Fcdf , L2 (P)) dǭ < ∞.

To show that such entropy result hold, we follow similar steps as the proof of Lemma 1 in
Akritas and van Keilegom (2001) and of Lemma A.4 in Frazier et al. (2018).
Let ǭ > 0 be an arbitrarily small constant, and consider partitions {Θl }L
l=1 of Θ. Given that
Θ is compact, under Assumption 3.3, there exists a ﬁnite constant K ≤ diam (Θ/ǭ)k such that
diam (Θl ) ≤ ǭ for every l = 1, . . . , K. Fix l ∈ {1, . . . , K} and pick up some θl ∈ Θl . Then, for
any ﬁxed u ∈ [0, 1] and any θ ∈ Θl , it follows from the Lipschitz condition in Assumption 3.3
that
Fl− (u) ≤ Fθ (u) ≤ Fl+ (u) ,
33

(A.4)

where Fl± (u) ≡ Fθl (u) ± ǭC, where C is as deﬁned in Assumption 3.3. Thus, for each θ ∈ Θl
and each u ∈ [0, 1], it follows that


1 ū ≤ Fl− (u) ≤ 1 {ū ≤ Fθ (u)} ≤ 1 ū ≤ Fl+ (u) .


−1
Denote FlL (u) = P U ≤ Fl− (u) and let uL
l,j , j = 1, . . . , Kǭ , partition the unit interval in





+
U
L uL
segments such that FlL uL
l,j−1 < ǭ. Similarly, deﬁne Fl (u) = P U ≤ Fl (u)
l,j − − Fl


−1 , partition the unit interval in segments such that F U uU − −
,
j
=
1,
.
.
.
,
Kǭ
and let uU
l,j
l
l,j


FlU uU
l,j−1 < ǭ. Now, deﬁne the following bracket for u :
U
uL
l,j1 ≤ u ≤ ul,j2 ,
U
L
where uL
l,j1 is the largest of the ul,j with the property of being less than or equal to u and ul,j2

is the smallest uU
l,j among those that are greater than or equal to u. Obviously, we have




.
≤ 1 {ū ≤ Fθ (u)} ≤ 1 ū ≤ Fl+ uU
1 ū ≤ Fl− uL
l,j2
l,j1
Then, for an arbitrary constant K,
 2



− 1 U ≤ Fl− uL
1 U ≤ Fl+ uU
l,j1
l,j2
2




 
− 1 U ≤ Fl− uL
= E 1 U ≤ Fl+ uU
l,j1
l,j2


−
uL
≤ Fl+ uU
l,j1
l,j2 − Fl




+
−
−
uL
= Fl+ (u) − Fl− (u) + Fl+ uU
l,j1
l,j2 − Fl (u) + Fl (u) − Fl

≤ Kǭ,

L
where the last inequality follows from (A.4) and the deﬁnition of deﬁnitions of uU
l,j2 and ul,j1 .
o

o
n

n
−
L
≤ Kǭ1/2 .
u
−
1
U
≤
F
Consequently, we have 1 U ≤ Fl+ uU
l,j1
l,j2
l
2

Thus, the bracketing number N[ ] (ǭ, Fcdf , L2 (P)) is of polynomial order (1/ǭ), and the entropy

is of smaller order than log (1/ǭ). Therefore, since Fcdf is uniformly bounded between 0 and 1,
we conclude that
Z

0

with

∞q

log N[ ] (ǭ, Fcdf , L2 (P)) dǭ ≤ K

Z

0

1p

log ǭ−1 dǭ < ∞,

R∞
R1p
√
2
log ǭ−1 dǭ = − 0 t de−t = π/2, which implies that class Fcdf (and therefore class
0

F) is Donsker. 

34

Deﬁne the auxiliary empirical process
n

1 X
εi (θ̂n )1 {q(Xi , θ0 ) ≤ u} .
R̃n (u) = √
n
i=1

Next lemma states that the unprojected process R̂n (u) deﬁned in (2.10) is asymptotically equivalent under H0 to the auxiliary process R̃n (u) deﬁned above.
Lemma A.3 Under Assumptions 3.1-3.3 and under the null hypothesis H0 , we have
sup R̂n (u) − R̃n (u) = op (1).

u∈Π

Proof of Lemma A.3: Note that we have uniformly in u,
R̂n (u) − R̃n (u)
n

 n
o

1 X
=√
εi (θ̂n ) 1 q(Xi , θ̂n ) ≤ u − 1 {q(Xi , θ 0 ) ≤ u}
n
i=1

n
 n
o

1 X
(εi (θ0 ) − (q(Xi , θ̂ n ) − q(Xi , θ 0 ))) 1 q(Xi , θ̂ n ) ≤ u − 1 {q(Xi , θ 0 ) ≤ u}
=√
n
i=1

n
 n
o

1 X
=√
εi (θ0 ) 1 q(Xi , θ̂ n ) ≤ u − 1 {q(Xi , θ0 ) ≤ u}
n
i=1

−

√

n

n(θ̂n − θ0 )′

 n
o

1X
g(Xi , θ 0 ) 1 q(Xi , θ̂n ) ≤ u − 1 {q(Xi , θ 0 ) ≤ u} + op (1)
n
i=1

:=A1n (u) + A2n (u) + op (1),
where the second to last equality follows by the Taylor expansion of q(Xi , θ̂ n ) around q(Xi , θ 0 )
and the Assumptions 3.1 and 3.2. Following the arguments in the proof of Theorem 1 in
Stute and Zhu (2002), we next show that both A1n (u) and A2n (u) are uniformly negligible in
u.
For the ﬁrst term A1n (u), deﬁne the process
n

1 X
αn (u, θ) = √
εi (θ 0 )1 {q(Xi , θ) ≤ u} .
n
i=1

Since under H0 the εi ’s are centered conditionally on Xi ’s, αn (u, θ) has i.i.d. centered summands.
Clearly, the ﬁrst term A1n (u) can be expressed as αn (u, θ̂ n ) − αn (u, θ 0 ). From Lemma A.2,
αn (·, ·) is asymptotically equicontinuous, see e.g. Corollary 2.3.12 in van der Vaart and Wellner
(1996). Since θ̂n →p θ0 by Assumption 3.1, A1n (u) → 0 in probability uniformly in u.
√
For the second term A2n (u), since by Assumption 3.1, n(θ̂n − θ0 ) = Op (1), it remains to

35

show that, uniformly in u,
n
 n
o

1X
g(Xi , θ0 ) 1 q(Xi , θ̂n ) ≤ u − 1 {q(Xi , θ 0 ) ≤ u} →p 0.
n
i=1

However, this follows straightforwardly from the uniform convergence of
n

1X
g(Xi , θ0 )1 {q(Xi , θ) ≤ u}
n
i=1

in u and θ together with the continuity of its limit. 
With the help of Lemma A.3, the next lemma establishes the asymptotic uniform decomposition of the unprojected process R̂n (u) in (2.10).
Lemma A.4 Under Assumptions 3.1-3.3 and under the null hypothesis H0 , we have
n

√
1 X
sup R̂n (u) − √
εi (θ 0 )1 {q(Xi , θ 0 ) ≤ u} + n(θ̂ n − θ0 )′ G(u, θ 0 ) = op (1),
n
u∈Π
i=1

where G(u, θ) = E [g(X, θ)1 {q(X, θ) ≤ u}].
Proof of Lemma A.4: From Lemma A.3, we immediately have uniformly in u,
R̂n (u) = R̃n (u) + op (1)
n

n

i=1

i=1

1 X
1 X
εi (θ0 )1 {q(Xi , θ0 ) ≤ u} − √
(q(Xi , θ̂n ) − q(Xi , θ 0 ))1 {q(Xi , θ0 ) ≤ u} + op (1).
=√
n
n
By the Mean Value Theorem (MVT) and Assumption 3.1, the second term in the previous
expression is simply
−
=−

√
√

′1

n(θ̂ n − θ0 )

n

n
X
∂q(Xi , θ̃ n )

∂θ

i=1

1 {q(Xi , θ 0 ) ≤ u}

n(θ̂ n − θ0 )′ E [g(X, θ 0 )1 {q(X, θ 0 ) ≤ u}] + op (1),

with θ̃n lying between θ̂n and θ0 , where the latter equality follows by the uniform law of large
numbers (ULLN) of Newey and McFadden (1994), Lemma 2.4. This ﬁnishes the proof of Lemma
A.4. 
Deﬁne the following quantity
n

1 X
εi (θ̂n )g(Xi , θ̂ n ).
Ŝn = √
n
i=1

36

Lemma A.5 Under Assumptions 3.1-3.3 and under the null hypothesis H0 , we have
n
√
1 X
εi (θ 0 )g(Xi , θ 0 ) − ∆(θ 0 ) n(θ̂n − θ0 ) + op (1),
Ŝn = √
n
i=1

where ∆(θ) = E[g(X, θ)g ′ (X, θ)].
Proof of Lemma A.5: We can rewrite
n

n

i=1

i=1

1 X
1 X
Ŝn = √
εi (θ 0 )g(Xi , θ0 ) + √
(εi (θ̂ n ) − εi (θ0 ))g(Xi , θ0 )
n
n

n
n
1 X
1 X
εi (θ 0 )(g(Xi , θ̂ n ) − g(Xi , θ0 )) + √
(εi (θ̂ n ) − εi (θ0 ))(g(Xi , θ̂ n ) − g(Xi , θ 0 ))
+√
n
n
i=1

i=1

n
1 X
:= √
εi (θ 0 )g(Xi , θ0 ) + C1n + C2n + C3n .
n
i=1

√
We ﬁrst show that C1n = − n(θ̂ n − θ0 )′ ∆(θ0 ) + op (1). Note that
n

1 X
C1n = − √
(q(Xi , θ̂n ) − q(Xi , θ 0 ))g(Xi , θ0 )
n
i=1

n
∂q(Xi , θ̃n ) √
1X
g(Xi , θ 0 )
=−
n(θ̂ n − θ0 )
n
∂θ′
i=1

√
= − E[g(X, θ 0 )g′ (X, θ 0 )] n(θ̂ n − θ0 ) + op (1),
with θ̃n lying between θ̂n and θ0 , where the second equality follows by the MVT, and the last
equality follows from the ULLN of Newey and McFadden (1994), Lemma 2.4, and Assumptions
3.1 and 3.2.
It remains to show that both C2n and C3n are asymptotically negligible. Note that
√

n
X

∂g(Xi , θ̃ n )
n
∂θ
i=1


√
∂g(X, θ 0 )
′
= n(θ̂ n − θ0 ) E ε(θ 0 )
+ op (1)
∂θ
′1

C2n = n(θ̂ n − θ0 )

εi (θ 0 )

=op (1),
where the ﬁrst equality follows by MVT, the second equality by ULLN of Newey and McFadden
(1994), and the last step by Assumptions 3.1 and 3.2 as well as the law of iterated expectations
under H0 .
On the other hand, for the term C3n , we get
√

nC3n = −

n
√
1 X ∂q(Xi , θ̃ n ) ∂g(Xi , θ̃n ) √
n(θ̂ n − θ0 )′
n(θ̂n − θ0 )
n
∂θ
∂θ ′
i=1

37

=−



√
∂g(X, θ 0 ) √
n(θ̂ n − θ0 )′ E g(X, θ 0 )
n(θ̂n − θ0 ) + op (1)
∂θ ′

=Op (1),
following similar arguments in proving the negligibility of C2n . Hence C3n = Op (n−1/2 ) = op (1).
This ends the proof of Lemma A.5. 
The next two lemmas establish the (uniform) convergence of Gn (u, θ̂ n ) and ∆−1
n (θ̂ n ) to
G(u, θ 0 ) and ∆−1 (θ 0 ), respectively.
Lemma A.6 Under Assumptions 3.1-3.3, we have
sup Gn (u, θ̂ n ) − G(u, θ 0 ) = op (1).

u∈Π

Proof of Lemma A.6: The proof follows directly from the ULLN of Newey and McFadden
(1994). 
Lemma A.7 Under Assumptions 3.1-3.2, we have
−1
∆−1
n (θ̂ n ) = ∆ (θ 0 ) + op (1).

Proof of Lemma A.7: The proof follows from the ULLN of Newey and McFadden (1994) and
the continuous mapping theorem. 
Now, we are ready to proceed with the proofs of our main theorems.
Proof of Theorem 1: By a straightforward decomposition, we have
R̂np (u)

n
 n
o

1 X
′
−1
√
=
εi (θ̂ n ) 1 q(Xi , θ̂n ) ≤ u − g (Xi , θ̂ n )∆n (θ̂ n )Gn (u, θ̂ n )
n
i=1

=R̂n (u) −

1
G′n (u, θ̂ n )∆−1
n (θ̂ n ) √

n

n
X

εi (θ̂ n )g(Xi , θ̂ n )

i=1

:=R̂n (u) − G′n (u, θ̂ n )∆−1
n (θ̂ n )Ŝn .
By Lemmas A.4-A.7, we have that
n

√
1 X
R̂np (u) = √
εi (θ 0 )1 {q(Xi , θ 0 ) ≤ u} − G′ (u, θ 0 ) n(θ̂ n − θ0 )
n
i=1
#
"
n
X
√
1
εi (θ 0 )g(Xi , θ 0 ) − ∆(θ0 ) n(θ̂ n − θ0 ) + op (1)
− G′ (u, θ 0 )∆−1 (θ 0 ) √
n
i=1

n

1 X
=√
εi (θ 0 ) 1 {q(Xi , θ 0 ) ≤ u} − G′ (u, θ 0 )∆−1 (θ0 )g(Xi , θ0 ) + op (1)
n
i=1

38

p
=Rn0
(u) + op (1),

uniformly in u ∈ Π.
p
The weak convergence of Rn0
(u) and consequently the weak convergence of R̂np (u) to the
p
centered Gaussian process R∞
with covariance structure K p (u1 , u2 ) in (3.1) can be readily
p
obtained by showing that the ﬁnite-dimensional distributions of Rn0
(u) converge to those of
p
p
R∞
and the asymptotic equicontinuity of Rn0
(u) by a direct application of Lemma A.2. This

ends the proof of Theorem 1. 
Proof of Corollary 1: The weak convergence of the empirical process R̂np (u) and the conp
tinuous mapping theorem ensure the convergence in distribution of Γ(R̂np ) to Γ(R∞
) for any

continuous functional Γ(·) and in particular that of KSn to KS∞ .
For the test statistic CvMn , we will prove that
Z

Π

R̂np (u)

2

d

Fn (du) −
→

Z

Π

p
|R∞
(u)|2 Fθ0 (du).

The weak convergence of the processes R̂np (u) and

√

n(Fn (u) − Fθ0 (u)) (by Lemma A.2 and

Assumption 3.1) and the Skorohod construction (see Serﬂing, 1980), yield
p
sup R̂np (u) − R∞
(u) →a.s. 0,

(A.5)

sup |Fn (u) − Fθ0 (u)| →a.s. 0.

(A.6)

u

and
u

Now write
Z

Π

R̂np (u)

2

Fn (du) −

Z

Π

p
|R∞
(u)|2

Fθ0 (du) ≤

Z 
Π

+

Z

Π

R̂np (u)

2

−

p
|R∞
(u)|2



Fn (du)

p
|R∞
(u)|2 (Fn (du) − Fθ0 (du)) .

The ﬁrst term of the right-hand side of the above inequality is o(1) a.s. due to (A.5). The
p
trajectories of the limiting process R∞
(u) are bounded and continuous almost surely. Then, by

applying Helly-Bray Theorem (see p.97 in Rao, 1965) to each of these trajectories and taking
R
2
p
into account (A.6), we obtain Π |R∞
(u)| (Fn (du) − Fθ 0 (du)) →a.s. 0. This concludes the
proof of Corollary 1. 

Proof of Theorem 2: Under Assumptions 3.1-3.3, uniformly in u ∈ Π,
n

sup
u∈Π

n
o
o
1 Xn
εi (θ̂ n )Pn 1 q(Xi , θ̂ n ) ≤ u − E [ε(θ0 )P1 {q(X, θ 0 ) ≤ u}]
n
i=1

39

1
= sup √ R̂np (u) − E [(p (X) − q (X, θ 0 )) P1 {q(X, θ 0 ) ≤ u}]
n
u∈Π
=op (1)
by ULLN of Newey and McFadden (1994) and similar arguments in proving Lemmas A.3, A.6
and A.7. 
Proof of Theorem 3: Note that under the local alternatives H1n in (3.4), we have that
uniformly in u ∈ Π:
n

1 X
r(q(Xi , θ̂n ))
√
R̂np (u) = √
εi (θ̂ n ) −
n
n
+

i=1
n
X

1
n

i=1

!

n
o
Pn 1 q(Xi , θ̂ n ) ≤ u

n
o
r(q(Xi , θ̂ n ))Pn 1 q(Xi , θ̂n ) ≤ u


n 
r(q(Xi , θ 0 ))
1 X
√
εi (θ0 ) −
=√
P1 {q(Xi , θ 0 ) ≤ u}
n
n
i=1

+ E [r(q(X, θ 0 ))P1 {q(X, θ 0 ) ≤ u}] + op (1)
p
:=Rn1
(u) + ∆r (u) + op (1)
p
⇒R∞
+ ∆r ,

where the second equality follows by similar arguments in proving Theorem 1 and by ULLN.
Since εi (θ 0 ) − n−1/2 r(q(Xi , θ0 )) forms a zero mean and i.i.d. summand in this local alternative
p
framework, we can apply the functional central limit theorem to Rn1
(u), just as we applied it
p
p
p
(u) ⇒ R∞
. The last step then follows and we ﬁnish
to Rn0
(u) deﬁned in (2.14), leading to Rn1

the proof of Theorem 3. 
Proof of Theorem 4: As in Theorem 1, we have the following decomposition:
R̂np∗ (u)

n
 n
o

1 X
εi (θ̂n ) 1 q(Xi , θ̂ n ) ≤ u − g′ (Xi , θ̂n )∆−1
=√
n (θ̂ n )Gn (u, θ̂ n ) Vi
n
i=1

n
n
n
o
1 X
1 X
′
−1
=√
εi (θ̂n )1 q(Xi , θ̂n ) ≤ u Vi − Gn (u, θ̂ n )∆n (θ̂n ) √
εi (θ̂ n )g(Xi , θ̂ n )Vi
n
n
i=1

i=1

∗
:=R̂n∗ (u) − G′n (u, θ̂ n )∆−1
n (θ̂ n )Ŝn .

By Lemma A.2, it follows from a stochastic equicontinuity argument and the consistency of θ̂ n
to θ0 that, uniformly in u ∈ Π,
n

1 X
εi (θ0 )1 {q(Xi , θ0 ) ≤ u} Vi + op (1),
R̂n∗ (u) = √
n
i=1

40

and

n

Ŝn∗

1 X
=√
εi (θ 0 )g(Xi , θ 0 )Vi + op (1).
n
i=1

Thus, by Lemmas A.6 and A.7, uniformly in u,
n

1 X
R̂np∗ (u) = √
εi (θ 0 )(1 {q(Xi , θ0 ) ≤ u} − G′ (u, θ 0 )∆−1 (θ0 )g(Xi , θ 0 ))Vi + op (1)
n
1
=√
n

i=1
n
X
i=1

εi (θ 0 )P1 {q(Xi , θ 0 ) ≤ u} Vi + op (1)

p∗
:= Rn0
(u) + op (1),
p
leading to the multiplier bootstrapped version of Rn0
(u) in (2.14). The rest of the proof then
p∗
follows from the multiplier central limit theorem applied to process Rn0
(u); see van der Vaart

and Wellner (1996, Theorem 2.9.2, p.179), and the continuous mapping theorem. 

Appendix B: Simulation results with trimming
In Section 4 we found that the inverse probability weighting type AT E estimators and traditional balancing tests can perform poorly when estimated propensity scores are relatively close
to zero or one. In this section, we conduct the same Monte Carlo study as in Section 4 but we
\
trim observations with estimated propensity score outside [0.05, 0.95] when considering AT
En in
(4.3) and the classical balancing tests; for the other test statistics, we do not use any trimming.
Table B.1 and Table B.2 present the results under designs DGP 1-DGP 5, and DGP 6-DGP 10,
respectively.
As discussed in the main text, when the propensity score is correctly speciﬁed (DGP 1 and
\
DGP 6), the IPW estimator AT
En has very attractive ﬁnite sample properties, with little to
no bias, coverage probability close to its nominal level, and 95% conﬁdence interval length
shrinking with sample size n. Here it is important to emphasize that in DGP 1, in contrast
with the “untrimmed” AT E estimator in Table 1, the coverage probability of the “trimmed”
AT E estimator under is close to the nominal level. However, when the propensity score is
misspeciﬁed, bias does not vanish as sample size increases, and coverage probability can be
substantially lower than its nominal level.
In terms of size, we note that under DGP 1 balancing tests seem to perform relatively well
once we trim observations with “extreme” propensity score estimates, though with n = 1, 000,
the Wald test seems to be over-rejecting. On the other hand, when the dimension of the
41

Table B.1: Monte Carlo results under designs DGP 1-DGP 5 with trimming

42

DGP

n

CvMn

KSn

Tn (0.01)

Tn (0.05)

Tn (0.10)

Tn (0.15)

Max-t

W ald

CvMnunp

KSnunp

CvMntrad

KSntrad

Bias

CI length

Coverage

1
1
1
1
1
1
2
2
2
2
2
2
3
3
3
3
3
3
4
4
4
4
4
4
5
5
5
5
5
5

100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000

5.00
4.40
5.10
5.20
5.30
5.00
28.90
61.50
90.60
98.90
99.70
100.00
32.80
59.10
69.20
79.70
81.00
83.30
15.20
35.00
64.70
85.30
92.50
96.50
11.00
16.40
26.70
35.80
45.00
56.00

5.60
4.60
5.80
5.70
4.30
5.90
26.40
55.30
84.30
96.30
99.10
100.00
26.10
49.90
64.10
74.60
77.70
81.30
12.20
27.00
53.80
75.40
86.70
93.80
7.80
13.70
23.00
32.80
39.30
49.20

4.90
4.90
4.10
4.30
4.50
4.50
6.70
7.30
18.50
33.60
50.40
67.40
6.20
18.70
38.40
56.60
63.40
71.00
4.40
5.10
8.10
13.40
19.00
29.80
5.00
4.90
5.90
5.30
5.70
7.80

2.30
2.30
2.40
1.80
1.50
2.90
7.60
17.30
44.60
66.60
83.50
93.90
5.30
16.50
28.60
40.90
42.30
48.90
1.50
7.30
17.20
33.00
50.00
63.20
2.20
2.70
5.70
8.70
11.80
17.00

0.80
0.60
1.10
0.70
0.50
1.20
7.70
20.80
50.40
74.00
89.20
96.10
1.50
6.40
9.20
14.70
15.20
17.70
1.10
6.50
21.10
39.00
60.40
74.00
1.30
2.30
4.70
9.90
14.30
20.70

0.20
0.20
0.40
0.40
0.40
0.80
6.20
18.70
50.40
75.80
89.70
96.80
0.40
1.10
2.40
3.80
4.10
3.90
0.50
3.50
17.00
35.70
59.40
75.40
0.60
1.60
3.90
8.40
12.90
19.30

0.10
2.40
4.20
4.80
5.00
6.00
14.20
12.50
13.80
19.60
22.60
28.50
0.10
0.00
0.00
0.00
0.00
0.10
0.10
0.50
3.60
7.80
9.40
12.60
4.20
9.50
18.80
23.70
28.80
35.30

0.30
2.10
4.50
5.00
6.10
6.80
21.40
19.70
20.00
26.10
28.60
31.70
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.30
1.60
4.80
7.40
10.00
4.10
10.90
18.90
26.20
31.60
35.70

5.40
4.00
4.70
5.00
4.90
5.10
17.90
41.60
79.80
94.90
99.10
99.90
33.60
59.00
69.70
80.10
81.30
82.90
15.60
37.50
70.30
88.30
94.80
97.60
9.20
13.80
23.50
35.20
44.00
57.20

5.00
4.50
5.30
5.30
4.50
4.90
18.70
42.60
74.80
93.40
98.00
99.90
25.00
49.60
63.70
75.30
77.80
81.00
12.00
26.80
51.20
72.50
85.00
92.00
6.90
9.70
15.80
21.70
28.60
38.30

5.40
4.40
4.70
4.60
6.20
5.70
16.10
35.50
71.50
89.80
97.70
99.40
15.90
40.80
83.00
98.70
99.70
100.00
20.00
42.00
74.60
90.50
96.70
99.20
9.20
13.00
22.70
32.40
38.80
52.40

6.10
3.90
4.80
5.50
4.70
5.00
16.80
30.50
60.60
82.80
93.80
98.40
18.10
38.80
80.30
97.10
99.70
100.00
11.40
25.10
46.30
69.90
83.70
90.40
5.70
7.80
11.10
15.50
19.10
27.00

0.02
0.01
0.01
0.00
0.00
0.00
0.64
0.68
0.68
0.68
0.67
0.68
0.01
-0.01
0.00
0.00
0.00
0.00
0.16
0.16
0.16
0.16
0.16
0.16
0.37
0.44
0.47
0.46
0.46
0.46

1.26
0.91
0.67
0.56
0.49
0.44
3.30
2.62
1.94
1.63
1.43
1.29
0.87
0.57
0.39
0.32
0.27
0.24
0.90
0.60
0.42
0.34
0.29
0.26
1.68
1.29
0.99
0.84
0.74
0.66

93.70
94.00
93.90
93.30
93.70
93.80
76.10
75.40
70.00
59.70
51.60
45.20
95.90
94.70
94.70
95.70
96.20
95.80
90.80
81.20
69.30
56.10
42.00
32.50
72.70
62.10
48.60
42.60
32.40
23.90

Note: Simulations based on 1,000 Monte Carlo experiments. “CvMn ” and “KSn ” stand for our proposed Cramér-von Mises and Kolmogorov-Smirnov tests. “Tn (c)” stands for
Shaikh et al. (2009)’s test, with bandwidth hn = cn−1/8 . “Max-t” and “W ald” stand for, respectively, the Bonferroni-corrected Max-t-test, and Wald balancing tests based on

[
AT
E n X j deﬁned in (4.2) but with observations with estimated propensity score outside [0.05, 0.95] trimmed. “CvMnunp ” and “KSnunp ” are the Cramér-von Mises and KolmogorovSmirnov tests based on the unprojected empirical process R̂n (u) deﬁned in (2.10), whereas “CvMntrad ” and “KSntrad” are deﬁned analogously, but based on R̂ntrad (x) as deﬁned in
(4.1). Finally, “Bias”, “CI length’, and “Coverage” stand for the average simulated bias, estimated 95% conﬁdence interval length, and 95% coverage probability for the AT E estima\
tor AT
En as deﬁned in (4.3), but with observations with estimated propensity score outside [0.05, 0.95] trimmed. All entries are proportions of rejections at 5% level, in percentage
points, except “Bias” ,“CI length”, and “Coverage” (measure in percentage points), which are as described above. See the main text for further details.

Table B.2: Monte Carlo results under designs DGP 6-DGP 10 with trimming

43

DGP

n

CvMn

KSn

Tn (0.01)

Tn (0.05)

Tn (0.10)

Tn (0.15)

Max-t

W ald

CvMnunp

KSnunp

CvMntrad

KSntrad

Bias

CI length

Coverage

6
6
6
6
6
6
7
7
7
7
7
7
8
8
8
8
8
8
9
9
9
9
9
9
10
10
10
10
10
10

100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000
100
200
400
600
800
1000

8.50
5.70
5.60
5.00
5.40
4.90
9.50
15.40
26.40
37.20
49.50
57.20
9.50
18.30
46.50
66.30
79.90
87.00
10.00
15.10
30.40
44.10
57.60
70.50
7.50
10.00
19.20
36.20
50.20
64.30

9.40
6.10
6.00
5.20
5.20
6.00
10.60
14.90
24.20
33.00
46.50
52.90
10.60
18.70
41.80
62.10
74.40
82.10
12.00
15.10
26.80
36.10
50.20
57.50
8.30
10.10
16.70
28.10
38.90
51.70

5.80
4.00
5.10
4.90
5.10
4.50
4.10
5.10
5.40
9.10
9.90
11.90
5.70
4.40
8.10
15.80
23.30
31.30
3.50
4.70
4.50
5.70
6.60
5.30
4.10
5.10
5.20
4.60
7.70
8.20

2.50
2.50
2.40
1.70
2.70
2.80
1.60
3.30
6.60
10.70
16.70
22.90
1.30
4.20
16.00
27.50
42.70
52.70
2.40
3.70
3.10
6.10
8.80
11.30
1.30
1.80
3.80
7.30
11.30
18.20

1.00
1.00
0.90
0.60
1.40
1.10
0.70
2.00
6.80
11.10
17.00
24.30
0.80
3.60
15.80
28.10
45.60
55.00
0.40
1.80
2.80
6.70
11.00
15.70
0.60
0.80
2.80
6.80
13.20
22.30

0.20
0.40
0.30
0.20
0.70
0.50
0.00
1.10
5.20
8.70
13.90
21.60
0.20
2.80
11.60
24.20
40.00
51.20
0.20
0.80
2.90
6.00
10.40
16.60
0.30
0.30
1.80
4.80
11.10
18.90

0.30
0.30
0.40
1.20
1.20
1.90
0.40
0.70
0.40
0.70
0.60
0.50
1.30
1.40
1.10
1.70
2.10
2.20
0.30
0.50
0.70
1.50
2.10
1.60
0.10
0.00
0.00
0.10
0.10
0.10

0.30
0.10
0.00
0.10
0.40
0.80
2.60
1.50
0.60
0.70
0.50
0.30
5.50
5.00
3.00
2.00
2.80
2.80
1.90
2.40
1.80
4.10
4.30
4.70
0.10
0.00
0.00
0.00
0.00
0.00

7.80
5.70
5.80
3.70
4.60
5.70
6.80
13.60
23.00
33.70
46.40
55.60
8.20
14.80
41.70
60.60
74.90
82.40
10.10
12.40
21.30
32.50
46.80
59.30
6.80
10.30
20.60
37.70
52.80
67.00

9.40
6.50
6.30
5.00
5.00
5.80
8.40
13.90
19.90
30.10
37.70
47.50
9.90
15.50
37.10
54.20
68.30
77.70
12.40
12.00
17.00
25.30
35.60
45.60
8.70
9.30
14.90
27.70
38.80
51.40

1.10
2.30
3.30
3.80
2.60
3.70
2.50
2.70
4.60
8.30
13.80
17.70
2.20
3.40
9.10
20.80
30.90
42.20
1.20
4.00
8.50
17.10
25.40
35.60
4.00
4.40
6.90
10.10
15.20
21.00

1.70
3.90
4.50
3.70
4.20
5.40
3.80
6.00
7.90
9.30
13.70
16.20
3.70
5.30
9.10
16.10
22.30
25.40
2.50
7.10
12.00
20.10
29.30
39.80
3.90
4.90
8.60
8.20
12.60
13.90

-0.05
-0.01
-0.01
-0.01
-0.01
0.00
0.00
0.22
0.39
0.44
0.47
0.50
-0.12
0.21
0.49
0.59
0.67
0.73
-0.30
-0.17
0.01
0.05
0.10
0.13
-0.11
-0.10
-0.11
-0.11
-0.12
-0.12

2.94
1.80
1.22
0.98
0.84
0.76
5.56
3.45
2.30
1.82
1.56
1.41
7.46
4.69
3.26
2.65
2.27
2.03
4.82
2.89
2.03
1.67
1.44
1.31
2.24
1.25
0.81
0.65
0.55
0.49

95.20
95.00
95.10
93.60
94.80
93.70
95.70
97.70
98.50
97.30
90.80
82.70
93.00
97.30
98.80
96.30
87.60
77.90
89.80
90.40
93.70
93.10
90.50
89.50
97.20
96.70
93.50
91.30
87.50
83.10

Note: Simulations based on 1,000 Monte Carlo experiments. “CvMn ” and “KSn ” stand for our proposed Cramér-von Mises and Kolmogorov-Smirnov tests. “Tn (c)” stands for
Shaikh et al. (2009)’s test, with bandwidth hn = cn−1/8 . “Max-t” and “W ald” stand for, respectively, the Bonferroni-corrected Max-t-test, and Wald balancing tests based on

[
AT
E n X j deﬁned in (4.2) but with observations with estimated propensity score outside [0.05, 0.95] trimmed. “CvMnunp ” and “KSnunp ” are the Cramér-von Mises and KolmogorovSmirnov tests based on the unprojected empirical process R̂n (u) deﬁned in (2.10), whereas “CvMntrad ” and “KSntrad” are deﬁned analogously, but based on R̂ntrad (x) as deﬁned
in (4.1). Finally, “Bias”, “CI length’, and “Coverage” stands for the average simulated bias, estimated 95% conﬁdence interval length, and 95% coverage probability for the AT E
\
estimator AT
En as deﬁned in (4.3), but with observations with estimated propensity score outside [0.05, 0.95] trimmed. All entries are proportions of rejections at 5% level, in
percentage points, except “Bias” ,“CI length”, and “Coverage” (measure in percentage points), which are as described above. See the main text for further details.

covariates is relatively high as in DGP 6, these balancing tests tend to be conservative even
with trimming, reﬂecting the “curse of dimensionality”. In terms of power, it is clear that
balancing tests are dominated by our projection-based tests in all designs. In particular, as
shown in Table B.2 balancing tests can have zero to no power when the dimension of covariates
is high. The comparison between our tests and other speciﬁcation tests is exactly as discussed
in the main text and is therefore omitted.

Acknowledgements
We would like to thank Han Hong and Elie Tamer (Editors), an Associate Editor, and four
anonymous referees for comments that greatly improved this paper. We also thank Daniel
Millimet for sharing with us the data we use in the empirical application, Tymon Sloczyński,
Tatsushi Oka, and several seminar and conference participants for their useful comments.
Pedro H. C. Sant’Anna acknowledge ﬁnancial support from the Spanish Plan Nacional de
I+D+I (Grant No. ECO2014-55858-P). Xiaojun Song acknowledge ﬁnancial support from the
National Natural Science Foundation of China (Grant No. 71532001) and Key Laboratory of
Mathematical Economics and Quantitative Finance (Peking University), Ministry of Education.

References
Abadie, A., and Imbens, G. W. (2016), “Matching on the estimated propensity score,” Econometrica,
84(2), 781–807.
Akritas, M. G., and van Keilegom, I. (2001), “Non-Parametric Estimation of the Residual Distribution,”
Scandinavian Journal of Statistic, 28(3), 549–567.
Belloni, A., Chernozhukov, V., Fernandez-Val, I., and Hansen, C. (2017), “Program Evaluation and
Causal Inference With High-Dimensional Data,” Econometrica, 85(1), 233–298.
Belloni, A., Chernozhukov, V., and Hansen, C. (2014), “Inference on Treatment Eﬀects after Selection
among High-Dimensional Controls,” The Review of Economic Studies, 81(2), 608–650.
Bickel, P. J., Ritov, Y., and Stoker, T. M. (2006), “Tailor-made tests for goodness of ﬁt to semiparametric
hypotheses,” Annals of Statistics, 34(2), 721–741.
Bierens, H. J. (1982), “Consistent model speciﬁcation tests,” Journal of Econometrics, 20(1982), 105–
134.
Bierens, H. J. (1990), “A consistent conditional moment test of functional form,” Econometrica,
58(6), 1443–1458.
Bierens, H. J., and Ploberger, W. (1997), “Asymptotic theory of integrated conditional moment tests,”
Econometrica, 65(5), 1129–1151.
Busso, M., Dinardo, J., and McCrary, J. (2014), “New Evidence on the Finite Sample Properties of
Propensity Score Reweighting and Matching Estimators,” The Review of Economics and Statistics,
96(5), 885–895.

44

Chernozhukov, V., Escanciano, J. C., Ichimura, H., and Newey, W. K. (2016), “Locally Robust Semiparametric Estimation,” arXiv preprint arXiv:1608.00033, .
Crump, R. K., Hotz, V. J., Imbens, G. W., and Mitnik, O. A. (2009), “Dealing with limited overlap in
estimation of average treatment eﬀects,” Biometrika, 96(1), 187–199.
Dehejia, R., and Wahba, S. (2002), “Propensity score-matching methods for nonexperimental causal
studies,” The Review of Economics and Statistics, 84(1), 151–161.
Dominguez, M. A., and Lobato, I. N. (2004), “Consistent Estimation of Models Deﬁned by Conditional
Moment Restrictions,” Econometrica, 72(5), 1601–1615.
Donald, S. G., and Hsu, Y.-C. (2014), “Estimation and inference for distribution functions and quantile
functions in treatment eﬀect models,” Journal of Econometrics, 178(3), 383–397.
Escanciano, J. C. (2006a), “A consistent diagnostic test for regression models using projections,” Econometric Theory, 22, 1030–1051.
Escanciano, J. C. (2006b), “Goodness-of-Fit Tests for Linear and Nonlinear Time Series Models,” Journal
of the American Statistical Association, 101(474), 531–541.
Escanciano, J. C. (2009a), “On the Lack of Power of Omnibus Speciﬁcation Tests,” Econometric Theory,
25(01), 162–194.
Escanciano, J. C. (2009b), Simple bootstrap tests for conditional moment restrictions,, Technical report,
Indiana University.
Escanciano, J. C., and Goh, S. C. (2014), “Speciﬁcation analysis of linear quantile models,” Journal of
Econometrics, 178, 495–507.
Fan, Y., and Li, Q. (1996), “Consistent model speciﬁcation tests: omitted variables and semiparametric
functional forms,” Econometrica, 64(4), 865–890.
Firpo, S. (2007), “Eﬃcient semiparametric estimation of quantile treatment eﬀects,” Econometrica,
75(1), 259–276.
Fortin, N., Lemieux, T., and Firpo, S. (2011), “Decomposition Methods in Economics,” Handbook of
Labor Economics, 4(a), 1–102.
Frankel, J. A., and Rose, A. K. (2005), “Is Trade Good or Bad for the Environment? Sorting Out the
Causality,” Review of Economics and Statistics, 87(1), 85–91.
Frazier, D. T., Oka, T., and Zhu, D. (2018), “Indirect Inference with a Non-Smooth Criterion Function,”
Mimeo, .
Frölich, M. (2004), “Finite-sample properties of propensity-score matching and weighting estimators,”
The Review of Economics and Statistics, 86(1), 77–90.
González-Manteiga, W., and Crujeiras, R. M. (2013), “An updated review of Goodness-of-Fit tests for
regression models,” Test, 22(3), 361–411.
Hahn, J. (1998), “On the Role of the Propensity Score in Eﬃcient Semiparametric Estimation of Average
Treatment Eﬀects,” Econometrica, 66(2), 315–331.
Hardle, W., and Mammen, E. (1993), “Comparing nonparametric versus parametric regression ﬁts,” The
Annals of Statistics, 21(4), 1926–1947.
Heckman, J. J., Ichimura, H., Smith, J., and Todd, P. (1998), “Characterizing selection bias using
experimental data,” Econometrica, 66(5), 1017–1098.
Heckman, J. J., Ichimura, H., and Todd, P. (1997), “Matching as an econometric evaluation estimator:
Evidence from evaluating a job training programme,” The Review of Economic Studies, 64(4605-654).
Heckman, J. J., Ichimura, H., and Todd, P. (1998), “Matching as an econometric evaluation estimator,”
The Review of Economic Studies, 65(2), 261–294.
Heckman, J. J., and Vytlacil, E. J. (2007), “Econometric evaluation of social programs, part I:
Causal models, structural models and econometric policy evaluation,” Handbook of Econometrics,
6B(70), 4779–4874.

45

Hirano, K., Imbens, G. W., and Ridder, G. (2003), “Eﬃcient estimation of average treatment eﬀects
using the estimated propensity score,” Econometrica, 71(4), 1161–1189.
Huber, M., Lechner, M., and Wunsch, C. (2013), “The performance of estimators based on the propensity
score,” Journal of Econometrics, 175(1), 1–21.
Imbens, G. W., and Wooldridge, J. M. (2009), “Recent developments in the econometrics of program
evaluation,” Journal of Economic Literature, 47(1), 5–86.
Janssen, A. (2000), “Global power functions of goodness of ﬁt tests,” Annals of Statistics, 28(1), 239–253.
Khan, S., and Tamer, E. (2010), “Irregular Identiﬁcation, Support Conditions, and Inverse Weight
Estimation,” Econometrica, 78(6), 2021–2042.
Lee, S., Seo, M. H., and Shin, Y. (2011), “Testing for threshold eﬀects in regression models,” Journal of
the American Statistical Association, 106(493), 220–231.
Lee, W.-S. (2013), “Propensity score matching and variations on the balancing test,” Empirical Economics, 44(1), 47–80.
Leeb, H., and Pötscher, B. M. (2005), “Model selection and inference: Facts and ﬁction,” Econometric
Theory, 21(1), 21–59.
Li, Q., and Wang, S. (1998), “A simple consistent bootstrap test for a parametric regression function,”
Journal of Econometrics, 87(1), 145–165.
Mammen, E. (1993), “Bootstrap and wild bootstrap for high dimensional linear models,” The Annals of
Statistics, 21(1), 255–285.
Millimet, D. L., and Tchernis, R. (2009), “On the Speciﬁcation of Propensity Scores, With Applications
to the Analysis of Trade Policies,” Journal of Business & Economic Statistics, 27(3), 397–415.
Newey, W. K., and McFadden, D. (1994), “Large sample estimation and hypothesis testing,” in Handbook
of Econometrics, Vol. 4, Amsterdam: North-Holland:, chapter 36, pp. 2111–2245.
Neyman, J. (1959), “Optimal Asymptotic Tests of Composite Statistical Hypotheses,” in Probability and
Statistics: The Harald Cramer Vaolume, ed. U. Grenander, Stockholm:, pp. 213–234.
Rao, C. R. (1965), Linear Statistical Inference and its Applications, New York: Wiley.
Rose, A. K. (2004), “Do WTO members have more liberal trade policy?,” Journal of International
Economics, 63(2), 209–235.
Rosenbaum, P. R. (1987), “Model-Based Direct Adjustment,” Journal of the American Statistical Association, 82(398), 387–394.
Rosenbaum, P. R., and Rubin, D. B. (1983), “The central role of the propensity score in observational
studies for causal eﬀects,” Biometrika, 70(1), 41–55.
Rosenbaum, P. R., and Rubin, D. B. (1985), “Constructing a control group using multivariate matched
sampling methods that incorporate the propensity score,” The American Statistician, 39(1), 33–38.
Sasaki, Y., and Ura, T. (2018), “Inference for moments of ratios with robustness against large trimming
bias and unknown convergence rate,” arXiv preprint arXiv:1709.00981v4, pp. 1–60.
Serﬂing, R. J. (1980), Approximation Theorems of Mathematical Statistics, New York: Wiley.
Shaikh, A. M., Simonsen, M., Vytlacil, E. J., and Yildiz, N. (2009), “A speciﬁcation test for the propensity
score using its distribution conditional on participation,” Journal of Econometrics, 151(1), 33–46.
Shorack, G. R. (2000), Probability for Statisticians, Vol. 97 of Springer Texts in Statistics, 1st edn, Cham:
Springer.
Sloczyński, T., and Wooldridge, J. M. (2018), “A General Double Robustness Result for Estimating
Average Treatment Eﬀects,” Econometric Theory, 34(1), 112–133.
Smith, J. A., and Todd, P. E. (2005), “Does matching overcome LaLonde’s critique of nonexperimental
estimators?,” Journal of Econometrics, 125, 305–353.
Strasser, H. (1990), “Global extrapolation of local eﬃciency,” Statistics and Decisions, 8, 11–26.
Stute, W. (1997), “Nonparametric model checks for regression,” The Annals of Statistics, 25(2), 613–641.

46

Stute, W., González-Manteiga, W., and Quindimil, M. P. (1998), “Bootstrap Approximations in Model
Checks for Regression,” Journal of the American Statistical Association, 93(441), 141–149.
Stute, W., and Wang, J.-L. (1993), “The strong law under random censorship,” The Annals of Statistics,
21(3), 1591–1607.
Stute, W., and Zhu, L.-X. (2002), “Model Checks for Generalized Linear Models,” Scandinavian Journal
of Statistics, 29(3), 535–545.
van der Vaart, A. W., and Wellner, J. A. (1996), Weak Convergence and Empirical Processes, New York:
Springer.
van der Vaart, A. W., and Wellner, J. A. (2007), “Empirical processes indexed by estimated functions,”
in Asymptotics: Particles, Processes and Inverse Problems, Vol. 55, Beachwood, Ohio, USA: Institute
of Mathematical Statistics, pp. 234–252.
Zheng, J. X. (1996), “A consistent test of functional form via nonparametric estimation techniques,”
Journal of Econometrics, 75, 263–289.

47

