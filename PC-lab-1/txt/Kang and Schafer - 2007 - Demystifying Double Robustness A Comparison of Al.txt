Statistical Science
2007, Vol. 22, No. 4, 523–539
DOI: 10.1214/07-STS227
© Institute of Mathematical Statistics, 2007

Demystifying Double Robustness:
A Comparison of Alternative Strategies for
Estimating a Population Mean from
Incomplete Data1
Joseph D. Y. Kang and Joseph L. Schafer

Abstract. When outcomes are missing for reasons beyond an investigator’s
control, there are two different ways to adjust a parameter estimate for covariates that may be related both to the outcome and to missingness. One
approach is to model the relationships between the covariates and the outcome and use those relationships to predict the missing values. Another is
to model the probabilities of missingness given the covariates and incorporate them into a weighted or stratified estimate. Doubly robust (DR) procedures apply both types of model simultaneously and produce a consistent
estimate of the parameter if either of the two models has been correctly specified. In this article, we show that DR estimates can be constructed in many
ways. We compare the performance of various DR and non-DR estimates of
a population mean in a simulated example where both models are incorrect
but neither is grossly misspecified. Methods that use inverse-probabilities as
weights, whether they are DR or not, are sensitive to misspecification of the
propensity model when some estimated propensities are small. Many DR
methods perform better than simple inverse-probability weighting. None of
the DR methods we tried, however, improved upon the performance of simple regression-based prediction of the missing values. This study does not
represent every missing-data problem that will arise in practice. But it does
demonstrate that, in at least some settings, two wrong models are not better
than one.
Key words and phrases: Causal inference, missing data, propensity score,
model-assisted survey estimation, weighted estimating equations.
1. INTRODUCTION
1.1 Purpose

A new class of methods called doubly robust (DR)
procedures was designed to mitigate selection bias arising from uncontrolled nonresponse and attrition, nonrandom treatment assignment in observational studies and noncompliance in randomized experiments
(Robins and Rotnitzky, 2001; van der Laan and Robins,
2003). DR methods require specification of two models: one that describes the population of responses, and
another that describes the process by which the data
are filtered or selected to produce the observed sample. The distinguishing feature of DR estimates is that

Joseph D. Y. Kang is Research Associate, The Methodology
Center, 204 E. Calder Way, Suite 400, State College,
Pennsylvania 16801, USA (e-mail:
josephkang@stat.psu.edu). Joseph L. Schafer is Associate
Professor, The Methodology Center, 204 E. Calder Way,
Suite 400, State College, Pennsylvania 16801, USA (e-mail:
jls@stat.psu.edu).
1 Discussed in 10.1214/07-STS227A, 10.1214/07-STS227B,

10.1214/07-STS227C and 10.1214/07-STS227D; rejoinder at
10.1214/07-STS227REJ.

523

524

J. D. Y. KANG AND J. L. SCHAFER

they remain asymptotically unbiased if one of the two
models is misspecified—that is, they consistently estimate their targets if either model is true (Robins and
Rotnitzky, 1995).
DR methods are a refinement of a weighted estimating-equations approach to regression with incomplete data proposed by Robins, Rotnitzky and Zhao
(1994, 1995) and Rotnitzky, Robins and Scharfstein
(1998). Further explanation and evaluation of DR estimators has been given by Lunceford and Davidian
(2004), Carpenter, Kenward and Vansteelandt (2006),
Davidian, Tsiatis and Leon (2005) and Bang and
Robins (2005). What is not widely known, however,
is that the methods developed by Robins et al. are not
the only way to achieve double robustness. Many other
types of estimates possess the DR property. Generalized regression estimators developed for sample surveys (Cassel, Särndal and Wretman, 1977), also known
as model-assisted survey estimators (Särndal, Swensson and Wretman, 1989, 1992), have this property, as
does a new class of parametric methods developed by
Little and An (2004) and several other methods that do
not seem to have been described before.
The first purpose of this article is pedagogical. We
review a variety of incomplete-data estimation strategies, describe various ways in which the DR property
can arise, and connect the recent articles on DR estimation to similar techniques found in the literature on
sample surveys and causal inference. Our second purpose is to investigate the practical behavior of these estimators not only when either of the underlying models is correct, but in a scenario where both models are
moderately misspecified.
1.2 Description of the Problem

For simplicity, we focus on the problem of estimating a population mean from an incomplete dataset.
Many of the methods we present have been applied
to the more general problem of estimating populationaverage regression coefficients, and we will describe
those extensions where appropriate. Let us suppose
that we have a random sample of units i = 1, . . . , n
from an infinite population. The variable of primary
interest is yi . Let ti be the response indicator for yi ,
so that ti = 1 if yi is observed and ti = 0 if yi is missing. For each unit, there is an observed p-dimensional
vector of covariates xi that may be related both to yi
and to ti . A schematic representation of the sample
data is shown in Figure 1(a). (In this figure, the indices
i = 1, . . . , n have been permuted so that the sample
units having ti = 1 appear first.) Denote the numbers

F IG . 1. Schematic representation of sample data for estimating
(a) a population mean and (b) an average causal effect, with missing values denoted by shading.



of respondents
and nonrespondents by n(1) = i ti and

n(0) = i (1 − ti ), the population response and nonresponse rates by r (1) = P (ti = 1) and r (0) = P (ti =
0), and the sample rates by r̂ (1) = n(1) /n and r̂ (0) =
n(0) /n.
The sample mean of the observed yi ’s,
ȳ (1) =

1 
ti yi ,
n(1) i

consistently estimates the mean for the respondents,
μ(1) = E(yi | ti = 1), under any reasonable population
distribution and response mechanism. An estimator
having this property will be said to be strongly robust.
In general, there is no strongly robust estimate of the
mean for the nonrespondents, μ(0) = E(yi | ti = 0),
or for the mean of the entire population, μ = E(yi ) =
r (0) μ(0) + r (1) μ(1) , based on the observed data alone.
Naive estimates such as ȳ (1) may work well enough
if r̂ (0) is small and the relationships among xi , ti and
yi are weak. As the nonresponse rate and the strength
of these relationships grow, adjusting for selection bias
becomes important, and inferences become sensitive to
the assumptions underlying the adjustment.
This problem is closely related to estimating an average causal effect from an experiment or observational
study. Suppose now that ti is an indicator of the treatment received by unit i. Associated with unit i is a
pair of potential outcomes: the response yi1 that is realized if ti = 1, and another response yi0 that is realized if ti = 0. This situation is depicted in Figure 1(b).

525

DEMYSTIFYING DOUBLE ROBUSTNESS

The causal effect of the treatment on unit i, defined as
yi1 − yi0 , is unobservable because one of the two potential outcomes is necessarily missing. It is often of
interest to estimate the average causal effect (ACE) in
the population,
ACE = E(yi1 ) − E(yi0 ),
or the ACE’s among the treated and the untreated,
ACE(1) = E(yi1 | ti = 1) − E(yi0 | ti = 1),

assumptions about P (ti | xi ), P (yi | xi ) or both. Denote the response probability for unit i by
(1)

This probability is called the propensity score (Rosenbaum and Rubin, 1983). A proposed functional form
for (1) will be called a π -model. If estimates of the
propensity scores are needed, they are often taken to
be

ACE(0) = E(yi1 | ti = 0) − E(yi0 | ti = 0).
The notion of potential outcomes was introduced by
Neyman (1923) for randomized experiments and by
Rubin (1974a) for nonrandomized studies. Reviews of
causal inference from this perspective are given by
Holland (1986), Winship and Sobel (2004), Gelman
and Meng (2004) and Rubin (2005). From Figure 1(b),
it is apparent that the correlation between yi1 and yi0
[more precisely, the partial correlation between them
given xi ; see Rubin (1974b)] cannot be estimated from
the observed data. Without prior information on what
this correlation might be—and it is unclear from where
such information would come—one may separate the
problem of estimating an ACE into independent estimation of the means of yi1 and yi0 . Any of the methods
described in this article can be used to estimate an average causal effect by applying the method separately to
each potential outcome. When estimating ACE’s, rates
of missing information tend to be high and sensitivity
to modeling assumptions may be acute.
1.3 Assumptions

Throughout this article, we will assume that the response mechanism is unconfounded in the sense that yi
and ti are conditionally independent given xi (Rubin,
1978); this assumption has also been called strong ignorability (Rosenbaum and Rubin, 1983). Under strong
ignorability, the joint distribution of the complete data
can be written as
P (X, T , Y ) =



P (xi )P (ti | xi )P (yi | xi ).

i

Strong ignorability implies that the missing yi ’s are
missing at random (MAR) (Rubin, 1976; Little and
Rubin, 2002). In many applications, MAR is unrealistic. Nevertheless, this assumption provides an important benchmark and point of departure for sensitivity
analyses, and it is the foundation upon which DR procedures rest.
None of the methods we examine will require an explicit model for the covariates, but they will all make

P (ti = 1 | xi ) = πi (xi ) = πi .

π̂i = expit(xiT α̂) =

exp(xiT α̂)
,
1 + exp(xiT α̂)

where α̂ is the maximum-likelihood (ML) estimate of
the coefficients from the logistic regression of t1 , . . . , tn
on x1 , . . . , xn . In many situations, of course, the assumed form of the π -model is not correct, and this misspecification can be problematic depending on how the
π̂i ’s are used.
Let us also define E(yi | xi ) = m(xi ) = mi , so that
(2)

yi = m(xi ) + εi

with E(εi ) = 0. A functional form for m(xi ) will be
called a y-model. When an estimate of mi is needed,
an obvious candidate is m̂i = xiT β̂, where β̂ is the vector of coefficients from the linear regression of yi on xi
estimated from the respondents; y-models with nonlinear link functions are also straightforward (McCullagh
and Nelder, 1989). In most cases, an analyst’s regression model will be only a rough approximation to the
true y-model. The implications of this misspecification
can be serious if P (xi | ti = 1) and P (xi | ti = 0) are
very different, because the m̂i ’s for the nonrespondents
will then be based on extrapolation. This is particularly
true when xi is high-dimensional because of the socalled curse of dimensionality. With many covariates,
it becomes difficult to specify a y-model that is sufficiently flexible to capture important nonlinear effects
and interactions, yet parsimonious enough to keep the
variance of prediction manageably low.
Under ignorability, the πi ’s play no role in likelihood-based or Bayesian analyses for the parameters of the y-model (Rubin, 1976). The parametric
approach—specifying a full model for yi and ignoring
the πi ’s—is emphasized in texts on missing data by
Rubin (1987), Schafer (1997), Little and Rubin (2002)
and others. Nevertheless, many advocates of the parametric approach also recognize that the πi ’s are useful for model validation and criticism (Gelman, Carlin,
Rubin and Stern, 2004, Chapters 6–7). On the other
hand, much of the literature on causal inference in
the tradition of Rosenbaum and Rubin (1983) eschews

526

J. D. Y. KANG AND J. L. SCHAFER

models for yi in favor of matching and stratification
based on propensity scores (e.g., Rosenbaum, 2002).
The latter is motivated in part by a perceived inability
to model the responses well enough to mitigate the dangers of extrapolation. Other uses for propensity scores,
including inverse-propensity weighting (Robins, Rotnitzky and Zhao, 1994), also rely heavily on a π -model
while relaxing assumptions about yi . DR methods will
require both a y-model and a π -model but remain consistent if one or the other is wrong. As we shall see,
however, this property does not necessarily translate
into improved performance when both models fail.
1.4 A Simulated Example

Consider the following example which, although artificial, bears some resemblance to what we have encountered in a real study. For each unit i = 1, . . . , n,
suppose that (zi1 , zi2 , zi3 , zi4 )T is independently distributed as N(0, I ) where I is the 4 × 4 identity matrix.
The yi ’s are generated as
yi = 210 + 27.4zi1 + 13.7zi2 + 13.7zi3 + 13.7zi4 + εi ,
where εi ∼ N(0, 1), and the true propensity scores are
πi = expit(−zi1 + 0.5zi2 − 0.25zi3 − 0.1zi4 ).
This mechanism produces an average response rate of
r (1) = 0.5, and the means are μ = 210.0, μ(1) = 200.0
and μ(0) = 220.0. The selection bias in this example is
not severe; the difference between the mean of the respondents and the mean of the full population is only
one-quarter of a population standard deviation. Nevertheless, this difference is large enough to wreak havoc
on the performance of the naive estimate ȳ (1) when
used as the basis for confidence intervals and tests.
In this example, a logistic regression of ti on the zij ’s
would be a correct π -model, and a linear regression of
yi on the zij ’s would be a correct y-model. We will
suppose, however, that instead of being given the zij ’s,
the covariates actually seen by the data analyst are
xi1 = exp(zi1 /2),




xi2 = zi2 / 1 + exp(zi1 ) + 10,
xi3 = (zi1 zi3 /25 + 0.6)3 ,
xi4 = (z2 + z4 + 20)2 .
This implies that logit(πi ) and mi are linear functions
1/2
of log(xi1 ), x2 , x12 x2 , 1/ log(x1 ), x3 / log(x1 ) and x4 .
Except by divine revelation, it is unlikely that an analyst who sees only xi would ever formulate a correct π - or y-model. Rather, he or she would naturally

be drawn to models that are linear and logistic in the
xij ’s, and those incorrect models look trustworthy. To
illustrate, we drew a random sample of n = 200 units
from this population, which happened to produce exactly n(1) = 100 respondents and n(0) = 100 nonrespondents. Scatterplots of yi versus xij , j = 1, . . . , 4,
for the 100 respondents are shown in Figure 2. Regressing yi on the xij ’s yields coefficients for xi1 , xi3 and xi4
that are highly significant and a coefficient for xi2 that
is nearly significant at the 0.05-level; the prediction is
strong (R 2 = 0.81), and a plot of residuals versus fitted
values reveals no obvious outliers and little evidence
of heteroscedasticity or nonlinearity. (In other samples,
some higher-order terms such as x12 and x1 x2 , are significant and might be considered for inclusion in the
model. Those terms, however, do little to improve the
performance of any of the regression-based methods
discussed below, and sometimes they are harmful.)
The covariates seen by the analyst are also related
to the ti ’s. Side-by-side boxplots of the xij ’s for the
ti = 0 and ti = 1 groups are shown in Figure 3(a)–(d).
Fitting a logistic model to this sample, we find that the
coefficients for xi1 and xi2 are statistically significant,
and all of the deviance residuals lie between −1.85 and
+2.51. Figure 3(e) shows side-by-side boxplots of the
linear predictors η̂i = logit(π̂i ). As one would expect,
the distributions of π̂i in the two groups are different
but not drastically so. To check the appropriateness of
the link function, Hinkley (1985) suggested adding η̂i2
as another covariate to see whether it is related to the
response; the coefficient for this extra term was not
significantly different from zero (p = 0.20), so in this
sample an analyst would have little reason to alter the
link.
Comparing the fitted values of yi under the true and
misspecified y-models, we find that the correlation between them is approximately 0.9. Similarly, the correlation between the η̂i ’s under the true and misspecified
π -models is also about 0.9. This example appears to be
precisely the type of situation for which the DR estimators of Robins et al. were developed. By relying on two
reasonably good models, one hopes that at least one is
close enough to the truth to yield satisfactory results.
Indeed, Bang and Robins (2005, Section 2.1) state:
In our opinion, a DR estimator has the following advantage that argues for its routine
use: if either the [y-model] or the [π -model]
is nearly correct, then the bias of a DR estimator of μ will be small. Thus, the DR es-

DEMYSTIFYING DOUBLE ROBUSTNESS

F IG . 2.

527

Scatterplots of response versus observed covariates for respondents in a sample of 200 units.

timator . . . gives the analyst two chances to
get nearly correct inferences about the mean
of Y .

In Sections 2 and 3, we describe various techniques
for estimating μ based on the observed data and evaluate their performance in this simulated example. Some

F IG . 3. Distributions of (a)–(d) observed covariates and (e) estimated propensity scores for nonrespondents and respondents in a sample
of 200 units.

528

J. D. Y. KANG AND J. L. SCHAFER

of these methods use a π -model, some use a y-model,
and some rely on both. All of the dual-modeling strategies possess a DR property, but they do not perform
equally well. Pooling information from two models can
be helpful, but the manner in which the information is
pooled makes a difference. (Due to space limitations,
we will not discuss computation of standard errors.
Tractable variance estimates are available for most of
these methods, but our purpose is to compare the performance of the estimates themselves.) In Section 4,
we will provide further justification for why we constructed our example as we did, and we will outline the
crucial differences between this and simulated examples used by Bang and Robins (2005) and others, so
that apparently contradictory conclusions can be reconciled.
2. WEIGHTING, STRATIFICATION
AND REGRESSION
2.1 Inverse-Propensity Weighting

Weighting observed values by inverse-probabilities
of selection was proposed by Horvitz and Thompson
(1952) in the context of survey inference for finite populations. The same idea is used in importance sampling, a Monte Carlo technique for approximating the
moments of a distribution using random draws from
another distribution that approximates it (Hammersley
and Handscomb,
1964; Geweke, 1989). It is easy to see

−1
−1
that n
i ti πi yi , which can be computed from the
respondents alone, unbiasedly estimates the mean of
the entire population, because strong ignorability implies that
E(ti πi−1 yi ) = E(E(ti πi−1 yi | xi ))
= E(πi πi−1 mi ) = μ.
Precision
is often enhanced if we use a denominator of

−1
rather than n, so that the estimate becomes
i ti πi
a weighted average of the yi ’s for the respondents.
Normalizing the weights in this manner, and replacing
the unknown propensities by estimates derived from a
π -model, the inverse-propensity weighted (IPW) estimate becomes


(3)

μ̂IPW -POP = i

ti π̂i−1 yi

−1
i ti π̂i

.

The “POP” in the subscript indicates that we are
reweighting the respondents to resemble the full population. Alternatively, we may reweight them to approximate the population of nonrespondents (Hirano and

Imbens, 2001). An estimate of μ(0) based on that idea
is

(0)
μ̂IPW -NR

= i

ti π̂i−1 (1 − π̂)yi

−1
i ti π̂i (1 − π̂)

,

and a corresponding estimate of μ is
(4)

μ̂IPW -NR = r̂ (1) ȳ (1) + r̂ (0) μ̂(0)
IPW -NR .

The IPW estimator can also be regarded as the
solution to a simple weighted estimating equation

−1
2
i wi Ui = 0, where wi = ti π̂i and Ui = (yi − μ)/σ
for any σ 2 > 0. From this standpoint, the IPW method
can be generalized to estimate a vector of populationaverage coefficients for the regression of yi on an arbitrary set of covariates. In the regression setting, Ui
becomes a vector representing the ith unit’s contribution to a quasi-score function. Coefficients estimated in
this manner are consistent and asymptotically normally
distributed provided that the πi ’s are bounded away
from zero and the π -model has been correctly specified. Asymptotic properties and methods for variance
estimation are described by Binder (1983) when the
propensities are known, and by Robins, Rotnitzky and
Zhao (1994, 1995) when the propensities have been
estimated.
In the original method of Horvitz and Thompson
(1952), the πi ’s were determined by a known survey
design. Surveys are usually designed to ensure that
IPW estimates are acceptably precise, but the forces
of nature that govern uncontrolled nonresponse are often unkind. In missing-data problems, IPW methods
assign large weights to respondents who closely resemble nonrespondents, causing the estimates to have high
variance. IPW estimates are also sensitive to misspecification of the π -model, because even mild lack of fit
in outlying regions of the covariate space where πi ≈ 0
translates into large errors in the weights. These shortcomings of IPW estimators have been known for many
years; see, for example, the comments of Little and
Rubin (1987, Section 4.4.3) on the IPW methods for
nonresponse proposed by Cassel, Särndal and Wretman (1983).
To see how well IPW performs on the artificial population described in Section 1.4, we created 1000 samples of n = 200 and n = 1000 units each and, for each
sample, estimated the propensity scores in two ways.
First, we fit a correctly specified π -model, regressing the ti ’s on zi1 , zi2 , zi3 and zi4 using a logit link.
Second, we fit the incorrect model which replaces the

529

DEMYSTIFYING DOUBLE ROBUSTNESS

zij ’s with xij ’s. The behavior of the four IPW estimates (3)–(4) under the correctly and incorrectly specified π -models is summarized in Table 1. In this table,
“Bias” is the average difference between the estimate
and μ = 210, and “% Bias” is the bias as a percentage of the estimate’s standard deviation. (A useful rule
of thumb is that the performance of interval estimates
and test statistics begins to deteriorate when the bias
of the point estimate exceeds about 40% of its standard deviation.) “RMSE” is square root of the average value of (μ̂ − μ)2 . Examining Table 1, we see
that the IPW estimates are biased when the π -model is
misspecified, and the biases are accompanied by huge
losses in precision. In fact, the bias and RMSE actually get worse as the sample size grows! IPW estimates have higher variance than other procedures examined in this article even when the propensities are
correctly modeled, but when the π -model is incorrect,
the method breaks down. Interestingly, NR weighting
performs better than POP weighting; we do not know
whether the superiority of NR is a peculiar feature of
this example or if it tends to hold more generally.
The poor performance of IPW is due in part to occasional highly erratic estimates produced by a few enormous weights. In practice, a good data analyst would
never use a simple IPW estimator if the weights were
too extreme. Unusually large weights may be taken as
a sign of model failure, prompting the researcher to revise the π -model. Outlying weights may be truncated
or shrunk to more sensible values, or the offending
units with large weights may be removed. (Removing
these units is not recommended, because the respondents with the lowest propensities are in fact those
that contain the best information for predicting nonrespondent behavior.) Analysts who apply IPW to real
problems quickly learn that it often cannot be used
without ad hoc modifications. The column of Table 1

labeled “MAE” reports the median of the absolute errors |μ̂ − μ|, which discards the worst 50% of the estimates. Even by this robust measure of precision, IPW
performs more poorly than the other methods we examine when the π -model is misspecified, and it fails to
improve as the sample size grows.
In many applications of IPW methodology, weights
are obtained by logistic regression. Logistic models
can be a poor way to estimate response propensities,
because ML estimates from the logistic model are not
resistant to outliers (Pregibon, 1982). A promising alternative is the robit model, which replaces the logistic
link by the cumulative distribution function of a Student’s t-distribution with ν degrees of freedom (Albert
and Chib, 1993). The logit link is well approximated
by the robit with ν = 7, and smaller values of ν lead
to estimates that are more robust (Liu, 2004). In this
example, robit models produce minor improvements
when the covariates are correct and major improvement when the covariates are wrong. We found that,
with samples of n = 1000, replacing the logit link by
robit with ν = 4 reduces the bias and RMSE by nearly
50% when the π -model is incorrect. If IPW must be
used, replacing the logistic regression with a more robust procedure can be advantageous.
2.2 Propensity-Based Stratification

To mitigate the dangers of extreme weights and misspecification of the π -model, some prefer to coarsen
the estimated propensity scores into a few categories
and compute weighted averages of the mean response
across categories. In the context of survey nonresponse, the technique is known as weighting-cell estimation or adjustment (Oh and Scheuren, 1983; Little,
1986; Little and Rubin, 2002). Strong ignorability implies that yi and ti are conditionally independent within

TABLE 1
Performance of IPW estimators of μ over 1000 samples from the artificial population
Sample size

π -model

(a) n = 200

Correct
Incorrect

(b) n = 1000

Correct
Incorrect

Method

Bias

% Bias

RMSE

MAE

IPW-POP
IPW-NR
IPW-POP
IPW-NR
IPW-POP
IPW-NR
IPW-POP
IPW-NR

−0.27
−0.29
1.58
0.61
−0.01
−0.03
5.05
3.22

−7.0
−8.2
19.2
10.3
−0.5
−1.5
45.9
49.1

3.86
3.60
8.35
5.99
1.81
1.68
12.10
7.29

2.43
2.36
3.32
3.03
1.16
1.09
2.80
2.34

530

J. D. Y. KANG AND J. L. SCHAFER

any subpopulation for which πi (xi ) is constant (Rosenbaum and Rubin, 1983). In classes of constant propensity, the mean values of yi for respondents and nonrespondents are equal, which implies that
(5)

μ=



2.3 Regression Estimation

E(yi | πi , ti = 1) dP (πi ).

Suppose we fit a π -model and define strata s =
1, . . . , S by grouping units whose π̂i ’s are similar. Define cis = 1 if unit i belongs to stratum s and 0 otherwise. The π̂ -stratified estimate of μ approximates (5)
by a weighted average of respondents’ mean in each
stratum, weighted by the proportion of sample units in
that stratum,
(6)

μ̂strat-π =

S 

s=1




i cis
i cis ti yi
.


n

the stratified estimators are more biased than IPW for
samples of n = 200 but less biased when n = 1000,
because the bias of the stratified estimators does not
worsen as n increases.

i cis ti

IPW and π̂ -stratified estimators pay no heed to relationships between the covariates and yi . Regression
estimators, on the other hand, model yi from xi directly
and use this information to predict the missing values.
Because strong ignorability implies that
E(yi | xi , ti = 0) = E(yi | xi , ti = 1) = E(yi | xi ),
we can regress yi on xi among the respondents, apply
the estimated regression function to predict yi for the
entire sample, and then average the predicted values to
obtain an estimate of μ. Let

Similarly, a π̂ -stratified estimate of μ(0) weights the
respondents’ mean in each stratum by the proportion
of nonrespondents in that stratum,
(0)
μ̂strat-π

=

S 

s=1



i cis (1 − ti )
n(0)


i cis ti yi
,

i cis ti

which may be combined with ȳ (1) as in (4) to produce
another estimate of μ̂. Rosenbaum and Rubin (1983)
suggest classifying units into S = 5 strata defined by
the sample quintiles of π̂i , as this tends to eliminate
more than 90% of the selection bias if the π -model is
correct (Cochran, 1968).
The performance of the π̂ -stratified estimator (6)
over the 1000 samples from the artificial population
is summarized in Table 2. Comparing these results to
those of Table 1, we see that stratification is less effective than IPW at removing bias when the π -model
is correct, but the stratified estimators still outperform IPW in terms of RMSE. The increase in bias
incurred by coarsening the π̂i ’s is easily offset by
the greater efficiency that results from stabilizing the
largest weights. When the π -model is misspecified,

β̂ =



−1

tj xj xjT

j



denote the ordinary least-squares (OLS) coefficients
from the regression of yi on xi among the respondents,
and let m̂i = xiT β̂. The OLS regression estimate for μ
is
1
μ̂OLS =
(7)
m̂i .
n i
This estimate is unbiased if the y-model is true, that is,
if E(yi | xi ) = xiT β for some β ∈ Rp ; in addition, it is
highly efficient if σi2 = V (yi | xi ) is nearly constant. If
the response is heteroscedastic, efficiency can be improved by replacing β̂ with a weighted least-squares
estimate with weights proportional to σi−2 .
From our 1000 samples, we computed OLS regression estimates under a correct y-model (regressing yi
on the zij ’s) and an incorrect y-model (regressing yi
on the xij ’s). The results, which are summarized in Table 3, verify that the bias is indeed removed when the
y-model is correct but not when the model is wrong.

TABLE 2
Performance of propensity-stratified estimators over 1000 samples from the
artificial population
Sample size

π-model

Method

Bias

% Bias

RMSE

MAE

(a) n = 200

Correct
Incorrect
Correct
Incorrect

strat-π
strat-π
strat-π
strat-π

−1.15
−2.82
−1.08
−2.87

−38.1
−87.7
−81.5
−202.7

3.22
4.28
1.71
3.19

2.17
3.13
1.18
2.83

(b) n = 1000

tj xj yj

j

531

DEMYSTIFYING DOUBLE ROBUSTNESS
TABLE 3
Performance of ordinary least-squares regression estimators over 1000 samples from the
artificial population
Sample size

y-model

Method

(a) n = 200

Correct
Incorrect
Correct
Incorrect

OLS
OLS
OLS
OLS

(b) n = 1000

Comparing the RMSE values in this table with those
in Tables 1 and 2, we see that estimates based on
the incorrect y-model are more stable and efficient
than those based on the incorrect π -model. The bias
that remains due to misspecification of the y-model
is not large in absolute terms, but it is still troubling
in samples of n = 1000 because there it amounts to
more than 50% of a standard error and begins to impair tests and intervals. Difficulties with parametric
missing-data methods arise when the uncertainty due
to the model specification, which is rarely accounted
for, grows relative to the sampling variation under the
assumed model. In those cases, a point estimate based
on a misspecified but reasonable y-model may still perform better than other estimates, but the analyst is too
optimistic about its precision.
The performance of the regression estimate depends
heavily on the strength of the correlation R between yi
and m̂i . As R 2 approaches 0, μ̂OLS converges to ȳ (1)
and suffers from the same bias as this naive estimate.
As R 2 approaches 1, 
it converges to the mean of the
full sample, ȳ = n−1 i yi , which is strongly robust.
Therefore, if the y-model has strong prediction, the regression estimator tends to dominate other methods in
terms of bias, efficiency and robustness. The IPW and
π -stratified estimators, on the other hand, break down
as the predictive ability of the π -model increases.
2.4 Stratification by Propensity Scores and
Predicted Values

We saw that the efficiency and robustness of an
IPW estimator can be enhanced by coarsening the π̂i ’s
into a small number of categories. The efficiency of
these estimators can be further increased by adding
covariates to the π -model that are predictive of yi ,
even if these covariates are unrelated to ti (Lunceford and Davidian, 2004). Vartivarian and Little (2002)
show that further improvement is possible if we crossclassify units by estimated propensity scores and covariates that are strongly related to the outcome. The

Bias
−0.08
−0.57
−0.00
−0.84

% Bias
−3.4
−17.7
−0.1
−56.0

RMSE

MAE

2.48
3.26
1.17
1.72

1.68
2.24
0.79
1.15

idea of combining estimated propensity scores with additional covariate information is not new. For example,
Rosenbaum and Rubin (1985) recommended matching respondents to nonrespondents or vice versa by
a Mahalanobis-distance criterion based on xi within
calipers defined by the estimated propensity scores.
Numerous authors have performed regression adjustments based on xi within strata defined by π̂ ; for references, see D’Agostino (1998).
To illustrate a simple version of this idea, suppose
that we create 25 strata by cross-classifying units into
cells defined by the sample quintiles of π̂i and m̂i , and
then estimate μ by a weighted average of the mean
response across the cells. If we apply this procedure
over repeated samples, we will occasionally encounter
a cell that contains nonrespondents but no respondents,
in which case the stratified estimates are undefined. For
those samples, we must modify the estimate in some
fashion. For example, we may collapse adjacent rows
or columns in the 5 × 5 table, fuse the offending cell
with an adjacent cell, impute the missing cell mean by
a regression estimate that assumes the response surface
has row and column effects but no interactions, and so
on.
In general, we dislike procedures that require frequent ad hoc adjustments unless their operating characteristics are well understood and the variance of the
adaptive estimator can be approximated. Nevertheless,
it is interesting to see how well the method performs
in our artificial example. For each of our samples, we
computed (π̂ × m̂)-stratified estimators using all four
possible combinations of correct and incorrect π - and
y-models. Missing cell means were imputed by a regression procedure that assumes no row-by-column interactions. The results, which are summarized in Table 4, show that dual stratification produces a crude
kind of double robustness; the bias is relatively low if
the π -model is correctly specified or if the y-model is
correctly specified. Under strong ignorability, a stratified estimate of the population mean will be unbiased if

532

J. D. Y. KANG AND J. L. SCHAFER
TABLE 4
Performance of propensity and fitted-value stratified estimators over 1000 samples from the
artificial population
Sample size

π -model

y-model

Method

Bias

% Bias

RMSE

MAE

(a) n = 200

Correct

Correct
Incorrect
Correct
Incorrect
Correct
Incorrect
Correct
Incorrect

strat-π m
strat-π m
strat-π m
strat-π m
strat-π m
strat-π m
strat-π m
strat-π m

−0.34
−0.59
−0.49
−2.00
−0.27
−0.45
−0.51
−2.10

−11.6
−18.4
−17.1
−61.4
−21.1
−33.7
−39.6
−148.7

2.92
3.25
2.89
3.82
1.31
1.42
1.38
2.53

1.90
2.19
1.96
2.62
0.87
0.92
0.92
2.11

Incorrect
(b) n = 1000

Correct
Incorrect

either the true πi ’s or the true mi ’s are constant within
strata.
It is also useful to compare the results in Table 4
where both models are incorrect with those of Table 2 where the π -model is incorrect. This comparison shows that a π -stratified estimator can be improved
with predicted values for the yi ’s, even if those predictions come from a coarsened, misspecified y-model.
The key idea of DR estimation—reducing your reliance on one model by specifying two—does produce
modest gains in this example over estimates based on
a π -model alone. Comparing Tables 3 and 4, however,
we find that the approximate DR procedure based on
two incorrect models performs worse than OLS based
on the incorrect y-model. When neither model is exactly true, two models are not necessarily better than
one.
3. CONSTRUCTING DOUBLY ROBUST ESTIMATES
3.1 Regression Estimation with Residual
Bias Correction

Cassel, Särndal and Wretman (1976, 1977) introduced a family of “generalized regression estimators”
for population means and totals that combine modelbased predictions for yi with inverse-probability
weights. These methods, which are part of a methodology called model-assisted survey estimation (Särndal,
Swensson and Wretman, 1992), are highly efficient
when the y-model is true, yet remain asymptotically
unbiased when the y-model is misspecified. In the
original formulation, the response probabilities were
a known feature of the survey design, but with uncontrolled nonresponse the propensities may be estimated under a π -model (Cassel, Särndal and Wretman,
1983).

To understand how these generalized regression estimators work, consider the simple regression estimator (7). If the regression model holds in the sense that
E(yi |xi ) = xiT β for some β ∈ Rp , then on average the
predictions m̂i = xiT β̂ will be neither too high nor too
low; the mean of the estimated residuals ε̂i = yi − m̂i
in the population will be zero. Of course, residuals are
seen only for sampled respondents. We can, however,
consistently estimate the mean residual for the full population if we have access to a π -model, and this estimate can in turn be used to correct the OLS estimate for
bias arising from y-model failure. Cassel, Särndal and
Wretman (1976) proposed the bias-corrected estimate
μ̂BC-OLS = μ̂OLS +

(8)

1  −1
ti π̂i ε̂i .
n i

Notice that if the y-model is true, then E(ε̂i ) = 0, and
the second term on the right-hand side of (8) has expectation zero for arbitrary π̂i ’s. If the π -model is true,
then the second term consistently estimates (minus one
times) the bias of the first term. Therefore, this estimate
is doubly robust.
Many variations on this approach are possible. For
example, we can normalize the weights in the correction term, so that the estimate becomes


μ̂OLS + i

ti π̂ −1 ε̂i
.
−1
i ti π̂

Or we can replace the POP weights with NR weights,
so that the correction term estimates the mean residual
in the population of nonrespondents. A bias-corrected
estimate of μ(0) based on this idea is


T
i (1 − ti )xi β̂



i (1 − ti )



+ i

ti π̂ −1 (1 − π̂i )ε̂i
,
−1
i ti π̂ (1 − π̂i )

533

DEMYSTIFYING DOUBLE ROBUSTNESS

which can be combined with ȳ (1) as in (4) to produce
another DR estimate for μ̂. A third possibility is to replace the weighted correction term with a π̂ -stratified
estimate of E(ε̂i ). Using five strata based on sample
quintiles of π̂i would remove over 90% of the bias from
the OLS estimate if the π -model were true and reduce
problems of instability caused by very large weights.
A more general version of (8) was independently
proposed by Robins, Rotnitzky and Zhao (1994) for
estimating population-average regression coefficients
from incomplete data. Suppose Ui is the contribution
of sample unit i to a vector-valued quasi-score function
covariates.
for the regression of yi on an arbitrary set of

As noted in Section 2.1, the solution to i wi Ui = 0
with wi = ti π̂i−1 provides a consistent and asymptotically normal estimate of the population-average regression coefficients if the model used to estimate the πi ’s
is correct. Now
suppose that we change the estimating

equations to i [wi Ui + (1 − wi )φi ] = 0, where φi =
φ(xi ) is an arbitrary term that may depend on xi but not
on yi . The mean of the additional term (1 − wi )φi is essentially zero if the π -model is true, because E(wi ) =
E(E(wi | xi )) = E(π̂i−1 πi ) ≈ 1. Therefore, the solution to these augmented inverse-probability weighted
(AIPW) estimating equations is again consistent and
asymptotically normally distributed under a correct
π -model. Robins and Rotnitzky (1995) demonstrate
that a judicious choice for φi can greatly improve upon
the efficiency of the simple IPW estimator. In particular, choosing φi = E(Ui | xi ), where the expectation
is taken with respect to the distribution for yi given xi ,
produces a locally semiparametric efficient estimator,
the most efficient estimator within this class. This estimate is DR, maintaining its consistency if either the
π -model or y-model is correct (Scharfstein, Rotnitzky
and Robins, 1999). Taking Ui = (yi − μ)/σ 2 , and estimating E(yi | xi ) by (m̂i − μ)/σ 2 where m̂i = xiT β̂,

the solution to the AIPW estimating equation reduces
to the generalized regression estimator (8). More generally, it becomes the solution to
1
1  −1
Ûi +
ti π̂i (Ui − Ûi ) = 0,
n i
n i

(9)

where Ûi is the quasi-score function Ui with yi replaced by m̂i .
By analogy to (8), (9) can be viewed as a predicted estimating equation with a residual bias correction. Any of the variations on (8) described above—
normalizing the weights, switching to NR weights, or
switching from an IPW bias correction to a π̂ -stratified
one—can be applied to (9) as well. Modifications like
these would take the estimator outside of the AIPW
class. Nevertheless, these changes could potentially
improve performance when either or both models are
misspecified.
The performance of the bias-corrected regression estimate (8) in our simulated example is summarized in
Table 5. The bias of this estimate does indeed vanish when either of the two models is correct. Moreover, comparing these results to those from the IPWPOP estimates in Table 1, we see that augmenting the
IPW procedure by information from a correct y-model
does indeed increase the efficiency. In the more realistic condition where both models are misspecified, however, this DR estimate does worse than IPW. A similar pattern emerges if we compare the new results to
those from the simple OLS regression estimate in Table 3. Bias from an incorrect y-model is repaired by a
π -model if the latter is correct. When both models are
misspecified, however, the DR procedure is substantially worse than OLS. Like IPW, estimates from this
DR procedure often behave erratically because one or
more weights are occasionally enormous. Even if we

TABLE 5
Performance of bias-corrected regression estimators over 1000 samples from the
artificial population
Sample size

π -model

y-model

Method

Bias

% Bias

RMSE

MAE

(a) n = 200

Correct

Correct
Incorrect
Correct
Incorrect
Correct
Incorrect
Correct
Incorrect

BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS

−0.08
0.25
−0.08
−5.12
0.00
0.06
−0.02
−21.03

−3.4
7.5
−3.3
−43.0
−0.1
3.4
−1.4
−13.5

2.48
3.28
2.48
12.96
1.17
1.75
1.49
157.21

1.68
2.17
1.70
3.54
0.79
1.02
0.80
5.32

Incorrect
(b) n = 1000

Correct
Incorrect

534

J. D. Y. KANG AND J. L. SCHAFER

trim away these “bad” samples and judge the performance by the MAE, however, the new procedure is still
worse than IPW and OLS. Once again, two models are
not necessarily better than one.
Why does this DR estimate fail to perform better
than IPW and OLS even though the π - and y-models
are reasonably close to being true? The local semiparametric efficiency property, which guarantees that the
solution to (9) is the best estimator within its class, was
derived under the assumption that both models are correct. This estimate is indeed highly efficient when the
π -model is true and the y-model is highly predictive.
In our experience, however, if the π -model is misspecified, it is not difficult to find DR estimators that outperform this one by venturing outside the AIPW class. For
this particular example, normalizing the POP weights,
switching to NR weights, and using a π̂ -stratified bias
correction all improve upon μ̂BC-OLS . There are yet
more ways to construct DR estimates, as we now describe.
3.2 Regression Estimation with Inverse-Propensity
Weighted Coefficients

The correction
term in μ̂BC-OLS repairs the bias in

μ̂OLS = n−1 i xiT β̂ by estimating the mean residual
in the full population. A different way to repair this
bias is to move the estimated coefficients away from β̂.
Imagine that we could see the OLS coefficients based
on the full sample,
β̂SAMP =



−1

xi xiT

i



xi yi .

i

A well-known property of OLS regression is that the
sum of the estimated residuals yi − xiT β̂SAMP , i =
1, . . . , n, is zero if xi includes a constant. This is an algebraic identity that holds regardless of the actual form

of E(yi | xi ). This identity implies that the regression
estimator based on β̂SAMP replicates the mean of yi in
the full sample,
1
1 T
xi β̂SAMP =
yi = ȳ,
n i
n i
which is a strongly robust estimate of μ. We cannot compute β̂SAMP from the observed data. But with
propensities estimated from a π -model, we can compute a weighted least-squares (WLS) estimate
β̂WLS =



ti π̂i−1 xi xiT

−1



i

i

In a well-behaved asymptotic sequence, β̂SAMP and
β̂WLS both converge to the coefficients from the linear
regression of yi on xi in the full population, regardless
of whether that regression is an accurate portrayal of
E(yi | xi ). If we compute a regression estimate for μ
based on the WLS coefficients,
1 T
(10)
x β̂WLS ,
μ̂WLS =
n i i
the difference between this estimate and ȳ converges
in probability to zero as n → ∞, provided that the
π -model holds.
From this discussion, we see that μ̂WLS consistently
estimates μ if the π -model is true. If the y-model is
true, then β̂WLS will be an inefficient but consistent estimate of β, and μ̂WLS will again be consistent; thus it
is DR.
In our simulated example, the WLS regression estimate is sometimes inferior to the bias-corrected OLS
estimate (8) when one of the models is true, but much
better when both models are misspecified (Table 6).
Comparing μ̂WLS to μ̂OLS , we see that the inversepropensity weighted estimate of β effectively corrects

TABLE 6
Performance of regression estimators with inverse-propensity weighted coefficients over 1000
samples from the artificial population
Sample size

π -model

y-model

Method

(a) n = 200

Correct

Correct
Incorrect
Correct
Incorrect
Correct
Incorrect
Correct
Incorrect

WLS
WLS
WLS
WLS
WLS
WLS
WLS
WLS

Incorrect
(b) n = 1000

Correct
Incorrect

ti π̂i−1 xi yi .

Bias

% Bias

RMSE

MAE

−0.09
0.38
−0.08
−2.20
0.00
0.16
0.00
−2.99

−3.4
13.2
−3.4
−70.0
−0.1
12.0
−0.1
−203.6

2.48
2.88
2.48
3.83
1.17
1.35
1.17
3.33

1.68
1.92
1.68
2.74
0.78
0.92
0.78
2.98

535

DEMYSTIFYING DOUBLE ROBUSTNESS

the bias from a wrong y-model if the π -model is correct, but makes matters worse if the π -model is wrong.
Once again, many variations on (10) are possible.
Normalizing the POP weights ti π̂i−1 has no effect on
β̂WLS , but one might consider switching to NR weights.
Applying NR weights and averaging the predicted values of xiT β among nonrespondents produces an estimate of μ̂(0) , which can then be combined with ȳ (1)
to produce another estimate of μ. Another possibility
is to coarsen the weights into, say, five categories and
compute a π̂ -stratified estimate of β.
3.3 Regression Estimation with
Propensity-Based Covariates

A third general strategy for constructing a DR estimate is to incorporate functions of estimated propensities into the y-model as covariates. Ordinary regression
estimates are based on the relationship
μ=



E(yi | xi ) dP (xi )

and achieve consistency if E(yi | xi ) = E(yi | xi ,
ti = 1) is consistently estimated for all xi . In practice, creating a model that gives unbiased predictions
for yi over the whole covariate space can be a daunting task, because real data often exhibit nonlinearities,
interactions, etc. that are difficult to identify and portray, especially as the dimension of xi grows. From (5),
however, we see that requiring unbiased prediction for
all xi is much stronger than necessary; it would suffice
to have unbiased prediction of E(yi | π(xi )) = E(yi |
π(xi ), ti = 1) for all π(xi ) ∈ (0, 1). If we want to repair
the bias in a parametric y-model, it makes sense to first
identify and correct for lack of fit in the direction of
the propensity score, because πi = π(xi ) is the coarsest summary of xi that makes yi and ti conditionally
independent (Rosenbaum and Rubin, 1983).
Consider the sample of n = 200 units from our artificial population that we examined in Section 1.4. Figure 4 shows the residuals ε̂i from the linear regression
of yi on xi , plotted against the linear predictors η̂i from
the logistic regression of ti on xi , for the n(1) = 100 responding units. A least-squares line fit to this plot has
an intercept and slope of zero, because the predictor is a
perfect linear combination of covariates already in the
y-model. A smooth curve created by a local polynomial (loess) fit, however, suggests that predictions from
the y-model tend to be slightly low in the middle of the
propensity scale and slightly high at the extremes. The
bias could be corrected by fitting a generalized additive model (Hastie and Tibshirani, 1990) that allows the

F IG . 4. Scatterplot of raw residuals from y-model against linear
predictors from a π -model, with least-squares and local polynomial fit.

mean of yi to vary smoothly with π̂i in a nonparametric
fashion. Little and An (2004) incorporated a smoothing spline hased on η̂i and demonstrated that the resulting regression estimate of μ is DR in the following
sense: If the y-model correctly describes E(yi | xi ) before the propensity-related terms are added, these additional terms (or any other functions of xi ) merely cause
the model to be overfitted and add mean-zero noise to
the predicted values. If the π -model is correct, then (5)
guarantees consistent estimation of μ, as long as the
mean of yi varies smoothly with πi and this relationship can be arbitrarily well approximated by the linear
combination of basis functions added to the model. In
the latter case, the propensity-related covariates completely remove the bias for estimating μ, and any additional information provided by xi merely serves to
make the estimate more precise.
In the spirit of Little and An (2004), let Si = S(η̂i )
denote a vector of basis functions (e.g., a spline basis)
that can serve to approximate the relationship between
the mean of yi and η̂i , the estimated linear predictor
from the π -model. Let xi∗ = (xiT , SiT )T denote the augmented vector of covariates, and let
(11)

∗

β̂ =


i

ti xi∗ xi∗T

−1



ti xi∗ yi

i

denote the OLS-estimated coefficients from the augmented y-model. If Si is a spline basis of degree k ≥ 1,
the matrix inverse in (11) will not exist, because Si
will contain a constant and a linear function of η̂i ,
which are themselves linear functions of xi . Problems
of collinearity can be alleviated by switching to a generalized inverse or by removing the offending terms

536

J. D. Y. KANG AND J. L. SCHAFER
TABLE 7
Performance of propensity-covariate (four dummy indicators) regression estimators over 1000
samples from the artificial population
Sample size

π -model

y-model

Method

(a) n = 200

Correct

Correct
Incorrect
Correct
Incorrect
Correct
Incorrect
Correct
Incorrect

π -cov
π -cov
π -cov
π -cov
π -cov
π -cov
π -cov
π -cov

Incorrect
(b) n = 1000

Correct
Incorrect

from Si ; either approach leads to the same predicted
values m̂∗i = xi∗T β̂ ∗ . The propensity-covariate regression estimate for μ is then
(12)

μ̂π -cov =

1 ∗
m̂ .
n i i

A particular case of (12) was proposed by Scharfstein,
Rotnitzky and Robins (1999) who took Si = π̂i−1 . Using the inverse-propensity as a single additional covariate is sufficient to achieve double robustness, because
the estimate then becomes the solution to an AIPW estimating equation (Bang and Robins, 2005).
We tried (12) in our simulated example with a variety of spline bases: a quadratic spline with a single knot
at the median of η̂i , a linear spline with knots at the
quartiles, and so on. We found that these polynomial
splines occasionally produced erratic predicted values
of yi for nonrespondents with low propensities, driving
up the variance of the regression estimate. The best performance was achieved by simply coarsening the η̂i ’s
into five categories and creating four dummy indicators

Bias

% Bias

RMSE

MAE

−0.09
−0.39
−0.09
−1.27
0.00
−0.55
0.00
−1.49

−3.4
−13.5
−3.4
−38.6
−0.1
−42.1
−0.2
−100.6

2.48
2.93
2.48
3.51
1.17
1.41
1.17
2.10

1.69
2.00
1.68
2.43
0.79
0.87
0.79
1.56

to distinguish among them. In other words, we approximated the relationship between the mean of yi and π̂i
by a piecewise-constant function with discontinuities
at the sample quintiles of π̂i . The performance of this
estimate is summarized in Table 7. It performs better
than any of the other DR methods when the π -model
and y-model are both incorrect. It performs better than
any method based on a π -model alone. Yet it is still inferior to the simple OLS regression estimate under the
incorrect y-model.
In contrast, the regression estimate of Scharfstein,
Rotnitzky and Robins (1999) that uses the inversepropensity as a covariate behaves poorly under a misspecified π -model (Table 8). The performance of this
method is disastrous when some of the estimated
propensities are small.
4. DISCUSSION

Double robustness is an interesting theoretical property that can arise in many ways. It does not necessarily translate into good performance when neither

TABLE 8
Performance of inverse-propensity covariate regression estimators over 1000 samples from the
artificial population
Sample size

π-model

y-model

Method

Bias

% Bias

RMSE

MAE

(a) n = 200

Correct

Correct
Incorrect
Correct
Incorrect
Correct
Incorrect
Correct
Incorrect

1/π -cov
1/π -cov
1/π -cov
1/π -cov
1/π -cov
1/π -cov
1/π -cov
1/π -cov

−0.09
1.66
56.5
−4236
0.00
0.59
−50.4
−7527

−3.7
37.6
3.1
−3.4
−0.1
31.3
−3.2
−3.3

2.48
4.70
1804
1.3 × 105
1.17
1.97
1593
2.3 × 105

1.69
2.84
1.76
7.79
0.78
1.26
0.83
5.75

Incorrect
(b) n = 1000

Correct
Incorrect

DEMYSTIFYING DOUBLE ROBUSTNESS

model is correctly specified. Some DR estimators have
been known to survey statisticians since the late 1970s.
In survey contexts, these methods are not thought of
as doubly robust but simply as robust, because the
propensities are a known feature of the sample design. When propensities are unknown and must be estimated, care should be taken to select an estimator
that is not overly sensitive to misspecification of the
propensity model.
No single example can effectively represent all
missing-data problems that researchers will see in
practice. We constructed our simulation to vaguely resemble a quasi-experiment to measure the effect of
dieting on body mass index (BMI) in a large sample of high-school students. The study has a pre-post
design. Covariates xi measured at baseline include
demographic variables, BMI, self-perceived weight
and physical fitness, social acceptance and personality measures. The treatment ti is dieting (0 = yes, 1 =
no) and the outcome yi is BMI one year later. The goal
is to estimate an average causal effect of dieting among
those who actually dieted. For that purpose, it suffices
to treat the dieters as nonrespondents, set their BMI
values to missing, and apply a missing-data method
to estimate what the mean BMI for this group would
have been had they not dieted. A simple linear regression of yi on xi among the nondieters yielded an R 2
of 0.81, just as in our simulated data, and boxplots of
the linear predictors from a logistic propensity model
looked similar to those of Figure 3(e). The large degree
of overlap in the distributions of estimated propensities
for the two groups makes a causal analysis seem feasible. The estimated propensities for some nondieters are
very small. Keeping these nondieters in the analysis is
highly desirable, because their covariate values closely
resemble those of dieters; they provide excellent proxy
information for predicting the missing values. Yet we
found no obvious way to use these cases in an inversepropensity weighted estimate, because they exerted too
much influence.
Our simulation represents a situation where selection
bias is moderate, good predictors of yi are available,
both models are approximately but not exactly true,
and some estimated propensities are nearly zero. In situations like these, a DR procedure that does not rely
on inverse-propensity weighting may perform reasonably well, but there is no guarantee that it will outperform a procedure based solely on a y-model. A model
that predicts yi reasonably well can enhance the performance of an approximate π -model. But in our simulations, we found no way to use the fitted propensities

537

from the approximate π -model to reduce the bias from
the approximate y-model. In every case, the bias correction applied to μ̂OLS tended to move the estimate in
the wrong direction.
Some might argue that inference about E(yi ) in
the full population should not be attempted in a situation like the one shown in Figure 3(e), where the
estimated propensities for a few nonrespondents fall
outside the range of those seen among the respondents. In our opinion, requiring the empirical support
of P (π̂i | ti = 1) to completely cover that of P (π̂i |
ti = 0) is too stringent, especially given the sensitivity of these ranges to minor changes in the π -model.
In all 1000 samples of n = 200 and n = 1000, the
distributions of the estimated propensities overlapped
sufficiently to compute a stratified estimate with five
quintile-based groups. Moreover, although some of the
estimated propensities were very small, none of the
true propensities were actually zero, so the conditions
required for DR estimation were not violated. Small
propensities frequently occur when missing data are
not missing by design, and data analysts need guidance
on how to deal with them. One who would argue for the
routine use of any kind of inverse-propensity weighted
estimator ignores the obvious fact that these estimators
cannot be used routinely.
Other evaluations of DR methods under dual misspecification have yielded mixed results, because the
nature of the problems and degree of misspecification
have varied. Davidian, Tsiatis and Leon (2005) presented a DR procedure analogous to μ̂BC-OLS for a
pre–post analysis of a randomized clinical trial with
dropout. Schafer and Kang (2005) evaluated their procedure and found that it performed slightly better than a
parametric method based on multiple imputation (Rubin, 1987). In that analysis, each of the two treatment
groups had its own y-model with R 2 ’s of about 0.5.
Each group also had its own π -model, and the smallest
fitted propensities were 0.14 and 0.07. It thus appears
that the use of AIPW estimating equations can produce
modest gains over a parametric method when the predictive power of the y-model is not too strong and the
estimated propensities do not get close to zero.
The only other simulations that we know of that
compare the performance of DR and non-DR methods under dual misspecification are those of Bang and
Robins (2005). Their first example pertains to the estimation of a population mean μ. They compare the
performance of
three methods—the unnormalized IPW

estimate n−1 i ti π̂i−1 yi , the ordinary regression es
timate n−1 i xiT β̂, and the propensity-covariate estimate (12) that augments the y-model with 1/π̂i —when

538

J. D. Y. KANG AND J. L. SCHAFER

the π - and y-models are correct and incorrect. In that
example, the predictive ability of the correct y-model
among the respondents is very strong (R 2 = 0.94), but
the incorrect version is worthless (R 2 = 0.001); thus
it maximally punishes the simple regression method
when the y-model is misspecified. This approximates
a situation where an analyst wants to impute missing
values but has no idea how to use the covariates, so he
simply ignores them and replaces all the missing values with ȳi(1) . It may also represent a situation where
all of the confounders are hidden from the analyst for
purposes of y-modeling (though not, strangely, for purposes of π -modeling). Another noteworthy feature of
that example is that all of the covariates in the propensity model have been dichotomized and the selection
mechanism is weak; when n is large, all of the estimated propensities fall nicely between 0.25 and 0.5.
Bang and Robins (2005) present three additional examples to demonstrate the performance of DR estimates in more elaborate problems. In each case, all of
the predictors in their π -models were dichotomized,
which helps to keep the estimated propensities away
from zero. Despite these features, none of their examples supports the claim that a DR method based
on two incorrect models is clearly and simultaneously
better than an IPW procedure based on an incorrect
π -model and a simple imputation procedure based on
an incorrect y-model. Only in the fourth example did
the DR method outperform both of its competitors under dual misspecification, and even there the advantage
was slight. Thus the results of Bang and Robins (2005)
support our contention that two wrong models are not
necessarily better than one.
ACKNOWLEDGMENT

This research was supported by National Institute on
Drug Abuse Grant P50-DA10075.
REFERENCES
A LBERT, J. H. and C HIB , S. (1993). Bayesian analysis of binary
and polychotomous response data. J. Amer. Statist. Assoc. 88
669–679. MR1224394
BANG , H. and ROBINS , J. M. (2005). Doubly robust estimation in
missing data and causal inference models. Biometrics 61 962–
972. MR2216189
B INDER , D. A. (1983). On the variances of asymptotically normal
estimators from complex surveys. Internat. Statist. Rev. 51 279–
292. MR0731144
C ARPENTER , J., K ENWARD , M. and VANSTEELANDT, S. (2006).
A comparison of multiple imputation and inverse probability
weighting for analyses with missing data. J. Roy. Statist. Soc.
Ser. A 169 571–584.

C ASSEL , C. M., S ÄRNDAL , C. E. and W RETMAN , J. H. (1976).
Some results on generalized difference estimation and generalized regression estimation for finite populations. Biometrika 63
615–620. MR0445666
C ASSEL , C. M., S ÄRNDAL , C. E. and W RETMAN , J. H. (1977).
Foundations of Inference in Survey Sampling. Wiley, New York.
MR0652527
C ASSEL , C. M., S ÄRNDAL , C. E. and W RETMAN , J. H. (1983).
Some uses of statistical models in connection with the nonresponse problem. In Incomplete Data in Sample Surveys III.
Symposium on Incomplete Data, Proceedings (W. G. Madow
and I. Olkin, eds.). Academic Press, New York.
C OCHRAN , W. G. (1968). The effectiveness of adjustment by subclassification in removing bias in observational studies. Biometrics 24 205–213. MR0228136
D’AGOSTINO , R. B. J R . (1998). Propensity score methods for bias
reduction in the comparison of a treatment to a non-randomized
control group. Statistics in Medicine 17 2265–2281.
DAVIDIAN , M., T SIATIS , A. A. and L EON , S. (2005). Semiparametric estimation of treatment effect in a pretest–posttest study
without missing data. Statist. Sci. 20 261–301. MR2189002
G ELMAN , A. and M ENG , X. L., eds. (2004). Applied Bayesian
Modeling and Causal Inference from Incomplete-Data Perspectives. Wiley, New York. MR2134796
G ELMAN , A., C ARLIN , J. B., S TERN , H. S. and RUBIN , D. B.
(2004). Bayesian Data Analysis. Chapman and Hall, London.
MR2027492
G EWEKE , J. (1989). Bayesian inference in econometric models
using Monte Carlo integration. Econometrica 57 1317–1339.
MR1035115
H AMMERSLEY, J. M. and H ANDSCOMB , D. C. (1964). Monte
Carlo Methods. Methuen, London. MR0223065
H ASTIE , T. J. and T IBSHIRANI , R. J. (1990). Generalized Additive Models. Chapman and Hall, London. MR1082147
H INKLEY, D. (1985). Transformation diagnostics for linear models. Biometrika 72 487–496. MR0817563
H IRANO , K. and I MBENS , G. (2001). Estimation of causal effects using propensity score weighting: An application to data
on right heart catherization. Health Services and Outcome Research Methodology 2 259–278.
H OLLAND , P. W. (1986). Statistics and causal inference. J. Amer.
Statist. Assoc. 81 945–970. MR0867618
H ORVITZ , D. G. and T HOMPSON , D. J. (1952). A generalization
of sampling without replacement from a finite universe. J. Amer.
Statist. Assoc. 47 663–685. MR0053460
L ITTLE , R. J. A. and A N , H. (2004). Robust likelihood-based
analysis of multivariate data with missing values. Statist. Sinica
14 949–968. MR2089342
L ITTLE , R. J. A. (1986). Survey nonresponse adjustments for estimates of means. Internat. Statist. Rev. 54 139–157.
L ITTLE , R. J. A. and RUBIN , D. B. (1987). Statistical Analysis
with Missing Data. Wiley, New York. MR0890519
L ITTLE , R. J. A. and RUBIN , D. B. (2002). Statistical Analysis
with Missing Data, 2nd ed. Wiley, New York. MR1925014
L IU , C. (2004). Robit regression: A simple robust alternative
to logistic and probit regression. In Applied Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives
(A. Gelman and X. L. Meng, eds.) 227–238. Wiley, New York.
MR2138259

DEMYSTIFYING DOUBLE ROBUSTNESS
L UNCEFORD , J. K. and DAVIDIAN , M. (2004). Stratification and
weighting via the propensity score in estimation of causal treatment effects: A comparative study. Statistics in Medicine 23
2937–2960.
M C C ULLAGH , P. and N ELDER , J. A. (1989). Generalized Linear
Models, 2nd ed. Chapman and Hall, London. MR0727836
N EYMAN , J. (1923). On the application of probability theory to
agricultural experiments: Essays on principles, Section 9. Translated from the Polish and edited by D. M. Dabrowska and
T. P. Speed. Statist. Sci. 5 (1990) 465–480. MR1092986
O H , H. L. and S CHEUREN , F. S. (1983). Weighting adjustments
for unit nonresponse. In Incomplete Data in Sample Surveys II.
Theory and Annotated Bibliography (W. G. Madow, I. Olkin
and D. B. Rubin, eds.) 143–184. Academic Press, New York.
P REGIBON , D. (1982). Resistant fits for some commonly used logistic models with medical applications. Biometrics 38 485–
498.
ROBINS , J. M. and ROTNITZKY, A. (1995). Semiparametric efficiency in multivariate regression models with missing data.
J. Amer. Statist. Assoc. 90 122–129. MR1325119
ROBINS , J. M. and ROTNITZKY, A. (2001). Comment on “Inference for semiparametric models: some questions and an answer,” by P. J. Bickel and J. Kwon. Statist. Sinica 11 920–936.
MR1867326
ROBINS , J. M., ROTNITZKY, A. and Z HAO , L. P. (1994). Estimation of regression coefficients when some regressors are
not always observed. J. Amer. Statist. Assoc. 89 846–866.
MR1294730
ROBINS , J. M., ROTNITZKY, A. and Z HAO , L. P. (1995). Analysis
of semiparametric regression models for repeated outcomes in
the presence of missing data. J. Amer. Statist. Assoc. 90 106–
121. MR1325118
ROTNITZKY, A., ROBINS , J. M. and S CHARFSTEIN , D. O.
(1998). Semiparametric regression for repeated outcomes with
ignorable nonresponse. J. Amer. Statist. Assoc. 93 1321–1339.
MR1666631
ROSENBAUM , P. R. (2002). Observational Studies, 2nd ed.
Springer, New York. MR1899138
ROSENBAUM , P. R. and RUBIN , D. B. (1983). The central role of
the propensity score in observational studies for causal effects.
Biometrika 70 41–55. MR0742974
ROSENBAUM , P. R. and RUBIN , D. B. (1985). Constructing a control group using multivariate matched sampling methods that incorporate the propensity score. American Statistician 39 33–38.

539

RUBIN , D. B. (1974a). Estimating causal effects of treatments in
randomized and nonrandomized studies. J. Educational Psychology 66 688–701.
RUBIN , D. B. (1974b). Characterizing the estimation of parameters
in incomplete data problems. J. Amer. Statist. Assoc. 69 467–
474.
RUBIN , D. B. (1976). Inference and missing data. Biometrika 63
581–592. MR0455196
RUBIN , D. B. (1978). Bayesian inference for causal effects: The
role of randomization. Ann. Statist. 6 34–58. MR0472152
RUBIN , D. B. (1987). Multiple Imputation for Nonresponse in Surveys. Wiley, New York. MR0899519
RUBIN , D. B. (2005). Causal inference using potential outcomes:
design, modeling, decisions. J. Amer. Statist. Assoc. 100 322–
331. MR2166071
S ÄRNDAL , C.-E., S WENSSON , B. and W RETMAN , J. (1989). The
weighted residual technique for estimating the variance of the
general regression estimator of a finite population total. Biometrika 76 527–537. MR1040646
S ÄRNDAL , C.-E., S WENSSON , B. and W RETMAN , J. (1992).
Model Assisted Survey Sampling. Springer, New York.
MR1140409
S CHAFER , J. L. (1997). Analysis of Incomplete Multivariate Data.
Chapman and Hall, London. MR1692799
S CHAFER , J. L. and K ANG , J. D. Y. (2005). Discussion of “Semiparametric estimation of treatment effect in a pretest–postest
study with missing data” by M. Davidian et al. Statist. Sci. 20
292–295. MR2189002
S CHARFSTEIN , D. O., ROTNITZKY, A. and ROBINS , J. M.
(1999). Adjusting for nonignorable drop-out using semiparametric nonresponse models. J. Amer. Statist. Assoc. 94 1096–
1120 (with rejoinder 1135–1146). MR1731478
VAN DER L AAN , M. J. and ROBINS , J. M. (2003). Unified Methods for Censored Longitudinal Data and Causality. Springer,
New York. MR1958123
VARTIVARIAN , S. and L ITTLE , R. J. A. (2002). On the formation
of weighting adjustment cells for unit nonresponse. Proceedings
of the Survey Research Methods Section, American Statistical
Association. Amer. Statist. Assoc., Alexandria, VA.
W INSHIP, C. and S OBEL , M. E. (2004). Causal inference in sociological studies. In Handbook of Data Analysis (M. Hardy, ed.)
481–503. Thousand Oaks, Sage, CA.

