Semiparametric Efficiency in Multivariate Regression Models with Missing Data
Author(s): James M. Robins and Andrea Rotnitzky
Source: Journal of the American Statistical Association, Vol. 90, No. 429 (Mar., 1995), pp.
122-129
Published by: Taylor & Francis, Ltd. on behalf of the American Statistical Association
Stable URL: https://www.jstor.org/stable/2291135
Accessed: 29-03-2019 20:23 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

American Statistical Association, Taylor & Francis, Ltd. are collaborating with JSTOR to
digitize, preserve and extend access to Journal of the American Statistical Association

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

Semiparametric Efficiency in Multivariate Regression
Models with Missing Data
James M. ROBINS and Andrea ROTNITZKY*

We consider the efficiency bound for the estimation of the parameters of semiparametric models defined solely by restrictions on
the means of a vector of correlated outcomes, Y, when the data on Y are missing at random. We show that the semiparametric
variance bound is the asymptotic variance of the optimal estimator in a class of inverse probability of censoring weighted estimators

and that this bound is unchanged if the data are missing completely at random. For this case we study the asymptotic performance

of the generalized estimating equations (GEE) estimators of mean parameters and show that the optimal GEE estimator is inefficient
except for special cases. The optimal weighted estimator depends on unknown population quantities. But for monotone missing
data, we propose an adaptive estimator whose asymptotic variance can achieve the bound.

KEY WORDS: Correlated outcomes; Generalized estimating equations; Generalized least squares; Missing at random; Longitudinal
studies.

1. INTRODUCTION

( 1976) and studied by McCullagh ( 1983). These estimating

equations are in the class of generalized estimating equations

We consider a longitudinal study conducted over a fixed

(GEE) discussed by Liang and Zeger ( 1986 ) and Gourieroux,

interval from time 1 to T. Let Yi = (Yi 1, . . ., YiT)T, i = 1,Monfort, and Trognon ( 1984). As in the linear case, semi... , n, be the vector of multivariate outcomes corresponding
parametric feasible efficient estimators of flo can be obtained,
to the ith subject measured at prespecified visit times ( 1,
under smoothness conditions, by substituting nonparametric
... . T). Here and throughout, T, when used as a superscript,

estimates of the unknown conditional covariance matrix into

denotes matrix transposition. We suppose that the goal of

the optimal estimating equations (Newey 1991 ).

the study is to describe the evolution of the mean of Yi, t The goal of this article is to extend Chamberlain's effi= 1, .. ., T, conditional on a vector of variables Xi. In ranciency results to the setting in which some Yi, are missing.
domized studies, Xi may include a treatment arm indicator We consider several missing data (i.e., nonresponse) mechand pretreatment variables such as age, sex, and race.
anisms. The first mechanism assumes that the data are missExtensive literature exists on the efficient estimation of
ing completely at random (Rubin 1976); that is, the missing

the parameters f0 of the regression of Yi on Xi in the absence data process may depend on the covariates Xi but is otherwise
of missing data. When the mean of Yi is X Tfo and the
independent of observed and unobserved outcomes. A seccovariance of Yi given Xi is known, the generalized least
ond mechanism allows for the probability of nonresponse
squares estimator G of f0 is best linear unbiased (Rao 1973, at visit (i.e., occasion) t to depend on a subject's observed
p. 301). With unknown conditional covariance matrix, fG
past, including the past history of a vector of time-dependent
is not a feasible estimator, because it depends on the uncovariates Vit that are correlated with Yi. The first mechanism
known covariance function. But Carroll and Ruppert (1982)
is a special case of the second. We derive the efficient score
and Robinson (1988) showed that if the covariance matrix
equations; that is, the estimating equations that have a so-

is a smooth function of Xi, then the generalized least squares
lution whose asymptotic variance coincides with the semiestimator fG that replaces the unknown covariance matrix
parametric variance bound. We show that the form of the
by a nonparametric estimator has the same asymptotic disbound is the same under both missing data mechanisms
tribution as fG. Furthermore, Chamberlain (1987) showed
considered.
that the asymptotic variance of fG attains the semiparametric In Section 2 we present the model and we review a class
variance bound for regular estimators of f0 in the semiparaof estimators proposed by Robins, Rotnitzky, and Zhao
metric model defined solely by the linear model restrictions ( 1995 ), denoted hereon as the RRZ class, that extends the

on the marginal means. The efficiency of estimators of f0
class of weighted least squares estimators to setting where
has also been studied in settings where the mean of Yi, nonresponse
is
depends on the past. The RRZ estimators relinked to Xi through some known arbitrary function g1(Xi,quire a model for the nonresponse probabilities. In Section
f). Chamberlain (1987) showed that the semiparametric
3 we calculate the semiparametric variance bound for the

variance bound under a semiparametric model that imposes

model and show that this bound is the same whether the

restrictions solely on the conditional means of Yi, given Xi nonresponse probabilities are completely known, completely
is achieved at the asymptotic variance of the solution to esunknown, or follow a model. We further show that the bound
timating equations that are the multivariate version of the
is achieved at the asymptotic variance of the optimal estiquasi-likelihood equations introduced by Wedderburn
mator in the RRZ class. In Section 4 we specifically study
the case of data missing completely at random. In particular,
we study the asymptotic performance of the GEE estimators
* James M. Robins is Professor of Epidemiology and Biostatistics and
Andrea Rotnitzky is Assistant Professor of Biostatistics, Harvard University,
proposed by Liang and Zeger ( 1986 ) and Gourieroux et al.
Boston, MA 02115. Support for this research was provided in part by Grants
2 P30 ES00002, ROI-AI32475, R01-ES03405, K04-ES00180, GM-48704,
and GM-29745 from the National Institutes of Health. Andrea Rotnitzky
?3 1995 American Statistical Association
was additionally supported in part by a Mellon Foundation Faculty DevelJournal of the American Statistical Association
opment Award.
March 1995, Vol. 90, No. 429, Theory and Methods
122

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

Robins and Rotnitzky: Efflciency in Multivariate Regression with Missing Outcomes 123

E(Yit I Xi) = gt(Xi, io), (4)

( 1984) and show that the optimal estimator in the GEE class

is inefficient except under special conditions. A small sim-

where f0 is a p X 1 vector of unknown
gt(, * ), for t = 1, . . ., T, are known fu

ulation study illustrates this theoretical result. Because the
solution to the efficient score equations depends on unknown

population parameters, in Section 5 we propose a two-stage
adaptive RRZ estimator whose asymptotic variance can

achieve the semiparametric variance bound and examine its
performance in a small simulation study. In Sections 2-5
we assume that the missing data pattern is monotone; that
is, once a subject misses a visit, return is not possible. In

Section 6 we extend our results to arbitrary missing data

of this article is to study the efficiency with which we can

estimate f0 under nonresponse processes satisfying ( 1), (2),
or (3). It is important to understand that even when data
on the time-dependent covariates Vit are available, it is the
conditional mean of Yi given Xi alone that it is of substantive
interest. To estimate d0 under dependent censoring when

the dimension of Wit is large and the nonresponse proba-

bilities are unknown, Robins et al. (1995) assumed that the
patterns. Finally, in Section 7 we present some final remarks.
response probabilities Xit = P (Rit = 1I Ri(t-1) = 1, Wit) are
known up to a q X 1 vector of unknown parameters ao; that
2. THE MODEL
iS5,

To define our model, let Yi = (Yi, ..., YiT) and Xi

Xit = Xit(ao), (5)

= (X ~iT ..., x iTT)T, where Xi, is a vector of explanatory

variables at visit t and visit zero occurs just prior to start
of
where
for each a, Xit(a) is a known f
follow-up. Often the Xi, are deterministic functions of
time
values
in (0, 1]. Given a^, the value of
and the baseline variables X i; for example, Xit = X i* t.
partial likelihood
Further, suppose that the study is designed so that in addition

L(a) 1:1I [1 Xit(a),t{ 1 - Xit(a)I }
to the Yit and Xi, measurements are to be made on a vector
i t
of time-dependent covariates Vit, t = 0, . . ., T and we set
Wit= (VT, yit)T, t = 1... ., T, and Wio = (Xi, Vio). Define they proposed solving the estimating equation
Rit= 1 if subject i is observed at time t (i.e., if Yi, and Vit
are observed) and Ri, = 0 otherwise. We assume that Rio
= 1 for all subjects i and that Yi, and Vit are either both
observed or both missing at each time t ? 1. Until Section
5, we shall assume that the missing data patterns are mono-

-Rlt]RI(t-), (6)

n

U0(3,&)= 0, (7)
i= I

where Us (d, a) = Di(f)zAi(a) ei (3), Ai (a) is the T X T

diagonal matrix with diagonal elements Ait (a) = X it (a) 1
tone; that is, Rit = 0 implies Ri(t+l ) = 0. We also shall assume

Rit, irija() = XiI(a) X . . . X X1(a), ei(f) = (e11(f3) * ... .

that Xi is completely observed (i.e., known); that is, Xi, is
ciT(f))T, tit(:) = Yit -gt(Xi, f), and Di(f) = d(Xi, f) is
observed even if Rit = 0, as would be the case if Xi,
a p X T matrix of known functions of Xi. Robins et al.
=Xi t. We assume that TWlT+1), Ril, * * -*, RiT)i i =1,
n, are independent and identically distributed, where

(1995) showed that under mild regularity conditions, and
providedthat (1), (4), (5), and, for t = 1, .. ., T,

for any variable z,t, t = 0, . . ., T, Zit = (z4T * ... *, zt-l)) T
and we use overbars to indicate past data recorded up to but

not including the corresponiding occasion. Consider the following two conditions on the missing data process:

P(Rit= 1 IRi(t-)= 1, W,t, Yi)
= P(Rit = 1 Ri(tR1) = 1, Wit) (1)

X1t> a>O (8)
hold, the RRZ estimating equations (7) have a solution a
such that n' /2( j - fi) is asymptotically normal with zero
mean. For a fixed choice of d(., * ), they showed in their
lemma 1 that the asymptotic variance of a is greater than or

equal to that of the estimator that solves (7) when X1it ( )
replaces Xit(a^), where X^ is the maximum partial likelihood

and

estimator of w in the model

P (Rit = 11 Ri(t- ) = 1, JVii(T+l))

=P(R1t= lIRi(t-)= l,Xi). (2)

logit XV)(W) = logit Xit(a) + 6 TQt, (9)
where w = (a T, 6 T)T, Xit(*) satisfies (5 ) for some a0; bo,

the true
value of 6, is zero because (5) is true; and Qit
Under ( 1 ), censoring (i.e., nonresponse) is unrelated
to cur-

Di (f0)Qi*, where Qit is the T vector with the first t rent and future outcomes given the past WitV. =Assumption
components
zero and, for t < j < T, the jth component
( 1 ) holds in particular when the data are missing
at random
7 it ' Gitj with
in the sense of Rubin ( 1976), because under monotonicity,
missing at random is equivalent to

P (Rit = 11 Ri(t-) = 1, Wi(T+l))

= P (Rit = I I Ri(t-,) = 1, Wit). (3)

Gitj--E (-ij I Ri (t -l) = I, Wit)-

3. SEMIPARAMETRIC EFFICIENCY
In this section we show that the optimal RRZ estimator

When assumption (2) holds, we shall say that the data are

attains the semiparametric variance bound. Before stating

missing completely at random. Assumption ( 2) implies both

the main results of this section, we define the semiparametric
variance bound, following Begun, Hall, Huang, and Wellner

( 1) and ( 3) . We suppose that the marginal distribution of

(1983), Bickel, Klaassen, Ritov, and Wellner (1993) and
Yit given Xi follows the (possibly nonlinear) regression model

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

124 Journal of the American Statistical Association, March 1995

Newey ( 1990). Suppose that the data consist of n indepen-

known function of the Wit; (d), (1) and (5); (e), (3) and

dent copies Zi, i = ( 1,. . . , n), of a random variable Z. Let
L(f3, 0; Zi) be the likelihood for a subject i in a semiparametric model indexed by a p X I parameter vector : and

(h), (2) and Xit, a known function of the Wit; (i), (2) and
(5); (j), E[Yt11Rij = 1, Wij] = E[Y,tlRj(j_l) = 1, WiJV, t

a nuisance parameter 0 taking values in some infinite-

2 j, j = 1, . . ., T; and (k), model (j) and Equation (5).

Xi, a known function ofthe Wit; (f), (3) and (5); (g), (2);

dimensional set. Let ((0, 00) index the distribution generating
4. DATA MISSING COMPLETELY AT RANDOM
Zi. Define a regular parametric submodel to be a regular

fully parametric model with parameters (d, iq) and likelihood
When the data are missing completely at random (i.e.,
L(f, r; Zi) with true values (fi, m) where the "sub" prefix
Eq.
(2) holds), the weighted least squares estimator of /0
refers to the fact that for each q, the distribution L(fi, iq; Zi )

is a distribution L(f, 0; Z,) allowed by the semiparametric

restricted to the observed outcomes, that is, the solution of

model. An estimator of d0 is regular in a regular parametric
submodel if locally it converges uniformly to its limiting

-1/2 D* () (a) = 0, (10)

distribution. A regular estimator of f0 is an estimator that
is regular in every regular parametric submodel. The semi-

is also consistent and asymptotically normal for estimating

/% under regularity conditions (Liang and Zeger 1986). Here

parametric variance bound for f0 is the supremum of the
for each (, <(/3) = -g*(Xi, /3) is equal to the vector
Cramer-Rao variance bounds for f0 over all regular paraof observed residuals and, given Di (/), D* (/) is the cormetric submodels. The asymptotic variance of any regular
responding submatrix. In this section we compare the

estimator of f0 is no smaller than the semiparametric variasymptotic performance of the estimators that are solutions
ance bound. In the context of this article, f0 is the parameter
to equations of the form (7) with the performance of the
in Equation (4). Further, for a subject i lost to follow-up at
estimators resulting from ( 10). Our plan is to find c3comp, the
t(i.e., Ri (t - 1) = 1 and Rit = 0), Zi equals ( vi, R T) T, where
best estimator among the solutions to (10), and to provide
Ri = (Ri1, ... , RiT)T, and for subject i not lost to follownecessary and sufficient conditions for the asymptotic variup, Zi equals ( W 7( T+1), R T). The following theorem, proved
ance of /comp to equal the semiparametric variance bound
in Appendix A, provides the semiparametric variance bound
rP -t. Define UcOmp,i (0 ) = D f*11j,() e * (/3), where DfUll,ii()
in the semiparametric model defined by restrictions (3), (4),

and (8) and states that the bound is attained at the asymptotic
variance of a solution to an estimating equation of the
form (7).

=Og(X, ,/)/1o/}var(ci lxi)-' .Chamberlain( 1987)proved

that in the absence of missing data, /3comp solving

1i Ucomp,i(/3) = 0 achieves the semiparametric vari
bound in the semiparametric model characterized by (4)

Theorem 1. The asymptotic variance of the solution

even if data on additional time-dependent covariates Vit are
available. In the presence of missing data, we prove the fol-

fop of Equation (7) that uses Dop,i ((i) and Xit( co ) instead
lowing lemma in Appendix B.
of Di (() and Xi,( a) attains the semiparametric variance
bound for regular estimators of f0 in the semiparametric

Lemma ]. Under (2), (4), and (8), (a) /3comp is regular

model (a) defined by (3), (4), and (8), where DOPi,(i() and (b) n 1 '2(/comp - /3) has minimum asymptotic variance
= {ag(Xi, O)/Oaf}{E[(U* - P'*)02JX,I}-, with U*
among all estimators of /0 that are solutions to equations of
= AiC1, Pi = IT=l (Rit-XitRiQl))Qi* ci = (i0), A,
the form (10).
= Ai (ao), and A?2 = AA T. Furthermore, rP-

Because /comp is regular, it must have asymptotic variance

-E{ aDop,i (f0)ei (i0)/ d T}a - is the semiparametric vari-

greater than or equal to that of /op The following lemma,
ance bound.
proved in Appendix B, implies that necessary and sufficient
Theorem 2 states that the semiparametric variance bound
conditions for equality of the asymptotic variance of /comp
is unchanged if in the semiparametric model defined by (3),and /Op are that the conditional expectations Gi defined in
(4), and (8), restriction (3) is replaced by the weaker con-

Section 2 do not depend on Vit and are linear in Yit or, equivdition (1) or the yet-weaker condition E[ Yit I Rij = 1, WiJI
alently, in cit.

= E[ YitIRi(j1l) = 1, Wij], t ? j. It additionally states that

r - is also the bound in the semiparametric models defined

Lemma 2. Suppose that Xit < 1 w.p. 1, for 1 < t ' T.

by adding to ( 1 ), (4), and (8) restrictions on the nonresponse Then the asymptotic variance of nf1/2( comp - /0) equals

F-1 if and only ifGitj = Gt forj2 t, 1I t < Twhere Gt
probabilities Xit. Thus under (4) and (8) and when either
(1) or (3 ) hold, prior knowledge concerning the probabilities =E(cij- iT |IXi ){var(-Cjt IXi ) } lit
Xit does not provide further information about f0. In partic- Define /3in like Op, except with Gt substituted for G1tj in
ular, this implies that given ( 1) or ( 3 ), knowledge that the the definitions of Qi*. The key step in the proof of Lemma
2 is showing that under (2), /comp and /3iin have the same
nonresponse process satisfies the stronger condition (2) that
asymptotic
variance. Lemma 2 implies that if data on timethe data are missing completely at random does not provide
additional information about f0 because Equation (2) is
equivalent to Equation (3) plus a restriction on Xit.
Theorem 2. rPjt is also the semiparametric variance

dependent covariates Via correlated with Yi are available and
some data are missing, then under (2), (4), and (8), the

optimal solution /3O, will have smaller asymptotic variance

than /3comp or XBin because as opposed to /3comp or XBi /3

bound in the ten additional models (b)-(k) characterized

exploits the correlation between the past (V 1T, VT A..

by the restrictions (4), (8), and (b), ( 1); (c), ( 1) and X11, a

V 1T(t 1 )) and Yit. A remarkable property of/30p is that it takes

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

Robins and Rotnitzky: Efficiency in Multivariate Regression with Missing Outcomes 125

this correlation into account without making any assump-

5. ADAPTIVE ESTIMATION

tions about the joint distribution of ( W h T+1), R11,... , RiT)

3PO is not available for data analysis, because QC

other than (2), (4), and (8).

Dop,i (f) depend on the unknown probability law gener

To illustrate these theoretical results, Table 1 gives results

the data. Our approach will be to replace them by "adaptive"

for time t = 4 of simulation experiments, each based on 200
realizations, so that the estimated coverage probability of a

estimates. Specifically, given a preliminary inefficient esti-

true 95% confidence interval will have a simulation accuracy

mator 3 and an estimator Gdij of Gitj, we will estimate, in

order, Q *, Pi, Dop,i(3), and Qit. To estimate the Gitj, we

of approximately ?3% due to Monte Carlo variability. The

cannot simply regress the estimated residuals -Cij(f) on functions of Wit among subjects observed at time j, because the

experiments are similar to those reported in table 2 of Robins
et al. (1995), except that missingness is completely at ran-

missing mechanism (1) does not imply that Gitj equals
E(cijl Wit, Ri = 1). But it is straightforward to prove that

dom. Specifically, we conducted two simulation experiments

withXi = land Vio = 1 andfort = 1,2,3,4, i = 1,...,

when ( 1 ) holds, Gitj = E( r i R= 1, Wit)P (R1j
500, Yit= 200-40(t-1)+ ao1{6-(t-1)}?I +o1,and
= 1 I Ri(t-l) = 1, Wit). Hence we adopt the following twoVI1t33 = 3,000 - 100(t - 1) + 0{10 - (t - 1)} ? eit,
stage estimation procedure:
where the random effects (uf0, ali) were bivariate normal
with mean zero, squared correlation coefficient p2 either .81

Stage 1. Specify flexible regression models

or .36 (depending on the experiment) and variances (4.52,

1002). The Ilit and eoit were generated independently for each P (RI = I R1(t1) = 1, J'V) = lj('(xi 5, Wit) ( 1)

subject i and each time t as follows: clit N(0, 2002) and
for
all t, e0 N(0, 402), Oi 2 N(0, 352), e013 N(0, 252),
and c014 N(, 102) . Finally, Xit = 1 for t = 1 and X,t = .6

E { l(t- 1 IJ= 1, I.Wit} = mj )(T5t), JVWit), (12)
depending on finite-dimensional parameters X t) and T(t).

for all i and t = 2, 3, 4. The data generating and analysis
programs were written in Borland's C++ version 3.0 using

Often, the right side of ( 11 ) will be chosen to be of logistic

the built-in pseudorandom number generator and were im-

form. Given a^ and a preliminary inefficient estimate : of f0

plemented on a Northgate 386 PC. The efficiency of /3comp

obtained by solving (7), let t5t) be the maximum likelihood

and the weighted estimator that uses Yit in separate logistic
estimator of xi and let T(t) be the (possibly nonlinear) least
models for the X,t are equal and exceed that of the sample

estimator of Tjt) in the regression of ri(t l )
average estimator 1, R,4Yi4/; Rl, 4. The equal efficiency squares
is
(
a^)cij(
ij(
a^) on WJt among subjects observed at the
predicted by the foregoing theory, because the weighted es-

jth occasion. Then Gitj = I(t) ((t), J,p)m(I)(i(t), JWt),
timator is asymptotically equivalent to Ain. However,
/3comp and fBlin are less efficient than the weighted estimator r= a( -IGitj if t < j < T and zero otherwise; Pi*
= E/1l (Rlt - W) Ri (t_l))Q. We then estimate the p X p
that uses both Yi, and Vi-(-1) in logistic models for X,1. Finally,
matrix E{(UU* - p*)?2 XiX}. Given the (1/2)p(p + 1)
even this latter weighted estimator is less efficient than the
multivariate (possibly nonlinear) regression models
semiparametric efficient estimator Ofp that uses the optimal
covariate Qi, in the logistic model for Xi1. The actual coverage

E(ZikZik'IXi) = Ikk'(', Xi) (13)

rates of our nominal 95% confidence intervals are as low as
92%. This undercoverage is no longer present at a sample

for 1 < k < k' < p, where Zik iS the kth eleme

size of 1,000 (data not shown).

Lemma 2 also implies that when only data on Yit and Xi

-Pi*, estimate T with ', the (possibly nonlinear) multi-

variate least squares estimator of the regression of Z1kZik' on
are recorded, fOp will still have smaller asymptotic variance
Xi. Here Z1k is the kth element of UC' -Pi* and UC'
than /comp when the Gitj are nonlinear functions of Yit. But
= a^(&)ei (O). The estimate of Dop,i (() is given by Dop,i (f)
when Yi 1, . . ., YiT are jointly multivariate normal given X,

= {ag(Xi, l)/la} var { U* - P* I Xi } -1, where var { U*
and (2) holds, Gitj is linear in Y11, O3p is fin, and both
-P*
/3comp and Oop are asymptotically equivalent to the normal Xi } is the p X p symmetric matrix with (k, k')
element Ikk'(', Xi). The estimate of Qit is given by Qit
theory maximum likelihood estimator of f0. Thus knowledge

that the data are normally distributed does not asymptotically
= DopE, (i) Q * . Notice that by restricting the functions Ikk'( *,
Xi) such that the symmetric matrix with (k, k') element
add information about f0 when (2), (4), and (8) hold.

Table 1. Results of a Simulation Study at t = 4 with f3O4 = E(Y,4) = 80.0
Monte Carlo average Actual coverage rate of Monte Carlo variance

of f4 $4? 1.96Vs.e.34in% Of 34

Row Analysis method Missingness model p2 = .81 p2 = .36 p2 = .81 p2 = .36 p2 = .81 p2 = .36
1 Sample average 80.2 80.2 96 94.5 2.4 2.4
2 Optimal GEE ($comp) _ 79.9 79.9 94 94.5 2.0 2.0

3 Weighted Y,t 79.9 80.0 93 93 2.0 2.0
4 Weighted Yit, Vi(t_1) 79.9 80.0 92 92.5 1.8 2.0

5

6

Weighted,

Weighted,

3,p

3adap

Optimal

Adaptive

79.9

80.0

optimal

79.9

95

94.5

80.0

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

93

1.6

93

1.6

1.8

1.8

126 Journal of the American Statistical Association, March 1995

... all
,RiT) values
if Ri(tl) - Rit
1. The
theorem states
Ikk'(T, Xi) is positive definite for
of= ',
wefollowing
guarantee
that
having
access
to
data
M*
rather
than
the
"monotone"
the positive definiteness of var { U0 - P Xi }

data Mi provides
no additional information
concerning /0
Stage 2. Obtain &, the partial maximum
likelihood
of w0 in
if
we
impose
no
additional
assumptions
concerning
the model (9), where Qit is replaced by Q`it and then obtain the
missing
data mechanism
beyond
of Section 2, and if
fadap, the solution of (7) that uses
D,p,i(f)
and
X(those
) (C).
some dropouts do not later return in the sense that
It is standard to show that when ( I 1), ( 12), and ( 13) are
correctly specified, Ladap has the same asymptotic distribution P(Ri*t = ? l Ri(,-_l )-Ri, = 1, Wit) > c > O w.p. I

as f3Op (see, for example, Robins, Mark, and Newey 1992).
Furthermore, Ladap will be asymptotically unbiased for f0

for T?t'>t andsomec. (14)

even when ( I 1), ( 12), or ( 13) are misspecified or even in-

Theorem 3. In the model characterized by (1), (4), (5),
compatible in the sense that there exists no joint distribution and (8), if ( 14) is true, then the semiparametric variance
for the observable random variables compatible with (2),
bound for /0 based on the data M"*, i = 1, ..., n, equals

(4), and the models ( 11 )-( 1 3). As was shown by Robins
et al. ( 1995, sec. 3), a consistent estimate of the asymptotic

that based on the data Mi, i = 1,..., n.
Suppose that, following Robins et al. (1995), we impose

variance of n 1/2(Ladap - 0) that is robust to misspecificationthe additional assumption
of ( 1l), (12), or (13) is given by

P(R*it = IRiRt, Wi;t, Wi(T+l))

-l1(E D0op()ag(X1, f3/afT}
n

-

X z Vi - z LiS j(i) z SgTU,)g},i
i=l

(R* = lIRi, Wi) (15)
Equation ( 15) implies that the data are missing at random

in the sense of Rubin (1976). Redefine Xi, to be P (R *
= 1I R* WJiVt) and let Xit( a) be a correctly specified model

for Xi,; that is, Xit(a) = XA(a, Ri, Wj ) is now a known

X I Dop(3)ag(Xi, l)/alTl

function of a, 1? t, J'V taking values in (0, 1] satisfying
Equation (5). Let a' solve 2iSaf,i(a) = 0, where Sa,,i (a)

= 1T=l {Ri - Xki(a)J}a logit Xit(a)/aa. Let Oi = {'i,r; r
#=
1},zwhere
iS for each r # 1 a vector-valued function
where Ui = D(f /\A (a&) ei (f) and S9i
i (Rii,r-Xi,
of
Wi(T+1)(r)
of
v selected by the investigator
(')Ri(tIl )) {a logit X(Q)(6o* )/ac} with * = (aT, oT)T dimension
The
7ri(r, a) = HI T I XI (a, , W(r))rt[l - Xt(a, r1
one-step estimator fIstep I3 - { b 7=iDefine
D0P(f3)ag(X1,

l)/al}-T i= {T - (T Ei= U1S,)(= i) i

Wf*t(r))]l-rt and Ai(c, a) = RiT7riT(a) 12r*17i(r a)4i,r

-2r*lI(R*
= r)Oi,r, where r = (rl, .. ., rt)T. Following
is asymptotically equivalent to 0adap and avoids
the additional
calculations involved in Stage 2.

Robins et al. ( 1995), let 3 solve

Row 6 of Table 1 summarizes the performance of Ladap

0 = I UJ(O, a)- A a(k, (16)

in the simulation experiment of Section 4. fadap is seen to

be as efficient as f3p . reflecting the fact that the models ( where
11 )
6 = 6162 , 61 = n ;iResid[ U a(f, a), Sa,(&)]
and (12) were correctly specified. Specifically, we used

Resid [Ai(c, &), Sa, ( b)]T 62 = n-12i {Resid[Ai a)

j 'VWi in ( 12) and { I + exp(-xt))} 1in ( I 1 ), where Wit
Sa,j(&)] }?2, and for any random vectors Ai, Bi, Resid(Ai,

is Wit with Vi, replaced by V j, . Note that our model ( 11
Bi) )is the residual for subject i from the least squares regression of A1 on B1, i = 1, ... ., n. In Appendix C we prove the
at random. Further, because Xi was constant, there was nofollowing theorem.
need to fit model ( 13 ).
Theorem 4. In the model characterized by (15), (4),
(5),
and (8), there exist Dgp,1( /) - dop(Xi, /) and ?o,
6. EXTENSION TO ARBITRARY MISSING
such
that the estimator / that solves Equation ( 16) using
DATA PATTERNS

reflected prior knowledge that missingness was completely

these quantities attains the semiparametric variance bound
The assumption that the missing data pattern is monotone
based on the data M*, i= l, . ..,n.
is quite restrictive. To allow for arbitrary missing data patRemark. The bound is unchanged if we replace Equa-

terns, following Robins et al. (1995), set R* = Ri, so that tions ( 5) and ( 15 ) by the weaker assumption that the data
RX = (R*, ..., R*T)T is the vector of missing visit indi- are missing at random.

cators and allow R E to take on any of its 2 T possible realizations r = (r1, ..., rT)T, where r is a T-vector of ls

We show in Appendix C that, in contrast to Dopj,(3),

Dop,1(/3) and ?cop, depend on the solution to an integral

and zeros. Redefine Ri, so that Ri, = 1 if R " = R 2 =equation
*
that does not exist in closed form, and thus adaptive
= Rit = 1 and Ri, = 0 otherwise. Ri, is now an artificial
estimation of these quantities would be computationally

"censoring indicator" that is zero once a subject fails to return
complex requiring numerically solving the integral equations

at any occasion t', for t' < t. Hence RiT = 1 -R =by1,successive

where 1 is the Tvector of is. Set Wi*?l)(r) = (W..V0, r1W.V,
..,rtJ'V1) and Wi* = Wi*(R"*). Then M" = (RI T,

approximations ( Robins, Rotnitzky and Zhao

1994, sec. 7).

7. ADDITIONAL CONSIDERATIONS

J '* T?+1)) T are the observed data for subject i. Let Mi be

subject i's data until the first missed visit; that_ is, A4i

We have assumed that loss to follow-up (i.e., censoring)

and measurements of the outcome Y11 occur only at discrete

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

Robins and Rotnitzky: Efficiency in Multivariate Regression with Missing Outcomes 127

times t = 1, . . ., T. When loss to follow-up and measure-

normal sampling distribution). This poor performance is

ments of outcome occur in continuous time, results of Robins

due to the fact that f will not be centered on fo unless we

and Rotnitzky (1992) and Robins (1995) can still be used

can obtain an accurate estimate of ,rit; however, due to the

both to derive the semiparametric variance bound and to

curse of dimensionality, it is not possible to obtain an ac-

construct a class of estimators which includes an estimator

curate estimate because estimation of the unrestricted con-

whose asymptotic variance attains the bound. In fact, given

ditional expectations given Xi that occur in ,rit requires

any semiparametric model in which the data are missing at

smoothing in at least five dimensions. In contrast, GEE-like

random and the probability of observing complete data is

estimators solving ( 10) will perform well in moderate size

bounded away from zero, Robins and Rotnitzky (1992) and

samples because no high dimensional smooths are needed.

Robins (1995) derived both a functional (integral) equation

In fact, in a separate report, we argue that any regular

for the efficient score and showed how to construct a class

asymptotically linear estimator in this model with asymptotic

of regular asymptotically linear estimators that includes an

efficient estimator. Robins and Rotnitzky (1992) and Robins
(1993, 1995) constructed such a class of estimators in the

accelerated failure time model, a median regression failure

variance less than that of Lcomp will require accurate estimation of unrestricted conditional expectations given Xi and
thus, due to the curse of dimensionality, will perform poorly
in moderate size samples.

time model, the one-sample survival model and the Cox
proportional hazards regression model in the presence of

APPENDIX A: PROOF OF THEOREMS 1 AND 2

dependent censoring attributable to time-dependent covari-

ates that simultaneously predict failure and censoring. Robins

Our proof of Theorem 1 uses a general representation for the

et al. (1994) and Pugh, Robins, Lipsitz and Harrington

semiparametric efficient score of an arbitrary semiparametric model

(1993) constructed such a class of estimators in a conditional

with monotone missing at random data given by Robins and Rot-

mean model and the Cox proportional hazards model in the

nitzky ( 1992, thm. 4.2) and Robins et al. ( 1994, props. 8.1-8.2).

presence of missing covariates respectively. In contrast to

the results obtained in this article for the conditional mean
model with missing outcome Y, Robins et al. (1994) showed

that even with a monotone missing data pattern, there is no
closed-form expression for the efficient score in a conditional

mean model with missing covariates X when Wit has continuous components.
Robins et al. (1994, sec. 7.1) showed that with monotone

missing data, the class of estimators A* solving i 7=I Ui

We start with a review of the theory of semiparametric efficiency
bounds, borrowing heavily from the survey paper of Newey ( 1990)
and the monograph of Bickel et al. ( 1992). Using the notation in
the first paragraph of Section 3, define the nuisance tangent space

A to be the closed linear span of all random vectors bS, where S,
is the subject-specific score for n evaluated at the truth in some

regular parametric submodel, usually S, = a ln L(fi, no; Z)/l'i; b
is a conformable constant matrix with p rows; and the subscript i
has been suppressed. Here consider A as a subset of the Hilbert

space of p X 1 random vectors H with inner product E(HIH2)

(a, &) = 0 with U* (A, a) = 7riT(a)- RiTDi(f)ei(f) also

and E(HTH) < oo. Then the projection of any vector H on A

contains an estimator whose asymptotic variance attains the

exists and is the unique vector II(HIA) in A satisfying E[{H

semiparametric efficiency bound for our model. But because

- ll(H I A) } TA ] = 0 for all A in A. II is a projection operator.
The semiparametric variance bound for regular estimators of

the U* (f, 'a) are nonzero only if subject i has complete
data, the small-sample behavior of the estimators f* are inferior to those of the estimators f whenever 7iT(ao) can be
small, say less than .2 or .3. It is for this reason that we have
restricted attention to the estimators A.

equals the inverse of the variance of Seff = ll(S, 1 A'), where S6
the score for f in the semiparametric model L(fi, 0; Z), usually
= a ln L(fi0, 00; Z)/OaO, and A' is the orthogonal complement
A. The random variable Seff is called the efficient score. Further,

any regular, asymptotically linear estimator f with asymptotic

The estimator Ladap of Section 5 is locally semiparametric variance {var(Seff)}-' has the efficient influence function

efficient in the model characterized by (2), (4) and (8) be-

cause it attains the variance bound if models (11 )-( 13) are
true and remains regular, asymptotically linear even if they
are false (Bickel et al., 1993). The good performance of

{ var(Seff)} 'Seff, where A is asymptotically linear with influen

function Uifn 1/2(f-fi) = iUi + oP( 1), E( U) = O, and var( UT
< oo. We now specialize the foregoing general results to the "full"
and "missing" data models of Section 2.

fadap in the moderate sized samples of our simulation study
Let Z (F) = W(T+ ) be the data vector that would be available on
depends critically X being of small dimension. Specifically,
a subject in the absence of missing data. Let L(F)(f, 0; Z(F)) be the
likelihood for a single subject when Z(F) is fully observed in the
suppose that the missing data pattern is monotone, the
full-data
regression vector Xi is multivariate with a large number
of semiparametric model characterized by (4), indexed by
the
p X 1 vector f and an infinite-dimensional nuisance parameter
continuous components (say, 5), that we are willing to as-

0 and let S(F), A (F), and S(F) be the score for A, the nuisance
sume that, given Xi, the data are missing completely at rantangent space, and the efficient score for the full data model. Let
dom (i.e., Eq. (2) holds), but that we do not wish to specify

Z be the observed data vector for a subject in the presence of mono-

any model for P [Ri, = 1 I Ri(tIl ) = 1, Xi ] whatsoever. Hence
tone missing data, so that Z = (tW, R (T+ )) if the subject was
our semiparametric model is again characterized by (2), (8)
lost to follow-up at time t and Z = (Z(F) R(T+I)) in the absence of
and the conditional mean restriction (4). Then in general,
missing data. Let L(fi, 0, Z) be the likelihood for a single subject
any inverse probability of censoring weighted estimator:
in the semiparametric model characterized by (3) and (4). For any

(such as fladap) that is more efficient than f3comp will perform
set y7 of random variables, let S7 be the subset of variables in y7

poorly in moderate size samples (in the sense that there will

with mean zero. Our proof of Theorem 1 uses the following two

be distributions allowed by our semiparametric model under

lemmas, the first of which is a restatement of proposition (8.3 ) of

which:f fails to be centered at fpo with an approximately

Robins et al. ( 1994 ).

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

128 Journal of the American Statistical Association, March 1995
Lemma A.] . Under the full-data semiparametric model char-

acterized by the sole restriction Equation (4), (a) S(2)

model (b) only by imposing the additional nonidentifiable restriction

E(S(F)eTIX)E(eeTIX)-1e with E(S( )eTIX) = Og(X, 0o)/
8A; (b) If E(H) = 0 for H = h(Z(F)), II(HI A (F)1)

= E(HeTIX)E(eeTIX)-'e; and (c) A0 ") = {d(X)e}, where
(F), ? F I_ O

AO - (A()O)

f(Vtl Wt, e) =f(Vtl Wt, Rt = 1, e). (A.4)

Restriction (A.4) is nonidentifiable, because it may be true whatever
be the distribution of the observables Z. Indeed, models (a), (b),

and (j) imply exactly the same restrictions on the distribution of

Lemma A.2. The efficient score Seff in a semiparametric model

the observables-namely, gt(Xi, #o) = fff . f E[ Yit I it, Rit

L(/3, 0; Z) with monotone missing data satisfying the restrictions

=1, Xi ] H J-o-' dF[ wj I ij, Rij = 1, Xi ], t = 1, . . ., T, which, by

(3) and (8) satisfies

lemma (A. 1 ) of Robins, et al. ( 1995), is equivalent to the restrictions

gt(Xi, A0) = E[Riti- 'Yit IXi ]. Hence the allowable densities for

T

the observable random variables Z under the models (a), (b), and

Seff = Qeff + z (Rt- XtRt-l) t-' { Qeff-E[ Qeff I Wt, Rt-l = 1I},

(j) are the same, and thus by definition the implied semiparametric

t=1

(A.1)
where Qeff iS the unique Q in A (F)1 satisfying

eff= Q + ll[v(Q)IA(F)?I, (A.2)

with v(Q) = -=( ( t- ) rt-' {Q-E(QI W, Rt_I = 1)}.

models for the observables Z are identical. In particular, the semi-

parametric variance bound for estimating f0 will be the same functional of the distribution function of the observables. Finally, anal-

ogous arguments show that the bounds in models (c), (d) and (e)
are identical.

APPENDIX B: PROOF OF LEMMAS 1 AND 2
We prove Lemma la under regularity conditions (R.8) and (R.9)

Proof of Lemma A.2

of appendix A of Robins et al. ( 1994). Lemma l a follows from the

This is a specific application of theorems (4.1 f) and (4.2) of
Robins and Rotnitzky (1992) or of propositions (8.1)-(8.2) of

fact that (a) Ucomp(3) has mean zero when f = f0 under (2), (4),

and (8), (b) UcOmp(3) is continuously differentiable in f0, and (c)

Robins et al. ( 1994).

by Theorem 2.2 in Newey (1990), solutions to differentiable un-

Proof of Theorem 1

sumptions. Note that Lemma lb is true when the distribution of

biased estimating equations are regular under our regularity as-

e I X is multivariate normal (MVN), because Ocomp is the parametric
By Lemma A. Ic, Qeff = Deffe = deff (X)e. Substituting Deffe for
maximum likelihood estimator (MLE) of f0 in the model that im-

Qeff in (A. l), we obtain that Seff = Deff(A - P* ), because At poses,
= e
in addition to (2), (4), and (8), the assumption that e I X is

+ Et= (Rt - XtRt I)rt-'I(te, where I(t) is the T X T diagonal

MVN with mean zero and known covariance matrix var(e I X). We

matrix with diagonal elements ejj = 1 ifj ? t and ejj = 0 otherwise. now show that fcomp is at least as efficient as Ad that solves ( 10)
Note that A -P* = e + M(T), where

based on D(f3) = d(X, fi), even if IlX is not MVN. Because
D*(1f)e* is linear in e, we obtain, using the usual formula for the

M(t) = (Rj - XjRj-)Ifrj-1 {e-E[eI Wj, Rj1l = 1]}. (A.3)
j=I

Further, it follows by equation (A.4) in the proof of lemma 1 of

asymptotic variance of a solution to an unbiased estimating equa-

tion, that the asymptotic variance of Ad depends on the law of e I X
only through var(e I X). In particular, the efficiency ordering cannot

depend on whether e I X is MVN, proving Lemma lb. Turning now

Robins et al. (1995) that n/2O 0p- i0) = Fpn' /2Z i Dopj(Aiti
to Lemma 2, because rcomp is a parametric MLE when e I X is MVN
-FP ) + opf(1), where Dop = Dop(/o). Thus by the central limit
and is regular in the semiparametric model (2), (4), and (8), the
theorem, varA{ n 1/2 (%Op -o)_ } = {var(Seff) if we can show
asymptotic variance of fcomp must equal that of Oop when e I X is
Dop = Deff and Fop = var(Seff). Using Lemma A. Ic to write Q
MVN. But when e I X is MVN, it is easy to show that Git = G t and
= d(X)e, Equation (A.2) becomes {Og(X, /o)I/3}E(eeTIX)-le
fun = 3m,. Now, even when e I X is not MVN, the influence function
= d(X)e + E[V(Q)eTIX]E(eeTIX)-le. Further, E[v(Q)CTIX]

Of fin, in contrast to that of 3op remains linear in e and has an
asymptotic variance that only depends on the law of e I X through
Var(c I X). Hence flin and fcomp have the same asymptotic variance
= 1 )1 X } . For (A.2 ) to be true for all e, it is necessary that { Og(X,
whatever be the law of e I X. However flin has asymptotic variance

= E[ tT= (I- t) Ir t-' {d(X)e-E[d(X)eI Wt, Rt- = I}eTIX]
= d(X)K(X), with K(X) = E t= (-1-t) - Ir t-'var(e I WI, Rt-I

3o)/3a#E(eeTIX)-f = d(X) + d(X)K(X)E(eeTIX)-1, which im-equal to that of 3p if and only if Gitj = G by the uniqueness of
plies that Deff = {Og(X, fO))/0f3} {E(eeTIX) + K(X)}-'. To see
the efficient influence function.
that Dop = {Og(X, f30)/0f3}var(Ae - F*" X)-l equals Deff, note

APPENDIX C: PROOF OF THEOREMS 3 AND 4
that A -P* = e + M( T), where, as shown in the proof of theorem
1 of Robins et al. ( 1995 ), M(t) of Equation (A.3 ) is a discrete time Proof of Theorem 3
mean zero martingale process with respect to the filtration at{ Wt,
Let C record the first missed visit, so C = t if Rt1 -Rt = 1 and,
RA, e }, and thus E[eM( T)TIXI X= 0 and, by a standard martingaleby convention, C = T + 1 if RT = 1. Set R*+I 0. In the model
variance calculation, var[M( T) I X] = K(X). A similar calculation
shows that E(Seff SeT) = p-

of Theorem 3, the likelihood function L(f3, 0; M*) is given by

{f ... *f L (F (, 0; WT+I)f(RC IC, WT+I; 0) r T=C
dW(-R)} {(I - XC) n C-- Xm}, where for any a = (al,

Proof of Theorem 2

aT,) T, at = (at+I,. . ., aT ) Tand, without loss of generality, we assume

that Xm is known. Then S6 = E(SrF) I R*, W*) with W*
Theorem (4. if) of Robins and Rotnitzky ( 1992) and proposition
-W *T+1 is the score for : based on data Mi* by proposition (A5.5)
( 8. 1 ) of Robins et al. ( 1994) state that when the data are missing
of Bickel et al. ( 1993). Define SR'0 = E(SWF) IC, WA) and Sqsid
at random (i.e., Eq. (3) is true), the efficient score and semipara= S- S: on. S: on~ is the score for:~ based on the data M1 . Let Al
metric variance bound do nQt depend on a model for, or knowledge
= in
{Al = E(A(F)IR*, W*); A(F) E A(F)} and Al on
of, the missingness probabilities 1t. This implies that the bound
models (e)-(i) equals that in model (a). To show that models (a)

= {A lmonE(A(F)l|C, Wc); A(F) E A(F)}, AResid = {ARe

and (b) have the same bound, note that model (a) differs from

-Alm?n}.Let Amis= {Amis=a(Rc,C,WT+I); E(AmislC,WT+I)

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

Robins and Rotnitzky: Efficiency in Multivariate Regression with Missing Outcomes 129

= O} and let A2 = {A2 = E(ArmisIR*, W*);A misE Amis}. Then it

The asymptotic variance to the solution to i UOpj (/

-O0PAi((op, ao) will attain the semiparametric variance bound,
because
= Al D A2 = AResid (D A mon (D A2 for the model based on the
data estimators based on the efficient score attain the bound

is straightforward to show that the nuisance tangent spaces are A

M* and A mon for the model based on the data Mi = (Ci, (Newey
Wic,). 1990). Finally, the asymptotic variance of At solving
Note that E(A2 1 C, Wc) = 0, by definition of A mis. We wish
to (/, a) - ? Ai (0p, 'a) will attain the bound, because Rob
Xi UOpj
al. ( 1994)
showed in the proof of their Theorem 2 that replacing
show that the efficient score Seff = II(S6 1 A') based on dataetM"*,
i
GOp by its estimate 0 and ao by its estimate 'a can never increase the
= 1, ..., n, is the same as the efficient score Semff9
=ili(Smon IAmon,I) based on data Mi, i = 1, ..., n. Now it is
variance of the solution. This proves Theorem 4 with Dop(f)
= Detf
straightforward to check that S011 I (ASid D A2). Therefore,
lI(S IA') = lI(SWmonIAmon,I) + l(SRseid IA'). The following
We have provided closed-form expressions for op and Dop(3)
= Dtf in terms of Bt. But Bt itself solves an integral equation
lemma shows that SResid E A2 and hence ll(SResid I A') = 0.
Lemma. sesid = A2 when A2 = E(AmisJR*, W*) with Amis

- -{I(Rc = Oc)r(Oc)f{1 - ir(Oc)} - lrc#Qc I(RBc
= rc)} {SF)- SWm0n}, where rc = (rc+, .*.. rT), ?c = (?c+I,

whose solution does not exist in closed form. Specifically, Robins
et al. (1994, sec. 7.2) showed that (A.6) implies Bt solves their
equation (47) with X* instead of X.
[Received April 1992. Revised March 1994.]

*..,OT), and 1r(rc) P(R=c _rcIC, WT+I).
Proof Clearly, A2 is in A2 by Equation (14) and E(A mis IC,

REFERENCES

WT+I) = 0. Further, by construction, if Rc # ?c, then A2

= SResid. Hence it suffices to show that E(SrF) - Smon
-AmisJR* = - Wc, C, Wc) = 0. But this evaluates to
E [ { lr(Oc) } -' (SF) - SWmon) IBR = Oc, W Y, C, Wc] ,which
{P (R =Oc C, Wc)}l-E(SF)S-CnI =C, Tc)=O.

Begun, J. M., Hall, W. J., Huang, W. M., and Wellner, J. A. (1983), "Information and Asymptotic Efficiency in Parametric-Nonparametric
Models," The Annals of Statistics, 11, 432-452.
equals
Bickel, P., Klaassen, C. A. J., Ritov, Y., and Wellner, J. A. (1993), Efficient

and Adaptive Inference in Semiparametric Models, Baltimore: Johns
Hopkins University Press.

Proof of Theorem 4

For notational convenience, define A(k) = A(k, ao), W*(r)
= W*+l(r), W* = W*(R*) = WV*+1, r(r) = i(r, o), and

R*TI = 0. Let A (2) = {A(2) = a(2)(R*, W*); E(A(2)I WT+I) = O}
be the set of functions of the observed data Mt that have mean

Carroll, R. J., and Ruppert, D. (1982), "Robust Estimation in Heteroscedastic Linear Models," The Annals of Statistics, 10, 429-441.
Chamberlain, G. (1987), "Asymptotic Efficiency in Estimation With Conditional Moment Restrictions," Journal of Econometrics, 34, 305-324.
Gourieroux, C., Monfort, A., and Trognon, A. (1984), "Pseudo-Maximum
Likelihood Methods: Theory," Econometrica, 52, 681-700.
Liang, K-Y., and Zeger, S. L. (1986), "Longitudinal Data Analysis Using

zero given the full data WT+I. Robins and Rotnitzky ( 1992) proved
Generalized Linear Model," Biometrika, 73, 13-22.

that A (2) is closed. Let ll( * I A (2)) be the Hilbert space projection

on to A (2). According to theorem (4. 1f) of Robins and Rotnitzky
(1992) or proposition (8.1) of Robins et al. (1994), because

Equation ( 15) implies that the data are missing at random in the
sense of Rubin (1976), the efficient score in the semi-

parametric model for Theorem 4 is Seff = RTi T eff

-Hl(RT --I Qefff IA(2)), where

McCullagh, P. (1983), "Quasi-Likelihood Functions," The Annals of Statistics, 11, 59-67.
Newey, W. K. (1990), "Semiparametric Efficiency Bounds," Journal of
Applied Econometrics, 5, 99-135.
(1991), "Efficient Estimation of Models With Conditional Moment
Restrictions," working paper, Massachusetts Institute of Technology.
Pugh, M., Robins, J. M., Lipsitz, S., and Harrington, D. (1993), "Inference
in the Cox Proportional Hazards Model With Missing Covariates," technical report, Harvard School of Public Health, Dept. of Biostatistics.

Rao, C. R. (1973), Linear Statistical Inference and Its Applications (2nd
ed.), New York: John Wiley.
Robins, J. M. (1993), "Information Recovery and Bias Adjustment in Prom(B) --r 7r(r)E[BI W*(r)], and Bt is the unique function of
portional Hazards Regression Analysis of Randomized Trials Using SurWT+I satisfying
rogate Markers," American Statistical Association 1993 Proceedings of
Biopharmaceutical Section, pp. 24-33.
m(Bt) EE A(F), and fI(BtJA(F)1)=S jFj). the
(A.6)
(1995), "Locally Efficient Median Regression With Random Censoring and Surrogate Markers," Proceedings of the 1994 Conference on
Furthermore, according to theorem (4. Ig) of Robins and Rotnitzky
Lifetime Data Models in Reliability and Survival Analysis, Boston, MA
(1992) or proposition (8.1) of Robins et al. (1994),
(to appear).
ll(RT-TQeff IA(2)) RT -lQetff 2rI(R = r)Bt,which,by(A.5),
Robins, J. M., Mark, S. D., and Newey, W. K. (1992), "Estimating Exposure
equals A(Oeff) with keff,r = E(BtI W*(r)). Hence
Effects by Modeling the Expectation of Exposure Conditional on Confounders," Biometrics, 48, 479-495.
Seff = R -lQtffA (eff)* (A.7)
Robins, J. M., and Rotnitzky, A. (1992), "Recovery of Information and
Adjustment for Dependent Censoring Using Surrogate Markers," in AIDS
Further, by Lemma A. 1, Q t = m(Bt) EEpidemiology-Methodological
AoF),1 implies Issues,
that
eds.Qt
N. Jewell, K. Dietz, and V.

Qt = m(Bg), (A.5)

= DtffeforDtff =(D ,...,DetffT)satisfying Dffj=E[m(Bt)I Y
= ej, X] - E[m(Bt)I Y = 0, X], with ej the T vector with jth

component 1 and the remaining component zero.

Farewell, Boston: Birkhiiuser, pp. 297-331.

Robins, J. M., Rotnitzky, A., and Zhao, L.-P. (1994), "Estimation of
Regression Coefficients When Some Regressors Are Not Always Observed," Journal of the American Statistical Association, 89, 846-866.

Now let Uop(f3, a) be U(f3, a) that uses D(f3) = Deff for each f3.
, (1995), "Analysis of Semiparametric Regression Models for ReLet Uop = Uop(fo, a0). Then straightforward algebra shows that
peated Outcomes Under the Presence of Missing Data," Journal of the
American Statistical Association, 90, 106-121.
p= RT-Dtff C - A(O*) with /)* = Dtff(el/l.
Robinson, P. (1987), "Asymptotically Efficient Estimation in the Presence
et*(r)/lrt*(r), 0, 0 . *, 0)T and t*(r) = t if r1 = * = r, = 1,
of Heteroscedasticity of Unknown Form," Econometrica, 55, 875-891.
and r,+ = 0, 1 < t < T. It follows from (A.7) that Seff
Rubin, D. B. (1976), "Inference and Missing Data," Biometrika, 63, 581-

= Uop- A(0op), where (/)op,r = (/eff,r - /)* Further,
592. Oop

Weddeburn,
= E[ UopA ( .Op) T] { E[A (k0p)A (kOp)T } -'is the identity
matrix,R. W. M. (1976), "On the Existence and Uniqueness for Certain
Generalized Linear Models," Biometrika, 63, 27-32.
becasuse ll( UoplA (2)) = A0p

This content downloaded from 206.253.207.235 on Fri, 29 Mar 2019 20:23:38 UTC
All use subject to https://about.jstor.org/terms

