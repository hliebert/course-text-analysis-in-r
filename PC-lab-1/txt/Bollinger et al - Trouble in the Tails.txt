DISCUSSION PAPER SERIES

IZA DP No. 11710

Trouble in the Tails?
What We Know about Earnings Nonresponse
Thirty Years after Lillard, Smith, and Welch
Christopher R. Bollinger
Barry T. Hirsch
Charles M. Hokayem
James P. Ziliak

JULY 2018

DISCUSSION PAPER SERIES

IZA DP No. 11710

Trouble in the Tails?
What We Know about Earnings Nonresponse
Thirty Years after Lillard, Smith, and Welch
Christopher R. Bollinger
University of Kentucky

Barry T. Hirsch

Georgia State University and IZA

Charles M. Hokayem
U.S. Census Bureau

James P. Ziliak

University of Kentucky

JULY 2018

Any opinions expressed in this paper are those of the author(s) and not those of IZA. Research published in this series may
include views on policy, but IZA takes no institutional policy positions. The IZA research network is committed to the IZA
Guiding Principles of Research Integrity.
The IZA Institute of Labor Economics is an independent economic research institute that conducts research in labor economics
and offers evidence-based policy advice on labor market issues. Supported by the Deutsche Post Foundation, IZA runs the
world’s largest network of economists, whose research aims to provide answers to the global labor market challenges of our
time. Our key objective is to build bridges between academic research, policymakers and society.
IZA Discussion Papers often represent preliminary work and are circulated to encourage discussion. Citation of such a paper
should account for its provisional character. A revised version may be available directly from the author.

IZA – Institute of Labor Economics
Schaumburg-Lippe-Straße 5–9
53113 Bonn, Germany

Phone: +49-228-3894-0
Email: publications@iza.org

www.iza.org

IZA DP No. 11710

JULY 2018

ABSTRACT
Trouble in the Tails?
What We Know about Earnings Nonresponse
Thirty Years after Lillard, Smith, and Welch*
Earnings nonresponse in household surveys is widespread, yet there is limited knowledge
of how nonresponse biases earnings measures. We examine the consequences of
nonresponse on earnings gaps and inequality using Current Population Survey individual
records linked to administrative earnings data. The common assumption that earnings are
missing at random is rejected. Nonresponse across the earnings distribution is U-shaped,
highest in the left and right tails. Inequality measures differ between household and
administrative data due in part to nonresponse. Nonresponse biases earnings differentials
by race, gender, and education, particularly in the tails. Flexible copula-based models can
account for nonrandom nonresponse.
JEL Classification:

J31, C8, D31

Keywords:

CPS ASEC, nonresponse bias, copula, measurement error, hot
deck imputation, proxy reports, earnings inequality

Corresponding author:
Barry T. Hirsch
Department of Economics
Andrew Young School of Policy Studies
Georgia State University
Atlanta, GA 30302-3992
USA
E-mail: bhirsch@gsu.edu

* This paper is forthcoming in the Journal of Political Economy.
We thank Adam Bee, Dan Black, Charlie Brown, James Heckman, Bruce Meyer, Chuck Nelson, Trudi Renwick, James
Spletzer, Ed Welniak, and five anonymous reviewers for helpful comments, plus participants at presentations at
the U.S. Census Bureau, Society of Labor Economists, Joint Statistical Meetings, American Economic Association
Meetings, Brigham Young University, Emory University, Federal Reserve Bank of Cleveland, Federal Reserve Board,
Institute for Fiscal Studies, University of Essex, University of New South Wales, and University of Sydney. The analysis
provided in this paper has been conducted at the U.S. Census Bureau, the Atlanta Research Data Center, and the
Kentucky Research Data Center. All results shown in the paper have received clearance from Census. The opinions
and conclusions are solely those of the authors.

1. Introduction
Thirty-plus years ago, Lillard, Smith and Welch (LSW, 1986) brought to the forefront the issue of
earnings nonresponse in the Current Population Survey (CPS), providing a sharp critique of Census
imputation procedures. Since that time much has changed, some for the better and some not. The Census
Bureau responded to the LSW critique and substantially improved the quality of their imputation
procedures. For the Annual Social and Economic Supplement (ASEC, known historically as the March
supplement), Census uses a sequential hot deck procedure to address item nonresponse for missing
earnings data by assigning individuals with missing earnings values that come from individuals
(“donors”) with similar characteristics.1 Less well known is that in addition to item nonresponse, there
exists ASEC supplement nonresponse. This occurs when households participating and responding in the
monthly CPS refuse to participate in the ASEC supplement. The Census also uses a hot deck procedure
for whole supplement nonresponse. Offsetting the progress in data processing, however, were sharply
rising rates of earnings nonresponse. As depicted in Figure 1, there was a substantial increase in the 1990s
and then again after 2011, such that by 2015 total (item and whole) nonresponse in the ASEC reached 43
percent.2 The item nonresponse rate of 25 percent is more than double that at the time of the LSW
critique. Additionally, the CPS monthly outgoing rotation group (ORG) files have earnings item
nonresponse rates currently above 35 percent, while the much larger American Community Survey (ACS)
has earnings nonresponse rates of about 20 percent, suggesting that nonresponse is pervasive across the
most important Federal household surveys.
Unfortunately, we know surprisingly little about patterns of earnings nonresponse, or its potential
consequences for important labor-market issues such as earnings gaps by gender and race, or inequality.
LSW (1986, p. 492) suggested that ASEC nonresponse is likely to be highest in the tails of the
distribution, but provided limited evidence since they could not observe earnings for nonrespondents.
LSW (1986, Table 2, p. 493) place white men in eight earnings intervals based on a combination of
reported and predicted earnings. They find a U-shaped nonresponse pattern with respect to earnings, with
the highest rates in the top three earnings categories.
Whether and to what extent earnings nonresponse is of economic consequence depends on the
questions being addressed and the reasons for nonresponse. Prior research has shown that use of imputed
earnings can seriously bias average wage gap estimates studied widely by social science researchers

1

Welniak (1990) documents changes over time in Census hot deck methods for the CPS ASEC.
For a careful analysis, see Bee, Gathright, and Meyer (2015). An additional form of nonresponse is so-called unit
nonresponse, which occurs when there is a noninterview or refusal to participate even in the monthly CPS survey.
These rates for the basic CPS were between 8 and 9 percent during our sample period (Dixon 2012). Also, as a point
of comparison, nonresponse rates for typical labor supply variables (weeks worked or hours per week) were in the 3
to 5 percent range over the past two decades.
2

1

(Hirsch and Schumacher 2004; Bollinger and Hirsch 2006, Heckman and LaFontaine 2006), even if the
earnings data are missing completely at random (MCAR).3 If earnings are MCAR, then nonresponse is
not dependent on earnings, even absent covariates; if earnings are missing at random (MAR), then
nonresponse is not dependent on earnings after conditioning on covariates; and if earnings are not missing
at random (NMAR), then nonresponse is dependent on the value of missing earnings even after
conditioning on covariates (Rubin 1976; Little and Rubin 2002). It is this latter case that is referred to as
having nonresponse bias or nonignorable nonresponse. Both Census imputation procedures and common
inverse probability weighting methods to deal with nonresponse assume that nonresponse is ignorable;
that is, those not reporting earnings have earnings similar to respondents with equivalent measured
attributes. If the MAR assumption is violated, measures of earnings gaps and distributions will be biased.
Given the high earnings nonresponse rates in Census household surveys, coupled with a paucity
of evidence on nonresponse patterns and its consequences, we address three important and closely-related
questions. We do so using restricted-access ASEC household files linked to administrative tax data from
the Social Security Detailed Earnings Records (DER) for March 2006-2011 (corresponding to calendar
years 2005-2010). First, how does earnings nonresponse vary across the earnings distribution? Access to
the DER is uniquely advantageous to address this question as it affords the opportunity to fill in missing
earnings for nonrespondents, and to compare survey responses to administrative tax records for
respondents. We align each worker’s ASEC earnings response status against their corresponding earnings
level from the DER. We examine this relationship for men and women separately, as well as for fulltime/full-year workers and those whose ASEC reports are provided by a proxy (i.e., another household
member). Nearly half of ASEC earnings reports are from proxies. The extent to which proxy reporting
affects nonresponse patterns and earnings accuracy is not well understood.
The second question we address is whether nonresponse is ignorable. That is, do respondents and
nonrespondents have equivalent conditional earnings distributions, and if so, can the earnings of survey
respondents accurately describe the missing counterfactual distribution of a combined respondent and
nonrespondent sample as if the nonrespondents had responded? This question directly addresses the
efficacy of the MAR assumption used in Census imputation procedures, and more broadly, in many
related missing-data procedures. MAR relies on the assumption that the joint distribution of earnings and

Hirsch and Schumacher (2004) labeled this “match bias,” which occurs most notably in earnings equations where
the dependent variable includes nonrespondents whose earnings are assigned (imputed) based on a set of match
attributes. If one includes attributes on the right-hand side that are not matched in the earnings imputation process,
coefficients on these attributes are attenuated. Hirsch and Schumacher used union status as an example;
nonrespondent union members are mostly assigned nonunion earnings, while nonunion workers are sometimes
assigned the earnings of a union member. Heckman and LaFontaine (2006) focus on bias to GED estimated returns;
nonrespondent GED holders are rarely assigned the earnings of a GED donor. Bollinger and Hirsch (2006) expand
the analysis to forms of imperfect matching (e.g., education, age, etc.) and derive precise measures of match bias.
3

2

response status, conditional on covariates, can be expressed as the product of the conditional marginal
distribution of response status and the conditional marginal distribution of earnings. This leads to our two
complementary tests of MAR made possible with access to administrative data, one which examines
whether the decision to respond to the ASEC earnings question is independent of earnings, and the second
which examines whether the distribution of earnings is independent of response status. Furthermore, we
also estimate parametric and nonparametric earnings regressions using the DER, and then test differences
in the residuals from those regressions based on response status. This provides estimates of summary
statistics for the conditional distribution of earnings for both respondents and nonrespondents. Absent the
link to the DER these tests are not possible because of missing earnings of ASEC nonrespondents.
The third question is whether earnings nonresponse affects standard estimates of earnings gaps
(by gender, race, and ethnicity), returns-to-schooling, and earnings inequality and volatility? To address
this question, we estimate saturated quantile earnings models to test how nonresponse affects outcomes in
the tails of the distribution, alongside models of central tendency. In addition, we also present estimates of
how nonresponse impacts standard measures of inequality such as the Gini, 90-10 (and 90-50, 50-10)
ratios, and top income shares. For the volatility analysis, we exploit the longitudinal dimension of the
ASEC whereby it is possible to match up to half of the sample from one year to the next to examine both
the dynamics of nonresponse as well as implications for summary measures of volatility. Answers to the
inequality and volatility questions have taken on increasing importance in recent years with the expansion
of distributional research, whether using standard summary measures of unconditional or conditional
inequality (e.g. Piketty and Saez 2003; Lemieux 2006; Autor et al. 2008; Burkhauser et al. 2012) or fully
specified quantile regression models of earnings (Buchinsky 1994; Kline and Santos 2013; Arellano and
Bonhomme 2017). Under MAR, unconditioned measures of inequality may differ between the full sample
with imputations and a sample omitting imputed earners. The full sample is likely to provide a consistent
estimate of unconditional inequality if the covariates used in the imputation procedure provide an
unbiased measure of earnings and maintain variance. Using only respondents provides more accurate
earnings responses, but risks bias (absent reweighting) to the extent that nonresponse rates differ across
the earnings distribution, as we subsequently show. The full sample with imputes results in biased
estimates of conditional inequality, however, because the relationship between inequality and the
multivariate correlations with respect to demographic, geographical, and job attributes not used (or used
fully) in the imputation process will be biased (Hirsch and Schumacher 2004; Bollinger and Hirsch 2006).
Data from the DER are particularly helpful here both because we can fill in the missing ASEC earnings
with the DER, and unlike the public-release and internal versions of ASEC, earnings from the DER are
not topcoded, which improves our estimates of the importance of nonresponse in the right tail of the
earnings distribution.
3

We are not the first to examine nonresponse using a validation study, nor to find deviations from
MAR, but prior studies are generally old, use small samples, and/or examine restricted populations (e.g.,
married white males). Most similar to our initial analysis is a paper by Greenlees et al. (1982), who
examined the 1973 ASEC and compared wage and salary earnings the previous year with 1972 linked
income tax records of full-time, full-year male heads of households in the private nonagricultural sector
whose spouse did not work. They found evidence that selection into response declined weakly with
respect to earnings. No distributional analysis was provided. David et al. (1986) conducted a related
validation study using the 1981 ASEC linked to 1980 IRS reports, also finding evidence of negative
selection into response. More recently, Kline and Santos (2013) examined whether returns to schooling
and other earnings equation parameters are sensitive to departures from the MAR assumption, using the
exact match of the 1973 ASEC linked to IRS earnings data. They provided evidence that missing data
probabilities among men are U-shaped, with very low and high wage men least likely to report. Hokayem
et al. (2015) used the linked ASEC-DER data to examine how treatment of nonrespondents affects family
poverty rate estimates and noted the U-shape nonresponse pattern. Although informative and suggestive,
it is not known whether results from studies that examined response bias using older data can be
generalized outside their time period and narrow demographic samples. In short, there is little validation
evidence using recent data to examine the extent and consequences of CPS nonresponse bias across the
earnings distribution. Given the increasing rates of nonresponse over time, it is important to know
whether nonresponse is ignorable and, if not, the size and patterns of bias.
In general, we find that nonresponse is not ignorable—earnings are not missing at random, even
conditional on a rich set of covariates—and as we allude to in the title, the highest rates of nonresponse
are in the tails of the earnings distribution. While on average, male (female) nonrespondents have slightly
higher (lower) earnings than respondents, nonresponse is not simply an up or down shift in the
distribution. Individuals with earnings that differ substantially from the average (either the gross or
conditional mean) are the most likely not to report earnings. This U-shaped pattern is in evidence across
gender, race, ethnicity, employment status (hourly and full-time full-year), month-in-sample, proxy
earnings status, and panel status (year 1 or year 2).
Our finding of NMAR suggests that reliance on respondent samples (even if reweighted) also
may provide biased estimates of population earnings. While we find the impact of nonresponse bias on
averages is small, the bias on conditional quantile estimates of gender, race, and education earnings gaps
associated with very high or low earnings is upwards of 20 percent and statistically significant. Moreover,
between one-third and one-half the difference in inequality measures between the CPS and administrative
data is accounted for by nonresponse in the CPS. We conclude by demonstrating that public users of the

4

ASEC can approximate the population distribution of earnings using a copula-based selection model
recently proposed by Arellano and Bonhomme (2017).
2. Earnings Nonresponse and Response Bias
Official government statistics, as well as most research analyzing earnings (and income)
differences, include both respondents and nonrespondents, replacing the missing earnings with an
imputed value. Researchers typically assume (usually implicitly) that nonresponse does not produce
systematic biases in the measurement of earnings. The aim of our paper is to determine whether this
assumption is justified.
Formally the ignorability of missing earnings underlying the MAR assumption is a statement
about the joint distribution of earnings (Y) and response status (R), conditional on covariates (X):
(1)

𝑓(𝑌, 𝑅|𝑋) = 𝑓(𝑌|𝑋) ∗ 𝑓(𝑅|𝑋),

which means that once we condition on known covariates, earnings and response status are independent.
Because Bayes Theorem permits us to relate the joint distribution of (Y, R) to conditional distributions
regardless of whether MAR holds, we can write the joint distribution as:
(2)

𝑓(𝑌, 𝑅|𝑋) = 𝑓(𝑌|𝑅, 𝑋) ∗ 𝑓(𝑅|𝑋) = 𝑓(𝑅|𝑌, 𝑋) ∗ 𝑓(𝑌|𝑋).

The implication of MAR is then readily seen by equating equation (1) and (2)
𝑓(𝑌|𝑅, 𝑋) = 𝑓(𝑌|𝑋) and 𝑓(𝑅|𝑌, 𝑋) = 𝑓(𝑅|𝑋).
If either of these conditions fails, then the MAR assumption fails. When the only data available are survey
reports, one method for testing for the presence of nonresponse bias across the joint distribution in
equation (2) is to treat response as a form of sample selection and to estimate a flexible quantile model via
copula methods (Joe 2014; Arellano and Bonhomme 2017). Bollinger and Hirsch (2013) adopted a
restrictive version of this approach by estimating the conditional mean of earnings controlling for
selection via a standard two-step Heckman (1979) method. Below we demonstrate the efficacy of the
copula-based method to recover the unbiased distribution of earnings using respondents only, but the
main analysis in this study takes advantage of our access to linked administrative earnings for both
respondents and nonrespondents, permitting direct tests of nonresponse bias via validation methods.
Specifically, because the MAR assumption is conditioned on covariates, it is sufficient to test
MAR by focusing on the conditional distributions on the right-hand-side of equation (2). Simply put, does
response status depend upon earnings or does the distribution of earnings depend upon response status?
For the former we estimate models of the form
(3)

𝑃𝑟(𝑅𝑖 = 1|𝑌𝑖𝐷𝐸𝑅 , 𝑋𝑖 ) = 𝐹(𝛼 + 𝛾𝑌𝑖𝐷𝐸𝑅 + 𝑋𝑖 𝛽)
5

Where 𝑌𝑖𝐷𝐸𝑅 is administrative earnings reports from the DER described in the next section. Because of
the very large number of covariates we restrict these tests to parametric estimators (probit and linear
probability) so that a test that 𝑓(𝑅|𝑌, 𝑋) = 𝑓(𝑅|𝑋) amounts to a test of 𝛾 = 0. We consider specifications
that control for 𝑌𝑖𝐷𝐸𝑅 in both logarithmic form as well as flexible percentiles, and also models that relax
separability between 𝑌𝑖𝐷𝐸𝑅 and 𝑋𝑖 . Greenlees et al. (1982) and David et al. (1986) implemented tests
along the lines in equation (3) as it provides the simplest and most straightforward way to answer the
question of independence. Since R is a binary variable, its entire distribution is summarized by 𝑃𝑟(𝑅 =
1|𝑌, 𝑋). If earnings have any predictive power, then earnings and response are not independent and the
MAR assumption fails.
For the test of conditional independence of earnings from response we estimate both parametric
and nonparametric models of the form
(4)

𝑌𝑖𝐷𝐸𝑅 = 𝛿 + 𝜃𝑅𝑖 + 𝑋𝑖 𝜋 + 𝜐𝑖 .

Summary measures of 𝑓(𝑌|𝑅, 𝑋) are the key for understanding sample selection when Y is the dependent
variable in a regression. Unlike 𝑓(𝑅|𝑌, 𝑋), the conditional distribution of earnings given response may be
summarized by a variety of parameters (mean, median, quantiles, variance, and skewness for example),
which describe different features of the distribution, such as center, spread, or symmetry. The classic
paper by Heckman (1979) and later papers (for a survey, see Vella, 1998) suggest that a key parameter is
𝐸[𝑌|𝑅 = 1, 𝑋] in which case the test that 𝑓(𝑌|𝑅, 𝑋) = 𝑓(𝑌|𝑋) amounts to a test of 𝜃 = 0. When the
regression of interest is a quantile regression such as the median or other percentiles, it is less clear what
the most important parameters will be. For the nonparametric models we estimate kernel density
functions separately for respondents and nonrespondents and conduct Kolmogorov-Smirnov tests of the
null that 𝑓(𝑌|𝑅 = 1, 𝑋) = 𝑓(𝑌|𝑅 = 0, 𝑋). Rejecting the null of equality is a sufficient condition to reject
the hypothesis that 𝑓(𝑌|𝑅, 𝑋) = 𝑓(𝑌|𝑋).
3. Data: The ASEC-DER Link Files
The data used in our analysis are restricted-access CPS ASEC person records linked to Social
Security Administration Detailed Earnings Records (DER) for survey years 2006-2011 (reporting
earnings for calendar years 2005-2010).4 The ASEC is a survey of roughly 60,000 households (plus an
additional 30,000 households as part of the Children’s Health Insurance Program) conducted in March of
each year. It serves as the source of official federal statistics on income, poverty, inequality, and health

4

The linked ASEC-DER were obtained as part of an internal-to-Census project and analyzed in a secure facility at
the U.S. Census Bureau in Suitland, MD. Researchers outside of Census interested in accessing such data must have
their project approved by Census and the Social Security Administration for analysis conducted in a secure Federal
Statistical Research Data Center. For more information see https://www.census.gov/fsrdc.

6

insurance coverage, and has been the workhorse dataset for earnings inequality research in the U.S. The
primary difference between the internal ASEC we use and the version available publicly is that the
internal file has higher topcode values on income components (Larrimore et al. 2008). We link the
internal ASEC to the DER file, which is an extract of the Master Earnings File and includes data on total
earnings as reported on a worker’s W-2 form, wages and salaries and income from self-employment
subject to Federal Insurance Contributions Act and/or Self-Employment Contributions Act taxation, as
well as deferred wage (tax) contributions to 401(k), 403(b), 408(k), 457(b), and 501(c) retirement and
trust plans, all of which we include in our earnings measure. Only positive self-employment earnings are
reported in the DER because individuals do not make self-employment tax contributions if they have selfemployment losses (Nicholas and Wiseman 2009). In addition, some parts of gross compensation do not
appear in the DER file such as pre-tax health insurance premiums and education benefits (Abowd and
Stinson 2013), nor do “off-the-books” earnings appear in the DER, though they could be reported in the
ASEC.5 Unlike the internal ASEC earnings records, DER earnings are not topcoded.6 This is important
given substantial concerns regarding nonresponse and response bias in the right tail of the distribution.
The principal sample used in our analysis includes civilian wage and salary workers ages 18 to 65
who have reported or imputed positive earnings in the prior year. We exclude workers who are full time
students, as well as a small number of workers identified in ASEC and linked to the DER who show zero
DER earnings but positive deferred compensation. We also exclude individuals with whole imputes of the
ASEC; that is, those for whom all ASEC supplement data are imputed. We provide a separate analysis of
this subsample in the online Appendix. The full sample, including those with no ASEC-DER link,
consists of 508,288 individuals (270,409 men and 237,879 women).
Since a worker can appear multiple times per year in the DER file if they have multiple jobs, we
collapse the DER file into one earnings observation per worker per year by aggregating total earnings
(Box 1 of W-2, labeled “Wages, tips, other compensation”), total self-employment earnings, and total
deferred contributions across all employers. In this way, DER earnings are most compatible with ASEC
earnings from all wage and salary jobs (WSAL-VAL) plus non-negative self-employment earnings. We
classify a worker as having imputed earnings if wage and salary income from the longest job (IERNVAL), from other jobs (I-WSVAL), or from self-employment earnings is imputed. For much of our
analysis, we focus on annual earnings because this measure is available in both the ASEC and DER, but

5

Whether survey reports of earnings differ from tax reports is an important, open issue. Recent evidence in Hurst,
Li, and Pugsley (2014) suggests that among the self-employed survey and tax reports do not differ substantively, but
whether this holds for the general labor force is not established and should be the subject of future research.
6
Confidentiality protections preclude us from disclosing individual earnings values such as the maximum earnings
values in the DER. The two components of our internal ASEC total earnings variable, earnings on the primary job
and all other earnings, are each capped at $1.1 million.

7

we also examine earnings among full-time full-year workers, as well as average hourly earnings found by
dividing annual ASEC or DER earnings by annual hours worked. Annual hours worked is constructed by
multiplying weeks worked (WKSWORK) by usual hours worked per week (HRSWK); these ASEC
labor-market measures are available for earnings nonrespondents as well as respondents.
[Table 1 here]
Table 1 provides summary statistics for our full sample in the first column, weighted by the
ASEC person supplement weight. The average worker is 41 years old, slightly more likely to be a male
and has an average of nearly 14 years of education. The majority are married with spouse present (58
percent), native born (84 percent), and work full time, full year (71 percent). Nonresponse to either the
wage and salary questions or the self-employment earnings question totals 23 percent of the sample.
Nonresponse is concentrated on the wage and salary questions (22 percent) largely because relatively few
individuals are self-employed. ASEC interviews identify for each household a single respondent who
provides information about other members of the household; hence, 48 percent of the earnings responses
are proxy responses, an issue we return to in a subsequent section. Inflation-adjusted ASEC total earnings
are $45,897, while average real DER earnings are a higher $48,478.
Table 1 also presents descriptive statistics for the sample broken down by ASEC response status
and by DER link status. In general, nonrespondents are not markedly different than the full sample (or the
respondent sample). They are slightly less likely to be a Hispanic or a female, more likely to be never
married, and more likely to be full-time full-year workers. In both the ASEC and the DER measures,
nonrespondents have slightly higher annual earnings. It is unsurprising that the ASEC difference is small
since the imputed earnings derive from the earnings of the respondents. On average, 86 percent of the
ASEC sample is successfully linked to the DER, though the online Appendix Figure 1 demonstrates that
the linkage rate is considerably lower at low earnings, rising from about 72 percent to 92 percent across
the ASEC earnings distribution. In Table 1, the nonlinked sample shows more striking differences with
the full sample than the nonrespondent sample. Individuals for whom a link was not found are two years
younger, 8 percentage points more likely to be male, and have 1.3 fewer years of education. Most notably
they are more than twice as likely to be Hispanic, and over three times more likely to be foreign born and
not a citizen. Nonlinked workers are almost twice as likely to be an earnings nonrespondent, and they
report ASEC earnings nearly $13,000 lower than do linked workers.
In online Appendix Tables 1 and 2 we document that link failure between ASEC and DER is
concentrated among noncitizen immigrants. Because the opt-out rate to agree to link ASEC and the DER
is a trivial 0.5 percent, most link failures are due to lack of personally identifiable information used in
constructing a linkage indicator. To address this, we estimate a saturated probit model of the probability
8

of an ASEC-DER link as a function of a full array of demographic characteristics, including nativity,
Hispanic ethnicity, and their interaction (see Appendix Table 3). As described in the online
supplementary appendix, we then use the fitted values to construct inverse probability weights (IPW) to
rebalance the ASEC-DER linked sample for the missing nonlink sample (i.e. the ratio of the ASEC
weight to the fitted probability of a link). Because most of the linkage failures are not due to an opt-out
choice by the respondent, and instead are accounted for by observed demographics, we believe any
potential bias from selection on unobservables, which would not be corrected by IPW, is minimal.
4. Is Response a Function of Earnings, and Is Earnings a Function of Response?
We begin our analysis examining the conditional distribution of response given earnings, where
in Table 2 we present estimates of equation (3) using the linked ASEC-DER sample and both unweighted
and IPW linear probability models.7 In this first test, we begin by conditioning only on the logarithm of
DER earnings. The first two columns do not control for any confounders, while in columns (3) and (4) we
control for a rich a set of covariates in Xi, including a quartic in potential experience, race, marital status,
citizenship, education, metropolitan area size, occupation, industry, and year. Column (4) also interacts
the covariates with DER earnings, relaxing separability. We recognize that this is a relatively simple
model of the joint distribution and so, subsequent analysis moves from use of a single linear log earnings
term to categorical measures for earnings percentiles that allow for different responses throughout the
distribution. This allows for a less parametric relationship between nonresponse and earnings.
[Table 2 here]
The results in Table 2 suggest an average tendency of positive rather than negative selection into
response. That said, the coefficients for both men and women are close to zero (with or without controls).
The effect of DER earnings for men with controls is a precisely estimated -0.014 (a 10 percent increase in
earnings decreases the probability of nonresponse by just over a tenth of a percentage point). The effect
for women is roughly half that size (-0.008). Although these results provide what we believe are accurate
measures of central tendency for these broad samples of men and women, our results for men appear to be
just the opposite of that found by Greenlees et al., who found negative selection into response. Their small
sample of married white men with non-working spouses in 1972, however, is not representative of
today’s workforce. In order to compare our estimates with those of Greenlees et al., in results not shown
we create a similar sample restricted to married white male citizens with spouse present. Unlike Greenlees
et al., we include those with working spouses since married women’s labor force participation is now
closer to the norm rather than the exception. In contrast to the negative coefficients on log earnings for all
men, using the restrictive married while-male sample flips the signs and produces positive coefficients,
7

Probit models yield observationally equivalent marginal effects to the LP models presented.

9

meaning negative selection into response. The latter results are qualitatively consistent with Greenlees et
al., as well as previous studies finding negative selection into response, though again we emphasize that
their sample is not representative of the modern labor force.
A.

Nonresponse across the DER Distribution
Rather than focusing on central tendency, it is more informative to examine how nonresponse

varies across the distribution. Grouping observations by DER earnings centile for the linked sample and
estimating nonresponse rates for each centile (by gender) produces nonresponse rates which vary across
the distribution non-parametrically. Panel A of Figure 2 plots these results for the entire sample
(smoothed using 3-percentile point moving averages). We note that the highest nonresponse rates are for
men through the lowest 30 centiles (as high as 28 percent) and for both men and women at the highest 5
centiles, reaching 25 percent. Throughout the middle of the distribution, the graph is relatively flat. This is
suggestive of our main result—“trouble is in the tails”—which is underscored in more dramatic fashion in
Panels B and C of Figure 2. In Panel B we focus on earnings among full-time, full-year workers, and in
Panel C we adjust for hours of work regardless of work status and depict nonresponse rates across the
distribution of average real hourly earnings. Here the “trouble in the tails” is most evident: nonresponse
rates rise dramatically in the left and right tails. Although similar to Panel A, in Panel C both men and
women in the highest centiles have nonresponse rates reaching 30 percent. Through the middle of the
distribution, however, the nonresponse rates are remarkably flat. The linear models reported in Table 4
will necessarily fit this part of the distribution, thus explaining the apparent absence of substantive
nonresponse bias when focusing on central tendency. The less pronounced trouble in the lower tails in
Panel A, which includes part-time and part-year workers, is largely explained by the fact that low
earnings is caused not only by low pay, but also by few weeks worked and low weekly hours. Both Panels
B and C adjust for annual hours and thus reveal a more striking pattern of U-shaped nonresponse across
the distribution.8 In short, nonresponse in the left tail is associated primarily with a low wage; not low
earnings resulting from low hours worked. This pattern is widespread. Appendix Figures 2-4 show that Ushaped patterns hold across race, ethnicity, interview month, and proxy report status.
[Figure 2 here]
The nonresponse rates in Figure 2 do not control for other factors, many of which are known to
be associated with earnings and nonresponse. To address this, we modify the nonresponse equation

8

Reported hours are concentrated at 2080 (full-time, full-year). While nonresponse is somewhat higher for workers
at 2080 hours (3 percentage points), there is no other obvious pattern across hours worked. Mean annual hours
worked systematically increase across the DER earnings distribution, as expected. That said, for those with low
DER earnings, mean hours worked are substantial, about 1000 hours for men and 650 for women in the lowest 3
earnings percentiles. This suggests that hours worked are not driving the U-shape.

10

specification seen previously in Table 2 by grouping the bottom 90 percent of earners into earnings
deciles, while breaking up the top decile into finer percentile increments. Table 3 presents results both
with and without human capital, demographic, and location controls, separately for men and women. In
all cases, we include a full set of decile/percentile dummy variables, rather than including an intercept.
Hence, each coefficient provides an estimate of the nonresponse rate at the given DER earnings level.
Readily evident from the coefficients is that nonresponse rates are not constant across the distribution,
with the highest earnings deciles producing the highest nonresponse. The U-shapes are highly similar
with and without controls.9 Among men, the lowest decile has a 14 percent nonresponse rate, while the
typical range through the rest of the distribution is roughly half that at 6.5 percent to 7.5 percent. For men
in the highest 3 percentiles, the nonresponse rate again rises over 14 percent with the top 1 percent having
a 19 percent nonresponse rate. For women, the results with controls are less pronounced, but again we see
the U-shape. At the lowest decile, the nonresponse rate is 12 percent, while through the middle of the
distribution it falls to around 9 percent, and in the highest percentile, it rises to 14 percent. While we do
not reject the null hypothesis that these rates are equal through the middle of the decile range (40th
through 70th deciles), we do reject the null that all deciles are equal.
[Table 3 here]
Our final evidence in this section is to show nonresponse rates for men and women with respect
to percentiles across the predicted earnings distribution, seen in Figure 3. We do this to test whether or
not the U-shape is largely a result of observable covariates. The linked ASEC-DER sample is used to
estimate conditional mean earnings equations along the lines of equation (4) using the same rich set of
demographic controls, as well as controls for both full time/part time and full year/part year status. The
predicted DER earnings for each worker, which can be thought of as an “attribute index”, is then used
similarly to the actual DER wage in Figure 2. Workers are grouped by (3-pt moving average) centile and
the resulting nonresponse rate is plotted, along with a smoothed quadratic trend function. Panel A of
Figure 3 makes it clear that nonresponse is somewhat higher in the tails of the attribute distribution of
men compared to women in Panel B. For the most part, though, nonresponse for men and women
demonstrates less of a U-shape across the attribute distribution than it does across the earnings
distribution. The U-shaped nonresponse (i.e., trouble in the tails) is not driven primarily by observable
earnings attributes; rather, it results from the realization of either very low or very high earnings.
[Figure 3 here]

9

Note that our unconditioned figures showing nonresponse rates across the earnings distribution also have been
constructed conditioned on a detailed set of covariates. While conditioning affects the level of nonresponse,
curvature of the conditioned and unconditioned nonresponse figures is indistinguishable to the eye.

11

B.

DER Earnings Residuals across the Distribution
We next examine the distribution of earnings conditional on response and earnings covariates,

f (Y|R,X), again using the linked ASEC-DER data with inverse probability weights. We estimate earnings
regressions specified in equation (4) using 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠𝑖𝐷𝐸𝑅 , and in Figure 4 provide kernel density
estimates of residuals for respondents and nonrespondents.
[Figure 4 here]
The left panel of Figure 4 presents the administrative earnings distributions by ASEC response
status among men, while the right panel does so for women. In both panels, peaks of the respondent
distribution are higher than peaks of the nonrespondent distributions. Similarly, the tails of the
nonrespondent distribution are generally longer, indicating a higher variance for nonrespondents.
Appendix Table 4 supports this, demonstrating that the variance for male (female) nonrespondents is 1.37
(1.12) times the variance of male (female) respondents. Testing differences between these variances using
either the standard F-test or Levine’s test rejects the null hypothesis of equivalence at conventional levels.
Tests for differences in means reject the null hypothesis as well. A simple test of the difference in the
medians fails to reject for men, but does reject for women. Examining the percentiles shows the major
differences occur in the tails, as seen in Figure 4. We conclude that there is strong evidence of differences
between these distributions, with the most substantive differences in the variances and percentiles.
Furthermore, Kolmogorov-Smirnov tests reject the null (p-value < 0.00) that 𝑓(𝑌|𝑅 = 1, 𝑋) = 𝑓(𝑌|𝑅 =
0, 𝑋), which is a sufficient condition to reject the hypothesis that 𝑓(𝑌|𝑅, 𝑋) = 𝑓(𝑌|𝑋).
C.

Proxy Respondents and Measurement Error
Census interviewers designate a single person to be the respondent for all household members in

a bid to lower the time and money costs of conducting household surveys. Although a single person is
recorded as providing answers to survey questions, the designee may rely on input from other household
members in providing requested information. In the ASEC sample used in our analysis, 54 percent of men
have their earnings reported by a proxy, while 42 percent of women rely on proxy reports.10 As seen in
Appendix Figure 4, earnings nonresponse is substantially higher among individuals with proxy earnings
responses than among self-respondents. For our combined sample of women and men, earnings
nonresponse rates are 24.2 percent for proxy respondents versus 16.4 percent for self-respondents. The
gap in nonresponse rates between proxies and self-respondents is about 2 percentage points greater among

We designate a response as a proxy response when an individual’s line number differs from the line number of the
household respondent. This method is not 100 percent accurate. Census identifies a respondent at the end of an
interview. If there has been a change in the respondent after the survey collects earnings information, this method
need not identify correctly the household member providing the earnings information.
10

12

men than among women; this gap varies little across the earnings distribution.
There exists rather limited information on the reliability of proxy earnings responses (Mellow and
Sider 1983; Reynolds and Wenger 2012; Lee and Lee 2012). Using the linked ASEC-DER sample, we
can observe whether administrative earnings in DER, where there are no proxies, vary with respect to
proxy use in ASEC. That is, we estimate two equations, each separately for men and women: (1) an
ASEC wage equation with spouse and nonspouse proxy variables and (2) a DER wage equation with
ASEC spouse and nonspouse proxy variables. Each wage regression also controls for a saturated set of
confounders. The proxy variables in the DER equation act as “phantom” dummies; if ASEC proxy
coefficients only measured reporting differences between proxies and self-respondents, the DER proxy
coefficients should be zero. Proxy coefficients in ASEC wage equations reflect the combined effects of
proxy misreporting and worker heterogeneity. Inclusion of phantom ASEC proxy variables in DER
administrative earnings regressions thus provides estimates of worker earnings heterogeneity correlated
with proxy status (conditional on measured attributes). Thus, in order to estimate proxy misreporting
error, we simply subtract the DER phantom proxy coefficients from the corresponding ASEC proxy
coefficients. Note that we exclude imputed earners since we cannot know whether the donor’s earnings
used in the ASEC imputation were self-reported or from a proxy.
[Table 4 here]
These results are summarized in the two far right columns in Table 4, using both a single proxy
variable and distinguishing between spouse and nonspouse proxies. In general, the DER and ASEC proxy
coefficients differ substantively, particularly so in the male regressions. In models with a single proxy
variable (i.e., proxy use versus self-response), we find that proxies understate both men’s annual earnings
and hourly earnings by 0.062 log points. Underreporting of men’s earnings are moderately larger when
there are nonspouse rather than spousal proxies. For women, underreporting by proxies is a comparatively
small 0.014 log points. Underreporting by nonspouse proxies is about a third larger than by spouse
proxies. One clear result from this analysis is that inclusion of dummies for spouse and nonspouse proxy
reports captures substantive unobserved heterogeneity, as seen by the DER coefficients. Both women and
men with earnings reported by spousal proxies have higher administrative (DER) earnings (note that we
control for marital status in all earnings equations).
The substantive underreporting of men’s wages and earnings by proxies, coupled with minimal
underreporting of women’s earnings, has obvious implications for measurement of the gender gap, which
is frequently measured using the CPS.11 From above, the difference-in-difference in the male-female
earnings gap from proxy reports is 0.048 log points (0.062-0.014). Were all earnings reported by proxies,

11

Blau and Kahn (2017) provide a comprehensive survey of the gender wage gap, with a focus on CPS estimates.

13

these results would imply that the gender gap is understated by the full 0.048 log points. Based on sample
averages of proxy use among men of 54.4 percent and 41.5 percent among women, a back of the envelope
calculation implies that gender-asymmetric underreporting of earnings by proxies understates the gender
wage gap by about 0.028 log points [.544 x .0621 – .415 x .0145 = .0278], or about 14 percent of the
regression-adjusted ASEC average wage gap of .20 (the adjusted DER gender gap is .19). We return to
the gender gap in a later section, focusing on the gap across the distribution using quantile models.
We conclude this section with a brief discussion of differences in the reported earnings in ASEC
and in the DER. Empirical investigation of measurement error in earnings in the CPS and other surveys
has a long history (Herriot and Spiers, 1975; Alvey and Cobleigh 1980; Bound and Krueger 1991;
Bollinger 1998; Rogers and Herzog 1987; Poterba and Summers 1986; Halsey 1978; Mathiowetz and
Duncan 1988; Marquis and Moore 1990; Mellow and Sider 1983; Duncan and Hill 1985; Bound et al.
1994; Bound, Brown and Mathiowetz, 2001; Roemer, 2002). The goal of this exercise is to examine the
relationship between the survey respondents for those with linked surveys using nonparametric kernel
regression. We use OLS to estimate models of both ASEC and DER earnings on the same covariates as
previously, and the residuals from each model are then used for the nonparametric regression of ASEC on
DER. Appendix Figure 5, using a log-earnings scale, shows that the “common man” hypothesis (i.e.,
mean reverting measurement error) found in the validation literature is supported: individuals with low
earnings tend to over-report their earnings, while individuals with high earnings tend to under-report.
Since this analysis was conducted on residuals, these are not associated with demographic characteristics
such as education or race. This evidence provides some interesting qualifications on our main finding that
nonresponse is concentrated in the tails of the distribution. Here we see that for respondents, measurement
error is also concentrated in the tails of the distribution. Previous authors (Bollinger and David 2001;
Kapteyn and Ypma 2007) have found similar overlaps in the population of “non-cooperative” survey
respondents. This suggests, perhaps, that the Census imputation procedure may reflect the response that
typical nonrespondents would make, were they to participate, measurement error and all. It does,
however, highlight that individuals in the extreme parts of the earnings distribution (both unconditional
and conditional) are not responding to the survey in ways we might hope. Our prior results show that
many simply do not respond, while Appendix Figure 5 shows that those who do respond are not
appropriately revealing their earnings. This evidence adds support to the idea that survey response and
nonresponse are correlated with the level of income, even controlling for demographic factors.
D.

Earnings Nonresponse over Time and Earnings Growth
One advantage of the rotation group structure of the ASEC is the overlapping nature of the

sample, allowing up to 50 percent of sample individuals to be followed across adjacent years. There is a
small literature examining either measurement error or nonresponse in panel settings (Bound and
14

Krueger, 1991; Fitzgerald et al., 1998; Bollinger and David, 2005; Bound, Brown and Mathiowetz, 2001).
We briefly examine the rates of nonresponse for the two-year panels covered by our data, the relationship
between earnings and nonresponse, and the impact of nonresponse on simple measures of earnings
growth. Several authors (Peracchi and Welch 1995; Cameron and Tracy 1998; Hardy and Ziliak 2014)
have pointed out that the subsample of individuals who can be followed across adjacent years in the
ASEC are not fully representative because the sample frame is the household address and not the person,
and thus movers are not followed. Nonetheless, the longitudinal sample is widely used and thus it is
important to assess nonresponse, and indeed, as Appendix Table 6 demonstrates, there are few observable
differences between the panel and cross-sectional samples. We find that the linkage rate for panel
individuals rises to 88.3 percent (compared to 87.4 percent for the full ASEC sample). The earnings
nonresponse rate is 16.9 percent in year 1 of the panel and 18.2 percent in year 2, as compared to 22.6
percent in the full cross-section sample.
[Figure 5 here]
The first column of Table 5 presents the (unweighted) response status in the first year, cross
tabulated with the response status in the second year. Overall, 72.8 percent of the sample responds in both
years and 7.9 percent do not respond in either year. The joint-year response rate is of course lower than
the single year response rates (83.1 percent in the first and 81.8 percent in the second year, as reported in
Appendix Table 6). Many individuals change their response status and such changes are approximately
symmetric. We find that 10 percent of individuals respond in the first year but become nonrespondents in
the second year; 9 percent of individuals do not respond in year 1 but then do so in year 2. Figure 5
displays panel nonresponse rates plotted against the DER earnings centile for the first year in the panel.
Panel A combines full-time full-year workers with part-time and part-year workers, but unlike the earlier
figures, here we combine the male and female samples. The year 1 and year 2 rates are (unsurprisingly)
very comparable in shape to our prior results seen in Figure 2. The third line tracks the percentage of
those who failed to respond in both years. Although multi-year nonresponse is obviously lower than
annual nonresponse, we again find that such nonresponse is U-shaped with respect to the level of
earnings. Panel B presents the same breakdown for the full-time, full-year sample, while Panel C shows
the full sample with respect to hourly wage centiles. As in comparable panels in Figure 2, we find more
pronounced U-shape patterns in Panels B and C.
[Table 5 here]
Using IPW weights to account for individuals not linked to the DER, columns (2) and (3) of
Table 5 present average earnings growth between the first and second year of the panel. We focus
primarily on the third column, examining the growth of inflation-adjusted earnings in the DER. Overall,
15

the average earnings growth was 0.013 log points. Most notable is the striking pattern between those who
respond only in one year: low (negative) DER earnings growth for those who respond only in year 1 and
high (positive) DER earnings growth for those who respond in year 2. This pattern suggests strong
selection into response based on changes in earnings, and is consistent with the U-shaped pattern found in
the cross-sectional analysis as well—those who have very low or very high earnings may fail to respond
if that is an unusual or new situation. Earnings growth for nonrespondents in either year is higher in
absolute value than those who respond in both years. This provides further evidence that nonresponse in
the CPS should be treated as NMAR.
Here, unlike the previous analyses, the ASEC earnings growth includes the imputations for
nonrespondents. We include the ASEC growth rates in column (2) for comparison and evaluation of the
imputation process. Comparison of growth rates between the ASEC and DER confound both
measurement error and imputations in the two categories where response switches. For those who respond
in both periods, measurement differences lead to ASEC having strikingly lower estimates of earnings
growth. In the case of nonresponse in both periods, the ASEC imputation procedure appears to impute
higher earnings growth than observed. While one can take a variety of perspectives on whether
administrative earnings are the correct measure, the marked difference in relative growth suggests that the
imputations are extremely poor in capturing earnings dynamics.
5. How Troubling is Trouble in the Tails? The Consequences of Nonresponse
The linked ASEC-DER data permits us to examine directly whether relying solely on
respondents’ earnings may produce in some circumstances results similar to what would be produced
using complete (but unobtainable) data. Because the DER sample includes administrative earnings for
nonrespondents as well as respondents, we can compare estimates from respondent-only samples with
those from complete samples, something not possible with publicly-available data. Here we focus on
three main types of estimation which should provide researchers with guidelines for judging the
importance of nonresponse in their research (above and beyond that demonstrated in the prior section on
proxy responses and longitudinal earnings growth). In section A we examine the implications for linear
models of earnings fit with least squares estimators. We find a modest impact from using a respondentonly sample, as the symmetric nonresponse in the tails has little impact on estimation of the means. In
section B, we consider the impact on coefficient estimates from quantile regressions. Here we find
estimates in the lower and upper quantiles from respondent-only samples to be problematic, as compared
to use of a full sample from the ASEC-DER link. Our concerns regarding use of a respondent-only ASEC
sample are reinforced in Section C where we examine earnings inequality. This conclusion is not
surprising given that measures of inequality are sensitive to earnings in the tails.

16

A.

Mean Earnings Estimates
Using the ASEC-DER sample and the IPW weighting to account for representativeness, we

estimate least squares log annual DER earnings equations by gender, separately for the linked
respondents, linked nonrespondents, and all linked workers samples, again controlling for the same set of
covariates used previously in the analysis. In Table 6 we provide the predicted DER earnings for men and
women using means from the full sample multiplied by coefficient estimates from (1) regressions using
the full sample in column (1), (2) regressions on the subsample of respondents in column (2), and (3)
regressions on the subsample of nonrespondents in column (3). We use as our benchmark the predicted
DER earnings based on coefficients from the full sample in column (1).
[Table 6 here]
Focusing first on men, use of full sample coefficients with the full sample worker attributes (X’s)
results in a predicted mean log earnings of 10.488. This is close to that obtained using respondent-only
betas, which leads to a predicted mean log earnings of 10.502, or 0.014 (one percent) higher than obtained
with the full sample. The equivalent values for women are 10.053 using full sample betas and 10.061
using respondent betas, a 0.008 difference. However, selection on observables is readily evident
comparing columns (2) and (3) using respondent (R) and nonrespondent (NR) betas, respectively. The R–
NR predicted earnings difference is 10.502-10.437 = 0.065 for men and 10.061 – 10.018 = .043 for
women. These differences are substantive. Because the nonrespondent shares of the total samples are
relatively small (roughly 20 percent), the respondent only sample provides coefficient estimates close to
what would be produced using the full sample, the latter not being an option with public use data. In
short, users of public data can avoid substantial bias by removing imputed earnings. One can rebalance
the respondent sample using inverse probability weights, adjusting the ASEC supplement weight with
model-based estimates of the probability of response. The analysis comparing male and female earnings
is particularly interesting because gender is the one worker attribute always matched correctly in Census
imputations (Bollinger and Hirsch 2006). That is, there exists no “match bias” (i.e., wage gap attenuation)
resulting from assignment of imputed earnings from a different-sex donor.
B.

Earnings Gaps across the Distribution
We next examine the implications of nonresponse across the distribution of earnings for a host of

widely-studied outcomes such as earnings gaps across gender, race, and education. Figures 6-8 depict
estimates of coefficients from quantile regressions of log annual earnings on the same set of covariates
used in our earlier conditional analyses at the 5th, 10th, 25th, 50th, 75th, 90th, 95th, and 99th quantiles. Each
figure contains estimates from two samples—one using DER earnings on both linked ASEC respondents
and nonrespondents (All Linked), and the other using linked respondents only (Linked Respondent). We
17

focus here on the full-time full-year subsample, in part because earnings distributions including part-time
and part-year workers confound the level of earnings with hours worked and thus are difficult to interpret.
While wages are often used in applications, concern arises there too with differences in wage distributions
between full-time/full-year workers and those who work less, as well as potential measurement error in
annual hours worked. It should be noted that quantile estimates are measuring differences in the
conditional distribution, and hence do not match the unconditional quantiles.
[Figure 6 here]
Figure 6 presents the estimated coefficients on the female indicator variable from pooled earnings
quantile regressions, along with the p-value of the difference in coefficient estimates from the two
samples. The OLS coefficients are presented as horizontal lines for comparison. In general, there are very
few differences between the OLS estimates on the two samples; respondent-only samples produce mean
estimates highly similar to the typically unavailable full sample, thus avoiding the sometimes severe bias
from including imputations. Quantile estimates at the tails, however, diverge substantially from mean
estimates and from each other. We observe gender gap estimates from the respondent-only sample that
are biased in the tails. The understatement is 0.04 log points at the 5th percentile, and 0.1 log points at the
99th percentile, or nearly one-fourth of the overall gap. As noted in Figure 2, differential response rates
between men and women are most pronounced in the tails of the distribution. These differential rates in
the tails have little impact on average gender gaps, but gender-gap estimates in the tails are problematic.
[Figure 7 here]
In Figure 7 we examine the black-white earnings differential separately for men (Panel A) and
women (Panel B) in the top panel, and the Hispanic-white differential for men (Panel C) and women
(Panel D) in the bottom panel. As in Figure 6, we see a similar pattern, where the respondent sample
produces biased estimates that understate the racial gap among men. The largest impact in Panel A is at
the high end of the distribution, where the bias is 0.038 log points, or nearly 20 percent relative to the
combined respondent-nonrespondent sample. As with the male-female differential, this is likely driven by
missing high earning men. Although black men are less likely to report than white men in general, it
appears that conditional on other factors, nonrespondents are disproportionately white men at the highest
earnings. Here, along with the consistent under-estimation of the differential in the respondent only
sample, the OLS estimates display modest under-estimation as well. In Panel B, the black-white
differential for women displays a slightly different pattern. While at the higher quantiles, the respondent
only sample continues to slightly understate the gap, we note that at the lower quantiles the bias is
reversed, with the respondent-only subsample slightly overstating the gap by about 0.012 log points, or
about 10 percent of the combined sample gap. Panels C and D depict the respective gaps for men and
18

women between Hispanics and whites. As we saw for the female black-white differential, the respondentonly sample understates the differential at the highest quantiles but overstates it at the lower quantiles for
both men and women. For Hispanic men, the bias in the differential is most pronounced at the highest
quantiles (0.03 log points at the 99th percentile, or 20 percent of the combined respondent/non-respondent
gap), while for women the bias is largest at the lowest quantiles.
[Figure 8 here]
Finally, Figure 8 examines the earnings differential between those whose highest degree is high
school (excluding GEDs) compared to high school dropouts (Panel A) and college graduates (with that
being the highest degree) compared to high school graduates (Panel B). High school returns are
systematically understated using the respondent sample, particularly so in the bottom half of the
distribution, but with minimal difference at the top of the distribution. The same qualitative pattern is seen
for estimates of the return to college, but with a modest downward bias throughout the entire distribution
(being largest at the 90th and 95th percentiles). In both schooling return cases, the respondent sample
understates the return at the means (OLS).
C.

Earnings Inequality
There is limited evidence regarding how earnings nonresponse affects the measurement of

inequality; a priori it is not readily apparent how it should do so. One needs to identify who fails to
respond, how nonresponse differs with respect to true and typically unobserved earnings (conditional on
covariates), how any such nonresponse bias might differ across the earnings distribution, and how one can
best treat topcoded earnings. Census uses different topcode values depending on earnings source, and
these values differ between internal and public release versions of the ASEC. A key advantage of the
DER data is that earnings are not topcoded, thus permitting a direct comparison of estimates of upper-tail
inequality from tax records to topcoded survey responses. Some inequality studies have excluded imputed
earners (Lemieux 2006; Autor, Katz, and Kearney 2008), while others have not (Burkhauser et al. 2012).
This is the first such direct comparison from linked individual survey and tax data on how nonresponse
and topcoding affects earnings inequality estimates. We estimate several leading measures of inequality
emphasized in the recent literature—including the Gini coefficient (Figure 9) and 90/10 ratio (Figure 10),
along with 90/50, 50/10, and top 1% share in Appendix Figures 7-9. For brevity, we restrict our
discussion here to the Gini coefficient results as similar patterns are obtained for the 90/10 ratio.
[Figures 9 and 10 here]
In Panel A of Figure 9 we show the earnings Gini for the full sample of workers. Shown in dashdot line is the full ASEC sample, in long-dash line is the ASEC for respondents only, in the solid line is
the DER for all linked workers (and ASEC for nonlinked), and in the short-dash line is the DER for
19

linked respondents. Comparing the full ASEC with imputes versus ASEC respondents only, one sees that
the respondent-only sample shows too low a level of inequality owing to the omission of nonrespondents
disproportionately represented in the far left and right tails. Hence, inclusion of imputes is appropriate for
measuring unconditioned inequality, despite the severe biases that can arise from inclusion of imputes in
conditioned analyses (Bollinger and Hirsch 2006). As with the ASEC, removing nonrespondents from the
DER reduces the Gini measure. The larger impact in the DER reflects the fact that the imputations in the
ASEC do not capture the NMAR aspect of nonresponse. As compared to the two DER measures, the
ASEC measures show a substantially lower level of inequality and somewhat different trends. Earnings
inequality in the ASEC is roughly flat over the full sample period, and everywhere below the DER. Using
DER earnings, we find a higher level of inequality (about 10 percent higher) and a modest upward trend
after 2007. Panel A establishes that NMAR nonresponse has an impact on measures of inequality.
Removing those missing values results in a downward bias in estimating inequality. Although inclusion
of the imputations fails to account for NMAR bias, it does correct for MAR bias with respect to those
attributes matched in the Census imputations.
In Panels B and C of Figure 9, we explore whether the gap between ASEC and DER earnings
inequality is due to nonresponse (Panel B) or due to differences in measurement of earnings, including
topcoding (Panel C). Panel B shows three series—the ASEC inclusive of nonrespondents; the DER for
linked respondents and nonrespondents (and ASEC for nonlinked); and a hybrid DER measure that uses
DER earnings for linked nonrespondents and ASEC earnings for respondents (and ASEC for the
nonlinked). In all cases the sample size is held constant by using the ASEC for the nonlinked, whether a
respondent or nonrespondent. Here we see that the hybrid measure produces a Gini level roughly onethird to halfway between the pure ASEC and DER measures. Comparing the hybrid measures to the pure
ASEC measures supports the conclusion that nonrandom, nonresponse bias (NMAR) causes an
understatement in the level and trend in earnings inequality based solely on ASEC.
Panel C presents the original ASEC and DER series, along with two additional series. In one
series the DER is used only for topcoded ASEC values with a DER link, and in the other series we
replace the ASEC with the DER for workers in the top half but not bottom half of the ASEC earnings
distribution, regardless of imputation or topcode status. The former case is of interest because the full
ASEC and DER groups include a convolution of nonrespondents and topcoded workers, and thus it is less
obvious what direct role the topcode in the internal ASEC plays vis-à-vis administrative tax data. The
latter case is of interest because the DER does not capture earnings off-the-book, and thus the higher level
of inequality observed in the DER might be an artifact of underreported earnings in the lower half of the
distribution. The results in Panel C demonstrate that topcoded earnings alone in the internal ASEC are not
the primary cause of the gap in inequality estimates from tax data in the DER versus ASEC survey data.
20

The DER-only series shows substantially higher and (to a lesser extent) rising inequality as compared to
ASEC earnings with DER replacing ASEC topcodes. In addition, the majority of the gap between the
DER and ASEC earnings inequality arises from earnings in the upper half of the ASEC distribution, and
not from off-the-books underreporting in the lower half. This conclusion is based on the minimal
differences between the DER-only series and the hybrid ASEC-DER series with DER earnings replacing
the ASEC in the top half of the ASEC distribution. ASEC measures of inequality tend to understate
inequality because the Census hot deck (owing to nonresponse bias) imputes earnings for nonrespondents
that are too high in the left tail and too low in the right tail.
6. Recommendations for Users of Public ASEC
Our results indicate that nonresponse bias causes both earnings gaps and inequality measures
estimated with ASEC earnings responses to be understated. Because of nonresponse, the observed data
include too few low earners and too few very high earners. The Census hot-deck procedure, based on the
MAR assumption, fails to correct this problem because MAR conditions are not met. The general CPS
user community does not have access to either the internal ASEC used in this paper (and by Census
employees) or the DER. The advantage of the former comes primarily from data with higher topcode
values compared to the public ASEC. Since 1996 Census has attempted to address this discrepancy, while
still maintaining confidentiality, by releasing “proxy values” for those individuals with earnings in
between the public and internal topcodes. During survey years 1996-2010 the proxy came in the form of
cell means, while from 2011 onward via rank swapping. The latter approach is preferred because it
preserves the distribution of earnings above the topcode. Recently Census released rank-swap values for
all the topcode income components (not just earnings) back to 1975, and we recommend that public
researchers using the ASEC prior to the 2011 survey year adopt these topcodes.12
Hirsch and Schumacher (2004) and Bollinger and Hirsch (2006) recommended dropping the
imputed nonrespondents in the ASEC because of the attenuation bias that imputations impart on
regression coefficients, and then reweighting the sample with inverse probability weights to retain
population representativeness. Their recommendation to drop imputes was based on analyses focusing on
models of central tendency (OLS, median regression). Overall, our results here strongly suggest that
MAR is violated across the distribution, and thus dropping nonrespondents and reweighting will not
correct for nonrandom nonresponse. In practice, we demonstrate that the economic bias from nonresponse
may be small in well-specified linear models of wages and earnings. As a general recommendation for
distributional research, however, public ASEC users are advised to implement a flexible selection model

12

https://www2.census.gov/programs-surveys/demo/datasets/income-poverty/time-series/data-extracts/asecincometopcodes-swappingmethod-corrected-110514.zip

21

that corrects for nonrandom nonresponse. In this section, we demonstrate the utility of one such approach
in an application to earnings inequality.
Specifically, we implement a procedure recently proposed in Arellano and Bonhomme (2017)
whereby one first estimates quantile regressions corrected for nonresponse using copula methods, and
then uses predictions from those regressions to create simulated earnings data. The key assumptions to
identification are an exclusion restriction, continuity of the residuals of the two equations (main and
selection), continuity of the dependent variable in the main outcome (earnings) and the propensity of
being observed to be conditionally non-zero (e.g. there is not some group that can be correctly predicted
to never be observed). For our application, we estimate conditional quantile models of earnings that
include controls for a quartic in age, nine education categories, race, gender, immigration status, region
and metro status, and industry, and correct for nonrandom selection using the Frank copula as it allows
for nonresponse to be concentrated in a tail.13 To identify the selection model, we use the month-insample in which the respondent is observed in the ASEC as an exclusion restriction. All else equal, we
expect nonresponse to be lower in months one or five of the rotation cycle as interviews are done in
person, while the other six months are conducted over phone. Appendix Figure 3 seems to confirm this as
it shows that rates of nonresponse in months 1 and 5 lie everywhere below months 2-4 and 6-8. Thus
month-in-sample should be correlated with nonresponse, and at the same time, we do not expect monthin-sample to be related to true individual earnings (Bollinger and Hirsch 2013).14 We have not observed
any variable, or combination of variables, which perfectly predict non-response or response. Thus, we are
confident that the key assumptions for identifying the Arellano and Bonhomme model are met.
After estimating the quantiles, we randomly generate an integer, q, between 1 and 99 for each
individual in the full sample. Following the conditional quantile decomposition method of Machado-Mata
(2005), we use the quantile coefficients associated with the draw of q for each individual to produce a
prediction of the qth quantile of their earnings distribution. This provides a simulated distribution which
can then be used to estimate a variety of statistics, including measures of income inequality. Because the
nonresponse throughout the distribution is addressed differentially at each quantile, the ArellanoBonhomme approach will provide a simulated distribution that has higher dispersion compared to the
more restrictive approach in Buchinsky (1998).
In evaluating the efficacy of this approach, there are two possible benchmarks against which to
compare our estimates, the latter of which are based solely on survey responses from the ASEC. The first
13

Our programs, which are based on those provided by Arellano and Bonhomme (2017), are available as
supplementary materials in the online publication.
14
Krueger, Mas, and Niu (2017) and Hirsch and Winters (2016) find substantial differences across the CPS monthin-sample reports of unemployment and multiple job holding, respectively. We find no such pattern of rotation
group bias with respect to earnings.

22

are the administrative records of the DER. The DER provides a source of information on income that is
official and is a natural comparison. As noted in Section 4.C, however, there are differences in how
individuals report ASEC earnings relative to their DER earnings. While one perspective is that the DER
earnings are “correct,” there is the potential that ASEC earnings contain earnings that are not reported to
the government (at the low end) or that DER earnings contain other errors (see Kapteyn and Ypma 2007).
The fundamental question being addressed in this paper is how to account for nonresponse. Hence the
ideal “benchmark” would be the ASEC where everyone answered the earnings question. The closest
approximation to that would be to use the ASEC earnings, but replace linked nonrespondents with their
DER. This is the benchmark we adopt.
[Table 7 and Figure 11 here]
We estimate the quantile selection model for each year, and in Table 7 present the six-year
average Gini coefficient, and 90-10, 90-50, and 50-10 ratios. We present the estimates for the full ASEC
including both respondents and imputed nonrespondents, the ASEC for respondents only but using
inverse probability weights to adjust for nonresponse, the ASEC for respondents only using the copula
selection model, and the benchmark of ASEC for respondents and DER for nonrespondents. Table 7
demonstrates that while the ASEC with IPW brings the inequality estimates closer to the benchmark
compared to the full ASEC, the IPW approach falls short compared to the quantile copula selection model
that captures nonrandom selection into response in the tails. Figure 11 presents the annual estimates of the
inequality measures, where we see that for several measures (i.e. Gini and 90-50 ratio) our method
sometimes exceeds inequality from the benchmark, and in some years falls below, so that on average it
aligns closely with the benchmark. The 90-10 and 50-10 ratios using the copula method lie below the
benchmark in each year, suggesting that some of the measurement differences between the DER and
ASEC at low earnings persist. The copula method still performs better, relative to the benchmark,
compared to either ASEC or the ASEC with IPW.
7. Conclusion
This paper set out to examine the progress in earnings measurement in the CPS in the more than
three decades since the important critique of Lillard, Smith, and Welch (1986). In our analysis we address
three questions relying on a unique restricted-access dataset that links ASEC household files to
administrative earnings tax records. First, how do nonresponse and patterns of nonresponse bias vary
across the earnings distribution and are these patterns similar for women and men (and other groups)?
Although levels of nonresponse differ based on gender, race, and ethnicity, U-shaped patterns of
nonresponse across the earnings distribution are highly similar across groups. Likewise, we see
substantial differences in the level of nonresponse based on the CPS survey month-in-sample and for
23

proxy versus self-respondents, yet we see highly similar U-shaped patterns of nonresponse with respect to
earnings for each of these groups. With or without conditioning on covariates, we find a U-shaped
nonresponse pattern, with left-tail “strugglers” and right-tail “stars” being least likely to report earnings.
Women and men have similar U-shaped nonresponse patterns across the distribution, although men have
a higher level of nonresponse.
Second, is nonresponse ignorable? The short answer is no. As stated above, nonresponse is not
independent of realized earnings, with or without control for covariates. Relatedly, earnings differ with
respect to response status, conditional on covariates. Our third question asks if there are economic
implications of nonrandom nonresponse on estimates of earnings gaps and inequality. We do find small
biases at the means for some earnings gaps (e.g., schooling returns and racial/ethnic wage gaps). Gender
gaps are slightly understated throughout much of the distribution, but substantively understated in both
the left and right tails. Because those with unusually low and high earnings, conditional on measured
attributes, are disproportionately missing from the sample, wage equation coefficient estimates on
attributes associated with very low (high) earnings are understated in absolute value. Race, gender, and
returns to schooling gaps in the tails can be off by as much as 20 percent due to nonresponse. Particularly
pronounced are estimates of upper-tail inequality where nonresponse accounts for one-third to one-half of
the 30 percent gap between survey and tax record estimates. Moreover, our evidence from matchedpanels shows that earnings growth estimates in the ASEC are substantially understated from imputations.
There is trouble in the tails.
The analysis in this paper has implications for researchers using the CPS, as well as similar
household data sets such as the American Community Survey (ACS). As emphasized in prior work, even
if nonresponse were completely missing at random, severe “match bias” can arise in the estimation of
earnings equation coefficients if researchers include nonrespondents whose earnings are imputed by
Census. The simplest and most widely used solution in this case is to throw out imputed earnings. The
respondent-only sample can be reweighted by the inverse probability of response, although in practice
this typically makes little difference. This easy fix, however, does not provide consistent estimates when
there is nonrandom nonresponse. This is particularly true for research focusing on the upper and lower
tails of the earnings distribution. Solving the problem of survey nonresponse is much more difficult
absent access to linked administrative data. Progress on this front can continue with additional efforts to
link household surveys, tax records, and federal and state-level administrative data on transfers, as
recommended recently by the bipartisan Commission of Evidence-Based Policymaking (2017). In the
interim, we demonstrated that a flexible copula-based model to correct for nonrandom selection into
response offers promise for researchers conducting distributional analysis using the ASEC.

24

References
Abowd, John M. and Martha H. Stinson. “Estimating Measurement Error in Annual Job Earnings: A
Comparison of Survey and Administrative Data.” Review of Economics and Statistics, 95 (December
2013): 1451-1467.
Alvey, Wendy and Cynthia Cobleigh, “Exploration of Differences between Linked Social Security and
CPS Earnings Data for 1972.” In Studies from Interagency Data Linkages, report no. 11, pp. 11-18.
Washington, D.C.: U.S. Department of Health, Education, and Welfare, 1980.
Arellano, Manuel and Stéphane Bonhomme “Quantile Selection Models with an Application to
Understanding Changes in Wage Inequality,” Econometrica 85 (January 2017): 1-28.
Autor, D., L. Katz, and M. Kearney. “Trends in U.S. Wage Inequality: Revising the Revisionists.” Review
of Economics and Statistics, 90(2), 2008: 300–323.
Bee, C. Adam, Graton M.R. Gathright, and Bruce D. Meyer. “Bias from Unit Non-Response in the
Measurement of Income in Household Surveys,” Unpublished Paper, August 2015.
Blau, Francine and Lawrence Kahn. “The Gender Wage Gap: Extent, Trends, and Sources.” Journal of
Economic Literature 55 (September 2017): 789-865.
Bollinger, Christopher R. “Measurement Error in the Current Population Survey: A Nonparametric
Look,” Journal of Labor Economics 16 (July 1998): 576-594.
Bollinger, Christopher R. and Martin H. David, “Estimation With Response Error and Nonresponse:
Food-Stamp Participation in the SIPP,” Journal of Business & Economic Statistics, 19 (April 2001):
129-141.
Bollinger, Christopher R. and Martin H. David, “I Didn’t Tell and I Won’t Tell: Dynamic Response Error
in the SIPP,” Journal of Applied Econometrics 20 (May/June 2005): 563-569.
Bollinger, Christopher R. and Barry T. Hirsch. “Match Bias from Earnings Imputation in the Current
Population Survey: The Case of Imperfect Matching,” Journal of Labor Economics 24 (July 2006):
483-519.
Bollinger, Christopher R. and Barry T. Hirsch. “Is Earnings Nonresponse Ignorable?” Review of
Economics and Statistics, 95 (May 2013): 407-416.
Bound, John, Charles Brown, Greg J. Duncan, and Willard L. Rodgers. “Evidence on the Validity of
Cross-sectional and Longitudinal Labor Market Data,” Journal of Labor Economics 12 (July 1994):
345-368.
Bound, John, Charles Brown, and Nancy Mathiowetz. “Measurement Error in Survey Data,” in Handbook
of Econometrics, Vol. 5, edited by E. E. Leamer and J. J. Heckman, Amsterdam: Elsevier, 2001,
3705-3843.
Bound, John and Alan B. Krueger. “The Extent of Measurement Error in Longitudinal Earnings Data: Do
Two Wrongs Make a Right?” Journal of Labor Economics 9 (1991): 1-24.
Buchinsky, Moshe. “Changes in the U.S. Wage Structure 1963-1987: An Application of Quantile
Regression.” Econometrica 62(2), 1994: 405-458.

25

Buchinsky, Moshe. “The Dynamics of Changes in the Female Wage Distribution in the USA: A Quantile
Regression Approach,” Journal of Applied Econometrics, 13(1998): 1-30.
Burkhauser, Richard V., Shuaizhang Feng, Stephen Jenkins and Jeff Larrimore. “Recent Trends in Top
Income Shares in the USA: Reconciling Estimates from March CPS and IRS Tax Return Data.”
Review of Economics and Statistics, 94 (2) (May 2012): 371-388.
Cameron, Stephen, and Joseph Tracy. “Earnings Variability in the United States: An Examination Using
Matched-CPS Data,” Working Paper, Federal Reserve Bank of New York (1998).
https://www.newyorkfed.org/medialibrary/media/research/economists/tracy/earnings_variability.pdf.
Commission on Evidence-Based Policymaking. The Promise of Evidence-Based-Policymaking
(September 2017): https://www.cep.gov/cep-final-report.html.
David, Martin, Roderick J. A. Little, Michael E. Samuhel, and Robert K. Triest. “Alternative Methods for
CPS Income Imputation,” Journal of the American Statistical Association 81 (March 1986): 29-41.
Dixon, John. “Using Contact History Information to Adjust for Nonresponse in the Current Population
Survey.” In JSM Proceedings, Section on Government Statistics. Alexandria, VA: American
Statistical Association, (August 2012): 1977-1982.
Duncan, Greg J. and Daniel H. Hill, “An Investigation of the Extent and Consequences of Measurement
Error in Labor-economic Survey Data,” Journal of Labor Economics 3 (October 1985): 508-532.
Fitzgerald, John, Peter Gottschalk, and Robert Moffitt. “The Michigan Panel Study of Income Dynamics,”
Journal of Human Resources 33 (Spring 1998): 251-299.
Greenlees, John, William Reece, and Kimberly Zieschang. “Imputation of Missing Values when the
Probability of Response Depends on the Variable Being Imputed,” Journal of the American
Statistical Association 77 (June 1982): 251-261.
Halsey, H. “Validating Income Data: Lessons from the Seattle and Denver Income Maintenance
Experiment,” Proceedings of the Survey of Income and Program Participation Workshop, Survey
Research Issues in Income Measurement: Field Techniques, Questionnaire Design, and Income
Validation, U.S. Department of Health, Education and Welfare, Washington, D.C., 1978.
Hardy, Bradly and James P. Ziliak. “Decomposing Trends in income Volatility: The “Wild Ride” at the
Top and the Bottom,” Economic Inquiry 52 (1) (January 2014): 459-476.
Heckman, James J. “Sample Selection Bias as Specification Error,” Econometrica 47 (January 1979):
153-161.
Heckman, James J. and Paul A. LaFontaine. “Bias-Corrected Estimates of GED Returns,” Journal of
Labor Economics 24 (3) (July 2006): 661-700.
Herriot, R. A. and E. F. Spiers. “Measuring the Impact on Income Statistics of Reporting Differences
between the Current Population Survey and Administrative Sources,” Proceedings, American
Statistical Association Social Statistics Section (1975): 147-158.
Hirsch, Barry T. and Edward J. Schumacher. “Match Bias in Wage Gap Estimates Due to Earnings
Imputation,” Journal of Labor Economics 22 (July 2004): 689-722.
Hirsch, Barry T. and John V. Winters. “Rotation Group Bias in Measures of Multiple Job Holding,”
Economics Letters 147 (2016): 160-163.
26

Hokayem, Charles, Christopher Bollinger, and James P. Ziliak. “The Role of CPS Nonresponse in the
Measurement of Poverty,” Journal of the American Statistical Association 110 (511) (September
2015): 935-045.
Hurst, Erik, Geng Li, and Ben Pugsley. “Are Household Surveys Like Tax Forms: Evidence from Income
Underreporting of the Self Employed,” Review of Economics and Statistics 96(1) (2015): 19-33.
Joe, Harry. Dependence Modeling with Copulas, CRC Press (Chapman and Hall), Boca Raton, FL, 2014.
Kapteyn, Arie and Jelmer Y. Ypma. “Measurement Error and Misclassification: A Comparison of Survey
and Administrative Data,” Journal of Labor Economics 25 (July 2007): 513-550.
Kline, Patrick and Andres Santos “Sensitivity to Missing Data Assumptions: Theory and an Evaluation of
the U.S. Wage Structure,” Quantitative Economics 4 (2013): 231-267.
Krueger, Alan, Alexandre Mas, and Xiaotong Niu. “The Evolution of Rotation Group Bias: Will the Real
Unemployment Rate Please Stand Up?” Review of Economics and Statistics 99 (May 2017): 258-264.
Larrimore, Jeff, Richard V. Burkhauser, Shuaizhang Feng, and Laura Zayatz. “Consistent Cell Means for
Topcoded Incomes in the Public Use March CPS (1976-2007).” Journal of Economic and Social
Measurement 33 (2008): 89-128.
Lee, Jungmin and Sokbae Lee. “Does It Matter Who Responded to the Survey? Trends in the U.S. Gender
Earnings Gap Revisited,” Industrial and Labor Relations Review 65 (January 2012): 148-160.
Lemieux, Thomas. “Increasing Residual Wage Inequality: Composition Effects, Noisy Data, or Rising
Demand for Skill.” American Economic Review 96 (June 2006): 461-498.
Lillard, Lee, James P. Smith, and Finis Welch. “What Do We Really Know about Wages? The Importance
of Nonreporting and Census Imputation,” Journal of Political Economy 94 (June 1986): 489-506.
Little, Roderick J.A. and Donald B. Rubin, Statistical Analysis with Missing Data, Second Edition. WileyInterscience: Hoboken, NJ, 2002.
Machado, Jose A.F. and Jose Mata. “Counterfactual Decomposition of Changes in Wage Distributions
Using Quantile Regression,” Journal of Applied Econometrics 20(2005):445-465.
Marquis, Kent H. and Jeffrey C. Moore. “Measurement Errors in SIPP Program Reports,” in Proceedings
of the 1990 Annual Research Conference, 721-745. Washington, DC: US Bureau of the Census, 1990.
Mathiowetz, Nancy A. and Greg J. Duncan. “Out of Work, Out of Mind: Response Error in Retrospective
Reports of Unemployment,” Journal of Business and Economic Statistics 6 (April 1988): 221-229.
Mellow, Wesley and Hal Sider. “Accuracy of Response in Labor Market Surveys: Evidence and
Implications,” Journal of Labor Economics 1 (October 1983): 331-344.
Nicholas, Joyce and Michael Wiseman. “Elderly Poverty and Supplemental Security Income,” Social
Security Bulletin 69 (2009): 45-73.
Peracchi, Franco, and Finis Welch. “How Representative are Matched Cross-Sections? Evidence from the
Current Population Survey,” Journal of Econometrics 68(1995): 153-179.
Piketty, Thomas and Emmanuel Saez. “Income Inequality in the United States,” Quarterly Journal of
Economics 118 (February 2003): 1-39.
Poterba, James M. and Lawrence H. Summers. “Reporting Errors and Labor Market Dynamics,”
27

Econometrica 6 (November 1986): 221-229.
Reynolds, Jeremy and Jeffrey B. Wenger. "He Said, She Said: The Gender Wage Gap According to Self and
Proxy Reports in the Current Population Survey," Social Science Research 41 (March 2012): 392-411.
Roemer, Mark. “Using Administrative Earnings Records to Assess Wage Data Quality in the Current
Population Survey and the Survey of Income and Program Participation.” Longitudinal EmployerHousehold Dynamics Program Technical Paper No. TP-2002-22, US Census Bureau, 2002.
Rogers, Willard L. and A. Regula Herzog. “Covariances of Measurement Errors in Survey Responses,”
Journal of Official Statistics 3 (October 1987): 403-418.
Rubin, Donald B., “Inference and Missing Data (with Discussion),” Biometrika 63 (1976): 581-592.
Vella, Francis. “Estimating Models with Sample Selection Bias: A Survey,” Journal of Human Resources
33 (Winter 1998): 127-169.
Welniak, Edward J. “Effects of the March Current Population Survey's New Processing System On
Estimates of Income and Poverty,” Proceedings of the American Statistical Association, 1990.

28

Note: This figure displays trends in item earnings and total (item + whole supplement) imputations in the ASEC
among workers. The imputation rate is weighted using the ASEC supplement weight. Source: Authors’
calculations. U.S. Census Bureau, Current Population Survey, 1988-2016 Annual Social and Economic Supplement.

29

Note: Each panel shows the nonresponse rate for a 3-pt moving percentile average across a common DER earnings
distribution for men and women. The nonresponse rate is weighted using inverse probability weights for ASECDER linkage. Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic
Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

30

Note: Each panel shows the nonresponse rate for a 3-pt moving average across the predicted DER earnings
distribution. The nonresponse rate is weighted using inverse probability weights for ASEC-DER linkage.
Predicted DER earnings come from an OLS estimation of equation (4) described in Section 4.A in the text. Sources:
U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social
Security Administration, Detailed Earnings Record, 2005-2010.

31

Note: Each panel shows the kernel density estimate of residuals for respondent and nonrespondent distributions.
Residuals come from an OLS estimation of equation (4) descrbed in Section 4.B in the text and Appendix A.5. The
OLS estimation uses inverse probability weights for ASEC-DER linkage. Sources: U.S. Census Bureau, Current
Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security Administration, Detailed
Earnings Record, 2005-2010.

32

Note: Each panel shows the nonresponse rate for a 3-pt moving average for the Year 1 DER earnings distribution in
the 2-year ASEC panel. The nonresponse rate is shown for Year 1, Year 2, and both years of the panel. The
nonresponse rate is weighted using inverse probability weights for ASEC-DER linkage. Sources: U.S. Census
Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security
Administration, Detailed Earnings Record, 2005-2010.

33

Note: This figure plots the female coefficient from saturated quantile and OLS regressions using DER
earnings for two samples: (1) linked ASEC respondents and nonrespondents (“DER All Linked Quantile”
and “DER All Linked OLS”) and (2) linked respondents only (“DER Linked Respondent Quantile” and
“DER Linked Respondent OLS”). OLS and quantile estimates are weighted using inverse probability weights
for ASEC-DER linkage. Numbers in the figure show p-values of the difference in the quantile estimates
between the “DER All Linked” and “DER Linked Respondent” samples at each quantile. Sources: U.S.
Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social
Security Administration, Detailed Earnings Record, 2005-2010.

34

Note: Panel A (C) plots the black (Hispanic) coefficient from saturated quantile and OLS regressions using DER
earnings for two male samples: (1) linked ASEC respondents and nonrespondents (“DER All Linked Quantile” and
“DER All Linked OLS”) and (2) linked respondents only (“DER Linked Respondent Quantile” and “DER Linked
Respondent OLS”). Similarly, Panel B (D) plots the black (Hispanic) coefficient from saturated quantile and OLS
regressions using DER earnings for two female samples. OLS and quantile estimates are weighted using inverse
probability weights for ASEC-DER linkage. Numbers in the figure show p-values of the difference in the quantile
estimates between the “DER All Linked” and “DER Linked Respondent” samples at each quantile. Sources: U.S.
Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security
Administration, Detailed Earnings Record, 2005-2010.

35

Note: Panel A plots the coefficient comparing high school to high school dropouts from saturated quantile and OLS
regressions using DER earnings for the two samples described in Figure 6. Similarly, Panel B plots the coefficient
comparing college graduates to high school graduates from saturated quantile and OLS regressions using DER earnings
for the two samples described in Figure 6. OLS and quantile estimates are weighted using inverse probability weights
for ASEC-DER linkage. Numbers in the figure show p-values of the difference in the quantile estimates between the
“DER All Linked” and “DER Linked Respondent” samples at each quantile. Sources: U.S. Census Bureau, Current
Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security Administration, Detailed
Earnings Record, 2005-2010.

36

Note: Panel A shows the earnings Gini for the following series: (1) full ASEC sample (“ASEC”); (2) ASEC earnings
for only respondents (“ASEC, Respondents Only”); (3) DER earnings for all linked workers and ASEC earnings for
nonlinked (“DER”); and (4) DER earnings for only linked respondents (“DER, Respondents Only”). Panel B includes a
series that uses DER earnings for nonrespondents and ASEC earnings for respondents (“DER for NR, ASEC for R”).
Panel C includes a series that uses DER earnings only for topcoded ASEC earnings (“DER for Top Code Only”) and a
series that uses DER earnings for workers in the top half of the ASEC earnings distribution (“DER for Top 50% Only”).
The Gini is weighted using the ASEC supplement weight. Sources: U.S. Census Bureau, Current Population Survey,
2006-2011 Annual Social and Economic Supplement. Social Security Administration, Detailed Earnings Record, 20052010.

Note: This figure shows the 90-10 percentile ratio for various series. See note to Figure 9 for series descriptions.
Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social
Security Administration, Detailed Earnings Record, 2005-2010.

37

Note: Each panel shows inequality measures for the following series: (1) full ASEC sample (“ASEC”); (2) DER
earnings for nonrespondents and ASEC earnings for respondents (“DER for NR, ASEC for R”); (3) ASEC earnings
for only respondents weighted by inverse probability weights for nonresponse (“ASEC, Respondents Only, IPW”);
and (4) ASEC earnings for only respondents using the copula selection model (“ASEC, Respondents Only,
Copula”). See Section 6 in the text for further details about each series. Unless otherwise noted, all series are
estimated using the ASEC supplement weight.Sources: U.S. Census Bureau, Current Population Survey, 2006-2011
Annual Social and Economic Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

38

Table 1. Sample Averages by Response Status and by Linkage Status
Response Status
Linkage Status
Full Sample Respondent Nonrespondent Linked Nonlinked
Age

41.4

41.3

41.8

41.7

39.6

White, Non-Hispanic

68.7

69.3

66.4

71.8

49.0

Black, Non-Hispanic

10.6

9.9

13.0

10.6

10.9

Asian, Non-Hispanic

4.5

4.3

5.2

4.2

6.2

Other Race, Non-Hispanic

1.9

1.9

1.7

1.9

1.7

Hispanic

14.4

14.5

13.7

11.5

32.2

Female

46.8

47.5

44.7

47.9

39.9

Education (years)

13.7

13.7

13.6

13.9

12.6

Married, Spouse Present

57.6

58.5

54.3

58.9

49.4

Married, Spouse Absent

16.9

16.9

16.9

16.6

18.6

Single, Never Married

25.6

24.6

28.9

24.5

32.0

Native

84.2

84.5

83.4

87.6

63.6

Foreign Born, US Citizen

6.5

6.3

7.2

6.3

7.7

Foreign Born, Not a US Citizen

9.2

9.2

9.4

6.1

28.8

Full Time, Full Year

71.2

70.6

73.4

72.3

64.3

Work Hours (per week)

39.9

40.0

39.8

40.2

38.5

Nonresponse Rate (W&S or SE)

22.6

0

100

20.1

38.0

Nonresponse Rate (W&S)

22.4

0

99.1

19.9

37.9

Linkage Rate

86.2

88.9

76.7

100

0

Proxy

48.0

45.1

58.1

47.2

53.1

ASEC Total Earnings ($2010)

45,897

45,838

46,099

47,665

34,884

DER Total Earnings ($2010)

48,478

47,895

50,796

48,478

NA

DER Ave. Hourly Total Earnings ($2010)
Observations

25.61
508,288

25.45
399,823

28.70
108,465

26.10
440,227

NA
68,061

Race/Ethnicity

Gender

Marital Status

Nativity

Employment

Nonresponse

Note: This table shows sample descriptive statistics for the full sample and broken down by ASEC response status and
ASEC-DER linkage status. Full ASEC averages include imputed nonrespondent earnings.Each average is weighted by the
ASEC supplement weight. Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and
Economic Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010. For information on
confidentiality protection, sampling error, non-sampling error, and definitions, see https://www2.census.gov/programssurveys/cps/techdocs/cpsmar17.pdf.

39

Table 2: ASEC Mean Nonresponse with Respect to DER Earnings for
Men and Women, 2006-2011
(1)

(2)

(3)

Unweighted
OLS

Weighted
OLS

Weighted
OLS w/X's

(4)
Weighted
OLS w/X's
Interacted
with DER

Men
𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅
Constant
Observations
R-squared

-0.017*
(0.001)
0.374*
(0.009)
224,852
0.002

-0.018*
(0.001)
0.398*
(0.011)
224,852
0.002

-0.014*
(0.001)
0.436*
(0.017)
224,852
0.018

-0.012*
(0.001)
0.401*
(0.054)
224,852
0.019

Women
𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅
Constant
Observations
R-squared

-0.009*
(0.001)
0.276*
(0.008)
214,869
0.001

-0.010*
(0.001)
0.292*
(0.010)
214,869
0.001

-0.008*
(0.001)
0.349*
(0.017)
214,869
0.015

-0.008*
(0.001)
0.412
(0.051)
214,869
0.016

Note: This table shows OLS estimation of equation (3) described in Section 4 of the text. Columns (1)
and (2) include a single control, 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 . Columns (3) and (4) include additional controls for
potential experience, race, marital status, citizenship, education, metropolitan area size, occupation,
industry, and year. Column (4) interacts these controls with 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 . Robust standard errors in
parentheses. * p<0.01. Weighted estimates are weighted using inverse probability weights for ASECDER linkage. Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and
Economic Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

40

Table 3: ASEC Nonresponse across the DER Earnings Distribution for
Men and Women, 2006-2011
(1)

(2)
Men

DER Earnings
Deciles and
Percentiles
Decile 10
Decile 20
Decile 30
Decile 40
Decile 50
Decile 60
Decile 70
Decile 80
Decile 90
Percentiles 91-95
Percentile 96
Percentile 97
Percentile 98
Percentile 99
Percentile 100

Observations
R-squared

(3)

(4)
Women
Earnings
Earnings
Decile
Decile
Dummies
Dummies and
OLS
X’s, OLS

Earnings
Decile
Dummies
OLS

Earnings
Decile
Dummies and
X’s, OLS

0.267***
(0.004)
0.253***
(0.004)
0.217***
(0.003)
0.210***
(0.003)
0.189***
(0.003)
0.179***
(0.003)
0.178***
(0.003)
0.176***
(0.003)
0.185***
(0.003)
0.200***
(0.004)
0.199***
(0.010)
0.227***
(0.011)
0.252***
(0.011)
0.271***
(0.011)
0.320***
(0.011)

0.140***
(0.009)
0.130***
(0.009)
0.098***
(0.009)
0.095***
(0.009)
0.074***
(0.009)
0.064***
(0.009)
0.065***
(0.009)
0.064***
(0.009)
0.073***
(0.009)
0.088***
(0.010)
0.086***
(0.013)
0.111***
(0.014)
0.133***
(0.014)
0.149***
(0.014)
0.192***
(0.015)

0.213***
(0.003)
0.214***
(0.004)
0.202***
(0.003)
0.198***
(0.003)
0.194***
(0.003)
0.184***
(0.003)
0.180***
(0.003)
0.174***
(0.003)
0.176***
(0.003)
0.176***
(0.004)
0.197***
(0.010)
0.193***
(0.010)
0.183***
(0.010)
0.189***
(0.010)
0.243***
(0.011)

0.120***
(0.009)
0.119***
(0.009)
0.109***
(0.009)
0.107***
(0.009)
0.103***
(0.009)
0.095***
(0.009)
0.094***
(0.009)
0.089***
(0.009)
0.091***
(0.009)
0.090***
(0.010)
0.106***
(0.013)
0.102***
(0.013)
0.091***
(0.013)
0.097***
(0.013)
0.146***
(0.014)

224,852
0.212

224,852
0.225

214,869
0.192

214,869
0.204

Note: This table shows OLS estimation of equation (3) which includes DER earnings decile dummy
variables described in Section 4.A of the text. Columns (1) and (3) only include decile dummy variables
while columns (2) and (4) add controls described in Table 2. Robust standard errors in parentheses. ***
p<0.01. Estimates are weighted using inverse probability weights for ASEC-DER linkage. Sources: U.S.
Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social
Security Administration, Detailed Earnings Record, 2005-2010.

41

Table 4: Proxy Misreporting of Male and Female Annual and Hourly Earnings
based on CPS-ASEC and DER Differences in Proxy Coefficients

Variable
Annual Earnings
Earnings equations with proxy coefficients
Proxy
Earnings equations with spouse and nonspouse proxy coefficients
Spouse Proxy
Nonspouse Proxy
Hourly Earnings
Wage equations with proxy coefficients
Proxy
Wage equations with spouse and nonspouse proxy coefficients
Spouse Proxy
Nonspouse Proxy

(1)
CPSASEC
Men

(2)
CPSASEC
Women

(3)

(4)
DER
Women

(5)
CPS Proxy
Misreport
Men

(6)
CPS Proxy
Misreport
Women

DER
Men

-0.0638

0.0502

-0.0017

0.0647

-0.0621

-0.0145

0.0233
-0.2010

0.1210
-0.0576

0.0807
-0.1320

0.1330
-0.0392

-0.0574
-0.0690

-0.0120
-0.0184

-0.0501

0.0031

0.0117

0.0172

-0.0618

-0.0141

-0.0091
-0.1150

0.0360
-0.0473

0.0483
-0.0459

0.0476
-0.0289

-0.0574
-0.0691

-0.0116
-0.0184

Note: This table shows the OLS estimation of earnings and wage regressions that include controls for proxy, spouse proxy, and nonspouse proxy. Columns 1 and 2
use ASEC earnings while Columns 3 and 4 use DER earnings. CPS proxy misreporting estimates (Columns 5 and 6) are calculated as the difference between the
ASEC and DER proxy coefficients (Column 1-Column 3 for men and Column 2-Column 4 for women). See Section 4.C in the text for further explanation. The CPSASEC equations exclude imputed earners since we cannot know whether the donor’s earnings were self-reported or from a proxy. The DER equations includes the
same sample. All columns include additional controls described in Table 2. Estimates are weighted using inverse probability weights for ASEC-DER linkage.
Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security Administration, Detailed Earnings
Record, 2005-2010.

42

Table 5: Joint Distribution of Response and Log Earnings Growth By Response Status
Log Earnings Growth:
Rate
ASEC
DER
(1)
(2)
(3)
0.006
0.013
Full Sample
7.9
0.037
0.020
Nonrespondent in both years
72.8
0.0001
0.011
Respondent in both years
10.3
-0.008
-0.017
Respondent only in year 1
9.0
0.037
0.055
Respondent only in year 2
Note: This table shows nonresponse and response rates (Column 1) and log earnings growth for ASEC earnings
(Column 2) and DER earnings (Column 3) by response status for the 2-year ASEC panel. Column 1 is unweighted
while Columns 2 and 3 are weighted by inverse probability weights for a ASEC-DER linkage. Sources: U.S. Census
Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security
Administration, Detailed Earnings Record, 2005-2010.

43

Table 6: 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 Equation Predicted Log Earnings with Full Sample,
ASEC Respondents, and ASEC Nonrespondents, 2006-2011

VARIABLES

(1)
(2)
(3)
Betas from
Betas from
Betas from
𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅
All Workers
Respondents
Nonespondents

Men
Prediction with full sample X’s
Observations
R-squared of earnings equation

10.488
224,852
0.321

10.502
180,564
0.327

10.437
44,288
0.306

Women
Prediction with full sample X’s
Observations
R-squared of earnings equation

10.053
214,869
0.268

10.061
175,253
0.274

10.018
39,616
0.253

Note: This table shows predicted mean 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 from earnings regressions for all linked workers
(Column 1), linked respondents (Column 2), and linked nonrespondents (Column 3). Predicted
𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 are based on sample means from the full ASEC sample. All columns include additional
controls described in Table 2. Regression estimates use inverse probability weights for ASEC-DER
linkage. Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic
Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

44

Table 7. Performance of Selection Correction Methods for Nonresponse in the ASEC on Inequality
Inequality Measures
Sample

Gini

90-10

90-50

50-10

ASEC

0.461

10.099

2.607

3.870

ASEC, Respondents Only
with IPW

0.464

10.227

2.641

3.869

ASEC, Respondents Only
with Copula

0.482

10.521

2.676

3.929

ASEC for Respondents,
DER for Nonrespondents
(benchmark)

0.477

11.038

2.683

4.112

Note: This table shows inequality measures for the following series: (1) full ASEC sample (“ASEC”); (2) ASEC earnings
for only respondents weighted by inverse probability weights for nonresponse (“ASEC, Respondents Only with IPW”); (3)
ASEC earnings for only respondents using the copula selection model (“ASEC, Respondents Only with Copula”); and (4)
DER earnings for nonrespondents and ASEC earnings for respondents (“ASEC for Respondents, DER for
Nonrespondents”). See Section 6 in the text for further details about each series. Unless otherwise noted, all series are
estimated using the ASEC supplement weight. Sources: U.S. Census Bureau, Current Population Survey, 2006-2011
Annual Social and Economic Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

45

Appendix
The following sections provide additional information on the data and results reported in “Trouble in the
Tails? What We Know about Earnings Nonresponse Thirty Years after Lillard, Smith, and Welch.” Two
references not in the paper are shown in footnotes. See the paper for all other references.
A.1 Data
The data used in our analysis are individual-level data from the Current Population Survey
Annual Social and Economic Supplement (CPS ASEC) for survey years 2006-2011 (calendar years 20052010). These records are linked to Social Security Administration Detailed Earnings Records (DER)
using a unique Protected Identification Key (PIK) produced within the Census Bureau’s Center for
Administrative Records Research and Applications. The PIK is a confidentiality-protected version of the
Social Security Number (SSN). Since the Census does not currently ask respondents for a SSN, Census
uses its own record linkage software system, the Person Validation System, to assign a SSN. This
assignment relies on a probabilistic matching model based on name, address, date of birth, and gender.
The SSN is then converted to a PIK in order to link the ASEC and DER. The Census Bureau changed its
consent protocol to link respondents to administrative data beginning with the 2006 ASEC. Prior to this
CPS collected respondent SSNs and an affirmative agreement allowing a link to administrative data; i.e.,
an “opt-in” consent option. Beginning with the 2006 ASEC, respondents not wanting to be linked to
administrative data had to notify the Census Bureau through the survey field representative, website or
use a mail-in response in order to “opt-out”. This opt-out rate is a very small 0.5 percent of the ASEC
sample. If the respondent doesn’t opt out, they are assigned a SSN using the Person Validation System.
Under the prior “opt-in” consent option in the 2005 ASEC, the linkage rate among earners was only 61
percent, as compared to 86 percent for our full 2006-2011 ASEC sample (Table 1 of main text).
Appendix Figure 1 shows the linkage rates across the ASEC earnings distribution for our full
sample of all wage and salary workers, for full-time full-year workers, and by gender. Linkage rates
between the ASEC and DER administrative data average about 87 percent. The linkage rate is lowest at
the low end of the earnings distribution, with men notably lagging women in linkage rates in the bottom
quarter of earnings. Below we discuss how we handle missing linkages.

A-1

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

A.2 The ASEC Imputation Procedure for Earnings
As reported in the main text (Figure 1), in survey year 2016 the total earnings nonresponse rate
was 43 percent, with item nonresponse accounting for 24 percentage points and whole supplement
nonresponse 19 percentage points. The Census Bureau has used a hot deck procedure for imputing
missing income since 1962, with the current system in place with few changes since 1989 (Welniak
1990). The ASEC uses a sequential hot deck procedure to address item nonresponse for missing earnings
data. The sequential hot deck procedure assigns individuals with missing earnings values that come from
individuals (“donors”) with similar characteristics. First, individuals with missing data are divided into
one of 12 allocation groups defined by the pattern of nonresponse. Examples include a group that is only
missing earnings from longest job or a group that is missing both longest job information and earnings
from longest job. Second, an observation in each allocation group is matched to a donor observation with
complete data based on a large set of socioeconomic variables, the match variables. If no match is found
based on the large set of match variables, then a match variable is dropped and variable definitions are
collapsed (i.e., categories are broadened) to be less restrictive. This process of sequentially dropping a
variable and collapsing variable definitions is repeated until a match is found. When a match is found, the
missing earnings amount is substituted with the reported earnings amount from the first available donor.

A-2

The ASEC also uses a hot deck procedure for whole supplement imputes. Whole imputation refers
to a household who has participated in the monthly CPS, but refused participation in the ASEC supplement.
In this case the entire supplement is imputed by a “similar” household that participated in the supplement.
The whole imputation procedure uses 8 allocation groups. The set of match variables is smaller than the set
used for item nonresponse, consisting of variables available from the monthly CPS for both the supplement
nonrespondent and donor household. Like the sequential hot deck procedure for item nonresponse, the
match process sequentially drops variables and makes them less restrictive until a donor is found. This
requirement implies that donors do not have to answer all the ASEC questions and can have item
imputations. The sequential hot deck used in the ASEC has the advantage that it always finds a match
within the current month. It has the disadvantage that one cannot readily know which characteristics are
matched and the extent to which variable categories have been collapsed. The quality of an earnings match
depends on how common are an individual’s attributes (Lillard, Smith, and Welch, 1986).
Appendix Table 1 further divides the full sample reported in Table 1 of the main text into four
groups: linked respondents, linked nonrespondents, nonlinked respondents and nonlinked
nonrespondents. Linked respondents have the highest percentage of women, the highest educational
attainment, the highest percent who are married spouse present, and the highest rate of native born.
Linked nonrespondents have the highest concentration of full-time full-year workers, and the highest
concentration of Blacks. Nonlinked respondents have the highest concentration of Hispanics and males,
and the highest percent of part-time full-year workers. Nonlinked nonrespondents have the highest
concentration of single-never married individuals, foreign born citizens, and full-time part-year workers.
Because of possible differences between those linked with a PIK and those not linked (for a review
of the CPS linkage, see Bond et al., 20131), in Appendix Table 2 we further subdivide the sample based on
nativity and Hispanic ethnicity. There we see that Hispanic workers have a lower link rate in the full
sample than non-Hispanic workers (other demographic groups did not show marked differences). Among
those who are native born, the difference between Hispanic and non-Hispanic samples is not remarkable
(86.9 percent as compared to 89.7 percent). Further, among the immigrant Hispanic samples, those who
have become naturalized citizens – while exhibiting lower link rates than the native born – the difference is
again small (82.1 percent vs 84.6 percent). However, among those who have not become naturalized
citizens, the difference is quite substantial: only 44 percent of non-naturalized Hispanic immigrants in the
ASEC were linked to a DER record. Non-naturalized Hispanic immigrants are approximately 6 percent of
the full sample, yet account for 26 percent of the nonlink cases. On the other hand, the nonresponse rates
Bond, Brittany, J. David Brown, Adela Luque, and Amy O’Hara. “The Nature of the Bias When Studying Only
Linkable Person Records: Evidence from the American Community Survey,” Proceedings of the 2013 Federal
Committee on Statistical Methodology (FCSM) Research Conference, 2013.
1

A-3

for the earnings questions are very stable across these groups. Overall 22.6 percent of the ASEC sample
failed to respond to the wage and salary or self-employment earnings questions, and this rate is little
different among the native born and naturalized and non-naturalized Hispanics (again, nearly all is from
wage and salary nonresponse). We note that non-citizen immigrants are dominated by Hispanics at 64.6
percent; naturalized immigrants are 38.9 percent Hispanic.
Appendix Table 1. Sample Averages by Link and Response Status
Linked
Respondent
41.6

Linked
Nonrespondent
42.1

Nonlinked
Respondent
38.8

Nonlinked
Nonrespondent
40.8

White, Non-Hispanic

72.3

69.8

45.4

55.0

Black, Non-Hispanic

9.9

13.3

10.1

12.1

Asian, Non-Hispanic

4.1

4.6

5.6

7.2

Other Race, Non-Hispanic

2.0

1.8

1.9

1.6

Hispanic

11.7

10.6

37.1

24.1

Female

48.5

45.8

39.3

40.9

Education (years)

13.9

13.7

12.4

13.0

Married, Spouse Present

59.7

55.6

49.2

49.7

Married, Spouse Absent

16.6

16.4

18.7

18.3

Single, Never Married

23.7

27.9

32.1

32.0

Native

87.6

87.3

59.3

70.5

Foreign Born, US Citizen

6.2

6.9

7.3

8.3

Foreign Born, Not a US Citizen

6.2

5.8

33.4

21.2

Full Time, Full Year

71.7

74.7

61.4

69.1

Work Hours (per week)

40.3

40.1

38.2

38.9

Nonresponse Rate (W&S or SE)

0

100

0

100

Nonresponse Rate (W&S)

0

98.9

0

99.8

Age
Race/Ethnicity

Gender

Marital Status

Nativity

Employment

Nonresponse

Linkage Rate

100

100

0

0

Proxy

44.4

58.1

50.1

58

ASEC Total Earnings ($2010)

47,660

47,685

31,213

40,876

DER Total Earnings ($2010)

47,895

50,796

NA

NA

DER Ave. Hourly Total Earnings ($2010)

25.45

28.7

NA

NA

356,190

84,037

43,633

24,428

Observations
Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

A-4

Appendix Table 2. Response and Linkage Rates by Hispanic Origin and Immigrant Status
Full Sample

Native Born

All

NonHispanic

Hispanic

Linkage Rate

86.1

89.0

Nonresponse Rate (W&S or SE)

22.6

Nonresponse Rate (W&S)

22.4

Immigrants
Naturalized Citizen
NonHispanic
Hispanic
84.6
82.1

Non-Citizen
NonHispanic
Hispanic
77.9
44.0

69.0

NonHispanic
89.7

Hispanic
86.9

22.7

21.6

22.4

21.2

26.9

21.0

24.3

22.3

22.5

21.5

22.2

21.0

26.8

20.9

21.2

22.2

78.8

73.1

78.9

75.7

77.8

Respondent

77.4

77.3

78.4

77.6

Percent Hispanic

14.4

0

100

0

100

0

100

0

100

100

84.2

15.8

76.7

7.2

4.1

2.6

3.3

6.1

Percent of Hispanic sample

-

0

100

-

45.1

-

16.3

-

38.5

Percent of non-Hispanic sample

-

100

0

91.2

-

4.8

-

4.0

-

Percent of all Immigrants
Percent of Naturalized Citizen
sample

-

46.0

54.0

-

-

25.3

16.1

20.8

37.9

-

-

-

-

-

61.1

38.9

-

-

Percent of Non-Citizen Sample

-

427,736

-

-

-

-

-

35.4

64.6

Column Relative to Other Samples
Percent of Full Sample

508,288
80,552
390,030
36,344
20,704
13,157
17,002
31,051
Observations
Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security Administration, Detailed
Earnings Record, 2005-2010.

A-5

A.3 ASEC Nonresponse across the DER Earnings Distribution
Figure 2 of the main text shows that while the level of nonresponse between men and women
differs, the general shape of the relationship with earnings percentiles is similar across gender. Here we
show that the U-shape holds for earnings nonresponse across racial and ethnic groups. We focus on four
groups here: Non-Hispanic White, Non-Hispanic Black, Hispanic, and Non-Hispanic Asian (includes
Native Americans, Pacific Islanders, and other groups). Appendix Figure 2 is comparable to Figure 2 in
that a U-shaped relationship is muted in Panel A (annual earnings) but readily apparent in both Panels B
and C (FT/FY and hourly earnings, respectively). The U-shape is ubiquitous: it appears to hold for all
racial and Hispanic ethnic groups. The overall level of nonresponse differs somewhat across groups, with
Blacks having the highest rates throughout much of the distribution, and Hispanics having the lowest
rates. Differences between Whites, Hispanics, and Asians are very small.

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

We also examine nonresponse by interview month in Appendix Figure 3. The sample design of
the ASEC is such that respondents are in for four months, out for another eight months, and then in for

A-6

four more months. Interviews for months 1 and 5 are conducted in-person, while months 2-4 and 6-8
typically rely on telephone interviews. Bollinger and Hirsch (2013) note that nonresponse for the ASEC
earnings question is lower in the first and fifth month in sample (MIS 1 and 5). Krueger, Mas, and Niu
(2017) find rotation group bias in unemployment rates, with the highest rates in MIS 1 and 5. Hirsch and
Winters (2016) find the same pattern for multiple job holding. It is not surprising that earnings
nonresponse is lower in MIS 1 and 5, but this raises the question of whether the U-shaped nonresponse
pattern found for the full sample differs between MIS 1 and 5 and the other months in sample. The figure
graphs the average nonresponse rates from months 1 and 5 against the average nonresponse rates in
months 2-4 and 6-8. Panels A-C are for men and refer to earnings among all workers, earnings among
full-time full-year workers, and average hourly earnings of all workers. Panels D-F present parallel
figures for women. The graphs highlight that the months spanning telephone interviews have higher
nonresponse, but in all cases the U-shape does not depend upon the month in sample.

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

As noted in the main text, over one-half of earnings responses of men in the ASEC are reported
by a proxy respondent, and over 40 percent of women’s earnings are via proxy. We also note there rates
of nonresponse among proxies are about 8 percentage points higher than self-reports. Appendix Figure 4

A-7

depicts rates of nonresponse across the distribution based on proxy status. Earning nonresponse rates by
proxy status are shown for men and women in the figure across both the DER earnings distribution
(Panels A and C) and the average hourly wage distribution (Panels B and D), separately for selfrespondents and those whose earnings are reported by a household proxy. Despite the large differences in
levels of nonresponse between proxies and self-respondents, their nonresponse patterns are similarly Ushaped. We see high rates of nonresponse in both tails of the distribution, with relatively flat rates
throughout the middle of the distribution. A finding that use of proxies increases item nonresponse of
earnings and lessens the accuracy of reported earnings need not imply that Census should increase use of
self-reports and rely less on proxy respondents. Use of proxies substantially lowers the time and money
costs of conducting Census household surveys. Unknown is the extent to which nonresponse among
proxies is due to poor information on earnings. For some (unknown) share of proxies, earnings
nonresponse may be preferable to a poor guestimate of earnings.

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

A-8

A.4 Inverse Probability Weights for ASEC-DER Linkage
As we note in the main text, we fail to link about 14 percent of the ASEC sample to the DER due
to missing PIKs. The evidence in Appendix Table 2 suggests that link failure between ASEC and DER is
concentrated on undocumented immigrants. Because the opt-out rate to agree to link ASEC and the DER
is a trivial 0.5 percent, the majority of the “link failures” are due to a lack of personally identifiable
information needed to construct a SSN, and in turn a PIK. We take a stand that failure to PIK is a problem
that can be addressed with a MAR assumption—selection on observables—and most readily implemented
via inverse probability weighting to reweight the linked ASEC-DER sample to make is representative
even in the presence of link failures. That is, because most of the linkage failures are not due to an opt-out
choice by the respondent, and instead are accounted for by observed demographics, we believe any
potential bias from selection on unobservables, which would not be corrected by IPW, is minimal.
In order to address this, for each year we estimate a saturated probit model of the probability of
an ASEC-DER link as a function of a full array of demographic characteristics as
(A.1)

𝐿∗𝑖𝑡 = 𝑋𝑖𝑡 𝛽𝑡 + 𝑢𝑖𝑡 ;

𝑤ℎ𝑒𝑟𝑒 𝐿𝑖𝑡 = 1 𝑖𝑓 𝐿∗𝑖𝑡 > 0; 𝐿𝑖𝑡 = 0 𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒,

where 𝑋𝑖𝑡 includes a quartic in potential experience (age-education-6), and indicators for race and
ethnicity, marital status, nativity, education, industry and occupation, metro size, and Census division.
̂𝑖𝑡 = Φ(𝑋𝑖𝑡 𝛽̂), we then construct the inverse
Denoting the fitted probability from the probit as Φ
probability weights (IPW) as 𝑤
̂ 𝑖𝑡𝐼𝑃𝑊 =

𝑤𝑖𝑡𝐴𝑆𝐸𝐶
⁄ ̂ , where 𝑤𝑖𝑡𝐴𝑆𝐸𝐶 is the ASEC supplement weight
Φ𝑖𝑡

constructed by the Census Bureau. We then use the IPW to rebalance the ASEC-DER linked sample for
the missing nonlink sample. Although in practice we implement this year-by-year, in Appendix Table 3
we present the probit coefficients for a model pooled across survey years in order to depict the
relationship between the demographics and the probability of a link. The table shows link status is
declining in potential experience (verified in marginal effects), and is lower for those individuals who are
non-white, unmarried, foreign-born (both Hispanic and non-Hispanic), female, less educated, and residing
in large metro areas.

A-9

Appendix Table 3: Probit Estimates of the Probability of an ASEC-DER
Link
VARIABLES
Potential Experience
Potential Experience 2
Potential Experience3
Potential Experience4
Black, Non-Hispanic
Asian, Non-Hispanic
Other Race, Non-Hispanic
Hispanic
Married-Spouse Present
Married-Spouse Absent
Foreign-born Citizen
Foreign-born Non-Citizen
Foreign-born Hispanic
Female
Less than 9 years schooling
10 years of schooling
11 years of schooling
12 years of schooling, no diploma
GED
High School Graduate
Some College
Associates Degree
Bachelors Degree
Masters Degree
Professional Degree
Doctorate

-0.0285***
(0.00372)
0.00182***
(0.000316)
-4.23e-05***
(1.02e-05)
3.22e-07***
(1.10e-07)
-0.154***
(0.00847)
-0.203***
(0.0134)
-0.172***
(0.0134)
-0.0726***
(0.00961)
0.167***
(0.00659)
0.0724***
(0.00828)
0.0814***
(0.0131)
-0.479***
(0.0117)
-0.445***
(0.0155)
-0.0114**
(0.00551)
0.0386**
(0.0189)
0.172***
(0.0197)
0.250***
(0.0185)
0.181***
(0.0215)
0.302***
(0.0188)
0.235***
(0.0124)
0.323***
(0.0133)
0.367***
(0.0145)
0.307***
(0.0139)
0.326***
(0.0163)
0.313***
(0.0240)
0.281***
(0.0252)

A-10

Metro size < 100k
Metro size 100k-249k
Metro size 250k-499k
Metro size 500k-999k
Metro size 1m-2.49m
Metro size 2.5m-4.99m
Metro size >= 5m
Occupation-Professional
Occupation-Services
Occupation-Sales
Occupation-Office Support
Occupation-Farm
Occupation-Construction
Occupation-Installer
Occupation-Production
Occupation-Transportation
Occupation-Federal (non-USPS)
Occupation-Federal (USPS)
Occupation-State
Occupation-Local
Industry-Agriculture
Industry-Mining
Industry-Construction
Industry-Wholesale & Retail Trade
Industry-Transportation & Utilities
Industry-Information
Industry-Finance
Industry-Professional

0.180***
(0.0112)
0.209***
(0.0110)
0.184***
(0.0113)
0.176***
(0.0115)
0.158***
(0.0105)
0.167***
(0.0107)
0.0644***
(0.0114)
0.0296***
(0.00929)
-0.124***
(0.00966)
-0.177***
(0.0108)
0.0672***
(0.0101)
0.188***
(0.0285)
-0.157***
(0.0142)
0.0451***
(0.0148)
0.0183
(0.0128)
-0.00139
(0.0128)
0.0179
(0.0172)
0.125***
(0.0375)
0.159***
(0.0137)
0.140***
(0.0109)
-0.734***
(0.0216)
0.123***
(0.0326)
-0.379***
(0.0135)
-0.0443***
(0.0108)
-0.110***
(0.0139)
-0.0300
(0.0184)
-0.119***
(0.0122)
-0.214***
(0.0103)

A-11

Industry-Education
Industry-Arts
Industry-Other
Census Division-Mid Atlantic
Census Division-East North Central
Census Division-West North Central
Census Division-South Atlantic
Census Division-East South Central
Census Division-West South Central
Census Division-Mountain
Census Division-Pacific
Year-2006
Year-2007
Year-2008
Year-2009
Year-2010
Constant

Observations

-0.00972
(0.00988)
-0.189***
(0.0115)
-0.396***
(0.0124)
-0.0383***
(0.0119)
-0.0296***
(0.0110)
0.0839***
(0.0112)
-0.141***
(0.00990)
-0.112***
(0.0139)
-0.0797***
(0.0115)
-0.198***
(0.0107)
-0.250***
(0.0101)
-0.00129
(0.00821)
-0.0375***
(0.00815)
-0.0581***
(0.00812)
-0.0997***
(0.00810)
-0.0587***
(0.00829)
1.174***
(0.0246)
508,288

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic
Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.
A.5

Earnings are a Function of Response Status
In Figure 4 of the main text we present kernel density estimates of residuals estimated from log

DER earnings equations, separately by gender and response status. Specifically, the DER earnings
residuals are constructed from OLS regressions as
(A.2)

𝐷𝐸𝑅,𝑘
𝑘
𝜐̂
− 𝛿̂ − 𝑋𝑖 𝜋̂, 𝑗 = 𝑚𝑎𝑙𝑒, 𝑓𝑒𝑚𝑎𝑙𝑒; 𝑘 = 𝑟𝑒𝑠𝑝𝑜𝑛𝑑𝑒𝑛𝑡, 𝑛𝑜𝑛𝑟𝑒𝑠𝑝𝑜𝑛𝑑𝑒𝑛𝑡.
𝑖,𝑗 = 𝑌𝑖,𝑗

In Appendix Table 4, we provide an alternative way to present the pattern of residuals across the
distribution. The column NR-R shows differences in residuals between ASEC nonrespondents and
respondents at selected percentiles. For men and women, NR-R differences change from highly negative
to highly positive as earnings increase. In the left tail, we see positive selection into response,

A-12

Appendix Table 4: Summary Statistics of Residuals from 𝑙𝑛𝐸𝑎𝑟𝑛𝑖𝑛𝑔𝑠 𝐷𝐸𝑅 Regressions by Response Status and Gender

Statistic
1%
5%
10%
25%
50%
75%
90%
95%
99%
Mean
Variance
Obs

All Men
-3.20
-1.58
-0.95
-0.31
0.14
0.52
0.87
1.11
1.67
0.02
0.78
224,852

Men
Nonrespondents
-3.56
-1.88
-1.19
-0.40
0.12
0.55
0.93
1.19
1.88
-0.03
1.00
44,288

Women
Respondents
-3.09
-1.50
-0.89
-0.29
0.15
0.52
0.86
1.09
1.62
0.03
0.73
180,564

Difference
(NR-R)
-0.48
-0.38
-0.30
-0.12
-0.03
0.03
0.06
0.11
0.27
-0.06
0.27

All
Women
-3.36
-1.79
-1.11
-0.32
0.18
0.54
0.86
1.06
1.52
-0.01
0.85
214,869

Nonrespondents
-3.50
-1.88
-1.21
-0.38
0.15
0.54
0.88
1.10
1.62
-0.04
0.93
39,616

Respondents
-3.32
-1.77
-1.09
-0.31
0.19
0.54
0.85
1.05
1.49
-0.002
0.83
175,253

Difference
(NR-R)
-0.18
-0.11
-0.12
-0.07
-0.03
0.00
0.03
0.05
0.13
-0.04
0.11

Percentiles, Mean, and Variance are unweighted.
Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement. Social Security Administration,
Detailed Earnings Record, 2005-2010

A-13

with ASEC nonrespondents having lower DER earnings residuals than respondents. In the middle of the
distribution, NR-R differences are close to zero, indicating little response bias. At the top of the
distribution, positive NR-R residual differences indicate negative selection into response.
A.6

Measurement Differences in the ASEC and DER
High rates of nonresponse among those with low earnings (conditional on covariates) may stem

from several reasons. Discussions with Census field representatives suggest that some ASEC participants
find it difficult to report annual earnings and income measures, despite attempts to help them produce
such information (e.g., prompts regarding the amount and frequency of typical paychecks). Substantial
effort may be required for many low-income household members to report earnings; these high effort
costs decrease response. Consistent with this explanation, Kassenboehmer and Schurer (2018) examine
paradata measuring the fraction of survey questions answered in an Australian household survey. The
authors conclude that nonresponse for income and other “difficult” questions results in part from
cognitive difficulties in answering such questions. They conclude that survey item-response rates vary
with cognitive abilities and are predictive of economic outcomes.2 An additional explanation offered by
persons knowledgeable about the ASEC is that high rates of nonresponse for earnings and other income
sources, particularly among low-wage women, may result in part from the (invalid) concern that reporting
such information to Census might place income support program eligibility at risk. Finally, it is worth
noting that some of the nonresponse in the left tail of the earning distribution might be associated with
off-the-books earnings. Workers likely to have off-the-book earnings, and thus lower DER earnings, may
also be less willing to answer ASEC earnings questions.
We briefly examine measurement differences between the ASEC and DER by following previous
work by Bollinger (1998) and using non-parametric kernel regression of the residuals from ASEC
earnings models on DER earnings models (the same models in Appendix Table 4). The results are
presented in Appendix Figure 5 using a log-earnings scale. As has been typically found in this literature,
we see the “common man” hypothesis supported: individuals with low earnings tend to over-report their
earnings, while individuals with high earnings tend to under-report. Since this analysis was conducted on
residuals, these are not associated with demographic characteristics such as education or race. The same
analysis was conducted for earnings levels (as opposed to log earnings) and for earnings absent controls
(i.e., without the initial DER/ASEC earnings and log earnings regressions). Qualitative results were
similar in both cases. We qualify this though by noting that the “common man” hypothesis hinges on the
administrative DER earnings being the “truth”; however, as noted above there could be some unreported

Kassenboehmer, Sonja C. and Stefanie Schurer, “Survey Item-Response Behavior as an Imperfect Proxy for
Unobserved Ability: Theory and Application,” IZA DP No. 11449, April 2018.
2

A-14

earnings in the DER, or possible measurement error in the DER (Kapteyn and Ypma 2007).

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

A.7

Whole ASEC Supplement Imputations
As depicted in Figure 1 of the main text, over 10 percent of households who participate in the

basic monthly CPS refuse to participate in the ASEC supplement in a typical year, and this rate has
increased since 2010. A non-participating household is then assigned ASEC values based on a “whole
impute” from a participating donor household. While these households are excluded from our main
analysis, we do observe DER earnings for the original nonrespondent household, plus their information
reported in the monthly CPS survey. However, we are unable to calculate an hourly wage measure or
construct full-time full-year subsamples because we lack information on weeks and hours worked among
supplement nonparticipants. Thus, we focus in this subsection on annual earnings.
Appendix Table 5 provides limited descriptive statistics of the sample of linked whole imputes,
where the variables chosen derive from the monthly survey data, and so are not part of the imputed ASEC
record, but represent response from the individual to whom DER income was linked. It is natural to
compare this group to the larger set of results shown in Table 1 of the main text and Appendix Table 1 in
the supplement. The whole imputes are slightly younger than linked item nonrespondents, are less likely
A-15

to be white and more likely to be Hispanic, more likely to be a woman, and less likely to be native born.
However, most of these differences are quantitatively small. One notable difference exists, and that is the
whole imputes have lower total DER earnings, $45,426, than linked nonrespondents at $50,796.
Appendix Table 5: Sample Averages for Linked Whole Imputes
Mean
Age
41.1
Race
White
65.2
Black
13.6
Asian
5.5
Other
1.9
Hispanic
13.8
Gender
Female
47.4
Education (years)
13.5
Marital Status
Married, Spouse Present
55.2
Married, Spouse Absent
16.9
Never Married
28.0
Nativity
Native
83.3
Foreign Born, U.S. Citizen
7.4
Foreign Born, Not a U.S. Citizen
9.3
Proxy
50.9
DER Total Earnings ($2010)
45,426
Observations

40,235

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic
Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

In Appendix Figure 6, we show how whole supplement nonresponse differs across the joint DER
earnings distribution among men and women, similar to the approach seen in Figure 2 of the main text for
item nonresponse. Note that the sample here differs from that seen elsewhere in the paper. The figure
shows a clear-cut pattern. Supplement nonresponse is highest among those with low earnings, with a
gradual and modest decline as earnings increase. In short, there is positive selection into supplement
participation, with a disproportionate share of low earnings workers not participating. While the figure
has similarities to the other figures presented here, the U-shape is far less evident. We observe little
difference in supplement nonresponse between men and women. Although supplement non-participation
is only about one-half the rate of item nonresponse for earnings, positive selection into supplement
participation likely leads to a modest understatement of family poverty (Hokayem et al. 2015). Recent
work by Bee, Gathright, and Meyer (2015) find a similar pattern for CPS refusals. They use 1040 returns
matched to respondents’ addresses to examine income characteristics of households who refuse to

A-16

participate in the entire survey (both the monthly and supplement). Our results for whole imputes seem to
be consistent with their results, suggesting that individuals who refuse to respond to the supplement are
more similar to those who refuse to participate in the survey (i.e., unit nonresponse) than those who
participate but refuse the earnings question (i.e., item nonresponse).

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic
Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

A.8

Longitudinally-Matched ASEC
The rotation group structure of the ASEC permits up to 50 percent of sample individuals to be

followed across adjacent ASEC years (the CHIP oversample in the ASEC is not eligible for longitudinal
matching). Following the recommended Census procedure, we perform an initial match of individuals on
the basis of five variables: month in sample (months 1-4 for year 1, months 5-8 for year 2); gender; line
number (unique person identifier); household identifier; and household number. We then cross check the
initial match on three additional criteria: race, state of residence, and age of the individual. If the race or
state of residence of the person changed we delete that observation, and if the age of the person falls or if
it increases by more than two years (owing to the staggered timing of the initial and final interviews), then
we delete those observations on the assumption that they were bad matches. We note that we drop movers
A-17

because the CPS is an address-based sample frame and not household-based, and thus it does not follow
movers over time. Because of this it is possible that the two-year matched panels may not be
representative of the underlying cross-sectional distribution of participants.
Appendix Table 6 provides means for the sample of individuals followed across years in the ASEC
who are also linked to the DER. This subset is most comparable to column 4 of Table 1 (i.e., the linked
sample) and the data used for much of the prior analysis. Linking the ASEC panel to the DER drops the
nonresponse rate even further (similar to the full sample) to be 16.9 percent and 18.2 percent in years 1 and
2 compared to 20.1 percent for our primary ASEC sample (Table 1, column 4). As noted in other papers,
the panel sample is older (average age 43.1 compared to 41.7), more likely to be white (75.6 percent
compared to 71.8 percent), more likely to be married with spouse present (68.1 percent compared to 58.9
percent), more likely to be native born (89.1 percent compared to 87.6 percent), and with most of the fewer
foreign-born concentrated on the foreign born non-citizens (4.9 percent compared to 6.1 percent).
Appendix Table 6: Sample Averages for Panel Sample
Mean
43.08
Age
Race
75.6
White
8.2
Black
4.17
Asian
2.53
Other Race
9.54
Hispanic
48.2
Female
14.01
Education
Marital Status
Married Spouse Present
Married Spouse Absent
Never Married
Nativity
Native Born
Foreign Born Citizen
Foreign Born non-Citizen
Response Rates
Nonresponse Year 1
Nonresponse Year 2
Observations

68.1
14.7
17.2
89.1
5.97
4.92
16.9
18.2
103,852

Averages are for year 1 characteristics and are unweighted.
Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic
Supplement. Social Security Administration, Detailed Earnings Record, 2005-2010.

A-18

A.9

Alternative Measures of Inequality
In Figures 9 and 10 of the main text we present trends in earnings inequality as measured by the

Gini coefficient and the 90-10 percentile ratio. In Appendix Figures 7-9 we decompose the 90-10
percentile ratio to focus on upper tail (90-50 in Appendix Figure 7) and lower-tail (50-10 in Appendix
Figure 8) inequality. Comparing the two figures makes clear that there are measurement differences
between the ASEC and DER, especially at the upper tail of the distribution (as seen previously also in
Appendix Figure 5). The first panel of Appendix Figure 7 shows much wider gaps in the top half of the
distribution between the full samples of DER and ASEC compared to respondent-only DER and ASEC
samples, respectively, than what we see in the lower-tail of the distribution in Appendix Figure 8. This is
underscored further in Appendix Figure 9 depicting trends in the share of earnings accruing to the top 1
percent of workers, the most prominent inequality measure presented from tax data (Piketty and Saez
2003). Here we see clear-cut differences between the ASEC and the DER. Among all workers, there is a
modest downward trend in the top 1 percent share in the ASEC, and little overall trend in the DER, but
with an increase in the share in 2010. Averaged over all years, the DER measure of the top centile is 2.9
percentage points higher than the ASEC measure, or 30 percent higher than the ASEC mean share of 9.6
percent. This gap grew over time, with the DER-ASEC gap averaging 2.7 percentage points in the first
half of the sample period, and 3.1 percentage points in the second half. As with the Gini in the main text,
Panel B shows that nonresponse accounts for one-third to one-half of the gap between the ASEC and the
DER.

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

A-19

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

Sources: U.S. Census Bureau, Current Population Survey, 2006-2011 Annual Social and Economic Supplement.
Social Security Administration, Detailed Earnings Record, 2005-2010.

A-20

