Chapter 71

ECONOMETRIC EVALUATION OF SOCIAL PROGRAMS,
PART II: USING THE MARGINAL TREATMENT EFFECT
TO ORGANIZE ALTERNATIVE ECONOMETRIC ESTIMATORS
TO EVALUATE SOCIAL PROGRAMS, AND TO FORECAST
THEIR EFFECTS IN NEW ENVIRONMENTS*
JAMES J. HECKMAN
The University of Chicago, USA
American Bar Foundation, USA
University College Dublin, Ireland
EDWARD J. VYTLACIL
Columbia University, USA

Contents
Abstract
Keywords
1. Introduction
2. The basic principles underlying the identification of the major econometric evaluation estimators
2.1. A prototypical policy evaluation problem

3. An index model of choice and treatment effects: Definitions and unifying
principles
3.1. Definitions of treatment effects in the two outcome model
3.2. Policy relevant treatment parameters

4. Instrumental variables
4.1. IV in choice models
4.2. Instrumental variables and local instrumental variables
4.2.1. Conditions on the MTE that justify the application of conventional instrumental variables

4878
4878
4879
4880
4890
4894
4897
4903
4907
4913
4914
4915

* This research was supported by NSF: 97-09-873, 00-99195, and SES-0241858 and NICHD: R01-

HD32058-03. We have benefited from comments received from Thierry Magnac and Costas Meghir at the
Handbook of Econometrics Conference, December 1998; general comments at the 2001 Chicago Conference; and specific and very helpful comments from Jaap Abbring, Thomas Amorde, Hugo Garduño, Seong
Moon, Rodrigo Pinto, Heleno Pioner, Jean-Marc Robin, Peter Saveleyev, G. Adam Savvas, Daniel Schmierer,
John Trujillo, Semih Tumen, Sergio Urzua and Jordan Weil. Parts of this document draw on joint work with
Sergio Urzua.
Handbook of Econometrics, Volume 6B
Copyright © 2007 Elsevier B.V. All rights reserved
DOI: 10.1016/S1573-4412(07)06071-0

4876

J.J. Heckman and E.J. Vytlacil
4.2.2. Estimating the MTE using local instrumental variables
4.3. What does linear IV estimate?
4.3.1. Further properties of the IV weights
4.3.2. Constructing the weights from data
4.3.3. Discrete instruments
4.3.4. Identifying margins of choice associated with each instrument and unifying diverse instruments within a common framework
4.3.5. Yitzhaki’s derivation of the weights
4.4. The central role of the propensity score
4.5. Monotonicity, uniformity and conditional instruments
4.6. Treatment effects vs. policy effects
4.7. Some examples of weights in the generalized Roy model and the extended Roy model
4.7.1. Further examples within the extended Roy model
4.7.2. Discrete instruments and weights for LATE
4.7.3. Continuous instruments
4.8. Comparing selection and IV models
4.9. Empirical examples: “The effect” of high school graduation on wages and using IV
to estimate “the effect” of the GED
4.9.1. Empirical example based on LATE: Using IV to estimate “the effect” of
high school graduation on wages
4.9.2. Effect of the GED on wages
4.10. Monotonicity, uniformity, nonseparability, independence and policy invariance: The
limits of instrumental variables
4.10.1. Implications of nonseparability
4.10.2. Implications of dependence
4.10.3. The limits of instrumental variable estimators

5. Regression discontinuity estimators and LATE
6. Policy evaluation, out-of-sample policy forecasting, forecasting the effects of new policies and structural models based on the MTE
6.1. Econometric cost benefit analysis based on the MTE
6.2. Constructing the PRTE in new environments
6.2.1. Constructing weights for new policies in a common environment
6.2.2. Forecasting the effects of policies in new environments
6.2.3. A comparison of three approaches to policy evaluation

7. Extension of MTE to the analysis of more than two treatments and associated outcomes
7.1. Background for our analysis of the ordered choice model
7.2. Analysis of an ordered choice model
7.2.1. The policy relevant treatment effect for the ordered choice model
7.2.2. What do instruments identify in the ordered choice model?
7.2.3. Some theoretical examples of the weights in the ordered choice model
7.2.4. Some numerical examples of the IV weights
7.3. Extension to multiple treatments that are unordered

4917
4920
4924
4925
4925
4926
4927
4928
4928
4930
4931
4934
4934
4939
4950
4953
4953
4953
4959
4961
4963
4964
4964
4967
4967
4971
4972
4976
4976
4978
4978
4980
4984
4984
4986
4988
4998

Ch. 71:

Econometric Evaluation of Social Programs, Part II
7.3.1.
7.3.2.
7.3.3.
7.3.4.

Model and assumptions
Definition of treatment effects and treatment parameters
Heterogeneity in treatment effects
LIV and nonparametric Wald estimands for one choice vs. the best alternative

7.3.5. Identification: Effect of best option in K versus best option not in K
7.3.6. Identification: Effect of one fixed choice versus another
7.3.7. Summarizing the results for the unordered model
7.4. Continuous treatment

8. Matching
8.1. Matching assumption (M-1) implies a flat MTE
8.2. Matching and MTE using mean independence conditions
8.3. Implementing the method of matching
8.3.1. Comparing matching and control functions approaches
8.4. Comparing matching and classical control function methods for a generalized Roy
model
8.5. The informational requirements of matching and the bias when they are not satisfied
8.5.1. The economist uses the minimal relevant information: σ (IR ) ⊆ σ (IE )
8.5.2. The economist does not use all of the minimal relevant information
8.5.3. Adding information to the econometrician’s information set IE : Using
some but not all the information from the minimal relevant information
set IR
8.5.4. Adding information to the econometrician’s information set: Using proxies for the relevant information
8.5.5. The case of a discrete outcome variable
8.5.6. On the use of model selection criteria to choose matching variables

9. Randomized evaluations
9.1.
9.2.
9.3.
9.4.
9.5.
9.6.

Randomization as an instrumental variable
What does randomization identify?
Randomization bias
Compliance
The dynamics of dropout and program participation
Evidence on randomization bias

9.7. Evidence on dropping out and substitution bias

10. Bounding and sensitivity analysis
10.1. Outcome is bounded
10.2. Latent index model: Roy model
10.3. Bounds that exploit an instrument
10.3.1. Instrumental variables: Mean independence condition
10.3.2. Instrumental variables: Statistical independence condition
10.3.3. Instrumental variables: Nonparametric selection model/LATE conditions
10.4. Combining comparative advantage and instrumental variables

11. Control functions, replacement functions, and proxy variables
12. Summary

4877

5002
5006
5009
5010
5015
5017
5020
5021
5026
5029
5031
5033
5036
5042
5043
5046
5048

5048
5052
5053
5056
5057
5060
5063
5066
5067
5068
5076
5078
5081
5083
5084
5086
5086
5088
5089
5091
5094
5098

4878

J.J. Heckman and E.J. Vytlacil

Appendix A: Relationships among parameters using the index structure
Appendix B: Relaxing additive separability and independence
Appendix C: Derivation of PRTE and implications of noninvariance for PRTE
Appendix D: Deriving the IV weights on MTE
D.1. Yitzhaki’s Theorem and the IV weights [Yitzhaki (1989)]
D.2. Relationship of our weights to the Yitzhaki weights

Appendix E: Derivation of the weights for the mixture of normals example
Appendix F: Local instrumental variables for the random coefficient model
Appendix G: Generalized ordered choice model with stochastic thresholds
Appendix H: Derivation of PRTE weights for the ordered choice model
Appendix I: Derivation of the weights for IV in the ordered choice model
Appendix J: Proof of Theorem 6
Appendix K: Flat MTE within a general nonseparable matching framework
Appendix L: The relationship between exclusion conditions in IV and exclusion conditions in matching
Appendix M: Selection formulae for the matching examples
References

5098
5102
5111
5112
5114
5116
5117
5120
5122
5124
5125
5127
5129
5130
5133
5134

Abstract
This chapter uses the marginal treatment effect (MTE) to unify and organize the econometric literature on the evaluation of social programs. The marginal treatment effect
is a choice-theoretic parameter that can be interpreted as a willingness to pay parameter for persons at a margin of indifference between participating in an activity or not.
All of the conventional treatment parameters as well as the more economically motivated treatment effects can be generated from a baseline marginal treatment effect. All
of the estimation methods used in the applied evaluation literature, such as matching,
instrumental variables, regression discontinuity methods, selection and control function
methods, make assumptions about the marginal treatment effect which we exposit. Models for multiple outcomes are developed. Empirical examples of the leading methods are
presented. Methods are presented for bounding treatment effects in partially identified
models, when the marginal treatment effect is known only over a limited support. We
show how to use the marginal treatment in econometric cost benefit analysis, in defining
limits of policy experiments, in constructing the average marginal treatment effect, and
in forecasting the effects of programs in new environments.
Keywords
marginal treatment effect, policy evaluation, instrumental variables, forecasting new
policies, econometric cost benefit analysis, regression discontinuity, matching, bounds
JEL classification: C10, C13, C50

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4879

1. Introduction
This part of our contribution to this Handbook reviews and extends the econometric literature on the evaluation of social policy. We organize our discussion around
choice-theoretic models for objective and subjective outcomes of the sort discussed in
Chapter 70. Specifically, we organize our discussion of the literature around the concept of the marginal treatment effect (MTE) that was introduced in Chapter 70. Using
the marginal treatment effect, we define a variety of treatment effects and show how
they can be generated by a single economic functional, the MTE. We then show what
various econometric methods assume about the MTE.
In this part, we focus exclusively on microeconomic partial equilibrium evaluation
methods, deferring analysis of general equilibrium issues to Abbring and Heckman
(Chapter 72). Thus throughout this chapter, except when we discuss randomized evaluation of social programs, we assume that potential outcomes are not affected by interventions but choices among the potential outcomes are affected. Thus, we invoke
policy invariance assumptions (PI-3) and (PI-4) of Chapter 70. We also focus primarily on mean responses, leaving analysis of distributions of responses for Abbring and
Heckman, Chapter 72.
The plan of this chapter is as follows. In Section 2, we present some basic principles
that underlie conventional econometric evaluation estimators. In Section 3, we define
the marginal treatment effect in a two potential outcome model that is a semiparametric version of the generalized Roy model. We then show how treatment parameters can
be generated as weighted averages of the MTE. We carefully distinguish the definition of parameters from issues of identification. Section 4 considers how instrumental
variable methods that supplement the classical instrumental variable assumptions of
econometrics can be used to identify treatment parameters. We discuss the crucial role
of monotonicity assumptions in the recent IV literature.
They impart an asymmetry to the admissible forms of agent heterogeneity. Outcomes
are permitted to be heterogeneous in a general way but responses of choices to external
inputs are not. When heterogeneity in choices and outcomes is allowed, the IV enterprise breaks down. Treatment parameters can still be defined but IV does not identify
them.
Section 5 extends our analysis to consider regression discontinuity estimators introduced in Campbell (1969) and adapted to modern econometrics in Hahn, Todd and Van
der Klaauw (2001). We interpret the regression discontinuity estimator within the MTE
framework, as a special type of IV estimator. In Section 6, we show how the output of the
IV analysis of Section 4 can be used to extend parameters identified in one population to
other populations and to forecast the effects of new programs. These are questions P-2
and P-3 introduced in Chapter 70. Sections 2–5 focus solely on the problem of internal
validity, which is the problem defined as P-1. We also develop a cost benefit analysis
based on the MTE and we analyze marginal policy changes. In Section 7, we generalize
the analysis of instrumental variables to consider models with multiple outcomes. We

4880

J.J. Heckman and E.J. Vytlacil

develop both unordered and ordered choice models linking them to an explicit choicetheoretic literature.
In Section 8, we consider matching as a special case of our framework. Matching
applied to estimating conditional means is a version of nonparametric least squares. It
assumes that marginal and average returns are the same whereas our general framework
allows us to distinguish marginal from average returns and to identify both. Matching
is more robust than IV to violations of conventional monotonicity assumptions but the
price for this robustness is steep in terms of its economic content. In Section 9, we
develop randomization as an instrumental variable. We consider problems with compliance induced by agent self-selection decisions. In Section 10, we consider how to
bound the various treatment parameters when models are not identified. Section 11 develops alternative methods for controlling for selection: control functions, replacement
functions and proxy variables. Section 12 concludes.

2. The basic principles underlying the identification of the major econometric
evaluation estimators
In this section, we review the main principles underlying the major evaluation estimators
used in the econometric literature. We assume two potential outcomes (Y0 , Y1 ). Models
for multiple outcomes are developed in later sections of this chapter. As in Chapter 70,
D = 1 if Y1 is observed, and D = 0 corresponds to Y0 being observed. The observed
objective outcome is
Y = DY1 + (1 − D)Y0 .

(2.1)

To briefly recapitulate the lessons of Chapter 70, we distinguish two distinct econometric problems. For simplicity, we focus our discussion on identification of objective
outcomes. A parallel analysis can be made for subjective outcomes.
The evaluation problem arises because for each person we observe either Y0 or Y1
but not both. Thus, in general, it is not possible to identify the individual level treatment
effect Y1 − Y0 for any person. The typical solution to this problem is to reformulate
the problem at the population level rather than at the individual level and to identify
certain mean outcomes or quantile outcomes or various distributions of outcomes as
described in Chapter 70. For example, a common approach is to focus attention on
average treatment effects, such as ATE = E(Y1 − Y0 ).
If treatment is assigned or chosen on the basis of potential outcomes, so

⊥ D,
(Y0 , Y1 ) ⊥
where ⊥

⊥ denotes “is not independent” and “ ⊥
⊥ ” denotes independent, we encounter
the problem of selection bias. Suppose that we observe people in each treatment
state D = 0 and D = 1. If Yj ⊥

⊥ D, then the observed Yj will be selectively different from randomly assigned Yj , j = 0, 1. Thus E(Y0 | D = 0) = E(Y0 ) and
E(Y1 | D = 1) = E(Y1 ). Using unadjusted data to construct E(Y1 − Y0 ) will produce

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4881

selection bias:
E(Y1 | D = 1) − E(Y0 | D = 0) = E(Y1 − Y0 ).
The selection problem is a key aspect of the problem of evaluating social programs.
Many methods have been proposed to solve both problems. This chapter unifies these
methods using the concept of the marginal treatment effect (MTE) introduced in
Chapter 70 of this Handbook.
The method with the greatest intuitive appeal, which is sometimes called the “gold
standard” in evaluation analysis, is the method of random assignment. Nonexperimental
methods can be organized by how they attempt to approximate what can be obtained by
an ideal random assignment. If treatment is chosen at random with respect to (Y0 , Y1 ),
or if treatments are randomly assigned and there is full compliance with the treatment
assignment,
⊥ D.
(R-1) (Y0 , Y1 ) ⊥
It is useful to distinguish several cases where (R-1) will be satisfied. The first is that
agents (decision makers whose choices are being investigated) pick outcomes that are
random with respect to (Y0 , Y1 ). Thus agents may not know (Y0 , Y1 ) at the time they
make their choices to participate in treatment or at least do not act on (Y0 , Y1 ), so that
Pr(D = 1 | X, Y0 , Y1 ) = Pr(D = 1 | X) for all X. Matching assumes a version of (R-1)
⊥ D | X.
conditional on matching variables X: (Y0 , Y1 ) ⊥
A second case arises when individuals are randomly assigned to treatment status even
if they would choose to self-select into no-treatment status, and they comply with the
randomization protocols. Let ξ be randomized assignment status. With full compliance,
ξ = 1 implies that Y1 is observed and ξ = 0 implies that Y0 is observed. Then, under
randomized assignment,
⊥ ξ,
(R-2) (Y0 , Y1 ) ⊥

⊥ D. If randomization is performed coneven if in a regime of self-selection, (Y0 , Y1 ) ⊥
⊥ ξ | X.
ditional on X, we obtain (Y0 , Y1 ) ⊥
Let A denote actual treatment status. If the randomization has full compliance among
participants, ξ = 1 ⇒ A = 1; ξ = 0 ⇒ A = 0. This is entirely consistent with a
regime in which a person would choose D = 1 in the absence of randomization, but
would have no treatment (A = 0) if suitably randomized, even though the agent might
desire treatment.
If treatment status is chosen by self-selection, D = 1 ⇒ A = 1 and D = 0 ⇒
A = 0. If there is imperfect compliance with randomization, ξ = 1  A = 1 because
of agent choices. In general, A = ξ D so that A = 1 only if ξ = 1 and D = 1. This
assumes that persons randomized out of the program cannot participate in it. If treatment
status is randomly assigned, either through randomization or randomized self-selection,
⊥ A.
(R-3) (Y0 , Y1 ) ⊥

4882

J.J. Heckman and E.J. Vytlacil

This version of randomization can also be defined conditional on X. Under (R-1), (R-2)
or (R-3), the average treatment effect (ATE) is the same as the marginal treatment effect
and the parameters treatment on the treated (TT) and treatment on the untreated (TUT)
as defined in Chapter 70:
TT = MTE = TUT = ATE = E(Y1 − Y0 ) = E(Y1 ) − E(Y0 ).
Observe that even with random assignment of treatment status and full compliance,
we cannot, in general, identify the distribution of the treatment effects (Y1 − Y0 ), although we can identify the marginal distributions F1 (Y1 | A = 1, X = x) = F1 (Y1 |
X = x) and F0 (Y0 | A = 0, X = x) = F0 (Y0 | X = x). One special assumption,
common in the conventional econometrics literature, is that Y1 − Y0 = (x), a constant given x. Since (x) can be identified from E(Y1 | A = 1, X = x) − E(Y0 |
A = 0, X = x) because A is allocated by randomization, the analyst can identify
the joint distribution of (Y0 , Y1 ).1 However, this approach assumes that (Y0 , Y1 ) have
the same distribution up to a parameter  (Y0 and Y1 are perfectly dependent). One
can make other assumptions about the dependence across ranks from perfect positive
or negative ranking to independence.2 In general, the joint distribution of (Y0 , Y1 ) or
of (Y1 − Y0 ) is not identified unless the analyst can pin down the dependence across
(Y0 , Y1 ). Thus, even with data from a randomized trial one cannot, without further assumptions, identify the proportion of people who benefit from treatment in the sense of
gross gain (Pr(Y1  Y0 )). This problem plagues all evaluation methods. Abbring and
Heckman discuss methods for identifying joint distributions of outcomes in Chapter 72.
Assumption (R-1) is very strong. In many cases, it is thought that there is selection
bias with respect to Y0 , Y1 , so persons who select into status 1 or 0 are selectively
different from randomly sampled persons in the population.
The assumption most commonly made to circumvent problems with (R-1) is that
even though D is not random with respect to potential outcomes, the analyst has access
to control variables X that effectively produce a randomization of D with respect to
(Y0 , Y1 ) given X. This is the method of matching, which is based on the following
conditional independence assumption:
⊥ D | X.
(M-1) (Y0 , Y1 ) ⊥
Conditioning on X randomizes D with respect to (Y0 , Y1 ). (M-1) assumes that any
selective sampling of (Y0 , Y1 ) can be adjusted by conditioning on observed variables.
(R-1) and (M-1) are different assumptions and neither implies the other. In a linear
equations model, assumption (M-1) that D is independent from (Y0 , Y1 ) given X justifies application of least squares on D to eliminate selection bias in mean outcome

1 Heckman (1992), Heckman, Smith and Clements (1997).
2 Heckman, Smith and Clements (1997).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4883

parameters. For means, matching is just nonparametric regression.3 In order to be able
to compare X-comparable people, we must assume
(M-2) 0 < Pr(D = 1 | X = x) < 1.
Assumptions (M-1) and (M-2) justify matching. Assumption (M-2) is required for any
evaluation estimator that compares treated and untreated persons. It is produced by
random assignment if the randomization is conducted for all X = x and there is full
compliance.
Observe that from (M-1) and (M-2), it is possible to identify F1 (Y1 | X = x) from
the observed data F1 (Y1 | D = 1, X = x) since we observe the left-hand side of
F1 (Y1 | D = 1, X = x) = F1 (Y1 | X = x)
= F1 (Y1 | D = 0, X = x).
The first equality is a consequence of conditional independence assumption (M-1). The
second equality comes from (M-1) and (M-2). By a similar argument, we observe the
left-hand side of
F0 (Y0 | D = 0, X = x) = F0 (Y0 | X = x)
= F0 (Y0 | D = 1, X = x),
and the equalities are a consequence of (M-1) and (M-2). Since the pair of outcomes
(Y0 , Y1 ) is not identified for anyone, as in the case of data from randomized trials, the
joint distributions of (Y0 , Y1 ) given X or of Y1 − Y0 given X are not identified without
further information.
From the data on Y1 given X and D = 1 and the data on Y0 given X and D = 0,
since E(Y1 | D = 1, X = x) = E(Y1 | X = x) = E(Y1 | D = 0, X = x) and
E(Y0 | D = 0, X = x) = E(Y0 | X = x) = E(Y0 | D = 1, X = x), we obtain
E(Y1 − Y0 | X = x) = E(Y1 − Y0 | D = 1, X = x)
= E(Y1 − Y0 | D = 0, X = x).
Effectively, we have a randomization for the subset of the support of X satisfying (M-2).
At values of X that fail to satisfy (M-2), there is no variation in D given X. We can
define the residual variation in D not accounted for by X as
E(x) = D − E(D | X = x) = D − Pr(D = 1 | X = x).
If the variance of E(x) is zero, it is not possible to construct contrasts in outcomes by
treatment status for those X values and (M-2) is violated. To see the consequences of
this violation in a regression setting, use Y = Y0 + D(Y1 − Y0 ) and take conditional
3 See the discussion in Section 8. Barnow, Cain and Goldberger (1980) present one application of matching
in a regression setting.

4884

J.J. Heckman and E.J. Vytlacil

expectations, under (M-1), to obtain


E(Y | X, D) = E(Y0 | X) + D E(Y1 − Y0 | X) .4
If Var(E(x)) > 0 for all x in the support of X, one can use nonparametric least
squares to identify E(Y1 − Y0 | X = x) = ATE(x) by regressing Y on D and X.
The function identified from the coefficient on D is the average treatment effect.5 If
Var(E(x)) = 0, ATE(x) is not identified at that x value because there is no variation in
D that is not fully explained by X. A special case of matching is linear least squares
where we write
Y0 = Xα + U,

Y1 = Xα + β + U,

U0 = U1 = U and hence under (M-1),
E(Y | X, D) = Xα + Dβ + E(U | X).
If D is perfectly predictable by X, we cannot identify β because of a multicollinearity problem. (M-2) rules out perfect collinearity.6 Matching is a nonparametric version
of least squares that does not impose functional form assumptions on outcome equations, and that imposes support condition (M-2). However, matching does not assume
exogeneity of X.
Conventional econometric choice models make a distinction between variables that
appear in outcome equations (X) and variables that appear in choice equations (Z). The
same variables may be in (X) and (Z), but more typically there are some variables not
in common. For example, the instrumental variable estimator is based on variables that
are not in X but that are in Z. Matching makes no distinction between the X and the Z.7
It does not rely on exclusion restrictions. The conditioning variables used to achieve
conditional independence can in principle be a set of variables Q distinct from the X
variables (covariates for outcomes) or the Z variables (covariates for choices). We use X
solely to simplify the notation. The key identifying assumption is the assumed existence
of a random variable X with the properties satisfying (M-1) and (M-2).
Conditioning on a larger vector (X augmented with additional variables) or a smaller
vector (X with some components removed) may or may not produce suitably modified
4 This follows because E(Y | X, D) = E(Y | X, D) + DE(Y − Y | X, D), but from (M-1), E(Y |
0
1
0
0
X, D) = E(Y0 | X) and E(Y1 − Y0 | X, D) = E(Y1 − Y0 | X).
5 Under the conditional independence assumption (M-1), it is also the effect of treatment on the treated
E(Y1 − Y0 | X, D = 1).
6 Clearly (M-1) and (M-2) are sufficient but not necessary conditions. For the special case of OLS, as a consequence of the assumed linearity in the functional form of the estimating equation, we achieve identification
of β if Cov(X, U ) = 0, Cov(D, U ) = 0 and (D, X) are not perfectly collinear. Observe that (M-1) does not
imply that E(U | X) = 0. Thus, we can identify β but not necessarily α.
7 Heckman et al. (1998) distinguish X and Z in matching.They consider a case where conditioning on X
may lead to failure of (M-1) and (M-2) but conditioning on (X, Z) satisfies a suitably modified version of this
condition.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4885

versions of (M-1) and (M-2). Without invoking further assumptions, there is no objective principle for determining what conditioning variables produce (M-1).
Assumption (M-1) is strong. Many economists do not have enough faith in their data
to invoke it. Assumption (M-2) is testable and requires no act of faith. To justify (M-1),
it is necessary to appeal to the quality of the data.
Using economic theory can help guide the choice of an evaluation estimator. A crucial
distinction is the one between the information available to the analyst and the information available to the agent whose outcomes are being studied. Assumptions made about
these information sets drive the properties of econometric estimators. Analysts using
matching make strong informational assumptions in terms of the data available to them.
In fact, all econometric estimators make assumptions about the presence or absence of
informational asymmetries, and we exposit them in this chapter.
To analyze the informational assumptions invoked in matching, and other econometric evaluation strategies, it is helpful to introduce five distinct information sets and
establish some relationships among them.8 (1) An information set σ (IR ∗ ) with an associated random variable that satisfies conditional independence (M-1) is defined as a
relevant information set; (2) the minimal information set σ (IR ) with associated random
variable needed to satisfy conditional independence (M-1), the minimal relevant information set; (3) the information set σ (IA ) available to the agent at the time decisions
to participate are made; (4) the information available to the economist, σ (IE ∗ ); and
(5) the information σ (IE ) used by the economist in conducting an empirical analysis.
We will denote the random variables generated by these sets as IR ∗ , IR , IA , IE ∗ , and IE ,
respectively.9
D EFINITION 1. We say that σ (IR ∗ ) is a relevant information set if the information set
is generated by the random variable IR ∗ , possibly vector-valued, and satisfies condition (M-1), so that
(Y0 , Y1 ) ⊥
⊥ D | IR ∗ .
D EFINITION 2. We say that σ (IR ) is a minimal relevant information set if it is the
⊥ D | IR . The associated random
intersection of all sets σ (IR ∗ ) and satisfies (Y0 , Y1 ) ⊥
variable IR is a minimum amount of information that guarantees that condition (M-1)
is satisfied. There may be no such set.10

8 See the discussion in Barros (1987), Gerfin and Lechner (2002), and Heckman and Navarro (2004).
9 We start with a primitive probability space (Ω, σ, P ) with associated random variables I . We assume

minimal σ -algebras and assume that the random variables I are measurable with respect to these σ -algebras.
Obviously, strictly monotonic or affine transformations of the I preserve the information and can substitute
for the I .
10 Observe that the intersection of all sets σ (I ∗ ) may be empty and hence may not be characterized by a
R
(possibly vector-valued) random variable IR that guarantees (Y0 , Y1 ) ⊥
⊥ D | IR . If the information sets that
produce conditional independence are nested, then the intersection of all sets σ (IR ∗ ) producing conditional

4886

J.J. Heckman and E.J. Vytlacil

If we define a relevant information set as one that produces conditional independence,
it may not be unique. If the set σ (IR ∗ ) satisfies the conditional independence condition,
then the set σ (IR ∗ , Q) such that Q ⊥
⊥ (Y0 , Y1 ) | IR ∗ would also guarantee conditional
independence. For this reason, when possible, it is desirable to use the minimal relevant
information set.
D EFINITION 3. The agent’s information set, σ (IA ), is defined by the information IA
used by the agent when choosing among treatments. Accordingly, we call IA the agent’s
information.
By the agent we mean the person making the treatment decision, not necessarily the
person whose outcomes are being studied (e.g., the agent may be the parent; the person
being studied may be a child).
D EFINITION 4. The econometrician’s full information set, σ (IE ∗ ), is defined as all of
the information available to the econometrician, IE ∗ .
D EFINITION 5. The econometrician’s information set, σ (IE ), is defined by the information used by the econometrician when analyzing the agent’s choice of treatment, IE ,
in conducting an analysis.
For the case where a unique minimal relevant information set exists, only three restrictions are implied by the structure of these sets: σ (IR ) ⊆ σ (IR ∗ ), σ (IR ) ⊆ σ (IA ),
and σ (IE ) ⊆ σ (IE ∗ ).11 We have already discussed the first restriction. The second
restriction requires that the minimal relevant information set must be part of the information the agent uses when deciding which treatment to take or assign. It is the
information in σ (IA ) that gives rise to the selection problem.
The third restriction requires that the information used by the econometrician must
be part of the information that the econometrician observes. Aside from these orderings,
the econometrician’s information set may be different from the agent’s or the relevant
information set. The econometrician may know something the agent does not know,
for typically he is observing events after the decision is made. At the same time, there
may be private information known to the agent but not the econometrician. Assuming a minimal relevant information set exists, matching assumption (M-1) implies that
independence is well defined and has an associated random variable IR with the required property, although it
may not be unique (e.g., strictly monotonic transformations and affine transformations of IR also preserve the
property). In the more general case of nonnested information sets with the required property, it is possible that
no uniquely defined minimal relevant set exists. Among collections of nested sets that possess the required
property, there is a minimal set defined by intersection but there may be multiple minimal sets corresponding
to each collection.
11 This formulation assumes that the agent makes the treatment decision. The extension to the case where the
decision maker and the agent are distinct is straightforward. The requirement σ (IR ) ⊆ σ (IR ∗ ) is satisfied by
nested sets.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4887

σ (IR ) ⊆ σ (IE ), so that the econometrician uses at least the minimal relevant information set, but of course he or she may use more. However, using more information is not
guaranteed to produce a model with conditional independence property (M-1) satisfied
for the augmented model. Thus an analyst can “overdo” it. We present examples of the
consequences of the asymmetry in agent and analyst information sets in Section 8.
The possibility of asymmetry in information between the agent making participation
decisions and the observing economist creates the potential for a major identification
problem that is ruled out by assumption (M-1). The methods of control functions and
instrumental variables estimators (and closely related regression discontinuity design
methods) address this problem in different ways. Accounting for this possibility is a
more conservative approach to the selection problem than the one taken by advocates
of matching. Those advocates assume that they know the X that produces a relevant information set. Heckman and Navarro (2004) show the biases that can result in matching
when standard econometric model selection criteria are applied to pick the X that are
used to satisfy (M-1) and we summarize their analysis in Section 8. Conditional independence condition (M-1) cannot be tested without maintaining other assumptions.12
As noted in Chapter 70, choosing the appropriate conditioning variables is a problem
that plagues all econometric estimators.
The methods of control functions, replacement functions, proxy variables and instrumental variables recognize the possibility of asymmetry in information between
the agent being studied and the econometrician and further recognize that even after conditioning on X (variables in the outcome equation) and Z (variables affecting
treatment choices, which may include the X), analysts may fail to satisfy conditional
independence condition (M-1).13 These methods postulate the existence of some unobservables θ , which may be vector-valued, with the property that
⊥ D | X, Z, θ ,
(U-1) (Y0 , Y1 ) ⊥
but allow for the possibility that

⊥ D | X, Z.
(U-2) (Y0 , Y1 ) ⊥
In the event (U-2) holds, these approaches model the relationship of the unobservable
θ with (Y0 , Y1 ) and D in various ways. The content in the control function principle is
to specify the exact nature of the dependence on the relationship between observables
and unobservables in a nontrivial fashion that is consistent with economic theory. We
present examples of models that satisfy (U-1) but not (U-2) in Section 8.
12 We discuss the required “exogeneity” conditions in our discussion of matching in Section 8. Thus ran-

domization of assignment of treatment status might be used to test (M-1) but this requires that there be full
compliance and that the randomization be valid (no anticipation effects or general equilibrium effects). Abbring and Heckman (Chapter 72) discuss this case.
13 The term and concept of control function is due to Heckman and Robb (1985a, 1985b, 1986a, 1986b). See
Blundell and Powell (2003) who call the Heckman–Robb replacement functions control functions. A more
recent nomenclature is “control variate”. Matzkin (2007) (Chapter 73 in this Handbook) provides a comprehensive discussion of identification principles for these, and other, econometric estimators.

4888

J.J. Heckman and E.J. Vytlacil

The early literature focused on mean outcomes conditional on covariates [Heckman
and Robb (1985a, 1985b, 1986a, 1986b)] and assumes a weaker version of (U-1) based
on conditional mean independence rather than full conditional independence. More
recent work analyzes distributions of outcomes [e.g., Aakvik, Heckman and Vytlacil
(2005), Carneiro, Hansen and Heckman (2003)]. Abbring and Heckman review this
work in Chapter 72.
The normal Roy model discussed in Chapter 70 makes distributional assumptions
and identifies the joint distribution of outcomes. (Recall the discussion in Section 6.1
of Chapter 70.) A large literature surveyed in Chapter 73 (Matzkin) of this Handbook
makes alternative assumptions to satisfy (U-1) in nonparametric settings. Replacement
functions [Heckman and Robb (1985a)] are methods that proxy θ. They substitute
out for θ using observables.14 Aakvik, Heckman and Vytlacil (1999, 2005), Carneiro,
Hansen and Heckman (2001, 2003), Cunha, Heckman and Navarro (2005), and Cunha,
Heckman and Schennach (2006b, 2007) develop methods that integrate out θ from
the model assuming θ ⊥
⊥ (X, Z), or invoking weaker mean independence assumptions, and assuming access to proxy measurements for θ. They also consider methods
for estimating the distributions of treatment effects. These methods are discussed in
Chapter 72.
The normal selection model discussed in Section 6.1 of Chapter 70 produces partial
identification of a generalized Roy model and full identification of a Roy model under
separability and normality. It models the conditional expectation of U0 and U1 given
X, Z, and D. In terms of (U-1), it models the conditional mean dependence of Y0 , Y1
on D and θ given X and Z. Powell (1994) and Chapter 73 (Matzkin) of this Handbook
survey methods for identifying semiparametric versions of these models. Appendix B
of Chapter 70 presents a prototypical identification proof for a general selection model
that implements (U-1) by estimating the distribution of θ , assuming θ ⊥
⊥ (X, Z), and
invoking support conditions on (X, Z).
Central to both the selection approach and the instrumental variable approach for a
model with heterogenous responses is the probability of selection. Let Z denote variables in the choice equation. Fixing Z at different values (denoted z), we define D(z)
as an indicator function that is “1” when treatment is selected at the fixed value of z and
that is “0” otherwise. In terms of the separable index model introduced in Chapter 70,
for a fixed value of z,


D(z) = 1 μD (z)  V ,
where Z ⊥
⊥ V | X. Thus fixing Z = z, values of z do not affect the realizations of V for
any value of X. An alternative way of representing the independence between Z and V
given X, due to Imbens and Angrist (1994), writes that D(z) ⊥
⊥ Z | X for all z ∈ Z,

14 This is the “control variate” of Blundell and Powell (2003). Heckman and Robb (1985a) and Olley and

Pakes (1996) use a similar idea. Chapter 73 (Matzkin) of this Handbook discusses replacement functions.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4889

where Z is the support of Z. The Imbens–Angrist independence condition for IV is


D(z) z∈Z ⊥
⊥ Z | X.
Thus the probabilities that D(z) = 1, z ∈ Z, are independent of Z.
The method of instrumental variables (IV) postulates that
⊥ Z | X (Independence).
(IV-1) (Y0 , Y1 , {D(z)}z∈Z ) ⊥
One consequence of this assumption is that E(D | Z) = P (Z), the propensity score, is
⊥ P (Z) | X. So are all other
random with respect to potential outcomes. Thus (Y0 , Y1 ) ⊥
functions of Z given X. The method of instrumental variables also assumes that
(IV-2) E(D | X, Z) = P (X, Z) is a nondegenerate function of Z given X (Rank
condition).
Alternatively, we can write that Var(E(D | X, Z)) = Var(E(D | X)).
Comparing (IV-1) to (M-1), in the method of instrumental variables, Z is independent
of (Y0 , Y1 ) given X whereas in matching, D is independent of (Y0 , Y1 ) given X. So
in (IV-1), Z plays the role of D in matching condition (M-1). Comparing (IV-2) with
(M-2), in the method of IV, the choice probability Pr(D = 1 | X, Z) is assumed to vary
conditional on X whereas in matching, D varies conditional on X. Unlike the method
of control functions, no explicit model of the relationship between D and (Y0 , Y1 ) is
required in applying IV. We exposit the implicit model of the relationship between D
and (Y0 , Y1 ) used in instrumental variables in this chapter.
(IV-2) is a rank condition and can be empirically verified. (IV-1) is not testable as
it involves assumptions about counterfactuals. In a conventional common coefficient
regression model
Y = α + βD + U,
where β is a constant and where we allow for Cov(D, U ) = 0, (IV-1) and (IV-2)
identify β.15 When β varies in the population and is correlated with D, additional
assumptions must be invoked for IV to identify interpretable parameters. We discuss
these conditions in Section 4 of this chapter, drawing on and extending the analysis of Heckman and Vytlacil (1999, 2001b, 2005) and Heckman, Urzua and Vytlacil
(2006).
Assumptions (IV-1) and (IV-2), with additional assumptions in the case where β
varies in the population which we discuss in this chapter, can be used to identify mean
treatment parameters. Replacing Y1 with 1(Y1  t) and Y0 with 1(Y0  t), where t is
a constant, the IV approach allows us to identify marginal distributions F1 (y1 | X) or
F0 (y0 | X).
In matching, the variation in D that arises after conditioning on X provides the source
of randomness that switches people across treatment status. Nature is assumed to pro15 β = Cov(Z,Y ) .
Cov(Z,D)

4890

J.J. Heckman and E.J. Vytlacil

vide an experimental manipulation conditional on X that replaces the randomization
assumed in (R-1)–(R-3). When D is perfectly predictable by X, there is no variation
in it conditional on X, and the randomization by nature breaks down. Heuristically,
matching assumes a residual E(X) = D − E(D | X) that is nondegenerate and is one
manifestation of the randomness that causes persons to switch status.16
In the IV method, it is the choice probability E(D | X, Z) = P (X, Z) that is random
with respect to (Y0 , Y1 ), not components of D not predictable by (X, Z). Variation in
Z for a fixed X provides the required variation in D that switches treatment status and
still produces the required conditional independence:
(Y0 , Y1 ) ⊥
⊥ P (X, Z) | X.
Variation in P (X, Z) produces variations in D that switch treatment status. Components
of variation in D not predictable by (X, Z) do not produce the required independence.
Instead, the predicted component provides the required independence. It is just the opposite in matching. Versions of the method of control functions use measurements to
proxy θ in (U-1) and (U-2) and remove spurious dependence that gives rise to selection
problems. These are called replacement functions [see Heckman and Robb (1985a)] or
control variates [see Blundell and Powell (2003)].
Table 1 summarizes some of the main lessons of this section. We stress that the stated
conditions are necessary conditions. There are many versions of the IV and control functions principle and extensions of these ideas which refine these basic postulates more
fully and we exposit them in this Handbook. We start with the method of instrumental
variables and analyze the general case where responses to treatment are heterogeneous
and persons select into treatment status in response to the heterogeneity in treatment
response.
Our strategy in this chapter is to anchor all of our analysis around the economic
theory of choice as embodied in discrete choice theory and versions of the generalized
Roy model developed in Chapter 70. We next show how recent developments allow
analysts to define treatment parameters within a well-posed economic framework but
without the strong assumptions maintained in the early literature on selection models.
To focus our discussion, we first consider the analysis of a prototypical policy evaluation
program.
2.1. A prototypical policy evaluation problem
To motivate our discussion in this chapter, consider the following prototypical policy
problem. Suppose a policy is proposed for adoption in a country. It has been tried in
other countries and we know outcomes there. We also know outcomes in countries

16 It is heuristically illuminating, but technically incorrect to replace E(X) with D in (R-1) or ξ in (R-2) or

A in (R-3). In general, E(X) is not independent of X even if it is mean independent.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4891

Table 1
Identifying assumptions under commonly used methods
Identifying assumptions

Random
(Y0 , Y1 ) ⊥
⊥ ξ,
assignment ξ = 1 ⇒ A = 1, ξ = 0 ⇒ A = 0 (full compliance).
Alternatively, if self-selection is random with
respect to outcomes, (Y0 , Y1 ) ⊥
⊥ D.
Assignment can be conditional on X.

Identifies
Exclusion
marginal
condition
distributions? needed?
Yes

No

Matching

(Y0 , Y1 ) ⊥

⊥ D, but (Y0 , Y1 ) ⊥
⊥ D | X,
0 < Pr(D = 1 | X) < 1 for all X.
So D conditional on X is a nondegenerate random variable.

Yes

No

Control
functions
and
extensions

(Y0 , Y1 ) ⊥

⊥ D | X, Z, but (Y0 , Y1 ) ⊥
⊥ D | X, Z, θ .
The method models dependence induced by θ
or else proxies θ (replacement function).
Version (i). Replacement functions
(substitute out θ by observables)
[Blundell and Powell (2003), Heckman and Robb (1985a),
Olley and Pakes (1996)].
Factor models [Carneiro, Hansen and Heckman (2003)]
allow for measurement error in the proxies.
Version (ii). Integrate out θ assuming θ ⊥
⊥ (X, Z)
[Aakvik, Heckman and Vytlacil (2005),
Carneiro, Hansen and Heckman (2003)].
Version (iii). For separable models for mean response
expect out θ conditional on X, Z, D
as in standard selection models
(control functions in the same sense of Heckman and Robb).

Yes

Yes
(for semiparametric models)
No (under
some parametric
assumptions)

IV

(Y0 , Y1 ) ⊥

⊥ D | X, Z, but (Y1 , Y0 ) ⊥
⊥ Z | X,
Pr(D = 1 | Z) is a nondegenerate function of Z.

Yes

Yes

Notes: (Y0 , Y1 ) are potential outcomes that depend on X;

1 if assigned (or choose) status 1,
D=
0 otherwise;
Z are determinants of D, θ is a vector of unobservables. For random assignments, A is a vector of actual
treatment status. A = 1 if treated; A = 0 if not; ξ = 1 if a person is randomized to treatment status; ξ = 0
otherwise.

where it was not adopted. From the historical record, what can we conclude about the
likely effectiveness of the policy in countries that have not implemented it?
To answer questions of this sort, economists build models of counterfactuals. Consider the following model. Let Y0 be the outcome of a country (e.g., GDP) under a
no-policy regime. Y1 is the outcome if the policy is implemented. (Y1 − Y0 ) is the
“treatment effect” of the policy. It may vary among countries. We observe characteristics X of various countries (e.g., level of democracy, level of population literacy, etc.).
It is convenient to decompose Y1 into its mean given X, μ1 (X), and deviation from

4892

J.J. Heckman and E.J. Vytlacil

mean U1 . We can make a similar decomposition for Y0 :
Y1 = μ1 (X) + U1 ,
Y0 = μ0 (X) + U0 .

(2.2)

We do not need to assume additive separability but it is convenient and we initially adopt
it to simplify the exposition and establish a parallel regression notation that serves to link
the statistical literature on treatment effects with the economic literature. We develop
more general nonseparable models in later sections of this chapter.
It may happen that controlling for the X, Y1 − Y0 is the same for all countries. This is
the case of homogeneous treatment effects given X. More likely, countries vary in their
responses to the policy even after controlling for X.
Figure 1 plots the distribution of Y1 − Y0 for a benchmark X. It also displays the
various treatment parameters introduced in Chapter 70. We use a special form of the
generalized Roy model with constant cost C of adopting the policy. This is called the
“extended Roy model”. We use this model because it is simple and intuitive. (The precise parameterization of the extended Roy model used to generate the figure and the
treatment effects is given at the base of Figure 1.) The special case of homogeneity in
Y1 − Y0 arises when the distribution collapses to its mean. It would be ideal if we could
estimate the distribution of Y1 − Y0 given X and there is research that does this. Abbring
and Heckman survey methods for doing so in Chapter 72.
More often, economists focus on some mean of the distribution displayed in Figure 1
and use a regression framework to interpret the data. To turn (2.2) into a regression
model, it is conventional to use the switching regression framework.17 Define D = 1
if a country adopts a policy; D = 0 if it does not. The observed outcome Y is the
switching regression model (2.1). Substituting (2.2) into this expression, and keeping
all X implicit, we obtain
Y = Y0 + (Y1 − Y0 )D
= μ0 + (μ1 − μ0 + U1 − U0 )D + U0 .

(2.3)

Using conventional regression notation,
Y = α + βD + ε,

(2.4)

where α = μ0 , β = (Y1 − Y0 ) = μ1 − μ0 + U1 − U0 and ε = U0 . We will also use
the notation that η = U1 − U0 , letting β̄ = μ1 − μ0 and β = β̄ + η. Throughout this
section we use treatment effect and regression notation interchangeably. The coefficient
on D is the treatment effect. The case where β is the same for every country is the case
conventionally assumed. More elaborate versions assume that β depends on X (β(X))

17 Statisticians sometimes attribute this representation to Rubin (1974, 1978), but it is due to Quandt (1958,

1972). It is implicit in the Roy (1951) model. See our discussion of this basic model of counterfactuals in
Chapter 70.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4893

U1 − U0 ⊥

⊥D

TT = 2.666, TUT = −0.632
Return to marginal agent = C = 1.5
ATE = μ1 − μ0 = β̄ = 0.2
The model
Outcomes

Choice model

1 if D ∗  0,
D=
0 if D ∗ < 0

Y1 = μ1 + U1 = α + β̄ + U1
Y0 = μ0 + U0 = α + U0
General case
(U1 − U0 ) ⊥

⊥D
ATE = TT = TUT
The researcher observes (Y, D, C).
Y = α + βD + U0 where β = Y1 − Y0 .
Parameterization
α = 0.67,

(U1 , U0 ) ∼ N (0, Σ),

β̄ = 0.2,

Σ=

1
−0.9

D ∗ = Y1 − Y0 − C

−0.9
,
1

C = 1.5

Figure 1. Distribution of gains in the Roy economy. Source: Heckman, Urzua and Vytlacil (2006).

and estimates interactions of D with X. The case where β varies even after accounting
for X is called the “random coefficient” or “heterogenous treatment effect” case. The

4894

J.J. Heckman and E.J. Vytlacil

case where η = U1 − U0 depends on D is the case of essential heterogeneity analyzed
by Heckman, Urzua and Vytlacil (2006). This case arises when treatment choices depend at least in part on the idiosyncratic return to treatment. A great deal of attention
has been focused on this case in recent decades and we develop the implications of this
model in this chapter.

3. An index model of choice and treatment effects: Definitions and unifying
principles
We now present the model of treatment effects developed in Heckman and Vytlacil
(1999, 2001b, 2005) and Heckman, Urzua and Vytlacil (2006), which relaxes the normality, separability and exogeneity assumptions invoked in the traditional economic
selection models. It is rich enough to generate all of the treatment effects displayed in
Figure 1 as well as many other policy parameters. It does not require separability. It is
a nonparametric generalized Roy model with testable restrictions that can be used to
unify the treatment effect literature, identify different treatment effects, link the literature on treatment effects to the literature in structural econometrics and interpret the
implicit economic assumptions underlying instrumental variables, regression discontinuity design methods, control functions and matching methods. We follow Heckman
and Vytlacil (1999, 2005) and Heckman, Urzua and Vytlacil (2006) in considering
binary treatments. We analyze multiple treatments in Section 7. Florens et al. (2002)
develop a model with a continuum of treatments and we briefly survey that work at the
end of Section 7.
Y is the measured outcome variable. It is produced from the switching regression
model (2.1). Outcomes are general nonlinear, nonseparable functions of observables
and unobservables:
Y1 = μ1 (X, U1 ),

(3.1)

Y0 = μ0 (X, U0 ).

(3.2)

Examples of models that can be written in this form include conventional latent variable
models for discrete choice that are generated by a latent variable crossing a threshold:
Yi = 1(Yi∗  0), where Yi∗ = μi (X) + Ui , i = 0, 1. Notice that in the general case,
μi (X, Ui ) − E(Yi | X) = Ui , i = 0, 1.
As defined in Chapter 70, the individual treatment effect associated with moving an
otherwise identical person from “0” to “1” is Y1 − Y0 =  and is defined as the causal
effect on Y of a ceteris paribus move from “0” to “1”. To link this framework to the
literature on economic choice models, we characterize the decision rule for program
participation by an index model:
D ∗ = μD (Z) − V ,

D = 1 if D ∗  0,

D = 0 otherwise,

(3.3)

where, from the point of view of the econometrician, (Z, X) is observed and
(U0 , U1 , V ) is unobserved. The random variable V may be a function of (U0 , U1 ). For

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4895

example, in the original Roy model, μ1 and μ0 are additively separable in U1 and U0 ,
respectively, and V = −[U1 − U0 ]. In the original formulations of the generalized Roy
model, outcome equations are separable and V = −[U1 − U0 − UC ], where UC arises
from the cost function (recall the discussion in Section 3.3 of Chapter 70). Without loss
of generality, we define Z so that it includes all of the elements of X as well as any
additional variables unique to the choice equation.
We invoke the following assumptions that are weaker than those used in the conventional literature on structural econometrics or the recent literature on semiparametric
selection models and at the same time can be used both to define and to identify different treatment parameters.18 The assumptions are:
(A-1) (U0 , U1 , V ) are independent of Z conditional on X (Independence);
(A-2) μD (Z) is a nondegenerate random variable conditional on X (Rank condition);
(A-3) the distribution of V is continuous19 ;
(A-4) the values of E(|Y1 |) and E(|Y0 |) are finite (Finite means);
(A-5) 0 < Pr(D = 1 | X) < 1.
(A-1) assumes that V is independent of Z given X, and is used below to generate
counterfactuals. For the definition of treatment effects, we do not need either (A-1)
or (A-2). Our definitions of treatment effects and their unification through MTE do
not require any elements of Z that are not elements of X or independence assumptions. However, our analysis of instrumental variables requires that Z contain at least
one element not in X. Assumptions (A-1) or (A-2) justify application of instrumental variables methods and nonparametric selection or control function methods. Some
parameters in the recent IV literature are defined by an instrument so we make assumptions about instruments up front, noting where they are not needed. Assumption (A-4) is
needed to satisfy standard integration conditions. It guarantees that the mean treatment
parameters are well defined. Assumption (A-5) is the assumption in the population of
both a treatment and a control group for each X. Observe that there are no exogeneity
requirements for X. This is in contrast with the assumptions commonly made in the
conventional structural literature and the semiparametric selection literature [see, e.g.,
Powell (1994)].
A counterfactual “no feedback” condition facilitates interpretability so that conditioning on X does not mask the effects of D. Letting Xd denote a value of X if D is set
to d, a sufficient condition that rules out feedback from D to X is:
(A-6) Let X0 denote the counterfactual value of X that would be observed if D is
set to 0. X1 is defined analogously. Assume Xd = X for d = 0, 1. (The XD
are invariant to counterfactual manipulations.)
18 A much weaker set of conditions is required to define the parameters than is required to identify them. See

the discussion in Appendix B. As noted in Section 6, stronger conditions are required for policy forecasting.
19 Absolutely continuous with respect to Lebesgue measure.

4896

J.J. Heckman and E.J. Vytlacil

Condition (A-6) is not strictly required to formulate an evaluation model, but it enables
an analyst who conditions on X to capture the “total” or “full effect” of D on Y [see
Pearl (2000)]. This assumption imposes the requirement that X is an external variable
determined outside the model and is not affected by counterfactual manipulations of D.
However, the assumption allows for X to be freely correlated with U1 , U0 and V so
it can be endogenous. Until we discuss the problems of external validity and policy
forecasting in Section 6, we analyze treatment effects conditional on X, and maintain
assumption (A-6).
In this notation, P (Z) is the probability of receiving treatment given Z, or the
“propensity score” P (Z) ≡ Pr(D = 1 | Z) = FV |X (μD (Z)), where FV |X (·) denotes
the distribution of V conditional on X.20 We sometimes denote P (Z) by P , suppressing
the Z argument. We also work with UD , a uniform random variable (UD ∼ Unif[0, 1])
defined by UD = FV |X (V ).21 The separability between V and μD (Z) or D(Z) and UD
is conventional. It plays a crucial role in justifying instrumental variable estimators in
the general models analyzed in this chapter.
Vytlacil (2002) establishes that assumptions (A-1)–(A-5) for selection model (2.1)
and (3.1)–(3.3) are equivalent to the assumptions used to generate the LATE model
of Imbens and Angrist (1994) which are developed below in Section 4. Thus the nonparametric selection model for treatment effects developed by Heckman and Vytlacil
is implied by the assumptions of the Imbens–Angrist instrumental variable model for
treatment effects. Our approach links the IV literature to the literature on economic
choice models exposited in Chapter 70. Our latent variable model is a version of the
standard sample selection bias model. We weave together two strands of the literature
often thought to be distinct [see, e.g., Angrist and Krueger (1999)].
The model of Equations (3.1)–(3.3) and assumptions (A-1)–(A-5) impose two testable restrictions on the distribution of (Y, D, Z, X). First, it imposes an index sufficiency restriction: for any set A and for j = 0, 1,


Pr(Yj ∈ A | X, Z, D = j ) = Pr Yj ∈ A X, P (Z), D = j .
Z (given X) enters the model only through the propensity score P (Z).22 This restriction
has empirical content when Z contains two or more variables not in X. Second, the
model also imposes monotonicity in p for E(Y D | X = x, P = p) and E(Y (1 − D) |

20 Throughout this chapter, we will refer to the cumulative distribution function of a random vector A by

FA (·) and to the cumulative distribution function of a random vector A conditional on random vector B by
FA|B (·). We will write the cumulative distribution function of A conditional on B = b by FA|B (· | b).
21 This representation is valid whether or not (A-1) is true. However, (A-1) imposes restrictions on counterfactual choices. For example, if a change in government policy changes the distribution of Z by an external
manipulation, under (A-1) the model can be used to generate the choice probability from P (Z) evaluated at
the new arguments, i.e., the model is invariant with respect to the distribution Z.
22 The set A is assumed to be measurable.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4897

X = x, P = p). Heckman and Vytlacil (2005, Appendix A) develop this condition
further, and show that it is testable.
Even though the model of treatment effects we exposit is not the most general possible model, it has testable implications and hence empirical content. It unites various
literatures and produces a nonparametric version of the selection model, and links the
treatment literature to economic choice theory. We compare the assumptions used to
identify IV with the assumptions used in matching in Section 8.
3.1. Definitions of treatment effects in the two outcome model
As developed in Chapter 70, the difficulty of observing the same individual in both
treated and untreated states leads to the use of various population level treatment
effects widely used in the biostatistics literature and often applied in economics.23
The most commonly invoked treatment effect is the average treatment effect (ATE):
ATE (x) ≡ E( | X = x) where  = Y1 − Y0 . This is the effect of assigning treatment randomly to everyone of type X assuming full compliance, and ignoring general
equilibrium effects.24 The average impact of treatment on persons who actually take the
treatment is treatment on the treated (TT): TT (x) ≡ E( | X = x, D = 1). This parameter can also be defined conditional on P (Z): TT (x, p) ≡ E( | X = x, P (Z) =
p, D = 1).25
The mean effect of treatment on those for whom X = x and UD = uD , the marginal
treatment effect (MTE), plays a fundamental role in the analysis of this chapter:
MTE (x, uD ) ≡ E( | X = x, UD = uD ).

(3.4)

This parameter is defined independently of any instrument. We separate the definition
of parameters from their identification. The MTE is the expected effect of treatment
conditional on observed characteristics X and conditional on UD , the unobservables
from the first stage decision rule. For uD evaluation points close to zero, MTE (x, uD )
is the expected effect of treatment on individuals with the value of unobservables that
make them most likely to participate in treatment and who would participate even if
the mean scale utility μD (Z) is small. If UD is large, μD (Z) would have to be large to
induce people to participate.
One can also interpret E( | X = x, UD = uD ) as the mean gain in terms of Y1 − Y0
for persons with observed characteristics X who would be indifferent between treatment
or not if they were randomly assigned a value of Z, say z, such that μD (z) = uD . When
Y0 and Y1 are value outcomes, MTE is a mean willingness-to-pay measure. MTE is a
23 Heckman, LaLonde and Smith (1999) discuss panel data cases where it is possible to observe both Y and
0

Y1 for the same person.
24 See, e.g., Imbens (2004).
25 These two definitions of treatment on the treated are related by integrating out the conditioning p variable:
TT (x) = 01 TT (x, p) dFP (Z)|X,D (p | x, 1) where FP (Z)|X,D (· | x, 1) is the distribution of P (Z) given
X = x and D = 1.

4898

J.J. Heckman and E.J. Vytlacil

choice-theoretic building block that unites the treatment effect, selection, matching and
control function literatures.
A third interpretation is that MTE conditions on X and the residual defined by
subtracting the expectation of D ∗ from D ∗ : ŨD = D ∗ − E(D ∗ | Z, X). This is a
“replacement function” interpretation in the sense of Heckman and Robb (1985a) and
Chapter 73 (Matzkin) of this Handbook, or “control function” interpretation in the sense
of Blundell and Powell (2003). These three interpretations are equivalent under separability in D ∗ , i.e., when (3.3) characterizes the choice equation, but lead to three different
definitions of MTE when a more general nonseparable model is developed. This point is
developed in Section 4.10 where we discuss a general nonseparable model. The additive
separability of Equation (3.3) in terms of observables and unobservables plays a crucial
role in the justification of instrumental variable methods.
The LATE parameter of Imbens and Angrist (1994) is a version of MTE. We present
their full conditions for identification in Section 4. Here we define it in the notation used
in this chapter. LATE is defined by an instrument in their analysis. As in Chapter 70, we
define LATE independently of any instrument after first presenting the Imbens–Angrist
definition. Define D(z) as a counterfactual choice variable, with D(z) = 1 if state 1
(D = 1) would have been chosen if Z had been set to z, and D(z) = 0 otherwise.
Let Z(x) denote the support of the distribution of Z conditional on X = x. For any
(z, z ) ∈ Z(x) × Z(x) such that P (z) > P (z ), LATE is E( | X = x, D(z) =
1, D(z ) = 0) = E(Y1 − Y0 | X = x, D(z) = 1, D(z ) = 0), the mean gain to
persons who would be induced to switch from D = 0 to D = 1 if Z were manipulated
externally from z to z. In an example of the returns to education, z could be the base
level of tuition and z a reduced tuition level. Using the latent index model, developed in
Chapter 70 and defined in the introduction to this section, Heckman and Vytlacil (1999,
2005) show that LATE can be written as


E Y1 − Y0 X = x, D(z) = 1, D(z ) = 0




= E Y1 − Y0 X = x, uD < UD  uD = LATE x, uD , uD
for uD = Pr(D(z) = 1) = P (z), uD = Pr(D(z ) = 1) = P (z ), where assumption
(A-1) implies that Pr(D(z) = 1) = Pr(D = 1 | Z = z) and Pr(D(z ) = 1) =
Pr(D = 1 | Z = z ).
Imbens and Angrist define the LATE parameter as the probability limit of an estimator. Their analysis conflates issues of definition of parameters with issues of identification. Our representation of LATE allows us to separate these two conceptually
distinct matters and to define the LATE parameter more generally. One can, in principle, evaluate the right-hand side of the preceding equation at any uD , uD points
in the unit interval and not only at points in the support of the distribution of the
propensity score P (Z) conditional on X = x where it is identified. From assump-

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4899

Table 2A
Treatment effects and estimands as weighted averages of the marginal treatment effect
ATE(x) = E(Y1 − Y0 | X = x) = 01 MTE (x, uD ) duD
TT(x) = E(Y1 − Y0 | X = x, D = 1) = 01 MTE (x, uD )ωTT (x, uD ) duD
TUT(x) = E(Y1 − Y0 | X = x, D = 0) = 01 MTE (x, uD )ωTUT (x, uD ) duD
Policy relevant treatment effect: PRTE(x) = E(Ya | X = x) − E(Ya | X = x) =
1 MTE
(x, uD )ωPRTE (x, uD ) duD for two policies a and a that affect the Z
0 
but not the X
J (x, u ) du , given instrument J
IVJ (x) = 01 MTE (x, uD )ωIV
D
D
1 MTE
OLS(x) = 0 
(x, uD )ωOLS (x, uD ) duD
Source: Heckman and Vytlacil (2005).

tions (A-1), (A-3), and (A-4), LATE (x, uD , uD ) is continuous in uD and uD and
limuD ↑uD LATE (x, uD , uD ) = MTE (x, uD ).26
Heckman and Vytlacil (1999) use assumptions (A-1)–(A-5) and the latent index
structure to develop the relationship between MTE and the various treatment effect
parameters shown in the first three lines of Table 2A. Appendix A presents the formal
derivation of the parameters and associated weights and graphically illustrates the relationship between ATE and TT. There we establish that all treatment parameters may be
expressed as weighted averages of the MTE:
1

Treatment parameter (j ) =

MTE (x, uD ) ωj (x, uD ) duD ,

0

where ωj (x, uD ) is the weighting function for the MTE and the integral is defined over
the full support of uD . Except for the OLS weights, the weights in the table all integrate
to one, although in some cases the weights for IV may be negative. We analyze how
negative weights for IV might arise in Section 4.
In Table 2A, TT (x) is shown as a weighted average of MTE :
1

TT (x) =

MTE (x, uD )ωTT (x, uD ) duD ,

0

where
ωTT (x, uD ) =

1 − FP |X (uD | x)
1
0 (1 − FP |X (t | x)) dt

=

SP |X (uD | x)
,
E(P (Z) | X = x)

(3.5)

26 This follows from Lebesgue’s theorem for the derivative of an integral and holds almost everywhere with

respect to Lebesgue measure. The ideas of the marginal treatment effect and the limit form of LATE were first
introduced in the context of a parametric normal generalized Roy model by Björklund and Moffitt (1987),
and were analyzed more generally in Heckman (1997). Angrist, Graddy and Imbens (2000) also define and
develop a limit form of LATE.

4900

J.J. Heckman and E.J. Vytlacil
Table 2B
Weights
ωATE (x, uD ) = 1


1
ωTT (x, uD ) = u1 fP |X (p | X = x) dp
D
E(P |X=x)
 uD

1
ωTUT (x, uD ) = 0 fP |X (p | X = x) dp
E((1−P )|X=x)
 FP |X (uD |x)−FP |X (uD |x) 
a
a
, where
ωPRTE (x, uD ) =
P (x)

P (x) = E(Pa | X = x) − E(Pa | X = x)

J (x, u ) =  1 (J (Z) − E(J (Z) | X = x))f
ωIV
D
J,P |X (j, t | X = x) dt dj
u
D

ωOLS (x, uD ) = 1 +

1
Cov(J (Z),D|X=x)
E(U1 |X=x,UD =uD )ω1 (x,uD )−E(U0 |X=x,UD =uD )ω0 (x,uD )
MTE (x,uD )

 1

1
uD fP |X (p | X = x) dp E(P |X=x)
 u

1
ω0 (x, uD ) = 0 D fP |X (p | X = x) dp
ω1 (x, uD ) =

E((1−P )|X=x)

Source: Heckman and Vytlacil (2005).

and SP |X (uD | x) is Pr(P (Z) > uD | X = x) and ωTT (x, uD ) is a weighted distribution. The parameter TT (x) oversamples MTE (x, uD ) for those individuals with low
values of uD that make them more likely to participate in the program being evaluated.
Treatment on the untreated (TUT) is defined symmetrically with TT and oversamples
those least likely to participate. The various weights are displayed in Table 2B. The other
weights, treatment effects and estimands shown in this table are discussed later. A central theme of this chapter is that under our assumptions all estimators and estimands can
be written as weighted averages of MTE. This allows us to unify the treatment effect
literature using a common functional MTE (x, uD ).
Observe that if E(Y1 − Y0 | X = x, UD = uD ) = E(Y1 − Y0 | X = x), so
 = Y1 − Y0 is mean independent of UD given X = x, then MTE = ATE = TT =
LATE . Therefore, in cases where there is no heterogeneity in terms of unobservables
in MTE ( constant conditional on X = x) or agents do not act on it so that UD drops
out of the conditioning set, marginal treatment effects are average treatment effects, so
that all of the evaluation parameters are the same. Otherwise, they are different. Only
in the case where the marginal treatment effect is the average treatment effect will the
“effect” of treatment be uniquely defined.
Figure 2A plots weights for a parametric normal generalized Roy model generated
from the parameters shown at the base of Figure 2B. This is an instance of the general
model developed in Chapter 70, Section 5. The model allows for costs to vary in the
population and is more general than the extended Roy model. We discuss the weights for
IV depicted in Figure 2B in Section 4 and the weights for OLS in Section 8. A high uD
is associated with higher cost, relative to return, and less likelihood of choosing D = 1.
The decline of MTE in terms of higher values of uD means that people with higher uD

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4901

Figure 2A. Weights for the marginal treatment effect for different parameters. Source: Heckman and Vytlacil
(2005).

have lower gross returns. TT overweights low values of uD (i.e., it oversamples UD that
make it likely to have D = 1). ATE samples UD uniformly. Treatment on the untreated
(E(Y1 − Y0 | X = x, D = 0)), or TUT, oversamples the values of UD which make it
unlikely to have D = 1.
Table 3 shows the treatment parameters produced from the different weighting
schemes for the model used to generate the weights in Figures 2A and 2B. Given the
decline of the MTE in uD , it is not surprising that TT > ATE > TUT. This is the
generalized Roy version of the principle of diminishing returns. Those most likely to
self-select into the program benefit the most from it. The difference between TT and
ATE is a sorting gain: E(Y1 − Y0 | X, D = 1) − E(Y1 − Y0 | X), the average gain
experienced by people who sort into treatment compared to what the average person
would experience. Purposive selection on the basis of gains should lead to positive sorting gains of the kind found in the table. If there is negative sorting on the gains, then
TUT  ATE  TT. Later in this chapter, we return to this table to discuss the other
numbers in it.
Table 4 reproduced from Heckman (2001) presents evidence on the nonconstancy of
the MTE in UD drawn from a variety of studies of schooling, job training, migration and
unionism. Most of the evidence is obtained using parametric normal selection models or
variants of such models. With the exception of studies of unionism, a common finding

4902

Y1 = α + β̄ + U1
Y0 = α + U0
D = 1 if Z − V  0

J.J. Heckman and E.J. Vytlacil

U1 = σ1 τ
U0 = σ0 τ
V = σV τ
UD = Φ( σ Vστ )
V

α = 0.67
β̄ = 0.2
τ ∼ N (0, 1)

σ1 = 0.012
σ0 = −0.050
σV = −1.000
Z ∼ N (−0.0026, 0.2700)

Figure 2B. Marginal treatment effect vs. linear instrumental variables and ordinary least squares weights.
Source: Heckman and Vytlacil (2005).

in the empirical literature is the nonconstancy of MTE given X.27 The evidence from
the literature suggests that different treatment parameters measure different effects, and
persons participate in programs based on heterogeneity in responses to the program
being studied. The phenomenon of nonconstancy of the MTE that we analyze in this
chapter is of substantial empirical interest.
The additively separable latent index model for D [Equation (3.3)] and assumptions (A-1)–(A-5) are far stronger than what is required to define the parameters in
terms of the MTE. The representations of treatment effects defined in Table 2A remain
valid even if Z is not independent of UD , if there are no variables in Z that are not
also contained in X, or if a more general nonseparable choice model generates D [so
D ∗ = μD (Z, UD )]. An important advantage of our approach over other approaches to
the analysis of instrumental variables in the recent literature is that no instrument Z is

27 However, most of the empirical evidence is based on parametric selection models.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4903

Table 3
Treatment parameters and estimands in the generalized Roy example
Treatment on the treated
Treatment on the untreated
Average treatment effect
Sorting gaina
Policy relevant treatment effect (PRTE)
Selection biasb
Linear instrumental variablesc
Ordinary least squares

0.2353
0.1574
0.2000
0.0353
0.1549
−0.0628
0.2013
0.1725

Source: Heckman and Vytlacil (2005).
Note: The model used to create Table 3 is the same as those used to
create Figures 2A and 2B. The PRTE is computed using a policy t
characterized as follows:
– If Z > 0 then D = 1 if Z(1 + t) − V  0.
– If Z  t then D = 1 if Z − V  0.
For this example t is set equal to 0.2.
a TT − ATE = E(Y − Y | D = 1) − E(Y − Y ).
1
0
1
0
b OLS − TT = E(Y | D = 1) − E(Y | D = 0).
0
0
c Using propensity score P (Z) as the instrument.

needed to define the parameters. We separate the tasks of definition and identification of
parameters as discussed in Table 1 of Chapter 70, and present an analysis more closely
rooted in economics. Appendices A and B define the treatment parameters for both separable (Appendix A) and nonseparable choice equations (Appendix B). We show that
the treatment parameters can be defined even if there is no instrument or if instrumental
variables methods break down as they do in nonseparable models.
As noted in Chapter 70, the literature on structural econometrics is clear about the
basic parameters of interest although it is not always clear about the exact combinations
of parameters needed to answer specific policy problems. The literature on treatment
effects offers a variety of evaluation parameters. Missing from that literature is an algorithm for defining treatment effects that answer precisely formulated economic policy
questions. The MTE provides a framework for developing such an algorithm. In the
next section, we present one well defined policy parameter that can be used to generate
Benthamite policy evaluations as discussed in Section 5 of Chapter 70.
3.2. Policy relevant treatment parameters
The conventional treatment parameters do not always answer economically interesting
questions. Their link to cost-benefit analysis and interpretable economic frameworks
is sometimes obscure. Each answers a different question. Many investigators estimate
a treatment effect and hope that it answers an interesting question. A more promising
approach for defining parameters is to postulate a policy question or decision problem

4904

J.J. Heckman and E.J. Vytlacil
Table 4
Evidence on selection on unobservables and constancy of the MTE for separable models

Study

Method

Finding on the hypothesis
of constancy of the MTE
Unionism

Lee (1978)
Farber (1983)
Duncan and Leigh
(1985)
Robinson (1989)

Normal selection model

σ1V = σ0V

(H0 : σ1V = σ0V )
Normal selection model

Do not reject
σ1V = σ0V

(H0 : σ1V = σ0V )
Normal selection model
(H0 : σ1V = σ0V )
Normal selection model
(μ1 − μ0 )IV = (μ1 − μ0 )normal

Do not reject
σ1V = σ0V
Do not reject
σ1V = σ0V
Do not reject

Schooling
(college vs. high school)
Willis and Rosen (1979)
Heckman, Tobias and
Vytlacil (2003)

Normal selection model
(H0 : σ1V = σ0V )
Normal selection model
(H0 : σ1V = σ0V )

σ1V = σ0V
Reject
σ1V = σ0V
Reject

Job training
Björklund and Moffitt
(1987)
Heckman et al. (1998;
Suppl.)

Normal selection model
(H0 : σ1V = σ0V )
E(U1 − U0 | D = 1, Z, X)
= E(U1 − U0 | D = 1, X)

σ1V = σ0V
Reject
Reject selection on
unobservables

Sectoral choice
Heckman and
Sedlacek (1990)

Normal selection model
(H0 : σ1V = σ0V )

σ1V = σ0V
Reject

Migration
Pessino (1991)
Tunali (2000)

Normal selection model

σ1V = σ0V

(H0 : σ1V = σ0V )
H0 : E(U1 − U0 | D = 1) = 0

Reject
Cannot reject

(estimated using robust selection)
Source: Heckman (2001).
Notes: Y = DY1 + (1 − D)Y0
Y1 = μ1 (X) + U1
Y0 = μ0 (X) + U0
Z⊥
⊥ (U0 , U1 ), Z ⊥

⊥D
D = 1(μD (Z) − V  0), where μD (Z) − V is the index determining selection into “1” or “0”
Hypothesis: No selection on unobservables (constancy of the MTE)
H0 : E(U1 − U0 | D = 1, Z, X) does not depend on D where Cov(U1 , UV ) = σ1V ,
Cov(U0 , UV ) = σ0V (in normal model, the null hypothesis is σ1V = σ0V ).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4905

of interest and to derive the treatment parameter that answers it. Taking this approach
does not in general produce the conventional treatment parameters or the estimands
produced from instrumental variables.
Consider a class of policies that affect P , the probability of participation in a program, but do not affect MTE . The policies analyzed in the treatment effect literature
that change the Z not in X are more restrictive than the general policies that shift X
and Z analyzed in the structural literature. An example from the schooling literature
would be policies that change tuition or distance to school but do not directly affect the
gross returns to schooling [Card (2001)]. Since we ignore general equilibrium effects in
this chapter, the effects on (Y0 , Y1 ) from changes in the overall level of education are
assumed to be negligible.
Let p and p denote two potential policies and let Dp and Dp denote the choices
that would be made under policies p and p . When we discuss the policy relevant treatment effect, we use “p” to denote the policy and distinguish it from the realized value
of P (Z). Under our assumptions, the policies affect the Z given X, but not the potential
outcomes. Let the corresponding decision rules be Dp = 1[Pp (Zp )  UD ], Dp =
1[Pp (Zp )  UD ], where Pp (Zp ) = Pr(Dp = 1 | Zp ) and Pp (Zp ) = Pr(Dp = 1 |
Zp ). To simplify the exposition, we will suppress the arguments of these functions and
write Pp and Pp for Pp (Zp ) and Pp (Zp ). Define (Y0,p , Y1,p , UD,p ) as (Y0 , Y1 , UD )
under policy p, and define (Y0,p , Y1,p , UD,p ) correspondingly under policy p . We
assume that Zp and Zp are independent of (Y0,p , Y1,p , UD,p ) and (Y0,p , Y1,p , UD,p ),
respectively, conditional on Xp and Xp . Let Yp = Dp Y1,p + (1 − Dp )Y0,p and
Yp = Dp Y1,p + (1 − Dp )Y0,p denote the outcomes that would be observed under
policies p and p , respectively.
MTE is policy invariant in the sense of Hurwicz as defined in Chapter 70 if
E(Y1,p | UD,p = uD , Xp = x) and E(Y0,p | UD,p = uD , Xp = x) are invariant to
the choice of policy p (Policy invariance for the marginal treatment effect).
Policy invariance can be justified by the strong assumption that the policy being investigated does not change the counterfactual outcomes, covariates, or unobservables, i.e.,
(Y0,p , Y1,p , Xp , UD,p ) = (Y0,p , Y1,p , Xp , UD,p ). However, MTE is policy invariant
if this assumption is relaxed to the weaker assumption that the policy change does not
affect the distribution of these variables conditional on X:
(A-7) The distribution of (Y0,p , Y1,p , UD,p ) conditional on Xp = x is the same
as the distribution of (Y0,p , Y1,p , UD,p ) conditional on Xp = x (policy
invariance for distribution).
Assumption (A-7) guarantees that manipulations of the distribution of Z do not affect
anything in the model except the choice of outcomes. These are specialized versions of
(PI-3) and (PI-4) invoked in Chapter 70.
For the widely used Benthamite social welfare criterion Υ (Y ), where Υ is a utility
function, comparing policies using mean utilities of outcomes and considering the effect

4906

J.J. Heckman and E.J. Vytlacil

for individuals with a given level of X = x we obtain the policy relevant treatment
effect, PRTE, denoted PRTE (x):




E Υ (Yp ) X = x − E Υ (Yp ) X = x
1

=
0



MTE
(x, uD ) FPp |X (uD | x) − FPp |X (uD | x) duD ,
Υ

(3.6)

where FPp |X (· | x) and FPp |X (· | x) are the distributions of Pp and Pp conditional
on X = x, respectively, defined for the different policy regimes and MTE
(x, uD ) =
Υ
E(Υ (Y1,p ) − Υ (Y0,p ) | UD,p = uD , Xp = x).28 ,29 The weights in expression (3.6) are
derived in Appendix C under the assumption that the policy does not change the joint
distribution of outcomes. To simplify the notation, throughout the rest of this chapter
when we discuss PRTE, we assume that Υ (Y ) = Y . Modifications of our analysis for
the more general case are straightforward. We also discuss the implications of noninvariance for the definition and interpretation of the PRTE in Appendix C.
Define P̄ (x) = E(Pp | X = x) − E(Pp | X = x), the change in the proportion of
people induced into the program due to the intervention. Assuming P̄ (x) is positive,
we may define per person affected weights as
ωPRTE (x, uD ) =

FPp |X (uD | x) − FPp |X (uD | x)
P̄ (x)

.

These weights are displayed in Table 2B. As demonstrated in the next section, in general, conventional IV weights the MTE differently than either the conventional treatment
parameters (ATE or TT ) or the policy relevant parameter, and so does not recover
these parameters.
Instead of hoping that conventional treatment parameters or favorite estimators answer interesting economic questions, the approach developed by Heckman and Vytlacil
(1999, 2001a, 2001b, 2005) is to estimate the MTE and weight it by the appropriate
weight determined by how the policy changes the distribution of P to construct PRTE .
In Heckman and Vytlacil (2005), we also develop an alternative approach that produces
a policy weighted instrument to identify PRTE by standard instrumental variables. We
elaborate our discussion of policy analysis based in the MTE and develop other policy
28 We could define policy invariance for MTE in terms of expectations of Υ (Y
1,p ) and Υ (Y0,p ).
29 If we assume that the marginal distribution of X and X are the same as the marginal distribution of
p
p

a benchmark X, the weights can be integrated against the distribution of X to obtain the total effect of the
policy in the population:




E Υ (Yp ) − E Υ (Yp )
 



= EX E Υ (Yp ) X − E Υ (Yp ) X
=

1
0



MTE
(x, uD ) FP |X (uD | x) − FPp |X (uD | x) duD dFX (x).
Υ
p

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4907

parameters for local and global perturbations of policy in Section 6 after developing the
instrumental variable estimator and the related regression discontinuity estimator. The
analyses of Sections 4 and 5 give us tools to make specific the discussion of alternative
approaches to policy evaluation.
4. Instrumental variables
The method of instrumental variables (IV) is currently the most widely used method in
economics for estimating economic models when unobservables are present that violate
the matching assumption (M-1).30 We first present an intuitive exposition of the method
and then present a more formal development. We analyze a model with two outcomes.
We generalize the analysis to multiple outcomes in Section 7.
Return to the policy adoption example presented at the end of Section 2. The distribution of returns to adoption is depicted in Figure 1. First, consider the method of IV,
where β (given X), which is the same as Y1 − Y0 given X, is the same for every country.
This is the familiar case and we develop it first. The model is
Y = α + βD + ε,

(4.1)

where conditioning on X is implicit. A simple least squares regression of Y on D (equivalently a mean difference in outcomes between countries with D = 1 and countries with
D = 0) is possibly subject to a selection bias on Y0 . Countries that adopt the policy may
be atypical in terms of their Y0 (= α + ε). Thus if countries that would have done well
in terms of unobservable ε (= U0 ) even in the absence of the policy are the ones that
adopt the policy, β estimated from OLS (or its semiparametric version – matching) is
upward biased because Cov(D, ε) > 0.
If there is an instrument Z, with the properties that
Cov(Z, D) = 0,

(4.2)

Cov(Z, ε) = 0,

(4.3)

then standard IV identifies β, at least in large samples,
Cov(Z, Y )
= β.31
Cov(Z, D)
If other instruments exist, each identifies β. Z produces a controlled variation in D relative to ε. Randomization of assignment with full compliance to experimental protocols
plim β̂IV =

30 More precisely, IV is the most widely used alternative to OLS. OLS is a version of matching that imposes

linearity of the functional form of outcome equations and assumes exogeneity of the regressors. See our
discussion of matching in Section 8.
31 The proof is straightforward. Under general conditions [see, e.g., White (1984)],
plim β̂IV = β +

Cov(Z, ε)
Cov(Z, D)

and

Cov(Z, ε) = 0,

so the second term on the right-hand side vanishes.

4908

J.J. Heckman and E.J. Vytlacil

is an example of an instrument. From the instrumental variable estimators, we can identify the effect of adopting the policy in any country since all countries respond to the
policy in the same way controlling for their X.
If β (= Y1 − Y0 ) varies in the population even after controlling for X, there is a
distribution of responses that cannot in general be summarized by a single number. Even
if we are interested in the mean of the distribution, a new phenomenon distinct from
selection bias might arise. This is a problem of sorting on the gain, which is distinct
from sorting on levels. If β varies, even after controlling for X, there may be sorting on
the gain (Cov(β, D) = 0). This is the model of essential heterogeneity as defined by
Heckman, Urzua and Vytlacil (2006). It is also called a correlated random coefficient
model [Heckman and Vytlacil (1998)].
The application of instrumental variables to this case is more problematic. Suppose
that we augment the standard instrumental variable assumptions (4.2) and (4.3) by the
following assumption:
Cov(Z, β) = 0.

(4.4)

Can we identify the mean of (Y1 − Y0 ) using IV? In general we cannot.32
To see why, let β̄ = (μ1 − μ0 ) be the mean treatment effect (the mean of the distribution in Figure 1). β = β̄ + η, where U1 − U0 = η and β̄ = μ1 − μ0 and we keep the
conditioning on X implicit. Write Equation (4.1) in terms of these parameters:
Y = α + β̄D + [ε + ηD].
The error term of this equation (ε + ηD) contains two components. By assumption,
Z is uncorrelated with ε and η. But to identify β̄, we need IV to be uncorrelated with
[ε + ηD]. That requires Z to be uncorrelated with ηD.
If policy adoption is made without knowledge of η (= U1 − U0 ), the idiosyncratic
gain to policy adoption after controlling for the observables, then η and D are statistically independent and hence uncorrelated, and IV identifies β̄.33 If, however, policy
adoption is made with partial or full knowledge of η, IV does not identify β̄ because
E(ηD | Z) = E(η | D = 1, Z) Pr(D = 1 | Z) and if there is sorting on the unobserved
gain η, the first term is not zero. Similar calculations show that IV does not identify
the mean gain to the countries that adopt the policy (E(β | D = 1)) and many other
summary treatment parameters.34 Whether η (= U1 − U0 ) is correlated with D depends
on the quality of the data available to the empirical economist and cannot be settled
32 This point was made by Heckman and Robb (1985a, 1986a). See also Heckman (1997).
33 The proof is straightforward:

plim β̂IV = β̄ +

Cov(Z, ε + ηD)
.
Var(D, Z)

But Cov(Z, ε + ηD) = Cov(Z, ε) + Cov(Z, ηD) and Cov(Z, ηD) = E(ZηD) − E(Z)E(ηD), E(ηD) = 0
by the assumed independence. E(ZηD) = E[E(ηDZ | Z)] = E[E(ηD | Z)Z] = 0 since E(ηD | Z) = 0.
34 See Heckman and Robb (1985a, 1986a), Heckman (1997) or Heckman and Vytlacil (1999).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4909

a priori. The conservative position is to allow for such a correlation. However, this rules
out IV as an interesting econometric strategy for identifying any of the familiar mean
treatment parameters.
In light of the negative conclusions about IV in the literature preceding their paper,
it is remarkable that Imbens and Angrist (1994) establish that under certain conditions,
in the model with essential heterogeneity, IV can identify an interpretable parameter.
The parameter they identify is a discrete approximation to the marginal gain parameter
introduced by Björklund and Moffitt (1987). The Björklund–Moffitt parameter is a version of MTE for a parametric normal selection model. We derive their parameter from a
selection model in Section 4.8. Björklund and Moffitt (1987) demonstrate how to use a
selection model to identify the marginal gain to persons induced into a treatment status
by a marginal change in the cost of treatment. Imbens and Angrist (1994) show how to
estimate a discrete approximation to the Björklund–Moffitt parameter using instrumental variables.
Imbens and Angrist (1994) assume the existence of an instrument Z that takes two or
more distinct values. This is implicit in (4.2). If Z assumes only one value, the covariance in (4.2) would be zero. Strengthening the covariance conditions of Equations (4.3)
and (4.4), they assume (IV-1) and (IV-2) (independence and rank, respectively) and that
Z is independent of β = (Y1 − Y0 ) and Y0 . Recall that we denote by D(z) the random
variable indicating receipt of treatment when Z is set to z. (D(z) = 1 if treatment is received; D(z) = 0 otherwise.) The Imbens–Angrist independence and rank assumptions
are (IV-1) and (IV-2).
They supplement the standard IV assumptions with what they call a “monotonicity”
assumption. It is a condition across persons. The assumption maintains that if Z is fixed
first at one and then at the other of two distinct values, say Z = z and Z = z , then
all persons respond in their choice of D to the change in Z in the same way. In our
policy adoption example, this condition states that a movement from z to z , causes all
countries to move toward (or against) adoption of the public policy being studied. If
some adopt, others do not drop the policy in response to the same change.
More formally, letting Di (z) be the indicator (= 1 if adopted; = 0 if not) for adoption
of a policy if Z = z for country i, then for any distinct values z and z Imbens and
Angrist (1994) assume:
(IV-3) Di (z)  Di (z ) for all i, or Di (z)  Di (z ) for all i = 1, . . . , I (Monotonicity or uniformity).
The content in this assumption is not in the order for any person. Rather, the responses
have to be uniform across people for a given choice of z and z . One possibility allowed under (IV-3) is the existence of three values of z < z < z such that for all i,
Di (z)  Di (z ) but Di (z )  Di (z ). The standard usage of the term monotonicity rules
out this possibility by requiring that one of the following hold for all i: (a) z < z componentwise implies Di (z)  Di (z ) or (b) z < z componentwise implies Di (z)  Di (z ).
Of course, if the Di (z) are monotonic in Z in the same direction for all i, they are
monotonic in the sense of Imbens and Angrist.

4910

J.J. Heckman and E.J. Vytlacil

For any value of z in the domain of definition of Z, from (IV-1) and (IV-2) and
the definition of D(z), (Y0 , Y1 , D(z )) is independent of Z. For any two values of the
instrument Z = z and Z = z , we may write
E(Y | Z = z) − E(Y | Z = z )




= E Y1 D + Y0 (1 − D) Z = z − E Y1 D + Y0 (1 − D) Z = z




= E Y0 + D(Y1 − Y0 ) Z = z − E Y0 + D(Y1 − Y0 ) Z = z .
From the independence condition (IV-1) and the definition of D(z) and D(z ), we may
write this expression as E[(Y1 − Y0 )(D(z) − D(z ))]. Using the law of iterated expectations,
E(Y | Z = z) − E(Y | Z = z )
 


= E Y1 − Y0 D(z) − D(z ) = 1 Pr D(z) − D(z ) = 1

 

− E Y1 − Y0 D(z) − D(z ) = −1 Pr D(z) − D(z ) = −1 .

(4.5)

By the monotonicity condition (IV-3), we eliminate one or the other term in the final
expression. Suppose that Pr(D(z) − D(z ) = −1) = 0, then
E(Y | Z = z) − E(Y | Z = z )

 

= E Y1 − Y0 D(z) − D(z ) = 1 Pr D(z) − D(z ) = 1 .
Observe that, by monotonicity, Pr(D(z) − D(z ) = 1) = Pr(D = 1 | Z = z) −
Pr(D = 1 | Z = z ). For values of z and z that produce distinct propensity scores
Pr(D = 1 | Z = z), using monotonicity once more, we obtain LATE:
E(Y | Z = z) − E(Y | Z = z )
Pr(D = 1 | Z = z) − Pr(D = 1 | Z = z )


= E Y1 − Y0 D(z) − D(z ) = 1 .35

LATE =

(4.6)

This is the mean gain to those induced to switch from “0” to “1” by a change in Z from
z to z.
This is not the mean of Y1 − Y0 (average treatment effect) unless the Z assume values
(z, z ) such that Pr(D(z) = 1) = 1 and Pr(D(z ) = 1) = 0.36 It is also not the effect of
treatment on the treated (E(Y1 − Y0 | D = 1) = E(β | D = 1)) unless the analyst has
access to one or more values of Z such that Pr(D(z) = 1) = 1.
The LATE parameter is defined by a hypothetical manipulation of instruments. It
depends on the particular instrument used.37 If monotonicity (uniformity) is violated,
35 Pr(D(z)−D(z ) = 1) = Pr(D(z = 1)∧D(z = 0)) = Pr(D(z) = 1)−Pr(D(z ) = 1) from monotonicity.
36 Such values produce “identification at infinity” or more accurately limit points where P (z) = 1 and

P (z ) = 0.

37 Dependence of the estimands on the choices of IV used to estimate models with essential heterogeneity

was first noted in Heckman and Robb (1985a, 1986a).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4911

IV estimates an average response of those induced to switch into the program and those
induced to switch out of the program by the change in the instrument because both terms
in (4.5) are present.38
In an application to wage equations, Card (1999, 2001) interprets the LATE estimator
as identifying returns to marginal persons. Heckman (1996) notes that the actual margin
of choice selected by the IV estimator is not identified by the instrument. It is unclear
as to which segment of the population the return estimated by LATE
  applies.
If the analyst is interested in knowing the average response β̄ , the effect of the
policy on the outcomes of countries that adopt it (E(β | D = 1)) or the effect of the
policy if a particular country adopts it, there is no guarantee that the IV estimator comes
any closer to the desired target than the OLS estimator and indeed it may be more biased
than OLS. Because different instruments define different parameters, having a wealth
of different strong instruments does not improve the precision of the estimate of any
particular parameter. This is in stark contrast with the traditional model with β ⊥
⊥ D. In
that case, all valid instruments identify β̄. The Durbin (1954) – Wu (1973) – Hausman
(1978) test for the validity of extra instruments applies to the traditional model. In the
more general case with essential heterogeneity, because different instruments estimate
different parameters, no clear inference emerges from such specification tests.
When there are more than two distinct values of Z, Imbens and Angrist draw on
the analysis of Yitzhaki (1989), which was refined in Yitzhaki (1996) and Yitzhaki
and Schechtman (2004), to produce a weighted average of pairwise LATE parameters
where the scalars Z are ordered to define the LATE parameter. In this case, IV is a
weighted average of LATE parameters with nonnegative weights.39 Imbens and Angrist
generalize this result to the case of vector Z assuming that instruments are monotonic
functions of the probability of selection.
Heckman and Vytlacil (1999, 2001b, 2005), Heckman, Urzua and Vytlacil (2006)
and Carneiro, Heckman and Vytlacil (2006) generalize the analysis of Imbens and
Angrist (1994) in several ways and we report their results in this chapter. Using a choicetheoretic parameter (the marginal treatment effect or MTE) introduced into the literature
on selection models by Björklund and Moffitt (1987), they relate the parameters estimated by IV to well formulated choice models. This allows treatment parameters to be
defined independent of any values assumed by instruments. It is possible to generate all
treatment effects as different weighted averages of the MTE. IV can also be interpreted

38 Angrist, Imbens and Rubin (1996) consider the case of two way flows for the special case of a scalar

instrument when the monotonicity assumption is violated. Their analysis is a version of Yitzhaki’s (1989,
1996) analysis, which we summarize in Appendix D. He analyzes the net effect whereas they break the net
effect into two components corresponding to the two gross flows that produce the two way flows.
39 Yitzhaki (1989) shows for a scalar instrument that two stage least squares estimators of Y on P (Z) =
E(D | Z) identify weighted averages of terms like the second terms in (4.6) with positive weights. See also
Yitzhaki (1996) and Yitzhaki and Schechtman (2004). We discuss this work in greater detail in Section 4.3.1,
and we derive his weights in Appendix D. The original Yitzhaki (1989) paper is posted at the website of
Heckman, Urzua and Vytlacil (2006).

4912

J.J. Heckman and E.J. Vytlacil

as a weighted average of MTE. Different instruments weight different segments of the
MTE differently. Using the nonparametric generalized Roy model, MTE is a limit form
of LATE. Using MTE, we overcome a problem that plagues the LATE literature. LATE
estimates marginal returns at an unidentified margin (or intervals of margins). We show
how to use the MTE to unify diverse instrumental variables estimates and to determine
what margins (or intervals of margins) they identify. Instead of reporting a marginal
return for unidentified persons, we show how to report marginal returns for all persons
identified by their location on the scale of a latent variable that arises from a well defined choice model and is related to the propensity of persons to make the choice being
studied. We can interpret the margins of choice identified by various instruments and
place diverse instruments on a common interpretive footing.
Heckman and Vytlacil (1999, 2005) establish the central role of the propensity score
(Pr(D = 1 | Z = z) = P (z)) in both selection and IV models.40 They show that with
vector Z and a scalar instrument J (Z) constructed from vector Z, the weights on LATE
and MTE that are implicit in standard IV are not guaranteed to be nonnegative. Thus IV
can be negative even though all pairwise LATEs and pointwise MTEs are positive. Thus
the treatment effects for any pair of (z, z ) can be positive but the IV can be negative.
We present examples below. Certain instruments produce positive weights and avoid
this particular interpretive problem. Our analysis generalizes the analyses of weights on
treatment effects by Yitzhaki and Imbens–Angrist, who analyze a special case where all
weights are positive.
We establish the special status of P (z) as an instrument. It always produces nonnegative weights for MTE and LATE. It enables analysts to identify MTE or LATE.
With knowledge of P (z), and the MTE or LATE, we can decompose any IV estimate
into identifiable MTEs (at points) or LATEs (over intervals) and identifiable weights
on MTE (or LATE) where the weights can be constructed from data. The ability to decompose IV into interpretable components allows analysts to determine the response to
treatment of persons at different levels of unobserved factors that determine treatment
status.
We present a simple test for essential heterogeneity (β dependent on D) that allows
analysts to determine whether or not they can avoid the complexities of the more general model with heterogeneity in response to treatments. In Section 7, we generalize the
analysis of IV in the two-outcome model to a multiple outcome model, analyzing both
ordered and unordered choice cases.41 We also demonstrate the fundamental asymmetry in the recent IV literature for models with heterogeneous outcomes. Responses to
treatment are permitted to be heterogeneous in a general way. Responses of choices to
instruments are not. When heterogeneity in choice is allowed for in a general way, IV
and local IV do not estimate parameters that can be interpreted as weighted averages of
MTEs or LATEs. We now turn to an analysis of the two-outcome model.
40 Rosenbaum and Rubin (1983) establish the control role of the propensity score in matching models.
41 Angrist and Imbens (1995) consider an ordered choice case with instruments common across all choices.

Heckman, Urzua and Vytlacil (2006) consider both common and choice-specific instruments for both ordered
and unordered cases.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4913

4.1. IV in choice models
A key contribution of the analysis of Heckman and Vytlacil is to adjoin choice equation (3.3) to the outcome equations (2.1), (3.1) and (3.2). A standard binary threshold
cross model for D is D = 1(D ∗  0), where 1(·) is an indicator (1(A) = 1 if A is true,
0 otherwise). A familiar version of (3.3) sets μD (Z) = Zγ and writes
D ∗ = Zγ − V ,

(4.7)

where (V ⊥
⊥ Z) | X. (V is independent of Z given X.) In this notation, the propensity
score or choice probability is
P (z) = Pr(D = 1 | Z = z) = Pr(Zγ  V ) = FV (Zγ ),
where FV is the distribution of V which is assumed to be continuous. In terms of the
generalized Roy model where C is the cost of participation in sector 1, D = 1[Y1 −
Y0 − C > 0]. For a separable model in outcomes and in costs,
C = μD (W ) + UC ,
we have Z = (X, W ), μD (Z) = μ1 (X)−μ0 (X)−μD (W ), and V = −(U1 −U0 −UC ).
In constructing many of our examples, we work with a special version where UC = 0.
We call this version the extended Roy model.42 It is the model used to produce Figure 1.
Our analysis, however, applies to more general models, and we also offer examples of
generalized Roy models, as we have in Figure 2 and Table 3.
In the case where β (given X) is a constant, under (IV-1) and (IV-2) it is not necessary to specify the choice model to identify β. In a general model with heterogenous
responses, the specification of P (z) and its relationship with the instrument play crucial
roles. To see this, study the covariance between Z and ηD discussed in the introduction
to this section.43 By the law of iterated expectations, letting Z̄ denote the mean of Z,


Cov(Z, ηD) = E (Z − Z̄)Dη


= E (Z − Z̄)η D = 1 Pr(D = 1)


= E (Z − Z̄)η Zγ > V Pr(Zγ  V ).
Thus, even if Z and η are independent, they are not independent conditional on
D = 1[Zγ  V ] if η = (U1 − U0 ) is dependent on V (i.e., if the decision maker
has partial knowledge of η and acts on it). Selection models allow for this dependence
[see Heckman and Robb (1985a, 1986a), Ahn and Powell (1993), and Powell (1994)].
Keeping X implicit, assuming that
(U1 , U0 , V ) ⊥
⊥Z
42 Recall that the generalized Roy model has U ≡ 0, whereas the extended Roy model sets U = 0.
C
C
43 Recall that η = U − U .
1
0

(4.8)

4914

J.J. Heckman and E.J. Vytlacil

(alternatively, assuming that (ε, η) ⊥
⊥ Z), we obtain
E(Y | D = 0, Z = z) = E(Y0 | D = 0, Z = z)
= α + E(U0 | zγ < V ),
where α and possibly E(U0 | zγ < V ) depend on X, which can be written as


E(Y | D = 0, Z = z) = α + K0 P (z) ,
where the functional form of K0 is produced from the distribution of (U0 , V ).44 Focusing on means, the conventional selection approach models the conditional mean
dependence between (U0 , U1 ) and V .
Similarly,
E(Y | D = 1, Z = z) = E(Y1 | D = 1, Z = z)
= α + β̄ + E(U1 | zγ  V )


= α + β̄ + K1 P (z) ,
where α, β̄ and K1 (P (z)) may depend on X. K0 (P (z)) and K1 (P (z)) are control functions in the sense of Heckman and Robb (1985a, 1986a). The control functions expect
out the unobservables θ that give rise to selection bias (see (U-1)). Under standard
conditions developed in the literature, analysts can identify β̄. Powell (1994) discusses
semiparametric identification. Because we condition on Z = z (or P (z)), correct
specification of the Z plays an important role in econometric selection methods. This
sensitivity to the full set of instruments in Z appears to be absent from the IV method.
If β is a constant (given X), or if η (= β − β̄) is independent of V , only one instrument from vector Z needs to be used to identify the parameter. Missing or unused
instruments play no role in identifying mean responses but may affect the efficiency of
the IV estimators. In a model where β is variable and not independent of V , misspecification of Z plays an important role in interpreting what IV estimates analogous to its
role in selection models. Misspecification of Z affects both approaches to identification.
This is a new phenomenon in models with heterogenous β. We now review results from
the recent literature on instrumental variables in the model with essential heterogeneity.
4.2. Instrumental variables and local instrumental variables
In this section, we use MTE defined in Section 3 for a general nonseparable model
(3.1)–(3.3) to organize the literature on econometric evaluation estimators. In terms of
our simple regression model,
MTE (x, uD ) = E( | X = x, UD = uD )
44 This representation is derived in Heckman (1980), Heckman and Robb (1985a, 1986a), Ahn and Powell

(1993) and Powell (1994).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4915



= E β X = x, V = FV−1 (uD )
= β̄(x) + E(η | X = x, V = v),
where v = FV−1 (uD ). We assume policy invariance in the sense of Hurwicz for mean
parameters (assumption (A-7)). For simplicity, we suppress the a and a subscripts that
indicate specific policies. We focus primarily on instrumental variable estimators and
review the method of local instrumental variables. Section 4.1 demonstrated in a simple
but familiar case that well established intuitions about instrumental variable identification strategies break down when MTE is nonconstant in uD given X (β ⊥

⊥ D | X). We
acquire the probability of selection P (z) as a determinant of the IV covariance relationships.
Two sets of instrumental variable conditions are presented in the current literature
for this more general case: those associated with conventional instrumental variable
assumptions, which are implied by the assumption of “no selection on heterogenous
gains”, (β ⊥
⊥ D | X) and those which permit selection on heterogeneous gains. Neither
set of assumptions implies the other, nor does either identify the policy relevant treatment effect or other economically interpretable parameters in the general case. Each set
of conditions identifies different treatment parameters.
In place of standard instrumental variables methods, Heckman and Vytlacil (1999,
2001b, 2005) advocate a new approach to estimating policy impacts by estimating
MTE using local instrumental variables (LIV) to identify all of the treatment parameters from a generator MTE that can be weighted in different ways to answer
different policy questions. For certain classes of policy interventions covered by assumption (A-7) and analyzed in Section 6, MTE possesses an invariance property
analogous to the invariant parameters of traditional structural econometrics.
4.2.1. Conditions on the MTE that justify the application of conventional instrumental
variables
In the general case where MTE (x, uD ) is nonconstant in uD (E(β | X = x, V = v)
depends on v), IV does not in general estimate any of the treatment effects defined in
Section 3. We consider a scalar instrument J (Z) constructed from Z which may be
vector-valued. We sometimes denote J (Z) by J , leaving implicit that J is a function
of Z. If Z is a vector, J (Z) can be one coordinate of Z, say Z1 . We develop this particular case in presenting our examples.
The notation is sufficiently general to make J (Z) a general function of Z. The
standard conditions J (Z) ⊥
⊥ (U0 , U1 ) | X and Cov(J (Z), D | X) = 0 corresponding to (IV-1) and (IV-2), respectively, do not, by themselves, imply that instrumental
variables using J (Z) as the instrument will identify conventional or policy relevant
treatment effects. When responses to treatment are heterogenous, we must supplement
the standard conditions to identify interpretable parameters. To link our analysis to
conventional analyses of IV, we continue to invoke familiar-looking representations of
additive separability of outcomes in terms of (U0 , U1 ) so we invoke (2.2). This is not

4916

J.J. Heckman and E.J. Vytlacil

required. All derivations and results in this subsection hold without assuming additive
separability if μ1 (x) and μ0 (x) are replaced by E(Y1 | X = x) and E(Y0 | X = x),
respectively, and U1 and U0 are replaced by Y1 −E(Y1 | X) and Y0 −E(Y0 | X), respectively. This highlights the point that all of our analysis of IV is conditional on X and X
need not be exogenous with respect to (U0 , U1 ) to identify the MTE conditional on X.
To simplify the notation, we keep the conditioning on X implicit unless it is useful to
break it out separately.
Two distinct sets of instrumental variable conditions in the literature are those due
to Heckman and Robb (1985a, 1986a) and Heckman (1997), and those due to Imbens
and Angrist (1994) which we previously discussed. We review the conditions of Heckman and Robb (1985a, 1986a) and Heckman (1997) in Appendix L, which is presented
in the context of our discussion of matching in Section 8, where we compare IV and
matching. In the case where MTE is nonconstant in uD , standard IV estimates different parameters depending on which assumptions are maintained. We have already
shown that when responses to treatment are heterogeneous, and choices are made on
the basis of this heterogeneity, standard IV does not identify μ1 − μ0 = β̄.
There are two important cases of the variable response model. The first case arises
when responses are heterogeneous, but conditional on X, people do not base their participation on these responses. In this case, keeping the conditioning on X implicit,
(C-1) D ⊥
⊥  ⇒ E( | UD ) = E(), MTE (uD ) is constant in uD and
MTE

= ATE = TT = LATE , i.e., E(β | D = 1) = E(β), because
β⊥
⊥ D.
In this case, all mean treatment parameters are the same. The second case arises when
selection into treatment depends on β:
(C-2) D ⊥

⊥  and E( | UD ) = E() (i.e., β ⊥

⊥ D).
In this case, MTE is nonconstant, and in general, the treatment parameters differ among
each other. In this case (IV-1) and (IV-2) for general instruments do not identify β̄ (as
shown in Section 4.1) or E(β | D = 1).
A sufficient condition that generates (C-1) is the information condition that decisions
to participate in the program are not made on the basis of U1 − U0 (= η) (in the notation
of Section 4.1):
(I-1) Pr(D = 1 | Z, U1 − U0 ) = Pr(D = 1 | Z)
(i.e., Pr(D = 1 | Z, β) = Pr(D = 1 | Z)).45

45 Given the assumption that U − U is independent of Z (given X), (I-1) implies
1
0

E(U1 − U0 | Z, X, D = 1) = E(U1 − U0 | X) so that the weaker mean independence condition is certainly
satisfied:
(I-2) E(U1 − U0 | Z, X, D = 1) = E(U1 − U0 | X, D = 1),
which is generically necessary and sufficient for linear IV to identify TT and ATE .

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4917

Before we investigate what standard instrumental variables estimators identify, we
first present the local instrumental variables estimator which directly estimates the
MTE. It is a limit form of LATE.
4.2.2. Estimating the MTE using local instrumental variables
Heckman and Vytlacil (1999, 2001b, 2005) develop the local instrumental variable
(LIV) estimator to recover MTE pointwise. LIV is the derivative of the conditional
expectation of Y with respect to P (Z) = p. This is defined as
LIV (p) ≡

∂E(Y | P (Z) = p)
.
∂p

(4.9)

It is the population mean response to a policy change embodied in changes in P (Z) analyzed by Björklund and Moffitt (1987). E(Y | P (Z)) is well defined as a consequence
of assumption (A-4), and E(Y | P (Z)) can be recovered over the support of P (Z).46
Under our assumptions, LIV identifies MTE at all points of continuity in P (Z) (conditional on X). This expression does not require additive separability of μ1 (X, U1 ) or
μ0 (X, U0 ).47
Under standard regularity conditions, a variety of nonparametric methods can be used
to estimate the derivative of E(Y | P (Z)) and thus to estimate MTE . With MTE in
hand, if the support of the distribution of P (Z) conditional on X is the full unit interval,
one can generate all the treatment parameters defined in Section 3 as well as the policy
relevant treatment parameter presented in Section 3.2 as weighted versions of MTE .
When the support of the distribution of P (Z) conditional on X is not full, it is still possible to identify some parameters. Heckman and Vytlacil (2001b) show that to identify
ATE under assumptions (A-1)–(A-5), it is necessary and sufficient that the support of
the distribution of P (Z) include 0 and 1. Thus, identification of ATE does not require
that the distribution of P (Z) be the full unit interval or that the distribution of P (Z) be
continuous. But the support must include {0, 1}. Sharp bounds on the treatment parameters can be constructed under the same assumptions imposed in this chapter without
imposing full support conditions. The resulting bounds are simple and easy to apply

46 Assumptions (A-1), (A-3) and (A-4) jointly allow one to use Lebesgue’s theorem for the derivative of an
∂ E(Y | P (Z) = p)
integral to show that E(Y | P (Z) = p) is differentiable in p. Thus we can recover ∂p

for almost all p that are limit points of the support of the distribution of P (Z) (conditional on X = x).
For example, if the distribution of P (Z) conditional on X has a density with respect to Lebesgue measure,
then all points in the support of the distribution of P (Z) are limit points of that support and we can identify
LIV (p) = ∂E(Y |P∂p(Z)=p) for p (almost everywhere).
47 Note, however, that it does require the assumption of additive separability between U and Z in the latent
D
index for selection into treatment. Specifically, for LIV to identify MTE, we require additive separability in
the choice equation. See our discussion in Section 4.10.

4918

J.J. Heckman and E.J. Vytlacil

compared with those presented in the previous literature. We discuss these and other
bounds in Section 10.
To establish the relationship between LIV and ordinary IV based on P (Z) and to
motivate how LIV identifies MTE , notice that from the definition of Y , the conditional
expectation of Y given P (Z) is, recalling that  = Y1 − Y0 ,

E Y






P (Z) = p = E Y0 P (Z) = p + E  P (Z) = p, D = 1 p,

where we keep the conditioning on X implicit. Our model and conditional independence
assumption (A-1) imply

E Y


P (Z) = p = E(Y0 ) + E( | p  UD )p.

Applying the IV (Wald) estimator for two different values of P (Z), p and p , for p =
p , we obtain:
E(Y | P (Z) = p) − E(Y | P (Z) = p )
p−p
= ATE +

E(U1 − U0 | p  UD )p − E(U1 − U0 | p  UD )p
,
p−p

(4.10)

where this particular expression is obtained under the assumption of additive separability in the outcomes.48 ,49 Exactly the same equation holds without additive separability
if one replaces U1 and U0 with Y1 − E(Y1 | X) and Y0 − E(Y0 | X).
⊥ UD (case (C-1)), IV based on P (Z) estimates ATE
When U1 ≡ U0 or (U1 − U0 ) ⊥
because the second term on the right-hand side of the expression (4.10) vanishes. Otherwise, IV estimates a combination of MTE parameters which we analyze further below.
Assuming additive separability of the outcome equations, another representation of
E(Y | P (Z) = p) reveals the index structure. It writes (keeping the conditioning on X
implicit) that

E Y

P (Z) = p


p

= E(Y0 ) + ATE p +

E(U1 − U0 | UD = uD ) duD .

0

48 The Wald estimator is IV for two values of the instrument.
49 Observe that


E Y




P (z) = p = E Y0 + D(Y1 − Y0 ) P (z) = p
= μ0 + E(Y1 − Y0 | P (z) = p, D = 1) Pr(D = 1 | Z)
= μ0 + (μ1 − μ0 )p + E(U1 − U0 | p  UD )p.

(4.11)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4919

We can differentiate with respect to p and use LIV to identify MTE :
∂E(Y | P (Z) = p)
= ATE + E(U1 − U0 | UD = p).50
∂p
Notice that IV estimates ATE when E(Y | P (Z) = p) is a linear function of p so
the third term on the right-hand side of (4.11) vanishes. Thus a test of the linearity of
E(Y | P (Z) = p) in p is a test of the validity of linear IV for ATE , i.e., it is a test
of whether or not the data are consistent with a correlated random coefficient model
(β ⊥

⊥ D). The nonlinearity of E(Y | P (Z) = p) in p provides a way to distinguish
whether case (C-1) or case (C-2) describes the data. It is also a test of whether or not
agents can at least partially anticipate future unobserved (by the econometrician) gains
(the Y1 − Y0 given X) at the time they make their participation decisions. The levels and
derivatives of E(Y | P (Z) = p) and standard errors can be estimated using a variety
of semiparametric methods. Heckman, Urzua and Vytlacil (2006) present an algorithm
for estimating MTE using local linear regression.51
This analysis generalizes to the nonseparable outcomes case. We use separability
in outcomes only to simplify the exposition and link to more traditional models. In
particular, exactly the same expression holds with exactly the same derivation for the
nonseparable case if we replace U1 and U0 with Y1 − E(Y1 | X) and Y0 − E(Y0 | X),
respectively. This simple test for the absence of general heterogeneity based on linearity
of E(Y | Z) in P (Z) applies to the case of LATE for any pair of instruments. An
equivalent way is to check that all pairwise LATEs are the same over the sample support
of Z.52
Figure 3A plots two cases of E(Y | P (Z) = p) based on the generalized Roy model
used to generate the example in Figures 2A and 2B. Recall that in this model, there
are unobserved components of cost. When MTE (= E(β | X = x, V = v)) does
not depend on uD (or v) the expectation is a straight line. This is case (C-1). Figure 3B plots the derivatives of the two curves in Figure 3A. When MTE depends
on uD (or v) (case (C-2)), people sort into the program being studied positively on
the basis of gains from the program, and one obtains the curved line depicted in Figure 3A.
MTE (p) =

50 Making the conditioning on X explicit, we obtain that E(Y | X = x, P (Z) = p) = E(Y | X = x) +
0
p
ATE (x)p + 0 E(U1 − U0 | X = x, UD = uD ) duD , with derivative with respect to p given by
MTE (x, p).
51 Thus, one can apply any one of the large number of available tests for a parametric null versus a non-

parametric alternative [see, e.g., Ellison and Ellison (1999), Zheng (1996)]. With regressors, the null is
nonparametric leaving E(Y | X = x, P (Z) = p) unspecified except for restrictions on the partial derivatives with respect to p. In this case, the formal test is that of a nonparametric null versus a nonparametric
alternative, and a formal test of the null hypothesis can be implemented using the methodology of Chen and
Fan (1999).
52 Note that it is possible that E(Y | Z) is linear in P (Z) only over certain intervals of U , so there can be
D
local dependence and local independence of (U0 , U1 , UD ).

4920

J.J. Heckman and E.J. Vytlacil

Figure 3A. Plot of the E(Y | P (Z) = p). Source: Heckman and Vytlacil (2005).

4.3. What does linear IV estimate?
It is instructive to determine what linear IV estimates when MTE is nonconstant and
conditions (A-1)–(A-5) hold. We analyze the general nonseparable case. We consider
instrumental variables conditional on X = x using a general function of Z as an instrument. We then specialize our result using P (Z) as the instrument. As before, let J (Z)
be any function of Z such that Cov(J (Z), D) = 0. Define the IV estimator:
βIV (J ) ≡

Cov(J (Z), Y )
,
Cov(J (Z), D)

where to simplify the notation we keep the conditioning on X implicit. Appendix D
derives a representation of this expression in terms of weighted averages of the MTE
displayed in Table 2B. We exposit this expression in this section.
In Appendix D, we establish that


Cov J (Z), Y
1

=

 




MTE (uD )E J (Z) − E J (Z) P (Z)  uD Pr P (Z)  uD duD .

0

(4.12)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4921

Figure 3B. Plot of the identified marginal treatment effect from Figure 3A (the derivative). Source: Heckman
and Vytlacil (2005). Note: Parameters for the general heterogeneous case are the same as those used in Figures 2A and 2B. For the homogeneous case we impose U1 = U0 (σ1 = σ2 = 0.012).

By the law of iterated expectations, Cov(J (Z), D) = Cov(J (Z), P (Z)). Thus
1

βIV (J ) =

MTE (uD )ωIV (uD | J ) duD ,

0

where
ωIV (uD | J ) =

E(J (Z) − E(J (Z)) | P (Z)  uD ) Pr(P (Z)  uD )
,
Cov(J (Z), P (Z))

(4.13)

assuming the standard rank condition (IV-2) holds: Cov(J (Z), P (Z)) = 0. The weights
integrate to one,
1
0

ωIV (uD | J ) duD = 1,

4922

J.J. Heckman and E.J. Vytlacil

Figure 4A. MTE vs. linear instrumental variables, ordinary least squares, and policy relevant treatment effect
weights: when P (Z) is the instrument. The policy is given at the base of Table 3. The model parameters are
given at the base of Figure 2. Source: Heckman and Vytlacil (2005).

and can be constructed from the data on P (Z), J (Z) and D. Assumptions about the
properties of the weights are testable.53
We discuss additional properties of the weights for the special case where the propensity score is the instrument J (Z) = P (Z). We then analyze the properties of the weights
for a general instrument J (Z). When J (Z) = P (Z), Equation (4.13) specializes to
 [E(P (Z) | P (Z)  uD ) − E(P (Z))] Pr(P (Z)  uD )

ωIV uD P (Z) =
.
Var(P (Z))
Figure 4A plots the IV weight for J (Z) = P (Z) and the MTE for our generalized
Roy model example developed in Figures 2 and 3 and Table 3. The weights are positive
and peak at the mean of P . Figure 4A also plots the OLS weight given in Table 2 and
the weight for a policy exercise described below Table 3 and discussed further below.

53 Expressions for IV and OLS as weighted averages of marginal response functions, and the properties and

construction of the weights, were first derived by Yitzhaki in 1989 in a paper that was eventually published
in 1996 [see Yitzhaki (1996)]. Under monotonicity (IV-3), his expression is a weighted average of MTEs or
LATEs. We present Yitzhaki’s derivation in Appendix D.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4923

Let p Min and p Max denote the minimum and maximum points in the support of the
distribution of P (Z) (conditional on X = x). The weights on MTE when P (Z) is
the instrument are nonnegative for all evaluation points, are strictly positive for uD ∈
(p Min , p Max ) and are zero for uD < p Min and for uD > p Max .54
The properties of the weights for general J (Z) depend on the conditional relationship
between J (Z) and P (Z). From the general expression for (4.13), it is clear that the IV
estimator with J (Z) as an instrument satisfies the following properties:
(i) Two instruments J and J ∗ weight MTE equally at all values of uD if and only
if they have the same (centered) conditional expectation of J given P , i.e.,
E(J | P (Z) = p) − E(J ) = E(J ∗ | P (Z) = p) − E(J ∗ ) for all p in the
support of the distribution of P (Z).
(ii) The support of ωIV (uD | J ) is contained in [p Min , p Max ] the minimum and
maximum value of p in the population (given x). Therefore ωIV (t | J ) = 0
for t < p Min and for t > p Max . Using any instrument other than P (Z) leads to
nonzero weights only on a subset of [p Min , p Max ], and using the propensity score
as an instrument leads to nonnegative weights on a larger range of evaluation
points than using any other instrument.
(iii) ωIV (uD | J ) is nonnegative for all uD if E(J | P (Z)  p) is weakly monotonic
in p. Using J as an instrument yields nonnegative weights on MTE if
E(J | P (Z)  p) is weakly monotonic in p. This condition is satisfied when
J (Z) = P (Z). More generally, if J is a monotonic function of P (Z), then using J as the instrument will lead to nonnegative weights on MTE . There is no
guarantee that the weights for a general J (Z) will be nonnegative for all uD , although the weights integrate to unity and thus must be positive over some range
of evaluation points. We produce examples below where the instrument leads to
negative weights for some evaluation points. Imbens and Angrist (1994) assume
that J (Z) is monotonic in P (Z) and thus produce positive weights. Our analysis
is more general.

54 For u evaluation points between p Min and p Max , u ∈ (p Min , p Max ), we have that
D
D





E P (Z) P (Z)  uD > E P (Z)

and



Pr P (Z)  uD > 0,

so that ωIV (uD | P (Z)) > 0 for any uD ∈ (pMin , pMax ). For uD < pMin ,




E P (Z) P (Z)  uD = E P (Z) .
For any uD > pMax , Pr(P (Z)  uD ) = 0. Thus, ωIV (uD | P (Z)) = 0 for any uD < pMin and for any
uD > pMax . ωIV (uD | P (Z)) is strictly positive for uD ∈ (p Min , pMax ), and is zero for all uD < pMin
and all uD > pMax . Whether the weights are nonzero at the endpoints depends on the distribution of P (Z).
However, since the weights are defined for integration with respect to Lebesgue measure, the value taken by
the weights at p Min and pMax does not affect the value of the integral.

4924

J.J. Heckman and E.J. Vytlacil

The propensity score plays a central role in determining the properties of the weights.
The IV weighting formula critically depends on the conditional mean dependence between instrument J (Z) and the propensity score.
The interpretation placed on the IV estimand depends on the specification of P (Z)
even if only Z1 (e.g., the first coordinate of Z) is used as the instrument. This drives
home the point about the difference between IV in the traditional model and IV in
the more general model with heterogeneous responses analyzed in this chapter. In the
traditional model, the choice of any valid instrument and the specification of instruments in P (Z) not used to construct a particular IV estimator does not affect the IV
estimand. In the more general model, these choices matter. Two economists, using the
same J (Z) = Z1 , will obtain the same IV point estimate, but the interpretation placed
on that estimate will depend on the specification of the Z in P (Z) even if P (Z) is not
used as an instrument. The weights can be positive for one instrument and negative for
another. We show some examples after developing the properties of the IV weights.
4.3.1. Further properties of the IV weights
Expression (4.13) for the weights does not impose any support conditions on the distribution of P (Z), and thus does not require either that P (Z) be continuous or discrete.
To demonstrate this, consider two extreme special cases: (i) when P (Z) is a continuous
random variable, and (ii) when P (Z) is a discrete random variable.
To simplify the exposition, initially assume that J (Z) and P (Z) are jointly continuous random variables. This assumption plays no essential role in any of the results of
this chapter and we develop the discrete case after developing the continuous case. The
weights defined in Equation (4.13) can be written as
ωIV (uD ) =

(j − E(J (Z)))

1
uD

fJ,P (j, t) dt dj

Cov(J (Z), D)

,

(4.14)

where fJ,P is the joint density of J (Z) and P (Z) and we implicitly condition on X.
The weights can be negative or positive. Observe that ω(0) = 0 and ω(1) = 0. The
weights integrate to 1 because as shown in Appendix D,




j − E J (Z)

1



fJ,P (j, t) dt dj duD = Cov J (Z), D ,

uD

so even if the weight is negative over some intervals, it must be positive over other
intervals. Observe that when there is one instrument (Z is a scalar), and assumptions
(A-1)–(A-5) are satisfied, the weights are always positive provided J (Z) is a monotonic
function of the scalar Z. In this case, which is covered by (4.13) but excluded in deriving
(4.14), J (Z) and P (Z) have the same distribution and fJ,P (j, t) collapses to a univariate distribution. The possibility of negative weights arises when J (Z) is not a monotonic
function of P (Z). It also arises when there are two or more instruments, and the analyst
computes estimates with only one instrument or a combination of the Z instruments that

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4925

is not a monotonic function of P (Z) so that J (Z) and P (Z) are not perfectly dependent.
If the instrument is P (Z) (so J (Z) = P (Z)) then the weights are everywhere nonnegative because from (4.14), E(P (Z) | P (Z) > uD ) − E(P (Z))  0. In this case, the
density of (P (Z), J (Z)) collapses to the density of P (Z). For any scalar Z, we can define J (Z) and P (Z) so that they are perfectly dependent, provided that J (Z) and P (Z)
are monotonic in Z. Generally, the weight (4.13) is positive if E(J (Z) | P (Z) > uD )
is weakly monotonic in uD . Nonmonotonicity of this expression can produce negative
weights.55
4.3.2. Constructing the weights from data
Observe that the weights can be constructed from data on (J, P , D). Data on
(J (Z), P (Z)) pairs and (J (Z), D) pairs (for each X value) are all that is required.
We can use a smoothed sample frequency to estimate the joint density fJ,P . Thus,
given our maintained assumptions, any property of the weight, including its positivity
at any point (x, uD ), can be examined with data. We present examples of this approach
below.
As is evident from Tables 2A and 2B and Figures 2A and 2B, the weights on
MTE (uD ) generating IV are different from the weights on MTE (uD ) that generate
the average treatment effect which is widely regarded as an important policy parameter [see, e.g., Imbens (2004)] or from the weights associated with the policy relevant
treatment parameter which answers well-posed policy questions [Heckman and Vytlacil
(2001b, 2005)]. It is not obvious why the weighted average of MTE (uD ) produced by
IV is of any economic interest. Since the weights can be negative for some values of
uD , MTE (uD ) can be positive everywhere in uD but IV can be negative. Thus, IV may
not estimate a treatment effect for any person. We present some examples of IV models
with negative weights below. A basic question is why estimate the model with IV at all
given the lack of any clear economic interpretation of the IV estimator in the general
case.
4.3.3. Discrete instruments
The representation (4.13) can be specialized to cover discrete instruments, J (Z). Consider the case where the distribution of P (Z) (conditional on X) is discrete. The support
of the distribution of P (Z) contains a finite number of values p1 < p2 < · · · < pK
and the support of the instrument J (Z) is also discrete taking I distinct values where
I and K may be distinct. E(J (Z) | P (Z)  uD ) is constant in uD , for uD within any
(p , p+1 ) interval, and Pr(P (Z)  uD ) is constant in uD , for uD within any (p , p+1 )
J (u ) is constant in u over any (p , p
interval, and thus ωIV
D
D

+1 ) interval. Let λ denote
55 If it is weakly monotonically increasing, the claim is evident from (4.13). If it is decreasing, the sign of the

numerator and the denominator are both negative so the weight is nonnegative.

4926

J.J. Heckman and E.J. Vytlacil

the weight on LATE for the interval (,  + 1). In this notation,
IV
J =
=

J
E(Y1 − Y0 | UD = uD )ωIV
(uD ) duD
K−1

=1

=

K−1


p+1

λ

E(Y1 − Y0 | UD = uD )

p

LATE (p , p+1 )λ .

1
duD
(p+1 − p )
(4.15)

=1

Let ji be the ith smallest value of the support of J (Z). The discrete version of Equation (4.13) is
K
I
i=1 (ji − E(J (Z)))
t> (f (ji , pt ))
(p+1 − p ),
λ =
(4.16)
Cov(J (Z), D)
where f is the probability frequency of (ji , pt ): the probability that J (Z) = ji and
P (Z) = pt . There is no presumption that high values of J (Z) are associated with high
values of P (Z). J (Z) can be one coordinate of Z that may be positively or negatively
dependent on P (Z), which depends on the full vector. In the case of scalar Z, as long
as J (Z) and P (Z) are monotonic in Z there is perfect dependence between J (Z) and
P (Z). In this case, the joint probability density collapses to a univariate density and the
weights have to be positive, exactly as in the case for continuous instruments previously
discussed. Our expression for the weight on LATE generalizes the expression presented
by Imbens and Angrist (1994) who in their analysis of the case of vector Z only consider
the case where J (Z) and P (Z) are perfectly dependent because J (Z) is a monotonic
function of P (Z).56 More generally, the weights can be positive or negative for any 
but they must sum to 1 over all .
Monotonicity or uniformity is a property needed with just two values of Z, Z = z1
and Z = z2 , to guarantee that IV estimates a treatment effect. With more than two
values of Z, we need to weight the LATEs and MTEs. If the instrument J (Z) shifts
P (Z) in the same way for everyone, it shifts D in the same way for everyone since
D = 1[P (Z)  UD ] and Z is independent of UD . If J (Z) is not monotonic in P (Z), it
may shift P (Z) in different ways for different people. Negative weights are a tip-off of
two-way flows. We present examples below.
4.3.4. Identifying margins of choice associated with each instrument and unifying
diverse instruments within a common framework
We have just established that different instruments weight the MTE differently. Using
P (Z) in the local IV estimator, we can identify the MTE. We can construct the weights
56 In their case, I = K and f (j , p ) = 0, ∀i = t.
i t

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4927

associated with each instrument from the joint distribution of (J (Z), P (Z)) given X.
By plotting the weights for each instrument, we can determine the margins identified
by the different instruments. Using P (Z) as the instrument enables us to extend the
support associated with any single instrument, and to determine which segment of the
MTE is identified by any particular instrument. As before, we keep conditioning on X
implicit.
4.3.5. Yitzhaki’s derivation of the weights
An alternative and in some ways more illuminating way to derive the weights used in
IV is to follow Yitzhaki (1989, 1996) and Yitzhaki and Schechtman (2004) who prove
for a general regression function E(Y | P (Z) = p) that a linear regression of Y on P
estimates
1

βY,P =
0

∂E(Y | P (Z) = p)
ω(p) dp,
∂p

where
ω(p) =

1
p (t

− E(P )) dFP (t)
Var(P )

,

which is exactly the weight (4.13) when P is the instrument. Thus we can interpret
(4.13) as the weight on ∂E(Y |P∂p(Z)=p) when two-stage least squares (2SLS) based on
P (Z) is used to estimate the “causal effect” of D on Y . Under uniformity,
∂E(Y | P (Z) = p)
∂p

= E(Y1 − Y0 | UD = uD ) = MTE (uD ).57
p=uD

Our analysis is more general than that of Yitzhaki (1989) or Imbens and Angrist (1994)
because we allow for instruments that are not monotonic functions of P (Z), whereas
the Yitzhaki weighting formula only applies to instruments that are monotonic functions of P (Z).58 The analysis of Yitzhaki (1989) is more general than that of Imbens
and Angrist (1994), because he does not impose uniformity (monotonicity). We present
some further examples of these weights after discussing the role of P (Z) and the role
of monotonicity and uniformity. We present Yitzhaki’s Theorem and the relationship of
our analysis to Yitzhaki’s analysis in Appendices D.1 and D.2.

57 Yitzhaki’s weights are used by Angrist and Imbens (1995) to interpret what 2SLS estimates in the model

of Equation (4.1) with heterogeneous β. Yitzhaki (1989) derives the finite sample weights used by Imbens
and Angrist. See the refinement in Yitzhaki and Schechtman (2004).
58 Heckman and Vytlacil (2001b) generalize the Yitzhaki analysis of the IV weights by relaxing separability
(monotonicity).

4928

J.J. Heckman and E.J. Vytlacil

4.4. The central role of the propensity score
Observe that both (4.13) and (4.14) (and their counterparts for LATE (4.15) and (4.16))
contain expressions involving the propensity score P (Z), the probability of selection
into treatment. Under our assumptions, it is a monotonic function of the mean utility of
treatment, μD (Z). The propensity score plays a central role in selection models as a determinant of control functions in selection models [Heckman and Robb (1985a, 1986a)]
as noted in Section 4.1. In matching models, it provides a computationally convenient
way to condition on Z [see, e.g., Rosenbaum and Rubin (1983), Heckman and Navarro
(2004), and the discussion in Section 8]. For the IV weight to be correctly constructed
and interpreted, we need to know the correct model for P (Z), i.e., we need to know
exactly which Z determine P (Z). As previously noted, this feature is not required in
the traditional model for instrumental variables based on response heterogeneity. In that
simpler framework, any instrument will identify μ1 (X)−μ0 (X) and the choice of a particular instrument affects efficiency but not identifiability. One can be casual about the
choice model in the traditional setup, but not in the model of choice of treatment with
essential heterogeneity. Thus, unlike the application of IV to traditional models under
condition (C-1), IV applied in the model of essential heterogeneity depends on (a) the
choice of the instrument J (Z), (b) its dependence with P (Z), the true propensity score
or choice probability, and (c) the specification of the propensity score (i.e., what variables go into Z). Using the propensity score one can identify LIV and LATE and the
marginal returns at values of the unobserved UD . From the MTE identified by P (Z) and
the weights that can be constructed from the joint distribution of (J (Z), P (Z)) given X,
we can identify the segment of the MTE identified by any IV.
4.5. Monotonicity, uniformity and conditional instruments
Monotonicity, or uniformity condition (IV-3), is a condition on a collection of counterfactuals for each person and hence is not testable, since we know only one element
of the collection for any person. It rules out general heterogeneous responses to treatment choices in response to changes in vector Z. The recent literature on instrumental
variables with heterogeneous responses is thus asymmetric. Outcome equations can be
heterogeneous in a general way while choice equations cannot be. If μD (Z) = Zγ ,
where γ is a common coefficient shared by everyone, the choice model satisfies the
uniformity property. On the other hand, if γ is a random coefficient (i.e., has a nondegenerate distribution) that can take both negative and positive values, and there are two
or more variables in Z with nondegenerate γ coefficients, uniformity can be violated.
Different people can respond to changes in Z differently, so there can be nonuniformity.
The uniformity condition can be violated even when all components of γ are of the
same sign if Z is a vector and γ is a nondegenerate random variable.59
59 Thus if γ > 0 for each component and some components of Z are positive and others are negative, changes

from z to z can increase γ Z for some and decrease γ Z for others since the γ are different among persons.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4929

Changing one coordinate of Z, holding the other coordinates at different values across
people is not the experiment that defines monotonicity or uniformity. Changing one
component of Z, allowing the other coordinates of Z to vary across people, does not
necessarily produce uniform flows toward or against participation in the treatment status. For example, let μD (z) = γ0 + γ1 z1 + γ2 z2 + γ3 z1 z2 , where γ0 , γ1 , γ2 and γ3 are
constants, and consider changing z1 from a common base state while holding z2 fixed
at different values across people. If γ3 < 0, then μD (z) does not necessarily satisfy the
uniformity condition. If we move (z1 , z2 ) as a pair from the same base values to the
same destination values z , uniformity is satisfied even if γ3 < 0, although μD (z) is not
a monotonic function of z.60
Positive weights and uniformity are distinct issues.61 Under uniformity, and assumptions (A-1)–(A-5), the weights on MTE for any particular instrument may be positive or
negative. The weights for MTE using P (Z) must be positive as we have shown so the
propensity score has a special status as an instrument. Negative weights associated with
the use of J (Z) as an instrument do not necessarily imply failure of uniformity in Z.
Even if uniformity is satisfied for Z, it is not necessarily satisfied for J (Z). Condition
(IV-3) is an assumption about a vector. Fixing one combination of Z (when J is a function of Z) or one coordinate of Z does not guarantee uniformity in J even if there is
uniformity in Z. The flow created by changing one coordinate of Z can be reversed by
the flow created by the other components of Z if there is negative dependence among
components even if ceteris paribus all components of Z affect D in the same direction.
We present some examples below.
The issues of positive weights and the existence of one way flows in response to an
intervention are conceptually distinct. Even with two values for a scalar Z, flows may
be two way [see Equation (4.5)]. If we satisfy (IV-3) for a vector, so uniformity applies,
weights for a particular instrument may be negative for certain intervals of UD (i.e., for
some of the LATE parameters).
60 Associated with Z = z is the counterfactual random variable D(z). Associated with the scalar ran-

dom variable J (Z) constructed from Z is a counterfactual random variable D(j (z)) which is in general
different from D(z). The random variable D(z) is constructed from (3.3) using 1[μD (z)  V ]. In this expression, V assumes individual specific values which remain fixed as we set different z values. From (A-1),
Pr(D(z) = 1) = Pr(D = 1 | Z = z). The random variable D(j ) is defined by the following thought experiment. For each possible realization j of J (Z), define D(j ) by setting D(j ) = D(Z(j )) where Z(j ) is a
random draw from the distribution of Z conditional on J (Z) = j . Set D(j ) equal to the choice that would be
made given that draw of Z(j ). Thus D(j ) is a function of (Z(j ), uD ). As long as we draw Z(j ) randomly (so
⊥ Z so D(j ) ⊥
⊥ Z. There are other possible constructions of the
independent of Z), we have that (Z(j ), UD ) ⊥
counterfactual D(j ) since there are different possible distributions from which Z can be drawn, apart from
the actual distribution of Z. The advantage of this construction is that it equates the counterfactual probability
that D(j ) = 1 given J (Z) = j with the population probability. If the Z were uncertain to the agent, this
would be a rational expectations assumption. At their website, Heckman, Urzua and Vytlacil (2006) discuss
this assumption further.
61 When they analyze the vector case, Imbens and Angrist (1994) analyze instruments that are monotonic
functions of P (Z). Our analysis is more general and recognizes that, in the vector case, IV weights may be
negative or positive.

4930

J.J. Heckman and E.J. Vytlacil

If we condition on Z2 = z2 , . . . , ZK = zK using Z1 as an instrument, then a
uniform flow condition is satisfied. We call this conditional uniformity. By conditioning,
we effectively convert the problem back to that of a scalar instrument where the weights
must be positive. If uniformity holds for Z1 , fixing the other Z at common values, then
one-dimensional LATE/MTE analysis applies. Clearly, the weights have to be defined
conditionally.
The concept of conditioning on other instruments to produce positive weights for the
selected instrument is a new idea, not yet appreciated in the empirical IV literature and
has no counterpart in the traditional IV model. In the conventional model, the choice of
a valid instrument affects efficiency but not the definition of the parameters as it does in
the more general case.62
In summary, nothing in the economics of choice guarantees that if Z is changed
from z to z , that people respond in the same direction to the change. See the general
expression (4.5). The condition that people respond to choices in the same direction
for the same change in Z does not imply that D(z) is monotonic in z for any person
in the usual mathematical usage of the term monotonicity. If D(z) is monotonic in the
usual usage of this term and responses are in the same direction for all people, then
“monotonicity” or better “uniformity” condition (IV-3) would be satisfied.
If responses to a common change of Z are heterogenous in a general way, we obtain (4.5) as the general case. Vytlacil’s 2002 Theorem breaks down and IV cannot be
expressed in terms of a weighted average of MTE terms. Nonetheless, Yitzhaki’s char|P =p)
acterization of IV, derived in Appendix D, remains valid and the weights on ∂E(Y∂p
are positive and of the same form as the weights obtained for MTE (or LATE) when
the monotonicity condition holds. IV can still be written as a weighted average of LIV
terms, even though LIV does not identify the MTE.
4.6. Treatment effects vs. policy effects
Even if uniformity condition (IV-3) fails, IV may answer relevant policy questions.
By Yitzhaki’s analysis, summarized in Section 4.3.5, IV or 2SLS estimates a weighted
average of marginal responses which may be pointwise positive or negative. Policies
may induce some people to switch into and others to switch out of choices, as is evident
from Equation (4.5). These net effects are of interest in many policy analyses. Thus,
subsidized housing in a region supported by higher taxes may attract some to migrate to
the region and cause others to leave. The net effect from the policy is all that is required
to perform cost benefit calculations of the policy on outcomes. If the housing subsidy is
the instrument, and the net effect of the subsidy is the parameter of interest, the issue of
monotonicity is a red herring. If the subsidy is exogenously imposed, IV estimates the
62 In the conventional model, with homogenous responses, a linear probability approximation to P (Z) used

as an instrument would identify the same parameter as P (Z). In the general model, replacing P (Z) by a linear
probability approximation of it (e.g., E(D | Z) = π Z = J (Z)) is not guaranteed to produce positive weights
for MTE (x, uD ) or LATE (x, uD , uD ), or to replicate the weights based on the correctly specified P (Z).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4931

net effect of the policy on mean outcomes. Only if the effect of migration on outcomes
induced by the subsidy on outcomes is the question of interest, and not the effect of the
subsidy, does uniformity emerge as an interesting condition.
4.7. Some examples of weights in the generalized Roy model and the extended Roy
model
It is useful to develop intuition about the properties of the IV estimator and the structure
of the weights for two prototypical choice models. We develop the weights for a generalized Roy model where unobserved cost components are present and an extended Roy
model where cost components are observed but there are no unobserved cost components. The extended Roy model is used to generate Figure 1 and was introduced at the
end of Section 2.
Table 3 presents the IV estimand for the generalized Roy model used to generate Figures 2A and 2B using P (Z) as the instrument. The model generating D = 1[Zγ  V ]
is given at the base of Figure 2B (Z is a scalar, γ is 1, V is normal, UD = Φ( σVV )). We
compare the IV estimand with the policy relevant treatment effect for a policy precisely
defined at the base of Table 3. This policy has the structure that if Z > 0, persons get a
bonus Zt for participation in the program, where t > 0. The decision rule for program
participation for Z > 0 is D = 1[Z(1+t)  V ]. People are not forced into participation
in the program but are rather induced into it by the bonus. Given the assumed distribution of Z, and the other parameters of the model, we obtain the policy relevant treatment
parameter weight ωPRTE (uD ) as plotted in Figures 4A–4C (the scales of the ordinates
differ across the graphs, but the weight is the same). We use the per capita PRTE and
consider three instruments. Table 5 presents estimands for the three instruments shown
in the table for the generalized Roy model in three environments.
The first instrument we consider for this example is P (Z), which assumes that there
is no policy in place (t = 0). It is identified (estimated) on a sample with no policy in place but otherwise the model is the same as the one with the policy in place.
The weight on this instrument is plotted in Figure 4A. That figure also displays the
OLS weight as well as the MTE that is being weighted to generate the estimate. It also
shows the weight used to generate PRTE. The IV weights for P (Z) and the weights
for PRTE differ. This is as it should be because PRTE is making a comparison across
regimes but the IV in this case makes comparisons within a no policy regime. Given
the shape of MTE (uD ), it is not surprising that the estimand for IV based on P (Z) is
so much above the PRTE which weights a lower-valued segment of MTE (uD ) more
heavily.63
The second instrument we consider exploits the variation induced by the policy in
place and fits it on samples where the policy is in place (i.e., the t is the same as that

63 Heckman and Vytlacil (2005) show how to construct the proper instrument for such policies using a pre-

policy sample.

4932

J.J. Heckman and E.J. Vytlacil

Figure 4B. MTE vs. linear IV with P (Z(1 + t (1[Z > 0]))) = P̃ (z, t) as an instrument, and policy relevant
treatment effect weights for the policy defined at the base of Table 3. The model parameters are given at the
base of Figure 2. Source: Heckman and Vytlacil (2005).

used to generate the PRTE). On intuitive grounds, this instrument might be thought to
work well in identifying the PRTE, but in fact it does not. The instrument is P̃ (Z, t) =
P (Z(1 + t1[Z > 0])) which jumps in value when Z switches from Z < 0 to Z > 0.
This is the choice probability in the regime with the policy in place. Figure 4B plots the
weight for this IV along with the weight for P (Z) as an IV and the weight for PRTE
(repeated from Figure 4A).64 While this weight looks a bit more like the weight for
PRTE than the previous instrument, it is clearly different.
Figure 4C plots the weight for an ideal instrument for PRTE: a randomization of
eligibility. This compares the outcomes in one population where the policy is in place
with outcomes in a regime where the policy is not in place. Thus we use an instrument
B such that

1 if a person is eligible to participate in the program,
B=
0 otherwise.
Persons for whom B = 1, make their participation choices under the policy with a
jump in Z, t1(Z > 0), in their choice sets.65 If B = 0, persons are embargoed from
64 Remember that the scales are different across the two graphs.
65 Recall that, in this example, we set γ = 1.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4933

Figure 4C. MTE vs. IV policy and policy relevant treatment effect weights for the policy defined at the base
of Table 3. Source: Heckman and Vytlacil (2005).

the policy and cannot receive a bonus. The B = 0 case is a prepolicy regime. We
assume Pr[B = 1 | Y0 , Y1 , V , Z] = Pr[B = 1] = 0.5, so all persons are equally likely
to receive or not receive eligibility for the bonus and assignment does not depend on
model unobservables in the outcome equation.
The Wald estimator in this case is
E(Y | B = 1) − E(Y | B = 0)
.
Pr(D = 1 | B = 1) − Pr(D = 1 | B = 0)
Table 5
Linear instrumental variable estimands and the policy relevant treatment effect
Using propensity score P (Z) as the instrument
Using propensity score P (Z(1 + t (1[Z > 0]))) as the instrument
Using a dummy B as an instrumenta
Policy relevant treatment effect (PRTE)

0.2013
0.1859
0.1549
0.1549

Source: Heckman and Vytlacil (2005).
a The dummy B is such that B = 1 if an individual belongs to a randomly assigned
eligible population, 0 otherwise.

4934

J.J. Heckman and E.J. Vytlacil

The IV weight for this estimator is a special case of Equation (4.13):
ωIV (uD | B) =

E(B − E(B) | P̂ (Z)  uD ) Pr(P̂ (Z)  uD )
Cov(B, P̂ (Z))

,

where P̂ (Z) = P (Z(1+t1[Z > 0]))B P (Z)(1−B) . Here, the IV is eligibility for a policy
and IV is equivalent to a social experiment that identifies the mean gain per participant
who switches to participation in the program. It is to be expected that this IV weight
and ωPRTE are identical.
4.7.1. Further examples within the extended Roy model
To gain a further understanding of how to construct the weights, and to understand how
negative weights can arise, it is useful to return to the policy adoption model presented at
the end of Section 2. The only unobservables in this model are in the outcome equations.
To simplify the analysis, we use an extended Roy model where the only unobservables
are the unmeasured gains.
In this framework, the cost C of adopting the policy is the same across all countries.
Countries choose to adopt the policy if D ∗ > 0 where D ∗ is the net benefit of adoption:
D ∗ = (Y1 − Y0 − C) and ATE = E(β) = E(Y1 − Y0 ) = μ1 − μ0 , while treatment on
the treated is E(β | D = 1) = E(Y1 − Y0 | D = 1) = μ1 − μ0 + E(U1 − U0 | D = 1).
In this setting, the gross return to the country at the margin is C, i.e., E(Y1 − Y0 |
D ∗ = 0) = E(Y1 − Y0 | Y1 − Y0 = C) = C. Recall that Figure 1 presents the standard
treatment parameters for the values of the choice parameter presented at the base of
the figure. Countries that adopt the policy are above average. In a model where the
cost varies (the generalized Roy model with UC = 0), and C is negatively correlated
with the gain, adopting countries could be below average.66 We consider cases with
discrete instruments and cases with continuous instruments. We first turn to the discrete
case.
4.7.2. Discrete instruments and weights for LATE
Consider what instrumental variables identify in the model of country policy adoption
presented below Figure 5. That figure presents three cases that we analyze in this section. Let cost C = Zγ where instrument Z = (Z1 , Z2 ). Higher values of Z reduce the
probability of adopting the policy if γ  0, component by component.
Consider the “standard” case depicted in Figure 5A. Increasing both components of
discrete-valued Z raises costs and hence raises the benefit observed for the country at the
margin by eliminating adoption in low return countries. It also reduces the probability
that countries adopt the policy. In general a different country is at the margin when
different instruments are used.
66 See, e.g., Heckman (1976a, 1976c) and Willis and Rosen (1979).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4935

Figure 5. Monotonicity: The extended Roy economy. Source: Heckman, Urzua and Vytlacil (2006).

4936

J.J. Heckman and E.J. Vytlacil
Outcomes
Y1 = α + β̄ + U1
Y0 = α + U0

(U1 , U0 ) ∼ N (0, Σ), Σ =

1
−0.9

Choice model
1 if Y1 − Y0 − γ Z  0,
0 if Y1 − Y0 − γ Z < 0
with γ Z = γ1 Z1 + γ2 Z2
Parameterization


D=

−0.9
, α = 0.67, β̄ = 0.2, γ = (0.5, 0.5) (except in Case C)
1

Z1 = {−1, 0, 1} and Z2 = {−1, 0, 1}
A. Standard case

B. Changing Z1 without
controlling for Z2

C. Random coefficient case

z→z
z = (0, 1) and z = (1, 1)

z → z or z → z
z = (0, 1), z = (1, 1) and
z = (1, −1)

z→z
z = (0, 1) and z = (1, 1)

D(γ z)  D(γ z )
For all individuals

D(γ z)  D(γ z ) or
D(γ z) < D(γ z )
Depending on the value
of z or z

γ is a random vector
γ̃ = (0.5, 0.5) and γ̃˜ = (−0.5, 0.5)
where γ̃ and γ̃˜ are two realizations of γ
D(γ̃˜ z)  D(γ̃˜ z ) and D(γ̃ z) < D(γ̃ z )
Depending on value of γ

Figure 5. (Continued)

Figure 6A plots the weights and Figure 6B plots the components of the weights for
the LATE values using P (Z) as an instrument for the distribution of discrete Z values
shown at the base of the figure. Figure 6C presents the LATE parameter derived using
P (Z) as an instrument. The weights are positive as predicted from Equation (4.5) when
J (Z) = P (Z). Thus, the monotonicity condition for the weights in terms of uD is
satisfied. The outcome and choice parameters are the same as those used to generate
Figures 1 and 5. The LATE parameters for each interval of P values are presented in a
table just below the figures. There are four LATE parameters corresponding to the five
distinct values of the propensity score for that value. The LATE parameters exhibit the
declining pattern with uD predicted by the Roy model.
A case producing negative weights is depicted in Figure 5B. In that graph, the same
Z is used to generate the choices as is used to generate Figure 1B. However, in this
case, the analyst uses Z1 as the instrument. Z1 and Z2 are negatively dependent and
E(Z1 | P (Z) > uD ) is not monotonic in uD . This nonmonotonicity is evident in
Figure 7B. It produces the pattern of negative weights shown in Figure 7A. These are
associated with two way flows. Increasing Z1 controlling for Z2 reduces the probability
of country policy adoption. However, we do not condition on Z2 in constructing this
figure. Z2 is floating. Two way flows are induced by uncontrolled variation in Z2 . For
some units, the strength of the associated variation in Z2 offsets the increase in Z1 and
for other units it does not. Observe that the LATE parameters defined using P (Z) are
the same in both examples. They are just weighted differently. We discuss the random
coefficient choice model generating Figure 5C in Section 4.10.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4937

Figure 6. IV weights and its components under discrete instruments when P (Z) is the instrument, the extended Roy economy. Source: Heckman, Urzua and Vytlacil (2006).

The IV estimator does not identify ATE, TT or TUT (given at the bottom of Figure 6C). Conditioning on Z2 produces positive weights. This is illustrated in the weights
shown in Table 6 that condition on Z2 using the same model that generated Figure 6.
Conditioning on Z2 effectively converts the problem back into one with a scalar instrument and the weights are positive for that case.
From Yitzhaki’s analysis, for any sample size, a regression of Y on P identifies a
weighted average of slopes based on ordered regressors:
E(Y | p ) − E(Y−1 | p−1 )
,
p − p−1

4938

J.J. Heckman and E.J. Vytlacil

The model is the same as the one presented below Figure 5.
ATE = 0.2, TT = 0.5942, TUT = −0.4823 and IV
P (Z) =

K−1


LATE (p , p+1 )λ = −0.09

=1

E(Y | P (Z) = p+1 ) − E(Y | P (Z) = p )
LATE (p , p+1 ) =
p+1 − p
β̄(p+1 − p ) + σU1 −U0 (φ(Φ −1 (1 − p+1 )) − φ(Φ −1 (1 − p )))
=

p+1 − p

(pi − E(P (Z))) K
t> f (pi , pt )
λ = (p+1 − p ) i=1
Cov(Z1 , D)
K
(pt − E(P (Z)))f (pt )
= (p+1 − p ) t>
Cov(Z1 , D)
K

Joint probability distribution of (Z1 , Z2 ) and the propensity score (joint probabilities in ordinary type
(Pr(Z1 = z1 , Z2 = z2 )); propensity score in italics (Pr(D = 1 | Z1 = z1 , Z2 = z2 )))
Z1 \Z2

−1

0

1

−1

0.02
0.7309
0.3
0.6402
0.2
0.5409

0.02
0.6402
0.01
0.5409
0.05
0.4388

0.36
0.5409
0.03
0.4388
0.01
0.3408

0
1
Cov(Z1 , Z2 ) = −0.5468

Figure 6. (Continued)

where p > p−1 and the weights are the positive Yitzhaki–Imbens–Angrist weights
derived in Yitzhaki (1989, 1996) or in Yitzhaki and Schechtman (2004). The weights
are positive whether or not monotonicity condition (IV-3) holds. If monotonicity holds,
IV is a weighted average of LATEs. Otherwise it is just a weighted average of ordered

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4939

Table 6
The conditional instrumental variable estimator (IV
Z1 |Z2 =z2 ) and conditional
local average treatment effect (LATE (p , p+1 | Z2 = z2 )) when Z1 is the
instrument (given Z2 = z2 )
The extended Roy economy
Z2 = −1

Z2 = 0

Z2 = 1

P (−1, Z2 ) = p3
P (0, Z2 ) = p2
P (1, Z2 ) = p1

0.7309
0.6402
0.5409

0.6402
0.5409
0.4388

0.5409
0.4388
0.3408

λ1
λ2

0.8418
0.1582

0.5384
0.4616

0.2860
0.7140

LATE (p1 , p2 )
LATE (p2 , p3 )

−0.2475
−0.7448

0.2497
−0.2475

0.7470
0.2497

IV
Z1 |Z2 =z2

−0.3262

0.0202

0.3920

The model is the same as the one presented below Figure 2.
I
−1
I
−1
LATE (p , p
IV
=

|
Z
=
z
)λ
=
LATE (p , p+1 | Z2 = z2 )λ|Z2 =z2

|Z
=z
+1
2
2
Z1 |Z2 =z2
2 2
=1

=1

E(Y | P (Z) = p+1 , Z2 = z2 ) − E(Y | P (Z) = p , Z2 = z2 )
LATE (p , p+1 | Z2 = z2 ) =
p+1 − p

I
(z1,i − E(Z1 | Z2 = z2 )) It> f (z1,i , pt | Z2 = z2 )
λ|Z2 =z2 = (p+1 − p ) i=1
Cov(Z1 , D)
I
(z1,t − E(Z1 | Z2 = z2 ))f (z1,t , pt | Z2 = z2 )
= (p+1 − p ) t>
Cov(Z1 , D)
Probability distribution of Z1 conditional on Z2 (Pr(Z1 = z1 | Z2 = z2 ))
z1

Pr(Z1 = z1 | Z2 = −1)

Pr(Z1 = z1 | Z2 = 0)

Pr(Z1 = z1 | Z2 = 1)

−1
0
1

0.0385
0.5769
0.3846

0.25
0.125
0.625

0.9
0.075
0.025

Source: Heckman, Urzua and Vytlacil (2006).

(by p ) estimators consistent with two-way flows. We next discuss continuous instruments.
4.7.3. Continuous instruments
For the case of continuous Z, we present a parallel analysis for the weights associated
with the MTE. Figure 8 plots E(Y | P (Z)) and MTE for the extended Roy models
generated by the parameters displayed at the base of the figure. In cases I and II, β ⊥
⊥ D,

4940

J.J. Heckman and E.J. Vytlacil

The model is the same as the one presented below Figure 5. The values of the treatment parameters are the
same as the ones presented below Figure 6.
Figure 7. IV weights and its components under discrete instruments when Z1 is the instrument, the extended
Roy economy. Source: Heckman, Urzua and Vytlacil (2006).

so MTE (uD ) is constant in uD . In case I, this is trivial since β is a constant. In case II, β
is random but selection into D does not depend on β. Case III is the model with essential
heterogeneity (β ⊥

⊥ D). The graph (Figure 8A) depicts E(Y | P (Z)) in the three cases.
Cases I and II make E(Y | P (Z)) linear in P (Z). Case III is nonlinear in P (Z). This
arises when β ⊥

⊥ D. The derivative of E(Y | P (Z)) is presented in Figure 8B. It is
a constant for cases I and II (flat MTE) but declining in UD = P (Z) for the case

Ch. 71:

Econometric Evaluation of Social Programs, Part II

IV
Z =
1

K−1


4941

LATE (p , p+1 )λ = 0.1833

=1

I

λ = (p+1 − p )

i=1 (z1,i − E(Z1 ))

K

t> f (z1,i , pt )

Cov(Z1 , D)

Joint probability distribution of (Z1 , Z2 ) and the propensity score (joint probabilities in ordinary type
(Pr(Z1 = z1 , Z2 = z2 )); propensity score in italics (Pr(D = 1 | Z1 = z1 , Z2 = z2 )))
Z1 \Z2

−1

0

1

−1

0.02
0.7309
0.3
0.6402
0.2
0.5409

0.02
0.6402
0.01
0.5409
0.05
0.4388

0.36
0.5409
0.03
0.4388
0.01
0.3408

0
1
Cov(Z1 , Z2 ) = −0.5468

Figure 7. (Continued)

with selection on the gain. A simple test for linearity in P (Z) in the outcome equation
reveals whether or not the analyst is in cases I and II (β ⊥
⊥ D) or case III (β ⊥

⊥ D).67
These cases are the extended Roy counterparts to E(Y | P (Z) = p) and MTE shown
for the generalized Roy model in Figures 3A and 3B.
MTE gives the mean marginal return for persons who have utility P (Z) = uD . Thus,
P (Z) = uD is the margin of indifference. Those with low uD values have high returns.
Those with high uD values have low returns. Figure 8 highlights that, in the general case,
MTE (and LATE) identify average returns for persons at the margin of indifference at
different levels of the mean utility function (P (Z)).
Figure 9 plots MTE and LATE for different intervals of uD using the model generating Figure 8. LATE is the chord of E(Y | P (Z)) evaluated at different points. The
relationship between LATE and MTE is depicted in Figure 9B. LATE is the integral
under the MTE curve divided by the difference between the upper and lower limits.
The treatment parameters associated with case III are plotted in Figure 10. The MTE
is the same as that presented in Figure 8. ATE has the same value for all p. The effect
of treatment on the treated for P (Z) = p, TT (p) = E(Y1 − Y0 | D = 1, P (Z) = p)
declines in p (equivalently it declines in uD ). Treatment on the untreated given p,
TUT(p) = TUT (p) = E(Y1 − Y0 | D = 0, P (Z) = p) also declines in p,
TT (p )p − TT (p)p
,
p −p
∂[TT (p)p]
.
MTE =
∂p

LATE(p, p ) =

67 Recall that we keep the conditioning on X implicit.

p = p,

4942

J.J. Heckman and E.J. Vytlacil

Figure 8. Conditional expectation of Y on P (Z) and the MTE, the extended Roy economy. Source: Heckman,
Urzua and Vytlacil (2006).

We can generate all of the treatment parameters from TT (p).
Matching on P = p (which is equivalent to nonparametric regression given P = p)
produces a biased estimator of TT(p). Matching assumes a flat MTE (average return

Ch. 71:

Econometric Evaluation of Social Programs, Part II
Outcomes
Y1 = α + β̄ + U1
Y0 = α + U0

4943

Choice
model

1 if D ∗  0,
0 if D ∗ < 0

D=

Case I

Case II

Case III

U1 = U0
β̄ = ATE = TT = TUT = IV

U1 − U0 ⊥
⊥D
β̄ = ATE = TT = TUT = IV

U1 − U0 ⊥

⊥D
β̄ = ATE = TT = TUT = IV

Parameterization
Cases I, II and III

Cases II and III

Case III

α = 0.67
β̄ = 0.2

(U1 , U0 ) ∼ N (0, Σ)
1
−0.9
with Σ =
−0.9
1

D ∗ = Y1 − Y0 − γ Z
Z ∼ N (μZ , Σ Z )
μZ = (2, −2) and Σ Z =
γ = (0.5, 0.5)

9
−2

−2
9

Figure 8. (Continued)

equals marginal return).68 Therefore it is systematically biased for TT (p) in a model
with essential heterogeneity. Making observables alike makes the unobservables dissimilar. Holding p constant across treatment and control groups understates TT(p) for
low values of p and overstates it for high values of p. We develop this point further
when we discuss matching in Section 8.
Figure 11 plots the MTE (as a function of uD where uD = FV (v)), the weights for
ATE, TT and TUT and the IV weights using Z1 as the instrument for the model used
to generate Figure 9. The distribution of the Z is assumed to be normal with generating
parameters given at the base of Figure 9. The IV weight for normal Z is always nonnegative even if we use only one coordinate of vector Z. This is a consequence of the
monotonicity of E(Zj | P (Z)  uD ) in uD for any component of vector Z, which is a
property of normal selection models.69
Panel A of Figure 11 plots the treatment weights derived by Heckman and Vytlacil
(1999, 2001b) and the IV weight (4.14), along with the MTE. The ATE = ATE weight
is flat (= 1). TT oversamples the low uD agents (those more likely to adopt the policies).
TUT oversamples the high uD agents. The IV weight is positive as it must be when the
Z are normally distributed. IV is far from any of the standard treatment parameters.
Panel B decomposes the weight into its numerator components E(Z1 | P (Z)  uD )
and E(Z1 ), and the weight itself. The difference E(Z1 | P (Z)  uD ) − E(Z1 )
multiplied by Pr(P (Z)  uD ) and normalized by Cov(Z1 , D) is the weight (see Equation (4.13)). The weight is plotted as the dotted line in Figure 9B.

68 See Heckman and Vytlacil (2005) and Section 8.
69 See Heckman and Honoré (1990). In a broad class of models [see, e.g., Heckman, Tobias and Vytlacil

(2003)] E(R | S > c) is monotonic in c for vector R. The normal model is one member of this family.

4944

J.J. Heckman and E.J. Vytlacil

p+1

LATE (p , p+1 ) =

E(Y |P (Z)=p+1 )−E(Y |P (Z)=p )
p
= 
p+1 −p

MTE (uD ) duD
p+1 −p

LATE (0.6, 0.9)=−1.17
LATE (0.1, 0.35)=1.719
Outcomes
Y1 = α + β̄ + U1
Y0 = α + U0

 Choice model
1 if D ∗  0,
D=
0 if D ∗ < 0
with D ∗ = Y1 − Y0 − γ Z

Figure 9. The local average treatment effect, the extended Roy economy. Source: Heckman, Urzua and Vytlacil (2006).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4945

Parameterization
(U1 , U0 ) ∼ N (0, Σ) and Z ∼ N (μZ , Σ Z )
Σ=

1
−0.9

−2
9

9
−0.9
, μZ = (2, −2) and Σ Z =
−2
1
α = 0.67, β̄ = 0.2, γ = (0.5, 0.5)
Figure 9. (Continued)

Parameter

Definition

Under assumptions (*)

Marginal
treatment effect
Average treatment
effect

E[Y1 − Y0 | D ∗ = 0, P (Z) = p]

β̄ + σU1 −U0 Φ −1 (1 − p)

E[Y1 − Y0 | P (Z) = p]

β̄

Treatment on the
treated

E[Y1 − Y0 | D ∗  0, P (Z) = p]

β̄ + σU1 −U0 φ(Φ p(1−p))

Treatment on the
untreated

E[Y1 − Y0 | D ∗ < 0, P (Z) = p]

(1−p))
β̄ − σU1 −U0 φ(Φ 1−p

OLS/Matching on
P (Z)

E[Y1 | D ∗  0, P (Z) = p]
− E[Y0 | D ∗ < 0, P (Z) = p]

β̄ +

−1

−1



σU2 −σU1 ,U0
√1σ
U1 −U0





1−2p
−1
p(1−p) φ(Φ (1 − p))

(*): The model in this case is the same as the one presented below Figure 9.
Note: Φ(·) and φ(·) represent the cdf and pdf of a standard normal distribution, respectively.
Φ −1 (·) represents the inverse of Φ(·).
Figure 10. Treatment parameters and OLS/Matching as a function of P (Z) = p.
Source: Heckman, Urzua and Vytlacil (2006).

4946

J.J. Heckman and E.J. Vytlacil

Parameter

Under assumptions (*)

ATE
TT
TUT
IVZ1

0.2
1.1878
−0.9132
0.0924

(*) The model in this case is the same as the one
presented below Figure 9.
Figure 11. Treatment weights, IV weights using Z1 as the instrument and the MTE.
Source: Heckman, Urzua and Vytlacil (2004).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4947

Suppose that instead of assuming normality for the regressors, instrument Z is assumed to be a random vector with a distribution function given by a mixture of two
normals:
Z ∼ P1 N (κ1 , Σ1 ) + P2 N (κ2 , Σ2 ),
where P1 is the proportion in population 1, P2 is the proportion in population 2,
and P1 + P2 = 1. This produces a model with continuous instruments, where
E(J˜(Z) | P (Z)  uD ) need not be monotonic in uD where J˜(Z) = J (Z) − E(J (Z)).
Such a data generating process for the instrument could arise from an ecological model
in which two different populations are mixed (e.g., rural and urban populations).70
Appendix E derives the instrumental variable weights on MTE when Z1 (the first
element of Z) is used as the instrument, i.e., J (Z) = Z1 . For simplicity, we assume that
there are no X regressors. The probability of selection is generated using μD (Z) = Zγ .
The joint distribution of (Z1 , Zγ ) is normal within each group.
In our example, the dependence between Z1 and Zγ (= FV (Zγ ) = P (Z)) is
negative in one population and positive in another. Thus in one population, as Z1 increases P (Z) increases. In the other population, as Z1 increases P (Z) decreases. If
this second population is sufficiently big (P1 is small) or the negative correlation in
the second population is sufficiently big, the weights can become negative because
E(J˜(Z) | P (Z)  uD ) is not monotonic in uD .
We present examples for a conventional normal outcome selection model generated
by the parameters presented at the base of Figure 12. The discrete choice equation is a
conventional probit: Pr(D = 1 | Z = z) = Φ( σzγV ). The outcome equations are linear
normal equations. Thus MTE (v) = E(Y1 − Y0 | V = v), is linear in v:
E(Y1 − Y0 | V = v) = μ1 − μ0 +

Cov(U1 − U0 , V )
v.
Var(V )

At the base of the figure, we define β̄ = μ1 − μ0 and α = μ0 . The average treatment
effects are the same for all different distributions of the Z.
In each of the following examples, we show results for models with vector Z that
satisfies (IV-1) and (IV-2) and with γ > 0 componentwise where γ is the coefficient
of Z in the cost equation. We vary the weights and means of the instruments. Ceteris
paribus, an increase in each component of Z increases Pr(D = 1 | Z = z). Table 7
presents the parameters treatment on the treated (E(Y1 − Y0 | D = 1)), treatment on
the untreated (E(Y1 − Y0 | D = 0)), and the average treatment effect (E(Y1 − Y0 ))
produced by our model for different distributions of the regressors.
In standard IV analysis, under assumptions (IV-1) and (IV-2) the distribution of Z
does not affect the probability limit of the IV estimator. It only affects its sampling
distribution. Figure 12A shows three weights corresponding to the perturbations of the
variances of the instruments in the second component population Σ2 and the means
70 Observe that E(Z) = P κ + P κ .
1 1
2 2

4948

J.J. Heckman and E.J. Vytlacil

Figure 12. MTE and IV weights using Z1 as the instrument when Z = (Z1 , Z2 ) ∼ p1 N (κ1 , Σ1 ) +
p2 N (κ2 , Σ2 ) for different values of Σ2 .
Source: Heckman, Urzua and Vytlacil (2006).

(κ1 , κ2 ) shown at the table at the base of the figure. The MTE
used in all of our examV
ples are plotted in Figure 12B. The MTE has the familiar shape, reported in Heckman

Ch. 71:

Econometric Evaluation of Social Programs, Part II
Outcomes

4949

Choice
model

1 if D ∗  0,
0 if D ∗ < 0
D ∗ = Y1 − Y0 − γ Z and V = −(U1 − U0 )

Y1 = α + β̄ + U1

D=

Y0 = α + U0

Parameterization
(U1 , U0 ) ∼ N (0, Σ), Σ =

1
−0.9

−0.9
, α = 0.67, β̄ = 0.2
1

Z = (Z1 , Z2 ) ∼ p1 N (κ1 , Σ1 ) + p2 N (κ2 , Σ2 )
p1 = 0.45, p2 = 0.55; Σ1 =

1.4 0.5
0.5 1.4

Cov(Z1 , γ Z) = γ Σ11 = 0.98; γ = (0.2, 1.4)
Figure 12. (Continued)
Table 7
The IV estimator and Cov(Z2 , γ Z) associated with each value of Σ2
Weights

Σ2

κ1

κ2

IV

ATE

TT

TUT

Cov(Z2 , γ Z) = γ Σ21

ω1

0.6 −0.5
−0.5 0.6

[0 0]

[0 0]

0.434

0.2

1.401

−1.175

−0.58

ω2

0.6
0.1

[0 0]

[0 0]

0.078

0.2

1.378

−1.145

0.26

ω3

0.6 −0.3
−0.3 0.6

[0 −1]

[0 1]

−2.261

0.2

1.310

−0.859

−0.30

0.1
0.6

Source: Heckman, Urzua and Vytlacil (2006).

(2001) and Heckman, Tobias and Vytlacil (2003) that returns are highest for those with
values of v that make them more likely to get treatment (i.e., low values of v).
The weights ω1 and ω3 plotted in Figure 12A correspond to the case where
E(Z1 − E(Z1 ) | P (Z)  uD ) is not monotonic in uD . In these cases, the sign of the
covariance between Z1 and Zγ (i.e., P (Z)) is not the same in the two subpopulations.
The IV estimates reported in the table at the base of the figure range all over the place
even though the parameters of the outcome and choice model are the same.71
Different distributions of Z critically affect the probability limit of the IV estimator
in the model of essential heterogeneity. The model of outcomes and choices is the same
across all of these examples. The MTE and ATE parameters are the same. Only the
distribution of the instrument differs. The instrumental variable estimand is sometimes
positive and sometimes negative, and oscillates wildly in magnitude depending on the
distribution of the instruments. The estimated “effect” is often way off the mark for any

71 Since TT and TUT depend on the distribution of P (Z), they are not invariant to changes in the distribution

of the Z.

4950

J.J. Heckman and E.J. Vytlacil

desired treatment parameter. These examples show how uniformity in Z does not translate into uniformity in J (Z) (Z1 in this example). This sensitivity is a phenomenon that
does not appear in the conventional homogeneous response model but is a central feature
of a model with essential heterogeneity.72 We now compare selection and IV models.
4.8. Comparing selection and IV models
We now show that local IV identifies the derivatives of a selection model. Making the
X explicit, in the standard selection model, U1 and U0 are scalar random variables
that are additively separable in the outcome equations, Y1 = μ1 (X) + U1 and Y0 =
μ0 (X) + U0 . The control function approach conditions on Z and D. As a consequence
of index sufficiency, this is equivalent to conditioning on P (Z) and D:


E(Y | X, D, Z) = μ0 (X) + μ1 (X) − μ0 (X) D




+ K1 P (Z), X D + K0 P (Z), X (1 − D),
where the control functions are




K1 P (Z), X = E U1 D = 1, X, P (Z) ,




K0 P (Z), X = E U0 D = 0, X, P (Z) .
The IV approach does not condition on D. It works with




E(Y | X, Z) = μ0 (X) + μ1 (X) − μ0 (X) P (Z) + K1 P (Z), X P (Z)



+ K0 P (Z), X 1 − P (Z) ,

(4.17)

the population mean outcome given X, Z.
From index sufficiency, E(Y | X, Z) = E(Y | X, P (Z)). The MTE is the derivative
of this expression with respect to P (Z), which we have defined as LIV:
∂E(Y | X, P (Z))
∂P (Z)

= LIV(X, p) = MTE(X, p).73
P (Z)=p

The distribution of P (Z) and the relationship between J (Z) and P (Z) determine the
weight on MTE.74 Under assumptions (A-1)–(A-5), along with rank and limit conditions [Heckman and Robb (1985a), Heckman (1990)], one can identify μ1 (X), μ0 (X),
K1 (P (Z), X), and K0 (P (Z), X).

72 We note parenthetically that if we assume P = 0 (or P = 0), the weights are positive even if we only
1
2
use Z1 as an instrument and Z1 and Z2 are negatively correlated. This follows from the monotonicity of

E(R | S > c) in c for vector R. See Heckman and Honoré (1990). This case is illustrated in Figure 11.

73 Björklund and Moffitt (1987) analyze this marginal effect for a parametric generalized Roy model.
74 Because LIV does not condition on D, it discards information. Lost in taking derivatives are the constants

in the model that do not interact with P (Z) in Equation (4.17).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

The selection (control function) estimator identifies the conditional means




E Y1 X, P (Z), D = 1 = μ1 (X) + K1 X, P (Z)

4951

(4.18a)

and




E Y0 X, P (Z), D = 0 = μ0 (X) + K0 X, P (Z) .

(4.18b)

These can be identified from nonparametric regressions of Y1 and Y0 on X, Z in each
population. To decompose these means and separate μ1 (X) from K1 (X, P (Z)) without
invoking functional form or curvature assumptions, it is necessary to have an exclusion (a Z not in X).75 In addition, there must exist a limit set for Z given X such that
K1 (X, P (Z)) = 0 for Z in that limit set. Otherwise, without functional form or curvature assumptions, it is not possible to disentangle μ1 (X) from K1 (X, P (Z)) which
may contain constants and functions of X that do not interact with P (Z) [see Heckman
(1990)]. A parallel argument for Y0 shows that we require a limit set for Z given X
such that K0 (X, P (Z)) = 0. Selection models operate by identifying the components
of (4.18a) and (4.18b) and generating the treatment parameters from these components.
Thus they work with levels of the Y .
The local IV method works with derivatives of (4.17) and not levels and cannot directly recover the constant terms in (4.18a) and (4.18b). Using our analysis of LIV but
applied to Y D = Y1 D and Y (1 − D) = Y0 (1 − D), it is straightforward to use LIV to
estimate the components of the MTE separately. Thus we can identify
μ1 (X) + E(U1 | X, UD = uD )
and
μ0 (X) + E(U0 | X, UD = uD )
separately. This corresponds to what is estimated from taking the derivatives of expressions (4.18a) and (4.18b) multiplied by P (Z) and (1 − P (Z)), respectively:76


P (Z)E(Y1 | X, Z, D = 1) = P (Z)μ1 (X) + P (Z)K1 X, P (Z)
and


1 − P (Z) E(Y0 | X, Z, D = 0)


 


= 1 − P (Z) μ0 (X) + 1 − P (Z) K0 X, P (Z) .
Thus the control function method works with levels, whereas the LIV approach works
with slopes of combinations of the same basic functions. Constants that do not depend
75 See Heckman and Navarro (2007) for use of semiparametric curvature restrictions in identification analysis

that do not require functional form assumptions.
76 Björklund and Moffitt (1987) use the derivative of a selection model in levels to define the marginal treat-

ment effect.

4952

J.J. Heckman and E.J. Vytlacil

on P (Z) disappear from the estimates of the model. The level parameters are obtained
by integration using the formulae in Table 2B.
Misspecification of P (Z) (either its functional form or its arguments) and hence of
K1 (P (Z), X) and K0 (P (Z), X), in general, produces biased estimates of the parameters of the model under the control function approach even if semiparametric methods
are used to estimate μ0 , μ1 , K0 and K1 . To implement the method, we need to know all
of the arguments of Z. The terms K1 (P (Z), X) and K0 (P (Z), X) can be nonparametrically estimated so it is only necessary to know P (Z) up to a monotonic transformation.77 The distributions of U0 , U1 and V do not need to be specified to estimate control
function models [see Powell (1994)].
These problems with control function models have their counterparts in IV models.
If we use a misspecified P (Z) to identify the MTE or its components, in general, we do
not identify MTE or its components. Misspecification of P (Z) plagues both approaches.
One common criticism of selection models is that without invoking functional form
assumptions, identification of μ1 (X) and μ0 (X) requires that P (Z) → 1 and P (Z) →
0 in limit sets.78 Identification in limit sets is sometimes called “identification at infinity”. In order to identify ATE = E(Y1 − Y0 | X), IV methods also require that
P (Z) → 1 and P (Z) → 0 in limit sets, so an identification at infinity argument is
implicit when IV is used to identify this parameter.79 The LATE parameter avoids this
problem by moving the goal posts and redefining the parameter of interest away from
a level parameter like ATE or TT to a slope parameter like LATE which differences
out the unidentified constants. Alternatively, if we define the parameter of interest to
be LATE or MTE, we can use the selection model without invoking identification at
infinity.
The IV estimator is model dependent, just like the selection estimator, but in application, the model does not have to be fully specified to obtain IV using Z (or J (Z)).
However, the distribution of P (Z) and the relationship between P (Z) and J (Z) generates the weights. The interpretation placed on IV in terms of weights on MTE depends
crucially on the specification of P (Z). In both control function and IV approaches for
the general model of heterogeneous responses, P (Z) plays a central role.
Two economists using the same instrument will obtain the same point estimate using
the same data. Their interpretation of that estimate will differ depending on how they
specify the arguments in P (Z), even if neither uses P (Z) as an instrument. By conditioning on P (Z), the control function approach makes the dependence of estimates on
the specification of P (Z) explicit. The IV approach is less explicit and masks the assumptions required to economically interpret the empirical output of an IV estimation.
We now turn to some empirical examples of LIV.
77 See Heckman et al. (1998).
78 See Imbens and Angrist (1994). Heckman (1990) establishes the identification in the limit argument for

ATE in selection models. See Heckman and Navarro (2007) for a generalization to multiple outcome models.
79 Thus if the support of P (Z) is not full, we cannot identify treatment on the treated or the average treatment

effect. We can construct bounds. See Heckman and Vytlacil (1999, 2001a, 2001b).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4953

4.9. Empirical examples: “The effect” of high school graduation on wages and using
IV to estimate “the effect” of the GED
The previous examples illustrate logical possibilities. This subsection shows that these
logical possibilities arise in real data. We analyze two examples: (a) the effect of graduating high school on wages, and (b) the effect of obtaining a GED on wages. We first
analyze the effect of graduating high school on wages.
4.9.1. Empirical example based on LATE: Using IV to estimate “the effect” of high
school graduation on wages
We first study the effects of graduating from high school on wages using data from the
National Longitudinal Survey of Youth 1979 (NLSY79). This survey gathers information at multiple points in time on the labor market activities for men and women born
in the years 1957–1964. We estimate LATE using log hourly wages at age 30 as the
outcome measure. Following a large body of research [see Mare (1980)], we use the
number of siblings and residence in the south at age 14 as instruments.
Figure 13 plots the weights on LATE using the estimated P (Z). The procedure used
to derive the estimates is explained in Heckman, Urzua and Vytlacil (2006). The weights
are derived from Equation (4.16). The LATE parameters are both positive and negative.
The weights using siblings as an instrument are both positive and negative. The weights
using P (Z) as an instrument are positive, as they must be following the analysis of
Yitzhaki (1989). The two IV estimates differ from each other because the weights are
different. The overall IV estimate is a crude summary of the underlying component
LATEs that are both large and positive and large and negative. We next turn to analysis
of the GED.
4.9.2. Effect of the GED on wages
The GED test is used to certify high school dropouts as high school equivalents. Numerous studies document that the economic return to the GED is low [see Cameron and
Heckman (1993), Heckman and LaFontaine (2007)]. It is estimated by the method described in Heckman, Urzua and Vytlacil (2006). In this example, we study the effect of
the GED on the wages of recipients compared to wages of dropouts. We use data from
the National Longitudinal Survey of Youth 1979 (NLSY79) which gathers information
at multiple points in time on the labor market activities for men and women born in the
years 1957–1964.
We estimate the MTE for the GED and also consider the IV weights for various
instruments for a sample of males at age 25. Figure 14 shows the sample support of
P (Z) for both GEDs and high school dropouts. It is not possible to estimate the MTE
over its full support. Thus the average treatment effect (ATE) and treatment on the
treated (TT) cannot be estimated from these data. The list of Z variables is presented in
Table 8 along with IV estimates. The IV estimates fluctuate from positive to negative.

4954

J.J. Heckman and E.J. Vytlacil

Figure 13. IV weights – the effect of graduating from high school – sample of high school dropouts and high
school graduates. Source: Heckman, Urzua and Vytlacil (2006).

Using P (Z) as an instrument, the GED effect on log wages is in general negative.80 For
other instruments, the signs and magnitudes vary.

80 In this example, we use the log of the average nonmissing hourly wages reported between ages 24 and 26.

Using the hourly wage reported at age 25 leads to roughly the same results (negative IV weights, and positive
and negative IV estimates), but an increase in the standard errors.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4955

Y = Log per-hour wage at age 30, Z1 = number of siblings in 1979, Z2 = mother is a high school graduate

1 if high school graduate,
D=
0 if high school dropout
IV estimates
(bootstrap std. errors in parentheses – 100 replications)
Instrument

Value

Number of siblings in 1979

0.115
(0.695)
0.316
(0.110)

Propensity score

Joint probability distribution of (Z1 , Z2 ) and the propensity score
(joint probabilities Pr(Z1 = z1 , Z2 = z2 ) in ordinary type;
propensity score Pr(D = 1 | Z1 = z1 , Z2 = z2 ) in italics)
Z2 \Z1

0

1

2

3

4

0

0.07
1.0

0.03
0.54

0.47
0.86

0.121
0.72

0.06
0.61

1

0.039
0.94

0.139
0.89

0.165
0.90

0.266
0.85

0.121
0.93

Cov(Z1 , Z2 ) = −0.066, number of observations = 1,702
Figure 13. (Continued)

Figure 15 plots the estimated MTE. Details of the nonparametric estimation procedure used to produce these estimates are shown in an appendix in Heckman, Urzua
and Vytlacil (2006). Local linear regression is used to estimate the MTE implementing
Equation (4.9). While the standard error band is large, the estimated MTE is in general
negative, suggesting a negative marginal treatment effect for most participants. However, we observe that for small values of uD the point estimates of the marginal effect

4956

J.J. Heckman and E.J. Vytlacil
Table 8
Instrumental variables estimatesa : Sample of GED and dropouts – males at age 25b
Instruments
Father’s highest grade completed
Mother’s highest grade completed
Number of siblings
GED cost
Family income in 1979
Dropout’s local wage at age 17
High school graduate’s local wage at age 17
Dropout’s local unemployment rate at age 17
High school graduate’s local unemployment rate at age 17
Propensity scorec

IV–MTE
0.146
(0.251)
−0.052
(0.179)
−0.052
(0.160)
−0.053
(0.156)
−0.047
(0.177)
−0.013
(0.218)
−0.049
(0.182)
0.443
(1.051)
−0.563
(0.577)
−0.058
(0.164)

Notes:
a The IV estimates are computed by taking the weighted sum of the MTE. The standard
deviations (in parentheses) are computed using bootstrapping (50 draws).
b We excluded the oversample of poor whites and the military sample. The cost of the GED
corresponds to the average testing fee per GED battery by state between 1993 and 2000.
(Source: GED Statistical Report.) Average local wage for dropouts and high school graduates correspond to the average in the place of residence for each group, respectively, and
local unemployment rate corresponds to the unemployment rate in the place of residence.
Average local wages, local unemployment rates, mother’s and father’s education refer to
the level at age 17.
c The propensity score (P (D = 1 | Z = z)) is computed using as controls the instruments
presented in the table, as well as two dummy variables controlling for the place of residence
at age 14 (south and urban), and a set of dummy variables controlling for the year of birth
(1957–1963).
Source: Heckman, Urzua and Vytlacil (2004).

are positive. This analysis indicates that, for people who are more likely to take the
GED exam in terms of their unobservables (i.e., for people at the margin of indifference
associated with a small uD ), the marginal effect is in fact positive.
It is instructive to examine the various IV estimates using the one instrument at a
time strategy favored by many applied economists who like to do sensitivity analysis.81
81 See, e.g., Card (2001).

Ch. 71:
Econometric Evaluation of Social Programs, Part II
Note: The propensity score (P(D = 1 | Z)) is computed using as controls (Z): Father’s highest grade completed, mother’s highest grade completed, number of
siblings, GED testing fee by state between 1993 and 2000, family income in 1979, dropout’s local wage at age 17, and high school graduate’s local
unemployment at age 17. We also include two dummy variables controlling for the place of residence at age 14 (south and urban), and a set of dummies
controlling for the year of birth (1957–1963).
Figure 14. Frequency of the propensity score by final schooling decision: Dropouts and GEDs, NLSY males at age 25. Source: Heckman, Urzua and Vytlacil
(2004).
4957

4958

J.J. Heckman and E.J. Vytlacil

Note: The dependent variable in the outcome equation is the log of the average hourly wage reported
between ages 24 and 26. The controls in the outcome equations are tenure, tenure squared, experience,
corrected AFQT, black (dummy), Hispanic (dummy), marital status, and years of schooling. Let D = 0
denote dropout status and D = 1 denote GED status. The model for D (choice model) includes as controls
the corrected AFQT, number of siblings, father’s education, mother’s education, family income at age 17,
local GED costs, broken home at age 14, average local wage at age 17 for dropouts and high school
graduates, local unemployment rate at age 17 for dropouts and high school graduates, the dummy variables
for black and Hispanic, and a set of dummy variables controlling for year of birth. We also include two
dummy variables controlling for the place of residence at age 14 (south and urban). The choice model is
estimated using a probit model. In computing the MTE, the bandwidths are selected using the “leave one
out” cross-validation method. We use biweight kernel functions. The confidence interval is computed from
bootstrapping using 50 draws.
Figure 15. MTE of the GED with confidence interval: Dropouts and GEDs, males of the NLSY at the age 25.
Source: Heckman, Urzua and Vytlacil (2004).

Many of the variables used in the analysis are determined by age 17. Both father’s highest grade completed and local unemployment rate among high school dropouts produce
positive (if not precisely determined) IV estimates. A negative MTE weighted by negative IV weights produces a positive IV. A naive application of IV could produce the
wrong causal inference, i.e., that GED certification raises wages. Our estimates show
that our theoretical examples have real world counterparts.82
Carneiro, Heckman and Vytlacil (2006) present an extensive empirical analysis of
the wage returns to college attendance. They show how to unify and interpret diverse
instruments within a common framework using the MTE and the weights derived in
Heckman and Vytlacil (1999, 2001a, 2005). They show negative weights on the MTE
for commonly used instruments. Basu et al. (2007) use the MTE and the derived weights
to identify the ranges of the MTE identified by different instruments in their analysis of
the costs of breast cancer. We next discuss the implications of relaxing separability in
the choice equations.
82 We discuss the GED further in Section 7.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4959

4.10. Monotonicity, uniformity, nonseparability, independence and policy invariance:
The limits of instrumental variables
The analysis of this section and the entire recent literature on instrumental variables
estimators for models with heterogeneous responses (i.e., models with outcomes of the
forms (3.1) and (3.2)) relies critically on the assumption that the treatment choice equation has a representation in the additively separable form (3.3). From Vytlacil (2002),
we know that under assumptions (A-1)–(A-5), separability is equivalent to the assumption of monotonicity or uniformity, (IV-3).
This uniformity condition imparts an asymmetry to the entire instrumental variable
enterprise. Responses are permitted to be heterogeneous in a general way, but choices
of treatment are not. In this section, we relax the assumption of additive separability
in (3.3). We establish that in the absence of additive separability or uniformity, the
entire instrumental variable identification strategy in this section and the entire recent
literature collapses. Parameters can be defined as weighted averages of an MTE. MTE
and the derived parameters cannot be identified using any instrumental variable strategy. Appendix B presents a comprehensive discussion, which we summarize in this
subsection.
One natural benchmark nonseparable model is a random coefficient model of choice
D = 1[Zγ  0], where γ is a random coefficient vector and γ ⊥
⊥ (Z, U0 , U1 ). If γ is
a random coefficient with a nondegenerate distribution and with components that take
both positive and negative values, uniformity is clearly violated. However, it can be
violated even when all components of γ are of the same sign if Z is a vector.83
Relax the additive separability assumption of Equation (3.3) to consider a more general case
D ∗ = μD (Z, V ),

(4.19a)

where μD (Z, V ) is not necessarily additively separable in Z and V , and V is not necessarily a scalar.84 In the random coefficient example, V = γ and μD = zγ .


D = 1 D∗  0 .
(4.19b)
We maintain assumptions (A-1)–(A-5) and (A-7).
In special cases, (4.19a) can be expressed in an additively separable form. For example, if D ∗ is weakly separable in Z and V , D ∗ = μD (θ (Z), V ) for any V where θ (Z) is
a scalar function, μD is increasing in θ (Z), and V is a scalar, then we can write (4.19b)
in the same form as (3.3):


D = 1 θ (Z)  Ṽ ,
83 Thus, if γ is a vector with positive components, a change from Z = z to Z = z can produce different

effects on choice if γ varies in the population and if components of Z are of different signs.
84 The additively separable latent index model is more general than it may at first appear. It is shown in

Vytlacil (2006a) that a wide class of threshold crossing models without the additive structure on the latent
index will have a representation with the additively separable structure on the latent index.

4960

J.J. Heckman and E.J. Vytlacil

where Ṽ = μ−1
⊥ Z | X, and the inverse function is expressed with reD (0; V ) and Ṽ ⊥
spect to the first argument [see Vytlacil (2006a)]. Vytlacil (2002) shows that any model
that does not satisfy uniformity (or “monotonicity”) will not have a representation in
this form.85
In the additively separable case, the MTE (3.4) has three equivalent interpretations.
(i) UD = FV (V ) is the only unobservable in the first stage decision rule, and MTE is
the average effect of treatment given the unobserved characteristics in the decision rule
(V = v). (ii) A person with V = v would be indifferent between treatment or not if
P (Z) = uD , where P (Z) is a mean scale utility function. Thus, the MTE is the average
effect of treatment given that the individual would be indifferent between treatment or
not if P (Z) = uD . (iii) One can also view the additively separable form (3.3) as intrinsic
in the way we are defining the parameter and interpret the MTE (Equation (3.4)) as an
average effect conditional on the additive error term from the first stage choice model.
Under all interpretations of the MTE and under the assumptions used in the preceding
sections of this chapter, MTE can be identified by LIV; the MTE does not depend on
Z and hence it is policy invariant and the MTE integrates up to generate all treatment
effects, policy effects and all IV estimands.
The three definitions are not the same in the general nonseparable case (4.19a).
Heckman and Vytlacil (2001b) extend MTE in the nonseparable case using interpretation (i). MTE defined this way is policy invariant to changes in Z. Appendix B, which
summarizes their work, shows that LIV is a weighted average of the MTE with possibly
negative weights and does not identify MTE. If uniformity does not hold, the definition of MTE allows one to integrate MTE to obtain all of the treatment effects, but the
instrumental variables estimator breaks down.
Alternatively, one could define MTE based on (ii):



MTE
(z) = E Y1 − Y0 V ∈ v: μD (z, v) = 0 .
ii
This is the average treatment effect for individuals who would be indifferent between
treatment or not at a given value of z (recall that we keep the conditioning on X implicit).
Heckman and Vytlacil (2001b) show that in the nonseparable case LIV does not identify
this MTE and that MTE does not change when the distribution of Z changes, provided
that the support of MTE does not change.86 In general, this definition of MTE does not
allow one to integrate up MTE to obtain the treatment parameters.
A third possibility is to force the index rule into an additive form by taking μ∗D (Z) =
E(μD (Z, V ) | Z), defining V ∗ = μD (Z, V ) − E(μD (Z, V ) | Z) and define MTE as
E(Y1 − Y0 | V ∗ = v ∗ ). Note that V ∗ is not independent of Z, is not policy invariant and
is not structural. LIV does not estimate this MTE. With this definition of the MTE it is
not possible, in general, to integrate up MTE to obtain the various treatment effects.
85 In the random coefficient case where Z = (1, Z ) where Z is a scalar, and γ = (γ , γ ) if γ > 0 for all
1
1
0 1
1
γ
γ
realizations, we can write the choice rule in the form of (3.3): Z1 γ1  −γ0 ⇒ Z1  − γ0 and Ṽ = − γ0 .
1
1

This trick does not work in the general case.

86 If the support of Z changes, then the MTE must be extended to a new support.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4961

For any version of the nonseparable model, except those that can be transformed to
separability, index sufficiency fails. To see this, assume that μD (Z, V ) is continuous.87
Define Ω(z) = {v: μD (z, v)  0}. In the additively separable case, P (z) ≡ Pr(D =
1 | Z = z) = Pr(UD ∈ Ω(z)), P (z) = P (z ) ⇔ Ω(z) = Ω(z ). This produces index
sufficiency. In the more general case of (4.19a), it is possible to have (z, z ) such that
P (z) = P (z ) and Ω(z) = Ω(z ) so index sufficiency does not hold.
4.10.1. Implications of nonseparability
This section develops generalization (i), leaving development of the other interpretations for later research. We focus on an analysis of PRTE, comparing two policies
p, p ∈ P. Here “p” denotes a policy and not a realization of P (Z) as in the previous sections. This is our convention when we discuss PRTE. The analysis of the other
treatment parameters follows by parallel arguments.
For any v in the support of the distribution of V , define Ω = {z: μD (z, v)  0}.
For example, in the random coefficient case, with V ≡ γ and D = 1[Zγ  0], we
have Ωg = {z: zg  0}, where g is a realization of γ . Define 1A (t) to be the indicator
function for the event t ∈ A. Then, making the X explicit, Appendix B derives the result
that
E(Yp ) − E(Yp )

= E E(Yp | X) − E(Yp
=


X)

E(MTE | X = x, V = v)


× Pr[Zp ∈ Ω | X = x] − Pr[Zp ∈ Ω | X = x] dFV |X (v | x) dFX (x).

(4.20)
Thus, without additive separability, we can still derive an expression for PRTE and by
similar reasoning the other treatment parameters. However, to evaluate the expression
requires knowledge of MTE, of Pr[Zp ∈ Ω | X = x] and Pr[Zp ∈ Ω | X = x] for
every (v, x) in the support of the distribution of (V , X), and of the distribution of V . In
general, if no structure is placed on the μD function, one can normalize V to be unit
uniform (or a vector of unit uniform random variables) so that FV |X will be known.
However, in this case, the Ω = {z: μD (z, v)  0} sets will not in general be identified. If structure is placed on the μD function, one might be able to identify the
Ω = {z: μD (z, v)  0} sets but then one needs to identify the distribution of V
(conditional on X). If structure is placed on μD , one cannot in general normalize the
distribution of V to be unit uniform without undoing the structure being imposed on μD .
In particular, consider the random coefficient model D = 1[Zγ  0] where V = γ is
a random vector, so that Ωγ = {z: zγ  0}. In this case, if all of the other assumptions
87 Absolutely continuous with respect to Lebesgue measure.

4962

J.J. Heckman and E.J. Vytlacil

hold, including Z ⊥
⊥ γ | X, and the policy change does not affect (Y1 , Y0 , X, γ ), the
PRTE is given by


E(Yp ) − E(Yp ) = E E(Yp | X) − E(Yp | X)

=
E(MTE | X = x, γ = g) Pr[Zp ∈ Ωg | X = x]

− Pr[Zp ∈ Ωg | X = x] dFγ |X (g | x) dFX (x).
Because structure has been placed on the μD (Z, γ ) function, the sets Ωγ are known.
However, evaluating the function requires knowledge of the distribution of γ which will
not in general be identified without further assumptions.88 Normalizing the distribution
of γ to be a vector of unit uniform random variables produces the distribution of γ but
eliminates the assumed linear index structure on μD and results in Ωγ sets that are not
identified.
Even if the weights are identified, Heckman and Vytlacil (2001b) show that it is not
possible to use LIV to identify MTE without additive separability between Z and V
in the selection rule index. Appendix F develops this point for the random coefficient
model. Without additive separability in the latent index for the selection rule, we can
still create an expression for PRTE (and the other treatment parameters) but both the
weights and the MTE function are no longer identified using instrumental variables.
One superficially plausible way to avoid these problems would be to define μ̃D (Z) =
E(μD (Z, V ) | Z) and Ṽ = μD (Z, V ) − E(μD (Z, V ) | Z), producing the model
D = 1[μ̃D (Z) + Ṽ  0]. We keep the conditioning on X implicit. One could redefine MTE using Ṽ and proceed as if the true model possessed additive separability
between observables and unobservables in the latent index. This is the method pursued
in approach (iii).
For two reasons, this approach does not solve the problem of providing an adequate
generalization of MTE. First, with this definition, Ṽ is a function of (Z, V ), and a policy
that changes Z will then also change Ṽ . Thus, policy invariance of the MTE no longer
holds. Second, this approach generates a Ṽ that is no longer statistically independent
of Z so that assumption (A-1) no longer holds when Ṽ is substituted for V even when
(A-1) is true for V . Lack of independence between observables and unobservables in
the latent index both invalidates our expression for PRTE (and the expressions for the
other treatment effects) and causes LIV to no longer identify MTE.
The nonseparable model can also restrict the support of P (Z). For example, consider
a standard normal random coefficient model with a scalar regressor (Z = (1, Z1 )).
⊥ γ1 . Then
Assume γ0 ∼ N (0, σ02 ), γ1 ∼ N (γ̄1 , σ12 ), and γ0 ⊥


γ̄1 z1
,
P (z1 ) = Φ 
σ02 + σ12 z12
88 See, e.g., Ichimura and Thompson (1998) for conditions for identifying the distribution of γ in a random

coefficient discrete choice model when Z ⊥
⊥γ.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4963

where Φ is the standard cumulative normal distribution. If the support of z1 is R, then
in the standard additive model, σ12 = 0 and P (z1 ) has support [0, 1]. When σ12 > 0,
the support is strictly within the unit interval.89 In the special case when σ02 = 0, the
support is one point (P (z) = Φ( σγ̄11 )). We cannot, in general, identify ATE, TT or any
treatment effect requiring the endpoints 0 or 1.
Thus the general models of nonuniformity presented in this section do not satisfy
the index sufficiency property, and the support of the treatment effects and estimators
is, in general, less than full. The random coefficient model for choice may explain the
empirical support problems for P (Z) found in Heckman et al. (1998) and many other
evaluation studies.
4.10.2. Implications of dependence
We next consider relaxing the independence assumption (A-1) to allow Z ⊥

⊥V | X
while maintaining the assumption that Z ⊥
⊥ (Y0 , Y1 ) | (X, V ). We maintain the other
assumptions, including additive separability between Z and V in the latent index for the
selection rule (Equation (3.3)) and the assumption that the policy changes Z but does
not change (V , Y0 , Y1 , X). Thus we assume that the policy shift does not change the
MTE function (policy invariance). Given these assumptions, we derive in Appendix C
the following expression for PRTE in the nonindependent case for policies p, p ∈ P:
E(Yp ) − E(Yp )


= E E(Yp | X) − E(Yp | X)
=

 

E(MTE | X = x, V = v) Pr μD (Zp ) < v X = x, V = v


− Pr μD (Zp ) < v X = x, V = v dFV |X (v | x) dFX (x).

(4.21)

Notice that “p” denotes a policy and not a realized value of P (Z). Although we can
derive an expression for PRTE without requiring independence between Z and V , to
evaluate this expression requires knowledge of MTE and of Pr[μD (Zp ) < v | X = x,
V = v] and of Pr[μD (Zp ) < v | X = x, V = v] for every (x, v) in the support of
the distribution of (X, V ). This requirement is stronger than what is needed in the case
of independence since the weights no longer depend only on the distribution of Pp (Zp )
and Pp (Zp ) conditional on X. To evaluate these weights requires knowledge of the
function μD and of the joint distribution of (V , Zp ) and (V , Zp ) conditional on X, and
these will in general not be identified without further assumptions.
Even if the weights are identified, Heckman and Vytlacil (2001b) show that it is not
possible to use LIV to identify MTE without independence between Z and V conditional on X. Thus, without conditional independence between Z and V in the latent
89 The interval is [Φ( −|γ̄1 | ), Φ( |γ̄1 | )].
σ
σ
1

1

4964

J.J. Heckman and E.J. Vytlacil

index for the decision rule, we can still create an expression for PRTE but both the
weights and the MTE function are no longer identified without invoking further assumptions.
One superficially appealing way to avoid these problems is to define Ṽ = FV |X,Z (V )
and μ̃D (Z) = FV |X,Z (μD (Z)), so D = 1[μD (Z) − V  0] = 1[μ̃D (Z) − Ṽ  0]
with Ṽ ∼ Unif[0, 1] conditional on X and Z and so Ṽ is independent of X and Z.
It might seem that the previous analysis would carry over. However, by defining Ṽ =
FV |X,Z (V ), we have defined Ṽ in a way that depends functionally on Z and X, and
hence we violate invariance of the MTE with respect to the shifts in the distribution
of Z given X.
4.10.3. The limits of instrumental variable estimators
The treatment effect literature focuses on a class of policies that move treatment choices
in the same direction for everyone. General instruments do not have universally positive
weights on MTE . They are not guaranteed to shift everyone in the same direction. They
do not necessarily estimate gross treatment effects. However, the effect of treatment
is not always the parameter of policy interest. Thus, in the housing subsidy example
developed in Section 4.6, migration is the vehicle through which the policy operates.
One might be interested in the effect of migration (the treatment effect) or the effect
of the policy (the housing subsidy). These are separate issues unless the policy is the
treatment.
Generalizing the MTE to the case of a nonseparable choice equation that violates
the monotonicity condition, we can define but cannot identify the policy parameters
of interest using ordinary instrumental variables or our extension LIV. If we make the
model symmetrically heterogeneous in outcome and choice equations, the method of
instrumental variables and our extensions of it break down in terms of estimating economically interpretable parameters. Vytlacil and Yildiz (2006) and Vytlacil, Santos and
Shaikh (2005) restore symmetry in the IV analysis of treatment choice and outcome
equations by imposing uniformity on both outcome and choice equations. The general
case of heterogeneity in both treatment and choice equations is beyond the outer limits
of the entire IV literature, although it captures intuitively plausible phenomena. More
general structural methods are required.90
5. Regression discontinuity estimators and LATE
Campbell (1969) developed the regression discontinuity design which is now widely
used. [See an early discussion of this estimator in econometrics by Barnow, Cain and
90 The framework of Carneiro, Hansen and Heckman (2003) can be generalized to allow for random coeffi-

cient models in choice equations, and lack of policy invariance in the sense of assumption (A-7). However,
a fully semiparametric analysis of treatment and choice equations with random coefficients remains to be
developed.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4965

Goldberger (1980).] Hahn, Todd and Van der Klaauw (2001) present an exposition of
the regression discontinuity estimator within a LATE framework. This section exposits
the regression discontinuity method within our MTE framework.
Suppose assumptions (A-1)–(A-5) hold except that we relax independence assumption (A-1) to assume that (Y1 − Y0 , UD ) is independent of Z conditional on X. We do
not impose the condition that Y0 is independent of Z conditional on X. Relaxing the
assumption that Y0 is independent of Z conditional on X causes the standard LIV estimand to differ from the MTE. We show that the LIV estimand in this case equals MTE
∂
plus a bias term that depends on ∂p
E(Y0 | X = x, P (Z) = p). Likewise, we show that
the discrete-difference IV formula will no longer correspond to LATE, but will now
correspond to LATE plus a bias term.
A regression discontinuity design allows analysts to recover a LATE parameter at
a particular value of Z. If E(Y0 | X = x, Z = z) is continuous in z, while P (z)
is discontinuous in z at a particular point, then it will be possible to use a regression
discontinuity design to recover a LATE parameter. While the regression discontinuity
design does have the advantage of allowing Y0 to depend on Z conditional on X, it only
recovers a LATE parameter at a particular value of Z and cannot in general be used
to recover either other treatment parameters such as the average treatment effect or the
answers to policy questions such as the PRTE. The following discussion is motivated
by the analysis of Hahn, Todd and Van der Klaauw (2001).
For simplicity, assume that Z is a scalar random variable. First, consider LIV while
relaxing independence assumption (A-1) to assume that (Y1 − Y0 , UD ) is independent
of Z conditional on X but without imposing that Y0 is independent of Z conditional
on X. In order to make the comparison with the regression discontinuity design easier,
we will condition on Z instead of P (Z). Using Y = Y0 + D(Y1 − Y0 ), we obtain
E(Y | X = x, Z = z)



= E(Y0 | X = x, Z = z) + E D(Y1 − Y0 ) X = x, Z = z
P (z)

= E(Y0 | X = x, Z = z) +

E(Y1 − Y0 | X = x, UD = uD ) duD .

0

So
∂
∂z E(Y

| X = x, Z = z)
∂
∂z P (z)

=

∂
∂z E(Y0

| X = x, Z = z)

∂
∂z P (z)


+ E Y1 − Y0 X = x, UD = P (z)

∂
where we have assumed that ∂z
P (z) = 0 and that E(Y0 | X = x, Z = z)
is differentiable in z. Notice that under our stronger independence condition (A-1),
∂
∂z E(Y0 | X = x, Z = z) = 0 so that we identify MTE as before. With Y0 possibly
dependent on Z conditional on X, we now get MTE plus the bias term that depends
∂
on ∂z
E(Y0 | X = x, Z = z). Likewise, if we consider the discrete change form

4966

J.J. Heckman and E.J. Vytlacil

of IV:
E(Y | X = x, Z = z) − E(Y | X = x, Z = z )
P (z) − P (z )
E(Y0 | X = x, Z = z) − E(Y0 | X = x, Z = z )
=
P (z) − P (z )



Bias for LATE



+ E Y1 − Y0 X = x, P (z) > UD > P (z )



LATE

so that we now recover LATE plus a bias term.
Now consider a regression discontinuity design. Suppose that there exists an
evaluation point z0 for Z such that P (·) is discontinuous at z0 , and suppose that
E(Y0 | X = x, Z = z) is continuous at z0 . Suppose that P (·) is increasing in a neighborhood of z0 . Let
P (z0 −) = lim P (z0 − ),
↓0

P (z0 +) = lim P (z0 + ),
↓0

and note that the conditions that P (·) is increasing in a neighborhood of z0 and discontinuous at z0 imply that P (z0 +) > P (z0 −). Let
μ(x, z0 −) = lim E(Y | X = x, Z = z0 − ),
↓0

μ(x, z0 +) = lim E(Y | X = x, Z = z0 + ),
↓0

and note that
μ(x, z0 −) = E(Y0 | X = x, Z = z0 )
P (z0 −)

+

E(Y1 − Y0 | X = x, UD = uD ) duD

0

and
μ(x, z0 +) = E(Y0 | X = x, Z = z0 )
P (z0 +)

+

E(Y1 − Y0 | X = x, UD = uD ) duD ,

0

where we use the fact that E(Y0 | X = x, Z = z) is continuous at z0 . Thus,
μ(x, z0 +) − μ(x, z0 −) =
⇒

P (z0 +)
P (z0 −)

E(Y1 − Y0 | X = x, UD = uD ) duD



μ(x, z0 +) − μ(x, z0 −)
= E Y1 − Y0 X = x, P (z0 +)  UD > P (z0 −)
P (z0 +) − P (z0 −)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4967

so that we now recover a LATE parameter for a particular point of evaluation. Note that
if P (z) is only discontinuous at z0 , then we only identify E(Y1 −Y0 | X = x, P (z0 +) 
UD > P (z0 −)) and not any LATE or MTE at any other evaluation points. While this
discussion assumes that Z is a scalar, it is straightforward to generalize the discussion
to allow for Z to be a vector. For more discussion of the regression discontinuity design
estimator and an example, see Hahn, Todd and Van der Klaauw (2001).

6. Policy evaluation, out-of-sample policy forecasting, forecasting the effects of
new policies and structural models based on the MTE
We have thus far focused on policy problem P-1, the problem of “internal validity”. We
have shown how to identify a variety of parameters but have not put them to use in evaluating policies. This section discusses policy evaluation and out-of-sample forecasting.
We discuss two distinct evaluation and forecasting problems. The first problem uses the
MTE to develop a cost benefit analysis. Corresponding to the gross benefit parameters
analyzed in Sections 3–4, there is a parallel set of cost parameters that emerge from the
economics of the generalized Roy model. This part of our analysis works in the domain
of problem P-1 to construct a cost-benefit analysis for programs in place. However,
these tools can be extended to new environments using the other results established in
this section.
The second topic is the problem of constructing the PRTE in new environments in
a more general way. This addresses policy problems P-2 and P-3 and considers large
scale changes in policies and forecasts of new policies.
6.1. Econometric cost benefit analysis based on the MTE
This section complements the analysis of Section 3. There we developed gross outcome measures for a generalized Roy model. Here we define a parallel set of treatment
parameters for the generalized Roy model corresponding to the average cost of participating in a program. The central feature of the generalized Roy model is that the agent
chooses treatment if the benefit exceeds the subjective cost perceived by the agent. This
creates a simple relationship between the cost and benefit parameters that can be exploited for identifying or bounding the cost parameters by adapting the results of the
previous sections. The main result of this section is that cost parameters in the generalized Roy model can be identified or bounded without direct information on the costs of
treatment. Our analysis complements and extends the analysis of Björklund and Moffitt
(1987) who first noted this duality.
Assume the outcomes (Y0 , Y1 ) are generated by the additively separable system (2.2).
Let C denote the individual-specific subjective cost of selecting into treatment. We assume that C is generated by: C = μC (W ) + UC , where W is a (possibly vector-valued)
observed random variable and UC is an unobserved random variable. We assume that
the agent selects into treatment if the benefit exceeds the cost, using the structure of

4968

J.J. Heckman and E.J. Vytlacil

the generalized Roy model where D = 1[Y1 − Y0  C] and C = μC (W ) + UC ,
where μC (W ) is nondegenerate and integrable; UC is continuous and Z = (W, X) is
independent of (UC , U0 , U1 ).91
We do not assume any particular functional form for the functions μ0 , μ1 and μC ,
and we do not assume that the distribution of U0 , U1 , or UC is known.92 Let V ≡
UC − (U1 − U0 ) and let FV denote the distribution function of V . As before, we use
the convention that UD is the probability integral transformation of the latent variable
generating choices so that UD = FV (V ). Let P (z) ≡ Pr(D = 1 | Z = z) so that
P (z) = FV (μ1 (x) − μ0 (x) − μC (w)). For convenience, we will assume that FV is
strictly increasing so that FV will be invertible, though this assumption is not required.
We work with UD = FV (V ) instead of working directly with V to link our analysis
to that in Section 3. In this section we make explicit the conditioning on X, Z, and W
because it plays an important role in the analysis.
Corresponding to the treatment parameters defined in Section 2 and Tables 2A and
2B, we can define analogous cost parameters. We define the marginal cost of treatment
for a person with characteristics W = w and UD = uD as
C MTE (w, uD ) ≡ E(C | W = w, UD = uD ).
This is a cost version of the marginal treatment effect. Likewise, we have an analogue
average cost:
C ATE (w) ≡ E(C | W = w)
1

=

E(C | W = w, UD = uD ) duD ,

(6.1)

0

recalling that dFUD (uD ) = duD because UD is uniform. This is the mean subjective
cost of treatment as perceived by the average agent. We next consider




C TT w, P (z) ≡ E C W = w, P (Z) = P (z), D = 1
=

1
P (z)

P (z)

E(C | W = w, UD = uD ) duD .

0

This is the mean subjective cost of treatment as perceived by the treated with a given
value of P (z). Removing the conditioning on P (z),
C TT (w) ≡ E(C | W = w, D = 1)
1

=

E(C | W = w, UD = uD )gw (uD ) duD ,

0

91 We require that U be absolutely continuous with respect to Lebesgue measure.
C
92 Recall that the original Roy model (1951) assumes that U = 0, that there are no observed X and W reC
gressors, that (U0 , U1 ) ∼ N (0, Σ) and that only Y = DY1 + (1 − D)Y0 is observed, but not both components

of the sum at the same time.

Ch. 71:

Econometric Evaluation of Social Programs, Part II
1−F

4969

(u )

D
where gw (uD ) = (1−FP (Z)|W =w (t))
and FP (Z)|W =w denotes the distribution of P (Z)
dt
P (Z)|W =w
conditional on W = w. This is the mean subjective cost of treatment for the treated.
Finally, we can derive a LATE version of the cost:



C LATE w, P (z), P (z ) ≡

1
P (z) − P (z )

P (z)

E(C | W = w, UD = uD ) duD .

P (z )

This is the mean subjective cost of switching states for those induced to switch status
by a change in the instrument.
The generalized Roy model makes a tight link between the cost of treatment and the
benefit of treatment. Thus one might expect a relationship between the gross benefit and
cost parameters. We show that the benefit and cost parameters coincide for MTE. This
relationship can be used to infer information on the subjective cost of treatment by the
use of local instrumental variables.
Define LIV (x, P (z)) as in Equation (4.9):

 ∂E(Y | X = x, P (Z) = P (z))
LIV x, P (z) ≡
.
∂P (z)
Under assumptions (A-1)–(A-5), LIV identifies MTE:




LIV x, P (z) = MTE x, P (z) .
Note that




MTE x, P (z) = E  X = x, UD = P (z)


= E  X = x, (x) = C(w)


= E (x) (x) = C(w) ,

(6.2)

where (x) = μ1 (x) − μ0 (x) + U1 − U0 , and C(w) = μC (w) + UC . ((x) and C(w)
are, respectively, the benefit and cost for the agent if the X and W are externally set to
x and w without changing (U1 , U0 , UD ) values.) We thus obtain




E (x) (x) = C(w) = E C(w) (x) = C(w)


= E C(w) W = w, UD = P (z)


= C MTE w, P (z) .
(6.3)
Thus,






LIV x, P (z) = MTE x, P (z) = C MTE w, P (z) ,

(6.4)

where LIV (w, P (z)) is LIV (x, P (z)) defined for the support where (x) = C(w).
The benefit and cost parameters coincide for the MTE parameter because at the margin,
the marginal cost should equal the marginal benefit. The benefit to treatment for an
agent indifferent between treatment and no treatment is equal to the cost of treatment,
and thus the two parameters coincide.

4970

J.J. Heckman and E.J. Vytlacil

Suppose that one has access to a large sample of (Y, D, X, W ) observations.
(Z)=P (z))
, LIV (x, P (z)) can be identified for any
Since LIV (x, P (z)) = ∂E(Y |X=x,P
∂P (z)
(x, P (z)) in the support of (X, P (Z)), and thus the corresponding MTE (x, P (z)) and
C MTE (w, P (z)) parameters can also be identified.93 One can thus identify the marginal
cost parameter without direct information on the cost of treatment by using the structure
of the Roy model and by identifying the marginal benefit parameter.
Heckman and Vytlacil (1999) establish conditions under which LIV can be used to
identify ATE and TT given large support conditions, and to bound those parameters
without large support conditions if the outcome variables are bounded. We review their
results on bounds in Section 10. We surveyed their results on identification of ATE
and TT in Sections 3 and 4. From (6.1) and (6.4), we can use the same arguments
to use C MTE to identify or bound C ATE and C TT . Thus, C MTE can be used to identify
C ATE (w) if the support of P (Z) conditional on W = w is the full unit interval. If the
support of P (Z) conditional on W = w is a proper subset of the full unit interval,
then C MTE can be used to bound C ATE (x) if C is bounded. One can thus identify or
bound the average cost of treatment or the cost of treatment on the treated without
direct information on the cost of treatment.
We next consider what information is available on the underlying benefit functions
μ0 and μ1 and the underlying cost function μC (w). From the definitions,




MTE x, P (z) = E  X = x, UD = P (z)


= μ1 (x) − μ0 (x) + Υ P (z)
(6.5)
with Υ (P (z)) = E(U1 − U0 | UD = P (z)). Likewise,




C MTE w, P (z) = E C W = w, UD = P (z)


= μC (w) + Γ P (z) ,

(6.6)

=
and recall from
with Γ (P (z)) = E(UC | UD = P (z)). Let
the preceding analysis that LIV (z) = MTE (x, P (z)) = C MTE (w, P (z)). Consider
two points of evaluation (z, z ) such that P (z) = P (z ). Using Equation (6.4), we obtain

 

LIV (z) − LIV (z ) = μ1 (x) − μ0 (x) − μ1 (x ) − μ0 (x )
LIV (z)

LIV (x, P (z)),

= μC (w) − μC (w ).
Assuming that X and W each have at least one component not in the other, we can
identify μC (w) up to constants within the support of W conditional on P (Z) = P (z)
using LIV (z). Shifting z while conditioning on P (z) shifts (μ1 (x)−μ0 (x)) and μC (w)
along the line (μ1 (x)−μ0 (x))−μC (w) = FV−1 (p). Thus, conditional on P (z), a shift in
the benefit, μ1 (X)−μ0 (X), is associated with the same shift in the cost, μC (w). For any
p ∈ (0, 1), let Ωp = {z: P (z) = p} = {(w, x): (μ1 (x) − μ0 (x)) − μC (w) = FV−1 (p)}.
93 Formally, these parameters are identified in the limit points of the set.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4971

As we vary z within the set Ωp , we trace out changes in μC (w) and μ1 (x) − μ0 (x),
where the changes in μC (w) equal the changes in μ1 (x) − μ0 (x).
For the special case of the generalized Roy model where UC is degenerate, LIV (z) =
μC (w). Thus, in the case of a deterministic cost function, LIV identifies μC (w). We plot
this case in Figures 5A–5C for the country policy adoption example where the cost C is
a constant across all countries.
In the case where UC is nondegenerate but U1 −U0 is degenerate, Y1 −Y0 = μ1 (X)−
μ0 (X) (β = β̄ in the context of the model of Section 2), and there is no variation
in the gross benefit from participating in the program conditional on X. In that case,
LIV (z) = μ1 (x) − μ0 (x) = β̄, where we keep the conditioning on X implicit in
defining LIV (z). Thus, in the case of a deterministic benefit from participation, LIV
identifies the benefit function. If UD and U1 − U0 are both degenerate, then LIV (z) is
not well defined.94
In summary, the generalized Roy model structure can be exploited to identify cost
parameters without direct information on the cost of treatment. The MTE parameter for
cost is immediately identified within the proper support, and can be used to identify or
bound the average cost of treatment and the cost of treatment on the treated. In addition,
the MTE parameter allows one to infer how the cost function shifts in response to a
change in observed covariates, and to completely identify the cost function if the cost of
treatment is deterministic conditional on observable covariates. Thus we can compute
the costs and benefits of alternative programs for various population averages. Heckman
and Vytlacil (2007) develop this analysis to consider marginal extensions of the policy
relevant treatment effect (PRTE).
6.2. Constructing the PRTE in new environments
In this section, we present conditions for constructing PRTE for new environments and
for new programs using historical data for general changes in policies and environments.
We consider general changes in the environment and policies and not just the marginal perturbations of the P (Z) considered in the previous section. We address policy
problems P-2, forecasting the effects of existing policies to new environments and P-3,
forecasting the effects of new policies, never previously implemented.
Let p ∈ P denote a policy characterized by random vector Zp . The usage of “p”
in this section is to be distinguished from a realized value of P (Z) as in most other
sections in this chapter. Let e ∈ E denote an environment characterized by random
vector Xe . A history, H, is a collection of policy–environment (p, e) pairs that have
been experienced and documented. We assume that the environment is autonomous so

94 In this case, E(Y −Y | Z = z, D = 0) is well defined for z = (w, x) such that μ (x)−μ (x)  μ (w),
C
1
0
1
0
in which case E(Y1 −Y0 | Z = z, D = 0) = μ1 (x)−μ0 (x)  μC (w). Likewise E(Y1 −Y0 | Z = z, D = 1)
is well defined for z = (w, x) such that μ1 (x) − μ0 (x)  μC (w), in which case E(Y1 − Y0 | Z = z,
D = 1) = μ1 (x) − μ0 (x)  μC (w).

4972

J.J. Heckman and E.J. Vytlacil

the choice of p does not affect Xe . Letting Xe,p denote the value of Xe under policy p,
autonomy requires that
(A-8) Xe,p = Xe , ∀p, e (Autonomy).
Autonomy is a more general notion than the no-feedback assumption introduced
in (A-6). They are the same when the policy is a treatment. General equilibrium feedback effects can cause a failure of autonomy. In this section, we will assume autonomy,
in accordance with the partial equilibrium tradition in the treatment effect literature.95
Autonomy is a version of Hurwicz’s policy invariance postulate but for a random variable and not a function.
Evaluating a particular policy p in environment e is straightforward if (p , e ) ∈ H.
One simply looks at the associated outcomes and treatment effects formed in that policy
environment and applies the methods previously discussed to obtain internally valid estimates. The challenge comes in forecasting the impacts of policies (p ) in environments
(e ) for (p , e ) not in H.
We show how MTE plays the role of a policy-invariant functional that aids in creating counterfactual states never previously experienced. We focus on the problem of
constructing the policy relevant treatment effect PRTE but our discussion applies more
generally to the other treatment parameters.
Given the assumptions invoked in Section 3, MTE can be used to evaluate a whole
menu of policies characterized by different conditional distributions of Pp . In addition,
given our assumptions, we can focus on how policy p , which is characterized by Zp ,
produces the distribution FPp |X which weights an invariant MTE without having to
conduct a new investigation of (Y, X, Z) relationships for each proposed policy.96
6.2.1. Constructing weights for new policies in a common environment
The problem of constructing PRTE for policy p (compared to baseline policy p̄)
in environment e when (p , e) ∈
/ H entails constructing E(Υ (Yp )). We maintain
the assumption that the baseline policy is observed, so (p̄, e) ∈ H. We also postulate instrumental variable assumptions (A-1)–(A-5), presented in Section 3, and the
policy invariance assumption (A-7), presented in Section 3.2 and embedded in assumption (A-8). We use separable choice Equation (3.3) to characterize choices. The policy
is assumed not to change the distribution of (Y0 , Y1 , UD ) conditional on X. Under these
conditions, Equation (3.6) is a valid expression for PRTE and constructing PRTE only
requires identification of MTE and constructing FPp |Xe from the policy histories He ,
defined as the elements of H for a particular environment e, He = {p: (p, e) ∈ H}.

95 See Heckman, Lochner and Taber (1998) for an example of a nonautonomous treatment model.
96 Ichimura and Taber (2002) present a discussion of local policy analysis in a more general framework with-

out the MTE structure, using a framework developed by Hurwicz (1962). We review the Hurwicz framework
in Chapter 70.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4973

Associated with the policy histories p ∈ He is a collection of policy variables
{Zp : p ∈ He }. Suppose that a new policy p can be written as Zp = Tp ,j (Zj ) for
some j ∈ He , where Tp ,j is a known deterministic transformation and Zp has the
same list of variables as Zj . Examples of policies that can be characterized in this way
are tax and subsidy policies on wages, prices and incomes that affect unit costs (wages
or prices) and transfers. Tuition might be shifted upward for everyone by the same
amount, or tuition might be shifted according to a nonlinear function of current tuition,
parents’ income, and other observable characteristics in Zj .
Constructing FPp |Xe from data in the policy history entails two distinct steps. From
the definitions,



Pr(Pp  t | Xe ) = Pr Zp : Pr(Dp = 1 Zp , Xe )  t | Xe .
If (i) we know the distribution of Zp , and (ii) we know the function Pr(Dp = 1 |
Zp = z, Xe = x) over the appropriate support, we can then recover the distribution of
Pp conditional on Xe . Given that Zp = Tp ,j (Zj ) for a known function Tp ,j (·), step
(i) is straightforward since we recover the distribution of Zp from the distribution of Zj
by using the fact that Pr(Zp  t | Xe ) = Pr({Zj : Tp ,j (Zj )  t} | Xe ). Alternatively,
part of the specification of the policy p might be the distribution Pr(Zp  t | Xe ). We
now turn to the second step, recovering the function Pr(Dp = 1 | Zp = z, Xe = x)
over the appropriate support.
If Zp and Zj contain the same elements though possibly with different distributions,
then a natural approach to forecasting the new policy is to postulate that
Pj (z) = Pr(Dj = 1 | Zj = z, Xe )
= Pr(Dp = 1 | Zp = z, Xe ) = Pp (z),

(6.7)
(6.8)

i.e., that over a common support for Zj and Zp the known conditional probability
function and the desired conditional probability function agree. Condition (6.7) will
⊥V |
hold, for example, if Dj = 1[μD (Zj )−V  0], Dp = 1[μD (Zp )−V  0], Zj ⊥
⊥ UD | Xe , recalling that UD = FV |X (V ). Even if condition (6.7) is
Xe , and Zp ⊥
satisfied on a common support, the support of Zj and Zp may not be the same. If
the support of the distribution of Zp is not contained in the support of the distribution
of Zj , then some form of extrapolation is needed. Alternatively, if we strengthen our
assumptions
so that (6.7) holds for all j ∈ He , we can identify Pp (z) for all z in

Supp(Z
j ). However,
j ∈He
 there is no guarantee that the support of the distribution
of Zp will be contained in j ∈He Supp(Zj ), in which case some form of extrapolation
is needed.
If extrapolation is required, one approach is to assume a parametric functional form
for Pj (·). Given a parametric functional form, one can use the joint distribution of
(Dj , Zj ) to identify the unknown parameters of Pj (·) and then extrapolate the parametric functional form to evaluate Pj (·) for all evaluation points in the support of Zp .

4974

J.J. Heckman and E.J. Vytlacil

Alternatively, if there is overlap between the support of Zp and Zj ,97 so there is some
overlap in the historical and policy p supports of Z, we may use nonparametric methods presented in Matzkin (1994) and extended by her in Chapter 73 (Matzkin) of this
Handbook, based on functional restrictions (e.g., homogeneity) to construct the desired
probabilities on new supports or to bound them. Under the appropriate conditions, we
may use analytic continuation to extend Pr(Dj = 1 | Zj = z, Xe = x) to a new support
for each Xe = x [Rudin (1974)].
The approach just presented is based on the assumption stated in Equation (6.7). That
assumption is quite natural when Zp and Zj both contain the same elements, say they
both contain tuition and parent’s income. However, in some cases Zp might contain
additional elements not contained in Zj . As an example, Zp might include new user
fees while Zj consists of taxes and subsidies but does not include user fees. In this case,
the assumption stated in Equation (6.7) is not expected to hold and is not even well
defined if Zp and Zj contain a different number of elements.
A more basic approach analyzes a class of policies that operate on constraints, prices
and endowments arrayed in vector Q. Given the preferences and technology of the
agent, a given Q = q, however arrived at, generates the same choices for the agent.
Thus a wage tax offset by a wage subsidy of the same amount produces a wage that has
the same effect on choices as a no-policy wage. Policy j affects Q (e.g., it affects prices
paid, endowments and constraints). Define a map Φj : Zj → Qj which maps a policy j , described by Zj , into its consequences (Qj ) for the baseline, fixed-dimensional
vector Q. A new policy p , characterized by Zp , produces Qp that is possibly different
from Qj for all previous policies j ∈ He .
To construct the random variable Pp = Pr(Dp = 1 | Zp , Xe ), we postulate that


Pr Dj = 1 Zj ∈ Φj−1 (q), Xe = x = Pr(Dj = 1 | Qj = q, Xe = x)
= Pr(Dp = 1 | Qp = q, Xe = x)


= Pr Dp = 1 Zp ∈ Φp−1 (q), Xe = x ,
where Φj−1 (q) = {z: Φj (z) = q} and Φp−1 (q) = {z: Φp (z) = q}. Given these
assumptions, our ability to recover Pr(Dp = 1 | Zp = z, Xe = x) for all (z, x) in
the support of (Zp , Xe ) depends on what Φj functions have been historically observed
and the richness of the histories of Qj , j ∈ He . For each zp evaluation point in the
support of the distribution of Zp , there is a corresponding q = Φp (zp ) evaluation
point in the support of the distribution of Qj = Φj (Zj ). If, in the policy histories, there
is at least one j ∈ He such that Φj (zj ) = q for a zj with (zj , x) in the support of the
distribution of (Zj , Xe ), then we can construct the probability of the new policy from
data in the policy histories. The methods used to extrapolate Pp (·) over new regions,
discussed previously, apply here. If the distribution of Qp (or Φp and the distribution
97 If we strengthen condition (6.7) to hold for all j ∈ H , then the condition becomes that Supp(Z ) ∩
e
p

j ∈He Supp(Zj ) is not empty.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4975

of Zp ) is known as part of the specification of the proposed policy, the distribution of
FPp |Xe can be constructed using the constructed Pp . Alternatively, if we can relate Qp
to Qj by Qp = Ψp ,j (Qj ) for a known function Ψp ,j or if we can relate Zp to Zj
by Zp = Tp ,j (Zj ) for a known function Tp ,j , and the distributions of Qj and/or Zj
are known for some j ∈ He , we can apply the method previously discussed to derive
FPp |Xe and hence the policy weights for the new policy.
This approach assumes that a new policy acts on components of Q like a policy
in He , so it is possible to forecast the effect of a policy with nominally new aspects. The
essential idea is to recast the new aspects of policy in terms of old aspects previously
measured. Thus in a model of schooling, let D = 1[Y1 − Y0 − B  0] where Y1 − Y0
is the discounted gain in earnings from going to school and B is the tuition cost. In this
example, a decrease in a unit of cost (B) has the same effect on choice as an increase in
return (Y1 − Y0 ). Historically, we might only observe variation in Y1 − Y0 (say tuition
has never previously been charged). But B is on the same footing (has the same effect
on choice, except for sign) as Y1 − Y0 . The identified historical variation in Y1 − Y0
can be used to nonparametrically forecast the effect of introducing B, provided that
the support of Pp is in the historical support generated by the policy histories in He .
Otherwise, some functional structure (parametric or semiparametric) must be imposed
to solve the support problem for Pp . We used this basic principle in constructing our
econometric cost benefit analysis in Section 6.1.
As another example, following Marschak (1953), consider the introduction of wage
taxes in a world where there has never before been a tax. This example is analyzed in
Heckman (2001). Let Zj be the wage without taxes. We seek to forecast a post-tax net
wage Zp = (1 − τ )Zj + b where τ is the tax rate and b is a constant shifter. Thus
Zp is a known linear transformation of policy Zj . We can construct Zp from Zj . We
can forecast under (A-1) using Pr(Dj = 1 | Zj = z) = Pr(Dp = 1 | Zp = z). This
assumes that the response to after tax wages is the same as the response to wages at
the after tax level. The issue is whether Pp |Xe lies in the historical support, or whether
extrapolation is needed. Nonlinear versions of this example can be constructed.
As a final example, environmental economists use variation in one component of cost
(e.g., travel cost) to estimate the effect of a new cost (e.g., a park registration fee). See
Smith and Banzhaf (2004). Relating the costs and characteristics of new policies to
the costs and characteristics of old policies is a standard, but sometimes controversial,
method for forecasting the effects of new policies.
In the context of our model, extrapolation and forecasting are confined to constructing Pp and its distribution. If policy p , characterized by vector Zp , consists of new
components that cannot be related to Zj , j ∈ He , or a base set of characteristics whose
variation cannot be identified, the problem is intractable. Then Pp and its distribution
cannot be formed using econometric methods applied to historical data.
When it can be applied, our approach allows us to simplify the policy forecasting
problem and concentrate our attention on forecasting choice probabilities and their distribution in solving the policy forecasting problem. We can use choice theory and choice

4976

J.J. Heckman and E.J. Vytlacil

data to construct these objects to forecast the impacts of new policies, by relating new
policies to previously experienced policies.
6.2.2. Forecasting the effects of policies in new environments
When the effects of policy p are forecast for a new environment e from baseline environment e, and Xe = Xe , in general both MTE (x, uD ) and FPp |Xe will change.
In general, neither object is environment invariant.98 The new Xe may have a different support than Xe or any other environment in H. In addition, the new (Xe , UD )
stochastic relationship may be different from the historical (Xe , UD ) stochastic relationship. Constructing FPp |Xe from FPp |Xe and FZp |Xe from FZp |Xe can be done using
(i) functional form (including semiparametric functional restrictions) or (ii) analytic
continuation methods. Notice that the maps Tp,j and Φp may depend on Xe and so the
induced changes in these transformations must also be modeled. There is a parallel discussion for MTE (x, uD ). The stochastic dependence between Xe and (U0 , U1 , UD )
may be different from the stochastic dependence between Xe and (U0 , U1 , UD ). We
suppress the dependence of U0 and U1 on e and p only for convenience of exposition
and make it explicit in the next paragraph.
Forecasting new stochastic relationships between Xe and (U1 , U0 , UD ) is a difficult
task. Some of the difficulty can be avoided if we invoke the traditional exogeneity assumptions of classical econometrics:
(A-9) (U0,e,p , U1,e,p , UD,e,p ) ⊥
⊥ (Xe , Zp ) ∀e, p.
Under (A-9), we only encounter the support problems for MTE and the distribution of
Pr(Dp = 1 | Zp , Xe ) in constructing policy counterfactuals.
Conditions (A-7)–(A-9) are unnecessary if the only goal of the analysis is to establish internal validity, the standard objective of the treatment effect literature. This is
problem P-1. Autonomy and exogeneity conditions become important issues if we seek
external validity. An important lesson from this analysis is that as we try to make the
treatment effect literature do the tasks of structural econometrics (i.e., make out-ofsample forecasts), common assumptions are invoked in the two literatures.
6.2.3. A comparison of three approaches to policy evaluation
Table 9 compares the strengths and limitations of the three approaches to policy evaluation that we have discussed in this Handbook chapter and our contribution in Chapter 70:
the structural approach, the conventional treatment effect approach, and the approach to
treatment effects based on the MTE function developed by Heckman and Vytlacil (1999,
2001b, 2005).

98 We suppress the dependence of U on p for notational convenience.
D

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4977

Table 9
Comparison of alternative approaches to program evaluation
Structural econometric
approach

Treatment effect
approach

Approach based on MTE

Interpretability

Well defined economic
parameters and welfare
comparisons

Link to economics and
welfare comparisons
obscure

Interpretable in terms of
willingness to pay;
weighted averages of the MTE
answer well-posed economic
questions

Range of
questions
addressed
Extrapolation to
new
environments

Answers many
counterfactual questions

Focuses on one
treatment effect or
narrow range of effects
Evaluates one program
in one environment

With support conditions,
generates all
treatment parameters
Can be partially extrapolated;
extrapolates to new policy
environments with different
distributions of the probability of
participation due solely to
differences in distributions of Z

Comparability
across studies

Policy invariant
parameters comparable
across studies

Not generally
comparable

Partially comparable; comparable
across environments with
different distributions of the
probability of participation due
solely to differences in
distributions of Z

Key econometric
problems

Exogeneity, policy
invariance and selection
bias

Selection bias

Selection bias: Exogeneity and
policy invariance if used for
forecasting

Range of policies
that can be
evaluated

Programs with either
partial or universal
coverage, depending on
variation in data
(prices/endowments)

Programs with partial
coverage (treatment and
control groups)

Programs with partial coverage
(treatment and control groups)

Extension to
general
equilibrium
evaluation

Need to link to time
series data; parameters
compatible with general
equilibrium theory

Difficult because link to
economics is not
precisely specified

Can be linked to nonparametric
general equilibrium models under
exogeneity and policy invariance

Provides ingredients for
extrapolation

Source: Heckman and Vytlacil (2005).

The approach based on the MTE function and the structural approach share interpretability of parameters. Like the structural approach, it addresses a range of policy
evaluation questions. The MTE parameter is less comparable and less easily extrapolated across environments than are structural parameters, unless nonparametric versions
of invariance and exogeneity assumptions are made. However, MTE is comparable
across populations with different distributions of P (conditional on Xe ) and results from
one population can be applied to another population under the conditions presented in
this section. Analysts can use MTE to forecast a variety of policies. This invariance

4978

J.J. Heckman and E.J. Vytlacil

property is shared with conventional structural parameters. Our framework solves the
problem of external validity, which is ignored in the standard treatment effect approach.
The price of these advantages of the structural approach is the greater range of econometric problems that must be solved. They are avoided in the conventional treatment
approach at the cost of producing parameters that cannot be linked to well-posed economic models and hence do not provide building blocks for an empirically motivated
general equilibrium analysis or for investigation of the impacts of new public policies.
MTE estimates the preferences of the agents being studied and provides a basis for
integration with well posed economic models. If the goal of a study is to examine one
policy in place (the problem of internal validity), the stronger assumptions invoked in
this section of the chapter, and in structural econometrics, are unnecessary. Even if this
is the only goal of the analysis however, our approach allows the analyst to generate all
treatment effects and IV estimands from a common parameter and provides a basis for
unification of the treatment effect literature.

7. Extension of MTE to the analysis of more than two treatments and associated
outcomes
We have thus far analyzed models with two potential outcomes associated with receipt
of binary treatments (D = 0 or D = 1). Focusing on this simple case allows us to
develop main ideas. However, models with more than two outcomes are common in
empirical work. Angrist and Imbens (1995) analyze an ordered choice model with a
single instrument that shifts people across all margins. We generalize their analysis in
several ways. We consider vectors of instruments, some of which may affect choices at
all margins and some of which affect choices only at certain margins. We then analyze
a general unordered choice model.
7.1. Background for our analysis of the ordered choice model
Angrist and Imbens (1995) extend their analysis of LATE to an ordered choice model
with outcomes generated by a scalar instrument that can assume multiple values. From
their analysis of the effect of schooling on earnings, it is unclear even under a strengthened “monotonicity” condition whether IV estimates the effect of a change of schooling
on earnings for a well defined margin of choice.
To summarize their analysis, let S̄ be the number of possible outcome states with
associated outcomes Ys and choice indicators Ds , s = 1, . . . , S̄. The s, in their analysis,
correspond to different levels of schooling. For any two instrument values Z = zi and
Z = zj with zi > zj , we can define associated indicators {Ds (zi )}S̄s=1 and {Ds (zj )}S̄s=1 ,
where Ds (zi ) = 1 if a person assigned instrument value zi chooses state s. As in the
two-outcome model, the instrument Z is assumed to be independent of the potential
outcomes {Ys }S̄s=1 as well as the associated indicator functions defined by fixing Z at zi

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4979

S̄
and zj . Observed schooling for instrument zj is S(zj ) =
s=1 sDs (zj ). Observed
S̄
outcomes with this instrument are Y (zj ) = s=1 Ys Ds (zj ).
Angrist and Imbens show that IV (with Z = zi and Z = zj ) applied to S in a two
stage least squares regression of Y on S identifies a “causal parameter”
IV =

S̄

 
 Pr(S(zi )  s > S(zj ))
E Ys − Ys−1 S(zi )  s > S(zj ) 
.
S̄
s=2
s=2 Pr(S(zi )  s > S(zj ))
(7.1)

This “causal parameter” is a weighted average of the gross returns from going from s −1
to s for persons induced by the change in the instrument to move from any schooling
level below s to any schooling level s or above. Thus the conditioning set defining the
sth component of IV includes people who have schooling below s − 1 at instrument
value Z = zj and people who have schooling above level s at instrument value Z =
zi . In expression (7.1), the average return experienced by some of the people in the
conditioning set for each component conditional expectation does not correspond to the
average outcome corresponding to the gain in the argument of the expectation. In the
case where S̄ = 2, agents face only two choices and the margin of choice is well defined.
Agents in each conditioning set are at different margins of choice. The weights are
positive but, as noted by Angrist and Imbens (1995), persons can be counted multiple
times in forming the weights. When they generalize their analysis to multiple-valued
instruments, they use the Yitzhaki (1989) weights.
Whereas the weights in Equation (7.1) can be constructed empirically using nonparametric discrete choice theory (see, e.g., our analysis in Appendix B of Chapter 70 or
the contribution of Matzkin to this Handbook), the terms in braces cannot be identified
by any standard IV procedure.99 We present decompositions with components that are
recoverable, whose weights can be estimated from the data and that are economically
interpretable.
In this section, we generalize LATE to a multiple outcome case where we can identify agents at different well-defined margins of choice. Specifically, we (1) analyze both
ordered and unordered choice models; (2) analyze outcomes associated with choices at
various well-defined margins; and (3) develop models with multiple instruments that
can affect different margins of choice differently. With our methods, we can define and
estimate a variety of economically interpretable parameters. In contrast, the Angrist–
Imbens analysis produces a single “causal parameter” (7.1) that does not answer any
well-defined policy question such as that posed by the PRTE. We first consider an
explicit ordered choice model and decompose the IV into policy-useful (identifiable)
components.

99 It can be identified by a structural model using the methods surveyed in Chapter 72.

4980

J.J. Heckman and E.J. Vytlacil

7.2. Analysis of an ordered choice model
Ordered choice models arise in many settings. In schooling models, there are multiple
grades. One has to complete grade s − 1 to proceed to grade s. The ordered choice
model has been widely used to fit data on schooling transitions [Harmon and Walker
(1999), Cameron and Heckman (1998)]. Its nonparametric identifiability has been studied [Carneiro, Hansen and Heckman (2003), Cunha, Heckman and Navarro (2007)].
It can also be used as a duration model for dynamic treatment effects with associated
outcomes as in Cunha, Heckman and Navarro (2007). It also represents the “vertical”
model of the choice of product quality [Prescott and Visscher (1977), Shaked and Sutton
(1982), Bresnahan (1987)].100
Our analysis generalizes the analysis for the binary model in a parallel way. Write
potential outcomes as
Ys = μs (X, Us ),

s = 1, . . . , S̄.

The S̄ could be different schooling levels or product qualities. We define latent variables
DS∗ = μD (Z) − V where


Ds = 1 Cs−1 (Ws−1 ) < μD (Z) − V  Cs (Ws ) ,

s = 1, . . . , S̄,

and the cutoff values satisfy
Cs−1 (Ws−1 )  Cs (Ws ),

C0 (W0 ) = −∞ and

CS̄ (WS̄ ) = ∞.

The cutoffs used to define the intervals are allowed to depend on observed (by the
economist) regressors Ws . In Appendix G we extend the analysis presented in the text
to allow the cutoffs to depend on unobserved regressors as well, following structural
analysis along these lines by Carneiro, Hansen and Heckman (2003) and Cunha, Heck
man and Navarro (2007). Observed outcomes are: Y = S̄s=1 Ys Ds . The Z shift the
index generally; the Ws affect s-specific transitions. Thus, in a schooling example, Z
could include family background variables while Ws could include college tuition or opportunity wages for unskilled labor.101 Collect the Ws into W = (W1 , . . . , WS̄ ), and the
Us into U = (U1 , . . . , US̄ ). Larger values of Cs (Ws ) make it more likely that Ds = 1.
The inequality restrictions on the Cs (Ws ) functions play a critical role in defining the
model and producing its statistical implications.

100 Cunha, Heckman and Navarro (2007) analyze a dynamic discrete choice setting with sequential revelation

of information.
101 Many of the instruments studied by Harmon and Walker (1999) and Card (2001) are transition-specific.
Card’s model of schooling is not sufficiently rich to make a distinction between the Z and the W . See Heckman
and Navarro (2007) and Cunha, Heckman and Navarro (2007) for more general models of schooling that make
these distinctions explicit.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4981

Analogous to the assumptions made for the binary outcome model, we assume
(OC-1) (Us , V ) ⊥
⊥ (Z, W ) | X, s = 1, . . . , S̄ (Conditional independence of the instruments);
(OC-2) μD (Z) is a nondegenerate random variable conditional on X and W (Rank
condition);
(OC-3) the distribution of V is continuous102 ;
(OC-4) E(|Ys |) < ∞, s = 1, . . . , S̄ (Finite means);
(OC-5) 0 < Pr(Ds = 1 | X) < 1 for s = 1, . . . , S̄, for all X (In large samples, there
are some persons in each treatment state);
(OC-6) for s = 1, . . . , S̄ −1, the distribution of Cs (Ws ) conditional on X, Z and the
other Cj (Wj ), j = 1, . . . , S̄, j = s, is nondegenerate and continuous.103
Assumptions (OC-1)–(OC-5) play roles analogous to their counterparts in the twooutcome model, (A-1)–(A-5). (OC-6) is a new condition that is key to identification
of the MTE defined below for each transition. It assumes that we can vary the choice
sets of agents at different margins of schooling choice without affecting other margins
of choice. A necessary condition for (OC-6) to hold is that at least one element of Ws is
nondegenerate and continuous conditional on X, Z and Cj (Wj ) for j = s. Intuitively,
one needs an instrument (or source of variability) for each transition. The continuity of
the regressor allows us to differentiate with respect to Cs (Ws ), like we differentiated
with respect to P (Z) to estimate the MTE in the analysis of the two-outcome model.
The analysis of Angrist and Imbens (1995) discussed in the introduction to this section makes independence and monotonicity assumptions that generalize their earlier
work. They do not consider estimation of transition-specific parameters as we do, or
even transition-specific LATE. We present a different decomposition of the IV estimator where each component can be recovered from the data, and where the transitionspecific MTEs answer well-defined and economically interpretable policy evaluation
questions.104
The probability of Ds = 1 given X, Z and W is generated by an ordered choice
model:
Pr(Ds = 1 | Z, W, X) ≡ Ps (Z, W, X)


= Pr Cs−1 (Ws−1 ) < μD (Z) − V  Cs (Ws ) X .
Analogous to the binary case, we can define UD = FV |X (V ) so UD ∼ Unif[0, 1]
under our assumption that the distribution of V is absolutely continuous with respect to Lebesgue measure. The probability integral transformation used extensively
102 Absolutely continuous with respect to Lebesgue measure.
103 Absolutely continuous with respect to Lebesgue measure.
104 Vytlacil (2006b) shows that their monotonicity and independence conditions imply (and are implied by)
a more general version of the ordered choice model with stochastic thresholds, which appears in Heckman,
LaLonde and Smith (1999), Carneiro, Hansen and Heckman (2003), and Cunha, Heckman and Navarro
(2007), and is analyzed in Appendix G.

4982

J.J. Heckman and E.J. Vytlacil

in the binary choice model is somewhat less useful for analyzing ordered choices,
so we work with both UD and V in this section of the chapter. Monotonic transformations of V induce monotonic transformations of μD (Z) − Cs (Ws ), but one is
not free to form arbitrary monotonic transformations of μD (Z) and Cs (Ws ) separately. Using the probability integral transformation, the expression for choice s is
Ds = 1[FV |X (μD (Z) − Cs−1 (Ws−1 )) > UD  FV |X (μD (Z) − Cs (Ws ))]. Keeping
the conditioning on X implicit, we define Ps (Z, W ) = FV (μD (Z) − Cs−1 (Ws−1 )) −
FV (μD (Z) − Cs (Ws )). It is convenient to work with the probability that S > s,

πs (Z, Ws ) = FV (μD (Z) − Cs (Ws )) = Pr( S̄j =s+1 Dj = 1 | Z, Ws ), πS̄ (Z, WS̄ ) = 0,
π0 (Z, W0 ) = 1 and Ps (Z, W ) = πs−1 (Z, Ws−1 ) − πs (Z, Ws ).
The transition-specific MTE for the transition from s to s + 1 is defined in terms
of UD :
MTE
s,s+1 (x, uD ) = E(Ys+1 − Ys | X = x, UD = uD ),

s = 1, . . . , S̄ − 1.

Alternatively, one can condition on V . Analogous to the analysis of the earlier sections
of this chapter, when we set uD = πs (Z, Ws ), we obtain the mean return to persons
indifferent between s and s + 1 at mean level of utility πs (Z, Ws ).
In this notation, keeping X implicit, the mean outcome Y , conditional on (Z, W ), is
the sum of the mean outcomes conditional on each state weighted by the probability of
being in each state summed over all states:
E(Y | Z, W ) =

S̄


E(Ys | Ds = 1, Z, W ) Pr(Ds = 1 | Z, W )

s=1

=

S̄


πs−1 (Z,Ws−1 )

E(Ys | UD = uD ) duD ,

(7.2)

s=1 πs (Z,Ws )

where we use conditional independence assumption (OC-1) to obtain the final expression. Analogous to the result for the binary outcome model, we obtain the index sufficiency restriction E(Y | Z, W ) = E(Y | π(Z, W )), where π(Z, W ) =
[π1 (Z, W1 ), . . . , πS̄−1 (Z, WS̄−1 )]. The choice probabilities encode all of the influence
of (Z, W ) on outcomes.
We can identify πs (z, ws ) for (z, ws ) in the support of the distribution of (Z, Ws )

from the relationship πs (z, ws ) = Pr( S̄j =s+1 Dj = 1 | Z = z, Ws = ws ). Thus
E(Y | π(Z, W ) = π) is identified for all π in the support of π(Z, W ). Assumptions
(OC-1), (OC-3), and (OC-4) imply that E(Y | π(Z, W ) = π) is differentiable in π. So
∂
105 Thus analogous to the result obtained in
∂π E(Y | π(Z, W ) = π) is well defined.
105 For almost all π that are limit points of the support of distribution of π(Z, W ), we use the Lebesgue
theorem for the derivative of an integral. Under assumption (OC-6), all points in the support of the distribution
∂ E(Y | π(Z, W ) = π ) is well defined
of π(Z, W ) will be limit points of that support, and we thus have that ∂π
and is identified for (a.e.) π .

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4983

the binary case
∂E(Y | π(Z, W ) = π)
= MTE
s,s+1 (UD = πs )
∂πs
= E(Ys+1 − Ys | UD = πs ).

(7.3)

Equation (7.3) is the basis for identification of the transition-specific MTE from data on
(Y, Z, X).
From index sufficiency, we can express (7.2) as

E Y



π(Z, W ) = π =

S̄


E(Ys | πs  UD < πs−1 )(πs−1 − πs )

s=1

=

S̄−1




s=1

E(Ys+1 | πs+1  UD < πs )


− E(Ys | πs  UD < πs−1 ) πs
+ E(Y1 | π1  UD < 1)

=

S̄−1





ms+1 (πs+1 , πs ) − ms (πs , πs−1 ) πs

s=1

+ E(Y1 | π1  UD < 1),

(7.4)

where ms (πs , πs−1 ) = E[Ys | πs  UD < πs−1 ]. In general, this expression is a nonlinear function of (πs , πs−1 ). This model has a testable restriction of index sufficiency
in the general case: E(Y | π(Z, W ) = π) is a nonlinear function that is additive in
functions of (πs , πs−1 ) so there are no interactions between πs and πs if |s − s | > 1,
i.e.,
∂ 2 E(Y | π(Z, W ) = π)
= 0 if |s − s | > 1.
∂πs ∂πs
⊥ Us for s = 1, . . . , S̄,
Observe that if UD ⊥

E Y

S̄
 
E(Ys )(πs−1 − πs )
π(Z, W ) = π =
s=1

=

S̄−1





E(Ys+1 ) − E(Ys ) πs + E(Y1 ).

s=1

S̄−1 ATE
Defining E(Ys+1 ) − E(Ys ) = ATE
s=1 s,s+1 πs +
s,s+1 , E(Y | π(Z, W ) = π) =
E(Y1 ). Thus, under full independence, we obtain linearity of the conditional mean of Y
in the πs , s = 1, . . . , S̄. This result generalizes the test for the presence of essential
heterogeneity presented in Section 4 to the ordered case. We can ignore the complexity

4984

J.J. Heckman and E.J. Vytlacil

induced by the model of essential heterogeneity if E(Y | π(Z, W ) = π) is linear in the
πs and can use conventional IV estimators to identify well-defined treatment effects.106
7.2.1. The policy relevant treatment effect for the ordered choice model
The policy relevant treatment effect compares the mean outcome under one policy
regime p with the mean outcome under policy regime p . It is defined analogously
to the way it is defined in the binary case in Section 3.2 and in Heckman and Vytlacil
(2001c, 2005). Policies (p, p ) are assumed to induce different distributions of (Z, W ),
p
F p (Z, W ). Forming Ep (Y ) = E(Y | Z = z, W = w) dFZ,W (z, w) for each policy p, the policy relevant treatment effect is Ep (Y ) − Ep (Y ).
We can represent the PRTE as a weighted average of pairwise MTE:
PRTE
p,p = Ep (Y ) − Ep (Y ) =

S̄−1


E(Ys+1 − Ys | V = v)ωp,p (v) dF (v). (7.5)

s=1

The weights are known functions of the data. See Appendix H for a derivation of the
weights and expression (7.5). Using the probability integral transform, we can alternatively express this in terms of UD = FV |X (V ).
7.2.2. What do instruments identify in the ordered choice model?
We now characterize what scalar instrument J (Z, W ) identifies. When Y is log earnings, it is common practice to regress Y on S where S is completed years of schooling
and call the coefficient on S a rate of return.107 We seek an expression for the instrumental variables estimator of the effect of S on Y in the ordered choice model:
Cov(J (Z, W ), Y )
,
(7.6)
Cov(J (Z, W ), D)
S̄
where S =
s=1 sDs is the number of years of schooling attainment. We keep the
conditioning on X implicit. We now analyze the weights for IV. Their full derivation is
presented in Appendix I.
Define Ks (v) = E(J˜(Z, W ) | μD (Z) − Cs (Ws ) > v) Pr(μD (Z) − Cs (Ws ) > v),
where J˜(Z, W ) = J (Z, W ) − E(J (Z, W )). Thus,
IV
J =
=

Cov(J, Y )
Cov(J, S)
S̄−1


E(Ys+1 − Ys | V = v)ω(s, v)fV (v) dv,

(7.7)

s=1
106 Notice that if U ⊥
⊥ Us for some s, then we obtain an expression with nonlinearities in (πs , πs−1 ) in
D
expression (7.4).
107 Heckman, Lochner and Todd (2006) present conditions under which this economic interpretation is valid.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4985

where
Ks (v)

ω(s, v) = 
S̄

s=1 s

=
S̄−1
s=1

[Ks−1 (v) − Ks (v)]fV (v) dv
Ks (v)
,
Ks (v)fV (v) dv

S̄−1

and clearly s=1 ω(s, v)fV (v) dv = 1, ω(0, v) = 0, and ω(S̄, v) = 0. We can
rewrite this result in terms of the MTE, expressed in terms of uD
MTE
s,s+1 (uD ) = E(Ys+1 − Ys | UD = uD )
so that
Cov(J, Y ) 
=
Cov(J, S)

S̄−1

1

s=1 0

MTE
s,s+1 (uD )ω̃(s, uD ) duD ,

where
ω̃(s, uD ) = 
S̄

s=1 s

=
S̄−1
s=1

K̃s (uD )
1
0 [K̃s−1 (uD ) − K̃s (uD )] duD
K̃s (uD )
1
0 K̃s (uD ) duD

(7.8)

and
 


K̃s (uD ) = E J˜(Z, W ) πs (Z, Ws )  uD Pr πs (Z, Ws )  uD .

(7.9)

Compare Equations (7.8) and (7.9) for the ordered choice model to Equations (4.13)
and (4.14) for the binary choice model. The numerator of the weights for the MTE
in the ordered choice model for a particular transition is exactly the numerator of the
weights for the binary choice model, substituting πs (Z, Ws ) = Pr(S > s | Z, Ws ) for
P (Z) = Pr(D = 1 | Z). The numerator for the weights for IV in the binary choice
model is driven by the connection between the instrument and P (Z). The numerator for
the weights for IV in the ordered choice model for a particular transition is driven by
the connection between the instrument and πs (Z, Ws ). The denominator of the weights
is the covariance between the instrument and D (or S) for the binary (or ordered) case,
respectively. However, in the binary case the covariance between the instrument and D
is completely determined by the covariance between the instrument and P (Z), while
in the ordered choice case the covariance with S depends on the relationship between
the instrument and the full vector [π1 (Z, W1 ), . . . , πS̄−1 (Z, WS̄−1 )]. Comparing our
decomposition of IV to decomposition (7.1), ours corresponds to weighting up marginal outcomes across well-defined and adjacent boundary values experienced by agents

4986

J.J. Heckman and E.J. Vytlacil

having their instruments manipulated whereas the Angrist–Imbens decomposition corresponds to outcomes not experienced by some of the persons whose instruments are
being manipulated.
From Equation (7.9), the IV estimator using J (Z, W ) as an instrument satisfies the
following properties. (a) The numerator of the weights on MTE
s,s+1 (uD ) is nonnegative
for all uD if E(J (Z, Ws ) | πs (Z, Ws )  πs ) is weakly monotonic in πs . For example,
if Cov(πs (Z, Ws ), S) > 0, setting J (Z, W ) = πs (Z, Ws ) will lead to nonnegative
weights on MTE
s,s+1 (uD ), though it may lead to negative weights on other transitions.
A second property (b) is that the support of the weights on MTE
s,s+1 using πs (Z, Ws ) as
the instrument is (πsMin , πsMax ) where πsMin and πsMax are the minimum and maximum
values in the support of πs (Z, Ws ), respectively, and the support of the weights on
Min
Max ). A third property (c) is
MTE
s,s+1 using any other instrument is a subset of (πs , πs
MTE
that the weights on s,s+1 implied by using J (Z, W ) as an instrument are the same as
the weights on MTE
s,s+1 implied by using E(J (Z, W ) | πs (Z, Ws )) as the instrument.
Our analysis generalizes that of Imbens and Angrist (1994) and Angrist and Imbens
(1995) by considering multiple instruments and by introducing both transition-specific
instruments (W ) and general instruments (Z) across all transitions. In general, the
method of linear instrumental variables applied to S does not estimate anything that
is economically interpretable. It is not guaranteed to estimate a positive number even if
the MTE is everywhere positive since the weights can be negative. In contrast, we can
use our generalization of LIV presented in Equation (7.3) under conditions (OC-1)–
(OC-6) to apply LIV to identify MTE for each transition, which can be used to build
up PRTE using weights that can be estimated.
7.2.3. Some theoretical examples of the weights in the ordered choice model
Suppose that the distributions of Ws , s = 1, . . . , S̄, are degenerate so that the Cs are
constants satisfying C1 < · · · < CS̄−1 . This is the classical ordered choice model. In
this case, πs (Z, Ws ) = FV (μD (Z) − Cs ) for any s = 1, . . . , S̄. For this special case,
using J as an instrument will lead to nonnegative weights on all transitions if J (Z, W )
is a monotonic function of μD (Z). For example, note that μD (Z) − Cs > v can be
written as μD (Z) > Cs + FV−1 (uD ). Using μD (Z) as the instrument leads to weights
on MTE
s,s+1 (uD ) of the form specified above with K̃s (uD ) = [E(μD (Z) | μD (Z) >
−1
FV (uD ) + Cs ) − E(μD (Z))] Pr(μD (Z) > FV−1 (uD ) + Cs ). Clearly, these weights will
be nonnegative for all points of evaluation and will be strictly positive for any evaluation
point uD such that 1 > Pr(μD (Z) > FV−1 (uD ) + Cs ) > 0.
Next consider the case where Cs (Ws ) = Ws , a scalar, for s = 1, . . . , S̄ − 1, and
where μD (Z) = 0. Consider J (Z, W ) = Ws , a purely transition-specific instrument. In
this case, the weight on MTE
s,s+1 (uD ) is of the form given above, with
 

 

K̃s (uD ) = E Ws Ws > FV−1 (uD ) − E(Ws ) Pr Ws > FV−1 (uD ) ,

Ch. 71:

Econometric Evaluation of Social Programs, Part II

4987

which will be nonnegative for all evaluation points and strictly positive for any evaluation point such that 1 > Pr(Ws > FV−1 (uD )) > 0.
What are the implied weights on MTE
s ,s +1 (uD ) for s = s? First, consider the case
where Ws is independent of Ws for s = s . This independence of Ws and Ws is not in
conflict with the requirement Ws > Ws for s > s if the supports do not overlap for any
s = s. In this case, the weight on MTE
s ,s +1 (uD ) for s = s is of the form given above
with
 

 

K̃s (uD ) = E Ws Ws > FV−1 (uD ) − E(Ws ) Pr Ws > FV−1 (uD ) = 0.
Thus, in this case, the instrument only weights the MTE for the s to s + 1 transition.
Note that this result relies critically on the assumption that Ws is independent of Ws for
s = s.
Consider another version of this example where Cs (Ws ) = Ws , s = 1, . . . , S̄ − 1,
with Ws a scalar, but now allow μD (Z) to have a nondegenerate distribution and allow
there to be dependence across the Ws . In particular, consider the case where W =
(W1 , . . . , WS̄−1 ) is a continuous random vector with a density given by
S̄−1
i=1 fi (wi )1[w1 < w2 < · · · < wS̄−1 ]

· · · [1[w1 < w2 < · · · < wS̄−1 ] S̄−1
i=1 fi (wi )] dw1 · · · dwS̄−1
for some marginal density functions f1 (w1 ), f2 (w2 ), . . . , fS̄−1 (wS̄−1 ). In this case, using Wj as the instrument, we have




ω(s, v) =
···
wj − E(wj ) 1 − FμD (Z) (ws + v)
−∞<w1 <···<wS̄−1 <∞



× f1 (w1 ) · · · fS̄−1 (wS̄−1 ) dw1 · · · dwS̄−1 fV (v) dv
×

 S̄−1

s=1

···




wj − E(wj ) 1 − FμD (Z) (ws + v)

−∞<w1 <···<wS̄−1 <∞

× f1 (w1 ) · · · fS̄−1 (wS̄−1 ) dw1 · · · dwS̄−1 fV (v) dv

−1
.

In the special case where μD (Z) ∼ Unif(−K, K), with Z ⊥
⊥ Ws for s = 1, . . . , S̄−1,
assuming −K < ws + v < K for all ws , v in the support of Ws and V , respectively, the
numerator is


wj − E(wj )
···
−∞<w1 <···<wS̄−1 <∞

×

(ws + v + K)
f1 (w1 ) · · · fS̄−1 (wS̄−1 ) dw1 · · · dwS̄−1 fV (v) dv
2K

4988

J.J. Heckman and E.J. Vytlacil

1
Cov(Wj , Ws | W1 < · · · < WS̄−1 ).
2K
Observe that when the latent Wj , Ws are independently distributed for all j, s, by
Bickel’s Theorem (1967), we know that this expression is positive. (This is trivial when
j = s.) The ordering W1 < · · · < WS̄−1 implies that Wl is stochastically increasing in
Wj for l < j (the lower boundary is shifted to the right). Hence, because of the order
on the W implied by the ordered discrete choice model, a positive weighting is produced. This result can be overturned when F (w) has a general structure. The positive
dependence induced by the order on the components of W can be reversed by negative
dependence in the structure of F (w). We present examples of these phenomena in our
discussions in Figures 19 and 20 below.
=

7.2.4. Some numerical examples of the IV weights
Figures 16–18 plot the transition-specific MTEs and the IV weights for the models
and distributions of the weights at the base of each of the figures. We consider a three
outcome (S̄ = 3) model with common instruments (Z) and transition-specific (Ws )
instruments. The Z and Ws , s = 1, . . . , S̄, are assumed to be independent. The exact specification is given in the notes below Figure 16. In this example, Ds can be
interpreted as an indicator of schooling. Y1 is the potential earnings of the person as a
dropout, Y2 is the potential earnings of the person as a high school graduate, and Y3 is the
potential earnings of the person as a college graduate. There are two transitions: 1 → 2
and 2 → 3. The IV estimates using Z1 and W1 as instruments are reported transition by
transition and overall decomposing IV representation (7.7) into its transition-specific
components. The IV weights are defined by Equations (7.8) and (7.9). In particular,
when the first element of Z, Z1 , is used as the instrument, we can decompose IVZ1 as
IVZ1 =

2


E(Ys+1 − Ys | V = v)ωZ1 (s, v)fV (v) dv

s=1

=

Z1
MTE
12 (v)ω (1, v)fV (v) dv +

Z1
MTE
23 (v)ω (2, v)fV (v) dv

Z1
1
= IVZ
21 + IV32 .

The same logic applies for the decomposition of IVP which uses P (Z) as an instrument.
These decompositions show in this case that an important component of the total values
of IVZ and IVW 1 comes from the 2 → 3 transition. The bottom table presents the
transition-specific treatment parameters. In Figure 16, the shape of the IV weights for
Z1 and W1 are nearly identical. The IV estimates reflect this. The bottom table reveals
that the IV estimates are far from standard treatment parameters.
In Figure 17, the IV weights for the Z1 and W1 are very different. So, correspondingly, are the IV estimates produced from each instrument, which are far off the mark
of the standard treatment parameters shown in the bottom of the table. Observe that

Ch. 71:

Econometric Evaluation of Social Programs, Part II

Outcomes
Y1 = α + β1 + U1
Y2 = α + β2 + U2
Y3 = α + β3 + U3

4989

Choice model
Ds = 1[Ws−1 < γ Z − V  Ws ],
s = 1, 2, 3

Figure 16. Treatment parameters and IV – the generalized ordered choice Roy model under normality
(Z, W1 ). Source: Heckman, Urzua and Vytlacil (2004).

the IV weight for W1 in the second transition is negative for an interval of values. This
accounts for the dramatically lower IV estimate based on W1 as the instrument. Figure 18 shows a different configuration of (Z1 , W1 , W2 ). This produces negative weights

4990

J.J. Heckman and E.J. Vytlacil
Parameterization
(U1 , U2 , U3 , V ) ∼ N (0, Σ U V ), (Z, W1 , W2 ) ∼ N (μZW , Σ ZW ) and W0 = −∞; W3 = ∞
⎡ 1
0.16
0.2
−0.3 ⎤
−0.32 ⎥
⎦, μZW = (−0.6, −1.08, 0.08)
−0.4
1
$ 0.1
0
0 %
and Σ ZW = 0
0.1 0.09
0 0.09 0.25

0.64
⎢ 0.16
ΣUV = ⎣
0.2
0.16
−0.3 −0.32

0.16
1
−0.4

Cov(U2 − U1 , V ) = −0.02, Cov(U3 − U2 , V ) = −0.08
β1 = 0; β2 = 0.025; β3 = 0.3; γ = 1
IV estimates and their components∗
Parameter

Value

IVZ
IV
12 Z

0.1487
0.0120

IV

23 Z

0.1367

IVW1

0.1406

IVW1

0.0126



12

IVW
23 1
∗ IVZ is decomposed as

0.1280

IVZ = E(Y2 − Y1 | V = v)ωZ (1, v)fV (v) dv
+ E(Y3 − Y2 | V = v)ωZ (2, v)fV (v) dv
Z
=IVZ
21 + IV32 .
An analogous decomposition applies to IVW1 .

Treatment parameters and their values
Parameter

Value

ATE12 = E(Y2 − Y1 )
ATE23 = E(Y3 − Y2 )
TT12 = E(Y2 − Y1 | D2 = 1)
TT23 = E(Y3 − Y2 | D3 = 1)
TUT12 = E(Y2 − Y1 | D1 = 1)
TUT23 = E(Y3 − Y2 | D2 = 1)

0.025
0.275
0.0282
0.1908
0.0060
0.2956

Figure 16. (Continued)

for Z1 for both transitions and a negative weight for W1 in the second transition. For
both instruments, IV is negative even though both MTEs are positive throughout most
of their range. IV provides a misleading summary of the underlying marginal treatment
effects.
Comparing Figures 16–18, it is important to recall that all are based on the same
structural model. All have the same MTE and average treatment effects. But the IV estimates are very different solely as a consequence of the differences in the distributions

Ch. 71:

Econometric Evaluation of Social Programs, Part II

Outcomes
Y1 = α + β1 + U1
Y2 = α + β2 + U2
Y3 = α + β3 + U3

4991

Choice model
Ds = 1[Ws−1 < γ Z − V  Ws ],
s = 1, 2, 3

Figure 17. Treatment parameters and IV – the generalized ordered choice Roy model under normality (Z, W1 ), Case I. Source: Heckman, Urzua and Vytlacil (2006).

of instruments across the examples. An alternative way to benchmark what IV estimates
in the ordered choice model is to compare IV estimates to the PRTE for well-defined
policy experiments. We consider two such experiments, corresponding to proportional

4992

J.J. Heckman and E.J. Vytlacil
Parameterization
(U1 , U2 , U3 , V ) ∼ N (0, Σ U V ), (Z, W1 , W2 ) ∼ N (μZW , Σ ZW ) and W0 = −∞; W3 = ∞
⎡ 1
0.16
0.2
−0.3 ⎤
0.64
⎢ 0.16
ΣUV = ⎣
0.2
0.16
−0.3 −0.32

0.16 −0.32 ⎥
⎦, μZW = (−0.6, −1.08, 0.08)
1
−0.4
−0.4
1
$ 0.1
0
0 %

and Σ ZW =

0
0

0.1
−0.09

−0.09
0.25

Cov(U2 − U1 , V ) = −0.02, Cov(U3 − U2 , V ) = −0.08
β1 = 0; β2 = 0.025; β3 = 0.3; γ = 1
IV estimates and their components∗
Parameter

Value

IVZ

0.1489

IV

12 Z

0.0117

IV

23 Z

0.1372

IVW1

0.0017



IVW
12 1
IVW
23 1

0.0325
−0.0308

∗ IVZ is decomposed as

IVZ = E(Y2 − Y1 | V = v)ωZ (1, v)fV (v) dv
E(Y3 − Y2 | V = v)ωZ (2, v)fV (v) dv
IVZ
IV
=12 + 23 Z .
IVW1
+

An analogous decomposition applies to 

.

Treatment parameters and their values
Parameter

Value

ATE12 = E(Y2 − Y1 )
ATE23 = E(Y3 − Y2 )
TT12 = E(Y2 − Y1 | D2 = 1)
TT23 = E(Y3 − Y2 | D3 = 1)
TUT12 = E(Y2 − Y1 | D1 = 1)
TUT23 = E(Y3 − Y2 | D2 = 1)

0.025
0.275
0.0271
0.1871
0.0047
0.2854

Figure 17. (Continued)

and fixed subsidies for attending different levels of schooling. We use the definition
of the PRTE given in Equation (7.5). The baseline model is the one used to generate
Figure 17. The weights can be constructed from data and are derived in Appendix H.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

Outcomes
Y1 = α + β1 + U1
Y2 = α + β2 + U2
Y3 = α + β3 + U3

4993

Choice model
Ds = 1[Ws−1 < γ Z − V  Ws ],
s = 1, 2, 3

Figure 18. Treatment parameters and IV – the generalized ordered choice Roy model under normality (Z, W1 ), Case II. Source: Heckman, Urzua and Vytlacil (2006).

Figure 19 plots the weights for the PRTE for each transition for a policy experiment.
We change the economy from the benchmark economy that generates Figure 17 to an
economy where W2 is subsidized by a proportional amount τ . The PRTE weights for

4994

J.J. Heckman and E.J. Vytlacil
Parameterization
(U1 , U2 , U3 , V ) ∼ N (0, Σ U V ), (Z, W1 , W2 ) ∼ N (μZW , Σ ZW ) and W0 = −∞; W3 = ∞
⎡ 1
0.16
0.2
−0.3 ⎤
0.16 −0.32 ⎥
⎦, μZW = (−0.6, −1.08, 0.08)
1
−0.4
−0.4
1
$ 0.1
0.092 −0.036 %

0.64
⎢ 0.16
ΣUV = ⎣
0.2
0.16
−0.3 −0.32

and Σ ZW =

0.092
−0.036

0.1
−0.09

−0.09
0.25

Cov(U2 − U1 , V ) = −0.02, Cov(U3 − U2 , V ) = −0.08
β1 = 0; β2 = 0.025; β3 = 0.3; γ = 1
IV estimates and their components∗
Parameter

Value

IVZ

−1.8091

IV
12 Z
IV
23 Z
IVW1

−2.0957

0.2866

−0.4284



IVW
12 1
IVW
23 1

0.0909
−0.5193

∗ See the footnote below Figure 16 for details of the
IVW1
IVZ

decomposition of 

and 

.

Treatment parameters and their values
Parameter

Value

ATE12 = E(Y2 − Y1 )
ATE23 = E(Y3 − Y2 )
TT12 = E(Y2 − Y1 | D2 = 1)
TT23 = E(Y3 − Y2 | D3 = 1)
TUT12 = E(Y2 − Y1 | D1 = 1)
TUT23 = E(Y3 − Y2 | D2 = 1)

0.025
0.275
0.0283
0.1754
0.0025
0.2898

Figure 18. (Continued)

each transition are negative over certain intervals. The overall PRTE is close to zero and
can be decomposed into two components corresponding to a negative component on the
second transition. The IV for the benchmark regime (p) and new regime (p ) are given
in the bottom table. The IV based on Z are far from the PRTE parameter. In general, the
IV estimands are far off the mark from the PRTEs.
We next present a comparison between what IV estimates and the PRTE for a policy that consists of changing W2 to W2 − t (t = 1.2 in the simulations). This can be
thought of as a college tuition reduction policy. We compare the weights on PRTE with

Ch. 71:

Econometric Evaluation of Social Programs, Part II

Outcomes
Y1 = α + β1 + U1
Y2 = α + β2 + U2
Y3 = α + β3 + U3

4995

Choice model
Ds = 1[Ws−1 < γ Z − V  Ws ],
s = 1, 2, 3

Parameterization
The benchmark model (regime p) is the same as the one presented below Figure 17.
p

p

Under the new regime (regime p ) we define W1 = W1 (1 − τ ) with τ = 0.5. Thus, under regime p we have
$ 0.1
0
0 %
p
p
μZW = (−0.6, −0.54, 0.08) and Σ ZW = 0
0.025 −0.045
0 −0.045
0.25
The other parameters remain at the values set under the regime p
PRTE estimates and their components1
Parameter
PRTEp ,p

Value
0.0076

p ,p
−0.0032
PRTE21
p ,p
0.0109
PRTE32
1 PRTEp , p is decomposed as
PRTEp ,p = E(Y2 − Y1 | V = v)ωp ,p (1, v)fV (v) dv
+ E(Y3 − Y2 | V = v)ωp ,p (2, v)fV (v) dv
p ,p
p ,p
=PRTE21 + PRTE32 .

Figure 19. The policy relevant treatment effect weights – the generalized ordered choice Roy model under
normality. Source: Heckman, Urzua and Vytlacil (2004).

the weights on IV using W1 (Figure 20) and Z (Figure 21) as instruments. The case
using W2 as an instrument is similar and for the sake of brevity is not discussed. In
Figure 20A, we plot the transition-specific MTE for the values of the model presented

4996

J.J. Heckman and E.J. Vytlacil
IV estimates and treatment parameters under different regimes2
Parameter
IVZ

Regime p

Regime p

IVZ
12

0.1489
0.0117

0.1521
0.0174

IVZ
23

0.1372

0.1347

0.0017

0.0804

0.0325

0.0358

−0.0308

0.0446

0.0250
0.2750
0.0271
0.1871
0.0047
0.2854

0.0250
0.2750
0.0327
0.1789
0.0103
0.3067

IVW1
W

IV121
W
IV231

ATE12
ATE23
TT12
TT23
TUT12
TUT23

2 See footnote below Figure 16 for details of the decompositions
of IVZ and IVW1 .

Figure 19. (Continued)

at the base of the table. These are identical to the transition-specific MTE plotted in
Figure 21A. Both of the MTE parameters have the typical shape of declining returns
for people less likely to make the transition, i.e., those who have a higher V = v. Even
though the levels are higher for outcomes 2 and 3, the marginal returns are higher for the
transition 1 → 2. Figure 20B plots the policy weights for the two transitions for a policy that lowers W2 (“reduces tuition”).108 It also plots the IV weights for the two MTE
functions for the case where W1 is the instrument. The correlation pattern for (W1 , W2 )
is positive with specific values given below the figure. The policy studied in Figure 20B
shifts 42.8% of the D1 = 1 people into the category D3 = 1 and 92.4% of D2 people into D3 . In this simulation, the IV weights are positive. The IV weights and PRTE
weights are distinctly different and the IV estimate is 0.201 vs. PRTE of 0.166.
When we change the correlation structure between W1 and W2 so that they are negatively correlated (Figure 20C), the IV weight for MTE
2,3 becomes negative while that for
MTE
1,2 remains positive. The contrast in these figures between negative and positive IV
weights depends on the correlation structure between W1 and W2 . The stochastic order
(W2 > W1 ) is a force toward positive weights, which can be undone when the dependence induced by the density (f (w1 , w2 )) is sufficiently negative. The discord between
the IV and PRTE weights is substantial and is reflected in the estimates (PRTE = 0.159
vs. IV = 0.296). As Figure 20D illustrates, the weights on PRTE are not guaranteed

108 Notice that, for clarity, of exposition we change the notation for the weights in Figures 20 and 21 to
distinguish IV from PRTE weights.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

Y3 = α + β3 + U3 ; D3 = 1 if W2 < I < ∞; U3 = σ3 τ ;
Y2 = α + β2 + U2 ; D2 = 1 if W1 < I  W2 ; U2 = σ2 τ ;
Y1 = α + U1 ;
D1 = 1 if −∞ < I  W1 ;U1 = σ1 τ ;
I =Z−V

4997

σ3 = 0.02, σ2 = 0.012, σ1 = −0.05, σV = −1
α = 0.67, β2 = 0.25, β3 = 0.4
Z ∼ N (−0.0026, 0.27) and Z ⊥
⊥V

V = σV τ ; τ ∼ N (0, 1)
UD = FV (V )

Sample size = 1500
Figure 20A. W2 − t where t = 1.2 and W1 is the instrument: Marginal treatment effects by transition.

to be positive either. Thus neither the IV weights nor the weights on PRTE are guaranteed to be positive or negative and the relationship between the two sets of weights can
be quite weak.
Figures 21A–21D present a parallel set of simulations when Z is used as an instrument. Changes in Z shift persons across all transitions whereas W1 is a transitionspecific shifter. Figure 21 reproduces the policy invariant MTE parameters from Figure 20A. Figure 21B shows that the IV weights for MTE
1,2 assume both positive and negMTE
ative values. The IV weights for 2,3 are positive but not monotonic. In Figure 21C,
where there is negative dependence between W1 and W2 , both sets of IV weights assume both positive and negative values. In the case where f (w1 , w2 ) = f1 (w1 )f2 (w2 ),
PRTE are negative.
the weights on MTE
1,2 for 
These simulations show a rich variety of shapes and signs for the weights. They illustrate a main point of this chapter – that standard IV methods are not guaranteed to
weight marginal treatment effects positively or to produce estimates close to policy rel-

4998

J.J. Heckman and E.J. Vytlacil




0
1 0.8
,
0
0.8 1
PRTE = 0.166, IV = 0.201
Proportion induced to change from D1 = 1 to D3 = 1 = 42.8%
Proportion induced to change from D2 = 1 to D3 = 1 = 92.4%
(W1 , W2 ) ∼ N

Figure 20B. W2 − t where t = 1.2 and W1 is the instrument: Policy relevant treatment effect vs. instrumental
variables weights by transition.

evant treatment effects or even to produce any gross treatment effect. Estimators based
on LIV and its extension to the ordered model (7.3) identify MTE for each transition
and answer policy relevant questions. We now turn to an analysis of a general unordered
model.
7.3. Extension to multiple treatments that are unordered
The previous section analyzes a multiple treatment model where the treatment choice
equation is an ordered choice model. In this section, we develop a framework for
the analysis of multiple treatments when the choice equation is a nonparametric
version of the classical multinomial choice model with no order imposed. Appendix B of Chapter 70, and Chapter 73 (Matzkin) analyze nonparametric and semiparametric identification of discrete choice models. With this framework, treatment
effects can be defined as the difference in the counterfactual outcomes that would
have been observed if the agent faced different general choice sets, i.e., the ef-

Ch. 71:

Econometric Evaluation of Social Programs, Part II


(W1 , W2 ) ∼ N

0
1
,
0
−0.8

4999

−0.8
1



PRTE = 0.159, IV = 0.296
Proportion induced to change from D1 = 1 to D3 = 1 = 32.1%
Proportion induced to change from D2 = 1 to D3 = 1 = 64.7%
Figure 20C. W2 − t where t = 1.2 and W1 is the instrument: Policy relevant treatment effect vs. instrumental
variables weights by transition.

fect of the individual being forced to choose from one choice set instead of another. We define treatment parameters for a general multiple treatment problem
and present conditions for the application of instrumental variables for identifying a variety of new treatment parameters. Our identification conditions are weaker
than the ones used in Appendix B of Chapter 70, which establishes conditions under which it is possible to nonparametrically identify a full multinomial selection
model.
Our use of choice theory is a unique aspect of our approach to the analysis of treatment effects. One particularly helpful result we draw on is the representation of the
multinomial choices in terms of the choice between a particular choice and the best option among all other choices. This representation is crucial for understanding why LIV
allows one to identify the MTE for the effect of one choice versus the best alternative
option. The representation was introduced in Domencich and McFadden (1975), and
has been used in the analysis of parametric multinomial selection models by Lee (1983)

5000

J.J. Heckman and E.J. Vytlacil


(W1 , W2 ) ∼ N

0
1 0
,
0
0 1



PRTE = 0.110, IV = 0.210
Proportion induced to change from D1 = 1 to D3 = 1 = 27.5%
Proportion induced to change from D2 = 1 to D3 = 1 = 76.8%
Figure 20D. W2 − t where t = 1.2 and W1 is the instrument: Policy relevant treatment effect vs. instrumental
variables weights by transition.

and Dahl (2002). Unlike those authors, we systematically explore treatment effect heterogeneity, consider nonparametric identification, and examine the application of the
LIV methodology to such models.
Our analysis proceeds as follows. We first introduce our nonparametric, multinomial
selection model and state our assumptions in Section 7.3.1. In Section 7.3.2, we define
treatment effects in a general unordered model as the differences in the counterfactual
outcomes that would have been observed if the agent faced different choice sets, i.e.,
the effects observed if individuals are forced to choose from one choice set instead
of another. We also define the corresponding treatment parameters. Treatment effects
in this context exhibit a form of treatment effect heterogeneity not present in the binary
treatment case. The new form of heterogeneity arises from agents facing different choice
sets, which we discuss in Section 7.3.3.
Section 7.3.4 establishes that LIV and the nonparametric Wald-IV estimand produce
identification of the MTE/LATE versions of the effect of one choice versus the best
alternative option without requiring knowledge of the latent index functions generat-

Ch. 71:

Econometric Evaluation of Social Programs, Part II

Y3 = α + β3 + U3 ; D3 = 1 if W2 < I < ∞;
Y2 = α + β2 + U2 ; D2 = 1 if W1 < I  W2 ;
Y1 = α + U1 ;
D1 = 1 if −∞ < I  W1 ;
I =Z−V

U3 = σ3 τ ;
U2 = σ2 τ ;
U1 = σ1 τ ;

5001

σ3 = 0.02, σ2 = 0.012, σ1 = −0.05, σV = −1
α = 0.67, β2 = 0.25, β3 = 0.4
Z ∼ N (−0.0026, 0.27) and Z ⊥
⊥V

V = σV τ ; τ ∼ N (0, 1)

Sample size = 1500
Figure 21A. W2 − t where t = 1.2 and Z is the instrument: Marginal treatment effects by transition.

ing choices or large support assumptions. Mean treatment effects comparing one option
versus the best alternative are the easiest treatment effects to study using instrumental
variable methods because we effectively collapse a multiple outcome model to a series of two-outcome models, picking one outcome relative to the rest. In Section 7.3.5,
we consider a more general case and state conditions for identifying the mean effect
of the outcome associated with the best option in one choice set to the mean effect of
the best option not in that choice set. We show that identification of the corresponding
MTE/LATE parameters requires knowledge of the latent index functions of the multinomial choice model. Thus, to identify the parameters by using IV or LIV requires the
formulation and estimation of an explicit choice model. In Section 7.3.6, we analyze the
identification of treatment parameters corresponding to the mean effect of one specified
choice versus another specified choice. Identification of marginal treatment parameters
in this case requires the use of identification at infinity arguments relying on large support assumptions, but does not require knowledge of the latent index functions of the
multinomial choice problem. This use of large support assumptions is closely related to

5002

J.J. Heckman and E.J. Vytlacil




0
1 0.8
,
0
0.8 1
PRTE = 0.166, IV = 0.247
Proportion induced to change from D1 = 1 to D3 = 1 = 42.8%
Proportion induced to change from D2 = 1 to D3 = 1 = 92.4%
(W1 , W2 ) ∼ N

Figure 21B. W2 − t where t = 1.2 and Z is the instrument: Policy relevant treatment effect vs. instrumental
variables weights by transition.

the need for large support assumptions to identify the full model developed in Appendix B of Chapter 70 of this Handbook. We summarize our analysis in Section 7.3.7.
7.3.1. Model and assumptions
Consider the following model with multiple choices and multiple outcome states for a
general unordered model. Let J denote the agent’s choice set, where J contains a finite
number of elements. The value to the agent of choosing option j ∈ J is
Rj (Zj ) = ϑj (Zj ) − Vj ,

(7.10)

where Zj are the agent’s observed characteristics that affect the utility from choosing
choice j , and Vj is the unobserved shock to the agent’s utility from choice j . We will
sometimes suppress the argument and write Rj for Rj (Zj ). Let
 Z denote the random
vector containing all unique elements of {Zj }j ∈J , i.e., Z = j ∈J {Zj }j ∈J . We will
also sometimes write Rj (Z) for Rj (Zj ), leaving implicit that Rj (·) only depends on

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5003




0
1
−0.8
,
0
−0.8
1
PRTE = 0.159, IV = 0.346
Proportion induced to change from D1 = 1 to D3 = 1 = 32.1%
Proportion induced to change from D2 = 1 to D3 = 1 = 64.7%
(W1 , W2 ) ∼ N

Figure 21C. W2 − t where t = 1.2 and Z is the instrument: Policy relevant treatment effect vs. instrumental
variables weights by transition.

those elements of Z that are contained in Zj . Let DJ ,j be an indicator variable for
whether the agent would choose option j if confronted with choice set J 109 :

1 if Rj  Rk , ∀k ∈ J ,
DJ ,j =
0 otherwise.
Let IJ denote the choice that would be made by the agent if confronted with choice
set J :
IJ = j

⇐⇒

DJ ,j = 1.

Let YJ be the outcome variable that would be observed if the agent faced choice set J ,
determined by

YJ =
DJ ,j Yj ,
j ∈J

109 We will impose conditions such that ties, R = R for j = k, occur with probability zero.
j
k

5004

J.J. Heckman and E.J. Vytlacil




0
1 0
,
0
0 1
PRTE = 0.104, IV = 0.215
Proportion induced to change from D1 = 1 to D3 = 1 = 27.3%
Proportion induced to change from D2 = 1 to D3 = 1 = 69.3%
(W1 , W2 ) ∼ N

Figure 21D. W2 − t where t = 1.2 and Z is the instrument: Policy relevant treatment effect vs. instrumental
variables weights by transition.

where Yj is the potential outcome, observed only if option j is chosen. Yj is determined
by
Yj = μj (Xj , Uj ),
where Xj is a vector of the agent’s observed characteristics and Uj is an unobserved random vector.
 Let X denote the random vector containing all unique elements of {Xj }j ∈J ,
i.e., X = j ∈J {Xj }j ∈J . (Z, X, IJ , YJ ) is assumed to be observed. Define RJ as the
maximum obtainable value given choice set J :

RJ = max{Rj } =
DJ ,j Rj .
j ∈J

j ∈J

We thus obtain the traditional representation of the decision process that choice j being
optimal implies that choice j is better than the “next best” option:
IJ = j

⇐⇒

Rj  RJ \j .

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5005

More generally, a choice from K being optimal is equivalent to the highest value obtainable from choices in K being higher than the highest value that can be obtained from
choices outside that set,
IJ ∈ K

⇐⇒

RK  RJ \K .

As we will show, this simple representation is the key intuition for understanding how
nonparametric instrumental variables estimate the effect of a given choice versus the
“next best” alternative.
Analogous to our definition of RJ , we define RJ (z) to be the maximum obtainable
value given choice set J when instruments are fixed at Z = z,


RJ (z) = max Rj (z) .
j ∈J

Thus, for example, a choice from K is optimal when instruments are fixed at Z = z if
RK (z)  RJ \K (z).
We make the following assumptions, which generalize assumptions (A-1)–(A-5) invoked in Heckman and Vytlacil (2001b) and later used in Heckman and Vytlacil (2005),
as developed in Section 2. We present the assumptions in a fashion parallel to (A-1)–
(A-5) and (OC-1)–(OC-6). For that reason, we present the second assumption, which
requires special attention, out of order.
(B-1)
(B-3)
(B-4)
(B-5)

{(Vj , Uj )}j ∈J is independent of Z conditional on X.
The distribution of ({Vj }j ∈J ) is continuous.110
E(|Yj |) < ∞ for all j ∈ J .
Pr(IJ = j | X) > 0 for all j ∈ J .

Assumption (B-1) and (B-3) imply that Rj = Rk w.p.1 for j = k, so that argmax{Rj }
is unique w.p.1. Assumption (B-4) is required for the mean treatment parameters to be
well defined. It allows us to integrate to the limit, which will be a crucial step for all
identification analysis. Assumption (B-5) requires that at least some individuals participate in each program for all X.
Our definition and analysis of the treatment parameters only require assumptions (B-1) and (B-3)–(B-5). However, we will also impose an exclusion restriction for
our identification analysis. Let Z [j ] denote the j th components of Z that are in Zj but
not in Zk , k = j . Let Z [−j ] denote all elements of Z except for the components in Z [j ] .
We work with two alternative assumptions for the exclusion restriction.111 Consider

110 Absolutely continuous with respect to Lebesgue measure on 
j ∈J R.
111 We work here with exclusion restrictions in part for ease of exposition. By adapting the analysis of

Cameron and Heckman (1998) and Heckman and Navarro (2007), one can modify our analysis for the case
of no exclusion restrictions if Z contains a sufficient number of continuous variables and there is sufficient
variation in the ϑk function across k.

5006

J.J. Heckman and E.J. Vytlacil

(B-2a) for each j ∈ J , there exists at least one element of Z, say Z [j ] , such that
Z [j ] is not an element of Zk , k = j , and such that the distribution of ϑj (Zj )
conditional on (X, Z [−j ] ) is nondegenerate,
or
(B-2b) for each j ∈ J , there exists at least one element of Z, say Z [j ] , such that
Z [j ] is not an element of Zk , k = j , and such that the distribution of ϑj (Zj )
conditional on (X, Z [−j ] ) is continuous.112
Assumption (B-2a) imposes the requirement that the analyst be able to independently
vary the index for the given value function. This produces variation that affects only
the value of the j th value function and causes people to enter or exit sector j . It imposes an exclusion restriction, that for any j ∈ J , Z contains an element such that
(i) it is contained in Zj ; (ii) it is not contained in any Zk for k = j and (iii) ϑj (·) is
a nontrivial function of that element conditional on all other regressors. Assumption
(B-2b) strengthens (B-2a) by adding a smoothness assumption. A necessary condition
for (B-2b) is for the excluded variable to have a density with respect to Lebesgue measure conditional on all other regressors and for ϑj (·) to be a continuous and nontrivial
function of the excluded variable.113 Assumption (B-2a) will be used to identify a generalization of the LATE parameter. Assumption (B-2b) will be used to identify a generalization of the MTE parameter. For certain portions of the analysis, we strengthen (B-2b)
to a large support condition, though the large support assumption will not be required
for most of our analysis. Assumptions (B-2a) and (B-2b) mirror (A-2) for the binary
choice model and are analogous to (OC-2) and (OC-6) in an ordered choice model.
7.3.2. Definition of treatment effects and treatment parameters
Treatment effects are defined as the difference in the counterfactual outcomes that would
have been observed if the agent faced different choice sets. For any two choice sets,
K, L ⊂ J , define
K,L = YK − YL .
This is the effect of the individual being forced to choose from choice set K versus
choice set L. The conventional treatment effect is defined as the difference in potential
outcomes between two specified states,
k,l = Yk − Yl ,

112 Absolutely continuous with respect to Lebesgue measure.
113 (B-2b) can be easily relaxed to the weaker assumption that the support of ϑ (Z ) conditional on
j j
(X, Z [−j ] ) contains an open interval, or further weakened to the assumption that the conditional support

contains at least one limit point. In these cases, the analysis of this section goes through without change for
analysis for points within the open interval or more generally for any limit point.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5007

which is nested within this framework by taking K = {k}, L = {l}. It is the effect for
the individual of having no choice except to choose state l.
K,L will be zero for agents who make the same choice when confronted with choice
set K and choice set L. Thus, IK = IL implies K,L = 0, and we have
K,L = 1(IL = IK )K\L,L
 

= 1(IL = IK )
DK,j j,L .

(7.11)
(7.12)

j ∈K\L

Two examples will be of particular importance for our analysis. First, consider choice
set K = {k} versus choice set L = J \ {k}. In this case, k,J \k is the difference
between the agent’s potential outcome in state k versus the outcome that would have
been observed if he or she had not been allowed to choose state k. If IJ = k, then
k,J \k is the difference between the outcome in the agent’s preferred state and the
outcome in the agent’s “next-best” state. Second, consider the set K = J versus choice
set L = J \{k}. In this case, J ,J \k is the difference between the agent’s best outcome
and what his or her outcome would have been if state k had not been available. Note that
J ,J \k = DJ ,k k,J \k .
Thus, there is a trivial connection between the two parameters, J ,J \k and k,J \k .
We will focus on k,J \k , the effect of being forced to choose option k versus being
denied option k. However, one can use Equation (7.11) to use the results for k,J \k to
obtain results for J ,J \k .
To fix ideas regarding these alternative definitions of treatment effects, consider the
following example concerning GED certification. The GED is an exam that certifies that
high school dropouts who pass the test are the equivalents of high school graduates.
E XAMPLE (GED certification). Consider studying the effect of GED certification
on later wages. Consider the case where J = {{GED}, {HS Degree}, {Permanent
Dropout}}. Let j = {GED}, k = {HS Degree}, and l = {Permanent Dropout}. Suppose one wishes to study the effect of the GED. Then possible definitions of the effect
of the GED include:
• j,k is the individual’s outcome if he or she received the GED versus if he or she
had graduated from high school;
• j,l is the individual’s outcome if he or she received the GED versus if he or she
had been a permanent dropout;
• j,J \j is the individual’s outcome if he or she had received the GED versus what
the outcome would have been if he or she had not had the option of receiving the
GED;
• J ,J \j is the individual’s outcome if he or she had the option of receiving the
GED versus the outcome if he or she did not have the option of receiving the GED.
Notice that J ,J \j is a version of an option value treatment effect.

5008

J.J. Heckman and E.J. Vytlacil

We now define treatment parameters for a general unordered model.
Treatment parameters The conventional definition of the average treatment effect
(ATE) is
ATE
k,l (x, z) = E(k,l | X = x, Z = z),
which immediately generalizes to the class of parameters discussed in this section as
ATE
K,L (x, z) = E(K,L | X = x, Z = z).
Notice that the treatment parameters now depend on the value of Z. We explain the
source of this dependence below. The conventional definition of the treatment on the
treated (TT) parameter is
TT
k,l (x, z) = E(k,l | X = x, Z = z, IJ = k),
which we generalize to
TT
K,L (x, z) = E(K,L | X = x, Z = z, IJ ∈ K).
We also generalize the marginal treatment effect (MTE) and local average treatment
effect (LATE) parameters considered in Heckman and Vytlacil (2001b). We generalize
the MTE parameter to be the average effect conditional on being indifferent between
the best option among choice set K versus the best option among choice set L at some
fixed value of the instruments, Z = z:


MTE
(7.13)
K,L (x, z) = E K,L X = x, Z = z, RK (z) = RL (z) .
We generalize the LATE parameter to be the average effect for someone for whom the
optimal choice in choice set K is preferred to the optimal choice in choice set L at
Z = z̃, but who prefers the optimal choice in choice set L to the optimal choice in
choice set K at Z = z:


LATE
K,L (x, z, z̃) = E K,L X = x, Z = z, RK (z̃)  RL (z̃), RL (z)  RK (z) .
(7.14)
An important special case of this parameter arises when z = z̃ except for elements that
enter the index functions only for choices in K and not for any choice in L. In that
special case, Equation (7.14) simplifies to


LATE
K,L (x, z, z̃) = E K,L X = x, Z = z, RK (z̃)  RL (z)  RK (z) ,
since RL (z) = RL (z̃) in this special case.
We have defined each of these parameters as conditional not only on X but also on
the “instruments” Z. In general, the parameters depend on the Z evaluation point. For
example, ATE
(x, z) generally depends on the z evaluation point. To see this, note that
 K,L

YK = k∈K DK,k Yk , and YL = l∈L DL,l Yl . By conditional independence assumption (B-1), Z ⊥
⊥ {Yj }j ∈J | X, but DK,k and DL,l depend on Z conditional on X and

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5009

thus YK − YL , in general, is dependent on Z conditional on X.114 In other words, even
though Z is conditionally independent of each individual potential outcome, it is correlated with the indicator for the choice that is optimal within the sets K and L and thus
is related to YK − YL .
7.3.3. Heterogeneity in treatment effects
Consider heterogeneity in the pairwise treatment effect j,k (with (j, k) ∈ J ) defined
as
j,k = Yj − Yk = μj (Xj , Uj ) − μk (Xk , Uk ),
which in general will vary with both observables (X) and unobservables (Uj , Uk ). Since
we have not assumed that the error terms are additively separable, the treatment effect
will in general vary with unobservables even if Uj = Uk .
The mean treatment parameters for j,k will differ if the effect of treatment is heterogeneous and agents base participation decisions, in part, on their idiosyncratic treatment
effect. In general, the ATE, TT, and the marginal treatment parameters for j,k will differ as long as there is dependence between (Uj , Uk ) and the decision rule, i.e., if there
is dependence between (Uj , Uk ) and ({Vl }l∈J ). If we impose that ({Vl }l∈J ) is independent of (Uj , Uk ), then the treatment effect will still be heterogeneous, but the average
treatment effect, average effect of treatment on the treated, and the marginal average
treatment effects will all coincide.
The literature on treatment effects often imposes additive separability in outcomes
between observables and unobservables. In particular, it is commonly assumed that Uj
and Uk are scalar random variables and that Yj = μj (Xj ) + Uj , Yk = μk (Xk ) +
Uk . In that case, a common treatment effect model is produced if the additive error
term does not vary with the treatment state: Uj = Uk .115 Thus, in the special case of
additive separability, the treatment parameters for j,k will be the same even if there is
dependence between {Vl }l∈J and (Uj , Uk ) as long as Uj = Uk .116
There is an additional source of treatment heterogeneity in the more general case
of K,L arising from heterogeneity in which states are being compared. Consider, for
114 An exception is if K = {k}, L = {l}, i.e., both sets are singletons.
115 More generally, if U , U are vector-valued, then additive separability is Y = μ (X ) + μ (U ),
j
k
j
j
1j
2j j
Yk = μ1k (Xk )+μ2k (Uk ), and the standard result is that a common treatment effect is produced if μ2j (Uj ) =
μ2k (Uk ).
116 Because the literature often assumes additive separability in outcome equations, questions about the exis-

tence of a common treatment effect hinge on whether the additively separable error terms differ by treatment
state. If the error terms differ by treatment state, there will be differences in the treatment parameters according to whether the differences in the error terms are stochastically dependent on the participation decision.
Aakvik, Heckman and Vytlacil (1999) examine the case where the outcome variable is binary so that an
additive separability assumption is not appropriate and Heckman and Vytlacil (2001b, 2005) consider cases
without additive separability. Vytlacil, Santos and Shaikh (2005) and Vytlacil and Yildiz (2006) develop the
case where Uj = Uk , but the model is not additively separable.

5010

J.J. Heckman and E.J. Vytlacil

example, j,J \j . We have that


j,J \j =

DJ \j,k j,k ,

k∈J \j

which will vary over individuals even if each individual has the same j,k treatment
effect. Consider the corresponding ATE and TT parameters:
ATE
j,J \j (x, z)
= E(j,J \j | X = x, Z = z)

Pr(IJ \j = k | X = x, Z = z)E(j,k | X = x, Z = z, IJ \j = k)
=
k∈J \j

and
TT
j,J \j (x, z)
= E(j,J \j | X = x, Z = z, IJ = j )

Pr(IJ \j = k | X = x, Z = z, IJ = j )
=
k∈J \j

× E(j,k | X = x, Z = z, IJ = j, IJ \j = k).
Even in the case where {Uj }j ∈J is independent of {Vj }j ∈J , so that E(j,k | X = x,
Z = z, IJ \j = k) = E(j,k | X = x, Z = z, IJ = j, IJ \j = k), it
TT
will still in general be the case that ATE
j,J \j (x, z) = j,J \j (x, z) since in general
Pr(IJ \j = k | X = x, Z = z) = Pr(IJ \j = k | X = x, Z = z, IJ = j ). Thus,
the ATE and TT parameters will differ in part because they place different weights on
the alternative pairwise treatment effects, and thus will differ even in the case where the
pairwise (j versus k) treatment effects are common across all individuals.
In summary, j,k will be heterogeneous depending on the functional form of the
μj (·) and μk (·) equations and on the pairwise dependence between the Uj and Uk
terms. The j,k mean treatment parameters will also vary depending on the dependence
between {Vl }l∈J and (Uj , Uk ). For j,J \j , there is an additional source of heterogeneity arising from variability in the optimal option in the set J \ j . Even if there is no
heterogeneity in the pairwise j,k terms, there will still be heterogeneity in j,J \j ,
and heterogeneity in the corresponding mean treatment parameters.
7.3.4. LIV and nonparametric Wald estimands for one choice vs. the best alternative
We first consider identification of treatment parameters corresponding to averages of
j,J \j , the effect of choosing option j versus the preferred option in J if j is not
available. We analyze both a discrete change (Wald form for the instrumental variables

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5011

estimand) and the local instrumental variables (LIV) estimand.117 Using a concise notation, define Z [j ] as the vector of elements in Zj that do not enter any other choice
index, and that Z [−j ] is a vector of elements of Z not in Z [j ] . The Z [j ] thus act as
shifters attracting people into or out of state j but not affecting the valuations in the
arguments of the other choice functions. For this case, we can develop an analysis of
IV parallel to that given for the binary case or the ordered choice case if we condition
on Z [−j ] . We obtain monotonicity or uniformity in this model if the movements among
states induced by Z [j ] are the same for all persons conditional on Z [−j ] = z[−j ] and
X = x. For example, ceteris paribus if Z [j ] = z[j ] increases, Rj (Zj ) increases but the
Rk (Zk ) are not affected, so the flow is toward state j .
Let DJ ,j be an indicator variable denoting whether option j is selected:
&

'
DJ ,j = 1 Rj (Zj )  max R (Z )
=j
&

'
= 1 ϑj (Zj )  Vj + max R (Z )


= 1 ϑj (Zj )  Ṽj ,

=j

(7.15)

where Ṽj = Vj + max=j {R (Z )}. Thus we obtain DJ ,j = 1(Pj (Zj )  UDj ), where
UDj = FV˜J |Z [−j ] (Vj + max=j {R (Z )} | Z [−j ] = z[−j ] ), where FV˜J |Z [−j ] is the cdf of

Ṽj given Z [−j ] = z[−j ] . In a format parallel to the binary model, we write
Y = DJ ,j Yj + (1 − DJ ,j )YJ \j ,

(7.16)

where YJ \j is the outcome that would be observed if option j were not available. This
case is just a version of the binary case developed in previous sections of the paper.
There is one crucial difference, however, and that is that the distributions of the Ṽj now
depend on the excluded Z = z. Thus instruments and parameters have to be defined
conditionally on Z = z. We can define MTE as


E Yj − YJ \j X = x, Z = z, ϑj (zj ) − Vj = RJ \j (z) .
We have to condition on Z = z because the choice sets are defined over the max of
elements in J \ j (see Equation (7.15)).
We now show that our identification strategies presented in the preceding part of
this paper extend naturally to the identification of treatment parameters for j,J \j .
In particular, it is possible to recover LATE and MTE parameters for j,J \j by use
of discrete change IV methods and local instrumental variable methods, respectively.
Averages of the effect of option j versus the next best alternative are the easiest effects
to study using instrumental variable methods and are natural generalizations of our twooutcome analysis.

117 An estimand is the population version of the estimator.

5012

J.J. Heckman and E.J. Vytlacil

The discrete change instrumental variables estimand will allow us to recover a version
of the local average treatment effect (LATE) parameter.118 Invoke assumption (B-2a).
Assume only one excluded variable Z [j ] in Zj . If there are more, pick any one that
satisfies (B-2a). Let Z [−j ] denote the excluded variable for option j with properties
assumed in (B-2a). We let Z = [Z [−j ] , Z [j ] ] and Z̃ = [Z̃ [−j ] , Z̃ [j ] ] be two values
where we only manipulate scalar Z [j ] .


Wald
x, z[−j ] , z[j ] , z̃[j ]
j
=

E(Y | X = x, Z = z̃) − E(Y | X = x, Z = z)
,
Pr(DJ ,j = 1 | X = x, Z = z̃) − Pr(DJ ,j = 1 | X = x, Z = z)

where for notational convenience we are assuming that Z [j ] is the last element of Z.
Note that all components of z and z̃ are the same except for the j th component. Without
loss of generality, we assume that ϑj (z̃) > ϑj (z).
If there were no X regressors, and if Z were a scalar, binary random variable, then
Wald
(x, z[−j ] , z[j ] , z̃[j ] ) would be the probability limit of the Wald form of two-stage
j
least squares regression (2SLS). With X regressors, and with Z a vector possibly including continuous components, it no longer corresponds to a Wald/2SLS, but rather
to a nonparametric version of the Wald estimator where the analyst nonparametrically
conditions on X and on Z taking one of two specified values.
The local instrumental variables estimator (LIV) estimand introduced in Heckman
(1997), and developed further in Heckman and Vytlacil (1999, 2000, 2005) and Florens
et al. (2002), will allow us to recover a version of the marginal treatment effect (MTE)
parameter. Impose (B-2b), and let Z [j ] denote the excluded variable for option j with
properties assumed in (B-2b). Because of the index structure, the LIV estimand will be
invariant to which particular variable in Z [j ] satisfying (B-2b) is used if there is more
than one variable with the property assumed in (B-2b). The effects are not invariant to
variables in Z [−j ] . Define
( ∂
∂
LIV
E(Y | X = x, Z = z)
Pr(DJ ,j = 1 | X = x, Z = z).
j (x, z) ≡
[j
]
∂z
∂z[j ]
Wald (x, z[−j ] , z[j ] , z̃[j ] ) as z̃[j ] approaches z[j ] .
LIV
j (x, z) is thus the limit form of j
Given our previous assumptions, one can easily show that this limit exists w.p.1. LIV
corresponds to a nonparametric, local version of indirect least squares. It is a function
of the distribution of the observable data, and it can be consistently estimated using any
nonparametric estimator of the derivative of a conditional expectation.
Given these definitions, we have the following identification theorem.

118 We are using the Z directly in the following manipulations instead of directly manipulating the
{ϑl (Zl )}l∈J indices. One can modify the following analysis to directly use {ϑl (Zl )}l∈J , with the disadvantage of requiring identification of {ϑl (Zl )}l∈J (e.g., by an identification at infinity argument) but with the
advantage of being able to follow the analysis of Heckman and Navarro (2007) in not requiring an exclusion
restriction if Z contains a sufficient number of continuous variables and there is sufficient variation in the ϑk
functions across k.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5013

T HEOREM 6.
1. Assume (B-1), (B-3)–(B-5), and (B-2a). Then


Wald
x, z[−j ] , z[j ] , z̃[j ] = LATE
j
j,J \j (x, z, z̃),
where z̃ = (z[−j ] , z̃[j ] ).
2. Assume (B-1), (B-3)–(B-5), and (B-2b). Then
MTE
LIV
j (x, z) = j,J \j (x, z).

P ROOF. See Appendix J.



The intuition underlying the proof is simple. Under (B-1), (B-3)–(B-5), and (B-2a), we
can convert the problem of comparing the outcome under j with the outcome under the
next best option. This is an IV version of the selection modeling of Dahl (2002).
LATE
j,J \j (x, z, z̃) is the average effect of switching to state j from state IJ \j for individuals who would choose IJ \j at Z = z but would choose j at Z = z̃. MTE
j,J \j (x, z)
is the average effect of switching to state j from state IJ \j (the best option besides
state j ) for individuals who are indifferent between state j and IJ \j at the given values
of the selection indices (at Z = z, i.e., at {ϑk (Zk ) = ϑk (zk )}k∈J ).
The mean effect of state j versus state IJ \j (the next best option) is a weighted
average over k ∈ J \ j of the effect of state j versus state k, conditional on k being the
next best option, weighted by the probability that k is the next best option. For example,
for the LATE parameter,
LATE
j,J \j (x, z, z̃)


= E j,J \j X = x, Z = z, Rj (z̃)  RJ \j (z)  Rj (z)
  

Pr IJ \j = k Z ∈ {z, z̃}, X = x, Rj (z̃)  RJ \j (z)  Rj (z)
=
k∈J \j



× E j,k X = x, Z ∈ {z, z̃}, Rj (z̃)  RJ \j (z)  Rj (z), IJ \j = k ,

where we use the result that RJ \j (z) = RJ \j (z̃) since z = z̃ except for one component
that only enters the index for the j th option. The higher ϑk (zk ), holding the other indices
constant, the larger the weight given to k as the base state. Thus, how heavily each
option is weighted in this average depends on the switching probability Pr(IJ \j = k |
Z = z, X = x, Rj (z̃j )  Rk (zk )  Rj (zj )), which in turn depends on {ϑk (zk )}k∈J \j .
The LIV and Wald estimands depend on the z evaluation point. Alternatively, one
can define averaged versions of the LIV and Wald estimands that will recover averaged
versions of the MTE and LATE parameters,




Wald
x, z[−j ] , z[j ] , z̃[j ] dFZ [−j ] z[−j ]
j
=

 [−j ] 
LATE
j,J \j (x, z, z̃) dFZ [−j ] z

5014

J.J. Heckman and E.J. Vytlacil


= E j,J \j







X = x, Rj Z [−j ] , z̃[j ]  RJ \j Z [−j ]  Rj Z [−j ] , z[j ]

and
LIV
j (x, z) dFZ (z) =

MTE
j,J \j (x, z) dFZ (z)


= E j,J \j X = x, Rj (Z) = RJ \j (Z) .119

Thus far we have only considered identification of marginal treatment effect parameters, LATE and MTE, and not of the more standard treatment parameters like ATE
and TT. However, following Heckman and Vytlacil (1999, 2001b), LATE can approximate ATE or TT arbitrarily well given the appropriate support conditions. Theorem 6
shows that we can use Wald estimands to identify LATE for j,J \j , and we can thus
adapt the analysis of Heckman and Vytlacil (2001b, 2005), as reviewed in Section 4,
to identify ATE or TT for j,J \j . Suppose that Z [j ] denotes the excluded variable
for option j with properties assumed in (B-2a), and suppose that: (i) the support of
the distribution of Z [j ] conditional on all other elements of Z is the full real line;
(ii) ϑj (zj ) → ∞ as z[j ] → ∞, and ϑj (zj ) → −∞ as z[j ] → −∞. Then ATE
j,J \j (x, z)
LATE
[−j
]
[j
]
[j
]
(x, z
, z , z̃ ) are arbitrarily close when evaluated at a sufficiently large
and j
value of z̃[j ] and a sufficiently small value of z[j ] . Following Heckman and Vytlacil
LATE (x, z[−j ] , z[j ] , z̃[j ] ) are arbitrarily close for sufficiently
(1999), TT
j,J \j (x, z) and j
small z[j ] . Using Theorem 6, we can use Wald estimands to identify the LATE parameters, and thus can use the Wald estimand to identify the ATE and TT parameters
provided that there is sufficient support for the Z. While this discussion has used the
Wald estimands, alternatively we could also follow Heckman and Vytlacil (1999), as
summarized in Section 3, in expressing ATE and TT as integrated versions of MTE.
By Theorem 6, we can use LIV to identify MTE and can thus express ATE and TT as
integrated versions of the LIV estimand.
For a general instrument J (Z [j ] , Z [−j ] ) constructed from (Z [j ] , Z [−j ] ), which we
denote as J [j ] , we can obtain a parallel construction to the characterization of standard
IV given in Section 4.3:
=
IV
J [j ]

1
0

[j ]

J
MTE (x, z, uDj )ωIV
(uDj ) duDj ,

(7.17)

where
[j ]

J
ωIV
(uDj ) =

E[J [j ] − E(J [j ] ) | Pj (Z)  uDj ] Pr(Pj (Z)  uDj | Z [−j ] = z[−j ] )
Cov(Z [j ] , DJ ,j )

,

(7.18)
119 We assume that the support of Z [−j ] conditional on Z [j ] is the same as the support of Z [−j ] conditional
on Z̃ [j ] .

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5015

where uDj is defined at the beginning of this subsection and where we keep the conditioning on X = x implicit.
Note that from Theorem 6, we obtain that
∂
E[Y
∂z[j ]

| X = x, Z = z]
∂Pj (z)
∂z[j ]

∂E[Y | X = x, Z = z]
∂Pj (z)


= E Yj − YJ \j X = x, Z = z, ϑj (Zj ) − Vj = RJ \j (Z)

=

so LIV identifies MTE and linear IV is a weighted average of LIV with the weights
summing to one. These results mirror the results established
in the binary case.

In the literature on the effects of schooling (S = j ∈J j DJ ,j ) on earnings (YJ ),
it is conventional to instrument S. The website of Heckman, Urzua and Vytlacil (2006)
presents an analysis of this case. For the general unordered case,
IV
=
J [j ]

Cov(J [j ] , YJ )
Cov(J [j ] , S)

can be decomposed into economically interpretable components where the weights can
be identified but the objects being weighted cannot be identified using local instrumental variables or LATE without making large support assumptions. However, the
components can be identified using a structural model.
The trick we have used in this subsection comparing outcomes in j to the next best
option converts a general unordered multiple outcome model into a two-outcome setup.
This effectively partitions YJ into two components, as in (7.16). Thus we write
YJ = DJ ,j Yj + (1 − DJ ,j )YJ \j ,
where
YJ \j =


=j
∈J

DJ ,
Y · 1(DJ ,j = 1).
1 − DJ ,j

In the more general unordered case with three or more choices,
to analyze IV estimates

of the effect of S on YJ , we must work with YJ =
D
J ,k Yk and make mulk∈J
tiple comparisons across potential outcomes. This requires us to move outside of the
LATE/LIV framework, which is inherently based on binary comparisons. We turn to
that analysis next.
7.3.5. Identification: Effect of best option in K versus best option not in K
We just presented an analysis of identification for treatment parameters defined as averages of j,J \j , the effect of choosing option j versus the preferred option in J if j
were not available. We now consider identification of K,J \K , the effect of choosing

5016

J.J. Heckman and E.J. Vytlacil

the preferred choice among set K versus the preferred choice among J if no option
in K were available. This is an effect where we compare sets of options, and not just a
single option compared to the rest.
We first start with an analysis that varies the {ϑk (·)}k∈J indices directly. This analysis
would be useful if one first identifies the index function, e.g., through an identification at
infinity argument using the analysis in Matzkin (1993), as in Appendix B of Chapter 70
or Chapter 73 (Matzkin) in this Handbook. We then perform an analysis shifting Z
directly. We show that it is possible to identify MTE and LATE averages of the K,J \K
effect if one has knowledge of the {ϑk (·)}k∈J index functions but is not possible using
shifts in Z without knowledge of the index functions. The one exception to this result is
the special case already considered, when K = k, i.e., the set only contains one element,
in which case it is possible to identify the marginal parameters using shifts in Z directly
without knowledge of the index functions.
Let ϑJ (Z) denote a random vector stacking the indices,
)

ϑJ (Z) =
ϑk (Z): k ∈ J .
k∈J

Let ϑJ be a vector denoting a potential evaluation point of ϑJ (Z), ϑJ = {ϑk : k ∈ J },
so that ϑJ (Z) = ϑJ denotes the event {ϑk (Z) = ϑk : k ∈ J }.120 Let ϑJ + h denote
{ϑk + h: k ∈ J }, where h ∈ R. We now define a version of the Wald estimand that uses
the indices directly as instruments instead of using Z as instruments,
˜ Wald (x, ϑJ , h)

K
 

≡ E Y X = x, ϑK (Z) = ϑK + h, ϑJ \K (Z) = ϑJ \K


− E Y X = x, ϑJ (Z) = ϑJ
 

× Pr IJ ∈ K X = x, ϑK (Z) = ϑK + h, ϑJ \K (Z) = ϑJ \K

−1
− Pr IJ ∈ K X = x, ϑJ (Z) = ϑJ
.
˜ Wald (x, ϑJ , h) corresponds to the effect of a shift in each index in K upward by h

K
while holding each index in J \ K constant. Using indices, we define a version of the
˜ LIV (x, ϑJ ) through a limit expression
LIV estimand using indices 
K
˜ LIV (x, ϑJ ) = lim 
˜ Wald (x, ϑJ , h).

K
h→0 K
Likewise, we define versions of the LATE and MTE parameters that are functions of
the ϑ indices instead of functions of z evaluation points,
˜ LATE (x, ϑJ , h)

K,L


= E K,L X = x, ϑJ (Z) = ϑJ , RK (Z) + h  RL (Z)  RK (Z) ,
120 Note that in our notation, R = max{R }
k k∈J is a scalar, while ϑJ (Z) = {ϑk (Z): k ∈ J } is a vector.
J

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5017



˜ MTE (x, ϑJ ) = E K,L X = x, ϑJ (Z) = ϑJ , RK (Z) = RL (Z) .

K,L
We state the following identification theorem:
T HEOREM 7.
1. Assume (B-1), (B-3)–(B-5), and (B-2a). Then
˜ LATE (x, ϑJ , h).
˜ Wald (x, ϑJ , h) = 

K,J \K
K
2. Assume (B-1), (B-3)–(B-5), and (B-2b). Then
˜ MTE (x, ϑJ ).
˜ LIV (x, ϑJ ) = 

K,J \K
K
P ROOF. Follows with trivial modifications from the proof of Theorem 6.



Now consider the same analysis shifting Z directly instead of shifting the indices.
First consider LATE. If one knew what shifts in Z corresponded to shifting each index in K upward by the same amount while holding each index in J \ K constant,
then one could immediately follow the preceding analysis to recover E(K,J \K |
X = x, ϑJ (Z) = ϑJ , RK (Z) + h  RJ \K (Z)  RK (Z)). However, unless K is
a singleton, without knowledge of the index functions one does not know what shifts
in Z will have this property. One possible approach would be to only shift elements of Z
that are elements of Zj for j ∈ K but are excluded from Zj for j ∈ J \ K. However,
unless the shifts move the indices for choices in K all by the same amount, the shift in
Z will result in movement not only from the set J \ K to the set K but also cause movement between choices within K. Thus, one can use shifts in Z to recover a LATE-type
parameter for K,J \K only if either (i) the index functions are known, or (ii) K = {k},
i.e., the set K contains only one element. Our analysis establishes a fundamental role
for choice theory in recovering the indices needed to perform IV analysis.
Thus far, we have only considered identification of marginal treatment effect parameters for K,J \K and not of the more standard treatment parameters ATE and TT for
K,J \K . As in the immediately preceding section, we can follow Heckman and Vytlacil (1999) in expressing ATE and TT as integrated versions of MTE or show that ATE
and TT can be approximated arbitrarily well by LATE parameters. Given appropriate
support conditions, we can again identify MTE over the appropriate range or identify the
appropriate LATE parameters and thus identify ATE and TT given the required support
conditions.
7.3.6. Identification: Effect of one fixed choice versus another
Consider evaluating the effect of fixed option j versus fixed option k, j,k , i.e., the
effect for the individual of having no choice except to choose state j versus no choice
except to choose state k. We show that it is possible to identify averages of j,k if one
has sufficient support conditions. These conditions supplement the standard IV conditions developed for the binary case [Heckman, Urzua and Vytlacil (2006)] with the

5018

J.J. Heckman and E.J. Vytlacil

conditions more commonly used in semiparametric estimation. We start by considering
the analysis if one knows the ϑ index functions, say from a semiparametric analysis of
discrete choice, and then show that knowledge of the ϑ index functions is not necessary.
For notational purposes, for any j, k ∈ J , define Uj,k = Uj − Uk , and let
ϑj,k (Z) = ϑj (Zj ) − ϑk (Zk ). One might try to follow our previous strategy to identify treatment parameters for j,k if one could shift ϑj − ϑk = ϑj,k while holding
constant {ϑl,m }(l,m)∈J ×J \{j,k} , i.e., while holding all other utility contrasts fixed.121
However, given the structure of the latent variable model determining choices, these are
incompatible conditions. To see this, note that ϑj,k = ϑl,k − ϑl,j for any l, and thus ϑj,k
cannot be shifted while holding ϑl,j and ϑl,k constant.122
To bypass this problem, we develop a limit strategy to make the consequences of
shifting ϑj,k negligible. Our strategy relies on an identification at infinity argument.
For example, consider the case where J = {1, 2, 3}, and consider identification of
the MTE parameter for option 3 versus option 1. Recall that DJ \3,l is an indicator
variable for whether option l would be chosen if option 3 were not available, so that
DJ \3,l 3,J \3 = DJ \3,l 3,l . Since 1 and 2 are the only options if 3 is not available, it
follows that 3,J \3 = DJ \3,1 3,1 + DJ \3,2 3,2 , and we have that


E 3,J \3 X = x, ϑJ (Z) = ϑJ , R3 (Z) = RJ \3 (Z)


= E DJ \3,1 3,1 X = x, ϑJ (Z) = ϑJ , R3 (Z) = RJ \3 (Z)


+ E DJ \3,2 3,2 X = x, ϑJ (Z) = ϑJ , R3 (Z) = RJ \3 (Z) .
The smaller ϑ2 is (holding ϑ1 and ϑ3 fixed), the larger the probability that the “next best
option” is 1 and not 2. Note that E(3,1 | X = x, ϑJ (Z) = ϑJ , R3 (Z) = R1 (Z))
does not depend on the ϑ2 evaluation point given independence assumption (B-1), so
that


E 3,1 X = x, ϑJ (Z) = ϑJ , R3 (Z) = R1 (Z)


= E 3,1 X = x, ϑJ \2 (Z) = ϑJ \2 , R3 (Z) = R1 (Z) .
121 Alternatively, one can allow ϑ
l,m (z) = ϑl,m (z ) if Pr(Ul,m ∈ [ϑl,m (z), ϑl,m (z )]) = 0. Such a possibility
would be ruled out except “at the limit” by the standard assumption that the support of Ul,m is connected.
(We discuss this below.) Even without such an assumption, such a possibility occurring simultaneously for
all (l, m) ∈ J × J \ {j, k} for a particular (z, z ) seems extremely implausible, and we will therefore not
consider this possibility further.
122 This suggests a nonparametric test of the latent variable model. If there exists (z, z ) such that
Pr(IJ = j | Z = z) = Pr(IJ = j | Z = z ), and Pr(IJ = k | Z = z) = Pr(IJ = k | Z = z ),
but Pr(IJ = l | Z = z) = Pr(IJ = l | Z = z ) for all l ∈ J \ {j, k}, then the latent variable model is
rejected. However, shifts in only two indices are possible for sequential models since unexpected innovations
in agent information sets will act to shift the current decision without affecting previous decisions. Consider
the following sequential model of GED certification. In the first period, the agent chooses to graduate from
high school or to dropout of high school. If the agent drops out of high school in the first period, he or she has
the option in the second period of attaining GED certification or staying a permanent dropout. An unexpected
shock in the second period to the relative value of GED certification versus permanent dropout status will
shift the GED/permanent dropout choice without changing the probability of high school graduation.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5019

Thus, by assumptions (B-1) and (B-3) and the Dominated Convergence Theorem, we
have that


lim E DJ \3,1 3,1 X = x, ϑJ (Z) = ϑJ , R3 (Z) = RJ \3 (Z)
ϑ2 →−∞


= E 3,1 X = x, ϑJ \2 (Z) = ϑJ \2 , R3 (Z) = R1 (Z)
while
lim

ϑ2 →−∞



E DJ \3,2 3,2 X = x, ϑJ (Z) = ϑJ , R3 (Z) = RJ \3 (Z) = 0,

so that


E 3,J \3 X = x, ϑJ (Z) = ϑJ , R3 (Z) = RJ \3 (Z)


= E 3,1 X = x, ϑJ \2 (Z) = ϑJ \2 , R3 (Z) = R1 (Z) .

lim

ϑ2 →−∞

In other words, as the value of option 2 becomes arbitrarily small, the probability of the
“next best option” being 1 becomes arbitrarily close to one. Thus the MTE parameter
for option 3 versus the next best option becomes arbitrarily close to the MTE parameter
for option 3 versus option 1.
We can identify the MTE parameter for option 3 versus the next best option using
the LIV estimand as in Theorem 6, and thus conditioning on ϑ2 arbitrarily small we
have that the LIV estimand is arbitrarily close to the MTE parameter for option 3 versus
option 1. This analysis requires the appropriate support conditions in order for the limit
operations to be well defined. The following theorem formalizes this idea, and is for the
more general case where J is a general finite set.
T HEOREM 8. Assume (B-1), (B-3)–(B-5), and (B-2b). Assume that, for any t ∈ R,


Pr ϑl (Zl )  t ϑj (Zj ), ϑk (Zk )  0 ∀l ∈ J \ {j, k}.
Then
˜ LIV
lim

j (x, ϑJ )


= E j,k X = x, ϑj,k (Z) = ϑj,k , Rj (Z) = Rk (Z)

maxl∈J \{j,k} {ϑl }→−∞

for any




x ∈ lim Supp X ϑj (Zj ) = ϑj , ϑk (Zk ) = ϑk , max ϑl (Z)  t .
t→−∞

l∈J \{j,k}

P ROOF. By a trivial modification to the proof of Theorem 6, we have that


˜ LIV

j (x, ϑJ ) = E j,J \j X = x, ϑJ (Z) = ϑJ , Rj (Z) = RJ \j (Z) .
The remainder of the proof follows from an immediate extension of the 3-option case
just analyzed.


5020

J.J. Heckman and E.J. Vytlacil

Thus, for x values in the appropriate limit support, we can approximate E(j,k | X = x,
ϑ{j,k} (Z) = ϑ{j,k} , Rj (z) = Rk (z)) arbitrarily well by LIV
j (x, ϑJ ) for an arbitrarily
small maxl∈J \{j,k} {ϑl }.
This analysis uses the ϑ index functions directly, but the results can be restated without using the ϑ functions directly. Again consider the three-choice example. The central
aspect of the identification strategy is to “zero-out” the second choice by making ϑ2
arbitrarily small, allowing one to then use the LIV estimand to identify the MTE parameter for the first option versus the third as if the second choice were not an option. If
we do not know the ϑ2 function, we cannot condition on it. However, if we know that
ϑ2 is decreasing in a particular element of Z, say Z [j ] , where Z [j ] does not enter the
index function for choices 1 and 3 and where ϑ2 (z2 ) → 0 as z[j ] → −∞, then we can
follow the same strategy as if we knew the ϑ2 index except we condition on Z [j ] being
small instead of conditioning on ϑ2 being small. The idea naturally extends to the case
of more than three options.
We can follow Heckman and Vytlacil (1999) in following a two-step identification
strategy for ATE and TT parameters of j,k . We first identify the appropriate MTE
or LATE parameters and then use them to identify ATE and TT given the appropriate
support conditions. Notice that the required support conditions are now stronger than
those required for the ATE and TT parameters of j,J \j . For identification of the ATE
and TT parameters of j,J \j , we require a large support assumption only on the j th
index. In particular, we require that it be possible to condition on Z values that make
ϑj arbitrarily small or arbitrarily large while holding the remaining indices fixed. In
contrast, for identification of the ATE and TT parameters of j,k , we require a large
support assumption on each index. We require that for each index we can condition
on Z values that make the index arbitrarily small or arbitrarily large while holding the
remaining indices fixed. The reason for this stronger condition is that for identification
of j,k we need to use an identification at infinity strategy on all but the j and k indices
to even obtain the marginal parameters. We then need an additional identification at
infinity step to use the marginal parameters to recover the ATE and TT parameters.
7.3.7. Summarizing the results for the unordered model
We have obtained the following results on the unordered choice model in this section:
• E(j,J \j | X = x, Z = z, Rj (z) = RJ \j (z)) and E(j,J \j | X = x, Z =
z, Rj (z̃)  RJ \j (z̃)  Rj (z)) can be identified without a limit argument.
• E(j,k | X = x, {ϑk }k∈J , Rj (z) = Rk (z)) and E(j,k | X = x, {ϑk }k∈J ,
Rj (z̃)  Rk (z̃)  Rj (z)) can be identified with a limit argument on each index in
J \ {j, k}.
TT
• ATE
j,J \j (x, z) and j,J \j (x, z) can be identified with a limit argument using the
ϑj index.
TT
• ATE
j,k (x, z) and j,k (x, z) can be identified with a limit argument using each index.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5021

These results establish the central role of choice theory (via {ϑk }k∈J ) and identification at infinity in using an IV strategy to identify a variety of treatment parameters and
their extensions to a general multiple choice model. Our analysis extends the analysis of
ordered outcome models developed in the preceding section to a general unordered case.
Local instrumental variables identify the marginal treatment effect corresponding to the
effect of one option versus the best alternative option without requiring large support
assumptions or knowledge of the parameters of the choice model. This result preserves
the spirit of the Imbens and Angrist (1994) LATE analysis and the analysis of Heckman
and Vytlacil (1999, 2001b, 2005). More generally, LIV can provide identification of the
marginal treatment effect corresponding to the effect of choosing between one choice set
versus not having that choice set available. However, identification of the more general
parameters requires knowledge (identification) of the structural, latent index functions
of the multinomial choice model. LIV can also provide identification of the effect of one
specified choice versus another, requiring large support assumptions but not knowledge
of the latent index functions. In order to identify some treatment parameters, we require
identification of the latent index functions generating the multinomial choice model or
else having large support assumptions. This connects the LIV analysis in this paper to
the more ambitious but demanding identification conditions for the full multinomial selection model developed in Heckman and Navarro (2007), Chapter 73 (Matzkin) of this
Handbook, and Appendix B of Chapter 70. We next develop the case of the continuum
of outcomes.
7.4. Continuous treatment
Thus far we have considered the case of a treatment variable taking a finite number of
values. Now consider the case where the treatment variable D can take a continuum of
values. Suppose that
Y = μ(D, X, U ),
D = ϑ(Z, V ),
with D a continuous random variable. We do not in general need to restrict U or V to
be scalar random variables. We can rewrite this model in potential outcome notation by
defining
Yd ≡ μd (X, U ) ≡ μ(d, X, U ).
For ease of exposition, we will assume that X is exogenous in addition to Z being
exogenous, so that (X, Z) ⊥
⊥ (U, V ).
We assume that μ(d, x, u) is continuous in its first argument. Equivalently, we assume that {Yd } is continuous in d for any realization. Implicit in the continuity assumption is an ordering, that two treatments that are close to one another have associated
outcomes that are close to one another. The restriction is qualitatively different from any

5022

J.J. Heckman and E.J. Vytlacil

restriction we have considered thus far. In the previous sections, there are no restrictions
connecting Yd to Yd . Equivalently, there are no restrictions connecting μd (X, U ) and
μd (X, U ). In the case of a continuum of treatments, we now tightly link counterfactual
values that correspond to treatments that are close to one another.
The literature analyzing continuous endogenous regressors often defines the object of
interest not as a treatment effect but instead as the “average structural function” (ASF).
Following Blundell and Powell (2004), the ASF is defined as
μ(d, x) = E(Yd | X = x) =

μ(d, x, u) dFU (u).

In other words, the ASF is defined as the average value of Y that would result from
assigning treatment d to all individuals with X = x. If D is endogenous, the ASF does
not in general equal the conditional expected value of Y in the data, E(Yd | X = x) =
E(Y | D = d, X = x), since μ(d, x, u) dFU (u) = μ(d, x, u) dFU |X,D (u | x, d).
This is just a version of the distinction between fixing and conditioning introduced in
Haavelmo (1943) and discussed in Chapter 70.
Instead of working with the ASF, we can follow the lead of Florens et al. (2002) and
define treatment effect parameters for a continuous treatment. Suppose that μ(d, x, u)
is differentiable in d for any (x, u). We can define the average treatment effect as


∂
∂
X
=
x
=
(x)
=
E
Y
μ(d, x, u) dFU (u),
ATE
d
d
∂d
∂d
which is the average effect of a marginal increase in the treatment if individuals were
randomly assigned treatment level d. Note that in this expression the average treatment
effect depends on the base treatment level, d, and for any of the continuum of possible
base treatment levels we have a different average treatment effect. The average treatment
effect is the derivative of the Blundell and Powell ASF:
∂
μ(d, x).
∂d
Florens et al. (2002) define treatment on the treated as


∂
TT
d (x) = E
Yd D = d2 , X = x
∂d1 1
d=d1 =d2
ATE
d (x) =

=

∂
μ(d1 , x, u)
∂d1

dFU |X,D (u | x, d),
d=d1

which is the average effect among those currently choosing treatment level d of an
incremental increase in the treatment while leaving their unobservables fixed. Likewise,
define the marginal treatment effect as


∂
∂
(x,
v)
=
E
Y
μ(d, x, u) dFU |V (u | v).
V
=
v,
X
=
x
=
MTE
d
d
∂d
∂d

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5023

To illustrate these definitions, suppose D is schooling level measured as a continuous
variable, and suppose Y is wages. Then, e.g., Y12 would be the potential wage corresponding to receiving exactly 12 years of schooling and μ12 = E(Y12 ) is the average
wage if individuals were exogenously assigned exactly 12 years of schooling. ATE
12 is
the average effect on wages of being assigned marginally more than 12 years of schooling versus being assigned exactly 12 years of schooling, and TT
12 would be the average
effect of obtaining marginally more schooling for those who self-select to obtain exactly
12 years of schooling.
One approach to identification of the treatment parameters is to impose more structure on the outcome equation while allowing the treatment selection equation to be
unspecified. The nonparametric instrumental variable approach of Darolles, Florens and
Renault (2002), Hall and Horowitz (2005), and Newey and Powell (2003) requires that
the unobservables in the outcome equation (U ) be a scalar random variable and that the
outcome be an additive function of the unobservables – Chapter 73 (Matzkin) of this
Handbook surveys this literature. Their additivity assumption imposes the restriction of
no treatment effect heterogeneity (conditional on X), so that all treatment effect parameters coincide. In exchange for this restriction on the outcome equation, they do not
require any structure on the first stage equation so that D does not need to be increasing in V and V is not required to be a scalar random variable. Furthermore, they only
require that U be mean independent of (X, Z), not that (U, V ) be fully independent
of (X, Z).
The additive error term assumption is relaxed by Chernozhukov, Imbens, and Newey
(2007), who impose the stronger requirement that the outcome is a strictly increasing
function of the error term (i.e., μ(x, d, u) strictly increasing in u),123 while strengthening the required independence property to be (Z, X) ⊥
⊥ U . The restriction of a scalar
error term with the outcome strictly increasing in this error term is again a strong restriction on the forms of treatment effect heterogeneity that are possible in the model.124
Suppress X for ease of exposition. Under their restriction, if μ(d, u) > μ(d, u ) at
some treatment level d, then μ(d̃, u) > μ(d̃, u ) for all treatment levels d̃. In other
words, if individual one has a higher potential outcome at some value of the treatment
than a second individual, than that first individual has a higher potential outcome for
any value of the treatment than the second individual. Under this restriction, treatment
cannot change the rank ordering of outcomes across individuals. These restrictions are
in contrast with the Roy model and generalized Roy model, where one individual may
have a higher with-treatment potential outcome but a lower without-treatment potential
outcome compared to a second individual.
123 More generally, that μ is a weakly separable function of U , so that μ can be rewritten as a function of a

scalar aggregator of U .
124 See also Chernozhukov and Hansen (2005), who allow for richer treatment effect heterogeneity but impose a “rank similarity” restriction that requires agents not to act upon their own individual effects. This can be
shown to eliminate the general form of heterogeneous responses analyzed by the generalized Roy model. For
a discussion of the analysis of Chernozhukov and Hansen (2005), see Chapter 73 (Matzkin) of this Handbook.

5024

J.J. Heckman and E.J. Vytlacil

In contrast to these approaches, control variate approaches impose more structure on
the selection equation, imposing that the unobservables in the treatment selection equation (V ) be a scalar random variable,125 and that the treatment is an additive function of
the unobservables or more generally a strictly increasing function of the unobservables.
Such approaches thus impose strong restrictions on the heterogeneity in the treatment
selection equation. In exchange for these restrictions, such approaches do not require Y
to be increasing in U and do not require U to be a scalar random variable. Imbens and
Newey (2002) consider identification and estimation of the average structural function
in a nonparametric model using the control variate approach, building on the work of
Blundell and Powell (2004) and Altonji and Matzkin (2005). Their approach does not
impose any further restrictions on the outcome equation, but does require a large support assumption. Another recent contribution to the control function literature is Florens
et al. (2006), who restrict Y to be determined by a stochastic polynomial in D but do
not require a large support assumption. We now further discuss both approaches.
Imbens and Newey (2002) proceed as follows. They assume that ϑ(z, v) is strictly
monotonic in v. Suppose that (U, V ) ⊥
⊥ (X, Z), and without loss of generality normalize V to be unit uniform. Then V is immediately identified (up to the normalization)
from V = F (Y | X, Z). Given identification of V , they can identify E(Y | D, X, V ).
Their independence assumptions imply that U ⊥
⊥ D | (X, V ), so that
E(Y | D = d, X = x, V = v) = E(Yd | X = x, V = v).
E(Yd | X = x, V = v) corresponds to the marginal treatment effect except that it is the
conditional expectation in level instead of the derivative of the conditional expectation.
Then, in parallel to the way Heckman and Vytlacil (1999) integrate up the MTE to
recover the ATE, Imbens and Newey integrate up E(Yd | X = x, V = v) to obtain the
ASF:
E(Yd | X = x) =
=

E(Yd | X = x, V = v) dFV (v)
E(Y | D = d, X = x, V = v) dFV (v).

Imbens and Newey do not explicitly consider the ATE, TT, or MTE, but we can adapt
the Heckman and Vytlacil (1999) weighting analysis summarized in Section 3 to obtain these parameters as a slight modification of the Imbens and Newey analysis. First
consider the MTE. We have that


∂
∂
E(Y | D = d, X = x, V = v) = E
Yd X = x, V = v ,
∂d
∂d

125 More generally, that ϑ is a weakly separable function of V , so that ϑ can be rewritten as a function of a
scalar aggregator of V .

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5025

so that the MTE is identified. Integrating up the MTE we obtain ATE




∂
∂
Yd X = x = E
Yd X = x, V = v dFV (v)
E
∂d
∂d
∂
=
E(Y | D = d, X = x, V = v) dFV (v)
∂d
and TT


∂
E
Yd D = d2 , X = x
∂d1 1
d=d1 =d2


∂
= E
Yd X = x, V = v dFV |D=d2 ,X (v | x)
∂d
∂
=
E(Y | D = d, X = x, V = v) dFV |D=d2 ,X (v | x).
∂d
Note the strong connection between the control variate approach and the LIV/MTE
approach of Heckman and Vytlacil (1999). They both proceed by identifying an expectation conditional on the first stage error term, and then integrating that expectation
up to obtain the parameter of interest. The primary distinction is that, in the control
variate approach with a continuous endogenous treatment, it is possible to assume that
the treatment is a strictly increasing function of an error term that is independent of
the instruments, to identify this error term, and then to explicitly include the identified first-stage error term as a regressor in the second stage regression for the outcome.
In contrast, with a discrete endogenous treatment, it is not possible to characterize the
treatment as a strictly increasing function of an error term that is independent of the
instruments. It is thus not possible to identify the first-stage error term, and thus not
possible to explicitly include an identified first-stage error term in the second stage. The
LIV strategy is the approach in the discrete case that by-passes the need to explicitly
identify the first stage error term.
In order to be able to integrate E(Y | D = d, X = x, V = v) = E(Yd | X = x, V =
v) up to obtain the ASF (or to integrate MTE to obtain ATE), it is necessary to evaluate
E(Y | D = d, X = x, V = v) at all values of v in the support of the distribution of V
conditional on X. This is a nontrivial requirement. To show this, suppress X for ease of
exposition. One can only evaluate E(Y | D = d, V = v) at values of v in the support of
the distribution of V conditional on D = d, so that the requirement is that the support
of the distribution of V conditional on D = d equal the support of the unconditional
distribution. This requires, in turn, a large support assumption on an element of Z. For
example, suppose that ϑ(Z, V ) = P (Z) + V , so that D = P (Z) + V . Let P denote the
support of the distribution of P (Z). Then


Supp(V | D = d) = Supp V P (Z) + V = d


= Supp V V = d − P (Z) = {d − p: p ∈ P},

5026

J.J. Heckman and E.J. Vytlacil

where the last equality uses Z ⊥
⊥ V . For example, if P = [a, b], then {d − p: p ∈
[a, b]} = [d − b, d − a] which does not depend on d if and only if a = −∞ and
b = ∞, i.e., if and only if P = R. For standard models, this requirement in turn necessitates a regressor with unbounded support, analogous to the identification at infinity
requirement in selection models shown by Heckman (1990). We have noted the central
role played by identification at infinity assumptions in many different settings throughout this Handbook.
Next consider the analysis of Florens et al. (2002). They assume that (U, V ) ⊥
⊥ (X, Z).
They impose additional structure on the outcome equation, in particular that the outcome equation can be expressed by a finite order stochastic polynomial in the treatment
variable:
Y = μ(D, X) +

K


D j Uj

j =0

so that
Yd = μd (X) +

K


d j Uj .

j =0

This specification can be seen as a nonparametric extension of the random coefficient
models of Heckman and Vytlacil (1998) and Wooldridge (1997, 2003). As a consequence of the structure on the outcome equation, Florens et al. (2006) are able to identify
the ATE without requiring the large support assumption of Imbens and Newey (2002).
Instead of a large support assumption, they require measurable separability of D and V
conditional on X.
Measurable separability is the requirement that any function of D and X that almost
surely equals a function of V and X must be a function of X only. This assumption can
be shown to be equivalent to requiring that D not lie in a subset of its support if and only
if V lies in a subset of its support (conditional on X). As shown by Florens et al. (2006),
measurable separability between D and V follows from the independence assumption
(U, V ) ⊥
⊥ (X, Z) along with mild regularity conditions. Thus the Florens, Heckman,
Meghir, and Vytlacil approach allows for identification of the average treatment effect
with continuous endogenous regressors without requiring large support assumptions in
exchange for requiring a finite-order, stochastic polynomial assumption on the outcome
equation. We next consider the method of matching, which is based on the assumption
of conditional independence that is assumed to characterize data structures.

8. Matching
The method of matching assumes selection of treatment based on potential outcomes

⊥ D,
(Y0 , Y1 ) ⊥

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5027

so Pr(D = 1 | Y0 , Y1 ) depends on Y0 , Y1 . It assumes access to variables Q such that
conditioning on Q removes the dependence:
⊥ D | Q.
(Q-1) (Y0 , Y1 ) ⊥
Thus,
Pr(D = 1 | Q, Y0 , Y1 ) = Pr(D = 1 | Q).
Comparisons between treated and untreated can be made at all points in the support of
Q such that
(Q-2) 0 < Pr(D = 1 | Q) < 1.
The method does not explicitly model choices of treatment or the subjective evaluations
of participants, nor is there any distinction between the variables in the outcome equations (X) and the variables in the choice equations (Z) that is central to the IV method
and the method of control functions. In principle, condition (Q-1) can be satisfied using a set of variables Q distinct from all or some of the components of X and Z. The
conditioning variables do not have to be exogenous.
From condition (Q-1), we recover the distributions of Y0 and Y1 given Q, Pr(Y0  y0 |
Q = q) = F0 (y0 | Q = q) and Pr(Y1  y1 | Q = q) = F1 (y1 | Q = q) – but not
the joint distribution F (y0 , y1 | Q = q), because we do not observe the same persons
in the treated and untreated states. This is a standard evaluation problem common to all
econometric estimators. Methods for determining which variables belong in Q rely on
untested exogeneity assumptions which we discuss in this section.
OLS is a special case of matching that focuses on the identification of certain conditional means. In OLS, linear functional forms are maintained as exact representations
or valid approximations. Considering a common coefficient model, OLS writes
(Q-3) Y = Qα + Dβ + U ,
where α is the treatment effect and
(Q-4) E(U | Q, D) = 0.
The assumption is made that the variance–covariance matrix of (Q, D) is of full rank:
(Q-5) Var(Q, D) full rank.
Under these conditions, we can identify β even though D and U are dependent: D ⊥

⊥ U.
Controlling for the observable Q eliminates any spurious mean dependence between D
and U : E(U | D) = 0 but E(U | D, Q) = 0. (Q-4) is the linear regression counterpart
to (Q-1). (Q-5) is the linear regression counterpart to (Q-2). Failure of (Q-5) would
mean that using a nonparametric estimator, we might perfectly predict D given Q, and
that Pr(D = 1 | Q = q) = 1 or 0.126
126 This condition might be met only at certain values of Q = q. For certain parameterizations (e.g., the
linear probability model), we may obtain predicted probabilities outside the unit interval.

5028

J.J. Heckman and E.J. Vytlacil

(Q-5) If the goal of the analysis is only to identify β, in place of (Q-4) we can get
by with
(Q-4) : E(U | Q, D) = E(U | Q).
Assuming Var(D | Q) > 0, we can identify β even if we cannot separate αQ
from E(U | Q).
Matching can be implemented as a nonparametric method. When this is done, the procedure does not require specification of the functional form of the outcome equations.
It enforces the requirement that (Q-2) be satisfied by estimating functions pointwise in
the support of Q. To link our notation in this section to that in the rest of the chapter, we
assume that Q = (X, Z) and that X and Z are the same except where otherwise noted.
Thus we invoke assumptions (M-1) and (M-2) presented in Section 2, even though in
principle we can use a more general conditioning set.
Assumptions (M-1) and (M-2) introduced in Section 2 or (Q-1) and (Q-2) rule out the
possibility that after conditioning on X (or Q), agents possess more information about
their choices than econometricians, and that the unobserved information helps to predict
the potential outcomes. Put another way, the method allows for potential outcomes to
affect choices but only through the observed variables, Q, that predict outcomes. This
is the reason why Heckman and Robb (1985a, 1986b) call the method selection on
observables.
This section establishes the following points. (1) Matching assumptions (M-1) and
(M-2) generically imply a flat MTE in uD , i.e., they assume that E(Y1 − Y0 | X = x,
UD = uD ) does not depend on uD . Thus the unobservables central to the Roy model
and its extensions and the unobservables central to the modern IV literature are assumed to be absent once the analyst conditions on X. (M-1) implies that all mean
treatment parameters are the same. (2) Even if we weaken (M-1) and (M-2) to mean
independence instead of full independence, generically the MTE is flat in uD under the
assumptions of the nonparametric generalized Roy model developed in Section 3, so
again all mean treatment parameters are the same. (3) We show that IV and matching
make distinct identifying assumptions even though they both invoke conditional independence assumptions. (4) We compare matching with IV and control function (sample
selection) methods. Matching assumes that conditioning on observables eliminates the
dependence between (Y0 , Y1 ) and D. The control function principle models the dependence. (5) We present some examples that demonstrate that if the assumptions of the
method of matching are violated, the method can produce substantially biased estimators of the parameters of interest. (6) We show that standard methods for selecting the
conditioning variables used in matching assume exogeneity. This is a property shared
with many econometric estimators, as noted in Chapter 70, Section 5.2. Violations of
the exogeneity assumption can produce biased estimators.
Nonparametric versions of matching embodying (M-2) avoid the problem of making
inferences outside the support of the data. This problem is implicit in any application of
least squares. Figure 22 shows the support problem that can arise in linear least squares

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5029

Figure 22. The least squares extrapolation problem avoided by using nonparametric regression or matching.

when the linearity of the regression is used to extrapolate estimates determined in one
empirical support to new supports. Careful attention to support problems is a virtue
of any nonparametric method, including, but not unique to, nonparametric matching.
Heckman et al. (1998) show that the bias from neglecting the problem of limited support
can be substantial. See also the discussion in Heckman, LaLonde and Smith (1999).
We now show that matching implies that conditional on X, the marginal return is
assumed to be the same as the average return (marginal = average). This is a strong behavioral assumption implicit in statistical conditional independence assumption (M-1).
It says that the marginal participant has the same return as the average participant.
8.1. Matching assumption (M-1) implies a flat MTE
An immediate consequence of (M-1) is that the MTE does not depend on UD . This is
so because (Y0 , Y1 ) ⊥
⊥ D | X implies that (Y0 , Y1 ) ⊥
⊥ UD | X and hence that
MTE (x, uD ) = E(Y1 − Y0 | X = x, UD = uD ) = E(Y1 − Y0 | X = x).
This, in turn, implies that MTE

(8.1)

conditional on X is flat in uD , so that matching invokes
assumption (C-1) invoked in Section 4.2.1. Under our assumptions for the generalized
Roy model, it assumes that E(Y | P (Z) = p) is linear in p. Thus the method of
matching assumes that mean marginal returns and average returns are the same and
all mean treatment effects are the same given X. However, one can still distinguish
marginal from average effects of the observables (X) using matching. See Carneiro
(2002).
It is sometimes said that the matching assumptions are “for free” [see, e.g., Gill and
Robins (2001)] because one can always replace unobserved F1 (Y1 | X = x, D = 0)
with observed F1 (Y1 | X = x, D = 1) and unobserved F0 (Y0 | X = x, D = 1) with
observed F0 (Y0 | X = x, D = 0). Such substitutions do not contradict any observed
data.

5030

J.J. Heckman and E.J. Vytlacil

While the claim is true, it ignores the counterfactual states generated under the matching assumptions. The assumed absence of selection on unobservables is not a “for free”
assumption, and produces fundamentally different counterfactual states for the same
model under matching and selection assumptions. To explore these issues in depth,
consider a nonparametric regression model more general than the linear regression
model (Q-3).
Without assumption (M-1), a nonparametric regression of Y on D conditional on X
identifies a nonparametric mean difference
OLS (X) = E(Y1 | X, D = 1) − E(Y0 | X, D = 0)
= E(Y1 − Y0 | X, D = 1)


+ E(Y0 | X, D = 1) − E(Y0 | X, D = 0) .

(8.2)

The term in braces in the second expression arises from selection on pre-treatment levels
of the outcome. OLS identifies the parameter treatment on the treated (the first term in
the second line of (8.2)) plus a bias term in braces corresponding to selection on the
levels.
The OLS estimator can be represented as a weighted average of MTE . The weight is
given in Table 2B where U1 and U0 for the OLS model are defined as deviations from
conditional expectations, U1 = Y1 − E(Y1 | X), U0 = Y0 − E(Y0 | X). Unlike the
weights for TT and ATE , the OLS weights do not necessarily integrate to one and
they are not necessarily nonnegative. Application of IV eliminates the contribution of
the second term of Equation (8.2). The weights for the first term are the same as the
weights for TT and hence they integrate to one.
The OLS weights for our generalized Roy model example are plotted in Figure 2B.
The negative component of the OLS weight leads to a smaller OLS treatment estimate
compared to the other treatment effects in Table 3. This table shows the estimated OLS
treatment effect for the generalized Roy example. The large negative selection bias in
this example is consistent with comparative advantage as emphasized by Roy (1951)
and detected empirically by Willis and Rosen (1979) and Cunha, Heckman and Navarro
(2005). People who are good in sector 1 (i.e., receive treatment) may be very poor in
sector 0 (those who receive no treatment). Hence the bias in OLS for the parameter
treatment on the treated may be negative (E(Y0 | X, D = 1) − E(Y0 | X, D = 0) < 0).
The differences among the policy relevant treatment effects, the conventional treatment
effects and the OLS estimand are illustrated in Figure 4A and Table 3 for the generalized Roy model example. As is evident from Table 3, it is not at all clear that the
instrumental variable estimator, with instruments that satisfy classical properties, performs better than nonparametric OLS in identifying the policy relevant treatment effect
in this example. While IV eliminates the term in braces in (8.2), it reweights the MTE
differently from what might be desired for many policy analyses.
If there is no selection on unobserved variables conditional on covariates, UD ⊥
⊥
(Y0 , Y1 ) | X, then E(U1 | X, UD ) = E(U1 | X) = 0 and E(U0 | X, UD ) = E(U0 |
X) = 0 so that the OLS weights are unity and OLS identifies both ATE and the parameter treatment on the treated (TT), which are the same under this assumption. This

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5031

condition is an implication of matching condition (M-1). Given the assumed conditional independence in terms of X, we can identify ATE and TT without use of any
instrument Z satisfying assumptions (A-1)–(A.2). If there is such a Z, the conditional
independence condition implies under (A-1)–(A-5) that E(Y | X, P (Z) = p) is linear
in p. The conditional independence assumption invoked in the method of matching has
come into widespread use for much the same reason that OLS has come into widespread
use. It is easy to implement with modern software and makes little demands of the data
because it assumes the existence of X variables that satisfy the conditional independence assumptions. The crucial conditional independence assumption is not testable.
As we note below, additional assumptions on the X are required to test the validity of
the matching assumptions.
If the sole interest is to identify treatment on the treated, TT , it is apparent from
representation (8.2) that we can weaken (M-1) to
⊥ D | X.
(M-1) Y0 ⊥
This is possible because E(Y1 | X, D = 1) is known from data on outcomes of the
treated and only need to construct E(Y0 | X, D = 1). In this case, MTE is not restricted
to be flat in uD and all treatment parameters are not the same. A straightforward implication of (M-1) in the Roy model, where selection is made solely on the gain, is
that persons must sort into treatment status positively in terms of levels of Y1 . We now
consider more generally the implications of assuming mean independence of the errors
rather than full independence.
8.2. Matching and MTE using mean independence conditions
To identify all mean treatment parameters, one can weaken the assumption (M-1) to
the condition that Y0 and Y1 are mean independent of D conditional on X. However,
(Y0 , Y1 ) will be mean independent of D conditional on X without UD being independent
of Y0 , Y1 conditional on X only if fortuitous balancing occurs, with regions of positive
dependence of (Y0 , Y1 ) on UD and regions of negative dependence of (Y0 , Y1 ) on UD
just exactly offsetting each other. Such a balancing is not generic in the Roy model and
in the generalized Roy model.
In particular, assume that Yj = μj (X) + Uj for j = 0, 1 and further assume that
⊥ (X, Z).
D = 1[Y1 −Y0  C(Z)+UC ]. Let V = UC −(U1 −U0 ). Assume (U0 , U1 , V ) ⊥
Then if V ⊥
⊥ (U1 − U0 ), and UC has a log concave density, then E(Y1 − Y0 | X, V = v)
is decreasing in v, TT (x) > ATE (x), and the matching conditions do not hold. If
V⊥
⊥ (U1 − U0 ) but V does not have a log concave density, then it is still the case that
(U1 − U0 , V ) is negative quadrant dependent. One can show that (U1 − U0 , V ) being
negative quadrant dependent implies that TT (x) > ATE (x), and thus again that the
matching conditions cannot hold. We now develop a more general analysis.
Suppose that we assume selection model (3.3) so that D = 1[P (Z)  UD ],
where Z is independent of (Y0 , Y1 ) conditional on X, where UD = FV |X (V ) and

5032

J.J. Heckman and E.J. Vytlacil

P (Z) = FV |X (μD (Z)). Consider the weaker mean independence assumptions in place
of assumption (M-1):
(M-3) E(Y1 | X, D) = E(Y1 | X), E(Y0 | X, D) = E(Y0 | X).
This assumption is all that is needed to identify the mean treatment parameters because
under it
E(Y | X = x, Z = z, D = 1) = E(Y1 | X = x, Z = z, D = 1) = E(Y1 | X = x)
and
E(Y | X = x, Z = z, D = 0) = E(Y0 | X = x, Z = z, D = 0) = E(Y0 | X = x).
Thus we can identify all the mean treatment parameters over the support that satisfies (M-2).
Recalling that  = Y1 − Y0 , (M-3) implies in terms of UD that


E  X = x, Z = z, UD  P (z) = E( | X = x)


⇐⇒ E MTE (X, UD ) X = x, UD  P (z) = E( | X = x),
and hence


E MTE (X, UD ) X = x, UD  P (z)


= E MTE (X, UD ) X = x, UD > P (z) .
If the support of P (Z) is the full unit interval conditional on X = x, then
MTE (X, UD ) = E( | X = x) for all UD . If the support of P (Z) is a proper subset of the full unit interval, then generically (M-3) will hold only if MTE (X, UD ) =
E( | X = x) for all UD , though positive and negative parts could balance out for any
particular value of X.
To see this, note that
 


EZ E MTE (X, UD ) X = x, UD  P (z) X = x, D = 1
 


= EZ E MTE (X, UD ) X = x, UD > P (z) X = x, D = 0 .
Working with V = FV−1
|X (UD ), suppose that D = 1[μD (Z, V )  0]. Let Ω(z) =
{v: μD (z, v)  0}. Then (M-3) implies that




c 
E MTE (X, V ) X = x, V ∈ Ω(z) = E MTE (X, V ) X = x, V ∈ Ω(z)
so we expect that generically under assumption (M-3) we obtain a flat MTE in terms of
V = FV−1
|X (UD ). We conduct a parallel analysis for the nonseparable choice model in
Appendix K and obtain similar conditions. Matching assumes a flat MTE, i.e., that marginal returns conditional on X and V do not depend on V (alternatively, that marginal
returns do not depend on UD given X).
We already noted in Section 2 that IV and matching invoke very different assumptions. Matching requires no exclusion restrictions whereas IV is based on the existence

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5033

of exclusion restrictions. Superficially, we can bridge these literatures by invoking
matching with an exclusion condition: (Y0 , Y1 ) ⊥

⊥ D | X but (Y0 , Y1 ) ⊥
⊥ D | X, Z.
This looks like an IV condition, but it is not.
We explore the relationship between matching with exclusion and IV in Appendix L,
and demonstrate a fundamental contradiction between the two identifying conditions.
For an additively separable representation of the outcome equations U1 = Y1 − E(Y1 |
X) and U0 = Y0 − E(Y0 | X), we establish that if (U0 , U1 ) is mean independent of D
conditional on (X, Z), as required by IV, but (U0 , U1 ) is not mean independent of D
conditional on X alone, then U0 is dependent on Z conditional on X, contrary to all
assumptions used to justify instrumental variables. We next consider how to implement
matching.
8.3. Implementing the method of matching
We draw on Heckman et al. (1998) and Heckman, LaLonde and Smith (1999) to describe the mechanics of matching. Todd (2007, 2008) presents a comprehensive treatment of the main issues and a guide to software.
To operationalize the method of matching, we assume two samples: “t” for treatment
and “c” for comparison group. Treatment group members have D = 1 and control
group members have D = 0. Unless otherwise noted, we assume that observations are
statistically independent within and across groups. Simple matching methods are based
on the following idea. For each person i in the treatment group, we find some group of
“comparable” persons. The same individual may be in both treated and control groups
if that person is treated at one time and untreated at another. We denote outcomes for
person i in the treatment group by Yit and we match these outcomes to the outcomes
of a subsample of persons in the comparison group to estimate a treatment effect. In
principle, we can use a different subsample as a comparison group for each person.
In practice, we can construct matches on the basis of a neighborhood ξ(Xi ), where
Xi is a vector of characteristics for person i. Neighbors to treated person i are persons in
the comparison sample whose characteristics are in neighborhood ξ(Xi ). Suppose that
there are Nc persons in the comparison sample and Nt in the treatment sample. Thus
the persons in the comparison sample who are neighbors to i, are persons j for whom
Xj ∈ ξ(Xi ), i.e., the set of persons Ai = {j | Xj ∈ ξ(Xi )}. Let W (i, j ) be the weight
placed on observation j in forming a comparison with observation i and further assume
 c
that the weights sum to one, N
j =1 W (i, j ) = 1, and that 0  W (i, j )  1. Form a
weighted comparison group mean for person i, given by
Ȳic =

Nc


W (i, j )Yjc .

(8.3)

j =1

The estimated treatment effect for person i is Yi − Ȳic . This selects a set of comparison
group members associated with i and the mean of their outcomes. Unlike IV or the

5034

J.J. Heckman and E.J. Vytlacil

control function approach, the method of matching identifies counterfactuals for each
treated member.
Heckman, Ichimura and Todd (1997) and Heckman, LaLonde and Smith (1999) survey a variety of alternative matching schemes proposed in the literature. Todd (2007,
2008) provides a comprehensive survey. In this chapter, we briefly consider two widelyused methods. The nearest neighbor matching estimator defines Ai such that only one j
is selected so that it is closest to Xi in some metric:

*
Ai = j | min Xi − Xj  ,
j ∈{1,...,Nc }

where “ ” is a metric measuring distance in the X characteristics space. The Mahalanobis metric is one widely used metric for implementing the nearest neighbor
matching estimator. This metric defines neighborhoods for i as
  = (Xi − Xj ) Σc−1 (Xi − Xj ),
where Σc is the covariance matrix in the comparison sample. The weighting scheme for
the nearest neighbor matching estimator is

1 if j ∈ Ai ,
W (i, j ) =
0 otherwise.
The nearest neighbor in the metric “ · ” is used in the match. A version of nearest neighbor matching, called “caliper” matching [Cochran and Rubin (1973)], makes
matches to person i only if
Xi − Xj  < ε,
where ε is a pre-specified tolerance. Otherwise, person i is bypassed and no match is
made to him or her.
Kernel matching uses the entire comparison sample, so that Ai = {1, . . . , Nc }, and
sets
K(Xj − Xi )
,
W (i, j ) = N
c
j =1 K(Xj − Xi )
where K is a kernel.127 Kernel matching is a smooth method that reuses and weights
the comparison group sample observations differently for each person i in the treatment
group with a different Xi . Kernel matching can be defined pointwise at each sample
point Xi or for broader intervals.
For example, the impact of treatment on the treated can be estimated by forming the
mean difference across the i:


Nt
Nt
Nc



 t

1
1
TT
c
t
c
ˆ =

(8.4)
Yi − Ȳi =
W (i, j )Yj .
Yi −
Nt
Nt
i=1

i=1

j =1

127 See, e.g., Härdle (1990) or Ichimura and Todd (2007) (Chapter 74 of this Handbook) for a discussion of
kernels and choices of bandwidths.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5035

We can define this mean for various subsets of the treatment sample defined in various
ways. More efficient estimators weight the observations accounting for the variance
[Heckman, Ichimura and Todd (1997, 1998), Heckman (1998), Hirano, Imbens and
Ridder (2003), Abadie and Imbens (2006)].128
Matching assumes that conditioning on X eliminates selection bias. The method requires no functional form assumptions for outcome equations. If, however, a functional
form assumption is maintained, as in the econometric procedure proposed by Barnow,
Cain and Goldberger (1980), it is possible to implement the matching assumption using standard regression analysis. Suppose, for example, that Y0 is linearly related to
observables X and an unobservable U0 , so that
E(Y0 | X, D = 0) = Xα + E(U0 | X, D = 0),
and
E(U0 | X, D = 0) = E(U0 | X)
is linear in X (E(U | X) = ϕX). Under these assumptions, controlling for X via linear
regression allows one to identify E(Y0 | X, D = 1) from the data on nonparticipants.
Under assumption (Q-4) , setting X = Q, this approach justifies OLS equation (Q-3) for
identifying treatment effects.129 Such functional form assumptions are not strictly required to implement the method of matching. Moreover, in practice, users of the method
of Barnow, Cain and Goldberger (1980) do not impose the common support condition (M-2) for the distribution of X when generating estimates of the treatment effect.
The distribution of X may be very different in the treatment group (D = 1) and comparison group (D = 0) samples, so that comparability is only achieved by imposing
linearity in the parameters and extrapolating over different regions.
One advantage of the method of Barnow, Cain and Goldberger (1980) is that it uses
data parsimoniously. If the X are high-dimensional, the number of observations in each
cell when matching can get very small.
Another solution to this problem that reduces the dimension of the matching problem
without imposing arbitrary linearity assumptions is based on the probability of participation or the “propensity score”, P (X) = Pr(D = 1 | X). Rosenbaum and Rubin
(1983) demonstrate that under assumptions (M-1) and (M-2),
(Y0 , Y1 ) ⊥
⊥ D | P (X) for X ∈ χc ,

(8.5)

for some set χc , where it is assumed that (M-2) holds in the set. Conditioning either on
P (X) or on X produces conditional independence.130
128 Regression-adjusted matching, proposed by Rubin (1979) and clarified in Heckman, Ichimura and Todd

(1997, 1998), uses regression-adjusted Yi , denoted by τ (Yi ) = Yi − Xi α, in place of Yi in the preceding
calculations. See the cited papers for the econometric details of the procedure.
129 In Equation (Q-3), this approach shows that α combines the effect of Q on U with the causal effect of Q
0
on Y .
130 Their analysis is generalized to a multiple treatment setting in Lechner (2001) and Imbens (2003).

5036

J.J. Heckman and E.J. Vytlacil

Conditioning on P (X) reduces the dimension of the matching problem down to
matching on the scalar P (X). The analysis of Rosenbaum and Rubin (1983) assumes
that P (X) is known rather than estimated. Heckman, Ichimura and Todd (1998), Hahn
(1998), and Hirano, Imbens and Ridder (2003) present the asymptotic distribution theory for the kernel matching estimator in the cases in which P (X) is known and in which
it is estimated both parametrically and nonparametrically.
Conditioning on P identifies all treatment parameters but as we have seen, it imposes the assumption of a flat MTE. Marginal returns and average returns are the same.
A consequence of (8.5) is that






E Y1 D = 0, P (X) = E Y1 D = 1, P (X) = E Y1 P (X) ,






E Y0 D = 1, P (X) = E Y0 D = 0, P (X) = E Y0 P (X) .
Support condition (M-2) has the unattractive feature that if the analyst has too much
information about the decision of who takes treatment, so that P (X) = 1 or 0, the
method breaks down at such values of X because people cannot be compared at a
common X. The method of matching assumes that, given X, some unspecified randomization in the economic environment allocates people to treatment. This justifies
assumption (Q-5) in the OLS example. The fact that the cases P (X) = 1 and P (X) = 0
must be eliminated suggests that methods for choosing X based on the fit of the model
to data on D are potentially problematic, as we discuss below.
Offsetting these disadvantages, the method of matching with a known conditioning
set that produces condition (M-2) does not require separability of outcome or choice
equations, exogeneity of conditioning variables, exclusion restrictions, or adoption of
specific functional forms of outcome equations. Such features are commonly used in
conventional selection (control function) methods and conventional applications of IV
although as we have demonstrated in Section 4, recent work in semiparametric estimation relaxes these assumptions. As noted in Section 8.2, the method of matching does
not strictly require (M-1). One can get by with weaker mean independence assumptions (M-3) in the place of the stronger conditions (M-1). However, if (M-3) is invoked,
the assumption that one can replace X by P (X) does not follow from the analysis of
Rosenbaum and Rubin (1983), and is an additional new assumption.
Methods for implementing matching are provided in Heckman et al. (1998) and are
discussed extensively in Heckman, LaLonde and Smith (1999). See Todd (1999, 2007,
2008) for software and extensive discussion of the mechanics of matching. We now
contrast the identifying assumptions used in the method of control functions with those
used in matching.
8.3.1. Comparing matching and control functions approaches

⊥
The method of matching eliminates the dependence between (Y0 , Y1 ) and D, (Y0 , Y1 ) ⊥
D, by assuming access to conditioning variables X such that (M-1) is satisfied:
⊥ D | X. By conditioning on observables, one can identify the distributions
(Y0 , Y1 ) ⊥
of Y0 and Y1 over the support of X satisfying (M-2).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5037

Other methods model the dependence that gives rise to the spurious relationship and
in this way attempt to eliminate it. IV involves exclusion and a different type of conditional independence, (Y0 , Y1 ) ⊥
⊥ Z | X, as well as a rank condition (Pr(D = 1 | X, Z)
depends on Z). The instrument Z plays the role of the implicit randomization used
in matching by allocating people to treatment status in a way that does not depend on
(Y0 , Y1 ). We have already established that matching and IV make very different assumptions. Thus, in general, a matching assumption that (Y0 , Y1 ) ⊥
⊥ D | X, Z neither implies
nor is implied by (Y0 , Y1 ) ⊥
⊥ Z | X. One special case where they are equivalent is when
treatment status is assigned by randomization with full compliance (letting ξ = 1 denote assignment to treatment, ξ = 1 ⇒ A = 1 and ξ = 0 ⇒ A = 0) and Z = ξ , so
that the instrument is the assignment mechanism. A = 1 if the person actually receives
treatment, and A = 0 otherwise.
The method of control functions explicitly models the dependence between (Y0 , Y1 )
and D and attempts to eliminate it. Chapter 73 (Matzkin) of this Handbook provides
a comprehensive review of these methods. In Section 11, we present a summary of
some of the general principles underlying the method of control functions, the method
of control variates, replacement functions, and proxy approaches as they apply to the
selection problem. All of these methods attempt to eliminate the θ in (U-1) that produces
the dependence captured in (U-2).
In this section, we relate matching to the form of the control function introduced in
Heckman (1980) and Heckman and Robb (1985a, 1986a). This version was used in our
analysis of local instrumental variables (LIV) in Section 4, where we compare LIV with
control function approaches and show that LIV and LATE estimate derivatives of the
control functions. We analyze conditional means because of their familiarity. Using the
fact that E(1(Y  y) | X) = F (y | X), the analysis applies to marginal distributions as
well.
Thus we work with conditional expectations of (Y0 , Y1 ) given (X, Z, D), where Z
is assumed to include at least one variable not in X. Conventional applications of the
control function method assume additive separability, which is not required in matching. Strictly speaking, additive separability is not required in the application of control
functions either.131 What is required is a model relating the outcome unobservables
to the observables and the unobservables in the choice of treatment equation. Various
assumptions give operational content to (U-1) defined in Section 2.
For the additively separable case (2.2), the control function for mean outcomes models the conditional expectations of Y1 and Y0 given X, Z, and D as
E(Y1 | Z, X, D = 1) = μ1 (X) + E(U1 | Z, X, D = 1),
E(Y0 | Z, X, D = 0) = μ0 (X) + E(U0 | Z, X, D = 0).

131 Examples of nonseparable selection models are found in Cameron and Heckman (1998). See also Altonji
and Matzkin (2005) and Chapter 73 (Matzkin) of this Handbook.

5038

J.J. Heckman and E.J. Vytlacil

In the traditional method of control functions, the analyst models E(U1 | Z, X,
D = 1) and E(U0 | Z, X, D = 0). If these functions can be independently varied
against μ1 (X) and μ0 (X), respectively, one can identify μ1 (X) and μ0 (X) up to constant terms.132 It is not required that X or Z be stochastically independent of U1 or U0 ,
although conventional methods often assume this.
⊥ (X, Z) and adopt Equation (3.3) as the treatment choice
Assume that (U0 , U1 , V ) ⊥
model augmented so that X and Z are determinants of treatment choice, using V as the
latent variable that generates D given X, Z: D = 1(μD (Z)  0). Let UD = FV |X (V )
and P (Z) = FV |X (μD (Z)). In this notation, the control functions are


E(U1 | Z, D = 1) = E U1 μD (Z)  V




= E U1 P (Z)  UD = K1 P (Z) and


E(U0 | Z, D = 0) = E U0 μD (Z) < V




= E U0 P (Z) < UD = K0 P (Z) ,
so the control function only depends on the propensity score P (Z). The key assumption
needed to represent the control function solely as a function of P (Z) is
⊥ X, Z.
(CF-1) (U0 , U1 , V ) ⊥
This assumption is not strictly required but it is traditional and useful in relating LIV
and selection models (as in Section 4) and selection models and matching (this section).
Under this condition


E(Y1 | Z, X, D = 1) = μ1 (X) + K1 P (Z) ,


E(Y0 | Z, X, D = 0) = μ0 (X) + K0 P (Z) ,
with limP →1 K1 (P ) = 0 and limP →0 K0 (P ) = 0. It is assumed that Z can be independently varied for all X, and the limits are obtained by changing Z while holding X
fixed.133 These limit results state that when the values of X, Z are such that the probability of being in a sample (D = 1 or D = 0, respectively) is 1, there is no selection
bias and one can separate out μ1 (X) from K1 (P (Z)) and μ0 (X) from K0 (P (Z)). This
is the same identification at infinity condition that is required to identify ATE and TT in
IV for models with heterogeneous responses.134 ,135
132 Heckman and Robb (1985a, 1986a) introduce this general formulation of control functions. The identifiability requires that the members of the pairs (μ1 (X), E(U1 | X, Z, D = 1)) and (μ0 (X), E(U0 |
X, Z, D = 0)) be variation-free so that they can be independently varied against each other.
133 More precisely, we assume that Supp(Z | X) = Supp(Z) and that limit sets of Z, Z , and Z exist so
0
1
that as Z → Z0 , P (Z, X) → 0, and as Z → Z1 , P (Z, X) → 1.
134 As noted in our discussion in Section 4, we need identification at infinity to obtain ATE and TT. This is a
feature of any evaluation model with general heterogeneity.
135 One can approximate the K (P ) and K (P ) terms by polynomials in P [see Heckman (1980), Heckman
1
0
and Robb (1985a, 1986a), Heckman and Hotz (1989)]. Ahn and Powell (1993) and Powell (1994) develop
methods for eliminating K1 (P (Z)) and K0 (P (Z)) by differencing.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5039

As noted in Section 4, unlike the method of matching based on (M-1), the method of
control functions allows the marginal treatment effect to be different from the average
treatment effect and from the conditional effect of treatment on the treated. Although
conventional practice has been to derive the functional forms of K0 (P ) and K1 (P ) by
making distributional assumptions about (U0 , U1 , V ) such as normality or other conventional distributional assumptions, this is not an intrinsic feature of the method and
there are many nonnormal and semiparametric versions of this method. See Powell
(1994) for a survey.
In its semiparametric implementation, the method of control functions requires an exclusion restriction (a variable in Z not in X) to achieve nonparametric identification.136
Without any functional form assumptions one cannot rule out a worst case analysis
where, for example, if X = Z, then K1 (P (X)) = τ μ(X) where τ is a scalar. In this
situation, there is perfect collinearity between the control function and the conditional
mean of the outcome equation, and it is impossible to separately identify either.137 Even
though this case is not generic, it is possible. The method of matching does not require an exclusion restriction, but at the cost of ruling out essential heterogeneity. In
the general case, the method of control functions requires that in certain limit sets of Z,
P (Z) = 1 and P (Z) = 0 in order to achieve full nonparametric identification.138 The
conventional method of matching does not invoke such limit set arguments.
All methods of evaluation, including matching and control functions, require that
treatment parameters be defined on a common support that is the intersection of the
supports of X given D = 1 and X given D = 0: Supp(X | D = 1) ∩ Supp(X | D = 0).
This is the requirement for any estimator that seeks to identify treatment effects by
comparing samples of treated persons with samples of untreated persons.
In this version of the method of control functions, P (Z) is a conditioning variable
used to predict U1 conditional on D and U0 conditional on D. In the method of matching, it is used as a conditioning variable to eliminate the stochastic dependence between
(U0 , U1 ) and D. In the method of LATE or LIV, P (Z) is used as an instrument. In the
⊥ (X, Z), but this asmethod of control functions, as conventionally applied, (U0 , U1 ) ⊥
sumption is not intrinsic to the method.139 This assumption plays no role in matching if
the correct conditioning set is known.140 However, as noted below, exogeneity plays a
key role in devising algorithms to select the conditioning variables. In addition, as noted
in Section 6, exogeneity is helpful in making out-of-sample forecasts. The method of
⊥ D | (X, Z), which is a central recontrol functions does not require that (U0 , U1 ) ⊥
quirement of matching. Equivalently, the method of control functions does not require
⊥ V | (X, Z),
(U0 , U1 ) ⊥

or that (U0 , U1 ) ⊥
⊥ V | X,

136 No exclusion is required for many common functional forms for the distributions of unobservables.
137 Clearly K (P (X)) and μ(X) cannot be independently varied in this case.
1
138 Symmetry of the errors can be used in place of the appeal to limit sets that put P (Z) = 0 or P (Z) = 1.

See Chen (1999).
139 Relaxing it, however, requires that the analyst model the dependence of the unobservables on the observables and that certain variation-free conditions are satisfied. [See Heckman and Robb (1985a).]
140 That is, a conditioning set that satisfies (M-1) and (M-2).

5040

J.J. Heckman and E.J. Vytlacil

whereas matching does and typically equates X and Z. Thus matching assumes access
to a richer set of conditioning variables than is assumed in the method of control functions.
The method of control functions allows for outcome unobservables to be dependent
on D even after conditioning on (X, Z), and it models this dependence. The method of
matching assumes no such D dependence. Thus in this regard, and maintaining all of
the assumptions invoked for control functions in this section, matching is a special case
of the method of control functions141 in which under assumptions (M-1) and (M-2),
E(U1 | X, D = 1) = E(U1 | X),
E(U0 | X, D = 0) = E(U0 | X).
In the method of control functions, in the case where (X, Z) ⊥
⊥ (U0 , U1 , V ), where
the Z can include some or all of the elements of X, the conditional expectation of Y
given X, Z, D is
E(Y | X, Z, D) = E(Y1 | X, Z, D = 1)D + E(Y0 | X, Z, D = 0)(1 − D)


= μ0 (X) + μ1 (X) − μ0 (X) D




+ E U1 P (Z), D = 1 D + E U0 P (Z), D = 0 (1 − D)


= μ0 (X) + K0 P (Z)





+ μ1 (X) − μ0 (X) + K1 P (Z) − K0 P (Z) D.
(8.6)
The coefficient on D in the final equation combines μ1 (X) − μ0 (X) with K1 (P (Z)) −
K0 (P (Z)). It does not correspond to any treatment effect. To identify μ1 (X) − μ0 (X),
one must isolate it from K1 (P (Z)) − K0 (P (Z)).
Under assumptions (M-1) and (M-2) of the method of matching, the conditional expectation of Y conditional on P (X) and D is






E Y P (X), D = μ0 P (X) + E U0 P (X)
 



+ μ1 P (X) − μ0 P (X)




+ E U1 P (X) − E U0 P (X) D.
(8.7)
The coefficient on D in this expression is now interpretable and is the average treatment
effect. If we assume that (U0 , U1 ) ⊥
⊥ X, which is not strictly required, we reach a more
familiar representation

  





E Y P (X), D = μ0 P (X) + μ1 P (X) − μ0 P (X) D,
(8.8)

141 See Aakvik, Heckman and Vytlacil (2005), Carneiro, Hansen and Heckman (2003) and Cunha, Heckman
and Navarro (2005) for a generalization of matching that allows for selection on unobservables by imposing
a factor structure on the errors and estimating the distribution of the unobserved factors. These methods are
discussed in Abbring and Heckman (Chapter 72).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5041

since E(U1 | P (X)) = E(U0 | P (X)) = 0. A parallel derivation can be made conditioning on X instead of P (X).
Under the assumptions that justify matching, treatment effects ATE or TT (conditional on P (X)) are identified from the coefficient on D in either (8.7) or (8.8).
Condition (M-2) guarantees that D is not perfectly predictable by X (or P (X)), so
the variation in D identifies the treatment parameter.
The coefficient on D in Equation (8.6) for the more general control function model
does not correspond to any treatment parameter, whereas the coefficients on D in Equations (8.7) and (8.8) correspond to treatment parameters under the assumptions of the
matching model. Under assumption (CF-1), μ1 (P (X)) − μ0 (P (X)) = ATE and ATE
= TT = MTE, so the method of matching identifies all of the (conditional on P (X))
mean treatment parameters.142
Under the assumptions justifying matching, when means of Y1 and Y0 are the parameters of interest, and X satisfies (M-1) and (M-2), the bias terms vanish. They do
not vanish in the more general case considered by the method of control functions.
This is the mathematical counterpart of the randomization implicit in matching: conditional on X or P (X), (U0 , U1 ) are random with respect to D. The method of control
functions allows these error terms to be nonrandom with respect to D and models the
dependence. In the absence of functional form assumptions, it requires an exclusion restriction (a variable in Z not in X) to separate out K0 (P (Z)) from the coefficient on D.
Matching produces identification without exclusion restrictions whereas identification
with exclusion restrictions is a central feature of the control function method in the
absence of functional form assumptions.
The fact that the control function approach allows for more general dependencies
among the unobservables and the conditioning variables than the matching approach
allows is implicitly recognized in the work of Rosenbaum (1995) and Robins (1997).
Their “sensitivity analyses” for matching when there are unobserved conditioning variables are, in their essence, sensitivity analyses using control functions.143 Aakvik,
Heckman and Vytlacil (2005), Carneiro, Hansen and Heckman (2003) and Cunha,
Heckman and Navarro (2005) explicitly model the relationship between matching and
selection models using factor structure models, treating the omitted conditioning variables as unobserved factors and estimating their distribution. Abbring and Heckman
discuss this work in Chapter 72.

142 This result also holds even if (CF-1) is not satisfied because (U , U ) ⊥
⊥ X. In this case, the treatment
0 1 
effects include the term





E U1 P (X) − E U0 P (X) .
143 See also Vijverberg (1993) who does such a sensitivity analysis in a parametric selection model with an
unidentified parameter.

5042

J.J. Heckman and E.J. Vytlacil

8.4. Comparing matching and classical control function methods for a generalized
Roy model
Figure 10, developed in connection with our discussion of instrumental variables, shows
the contrast between the shape of the MTE and the OLS matching estimand as a function of p for the extended Roy model developed in Section 4. The MTE(p) shows its
typical declining shape associated with diminishing returns, and the assumptions justifying matching are violated. Matching attempts to impose a flat MTE(p) and therefore
flattens the estimated MTE(p) compared to its true value. It understates marginal returns at low levels of p (associated with unobservables that make it likely to participate
in treatment) and overstates marginal returns at high levels of p.
To further illustrate the bias in matching and how the control function eliminates it,
we perform sensitivity analyses under different assumptions about the parameters of the
underlying selection model. In particular, we assume that the data are generated by the
model of Equations (3.1) and (3.2), where μD (Z) = Zγ , μ0 (X) = μ0 , μ1 (X) = μ1 ,
and
(U0 , U1 , V ) ∼ N (0, Σ),
corr(Uj , V ) = ρj V ,
Var(Uj ) = σj2 ,

j = {0, 1}.

We assume in this section that D = 1[μD (Z) + V  0], in conformity with the
examples presented in Heckman and Navarro (2004), from which we draw. This reformulation of choice model (3.3) simply entails a change in the sign of V . We assume that
Z⊥
⊥ (U0 , U1 , V ). Using the selection formulae derived in Appendix M, we can write
the biases conditional on P (Z) = p using propensity score matching in a generalized
Roy model as


Bias TT(Z = z) = Bias TT P (Z) = p = σ0 ρ0V M(p),




Bias ATE(Z = z) = Bias ATE P (Z) = p = M(p) σ1 ρ1V (1 − p) + σ0 ρ0V p ,
−1

(1−p))
, φ(·) and Φ(·) are the pdf and cdf of a standard normal
where M(p) = φ(Φp(1−p)
random variable and the propensity score P (z) is evaluated at P (z) = p. We assume
that μ1 = μ0 so that the true average treatment effect is zero.
We simulate the mean bias for TT (Table 10) and ATE (Table 11) for different values of the ρj V and σj . The results in the tables show that, as we let the variances of
the outcome equations grow, the value of the mean bias that we obtain can become
substantial. With larger correlations between the outcomes and the unobservables generating choices, come larger biases. These tables demonstrate the greater generality of the
control function approach, which models the bias rather than assuming it away by conditioning. Even if the correlation between the observables and the unobservables (ρj V ) is
small, so that one might think that selection on unobservables is relatively unimportant,
we still obtain substantial biases if we do not control for relevant omitted conditioning variables. Only for special values of the parameters do we avoid bias by matching.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5043

Table 10
Mean bias for treatment on the treated
ρ0V

Average bias (σ0 = 1)

Average bias (σ0 = 2)

−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00

−1.7920
−1.3440
−0.8960
−0.4480
0.0000
0.4480
0.8960
1.3440
1.7920

−3.5839
−2.6879
−1.7920
−0.8960
0.0000
0.8960
1.7920
2.6879
3.5839

Bias TT = ρ0V ∗ σ0 ∗ M(p).
−1 (1−p))
M(p) = φ(Φp(1−p)
.

Source: Heckman and Navarro (2004).

These examples also demonstrate that sensitivity analyses can be conducted for analysis
based on control function methods even when they are not fully identified. Vijverberg
(1993) provides an example.
8.5. The informational requirements of matching and the bias when they are not
satisfied
In this section, we present some examples of when matching “works” and when it breaks
down. This section is based on Heckman and Navarro (2004). In particular, we show
how matching on some of the relevant information but not all can make the bias using
matching worse for standard treatment parameters. These examples also introduce factor models that play a key role in the analysis of Abbring and Heckman in Chapter 72.
Section 2 of this chapter discussed informational asymmetries between the econometrician and the agents whose behavior they are analyzing. The method of matching
assumes that the econometrician has access to and uses all of the relevant information
in the precise sense defined there. That means that the X that guarantees conditional
independence (M-1) is available and is used. The concept of relevant information is a
delicate one and it is difficult to find the true conditioning set.
Assume that the economic model generating the data is a generalized Roy model of
the form
D ∗ = Zγ + V ,
Z⊥
⊥V

where

and

V = αV 1 f1 + αV 2 f2 + εV ,

5044

J.J. Heckman and E.J. Vytlacil
Table 11
Mean bias for average treatment effect
(σ0 = 1)
−1.00

ρ0V

−0.75

−0.50

−0.25

0

0.25

0.50

0.75

1.00

−0.6720
−0.4480
−0.2240
0
0.2240
0.4480
0.6720
0.8960
1.1200

−0.4480
−0.2240
0
0.2240
0.4480
0.6720
0.8960
1.1200
1.3440

−0.2240
0
0.2240
0.4480
0.6720
0.8960
1.1200
1.3440
1.5680

0
0.2240
0.4480
0.6720
0.8960
1.1200
1.3440
1.5680
1.7920

−0.4480
−0.2240
0
0.2240
0.4480
0.6720
0.8960
1.1200
1.3440

0
0.2240
0.4480
0.6720
0.8960
1.1200
1.3440
1.5680
1.7920

0.4480
0.6720
0.8960
1.1200
1.3440
1.5680
1.7920
2.0159
2.2399

0.8960
1.1200
1.3440
1.5680
1.7920
2.0159
2.2399
2.4639
2.6879

ρ1V (σ1 = 1)
−1.00
−0.75
−0.50
−0.25
0
0.25
0.50
0.75
1.00

−1.7920
−1.5680
−1.3440
−1.1200
−0.8960
−0.6720
−0.4480
−0.2240
0

−1.5680
−1.3440
−1.1200
−0.8960
−0.6720
−0.4480
−0.2240
0
0.2240

−1.3440
−1.1200
−0.8960
−0.6720
−0.4480
−0.2240
0
0.2240
0.4480

−1.1200
−0.8960
−0.6720
−0.4480
−0.2240
0
0.2240
0.4480
0.6720

−0.8960
−0.6720
−0.4480
−0.2240
0
0.2240
0.4480
0.6720
0.8960

ρ1V (σ1 = 2)
−1.00
−0.75
−0.50
−0.25
0
0.25
0.50
0.75
1.00

−2.6879
−2.4639
−2.2399
−2.0159
−1.7920
−1.5680
−1.3440
−1.1200
−0.8960

−2.2399
−2.0159
−1.7920
−1.5680
−1.3440
−1.1200
−0.8960
−0.6720
−0.4480

−1.7920
−1.5680
−1.3440
−1.1200
−0.8960
−0.6720
−0.4480
−0.2240
0

−1.3440
−1.1200
−0.8960
−0.6720
−0.4480
−0.2240
0
0.2240
0.4480

−0.8960
−0.6720
−0.4480
−0.2240
0
0.2240
0.4480
0.6720
0.8960

BIAS ATE = ρ1V ∗ σ1 ∗ M1 (p) − ρ0V ∗ σ0 ∗ M0 (p).
−1
M1 (p) = φ(Φ p(1−p)) .
−1 (1−p))
.
M0 (p) = −φ(Φ(1−p)

Source: Heckman and Navarro (2004).


D=

1 if D ∗  0,
0 otherwise,

and
Y1 = μ1 + U1 ,

where U1 = α11 f1 + α12 f2 + ε1 ,

Y0 = μ0 + U0 ,

where U0 = α01 f1 + α02 f2 + ε0 .

We remind the reader that contrary to the analysis throughout the rest of this chapter we
add V and do not subtract it in the decision equation. This is the familiar representation.
By a change in sign in V , we can go back and forth between the specification used in
this section and the specification used in other sections of the chapter.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5045

In this specification, (f1 , f2 , εV , ε1 , ε0 ) are assumed to be mean zero random variables that are mutually independent of each other and Z so that all the correlation among
the elements of (U0 , U1 , V ) is captured by f = (f1 , f2 ). Models that take this form are
known as factor models and have been applied in the context of selection models by
Aakvik, Heckman and Vytlacil (2005), Carneiro, Hansen and Heckman (2001, 2003),
and Hansen, Heckman and Mullen (2004), among others. We keep implicit any dependence on X which may be general.
Generically, the minimal relevant information for this model when the factor loadings
are not zero (αij = 0) is, for general values of the factor loadings,
IR = {f1 , f2 }.144
Recall that we assume independence between Z and all error terms. If the econometrician has access to IR and uses it, (M-1) is satisfied conditional on IR . Note that IR
plays the role of θ in (U-1). In the case where the economist knows IR , the economist’s
information set σ (IE ) contains the relevant information (σ (IE ) ⊇ σ (IR )).
The agent’s information set may include different variables. If we assume that ε0 , ε1
are shocks to outcomes not known to the agent at the time treatment decisions are made,
but the agent knows all other aspects of the model, the agent’s information is
IA = {f1 , f2 , Z, εV }.
Under perfect certainty, the agent’s information set includes ε1 and ε0 :
IA = {f1 , f2 , Z, εV , ε1 , ε0 }.
In either case, all of the information available to the agent is not required to satisfy
conditional independence (M-1). All three information sets guarantee conditional independence, but only the first is minimal relevant.
In the notation of Section 2, the observing economist may know some variables not
in IA , IR ∗ or IR but may not know all of the variables in IR . In the following subsections, we study what happens when the matching assumption that σ (IE ) ⊇ σ (IR ) does
not hold. That is, we analyze what happens to the bias from matching as the amount
of information used by the econometrician is changed. In order to get closed form expressions for the biases of the treatment parameters, we make the additional assumption
that
(f1 , f2 , εV , ε1 , ε0 ) ∼ N (0, Σ),
where Σ is a matrix with (σf21 , σf22 , σε2V , σε21 , σε20 ) on the diagonal and zero in all the
nondiagonal elements. This assumption links matching models to conventional normal
selection models of the sort developed in Chapter 70 and further analyzed in Section 2 of
this chapter. However, the examples based on this specification illustrate more general
principles. We now analyze various commonly encountered cases.
144 Notice that for a fixed set of α , the minimal information set is (α − α )f + (α − α )f , which
ij
11
01 1
12
02 2
captures the dependence between D and (Y0 , Y1 ).

5046

J.J. Heckman and E.J. Vytlacil

8.5.1. The economist uses the minimal relevant information: σ (IR ) ⊆ σ (IE )
We begin by analyzing the case in which the information used by the economist is
IE = {Z, f1 , f2 }, so that the econometrician has access to a relevant information set and
it is larger than the minimal relevant information set. In this case, it is straightforward
to show that matching identifies all of the mean treatment parameters with no bias. The
matching estimator has population mean
E(Y1 | D = 1, IE ) − E(Y0 | D = 0, IE )
= μ1 − μ0 + (α11 − α01 )f1 + (α12 − α02 )f2 ,
and all of the mean treatment parameters collapse to this same expression since, conditional on knowing f1 and f2 , there is no selection because (ε0 , ε1 ) ⊥
⊥ V . Recall that for
arbitrary choices of α11 , α01 , α12 , and α02 , IR = {f1 , f2 } and the economist needs less
information to achieve (M-1) than is contained in IE .
In this case, the analysis of Rosenbaum and Rubin (1983) tells us that knowledge of
(Z, f1 , f2 ) and knowledge of P (Z, f1 , f2 ) are equally useful in identifying all of the
treatment parameters conditional on P . If we write the propensity score as


εV
−Zγ − αV 1 f1 − αV 2 f2
P (IE ) = Pr
>
σεV
σεV


−Zγ − αV 1 f1 − αV 2 f2
=1−Φ
= p,
σεV
the event (D ∗  0, given f = f˜ and Z = z) can be written as σεεV  Φ −1 (1−P (z, f˜)),
V
where Φ is the cdf of a standard normal random variable and f = (f1 , f2 ). We abuse
notation slightly by using z as the realized fixed value of Z and f˜ as the realized value
of f . The population matching condition (M-1) implies that




E Y1 D = 1, P (IE ) = P (z, f˜) − E Y0 D = 0, P (IE ) = P (z, f˜)


= μ1 − μ0 + E U1 D = 1, P (IE ) = P (z, f˜)


− E U0 D = 0, P (IE ) = P (z, f˜)




εV
= μ 1 − μ 0 + E U1
> Φ −1 1 − P (z, f˜)
σεV




εV
 Φ −1 1 − P (z, f˜)
− E U0
σεV
= μ1 − μ 0 .
This expression is equal to all of the treatment parameters discussed in this chapter,
since





Cov(U1 , εV ) 
εV
> Φ −1 1 − P (z, f˜) =
M1 P (z, f˜)
E U1
σεV
σεV

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5047

and

E U0





εV
Cov(U0 , εV ) 
−1
˜
 Φ 1 − P (z, f ) =
M0 P (z, f˜) ,
σεV
σεV

where

 φ(Φ −1 (1 − P (z, f˜)))
,
M1 P (z, f˜) =
P (z, f˜)


φ(Φ −1 (1 − P (z, f˜)))
M0 P (z, f˜) = −
,
1 − P (z, f˜)
where φ is the density of a standard normal random variable. As a consequence of the
assumptions about mutual independence of the errors
Cov(Ui , εV ) = Cov(αi1 f1 + αi2 f2 + εi , εV ) = 0,

i = 0, 1.

In the context of the generalized Roy model, the case considered in this subsection
is the one matching is designed to solve. Even though a selection model generates the
data, the fact that the information used by the econometrician includes the minimal relevant information makes matching a correct solution to the selection problem. We can
estimate the treatment parameters with no bias since, as a consequence of our assump⊥ D | (f, Z), which is exactly what matching requires. The minimal
tions, (U0 , U1 ) ⊥
relevant information set is even smaller. For arbitrary factor loadings, we only need to
know (f1 , f2 ) to secure conditional independence. We can define the propensity score
solely in terms of f1 and f2 , and the Rosenbaum–Rubin result still goes through. Our
analysis in this section focuses on treatment parameters conditional on particular values
of P (Z, f ) = P (z, f˜), i.e., for fixed values of p, but we could condition more finely.
Conditioning on P (z, f˜) defines the treatment parameters more coarsely. We can use
either fine or coarse conditioning to construct the unconditional treatment effects.
In this example, using more information than what is in the relevant information set
(i.e., using Z) is harmless. But this is not generally true. If Z ⊥

⊥ (U0 , U1 , V ), adding Z
to the conditioning set can violate conditional independence assumption (M-1):
⊥ D | (f1 , f2 ),
(Y0 , Y1 ) ⊥
but
(Y0 , Y1 ) ⊥

⊥ D | (f1 , f2 , Z).
Adding extra variables can destroy the crucial conditional independence property of
matching. We present an example of this point below. We first consider a case where
Z⊥
⊥ (U0 , U1 , V ) but the analyst conditions on Z and not (f1 , f2 ). In this case, there is
selection on the unobservables that are not conditioned on.

5048

J.J. Heckman and E.J. Vytlacil

8.5.2. The economist does not use all of the minimal relevant information
Next, suppose that the information used by the econometrician is
IE = {Z},
and there is selection on the unobservable (to the analyst) f1 and f2 , i.e., the factor
loadings αij are all nonzero. Recall that we assume that Z and the f are independent.
In this case, the event (D ∗  0, Z = z) is characterized by


αV 1 f1 + αV 2 f2 + εV
αV2 1 σf21 + αV2 2 σf22 + σε2V



 Φ −1 1 − P (z) .

Using the analysis presented in Appendix M, the bias for the different treatment parameters is given by




Bias TT(Z = z) = Bias TT P (Z) = P (z) = η0 M P (z) ,
(8.9)
where M(P (z)) = M1 (P (z)) − M0 (P (z)).


Bias ATE(Z = z) = Bias ATE P (Z) = P (z)

 


= M P (z) η1 1 − P (z) + η0 P (z) ,

(8.10)

where
αV 1 α11 σf21 + αV 2 α12 σf22
η1 = 
,
αV2 1 σf21 + αV2 2 σf22 + σε2V
αV 1 α01 σf21 + αV 2 α02 σf22
η0 = 
.
αV2 1 σf21 + αV2 2 σf22 + σε2V
It is not surprising that matching on sets of variables that exclude the relevant conditioning variables produces bias for the conditional (on P (z)) treatment parameters. The
advantage of working with a closed form expression for the bias is that it allows us to
answer questions about the magnitude of this bias under different assumptions about the
information available to the analyst, and to present some simple examples. We next use
expressions (8.9) and (8.10) as benchmarks against which to compare the relative size
of the bias when we enlarge the econometrician’s information set beyond Z.
8.5.3. Adding information to the econometrician’s information set IE : Using some but
not all the information from the minimal relevant information set IR
Suppose that the econometrician uses more information but not all of the information
in the minimal relevant information set. He still reports values of the parameters conditional on specific p values but now the model for p has different conditioning variables.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5049

For example, the data set assumed in the preceding section might be augmented or
else the econometrician decides to use information previously available. In particular,
assume that the econometrician’s information set is
IE = {Z, f2 },
and that he uses this information set. Under Conditions 1 and 2 presented below, the
biases for the treatment parameters conditional on values of P = p are reduced in
absolute value relative to their values in Section 8.5.2 by changing the conditioning
set in this way. But these conditions are not generally satisfied, so that adding extra
information does not necessarily reduce bias and may actually increase it. To show how
this happens in our model, we define expressions comparable to η1 and η0 for this case:
η1 = 

η0 = 

αV 1 α11 σf21
αV2 1 σf21 + σε2V
αV 1 α01 σf21
αV2 1 σf21 + σε2V

,

.

We compare the biases under the two cases using formulae (8.9)–(8.10), suitably modified, but keeping p fixed at a specific value even though this implies different conditioning sets in terms of (z, f˜).
C ONDITION 1. The bias produced by using matching to estimate TT is smaller in absolute value for any given p when the new information set σ (IE ) is used if
|η0 | > η0 .
There is a similar result for ATE:
C ONDITION 2. The bias produced by using matching to estimate ATE is smaller in
absolute value for any given p when the new information set σ (IE ) is used if
η1 (1 − p) + η0 p > η1 (1 − p) + η0 p .
P ROOF OF C ONDITIONS 1 AND 2. These conditions are a direct consequence of formulae (8.9) and (8.10), modified to allow for the different covariance structure produced by the information structure assumed in this section (replacing η0 with η0 , η1
with η1 ).

It is important to notice that we condition on the same value of p in deriving these
expressions although the variables in P are different across different specifications of
the model. Propensity-score matching defines them conditional on P = p, so we are
being faithful to that method.

5050

J.J. Heckman and E.J. Vytlacil

These conditions do not always hold. In general, whether or not the bias will be
reduced by adding additional conditioning variables depends on the relative importance
of the additional information in both the outcome equations and on the signs of the
terms inside the absolute value.
Consider whether Condition 1 is satisfied in general. Assume η0 > 0 for all α02 , αV 2 .
Then η0 > η0 if
αV 1 α01 σf21 + (αV2 2 )( ααV022 )σf22
αV 1 α11 σf21
>
= η0 .
η0 = 
αV2 1 σf21 + αV2 2 σf22 + σε2V
αV2 1 σf21 + σε2V
When ααV022 = 0, clearly η0 < η0 . Adding information to the conditioning set increases
bias. We can vary ( ααV022 ) holding all of the other parameters constant and hence can make
∗
the left-hand side arbitrarily large.145 As α02 increases, there is some critical value α02
beyond which η0 > η0 . If we assumed that η0 < 0, however, the opposite conclusion
would hold, and the conditions for reduction in bias would be harder to meet, as the
relative importance of the new information is increased. Similar expressions can be
derived for ATE and MTE, in which the direction of the effect depends on the signs of
the terms in the absolute value.
Figures 23A and 23B illustrate the point that adding some but not all information
from the minimal relevant set might increase the point-wise bias and the unconditional or average bias for ATE and TT, respectively.146 Values of the parameters of
the model are presented at the base of the figures. In these figures, we compare conditioning on P (z), which in general is not guaranteed to eliminate bias, with conditioning
on P (z) and f2 but not f1 . Adding f2 to the conditioning increases bias.
The fact that the point-wise (and overall) bias might increase when adding some
but not all information from IR is a feature that is not shared by the method of control
functions. Because the method of control functions models the stochastic dependence of
the unobservables in the outcome equations on the observables, changing the variables
observed by the econometrician to include f2 does not generate bias. It only changes
the control function used. That is, by adding f2 we change the control function from




K1 P (Z) = P (z) = η1 M1 P (z) ,




K0 P (Z) = P (z) = η0 M0 P (z)
to





K1 P (Z, f2 ) = P (z, f˜2 ) = η1 M1 P (z, f˜2 ) ,

145 A direct computation shows that

αV2 2 σf2
2
> 0.
α02 = 
2 σ 2 + α2 σ 2 + σ 2
∂( α )
α
εV
V2
V 1 f1
V 2 f2
∂η0

146 Heckman and Navarro (2004) show comparable plots for MTE.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5051

Figure 23A. Bias for treatment on the treated. Source: Heckman and Navarro (2004).

Note: Using proxy Z̃ for f2 increases the bias. Correlation (Z̃, f2 ) = 0.5.
Model:
V = Z + f1 + f2 + εV ;
Y1 = 2f1 + 0.1f2 + ε1 ;
εV ∼ N (0, 1);
ε1 ∼ N (0, 1);
f2 ∼ N (0, 1)
f1 ∼ N (0, 1);

Y0 = f1 + 0.1f2 + ε0
ε0 ∼ N (0, 1)

Figure 23B. Bias for average treatment effect. Source: Heckman and Navarro (2004).

5052

J.J. Heckman and E.J. Vytlacil





K0 P (Z, f2 ) = P (z, f˜2 ) = η0 M0 P (z, f˜2 )
but do not generate any bias in using the control function estimator. This is a major
advantage of this method.
It controls for the bias of the omitted conditioning variables by modeling it. Of
course, if the model for the bias term is not valid, neither is the correction for the
bias. Semiparametric selection estimators are designed to protect the analyst against
model misspecification. [See, e.g., Powell (1994).] Matching evades this problem by
assuming that the analyst always knows the correct conditioning variables and that they
satisfy (M-1). In actual empirical settings, agents rarely know the relevant information
set. Instead they use proxies.
8.5.4. Adding information to the econometrician’s information set: Using proxies for
the relevant information
Suppose that instead of knowing some part of the minimal relevant information set,
such as f2 , the analyst has access to a proxy for it.147 In particular, assume that he has
access to a variable Z̃ that is correlated with f2 but that is not the full minimal relevant
information set. That is, define the econometrician’s information to be
I˜E = {Z, Z̃},
and suppose that he uses it so IE = I˜E . In order to obtain closed-form expressions for
the biases we assume that


Z̃ ∼ N 0, σZ̃2 ,
corr(Z̃, f2 ) = ρ,

and Z̃ ⊥
⊥ (ε0 , ε1 , εV , f1 ).

We define expressions comparable to η and η :
α11 αV 1 σf21 + α12 αV 2 (1 − ρ 2 )σf22
,
η̃1 = 
αV2 1 σf21 + αV2 2 σf22 (1 − ρ 2 ) + σε2V
α01 αV 1 σf21 + α02 αV 2 (1 − ρ 2 )σf22
η̃0 = 
.
αV2 1 σf21 + αV2 2 σf22 (1 − ρ 2 ) + σε2V
By substituting for IE by I˜E and ηj by η̃j (j = 0, 1) in Conditions 1 and 2 of
Section 8.5.3, we can obtain results for the bias in this case. Whether I˜E will be biasreducing depends on how well it spans IR and on the signs of the terms in the absolute
values in those conditions in Section 8.5.3.
147 For example, the returns-to-schooling literature often uses different test scores, like AFQT or IQ, to proxy
for missing ability variables. We discuss these proxy, replacement function, methods in Section 11. See also
Abbring and Heckman (Chapter 72).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5053

In this case, however, there is another parameter to consider: the correlation ρ between Z̃ and f2 , ρ. If |ρ| = 1 we are back to the case of I˜E = IE because Z̃ is a perfect
proxy for f2 . If ρ = 0, we are essentially back to the case analyzed in Section 8.5.3. Because we know that the bias at a particular value of p might either increase or decrease
when f2 is used as a conditioning variable but f1 is not, we know that it is not possible to determine whether the bias increases or decreases as we change the correlation
between f2 and Z̃. That is, we know that going from ρ = 0 to |ρ| = 1 might change
the bias in any direction. Use of a better proxy in this correlational sense may produce
a more biased estimate.
From the analysis of Section 8.5.3, it is straightforward to derive conditions under
which the bias generated when the econometrician’s information is I˜E is smaller than
when it is IE . That is, it can be the case that knowing the proxy variable Z̃ is better than
knowing the actual variable f2 . Returning to the analysis of treatment on the treated
as an example (i.e., Condition 1), the bias in absolute value (at a fixed value of p) is
reduced when Z̃ is used instead of f2 if
α01 αV 1 σf21 + α02 αV 2 (1 − ρ 2 )σf22
α01 αV 1 σf21

< 
.
αV2 1 σf21 + αV2 2 σf22 (1 − ρ 2 ) + σε2V
αV2 1 σf21 + σε2V
Figures 24A and 24B, use the same true model as used in the previous section to illustrate the two points being made here. Namely, using a proxy for an unobserved relevant
variable might increase the bias. On the other hand, it might be better in terms of bias to
use a proxy than to use the actual variable, f2 . However, as Figures 25A and 25B show,
by changing α02 from 0.1 to 1, using a proxy might increase the bias versus using the
actual variable f2 . Notice that the bias need not be universally negative or positive but
depends on p.
The point of these examples is that matching makes very knife-edge assumptions. If
the analyst gets the right conditioning set, (M-1) is satisfied and there is no bias. But
determining the correct information set is not a trivial task, as we note in Section 8.5.6.
Having good proxies in the standard usage of that term can create substantial bias in
estimating treatment effects. Half a loaf may be worse than none.
8.5.5. The case of a discrete outcome variable
Heckman and Navarro (2004) construct parallel examples for cases including discrete
dependent variables. In particular, they consider nonnormal, nonseparable equations
for odds ratios and probabilities. The proposition that matching identifies the correct
treatment parameter if the econometrician’s information set includes all the minimal
relevant information is true more generally, provided that any additional extraneous
information used is exogenous in a sense to be defined precisely in the next section.

5054

J.J. Heckman and E.J. Vytlacil

Figure 24A. Bias for treatment on the treated. Source: Heckman and Navarro (2004).

Note: Using proxy Z̃ for f2 increases the bias. Correlation (Z̃, f2 ) = 0.5.
Model:
V = Z + f1 + f2 + εV ;
Y1 = 2f1 + 0.1f2 + ε1 ;
εV ∼ N (0, 1);
ε1 ∼ N (0, 1);
f1 ∼ N (0, 1);
f2 ∼ N (0, 1)

Y0 = f1 + 0.1f2 + ε0
ε0 ∼ N (0, 1)

Figure 24B. Bias for average treatment effect. Source: Heckman and Navarro (2004).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5055

Figure 25A. Bias for treatment on the treated. Source: Heckman and Navarro (2004).

Note: Using proxy Z̃ for f2 increases the bias. Correlation (Z̃, f2 ) = 0.5.
Model:
V = Z + f1 + f2 + εV ;
Y1 = 2f1 + 0.1f2 + ε1 ;
εV ∼ N (0, 1);
ε1 ∼ N (0, 1);
f1 ∼ N (0, 1);
f2 ∼ N (0, 1)

Y0 = f1 + f2 + ε0
ε0 ∼ N (0, 1)

Figure 25B. Bias for average treatment effect. Source: Heckman and Navarro (2004).

5056

J.J. Heckman and E.J. Vytlacil

8.5.6. On the use of model selection criteria to choose matching variables
We have already shown by way of example that adding more variables from a minimal
relevant information set, but not all variables in it, may increase bias. By a parallel
argument, adding additional variables to the relevant conditioning set may make the bias
worse. Although we have used our prototypical Roy model as our point of departure,
the point is more general.
There is no rigorous rule for choosing the conditioning variables that produce (M-1).
Adding variables that are statistically significant in the treatment choice equation is
not guaranteed to select a set of conditioning variables that satisfies condition (M-1).
This is demonstrated by the analysis of Section 8.5.3 that shows that adding f2 when it
determines D may increase bias at any selected value of p.
The existing literature [e.g., Heckman et al. (1998)] proposes criteria based on selecting a set of conditioning variables based on a goodness of fit criterion (λ), where a
higher λ means a better fit in the equation predicting D. The intuition behind such criteria is that by using some measure of goodness of fit as a guiding principle one is using
information relevant to the decision process. In the example of Section 8.5.3, using f2
improves goodness of fit of the model for D, but increases bias for the parameters. In
general, such a rule is deficient if f1 is not known or is not used.
An implicit assumption underlying such procedures is that the added conditioning
variables X are exogenous in the following sense:
⊥ D | Iint , X ,
(E-1) (Y0 , Y1 ) ⊥
where Iint is interpreted as the variables initially used as conditioning variables before X
is added. Failure of exogeneity is a failure of (M-1) for the augmented conditioning set,
and matching estimators based on the augmented information set (Iint , X ) are biased
when the condition is not satisfied.
Exogeneity assumption (E-1) is not usually invoked in the matching literature, which
largely focuses on problem P-1, evaluating a program in place, rather than extrapolating to new environments (P-2). Indeed, the robustness of matching to such exogeneity
assumptions is trumpeted as one of the virtues of the method. In this section, we show
some examples that illustrate the general point that standard model selection criteria
fail to produce correctly specified conditioning sets unless some version of exogeneity
condition (E-1) is satisfied.
In the literature, the use of model selection criteria is justified in two different ways.
Sometimes it is claimed that they provide a relative guide. Sets of variables with better
goodness of fit in predicting D (a higher λ in the notation of Table 12) are alleged
to be better than sets of variables with lower λ in the sense that they generate lower
biases. However, we have already shown that this is not true. We know that enlarging
the analyst’s information from Iint = {Z} to Iint = {Z, f2 } will improve fit since f2 is
also in IA and IR . But, going from Iint to Iint might increase the bias. So it is not true
that combinations of variables that increase some measure of fit λ necessarily reduce
the bias. Table 12 illustrates this point using our normal example. Going from row 1 to

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5057

Table 12
Variables in probit

Z
Z, f2
Z, f1 , f2
Z, S1
Z, S2

Goodness of fit statistics λ

Average bias

Correct in-sample prediction rate

Pseudo-R 2

TT

ATE

66.88%
75.02%
83.45%
77.38%
92.25%

0.1284
0.2791
0.4844
0.3282
0.7498

1.1380
1.2671
0.0000
0.9612
0.9997

1.6553
1.9007
0.0000
1.3981
1.4541

Model: V = Z + f1 + f2 + εV ; εV ∼ N (0, 1); Y1 = 2f1 + 0.1f2 + ε1 ; ε1 ∼ N (0, 1); Y0 = f1 + 0.1f2 + ε0 ;
ε0 ∼ N (0, 1); S1 = V + U1 ; U1 ∼ N (0, 4); S2 = V + U2 ; U2 ∼ N (0, 0.25); f1 ∼ N (0, 1); f2 ∼ N (0, 1).

row 2 (adding f2 ) improves goodness of fit and increases the unconditional or overall
bias for all three treatment parameters, because (E-1) is violated.
The following rule of thumb argument is sometimes invoked as an absolute standard
against which to compare alternative models. In versions of the argument, the analyst
asserts that there is a combination of variables I that satisfy (M-1) and hence produces
zero bias and a value of λ = λ larger than that of any other I . In our examples, conditioning on {Z, f1 , f2 } generates zero bias. We can exclude Z and still obtain zero
bias. Because Z is a determinant of D, this shows immediately that the best fitting
model does not necessarily identify the minimal relevant information set. In this example including Z is innocuous because there is still zero bias and the added conditioning
variables satisfy (E-1) where Iint = (f1 , f2 ). In general, such a rule is not innocuous if
Z is not exogenous. If goodness of fit is used as a rule to choose variables on which to
match, there is no guarantee it produces a desirable conditioning set. If we include in
the conditioning set variables X that violate (E-1), they may improve the fit of predicted
probabilities but worsen the bias.
Heckman and Navarro (2004) produce a series of examples that have the following
feature. Variables S (shown at the base of Table 12) are added to the information set that
improve the prediction of D but are correlated with (U0 , U1 ). Their particular examples
use imperfect proxies (S1 , S2 ) for (f1 , f2 ). The point is more general. The S variables
fail exogeneity and produce greater bias for TT and ATE but they improve the prediction
of D as measured by the correct in-sample prediction rate and the pseudo-R 2 . See the
bottom two rows of Table 12.
We next turn to the method of randomization, which is frequently held up to be an
ideal approach for evaluating social programs. Randomization attempts to use a random
assignment to achieve the conditional independence assumed in matching.

9. Randomized evaluations
This section analyzes randomized social experiments as tools for evaluating social programs. In the introduction to this chapter, we discussed an ideal randomization where

5058

J.J. Heckman and E.J. Vytlacil

treatment status is randomly assigned. In this section, we discuss actual social experiments, where self-selection decisions often intrude on the randomization decisions of
experimenters.
Two cases have been made for the application of social experimentation. One case is
a classical argument in experimental design. Inducing variation in regressors increases
precision of estimates and the power of tests. The other case focuses on solving endogeneity and self-selection problems. Randomization is an instrumental variable.148 The
two cases are mutually compatible, but involve different emphases.
Both cases can be motivated within a linear regression model for outcome Y with
treatment indicator D and covariates X:
Y = Xα + Dβ + U,

(9.1)

where U is an unobservable. β may be the same for all observations (conditional on X)
as in the common coefficient setup, or it may be a variable coefficient of the type extensively discussed in this chapter. D (and the X) may be statistically dependent on U .
We also entertain the possibility that when β is random it is dependent on D, as in the
generalized Roy model.
Both cases for social experimentation seek to secure identification of some parameters of (9.1) or parameters that can be generated from (9.1). Analysts advocating
the first case for experimentation typically assume a common coefficient model for α
and β. They address the problem that variation in (X, D) may be insufficient to identify or precisely estimate (α, β). Manipulating (X, D) through randomization, or more
generally, through controlled variation, can secure identification. It is typically assumed
that (X, D) is independent of U or at least mean independent. This is the traditional
case analyzed in a large literature on experimental design in statistics.149
Good examples in economics of experimentation designed to increase the variation
in the regressors are studies by Conlisk (1973), Conlisk and Watts (1969), and Aigner
(1979a, 1979b, 1985). The papers by Conlisk show how experimental manipulation can
solve a multicollinearity problem. In analyzing the effects of taxes on labor supply, it is
necessary to isolate the effect of wages (the substitution effect) from the effect of pure
asset income (the income effect) on labor supply. In observational data, empirical measures of wages and asset income are highly intercorrelated. In addition, asset income is
often poorly measured. By experimentally assigning these variables as in the negative
income tax experiments, it is possible to identify both income and substitution effects in
labor supply equations [see Cain and Watts (1973)]. Aigner (1979b) shows how variation in the prices paid for electricity across the day can identify price effects that cannot
be identified in regimes with uniform prices across all hours of the day.150
Random assignment is not essential to this approach. Any regressor assignment rule
based on variables Q that are stochastically independent of U will suffice, although the
148 See Heckman (1996).
149 See, e.g., Silvey (1970).
150 Zellner and Rossi (1987) present a comprehensive discussion of this literature.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5059

efficiency of the estimates will depend on the choice of Q and care must be taken to
avoid inducing multicollinearity by the choice of an assignment rule.
The second case for social experiments and the one that receives the most attention
in applied work in economics and in this chapter focuses on the dependence between
(X, D) and U that invalidates least squares as an estimator of the causal effect of X and
D on Y . This is the problem of least squares bias raised by Haavelmo (1943) and extensively discussed in Chapter 70. In the second case, experimental variation in (X, D)
is sought to make it “exogenous” or “external” to U . A popular argument in favor of
experiments is that they produce simple, transparent estimates of the effects of the programs being evaluated in the presence of such biases. A quotation from Banerjee (2006)
is apt:
The beauty of randomized evaluations is that the results are what they are: we
compare the outcome in the treatment [group] with the outcome in the control
group, see whether they are different, and if so by how much. Interpreting quasiexperiments sometimes requires statistical legerdemain, which makes them less
attractive . . .
This argument assumes that interesting evaluation questions can be answered by the
marginal distributions produced from experiments. It also assumes that no economic
model is needed to interpret evidence, contrary to a main theme of this chapter.
Randomization is an instrument. As such, it shares all of the assets and liabilities
of IV already discussed. In particular, randomization applied to a correlated random
coefficient (or a model of essential heterogeneity) raises the same issues about the multiplicity of parameters identified by different randomizations as were discussed there in
connection with the multiplicity of parameters identified by different instruments.
The two popular arguments for social experimentation are closely related. Exogenous variation in (X, D) can, if judiciously administered, solve collinearity, precision,
and endogeneity problems. Applying the terminology of Chapter 70 to the analysis of
model (9.1), randomization can identify a model that can solve all three policy evaluation problems: P-1, the problem of internal validity; P-2, the problem of extrapolation
to new environments (by virtue of the linearity of (9.1)); and P-3, the problem of forecasting new policies that can be described by identifiable functions of (X, D) and any
external variables.
As noted in the concluding section of Chapter 70, the modern literature tends to reject
functional form assumptions such as those embodied in Equation (9.1). It has evolved
towards a more focused attempt to solve problem P-1 to protect against endogeneity
of D with respect to U . Sometimes the parameter being identified is not clearly specified. When it is, this focus implements Marschak’s Maxim of doing one thing well, as
discussed in Chapter 70.
Common to the literature on IV estimation, proponents of randomization often ignore
the consequences of heterogeneity in β and dependence of β on D – the problem of essential heterogeneity. Our discussion in the previous sections applies with full force to
randomization as an instrument. Only if the randomization (instrument) corresponds ex-

5060

J.J. Heckman and E.J. Vytlacil

actly to the policy that is sought to be evaluated will the IV (randomization) identify the
parameters of economic interest.151 This section considers the case for randomization
as an instrumental variable to solve endogeneity problems.
9.1. Randomization as an instrumental variable
The argument justifying randomization as an instrument assumes that randomization
(or more generally the treatment assignment rule) does not alter subjective or objective
potential outcomes. This is covered by assumption (PI-3) presented in Chapter 70. We
also maintain absence of general equilibrium effects (PI-4) throughout this section. We
discuss violations of (PI-3) when we discuss randomization bias.152 ,153
To be explicit about particular randomization mechanisms, we return to our touchstone generalized Roy model. Potential outcomes are (Y0 , Y1 ) and cost of participation
is C. Assume perfect certainty in the absence of randomization. Under self-selection,
the treatment choice is governed by
D = 1(Y1 − Y0 − C  0).
This model of program participation abstracts from the important practical feature of
many social programs that multiple agents contribute to decisions about program participation. We consider a more general framework in Section 9.5. We assume additive
separability between the observables (X, W ) and the unobservables (U0 , U1 , UC ) for
convenience:
Y1 = μ1 (X) + U1 ,
C = μC (W ) + UC ,

Y0 = μ0 (X) + U0 ,
V = U1 − U0 − UC ,

μI (X, W ) = μ1 (X) − μ0 (X) − μC (W ),

Z = (X, W ).

Only some components of X and/or W may be randomized. Randomization can be
performed unconditionally or conditional on strata, Q, where the strata may or may
not include components of (X, W ) that are not randomized. Specifically, it can be
performed conditional on X, just as in our analysis of IV. Parameters can be defined
conditional on X.154 Examples of treatments randomly assigned include the tax/benefit
plans of the negative income tax programs; the price of electricity over the course of the
day; variable tolls and bonuses; textbooks to pupils; reducing class size. Under invariance condition (PI-3), the functions μ0 (X), μ1 (X), μC (W ) (and hence μI (X, W )) are
151 The exchange between Banerjee (2006) and Deaton (2006) raises this point.
152 We maintain the absence of general equilibrium or spill over effects, assumption (PI-2). Such effects are

discussed in Abbring and Heckman (Chapter 72).
153 For evaluation of distributional and mean parameters, assumption (PI-3) can be weakened as in our invocation of policy invariance for the MTE to say that randomization does not alter the distributions of outcomes
or certain means or conditional means (recall assumption (A-7)).
154 In Equation (9.1), if X is endogenous and we randomize treatment D conditional on X with respect to U ,
we cannot identify α, but we can identify β.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5061

invariant to such modifications. The intervention is assumed to change the arguments
of functions without shifting the functions themselves. Thus for the intervention of randomization, the functions are assumed to be structural in the sense of Hurwicz (1962).
The distributions of (U0 , U1 , UC ) conditional on X, and hence the distribution of V
conditional on X, are also invariant. Under full compliance, the manipulated Z are the
same as the Z facing the agent. We formalize this assumption:
(R-4) The Z assigned agent ω conditional on X are the Z realized and acted on by
the agent conditional on X.155
In terms of the generalized Roy model, this assumption states that the Z assigned ω
given X is the W that appears in the cost function and the derived decision rule.
Some randomizations alter the environments facing agents in a more fundamental
way by introducing new random variables into the model instead of modifying the variables that would be present in a pre-experimental environment. Comparisons of these
randomizations involve an implicit dynamics, better exposited using the dynamic models presented in Abbring and Heckman (Chapter 72). For simplicity and to present some
main ideas, we initially invoke an implicit dynamics suitable to the generalized Roy
model. We develop a more explicit dynamic model of randomized evaluation in Section 9.5.
The most commonly used randomizations restrict eligibility either in advance of
agent decisions about participation in a program or after agent decisions are made, but
before actual participation begins. Unlike statistical discussions of randomization, we
build agent choice front and center into our analysis. Agents choose and experimenters
can only manipulate choice sets.
Let ξ = 1 if an agent is eligible to participate in the program; ξ = 0 otherwise.
ξ̃ = {0, 1} is the set of possible values of ξ . Let D indicate participation under ordinary
conditions. In the absence of randomization, D is an indicator of whether the agent
actually participates in the program. Let actual participation be A. By construction,
under invariance condition (PI-3) presented in Chapter 70,
A = Dξ.

(9.2)

This assumes that eligibility is strictly enforced.
There is a distinction between desired participation by the agent (D) and actual
participation (A). This distinction is conceptually distinct from the ex-ante, ex-post distinction. At all stages of the application and enrollment process, agents may be perfectly
informed about their value of ξ and desire to participate (D), but may not be allowed to
participate. On the other hand, the agent may be surprised by ξ after applying to the program. In this case, there is revelation of information and there is a distinction between
ex ante expectations and ex post realizations. Our analysis covers both cases.
We consider two types of randomization of eligibility.
155 Assumptions (R-1)–(R-3) are presented in Section 2.

5062

J.J. Heckman and E.J. Vytlacil

R ANDOMIZATION OF T YPE 1. A random mechanism (possibly conditional on (X, Z))
is used to determine ξ . The probability of eligibility is Pr(ξ = 1 | X, Z).
For this type of randomization, in the context of the generalized Roy model, it is
assumed that
(e-1a) ξ ⊥
⊥ (U0 , U1 , UC ) | X, Z (Randomization of eligibility)
and
(e-1b) Pr(A = 1 | X, Z, ξ ) depends on ξ .
This randomization affects the eligibility of the agent for the program but because agents
still self-select, there is no assurance that eligible agents will participate in the program.
This condition does not impose exogeneity on X, Z.156 Thus Z can fail as an instrument
but ξ remains a valid instrument. Alternatively, (e-1a) and (e-1b) may be formulated
according to the notation of Imbens and Angrist (1994). Define A(z, e) to be the value
of A when we set Z = z and ξ = e. Define Z as the set of admissible Z and +
ξ as the
set of admissible ξ . In this notation, we may rewrite assumptions (e-1a) and (e-1b) as
⊥ (Y0 , Y1 , {A(z, e)}(z,e)∈Z ×ξ̃ ) | X, Z
(e-1a) ξ ⊥
and
(e-1b) Pr(A = 1 | X, Z, ξ ) depends on ξ .157
A second type of randomization conditions on individuals manifesting a desire to participate through their decision to apply to the program. This type of randomization is
widely used.
R ANDOMIZATION OF T YPE 2. Eligibility may be a function of D (conditionally on
some or all components of X, Z, Q or unconditionally). It is common to deny entry into
programs among people who applied and were accepted into the program (D = 1) so
the probability of eligibility is Pr(ξ = 1 | X, Z, Q, D = 1). This assumes (PI-3) stated
in Chapter 70.
For this type of randomization of eligibility, it is assumed that
(e-2a) ξ ⊥
⊥ (U0 , U1 ) | X, Z, Q, D = 1
and

156 In place of the randomization, one might assign treatment on the basis of external variables Q includ-

ing variables in addition to X and Z. Care must be taken to avoid inducing collinearity problems. Random
assignment is simpler. It produces through randomization the independent variation assumed in matching.
157 When ξ is deterministic, (e-1a) is trivially satisfied.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5063

(e-2b) Pr(A = 1 | X, Z, D = 1, ξ = 1) = 1; Pr(A = 1 | X, Z, D = 1, ξ = 0) = 0.
Agent failure to comply with the eligibility rules or protocols of experiments can lead
to violations of (e-1) and/or (e-2).
An equivalent way to formulate (e-2a) and (e-2b) uses the Imbens–Angrist notation
for IV:
(e-2a) ξ ⊥
⊥ (Y0 , Y1 ) | X, Z, Q, D = 1
and
(e-2b) Pr(A = 1 | X, Z, D = 1, ξ = 1) = 1; Pr(A = 1 | X, Z, D = 1, ξ = 0) = 0.
Both randomizations are instruments as defined in Section 4. Under the stated conditions, both satisfy (IV-1) and (IV-2), suitably redefined for eligibility randomizations,
replacing D by A.
A variety of conditioning variables is permitted by these definitions. Thus, (e-1) and
(e-2) allow for the possibility that the conventional instruments Z fail (IV-1) and (IV-2),
but nonetheless the randomization generates a valid instrument ξ . The simplest randomizations do not condition on any variables.158 We next consider what these instruments
identify.
9.2. What does randomization identify?159
Under invariance assumption (PI-3) and under one set of randomization assumptions
just presented, IV is an instrument that identifies some treatment effect for an ongoing
program. The question is: which treatment effect? Following our discussion of IV with
essential heterogeneity presented in Section 4, different randomizations (or instruments)
identify different parameters unless there is a common coefficient model (Y1 − Y0 =
β(X) is the same for everyone given X) or unless there is no dependence between the
treatment effect (Y1 − Y0 ) and the indicator D of the agents’ desire to participate in
the treatment. In these two special cases, all mean treatment parameters are the same.
Using IV, we can identify the marginal distributions F0 (y0 | X) and F1 (y1 | X).160
In a model with essential heterogeneity, the instruments generated by randomization
can identify parameters that are far from the parameters of economic interest. Randomization of components of W (or Z given X) under (R-4) and conditions (IV-1) and
(IV-2) from Section 2 produces instruments with the same problems and possibilities
as analyzed in our discussion of instrumental variables. Using W as an instrument may
lead to negative weights on the underlying LATEs or MTEs.161 Thus, unless we condi158 We do not discuss optimal randomized experiments and the best choice of a randomization mechanism.
159 This subsection is based on Heckman (1992).
160 We can also identify F (y | X, Z) and F (y | X, Z) if Z does not satisfy the conditions required for it
0 0
1 1
to be an instrument but experimental variation provides new instruments.
161 In the special case where randomization of some components of W makes them fully independent of the
other components of W , under monotonicity for the randomized component irrespective of the values of the
other components, the IV weights must be nonnegative.

5064

J.J. Heckman and E.J. Vytlacil

tion on the other instruments, the IV defined by randomization can be negative even if
all of the underlying treatment effects or LATEs and MTEs generating choice behavior
are positive. The weighted average of the MTE generated by the instrument may be far
from the policy relevant treatment effect.
Under (PI-3) and (e-1), or equivalently (e-1) , the first type of eligibility randomization identifies Pr(D = 1 | X, Z) (the choice probability) and hence relative subjective evaluations, and the marginal outcome distributions F0 (y0 | X, D = 0) and
F1 (y1 | X, D = 1) for the eligible population (ξ = 1). Agents made eligible for the program self-select as usual. For those deemed ineligible (ξ = 0), under our assumptions,
we would identify the distribution of Y0 , which can be partitioned into components for
those who would have participated in the program had it not been for the randomization
and components for those who would not have participated if offered the opportunity to
do so:
F0 (y0 | X) = F0 (y0 | X, D = 0) Pr(D = 0 | X)
+ F0 (y0 | X, D = 1) Pr(D = 1 | X).
Since we know F0 (y0 | X, D = 0) and Pr(D = 1 | X) from the eligible population,
we can identify F0 (y0 | X, D = 1). This is the new piece of information produced
by the randomization compared to what can be obtained from standard observational
data. In particular, we can identify the parameter TT, E(Y1 − Y0 | X, D = 1), but
without further assumptions, we cannot identify the other treatment parameters ATE
(= E(Y1 − Y0 | X)) or the joint distributions F (y0 , y1 | X) or F (y0 , y1 | X, D = 1).
To show that ξ is a valid instrument for A, form the Wald estimand,
E(Y | ξ = 1, Z, X) − E(Y | ξ = 0, Z, X)
.
(9.3)
Pr(A = 1 | ξ = 1, Z, X) − Pr(A = 1 | ξ = 0, Z, X)
Under invariance assumption (PI-3), Pr(D = 1 | Z, X) is the same in the presence or
absence of randomization.162 Assuming full compliance so that agents randomized to
ineligibility do not show up in the program,
IV(e-1) =

Pr(A = 1 | ξ = 0, Z, X) = 0,
and
E(Y | ξ = 0, Z, X) = E(Y0 | Z, X)
= E(Y0 | D = 1, X, Z) Pr(D = 1 | X, Z)
+ E(Y0 | D = 0, X, Z) Pr(D = 0 | X, Z).
If Z also satisfies the requirement (IV-1) that it is an instrument, then E(Y0 | Z, X) =
E(Y0 | X). Under (e-1) or (e-1) we do not have to assume that Z is a valid instrument.163 Using (e-1) and assumption (PI-3), the first term in the numerator of (9.3) can
162 Pr(D = 1 | Z, X, ξ = 0) = Pr(D = 1 | Z, X, ξ = 1).
163 If Z fails to be an instrument, absorb Z into X.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5065

be written as
E(Y | ξ = 1, Z, X) = E(Y1 | D = 1, Z, X) Pr(D = 1 | Z, X)
+ E(Y0 | D = 0, Z, X) Pr(D = 0 | Z, X).
Substituting this expression into the numerator of Equation (9.3) and collecting terms,
IV(e-1) identifies the parameter treatment on the treated:
IV(e-1) = E(Y1 − Y0 | D = 1, Z, X).
It does not identify the other mean treatment effects, such as LATE or the average treatment effect ATE, unless the common coefficient model governs the data or (Y1 − Y0 )
is mean independent of D. Using the result that F (y | X) = E(1(Y  y) | X),
IV(e-1) also identifies F0 (y0 | X, D = 1), since we can compute conditional means of
1(Y  y) for all y. The distribution F1 (y1 | X, D = 1) can be identified from observational data. Thus we can identify the outcome distributions for Y0 and for Y1 separately,
conditional on D = 1, X, Z, but without additional assumptions we cannot identify the
joint distribution of outcomes or the other treatment parameters.
Randomization not conditional on (X, Z) (ξ ⊥
⊥ (X, Z)) creates an instrument ξ that
satisfies the monotonicity or uniformity conditions. If the randomization is performed
on (X, Z) strata, then the IV must be used conditional on the strata variables to ensure
monotonicity is satisfied.
The second type of eligibility randomization proceeds conditionally on D = 1.
Accordingly, data generated from such experiments do not identify choice probabilities (Pr(D = 1 | X, Z)) and hence do not identify the subjective evaluations of
agents [Heckman (1992), Moffitt (1992)]. Under (PI-3) and (e-2) (or equivalent conditions (e-2) ) randomization identifies F0 (y0 | D = 1, X, Z) from the data on the
randomized-out participants. This conditional distribution cannot be constructed from
ordinary observational data unless additional assumptions are invoked. From the data
for the eligible (ξ = 1) population, we identify F1 (y1 | D = 1, X, Z).
The Wald estimator for mean outcomes in this case is
IV(e-2) =

E(Y | D = 1, ξ = 1, X, Z) − E(Y | D = 1, ξ = 0, X, Z)
.
Pr(A = 1 | D = 1, ξ = 1, X, Z) − Pr(A = 1 | D = 1, ξ = 0, X, Z)

Under (e-2)/(e-2) ,
Pr(A = 1 | D = 1, ξ = 1, X, Z) = 1,
Pr(A = 1 | D = 1, ξ = 0, X, Z) = 0,
E(Y | A = 0, D = 1, ξ = 0, X, Z) = E(Y0 | D = 1, X, Z)
E(Y | A = 1, D = 1, ξ = 1, X, Z) = E(Y1 | D = 1, X, Z).
Thus,
IV(e-2) = E(Y1 − Y0 | D = 1, X, Z).

and

5066

J.J. Heckman and E.J. Vytlacil

In the general model with essential heterogeneity, randomized trials with full compliance that do not disturb the activity being evaluated answer a limited set of questions,
and do not in general identify the policy relevant treatment effect (PRTE). Randomizations have to be carefully chosen to make sure that they answer interesting economic
questions. Their analysis has to be supplemented with the methods previously analyzed
to answer the full range of policy questions addressed there.
Thus far we have assumed that the randomizations do not violate the invariance assumption (PI-3). Yet many randomizations alter the environment they are studying and
inject what may be unwelcome sources of uncertainty into agent decision making. We
now examine the consequences of violations of invariance.
9.3. Randomization bias
If randomization alters the program being evaluated, the outcomes of a randomized trial
may bear little resemblance to the outcomes generated by an ongoing version of the
program that has not been subject to randomization. In this case, assumption (PI-3) is
violated. Such violations are termed “Hawthorne effects” and are called “randomization
bias” in the economics literature.164 The process of randomization may affect objective
outcomes, subjective outcomes or both.
Even if (PI-3) is violated, randomization may still be a valid instrument for the altered
program. Although the program studied may be changed, under the assumptions made
in Section 9.2, randomization can produce “internally valid” treatment effects for the
altered program. Thus randomization can answer policy question P-1 for a program
changed by randomization, but not for the program as it would operate in the absence
of randomization.
As noted repeatedly, a distinctive feature of the econometric approach to social program evaluation is its emphasis on choice and agent subjective evaluations of programs.
This feature accounts for the distinction between the statistician’s invariance assumption (PI-1) and the economist’s invariance assumption (PI-3). (These are presented in
Chapter 70.) It is instructive to consider the case where assumption (PI-1) is valid but
assumption (PI-3) is not. This case might arise when randomization alters risk-averse
agent decision behavior but has no effects on potential outcomes. Thus the R(s, ω) are
affected, but not the Y (s, ω).
In this case, the parameter ATE(X) = E(Y1 − Y0 | X) is the same in the ongoing
program as in the population generated by the randomized trial. However, treatment
parameters conditional on choices such as
TT(X) = E(Y1 − Y0 | X, D = 1),
TUT(X) = E(Y1 − Y0 | X, D = 0)
164 See Campbell and Stanley (1963) for a discussion of Hawthorne effects and evidence of their prevalence
in educational interventions. See Heckman (1992) for a discussion of randomization bias in economics.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5067

are not, in general, invariant. If the subjective valuations are altered, so are the parameters based on choices produced by the subjective valuations. Different random variables
generate the conditioning sets in the randomized and nonrandomized regimes and, in
general, they will have a different dependence structure with the outcomes Y (s, ω). This
arises because randomization alters the composition of participants in the conditioning
set that defines the treatment parameter.
This analysis applies with full force to LATE. LATE based on P (Z) for two distinct
values of Z (Z = z and Z = z ) is E(Y1 − Y0 | X, P (z )  UD  P (z)). In the
randomized trial, violation of (PI-3) because of lack of invariance of R(s, ω) changes
UD and the values of P (Z) for the same Z = z. In general, this alters LATE.165
The case where (PI-1) holds, but (PI-3) does not, generates invariant conditional (on
choice) parameters if there is no treatment effect heterogeneity or if there is such heterogeneity that is independent of D. These are the familiar conditions: (a) Y1 − Y0 is
the same for all people with the same X = x or (b) Y1 − Y0 is (mean) independent of D
given X = x. In these cases, the MTE is flat in UD .
In general, in a model with essential heterogeneity, even if the Rubin invariance conditions (PI-1) and (PI-2) are satisfied, but conditions (PI-3) and (PI-4) are not, treatment
parameters defined conditional on choices are not invariant to the choice of randomization.166 This insight shows the gain in clarity in interpreting what experiments identify
from adopting a choice-theoretic, econometric approach to the evaluation of social programs, as opposed to the conventional approach adopted by statisticians. We now show
another advantage of the economic approach in an analysis of noncompliance and its
implications for interpreting experimental evidence.
9.4. Compliance
The statistical treatment effect literature extensively analyzes the problem of noncompliance.167 Persons assigned to a treatment may not accept it. In the notation of Equation (9.3), let ξ = 1 if a person is assigned to treatment, ξ = 0 otherwise. Compliance
is said to be perfect when ξ = 1 ⇒ A = 1 and ξ = 0 ⇒ A = 0. In the presence
of self-selection by agents, these conditions do not, in general, hold. People assigned
to treatment may not comply (ξ = 1 but D = 0). This is also called the “dropout”
problem [Mallar, Kerachsky and Thorton (1980), Bloom (1984)]. In its formulation of
this problem, the literature assumes that outcomes are measured for each participant but
that outcomes realized are not always those intended by the randomizers.168 In addition,
165 Technically, for identifying MTE or LATE, we can get by with weaker conditions than (PI-3) and (PI-4).
All we need is invariance of the conditional mean of Y1 − Y0 with respect to UD . Recall our discussion of
policy invariance surrounding our discussion of assumption (A-7).
166 Rubin combines (PI-1) and (PI-2) in his “SUTVA” condition.
167 See, e.g., Bloom (1984), Manski (1996), and Hotz, Mullin and Sanders (1997).
168 The problem of missing data is called the attrition problem. Thus we assume no attrition from the database, but we allow for the possibility that people assigned to a treatment do not receive it.

5068

J.J. Heckman and E.J. Vytlacil

people denied treatment may find substitutes for the treatment outside of the program.
This is the problem of substitution bias. Since self-selection is an integral part of choice
models, noncompliance, as the term is used by the statisticians, is a feature of most
social experiments.
The econometric approach builds in the possibility of self-selection as an integral part
of model specification. As emphasized in the econometric literature since the work of
Gronau (1974), Heckman (1974a, 1974b, 1976b), and McFadden (1974), agent decisions to participate are informative about their subjective evaluations of the program. In
the dynamic setting discussed in Section 3 of Chapter 72 of this Handbook, agent decisions to attrite from a program are informative about their update of information about
the program [Heckman and Smith (1998), Chan and Hamilton (2006), Smith, Whalley
and Wilcox (2006) and Heckman and Navarro (2007)]. Noncompliance is a source of
information about subjective evaluations of programs.
Noncompliance is a problem if the goal of the social experiment is to estimate
ATE(X) = E(Y1 − Y0 | X) without using the econometric methods previously discussed. We established in Section 9.3 that in the presence of self-selection, in a general
case with essential heterogeneity, experiments under assumptions (PI-3) and (PI-4) and
(e-1) or (e-2) identify E(Y1 − Y0 | X, D = 1) instead of ATE(X).
Concerns about noncompliance often arise from adoption of the Neyman–Cox–Rubin
“causal model” discussed in Chapter 70, Section 4.4. Experiments are conceived as
tools for direct allocation of agricultural treatments. For that reason, that literature elevates ATE to pre-eminence as the parameter of interest because it is thought that this
parameter can be produced by experiments. In social experiments, it is rare that the experimenter can force anyone to do anything. As the old adage goes, “you can lead a
horse to water but you cannot make it drink”. Agent choice behavior intervenes. Thus it
is no accident that if they are not compromised, the two randomizations most commonly
implemented directly identify parameters conditional on choices.169
There is a more general version of the noncompliance problem which requires a dynamic formulation. Agents are assigned to treatment (ξ = 1) and some accept (D = 1)
but drop out of the program at a later stage. We need to modify the formulation in this
section to cover this case. We now turn to that modification.
9.5. The dynamics of dropout and program participation
Actual programs are more dynamic in character than the stylized program just analyzed. Multiple actors are involved, such as the agents being studied and the groups
administering the programs. People apply, are accepted, enroll, and complete the program. A fully dynamic analysis, along the lines of the models developed by Abbring

169 Randomizations of treatment to entire geographically segmented regions can produce ATE assuming
homogeneity in background conditions across regions. This is the logic behind the Progressa experiment [see
Behrman, Sengupta and Todd (2005)].

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5069

and Heckman in Chapter 72, analyzes each of these decisions, accounting for the updating of agent and program administrators’ information.170 This section briefly discusses
some new issues that arise in a more dynamic formulation of the dropout problem.
Heckman (1992), Heckman, Smith and Taber (1998), Hotz, Mullin and Sanders (1997),
and Manski (1996, 2003) discuss these issues in greater depth.
In this subsection, we analyze the effects of dropouts on inferences from social experiments and assume no attrition. Our analysis of this case is of interest both in its own
right and as a demonstration of the power of our approach.
Consider a stylized multiple stage program. In stage “0”, the agent (possibly in
conjunction with program officials) decides to participate or not to participate in the
program. This is an enrollment phase prior to treatment. Let D0 = 1 denote that the
agent does not choose to participate. D0 = 0 denotes that the agent participates and receives some treatment among J possible program levels beyond the no treatment state.
The outcome associated with state “0” is Y0 . This assumes that acts of inquiry about
a program or registration in it have no effect on outcomes.171 One could disaggregate
stage “0” into recruitment, application, and acceptance stages, but for expositional simplicity we collapse these into one stage.
If the J possible treatment stages are ordered, say, by the intensity of treatment, then
“1” is the least amount of treatment and “J ” is the greatest amount. A more general
model would allow people to transit to stage j but not complete it. The J distinct stages
can be interpreted quite generally. If a person no longer participates in the program after
stage j , j = 1, . . . , J , we set indicator Dj = 1. The person is assumed to receive stage
j treatment. DJ = 1 corresponds to completion
 of the program in all J stages of its
treatment phase. Note that, by construction, Jj=0 Dj = 1. The sequential updating
model developed by Abbring and Heckman in Chapter 72 can be used to formalize
these decisions and their associated outcomes. We can also use the simple multinomial
choice model developed and analyzed in Appendix B of Chapter 70.
Let {Dj (z)}z∈Z be the set of potential treatment choices for choice j associated with

setting Z = z. For each Z = z, Jj=0 Dj (z) = 1. Using the methods exposited in
Abbring and Heckman (Chapter 72), we could update the information sets at each stage.
We keep this updating implicit. Different components of Z may determine different
choice indicators. Array the collections of choice indicators evaluated at each Z = z
into a vector





D(z) = D1 (z) z∈Z , . . . , DJ (z) z∈Z .
The potential outcomes associated with each of the J + 1 states are
Yj = μj (X, Uj ),

j = 0, . . . , J.

170 Heckman and Smith (1999) analyze the determinants of program participation for a job training program.
171 Merely being interested in a program, such as an HIV treatment program, may signal information that

affects certain outcomes prior to receiving any treatment. We ignore these effects, but can easily accommodate
them by making application a stage of the program.

5070

J.J. Heckman and E.J. Vytlacil

Y0 is the no treatment state, and the Yj , j  1, correspond to outcomes associated with
dropping out at various stages of the program. In the absence of randomization, the
observed Y is
Y =

J


Dj Yj ,

j =0

the Roy–Quandt switching regime model. Let Ỹ = (Y0 , . . . , YJ ) denote the vector of
potential outcomes associated with all phases of the program. Through selection, the Yj
for persons with Dj = 1 may be different from the Yj for persons with Dj = 0.
Appendix B of Chapter 70 gives conditions under which the distributions of the Yj
and the subjective evaluations Rj , j = 0, . . . , J , that generate choices Dj are identified.
Using the tools for multiple outcome models developed in Section 7, we can use IV and
our extensions of IV to identify the treatment parameters discussed there.
In this subsection, we consider what randomizations at various stages identify. We
assume that the randomizations do not disturb the program. Thus we invoke assumption (PI-3). Recall that we also assume absence of general equilibrium effects (PI-4).
Let ξj = 1 denote whether the person is eligible to move beyond stage j . ξj = 0 means
the person is randomized out of the program after completing stage j . A randomization
at stage j with ξj = 1 means the person is allowed to continue on to stage j + 1, although the agent may still choose not to. We set ξJ ≡ 1 to simplify the notation. The ξj
are ordered in a natural way: ξj = 1 only if ξ = 1,  = 0, . . . , j − 1. Array the ξj into
a vector ξ and denote its support by ξ̃ .
Because of agent self-selection, a person who does not choose to participate at stage
j cannot be forced to do so. For a person who
 would choose k (Dk = 1) in a nonexperimental environment, Yk is observed if k−1
=0 ξ = 1. Otherwise, if ξk−1 = 0 but,
k
k −1
say, =0 ξ = 1 and =0 ξ = 0 for k < k, we observe Yk for the agent. From an
experiment with randomization administered at different stages, we observe
 j  k−1 

J

 ,
Dj
ξ (1 − ξk )Yk .
Y =
j =0

k=0

=0

To understand this formula, consider a program with three stages (J = 3) after the initial
participation stage. For a person who would like to complete the program (D3 = 1), but
is stopped by randomization after stage 2, we observe Y2 instead of Y3 . If the person is
randomized out after stage 1, we observe Y1 instead of Y3 .172
172 A more descriptively accurate but notationally cumbersome framework would disaggregate the participation decision and would also recognize that enrolling in a program stage is different from completing it. Thus,
let DR = 1 if a person is recruited, DR = 0 if not; DA = 1 if a person applies, DA = 0 if not; DAcc = 1 if
a person is accepted, DAcc = 0 if not; D1e = 1 if a person enrolls in stage 1, D1e = 0 if not; D1c = 1 if a
person completes stage 1, D1c = 0 if not; and so forth up to DJ e = 1 or 0; DJ c = 1 or 0. Associated with
completing stage  but no later stage is Y ,  ∈ {R, A, Acc, 1e, 1c, . . . , J e, J c}. Information can be revealed

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5071

Let Ak be the indicator that we observe the agent with a stage k outcome. This can
happen if a person would
have chosen to stop at stage k (Dk = 1) and survives random
ization through k ( k−1
ξ
=0  = 1), or if a person would have chosen to stop at a stage
later than k but was thwarted from doing so by the randomization and settles for the best
attainable state given the constraint imposed by the randomization. We can express Ak
as
 k−1 
k−1
,
,

ξ +
Dj
ξ (1 − ξk ), k = 1, . . . , J.
Ak = D k
=0

j k

=0

If a person who chooses Dk = 1 survives all stages of randomization through k − 1 and
hence is allowed to transit to k, we observe Yk for that person.
 For persons who would
choose Dj = 1, j > k, but get randomized out at k, i.e., ( k−1
=0 ξ )(1 − ξk ) = 1, we
also observe Yk .173
We now state the conditions under which sequential randomizations are instrumental
variables for the Aj . Let Ai (z, ei ) be the value of Ai when Z = z and ξi = ei . Array
the Ai , i = 1, . . . , J , into a vector


A(z, e) = A1 (z, e1 ), A2 (z, e2 ), . . . , AJ (z, eJ ) .
A variety of randomization mechanisms are possible in which randomization depends
on the information known to the randomizer at each stage of the program.
IV conditions for ξ are satisfied under the following sequential randomization assumptions. They parallel the sequential randomization conditions developed in the
dynamic models analyzed by Abbring and Heckman (Chapter 72) of our contribution:

(e-3a) ξi ⊥
⊥ (Ỹ , {A(z, e)}(z,e)∈Z ×ξ̃ ) | X, Z, D = 1 for  < i, i−1
=0 ξ = 1), for
174
i = 1, . . . , J ,
and
(e-3b) Pr(Ai = 1 | X, Z, D = 1 for  < i, ξi ,
i = 1, . . . , J .

i−1

=0 ξ

= 1) depends on ξi , for

at stage . Observed Y is
Y =



D Y .

∈{R,A,Acc,1e,1c,...,J e,J c}


Randomization can be administered at any stage. We write ξ = 0 if −1
j =1 ξj = 1 and a person is randomized
out at stage .
173 Assumption (PI-3) is crucial in justifying this formula. If randomization alters agent choice behavior,
persons who would choose j but get randomized out at k, k < j , might change their valuations and decision
rule (i.e., there may be randomization bias).
174 The special case where ξ ≡ 1 satisfies (e-3a), because in that case ξ is a constant.
J
i

5072

J.J. Heckman and E.J. Vytlacil

These expressions assume that the components of Ỹ = (Y0 , . . . , YJ ) that are realized
are known to the randomizer after the dropout decision is made, and thus cannot enter
the conditioning set for the sequential randomizations.
To fix ideas, consider a randomization of eligibility ξ0 , setting ξ1 = · · · = ξJ = 1.
This is a randomization that makes people eligible for participation at all stages of
the program. We investigate what this randomization identifies, assuming invariance
conditions (PI-3) and (PI-4) hold. For those declared eligible,
E(Y | ξ0 = 1) =

J


E(Yj | Dj = 1) Pr(Dj = 1).

(9.4)

j =0

For those declared ineligible,
E(Y | ξ0 = 0) =

J


E(Y0 | Dj = 1) Pr(Dj = 1),

(9.5)

j =0

since agents cannot participate in any stage of the program and are all in the state “0”
with outcome Y0 . From observed choice behavior, we can identify each of the components of (9.4). We observe Pr(Dj = 1) from observed choices of treatment, and we
observe E(Yj | Dj = 1) from observed outcomes for each treatment choice. Except for
the choice probabilities (Pr(Dj = 1), j = 0, . . . , J ) and E(Y0 | D0 = 1), we cannot
identify individual components of (9.5) for J > 1. When J = 1, we can identify all
of the components of (9.5). The individual components of (9.5) cannot, without further
assumptions, be identified by the experiment, although the sum can be. Comparing the
treatment group with the control group, we obtain the “intention to treat” parameter
with respect to the randomization of ξ0 alone, setting ξ1 = · · · = ξJ = 1 for anyone for
whom ξ0 = 1,
E(Y | ξ0 = 1) − E(Y | ξ0 = 0) =

J


E(Yj − Y0 | Dj = 1) Pr(Dj = 1).

(9.6)

j =1

For J > 1, this simple experimental estimator does not identify the effect of full
participation in the program for those who participate (E(YJ − Y0 | DJ = 1)) unless
additional assumptions are invoked, such as the assumption that partial participation has
the same mean effect as full participation for persons who drop out at the early stages,
i.e., E(Yj − Y0 | Dj = 1) = E(YJ − Y0 | Dj = 1) for all j . This assumption might be
appropriate if just getting into the program is all that matters – a pure signaling effect.
A second set of conditions for identification of this parameter is that E(Yj − Y0 |
Dj = 1) = 0 for all j < J . Under those conditions, if we divide the mean difference
by Pr(DJ = 1), we obtain the “Bloom” estimator [Mallar, Kerachsky and Thorton
(1980), Bloom (1984)]
IVBloom =

E(Y | ξ0 = 1) − E(Y | ξ0 = 0)
,
Pr(DJ = 1)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5073

assuming Pr(DJ = 1) = 0. This is an IV estimator using ξ0 as the instrument for AJ .
In general, the mean difference between the treated and the controlled identifies only
the composite term shown in (9.6). In this case, the simple randomization estimator
identifies a not-so-simple or easily interpreted parameter.

More generally, if we randomize persons out after completing stage k ([ k−1
ξ ](1 −
J =0 
ξk ) = 1) and for another group establish full eligibility at all stages ( =0 ξ = 1), we
obtain
%
$
 k−1 
%
$
J
,
,
ξ = 1 − E Y
ξ (1 − ξk ) = 1
E Y
=0

=

J


=0

E(Yj − Yk | Dj = 1) Pr(Dj = 1),

j =k

and hence, since we know E(Yk | Dk = 1) and Pr(Dk = 1) from observational data,
we can identify the combination of parameters
J


E(Yk | Dj = 1) Pr(Dj = 1),

(9.7)

j =k+1

for each randomization that stops persons from advancing beyond level k, k = 0, . . . ,
J − 1.
Observe that a randomization
 −2 of eligibility that prevents people from going to stage
J − 1 but not to stage J ([ J=0
ξ ](1 − ξJ −1 ) = 1) identifies E(YJ − YJ −1 | DJ = 1):
E(Y | ξ0 = 1, . . . , ξJ −2 = 1, ξJ −1 = 0)
%
$ J −1

E(Yj | Dj = 1) Pr(Dj = 1) + E(YJ −1 | DJ = 1) Pr(DJ = 1).
=
j =0

Thus,
E(Y | ξ0 = 1, . . . , ξJ = 1) − E(Y | ξ0 = 1, . . . , ξJ −1 = 1, ξJ = 0)
= E(YJ − YJ −1 | DJ = 1) Pr(DJ = 1).
Since Pr(DJ = 1) is observed from choice data, as is E(YJ | DJ = 1), we can identify
E(YJ −1 | DJ = 1) from the experiment.
In the general case under assumptions (PI-3) and (PI-4), a randomization that prevents
agents from moving beyond stage  (ξ0 = 1, . . . , ξ−1 = 1, ξ = 0) directly identifies
E(Y | ξ0 = 1, . . . , ξ−1 = 1, ξ = 0)
=



j =0



E(Yj | Dj = 1) Pr(Dj = 1)




all components known from observational data

5074

J.J. Heckman and E.J. Vytlacil
J


+

j =+1



E(Y | Dj = 1) Pr(Dj = 1)


.



sum and probability weights known, but not individual E(Y |Dj =1)

All of the components of the first set of terms on the right-hand side are known from
observational data. The probabilities in the second set of terms are known, but the individual conditional expectations E(Y | Dj = 1), j =  + 1, . . . , J , are not known
without further assumptions.
Randomization at stage  is an IV. To show this, decompose the observed outcome
Y into components associated with each value of Aj , the indicator associated with observing a stage j outcome:
Y =

J


Aj Yj .

j =0

We can interpret ξ as an instrument for A . Keeping the conditioning on X, Z implicit,
we obtain
E[Y | ξ = 0] − E[Y | ξ = 1]
Pr(A = 1 | ξ = 0) − Pr(A = 1 | ξ = 1)
J
j =+1 E[Y − Yj | Dj = 1] Pr(Dj = 1)
=
,
J
j =+1 Pr(Dj = 1)

IVξ =

 = 0, . . . , J − 1.

By the preceding analysis, we know the numerator term but not the individual components. We know the denominator from choices measured in observational data and
invariance assumption (PI-3). The IV formalism is less helpful in the general case.
Table 13 summarizes the parameters or combinations of parameters that can be identified from randomizations performed at different stages. It presents the array of factual
and counterfactual conditional mean outcomes E(Yj | D = 1), j = 0, . . . , J and
 = 0, . . . , J . The conditional mean outcomes obtained from observational data are on
the diagonal of the table (E(Yj | Dj = 1), j = 0, . . . , J ). Because of choices of agents,
experiments do not directly identify the elements in the table that are above the diagonal. Under assumptions (PI-3) and (PI-4), experiments described at the base of the table
identify the combinations of the parameters below the diagonal. Recall that if ξ = 0,
the agent cannot advance beyond stage .175 If we randomly deny eligibility to move
to J (ξJ −1 = 0), we point identify E(YJ −1 | DJ = 1), as well as the parameters that can
be obtained from observational data. In general, we can only identify the combinations
of parameters shown at the base of the table. Following Balke and Pearl (1997), Manski
(1989, 1990, 1996, 2003), and Robins (1989), we can use the identified combinations

175 This definition of ξ assumes that ξ = · · · = ξ

0
−1 = 1.

Ch. 71:

Choice
probabilities
(known)

Choice

Pr(D0 = 1)
Pr(D1 = 1)
Pr(D2 = 1)
..
.
Pr(Dj = 1)
..
.
Pr(DJ −1 = 1)
Pr(DJ = 1)

D0
D1
D2
..
.
Dj
..
.
DJ −1
DJ

Randomization
New identified
combinations of
parameters

Outcome
Y0

Y1

· · · Yj

· · · YJ −1

YJ

E(Y0 | D0 = 1)
E(Y0 | D1 = 1)
E(Y0 | D2 = 1)
..
.
E(Y0 | Dj = 1)
..
.
E(Y0 | DJ −1 = 1)
E(Y0 | DJ = 1)

E(Y1 | D0 = 1)
E(Y1 | D1 = 1)
E(Y1 | D2 = 1)
..
.
E(Y1 | Dj = 1)
..
.
E(Y1 | DJ −1 = 1)
E(Y1 | DJ = 1)

· · · E(Yj | D0 = 1)
· · · E(Yj | D1 = 1)
· · · E(Yj | D2 = 1)
..
.
· · · E(Yj | Dj = 1)
..
.
· · · E(Yj | DJ −1 = 1)
· · · E(Yj | DJ = 1)

· · · E(YJ −1 | D0 = 1)
· · · E(YJ −1 | D1 = 1)
· · · E(YJ −1 | D2 = 1)
..
.
· · · E(YJ −1 | Dj = 1)
..
.
· · · E(YJ −1 | DJ −1 = 1)
· · · E(YJ −1 | DJ = 1)

E(YJ | D0 = 1)
E(YJ | D1 = 1)
E(YJ | D2 = 1)
..
.
E(YJ | Dj = 1)
..
.
E(YJ | DJ −1 = 1)
E(YJ | DJ = 1)

ξ0 = 0
ξ1 = 0
· · · ξj = 0
· · · ξJ −1 = 0
J
J
J
·
· · E(YJ −1 | DJ = 1)
{E(Y
|
D
=
1)
{E(Y
|
D
=
1)
{E(Y
|
D
=
1)
·
·
·
j



0
1
=1
=2
=j +1
× Pr(D = 1)}
× Pr(D = 1)}
× Pr(D = 1)}

Econometric Evaluation of Social Programs, Part II

Table 13
Parameters and combinations of parameters that can be identified by different randomizations

ξJ = 0

5075

5076

J.J. Heckman and E.J. Vytlacil

from different randomizations to bound the admissible values of counterfactuals below
the diagonal of Table 13.
Heckman, Smith and Taber (1998) present a test for a strengthened version of the
identifying assumptions made by Bloom.176 They perform a sensitivity analysis to
analyze departures from the assumption that dropouts have the same outcomes as nonparticipants. Hotz, Mullin and Sanders (1997) apply the Manski bounds in carefully
executed empirical examples and show the difficulties involved in using the Bloom estimator in experiments with multiple outcomes. We next turn to some evidence on the
importance of randomization bias.
9.6. Evidence on randomization bias
Violations of assumption (PI-3) in the general case with essential heterogeneity affect
the interpretation of the outputs of social experiments. They are manifestations of a more
general problem termed “Hawthorne effects” that arise from observing any population
[see Campbell and Stanley (1963), Cook and Campbell (1979)]. How important is this
theoretical possibility in practice? Surprisingly, very little is known about the answer to
this question for the social experiments conducted in economics. This is so because randomized social experimentation has usually only been implemented on “pilot projects”
or “demonstration projects” designed to evaluate new programs never previously estimated. Disruption by randomization cannot be confirmed or denied using data from
these experiments. In one ongoing program evaluated by randomization by the Manpower Demonstration Research Corporation (MDRC), participation was compulsory
for the target population [Doolittle and Traeger (1990)]. Hence randomization did not
affect applicant pools or assessments of applicant eligibility by program administrators.
There is some information on the importance of randomization, although it is indirect.
In the 1980s, the US Department of Labor financed a large-scale experimental evaluation of the ongoing, large-scale manpower training program authorized under the Job
Training Partnership Act (JTPA). A study by Doolittle and Traeger (1990) gives some
indirect information from which it is possible to determine whether randomization bias
was present in an ongoing program.177 Job training in the United States is organized
through geographically decentralized centers. These centers receive incentive payments
for placing unemployed persons and persons on welfare in “high-paying” jobs. The participation of centers in the experiment was not compulsory. Funds were set aside to
compensate job centers for the administrative costs of participating in the experiment.
The funds set aside range from 5 percent to 10 percent of the total operating costs of the
centers.
In attempting to enroll geographically dispersed sites, MDRC experienced a training
center refusal rate in excess of 90 percent. The reasons for refusal to participate are
176 They show how to test Bloom’s identifying assumption when it is made for distributions rather than just
means.
177 Hotz (1992) summarizes and extends their discussion.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5077

Table 14
Percentage of local JTPA agencies citing specific concerns about participating in the experiment
Concern

1. Ethical and public relations implications of:
a. Random assignment in social programs
b. Denial of services to controls
2. Potential negative effect of creation of a control group on achievement
of client recruitment goals
3. Potential negative impact on performance standards
4. Implementation of the study when service providers do intake
5. Objections of service providers to the study
6. Potential staff administrative burden
7. Possible lack of support by elected officials
8. Legality of random assignment and possible grievances
9. Procedures for providing controls with referrals to other services
10. Special recruitment problems for out-of-school youth
Sample size: 228

Percentage of training centers
citing the concern

61.8
54.4
47.8
25.4
21.1
17.5
16.2
15.8
14.5
14.0
10.5

Notes: Concerns noted by fewer than 5 percent of the training centers are not listed. Percentages add up to
more than 100.0 because training centers could raise more than one concern.
Source: Based on responses of 228 local JTPA agencies contacted about possible participation in the National
JTPA Study.
Source: Heckman (1992), based on Doolittle and Traeger (1990).

given in Table 14. (The reasons stated there are not mutually exclusive.) Leading the
list are ethical and public relations objections to randomization. Major fears (items 2
and 3) were expressed about the effects of randomization on the quality of applicant
pool, which would impede the profitability of the training centers. By randomizing,
the centers had to widen the available pool of persons deemed eligible, and there was
great concern about the effects of this widening on applicant quality – precisely the
behavior ruled out by assumptions (PI-3) and (PI-4). In attempting to entice centers to
participate, MDRC had to reduce the randomized rejection probability from 12 to as low
as 16 for certain centers. The resulting reduction in the size of the control group impairs
the power of statistical tests designed to test the null hypothesis of no program effect.
Compensation for participation was expanded sevenfold in order to get any centers to
participate in the experiment. The MDRC analysts conclude:
Implementing a complex random assignment research design in an ongoing program providing a variety of services does inevitably change its operation in some
ways. The most likely difference arising from a random assignment field study of
program impacts is a change in the mix of clients served. Expanded recruitment
efforts, needed to generate the control group, draw in additional applicants who
are not identical to the people previously served. A second likely change is that the

5078

J.J. Heckman and E.J. Vytlacil

treatment categories may somewhat restrict program staff’s flexibility to change
service recommendations [Doolittle and Traeger (1990), p. 121].
These authors go on to note that
Some [training centers] because of severe recruitment problems or up-front services cannot implement the type of random assignment model needed to answer
the various impact questions without major changes in procedures [Doolittle and
Traeger (1990), p. 123].
This indirect evidence is hardly decisive even about the JTPA experiment, much less
all experiments. Training centers may offer these arguments only as a means of avoiding administrative scrutiny, and there may be no “real” effect of randomization. During
the JTPA experiment conducted at Corpus Christi, Texas, center administrators successfully petitioned the government of Texas for a waiver of its performance standards on
the ground that the experiment disrupted center operations. Self-selection likely guarantees that participant sites are the least likely sites to suffer disruption. Such a selective
participation in the experiment calls into question the validity of experimental estimates
as a statement about the JTPA system as a whole, as it clearly poses a threat to external validity – problem P-2 as defined in Chapter 70. Torp et al. (1993) report similar
problems in a randomized evaluation of a job training program in Norway.
Kramer and Shapiro (1984) note that subjects in drug trials were less likely to participate in randomized trials than in nonexperimental studies. They discuss one study of
drugs administered to children afflicted with a disease. The study had two components.
The nonexperimental phase of the study had a 4 percent refusal rate, while 34 percent
of a subsample of the same parents refused to participate in a randomized subtrial, although the treatments were equally nonthreatening.
These authors cite further evidence suggesting that refusal to participate in randomization schemes is selective. In a study of treatment of adults with cirrhosis, no effect
of the treatment was found for participants in a randomized trial. But the death rates for
those randomized out of the treatment were substantially lower than among those individuals who refused to participate in the experiment, despite the fact that both groups
were administered the same alternative treatment. Part of any convincing identification
strategy by randomization requires that the agent document the absence of randomization bias. We next consider some evidence on the importance of dropping out and
noncompliance with experimental protocols.
9.7. Evidence on dropping out and substitution bias
Dropouts are a feature of all social programs. Randomization may raise dropout rates,
but the evidence for such effects is weak.178 In addition, most social programs have good
substitutes, so that the estimated effect of a program as typically estimated has to be
178 See Heckman, LaLonde and Smith (1999).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5079

defined relative to the full range of substitute activities in which nonparticipants engage.
Experiments exacerbate this problem by creating a pool of persons who attempt to take
training who then flock to substitute programs when they are placed in an experimental
control group (ξ = 0 in the simple randomization analyzed in Sections 9.1–9.4).
Table 15 [reproduced from Heckman et al. (2000)] demonstrates the practical importance of both dropout and substitution bias in experimental evaluations. It reports
the rates of treatment group dropout and control group substitution from a variety of
social experiments. It reveals that the fraction of treatment group members receiving
program services is often less than 0.7, and sometimes less than 0.5. Furthermore, the
observed characteristics of the treatment group members who drop out often differ from
those who remain and receive the program services.179 With regard to substitution bias,
Table 15 shows that as many as 40% of the controls in some experiments received substitute services elsewhere. In a simple one treatment experiment with full compliance
(ξ = 1 ⇒ A = 1 and ξ = 0 ⇒ A = 0), all individuals assigned to the treatment group
receive the treatment and there is no control group substitution, so that the difference
between the fraction of treatments and controls that receive the treatment equals 1.0. In
practice, this difference is often well below 1.0. Randomization reduced and delayed receipt of training in the experimental control group but by no means eliminated it. Many
of the treatment group members received no treatment.
The extent of both substitution and dropout depends on the characteristics of the treatment being evaluated and the local program environment. In the NSW study, where the
treatment was relatively unique and of high enough quality to be clearly perceived as
valuable by participants, dropout and substitution rates were low enough to approximate
the ideal case. In contrast, for the NJS and for other programs that provide low cost services widely available from other sources, substitution and dropout rates are high. In
the NJS, the substitution problem is accentuated by the fact that the program relied on
outside vendors to provide most of its training. Many of these vendors, such as community colleges, provided the same training to the general public, often with subsidies
from other government programs such as Pell Grants. In addition, in order to help in
recruiting sites to participate in the NJS, evaluators allowed them to provide control
group members with a list of alternative training providers in the community. Of the 16
sites in the NJS, 14 took advantage of this opportunity to alert control group members
to substitute training opportunities.
There are counterpart findings in the application of randomized clinical trials. For
example, Palca (1989) notes that AIDS patients denied potentially life-saving drugs
took steps to undo random assignment. Patients had the pills they were taking tested
to see if they were getting a placebo or an unsatisfactory treatment, and were likely to
drop out of the experiment in either case or to seek more effective medication, or both.
In the MDRC experiment, in some sites qualified trainees found alternative avenues for
securing exactly the same training presented by the same subcontractors by using other

179 For the NSW shown in this table, see LaLonde (1984). For the NJS data, see Smith (1992).

5080

J.J. Heckman and E.J. Vytlacil

Table 15
Fraction of experimental treatment and control groups receiving services in experimental evaluations of employment and training programs
Study

Authors/time period

Target group(s)

Fraction of
treatments
receiving
services

Fraction of
controls
receiving
services

1. NSW

Hollister et al. (1984)
(9 months after RA)

0.95
NA
NA

0.11
0.03
0.04

2. SWIM

Friedlander and
Hamilton (1993)
(Time period not
reported)

Long-term AFDC women
Ex-addicts
17–20 year old high
school dropouts
AFDC women: applicants
and recipients
a. Job search assistance
b. Work experience
c. Classroom training/OJT
d. Any activity
AFDC-U unemployed
fathers
a. Job search assistance
b. Work experience
c. Classroom training/OJT
d. Any activity
Youth high school
dropouts
Classroom training/OJT
AFDC women: applicants
and recipients
a. Job search assistance
b. Classroom training/OJT
c. Any activity
Teenage single mothers
Any education services
Any training services
Any education or training
Self-reported from survey
data
Adult males
Adult females
Male youth
Female youth

0.54
0.21
0.39
0.69

0.01
0.01
0.21
0.30

0.60
0.21
0.34
0.70

0.01
0.01
0.22
0.23

0.90

0.26

0.43
0.42
0.64

0.19
0.31
0.40

0.82
0.26
0.87

0.48
0.15
0.55

0.38
0.51
0.50
0.81

0.24
0.33
0.32
0.42

0.74
0.78
0.81
0.81

0.25
0.34
0.34
0.42

3. JOBSTART

Cave et al. (1993)
(12 months after RA)

4. Project
Independence

Kemple et al. (1995)
(24 months after RA)

5. New chance

6. National JTPA Study

Quint et al. (1994)
(18 months after RA)

Heckman and Smith
(1998)
(18 months after RA)

Combined Administrative Survey Data
Adult males
Adult females
Male youth
Female youth

(Continued on next page)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5081

Table 15
(Continued)
Notes: RA = random assignment. H.S. = high school. AFDC = Aid to Families with Dependent Children.
OJT=On the Job Training.
Service receipt includes any employment and training services. The services received by the controls in the
NSW study are CETA and WIN jobs. For the Long Term AFDC Women, this measure also includes regular
public sector employment during the period.
Sources for data: Maynard and Brown (1980), p. 169, Table A14; Masters and Maynard (1981), p. 148,
Table A.15; Friedlander and Hamilton (1993), p. 22, Table 3.1; Cave et al. (1993), p. 95, Table 4.1; Quint
et al. (1994), p. 110, Table 4.9; and Kemple et al. (1995), p. 58, Table 3.5; Heckman and Smith (1998) and
calculations by the authors.
Source: Heckman, LaLonde and Smith (1999) and Heckman et al. (2000).

methods of financial support. Heckman, LaLonde and Smith (1999) discuss a variety of
other problems that sometimes plague social experiments.
Our discussion up to this point has focused on point identification of parameters
over the empirical supports. A large and emerging literature produces bounds on the
parameters and distributions when point identification is not possible. We now consider
bounds on the parameters within the framework of economic models of choice and the
MTE.

10. Bounding and sensitivity analysis
Thus far we have assumed full support conditions and have presented conditions for
identification over those supports. We now consider partial identification in the context of the MTE framework. We return to the two-outcome model to develop the basic
approach in a simpler setting.
The central evaluation problem is that we observe the distribution of (Y, D, X, Z) =
(DY1 +(1−D)Y0 , D, X, Z), but do not observe the distribution of all of the components
that comprise it (Y1 , Y0 , D, X, Z). Let η denote a distribution for (Y1 , Y0 , D, X, Z),
and let it be known that η belongs to the class H ⊂ F , where F is the space of all
probability distributions on (Y1 , Y0 , D, X, Z). Let Pη denote the resulting distribution
of (DY1 + (1 − D)Y0 , D, X, Z) if η is the distribution for (Y1 , Y0 , D, X, Z). Let η0
and Pη0 denote the corresponding true distributions. Knowledge of the distribution of
(DY1 + (1 − D)Y0 , D, X, Z) allows us to infer that η lies in the set {η ∈ H: Pη = Pη0 }.
All elements of {η ∈ H: Pη = Pη0 } are consistent with the true distribution of the
observed data.
Let H0 = {η ∈ H: Pη = Pη0 }. Let Eη denote expectation with respect to the
measure η, i.e., Eη (A) = A dη, so that E(A) = Eη0 (A). Consider inference for ATE,
E(Y1 − Y0 ). Knowledge of the distribution of the observed variables allows us to infer
that


E(Y1 − Y0 ) ∈ Eη (Y1 − Y0 ): η ∈ H0 .

5082

J.J. Heckman and E.J. Vytlacil

The identification analyses of the previous sections proceed by imposing sufficient restrictions on H such that {Eη (Y1 − Y0 ): η ∈ H0 } contains only one element and
thus E(Y1 − Y0 ) is point identified. Bounding analysis proceeds by finding a set B
such that B ⊇ {Eη (Y1 − Y0 ): η ∈ H0 }.180 One goal of bounding analysis is to construct B such that B = {Eη (Y1 − Y0 ): η ∈ H0 } in which case the bounds are said
to be sharp. If the bounds are sharp, then the bounds exploit all information and no
smaller bounds can be constructed without imposing additional structure. In contrast, if
{Eη (Y1 − Y0 ): η ∈ H0 } is a proper subset of B, then smaller bounds can be constructed.
In every example we consider, the set {Eη (Y1 − Y0 ): η ∈ H0 } is a closed interval, so
that {Eη (Y1 − Y0 ): η ∈ H0 } = [infη∈H0 Eη (Y1 − Y0 ), supη∈H0 Eη (Y1 − Y0 )].
Sensitivity analysis is a commonly used procedure. It varies the parameters fixed in
a model and determines the sensitivity of estimates to the perturbations of the parameter. Sensitivity analysis is formally equivalent to bounding. In particular, in sensitivity
analysis, one parameterizes η and then constructs bounds based on letting the parameters vary over some set.181 Parameterize η as η(θ) for some parameter vector θ ∈ Θ, and
let θ 0 be the “true” parameter value so that η0 = η(θ 0 ). θ is typically finite-dimensional,
though it need not be. Let Θ 0 = {θ ∈ Θ: Pη(θ) = Pη(θ 0 ) }. If θ is point identified given
the observed variables, then Θ 0 will contain only one element, but if not all parameters are identified given the observed data then Θ will contain more than one element.
Consider


Eη(θ) (Y1 − Y0 ): θ ∈ Θ 0 .
This can trivially be seen as a special case of bounding analysis by taking H =
{η(θ): θ ∈ Θ} and H0 = {η(θ): θ ∈ Θ 0 }. Likewise, by taking a proper parameterization, any bounding analysis can be seen as a special case of sensitivity analysis.
We consider bounds on ATE. The corresponding bounds on treatment on the treated
follow with trivial modifications.182 We focus on bounds that exploit instrumental variable type assumptions or latent index assumptions, and we do not attempt to survey
the entire literature on bounds.183 We begin by describing the bounds that only assume
that the outcome variables are bounded. We then consider imposing additional assumptions. We consider imposing the assumption of comparative advantage in the decision

180 Examples of bounding analysis include Balke and Pearl (1997), Heckman, Smith and Clements (1997),
Manski (1989, 1990, 1997, 2003) and Robins (1989).
181 Examples of sensitivity analysis include Glynn, Laird and Rubin (1986), Smith and Welch (1986), and
Rosenbaum (1995).
182 We do not consider bounds on the joint distribution of (Y , Y ). Identification of the joint distribution
1 0
of (Y1 , Y0 ) is substantially more difficult than identification of the ATE or treatment on the treated (TT).
For example, even a perfect randomized experiment does not point identify the joint distribution of (Y1 , Y0 )
without further assumptions. See Heckman and Smith (1993), Heckman, Smith and Clements (1997), and
Heckman, LaLonde and Smith (1999) for an analysis of this problem.
183 Surveys of the bounding approach include Manski (1995, 2003). Heckman, LaLonde and Smith (1999)
includes an alternative survey of the bounding approach.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5083

rule, then consider instead imposing an instrumental variables type assumption, and
conclude by considering the combination of comparative advantage and instrumental
variables assumptions. We examine the relative power of these alternative assumptions
to narrow the very wide bounds that result from only imposing that the outcome variables are bounded.
10.1. Outcome is bounded
We first consider bounds on E(Y1 −Y0 ) that only assume that the outcomes be bounded.
We consider this case as a point of contrast for the later bounds that exploit instrumental variable conditions, and also for the pedagogical purpose of showing the bounding
methodology in a simple context. We impose that the outcomes are bounded with probability 1.
A SSUMPTION B (Outcome is Bounded). For j = 0, 1,


Pr y l  Yj  y u = 1.184
In our notation, this corresponds to






H = η ∈ F : η y l  Y1  y u = 1, η y l  Y0  y u = 1 .
For example, if Y is an indicator variable, then the bounds are y l = 0 and y u = 1.
Following Manski (1989) and Robins (1989), use the law of iterated expectations to
obtain


E(Y1 ) = Pr[D = 1]E(Y1 | D = 1) + 1 − Pr[D = 1] E(Y1 | D = 0),


E(Y0 ) = Pr[D = 1]E(Y0 | D = 1) + 1 − Pr[D = 1] E(Y0 | D = 0).
Pr[D = 1], E(Y1 | D = 1), and E(Y0 | D = 0) are identified, while E(Y0 | D = 1)
and E(Y1 | D = 0) are bounded by y l and y u , so that


Pr[D = 1]E(Y1 | D = 1) + 1 − Pr[D = 1] y l


 E(Y1 )  Pr[D = 1]E(Y1 | D = 1) + 1 − Pr[D = 1] y u ,


Pr[D = 1]y l + 1 − Pr[D = 1] E(Y0 | D = 0)


 E(Y0 )  Pr[D = 1]y u + 1 − Pr[D = 1] E(Y0 | D = 0)

184 We assume that Y and Y have the same bounds for ease of exposition. The modifications required to
1
0
analyze the more general case are straightforward.

5084

J.J. Heckman and E.J. Vytlacil

and thus


B = B L, B U ,
with


 
B L = Pr[D = 1]E(Y | D = 1) + 1 − Pr[D = 1] y l




− Pr[D = 1]y u + 1 − Pr[D = 1] E(Y | D = 0) ,


 
B U = Pr[D = 1]E(Y | D = 1) + 1 − Pr[D = 1] y u




− Pr[D = 1]y l + 1 − Pr[D = 1] E(Y | D = 0)
with the width of these bounds given by
BU − BL = yu − yl .
For example, if Y = 0, 1, then the width of the bounds equals 1, B U − B L = 1.
These bounds are sharp. To show this, for any M ∈ [B L , B U ], one can trivially
construct a distribution η of (Y0 , Y1 , D) which is consistent with the observed data,
consistent with the restriction that the outcomes are bounded, and for which Eη (Y1 −
Y0 ) = M, thus showing that M ∈ [B L , B U ]. Since this is true for any M ∈ [B L , B U ],
it follows that [B L , B U ] ⊆ {Eη (Y1 − Y0 ): η ∈ H0 }. Since we have already shown that
[B L , B U ] are valid bounds, [B L , B U ] ⊇ {Eη (Y1 − Y0 ): η ∈ H0 }, we conclude that
[B L , B U ] = {Eη (Y1 − Y0 ): η ∈ H0 } and thus that the bounds are sharp. This illustrates
a common technique towards the construction of sharp bounds: in a first step, construct
a natural set of bounds, and in a second step, use a proof by construction to show that
the bounds are sharp.
Note the following features of these bounds. First, as noted by Manski (1990), these
bounds always include zero. Thus, bounds that only exploit that the outcomes are
bounded can never reject the null of zero average treatment effect. The bounds themselves depend on the data, but the width of the bounds, B U −B L = y u −y l , is completely
driven by the assumed bounds on Y1 , Y0 . For example, if Y1 and Y0 are binary, the width
of the bounds is always 1.
10.2. Latent index model: Roy model
The bounds that only impose that the outcomes are bounded are typically very wide,
never provide point identification, and can never reject the null of zero average treatment
effect. This lack of identifying power raises the question of whether one can impose additional structure to narrow the bounds. The central issue with bounding analysis is to
explore the trade-off between assumptions and width of the resulting bounds. In this
section, we discuss bounds that follow from maintaining Assumption B, that the outcomes are bounded, but also add the assumption of a Roy model for selection into

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5085

treatment.185 Such an assumption substantially narrows the width of the bounds compared to only imposing that the outcomes themselves are bounded, but does not provide
point identification.
Again impose Assumption B: the outcomes are bounded. In addition, assume a model
of comparative advantage, in particular,
A SSUMPTION RM (Roy Model).
D = 1[Y1  Y0 ].

(10.1)

Restriction RM imposes a special case of a latent index model, D = 1[Y ∗  0] with
= Y1 − Y0 . Using the assumption of a Roy model while maintaining the assumption
that the outcomes are bounded, we can narrow the bounds compared to the case where
we only imposed that the outcomes are bounded. Peterson (1976) constructs the sharp
bounds for the competing risks model, which is formally equivalent to a Roy model.
Manski (1995) constructs the same bounds for the Roy model.
Following Peterson (1976) and Manski (1995), we have that

Y∗

E[Y1 | D = 1] = E[Y1 | Y0  Y1 ]
 E[Y0 | Y0  Y1 ]
= E[Y0 | D = 1]
and by a parallel argument, E[Y0 | D = 0]  E[Y1 | D = 0]. We thus have upper
bounds on E(Y0 | D = 1) and E(Y1 | D = 0). The lower bounds on E[Y0 | D = 1]
and E[Y1 | D = 0] are the same as for the bounds that only imposed that the outcomes
are bounded. We then have


E(Y1 − Y0 ) ∈ B ≡ B L , B U ,
with


 
B L = Pr[D = 1]E(Y | D = 1) + 1 − Pr[D = 1] y l




− Pr[D = 1]E(Y | D = 1) + 1 − Pr[D = 1] E(Y | D = 0) ,




B U = Pr[D = 1]E(Y | D = 1) + 1 − Pr[D = 1] E(Y | D = 0)




− Pr[D = 1]y l + 1 − Pr[D = 1] E(Y | D = 0) ,
185 In contrast to the comparative advantage Roy model, one could instead impose an absolute advantage
model as in the bounding analysis of Smith and Welch (1986). They assume that those with D = 1 have
an absolute advantage over those with D = 0 in terms of their Y1 outcomes: 12 E(Y1 | D = 1)  E(Y1 |
D = 0)  E(Y1 | D = 1), and use this assumption to bound E(Y1 ). In their application, Y1 is the wage
and D is an indicator variable for working, so that there is not a well defined Y0 variable. However, if one
were to adapt their idea of absolute advantage to the treatment effect literature, one could assume, e.g., that
E(Y0 | D = 0)  E(Y0 | D = 1)  32 E(Y0 | D = 0) with the bounds on ATE following immediately from
these assumptions.

5086

J.J. Heckman and E.J. Vytlacil

and we can rewrite these bounds as



B L = 1 − Pr[D = 1] y l − E(Y | D = 0) ,


B U = Pr[D = 1] E(Y | D = 1) − y l ,
with the width of the bounds given by
B U − B L = E(Y ) − y l .
For example, if Y = 0, 1, then the width of the bounds is given by B U − B L = Pr(Y =
1). Following an argument similar to that presented in the previous section, one can
show that these bounds are sharp.
Note the following features of these bounds. First, the bounds do not involve y u , and
actually the same bounds will hold if we were to weaken the maintained assumption
that Pr[y l  Yj  y u ] = 1 for j = 0, 1, to instead only require that Pr[y l  Yj ] = 1.
The width of the bounds imposing comparative advantage are E(Y ) − y l , so that the
bounds will never provide point identification (as long as E(Y ) > y l ). For example, if Y
is binary, the width of the bounds is Pr[Y = 1], the bounds will not provide point identification unless all individuals have Y = 0. However, the bounds will always improve
upon the bounds that impose only that the outcome is bounded – imposing comparative
advantage shrinks the width of the bounds from y u − y l to E(Y ) − y l , thus shrinking the
bounds by an amount equal to y u − E(Y ). For example, if Y is binary, then imposing
the bounds shrinks the width of the bounds from 1 to Pr[Y = 1]. Finally, note that the
bounds will always include zero, so that imposing comparative advantage does not by
itself allow one to ever reject the null of zero average treatment effect.
10.3. Bounds that exploit an instrument
The previous section considered bounds that exploit knowledge of the selection process,
in particular that selection is determined by a Roy model. An alternative way to narrow
the bounds over simply imposing that the outcome is bounded is to assume access to
an instrument. We now discuss bounds with various types of instrumental variables
assumptions. We begin with the Manski (1990) analysis for bounds that exploit a meanindependence condition, then consider the Balke and Pearl (1997) analysis for bounds
that exploit a full statistical independence condition, and finally conclude with a discussion of Heckman and Vytlacil (1999) who combine an instrumental variable assumption
with a nonparametric selection model.
10.3.1. Instrumental variables: Mean independence condition
Again impose Assumption B so that the outcomes are bounded. In addition, following
Manski (1990), impose a mean-independence assumption:

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5087

A SSUMPTION IV.
E(Y1 | Z = z) = E(Y1 ),
E(Y0 | Z = z) = E(Y0 )
for z ∈ Z where Z denotes the support of the distribution of Z.
For any z ∈ Z, following the exact same series of steps as for the bounds that only
imposed Assumption B, we have that


E(DY | Z = z) + 1 − P (z) y l  E(Y1 | Z = z)


 E(DY | Z = z) + 1 − P (z) y u .
By the IV assumption, we have E(Y1 | Z = z) = E(Y1 ). Since these bounds hold for
any z ∈ Z, we have


 
sup E(DY | Z = z) + 1 − P (z) y l
z∈Z



 
 E(Y1 )  inf E(DY | Z = z) + 1 − P (z) y u .
z∈Z

Applying the same analysis for E(Y0 ), we have


E(Y1 − Y0 ) ∈ B = B L , B U ,
with


 
B L = sup E(DY | Z = z) + 1 − P (z) y l
z∈Z

BU

 


− inf E (1 − D)Y Z = z + P (z)y u ,
z∈Z


 
= inf E(DY | Z = z) + 1 − P (z) y u
z∈Z
 


− sup E (1 − D)Y Z = z + P (z)y l .
z∈Z

As discussed by Manski (1994), these bounds are sharp under the mean-independence
condition.186 As noted by Manski (1990), these bounds do not necessarily include zero,
so that it may be possible to use the bounds to test the null of zero average treatment
effect. Let p u = supz∈Z Pr[D = 1 | Z = z], p l = infz∈Z Pr[D = 1 | Z = z]. A trivial
modification to Corollaries 1 and 2 of Proposition 6 of Manski (1994) shows that
(1) pu  12 and p l  12 is a necessary condition for B L = B U , i.e., for point
identification from the mean independence condition.

186 See Manski and Pepper (2000) for extensions of these bounds.

5088

J.J. Heckman and E.J. Vytlacil

(2) If Y1 , Y0 are independent of D, then the width of the IV-bounds is
((1 − p u ) + p l )(y u − y l ). Thus, if Y1 , Y0 are independent of D, the bounds
will collapse to point identification if and only if p u = 1, p l = 0.
Note that it is neither necessary nor sufficient for P (z) to be a nontrivial function
of z for these bounds to improve upon the bounds that only imposed that the outcome
is bounded. Likewise, comparing these bounds to the comparative advantage bounds
shows that neither set of bounds will in general be narrower than the other. Finally, note
that these bounds are relatively complicated, and to evaluate the bounds and the width
of the bounds requires use of P (z), E(Y D | Z = z), and E(Y (1 − D) | Z = z) for all
z ∈ Z.
10.3.2. Instrumental variables: Statistical independence condition
While Manski constructs sharp bounds for mean-independence conditions, Balke and
Pearl (1997) construct sharp bounds for the statistical independence condition for the
case where Y and Z are binary. Balke and Pearl impose the same independence condition as the Imbens and Angrist (1994) LATE independence condition. In particular, let
D0 , D1 denote the counterfactual choices that would have been made had Z been set
exogenously to 0 and 1, respectively, and impose the following assumption.
A SSUMPTION IV-BP.
(Y0 , Y1 , D0 , D1 ) ⊥
⊥ Z.
Note that this strengthens the Manski conditions not only in imposing that potential
outcomes are statistically independent of Z instead of mean-independent of Z, but also
imposing that the counterfactual choices are independent of Z.
For the case of Z and Y binary, Balke and Pearl manage to transform the problem
of constructing sharp bounds into a linear programming problem. Assuming that the
identified set is a closed interval, the sharp bounds are by definition [B L , B U ] with
B L = inf Eη (Y1 − Y0 ),
η∈H0

B U = sup Eη (Y1 − Y0 ).
η∈H0

In general, the constrained set of distributions, η ∈ H0 , may be high-dimensional and
nonconvex. Using the assumption that Z and Y are binary, they transform the problem
into the minimization of a linear function over a finite-dimensional vector space subject
to a set of linear constraints. The resulting bounds are somewhat complex. For some distributions of the observed data, they will coincide with the Manski mean-independence
bounds, but for other distributions of the observed data they will be narrower than the
Manski mean-independence bounds. Thus, imposing statistical independence does narrow the bounds over the mean independence bounds.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5089

It is not immediately clear how to generalize the Balke and Pearl analysis to distributions with continuous Z or Y , or how to construct sharp bounds under the statistical
independence condition for Z or Y continuous. The appropriate generalization of Balke
and Pearl’s analysis to a more general setting remains an open question.
10.3.3. Instrumental variables: Nonparametric selection model/LATE conditions
We started with the mean independence version of the instrumental variables condition,
and then discussed strengthening the instrumental variables condition to full independence in the special case where Y and Z are binary. The result of shifting from mean
independence to full independence is to sometimes reduce the width of the resulting bounds but also to have an even more complicated form for the bounds. We now
consider further strengthening the instrumental variables either by imposing a nonparametric selection model for the first stage as in Heckman and Vytlacil (1999) or
by imposing instrumental variable conditions of the form considered by Imbens and
Angrist (1994). The sharp bounds corresponding to these strengthened versions of instrumental variables do not reduce the bounds compared to imposing a weaker form of
the instrumental variables assumption but produces a much simpler form for the bounds.
Let D(z) denote the counterfactual choices that would have been made had Z been set
exogenously to z. Consider the LATE independence, rank, and monotonicity conditions
(IV-1), (IV-2), (IV-3), respectively, of Imbens and Angrist (1994) presented in Sections 2
and 4.
Note that the LATE monotonicity assumption (IV-3) strengthens assumption [IV-BP].
The LATE independence assumption (IV-1) is exactly the same as assumption [IV-BP]
except that the assumption is stated here without requiring Z to be binary. In their
context of binary Z and Y , Balke and Pearl discuss the LATE monotonicity condition and show that the LATE monotonicity condition imposes constraints on the
observed data which imply that the Balke and Pearl (1997) bounds and the Manski
mean-independence bounds will coincide.187
Consider the nonparametric selection model of Heckman and Vytlacil (1999):
N ONPARAMETRIC S ELECTION M ODEL S. D = 1[μ(Z)  U ] and Z ⊥
⊥ (Y0 , Y1 , U ).
This is a consequence of Equations (3.3) and assumptions (A-1)–(A-5) presented in
Section 4.
From Vytlacil (2002), we have that the Imbens and Angrist conditions (IV-1)–(IV-3)
are equivalent to imposing a nonparametric selection model of the form S. Thus, the
bounds derived under one set of assumptions will be valid under the alternative set of
assumptions, and bounds that are sharp under one set will be sharp under the alternative

187 Robins (1989) constructs the same bounds under the LATE condition for the case of Z and Y binary,
though he does not prove that the bounds are sharp.

5090

J.J. Heckman and E.J. Vytlacil

set of assumptions. This equivalence implies that the Balke and Pearl result also holds
for the selection model: if Z and Y are binary, then the sharp bounds under the nonparametric selection model coincide with the sharp bounds under mean independence IV.
We now consider the more general case where neither Z nor Y need be binary.
Heckman and Vytlacil (1999) derived bounds on the average treatment effect under
the assumptions that the outcomes are generated from a bounded outcome nonparametric selection model for treatment without requiring that Z or Y be binary or any other
restrictions on the support of the distributions of Z and Y beyond the assumption that
the outcomes are bounded (Assumption B). In particular, they derived the following
bounds on the average treatment effect:
B L  E(Y1 − Y0 )  B U ,
with
 


B U = E DY P (Z) = pu + 1 − p u y u


− E (1 − D)Y P (Z) = pl − p l y l ,
 



B L = E DY P (Z) = pu + 1 − p u y l − E (1 − D)Y


P (Z) = p l − p l y u .

Note that these bounds do not necessarily include zero. The width of the bounds is




B U − B L = 1 − pu + pl y u − y l .
For example, if Y is binary then the width of the bounds is simply B U − B L = ((1 −
p u ) + p l ). Trivially, p u = 1 and p l = 0 is necessary and sufficient for the bounds
to collapse to point identification, with the width of the bounds linearly related to the
distance between p u and 1 and the distance between p l and 0. Note that it is necessary
and sufficient for P (z) to be a nontrivial function of z for these bounds to improve upon
the bounds that only imposed that the outcomes are bounded. Evaluating the width of
the bounds only requires p u , p l . The only additional information required to evaluate
the bounds themselves is E(DY | P (Z) = pu ) and E((1 − D)Y | P (Z) = p l ).
Heckman and Vytlacil (2001a) analyze how these bounds compare to the Manski
(1990) mean independence bounds, and analyze whether these bounds are sharp. They
show that the selection model imposes restrictions on the observed data such that the
Manski (1990) mean independence bounds collapse to the simpler Heckman and Vytlacil (2001a) bounds. In particular, given assumption S, they show that


 

 

inf E(DY | Z = z) + 1 − P (z) y u = E DY P (Z) = pu + 1 − p u y u ,
z∈Z
 




sup E (1 − D)Y Z = z + P (z)y l = E (1 − D)Y P (Z) = pl − p l y l
z∈Z

and thus the Manski (1990) upper bound collapses to the Heckman and Vytlacil (1999)
upper bound under assumption S. The parallel result holds for the lower bounds. Furthermore, Heckman and Vytlacil (2001a) establish that the Heckman and Vytlacil
(1999) bounds are sharp given Assumptions B and S. Thus, somewhat surprisingly,

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5091

imposing the stronger assumption of the existence of an instrument in a nonparametric
selection model does not narrow the bounds compared to the case of imposing only the
weaker assumption of mean independence, but does impose structure on the data which
substantially simplifies the form of the mean-independence bounds. By the Vytlacil
(2002) equivalence result, the same conclusion holds for the LATE assumptions – imposing the LATE assumptions does not narrow the bounds compared to only imposing
the weaker assumption of mean independence, but does impose restrictions on the data
that substantially simplify the form of the bounds. Vytlacil, Santos and Shaikh (2005)
extend these bounds.
10.4. Combining comparative advantage and instrumental variables
We have thus far examined bounds that impose a comparative advantage model, and
bounds that exploit an instrumental variables assumption. In general, neither restriction
has more identifying power than the other. We now consider combining both types of
assumptions.
⊥ (Y0 , Y1 ). This is a Roy
Assume D = 1[Y1 − Y0  C(Z)], with Z observed and Z ⊥
model with a cost C(Z) of treatment, with the cost of treatment a function of an “instrument” Z. For ease of exposition, assume that Z is a continuous scalar random variable
and that (Y0 , Y1 ) are continuous random variables.188 Also for ease of exposition, assume that Z (the support of the distribution Z) is compact and that C(·) is a continuous
function. These assumptions are only imposed for ease of exposition.
The model is a special case of the nonparametric selection model considered by
Heckman and Vytlacil (2001a), but with more structure that we can now exploit. Begin by following steps similar to Heckman and Vytlacil (2001a). Using the fact that
⊥ (Y0 , Y1 ), we have
D = 1[Y1 − Y0  C(Z)] and that Z ⊥


P (Z) = 1 − FY1 −Y0 C(Z) ,
where FY1 −Y0 is the distribution function of Y1 − Y0 . Given our assumptions, we have
that there will exist zu and zl such that


 
C zu = sup C(z): z ∈ Z ,
  


 
P zu = 1 − FY1 −Y0 C zu = inf P (Z): z ∈ Z ,
 


C zl = inf C(z): z ∈ Z ,
 
  


P zl = 1 − FY1 −Y0 C zl = sup P (Z): z ∈ Z .
In other words, Z = zu is associated with the highest possible cost of treatment and
thus the lowest possible conditional probability of D = 1, while Z = zl is associated
with the lowest possible cost of treatment and thus the highest possible conditional
188 More formally, impose that the distribution of Z has a density with respect to Lebesgue measure on R,
and assume that (Y1 , Y0 ) has a density with respect to Lebesgue measure on R2 .

5092

J.J. Heckman and E.J. Vytlacil

probability of D = 1. Since P (·) for z ∈ Z is identified, we have that zu and zl are
identified.
Consider identification of C(z). Using the model and the independence assumptions,
we have
∂
E(Y | Z = z)
∂z

∂ 
∂
E(Y D | Z = z) + E Y (1 − D) Z = z
=
∂z
∂z
∞
∂
=
E(Y1 | Y1 − Y0 = t) dFY1 −Y0 (t)
∂z C(z)
C(z)
∂
E(Y0 | Y1 − Y0 = t) dFY1 −Y0 (t)
+
∂z −∞





 
= − E Y1 Y1 − Y0 = C(z) − E Y0 Y1 − Y0 = C(z) fY1 −Y0 C(z) C (z)


= −C(z)C (z)fY1 −Y0 C(z)

and
∞

∂
∂
P (z) =
∂z
∂z

dFY1 −Y0 (t)


= −C (z)fY1 −Y0 C(z)
C(z)

and thus
(∂
∂
E(Y | Z = z)
P (z) = C(z)
∂z
∂z
∂
for any z ∈ Z such that ∂z
P (z) = 0, i.e., for any z ∈ Z such that C (z) = 0 and
FY1 −Y0 (C(z)) = 0. We thus conclude that C(z) is identified for z ∈ Z.
Our goal is to identify E(Y1 − Y0 ). For any z ∈ Z, we have by the law of iterated
expectations that

E(Yj ) =
=

E(Yj | Y1 − Y0 = t) dFY1 −Y0 (t)
C(z)
−∞

+

E(Yj | Y1 − Y0 = t) dFY1 −Y0 (t)

∞

C(z)

E(Yj | Y1 − Y0 = t) dFY1 −Y0 (t)

for j = 0, 1. Using the model for D and the assumption that Z ⊥
⊥ (Y0 , Y1 ), we have
∞

E(Y1 | Y1 − Y0 = t) dFY1 −Y0 (t) = E(DY | Z = z),

C(z)
C(z)
−∞


E(Y0 | Y1 − Y0 = t) dFY1 −Y0 (t) = E (1 − D)Y


Z=z .

(10.2)
(10.3)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5093

We identify the right-hand sides of these equations for any z ∈ Z, and thus identify
the left-hand sides for any z ∈ Z. In particular, consider evaluating Equation (10.2) at
z = zl and Equation (10.3) at z = zu . Then, to bound E(Y1 − Y0 ), we need to bound
C(zl )
−∞ E(Y1

| Y1 − Y0 = t) dFY1 −Y0 (t) and

∞
C(zu ) E(Y0

| Y1 − Y0 = t) dFY1 −Y0 (t).

We have

C(zl )
−∞

E(Y1 | Y1 − Y0 = t) dFY1 −Y0 (t)

 

  
= 1 − P zl E Y1 Z = zl , Y1  Y0 + C zl

  
 
 
 1 − P zl E Y0 + C zl Z = zl , Y1  Y0 + C zl

 
   
= E (1 − D)Y Z = zl + 1 − P zl C zl

(∂ 


∂
E(Y | Z = z)
ln 1 − P (z)
= E (1 − D)Y Z = zl −
∂z
∂z

,
z=zl

where the inequality arises from the conditioning Y1  Y0 + C(zl ). The final expression
follows from our derivation of C(z). Since Pr[y l  Y1  y u ] = 1 by assumption, we
have

 
1 − P zl y l


C(zl )
−∞

E(Y1 | Y1 − Y0 = t) dFY1 −Y0 (t)


 E (1 − D)Y


Z = zl −

(∂ 

∂
E(Y | Z = z)
ln 1 − P (z)
∂z
∂z

.
z=zl

By a parallel argument, we have
 
P zu y l 

∞
C(zu )

E(Y0 | Y1 − Y0 = t) dFY1 −Y0 (t)


 E DY


Z = zu +

(∂
∂
E(Y | Z = z)
ln P (z)
∂z
∂z

We thus have the bounds
B L  E(Y1 − Y0 )  B U ,
with

BU = E Y

Z = zl



(∂ 

∂
E(Y | Z = z)
ln 1 − P (z)
∂z
∂z

 

− E (1 − D)Y Z = zu − P zu y l ,

−

z=zl

.
z=zu

5094

J.J. Heckman and E.J. Vytlacil

 
 

Z = zl + 1 − P zl y l − E Y
(∂
∂
.
E(Y | Z = z)
ln P (z)
−
∂z
∂z
z=zu


B L = E DY

Z = zu



The last two terms in B U come from the lower bound for E(Y0 ) and the first two terms
come from the upper bound for E(Y1 ) just derived. The terms for B L are decomposed
in an analogous fashion, reversing the roles of the upper and lower bounds for E(Y1 )
and E(Y0 ). These bounds improve over the bounds that only impose a nonparametric
selection model (Assumption S) without imposing the Roy model structure. We next
consider some alternative approaches to the solution of selection and hence evaluation
problems developed in the literature using replacement functions, proxy functions, and
other conditions.

11. Control functions, replacement functions, and proxy variables
This chapter analyzes the main tools used to evaluate social programs in the presence
of selection bias in observational data. Yet many other tools have not been analyzed.
We briefly summarize these approaches. Chapter 73 (Matzkin) of this Handbook establishes conditions under which some of the methods we discuss produce identification of
econometric models. Abbring and Heckman (Chapter 72) use some of these tools.
The methods of replacement functions and proxy variables all start from characterizations (U-1) and (U-2) which we repeat for convenience:
(U-1) (Y0 , Y1 ) ⊥
⊥ D | X, Z, θ ,
but

⊥ D | X, Z,
(U-2) (Y0 , Y1 ) ⊥
where θ is not observed by the analyst and (Y0 , Y1 ) are not observed directly but Y is
observed as are the X, Z:
Y = DY1 + (1 − D)Y0 .
Missing variables θ produce selection bias which creates a problem with using observational data to evaluate social programs. From (U-1), if we condition on θ, we would
satisfy the condition (M-1) for matching, and hence could identify the parameters and
distributions that can be identified if the conditions required for matching are satisfied.
The most direct approach to controlling for θ is to assume access to a function
τ (X, Z, Q) that perfectly proxies θ :
θ = τ (X, Z, Q).

(11.1)

This approach based on a perfect proxy is called the method of replacement functions by
Heckman and Robb (1985a). In (U-1), we can substitute for θ in terms of observables

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5095

(X, Z, Q). Then
(Y0 , Y1 ) ⊥
⊥ D | X, Z, Q.
We can condition nonparametrically on (X, Z, Q) and do not have to know the exact
functional form of τ , although knowledge of τ might reduce the dimensionality of the
matching problem, θ can be a vector and τ can be a vector of functions. This method has
been used in the economics of education for decades [see the references in Heckman
and Robb (1985a)]. If θ is ability and τ is a test score, it is sometimes assumed that
the test score is a perfect proxy (or replacement function) for θ and τ is entered into
the regressions of earnings on schooling to escape the problem of ability bias, typically
assuming a linear relationship between τ and θ .189 Heckman and Robb (1985a) discuss
the literature that uses replacement functions in this way. Olley and Pakes (1996) apply
this method and consider nonparametric identification of the τ function. Chapter 73
(Matzkin) of this Handbook provides a rigorous proof of identification for this approach
in a general nonparametric setting.
The method of replacement functions assumes that (11.1) is a perfect proxy. In many
applications, this assumption is far too strong. More often, we measure θ with error. This
produces a factor model or measurement error model [Aigner et al. (1984)]. Chapter 73
(Matzkin) of this Handbook surveys this method. We can represent the factor model in
a general way by a system of equations:
Yj = gj (X, Z, Q, θ, εj ),

j = 1, . . . , J.

(11.2)

A linear factor model separable in the unobservables writes
Yj = gj (X, Z, Q) + λj θ + εj ,

j = 1, . . . , J,

(11.3)

j = 1, . . . , J,

(11.4)

where
(X, Z, Q) ⊥
⊥ (θ, εj ),

εj ⊥
⊥ θ,

and the εj are mutually independent. Observe that under (11.2) and (11.3), Yj controlling for X, Z, Q only imperfectly proxies θ because of the presence of εj . The θ
are called factors, λj factor loadings and the εj “uniquenesses” [see, e.g., Aigner et al.
(1984)].
A large literature, partially reviewed in Abbring and Heckman (Chapter 72), Section 1, and in Chapter 73 (Matzkin) of this Handbook, shows how to establish identification of econometric models under factor structure assumptions. Cunha, Heckman

189 Thus if τ = α + α X + α Q + α Z + θ , we can write
0
1
2
3

θ = τ − α0 − α1 X − α2 Q − α3 Z,
and use this as the proxy function. Controlling for τ, X, Q, Z controls for θ . Notice that we do not need to
know the coefficients (α0 , α1 , α2 , α3 ) to implement the method. We can condition on X, Q, Z.

5096

J.J. Heckman and E.J. Vytlacil

and Matzkin (2003), Schennach (2004) and Hu and Schennach (2006) establish identification in nonlinear models of the form (11.2).190 The key to identification is multiple,
but imperfect (because of εj ), measurements on θ from the Yj , j = 1, . . . , J , and
X, Z, Q, and possibly other measurement systems that depend on θ . Carneiro, Hansen
and Heckman (2003), Cunha, Heckman and Navarro (2005, 2006) and Cunha and Heckman (2008, 2007) apply and develop these methods. Under assumption (11.4), they
show how to nonparametrically identify the econometric model and the distributions of
the unobservables Fθ (θ ) and Fεj (εj ). In the context of classical simultaneous equations
models, identification is secured by using covariance restrictions across equations exploiting the low dimensionality of vector θ compared to the high-dimensional vector of
(imperfect) measurements on it. The recent literature [Cunha, Heckman and Matzkin
(2003), Hu and Schennach (2006), Cunha, Heckman and Schennach (2006b)] extends
the linear model to a nonlinear setting.
The recent econometric literature applies in special cases the idea of the control function principle introduced in Heckman and Robb (1985a). This principle, versions of
which can be traced back to Telser (1964), partitions θ in (U-1) into two or more components, θ = (θ1 , θ2 ), where only one component of θ is the source of bias. Thus it is
assumed that (U-1) is true, and (U-1) is also true:
⊥ D | X, Z, θ1 ,
(U-1) (Y0 , Y1 ) ⊥
and (U-2) holds. For example, in the normal selection model analyzed in Chapter 70,
Section 9, we broke U1 , the error term associated with Y1 , into two components:
U1 = E(U1 | V ) + ε,
where V plays the role of θ1 and arises from the choice equation. Under normality, ε is
independent of E(U1 | V ). Further,
E(U1 | V ) =

Cov(U1 , V )
V,
Var(V )

(11.5)

assuming E(U1 ) = 0 and E(V ) = 0. In that section, we show how to construct a control
function in the context of the choice model


D = 1 μD (Z)  V .
Controlling for V controls for the component of θ1 in (U-1) that gives rise to the spurious dependence. The Blundell and Powell (2003, 2004) application of the control
function principle assumes functional form (11.5) but assumes that V can be perfectly
proxied by a first stage equation. Thus they use a replacement function in their first
stage. Their method does not work when one can only condition on D rather than on

190 Cunha, Heckman and Schennach (2007, 2006b) apply and extend this approach to a dynamic factor
setting where the θt are time-dependent.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5097

D ∗ = μD (Z) − V .191 In the sample selection model, it is not necessary to use V . As
developed in Chapter 70 and reviewed in Sections 4.8 and 8.3.1 of this chapter, under
additive separability for the outcome equation for Y1 , we can write


E(Y1 | X, Z, D = 1) = μ1 (X) + E U1 μD (Z)  V



control function

so we “expect out” rather than solve out the effect of the component of V on U1 and thus
control for selection bias under our maintained assumptions. In terms of the propensity
score, under the conditions specified in Chapter 70, we may write the preceding expression in terms of P (Z):


E(Y1 | X, Z, D = 1) = μ1 (X) + K1 P (Z) ,
where K1 (P (Z)) = E(U1 | X, Z, D = 1). It is not necessary to know V or be able
to estimate it. The Blundell and Powell (2003, 2004) application of the control function
principle assumes that the analyst can condition on and estimate V .
The Blundell–Powell method and the method of Imbens and Newey (2002) build
heavily on (11.5) and implicitly make strong distributional and functional form assumptions that are not intrinsic to the method of control functions. As just noted, their method
uses a replacement function to obtain E(U1 | V ) in the first step of their procedures. The
general control function method does not require a replacement function approach. The
literature has begun to distinguish between the more general control function approach
and the control variate approach that uses a first stage replacement function.
Matzkin (2003) develops the method of unobservable instruments which is a version
of the replacement function approach applied to nonlinear models. Her unobservable
instruments play the role of covariance restrictions used to identify classical simultaneous equations models [see Fisher (1966)]. Her approach is distinct from and therefore
complementary with linear factor models. Instead of assuming (X, Z, Q) ⊥
⊥ (θ, εj ),
⊥ Y2 | Y1 , X, Z. See the discussion
she assumes in a two equation system that (θ, ε1 ) ⊥
in Chapter 73 (Matzkin) of this Handbook.
We have not discussed panel data methods in this chapter. The most commonly
used panel data method is difference-in-differences as discussed in Heckman and Robb
(1985a), Blundell, Duncan and Meghir (1998), Heckman, LaLonde and Smith (1999),
and Bertrand, Duflo and Mullainathan (2004), to cite only a few key papers. Most of
the estimators we have discussed can be adapted to a panel data setting. Heckman et
al. (1998) develop difference-in-differences matching estimators. Abadie (2002) extends this work.192 Separability between errors and observables is a key feature of the
panel data approach in its standard application. Altonji and Matzkin (2005) and Matzkin
(2003) present analyses of nonseparable panel data methods.
191 Imbens and Newey (2002) extend their approach. See the discussion in Chapter 73 (Matzkin) of this
Handbook.
192 There is related work by Athey and Imbens (2006).

5098

J.J. Heckman and E.J. Vytlacil

12. Summary
This chapter summarizes the main methods used to identify mean treatment effect
parameters under semiparametric and nonparametric assumptions. We have used the
marginal treatment effect as the unifying parameter to straddle a diverse econometric
literature summarized in Table 1 of this chapter. For each estimator, we establish what
it identifies, the economic content of the estimand and the identifying assumptions of
the method.

Appendix A: Relationships among parameters using the index structure
Given the index structure, a simple relationship exists among the parameters. It is immediate from the definitions D = 1(UD  P (z)) and  = Y1 − Y0 that




TT x, P (z) = E  X = x, UD  P (z) .
(A.1)
Next consider LATE (x, P (z), P (z )). Note that


E Y X = x, P (Z) = P (z)
 

= P (z) E Y1 X = x, P (Z) = P (z), D = 1


 
+ 1 − P (z) E Y0 X = x, P (Z) = P (z), D = 0
P (z)

=

E(Y1 | X = x, UD = uD ) duD

0

+

1

E(Y0 | X = x, UD = uD ) duD ,

P (z)

so that


E Y



X = x, P (Z) = P (z) − E Y
P (z)

=


X = x, P (Z) = P (z )

E(Y1 | X = x, UD = uD ) duD

P (z )
P (z)

−

E(Y0 | X = x, UD = uD ) duD ,

P (z )

and thus





LATE x, P (z), P (z ) = E  X = x, P (z )  UD  P (z) .

Notice that this expression could be taken as an alternative definition of LATE. Note
that, in this expression, we could replace P (z) and P (z ) with uD and uD . No instrument
needs to be available to define LATE.
We can rewrite these relationships in succinct form in the following way:
MTE (x, uD ) = E( | X = x, UD = uD ),

Ch. 71:

Econometric Evaluation of Social Programs, Part II
1

ATE (x) =

5099

E( | X = x, UD = uD ) duD ,

0




P (z) TT x, P (z) =

P (z)

E( | X = x, UD = uD ) duD ,

0





P (z) − P (z ) LATE x, P (z), P (z )
=

P (z)

E( | X = x, UD = uD ) duD .

(A.2)

P (z )

We stress that everywhere in these expressions we can replace P (z) with uD and P (z )
with uD . Each parameter is an average value of MTE, E( | X = x, UD = uD ),
but for values of UD lying in different intervals and with different weighting functions. MTE defines the treatment effect more finely than do LATE, ATE, or TT. The
relationship between MTE and LATE or TT conditional on P (z) is analogous to the relationship between a probability density function and a cumulative distribution function.
The probability density function and the cumulative distribution function represent the
same information, but for some purposes the density function is more easily interpreted.
Likewise, knowledge of TT for all P (z) evaluation points is equivalent to knowledge of
the MTE for all uD evaluation points, so it is not the case that knowledge of one provides more information than knowledge of the other. However, in many choice-theoretic
contexts it is often easier to interpret MTE than the TT or LATE parameters. It has the
interpretation as a measure of willingness to pay on the part of people on a specified
margin of participation in the program.
MTE (x, uD ) is the average effect for people who are just indifferent between participation in the program (D = 1) or not (D = 0) if the instrument is externally set
so that P (Z) = uD . For values of uD close to zero, MTE (x, uD ) is the average effect
for individuals with unobservable characteristics that make them the most inclined to
participate in the program (D = 1), and for values of uD close to one it is the average
treatment effect for individuals with unobserved (by the econometrician) characteristics
that make them the least inclined to participate. ATE integrates MTE (x, uD ) over the
entire support of UD (from uD = 0 to uD = 1). It is the average effect for an individual
chosen at random from the entire population. TT (x, P (z)) is the average treatment
effect for persons who chose to participate at the given value of P (Z) = P (z); it integrates MTE (x, uD ) up to uD = P (z). As a result, it is primarily determined by the
MTE parameter for individuals whose unobserved characteristics make them the most
inclined to participate in the program. LATE is the average treatment effect for someone who would not participate if P (Z)  P (z ) and would participate if P (Z)  P (z).
The parameter LATE (x, P (z), P (z )) integrates MTE (x, uD ) from uD = P (z ) to
uD = P (z).
Using the third expression in Equation (A.2) to substitute into Equation (A.1), we
obtain an alternative expression for the TT parameter as a weighted average of MTE

5100

J.J. Heckman and E.J. Vytlacil

parameters:
TT (x)
1

=
0

1
p

p

E( | X = x, UD = uD ) duD dFP (Z)|X,D (p|x, D = 1).

0

Using Bayes’ rule, it follows that
dFP (Z)|X,D (p | x, 1) =

Pr(D = 1 | X = x, P (Z) = p)
dFP (Z)|X (p|x).
Pr(D = 1 | X = x)

Since Pr(D = 1 | X = x, P (Z) = p) = p, it follows that
TT (x) =

1
Pr(D = 1 | X = x)

1
p
E( | X = x, UD = uD ) duD dFP (Z)|X (p|x).
×
0

(A.3)

0
1

Note further that since Pr(D = 1 | X = x) = E(P (Z) | X = x) = 0 (1 −
FP (Z)|X (t|x)) dt, we can reinterpret (A.3) as a weighted average of local IV parameters where the weighting is similar to that obtained from a length-biased, size-biased, or
P -biased sample:
TT (x) =
×
0

=

1
Pr(D = 1 | X = x)

1
1
1(uD  p)E( | X = x, UD = uD ) duD dFP (Z)|X (p|x)
0

1
(1 − FP (Z)|X (t|x)) dt

1
1
E( | X = x, UD = uD )1(uD  p) dFP (Z)|X (p|x) duD
×
0

1

=
0

1

=

0



1 − FP (Z)|X (uD |x)
E( | X = x, UD = uD )
duD
(1 − FP (Z)|X (t|x)) dt
E( | X = x, UD = uD )gx (uD ) duD ,

0

where
gx (uD ) =

1 − FP (Z)|X (uD |x)
.
(1 − FP (Z)|X (t|x)) dt

Thus gx (uD ) is a weighted distribution [Rao (1985)]. Since gx (uD ) is a nonincreasing
function of uD , we have that drawings from gx (uD ) oversample persons with low values of UD , i.e., values of unobserved characteristics that make them the most likely to

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5101

Figure A.1. MTE integrates to ATE and TT under full support (for dichotomous outcome). Source: Heckman
and Vytlacil (2000).

participate in the program no matter what their value of P (Z). Since
MTE (x, uD ) = E( | X = x, UD = uD )
it follows that
1

TT (x) =

MTE (x, uD )gx (uD ) duD .

0

The TT parameter is thus a weighted version of MTE, where MTE (x, uD ) is given the
largest weight for low uD values and is given zero weight for uD  pxmax , where pxmax
is the maximum value in the support of P (Z) conditional on X = x.
Figure A.1 graphs the relationship between MTE (uD ), ATE and TT (P (z)), assuming that the gains are the greatest for those with the lowest UD values and that the
gains decline as UD increases. The curve is the MTE parameter as a function of uD , and
is drawn for the special case where the outcome variable is binary so that MTE parameter is bounded between −1 and 1. The ATE parameter averages MTE (uD ) over the
full unit interval (i.e., is the area under A minus the area under B and C in the figure).
TT (P (z)) averages MTE (uD ) up to the point P (z) (is the area under A minus the
area under B in the figure). Because MTE (uD ) is assumed to be declining in uD , the
TT parameter for any given P (z) evaluation point is larger then the ATE parameter.
Equation (A.2) relates each of the other parameters to the MTE parameter. One can
also relate each of the other parameters to the LATE parameter. This relationship turns
out to be useful later on in this chapter when we encounter conditions where LATE can

5102

J.J. Heckman and E.J. Vytlacil

be identified but MTE cannot. MTE is the limit form of LATE:
MTE (x, p) = lim LATE (x, p, p ).
p →p

Direct relationships between LATE and the other parameters are easily derived. The
relationship between LATE and ATE is immediate:
ATE (x) = LATE (x, 0, 1).
Using Bayes’ rule, the relationship between LATE and TT is
1

TT (x) =

LATE (x, 0, p)

0

p
dFP (Z)|X (p|x).
Pr(D = 1 | X = x)

(A.4)

Appendix B: Relaxing additive separability and independence
There are two central assumptions that underlie the latent index representation used in
this chapter: that V is independent of Z, and that V and Z are additively separable in the
index.193 The latent index model with these two restrictions implies the independence
and monotonicity assumptions of Imbens and Angrist (1994) and the latent index model
implied by those assumptions implies a latent index model with a representation that
satisfies both the independence and the monotonicity assumptions. In this appendix, we
consider the sensitivity of the analysis presented in the text to relaxation of either of
these assumptions.
First, consider allowing V and Z to be nonseparable in the treatment index:
D ∗ = μD (Z, V ),

1 if D ∗  0,
D=
0 otherwise,
while maintaining the assumption that Z is independent of (V , U1 , U0 ). We do not
impose any restrictions on the cross partials of μD . The monotonicity condition of
Imbens and Angrist (1994) is that for any (z, z ) pair, μD (z, v)  μD (z , v) for all v,
or μD (z, v)  μD (z , v) for all v.194 Vytlacil (2002) shows that monotonicity always
implies one representation of μD as μD (z, v) = μD (z) + v. We now reconsider the
analysis in the text without imposing the monotonicity condition by considering the
latent index model without additive separability. Since we have imposed no structure
on the μD (z, v) index, one can easily show that this model is equivalent to imposing the independence condition of Imbens and Angrist (1994) without imposing their

193 Recall that U = F
D
V |X (V ).
194 Note that the monotonicity condition is a restriction across v. For a given fixed v, it will always trivially

have to be the case that either μD (z, v)  μD (z , v) or μD (z, v)  μD (z , v).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5103

monotonicity condition. A random coefficient discrete choice model with μD = Zγ +ε
where γ and ε are random, and γ can assume positive or negative values is an example
of this case, i.e., V = (γ , ε).
We impose the regularity condition that, for any z ∈ Supp(Z), μD (z, V ) is absolutely
continuous with respect to Lebesgue measure.195 Let


Ω(z) = v: μD (z, v)  0 ,
so that


P (z) ≡ Pr(D = 1 | Z = z) = Pr V ∈ Ω(z) .
Under additive separability, P (z) = P (z ) ⇔ Ω(z) = Ω(z ). This equivalence enables
us to define the parameters in terms of the P (z) index instead of the full z vector. In
the more general case without additive separability, it is possible to have (z, z ) such
that P (z) = P (z ) and Ω(z) = Ω(z ). We present a random coefficient choice model
example of this case in Section 4.10.1 in the text. In this case, we can no longer replace
Z = z with P (Z) = P (z) in the conditioning sets.
Define, using  = Y1 − Y0 ,
MTE (x, v) = E( | X = x, V = v).
For ATE, we obtain the same expression as before:
ATE (x) =

∞
−∞

E( | X = x, V = v) dFV |X (v).

For TT, we obtain a similar but slightly more complicated expression:
TT (x, z) ≡ E( | X = x, Z = z, D = 1)


= E  X = x, V ∈ Ω(z)
1
=
E( | X = x, V = v) dFV |X (v).
P (z) Ω(z)
Because it is no longer the case that we can define the parameter solely in terms of
P (z) instead of z, it is possible to have (z, z ) such that P (z) = P (z ) but TT (x, z) =
TT (x, z ).
Following the same derivation as used in the text for the TT parameter not conditional
on Z,
TT (x)
≡ E( | X = x, D = 1)
=

E( | X = x, Z = z, D = 1) dFZ|X,D (z|x, 1)

195 We impose this condition to ensure that Pr(μ (z, V ) = 0) = 0 for any z ∈ Supp(Z).
D

5104

J.J. Heckman and E.J. Vytlacil

=

1
Pr(D = 1 | X = x)
∞ 

1 v ∈ Ω(z) E( | X = x, V = v) dFV |X (v) dFZ|X (z|x)
×
−∞

=

=

1
Pr(D = 1 | X = x)
∞


×
1 v ∈ Ω(z) E( | X = x, V = v) dFZ|X (z|x) dFV |X (v)
−∞
∞

−∞

E( | X = x, V = v)gx (v) dv,

where
gx (v) =

1[v ∈ Ω(z)] dFZ|X (z|x)
Pr(D = 1 | V = v, X = x)
=
.
Pr(D = 1 | X = x)
Pr(D = 1 | X = x)

Thus the definitions of the parameters and the relationships among them that are developed in the main text of this chapter generalize in a straightforward way to the
nonseparable case. Separability allows us to define the parameters in terms of P (z) instead of z and allows for slightly simpler expressions, but is not crucial for the definition
of parameters or the relationship among them.
Separability is, however, crucial to the form of LATE when we allow V and Z to be
additively nonseparable in the treatment index. For simplicity, we will keep the conditioning on X implicit. Define the following sets


A(z, z ) = v: μD (z, v)  0, μD (z , v)  0 ,


B(z, z ) = v: μD (z, v)  0, μD (z , v) < 0 ,


C(z, z ) = v: μD (z, v) < 0, μD (z , v) < 0 ,


D(z, z ) = v: μD (z, v) < 0, μD (z , v)  0 .
Monotonicity implies that either B(z, z ) or D(z, z ) is empty. Suppressing the z, z
arguments, we have
E(Y | Z = z) = Pr(A ∪ B)E(Y1 | A ∪ B) + Pr(C ∪ D)E(Y0 | C ∪ D),
E(Y | Z = z ) = Pr(A ∪ D)E(Y1 | A ∪ D) + Pr(B ∪ C)E(Y0 | B ∪ C)
so that
E(Y | Z = z) − E(Y | Z = z )
Pr(D = 1 | Z = z) − Pr(D = 1 | Z = z )
E(Y | Z = z) − E(Y | Z = z )
=
Pr(A ∪ B) − Pr(A ∪ D)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5105

Pr(B)E(Y1 − Y0 | B) − Pr(D)E(Y1 − Y0 | D)
Pr(B) − Pr(D)
= wB E( | B) − wD E( | D)
=

with
Pr(B | B ∪ D)
,
Pr(B | B ∪ D) − Pr(D | B ∪ D)
Pr(D | B ∪ D)
.
wD =
Pr(B | B ∪ D) − Pr(D | B ∪ D)
wB =

Under monotonicity, either Pr(B) = 0 and LATE identifies E( | D) or Pr(D) = 0 and
LATE identifies E( | B). Without monotonicity, the IV estimator used as the sample
analogue to LATE converges to the above weighted difference in the two terms, and the
relationship between LATE and the other treatment parameters presented in the text no
longer holds.
Consider what would happen if we could condition on a given v. For v ∈ A ∪ C, the
denominator is zero and the parameter is not well defined. For v ∈ B, the parameter
is E( | V = v), for v ∈ D, the parameter is E( | V = v). If we could restrict
conditioning to v ∈ B (or v ∈ D), we would obtain monotonicity within the restricted
sample.
Now consider LIV. For simplicity, assume z is a scalar. Assume μD (z, v) is continuously differentiable in (z, v), with μj (z, v) denoting the partial derivative with respect
to the j th argument. Assume that μD (Z, V ) is absolutely continuous with respect to
Lebesgue measure. Fix some evaluation point, z0 . One can show that there may be at
most a countable number of v points such that μD (z0 , v) = 0. Let j ∈ J = {1, . . . , L}
index the set of v evaluation points such that μD (z0 , v) = 0, where L may be infinity,
and thus write: μD (z0 , vj ) = 0 for all j ∈ J . (Both the number of such evaluation points and the evaluation points themselves depend on the evaluation point, z0 ,
but we suppress this dependence for notational convenience.) Assume that there ex
1 (z,v )
k
|  Bk for k ∈ J and all z in some
ists {Bk }k∈J , k∈J Bk < ∞ such that | μ
μ2 (z,vk )
neighborhood of z0 . One can show that

∂ 
E(Y | Z = z)
∂z

z=z0

=

L

μ1 (z0 , vk )
E( | V = vk )
|μ2 (z0 , vk )|
k=1

and

∂ 
Pr(D = 1 | Z = z)
∂z

z=z0

=

L

μ1 (z0 , vk )
.
|μ2 (z0 , vk )|
k=1

LIV is the ratio of these two terms, and does not in general equal the MTE. Thus, the
relationship between LIV and MTE breaks down in the nonseparable case.

5106

J.J. Heckman and E.J. Vytlacil
1

μ (z0 ,vk )
As an example, take the case where L is finite and |μ
2 (z ,v )| does not vary with k.
0 k
For this case,


LIV (z0 ) = Pr μ1 (z0 , V ) > 0 μ(z0 , V ) = 0


· E  μD (z0 , V ) = 0, μ1 (z0 , V ) > 0


− Pr μ1 (z0 , V ) < 0 μ(z0 , V ) = 0


· E  μD (z0 , V ) = 0, μ1 (z0 , V ) < 0 .

Thus, while the definition of the parameters and the relationship among them does not
depend crucially on the additive separability assumption, the connection between the
LATE or LIV estimators and the underlying parameters crucially depends on the additive separability assumption.
Next consider the assumption that V and Z are separable in the treatment index while
allowing them to be stochastically dependent:
D ∗ = μD (Z) − V ,

1 if D ∗  0,
D=
0 otherwise,
with Z independent of (U0 , U1 ), but allowing Z and V to be stochastically dependent.
The analysis of Vytlacil (2002) can be easily adapted to show that the latent index
model with separability but without imposing independence is equivalent to imposing
the monotonicity assumption of Imbens and Angrist without imposing their independence assumption.196
We have


Ω(z) = v: μD (z)  v
and


P (z) ≡ Pr(D = 1 | Z = z) = Pr V ∈ Ω(z) Z = z .
Note that Ω(z) = Ω(z ) ⇒ μD (z) = μD (z ), but Ω(z) = Ω(z ) does not imply
P (z) = P (z ) since the distribution of V conditional on Z = z need not equal the
distribution of V conditional on Z = z . Likewise, P (z) = P (z ) does not imply
Ω(z) = Ω(z ). As occurred in the nonseparable case, we can no longer replace Z = z
with P (Z) = P (z) in the conditioning sets.197
196 To show that the monotonicity assumption implies a separable latent index model, one can follow the

proofs of Vytlacil (2002) with the sole modification of replacing P (z) = Pr(D = 1 | Z = z) with
Pr(D(z) = 1), where D(z) is the indicator variable for whether the agent would have received treatment
if Z had been externally set to z.
197 However, we again have equivalence between the alternative conditioning sets if we assume index sufficiency, i.e., that FV |Z (v|z) = FV |P (Z) (v|P (z)).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5107

Consider the definition of the parameters and the relationship among them. The definition of MTE and ATE in no way involves Z, nor does the relationship between them, so
that both their definition and their relationship remains unchanged by allowing Z and V
to be dependent. Now consider the TT parameter where now we make the dependence
of X explicit:


TT (x, z) = E  X = x, Z = z, V  μD (z)
=

1
P (z)

=

1
P (z)

μD (z)
−∞
μD (z)
−∞

E( | X = x, V = v) dFV |Z,X (v|z, x)
E( | X = x, V = v)

fZ|V ,X (z|v, x)
dFV |X (v|x),
fZ|X (z|x)

where fZ|X and fZ|V ,X denote the densities corresponding to FZ|X and FZ|V ,X with
respect to the appropriate dominating measure. We thus obtain


TT (x) = E  X = x, V  μD (Z)
=

μD (z)

1
Pr(D = 1 | X = x)

−∞

×
=

1
Pr(D = 1 | X = x)

∞
−∞

fZ|U,X (z|v, x)
dFV |X (v|x) dFZ|X (z|x)
fZ|X (z|x)


1 v  μD (z) E( | X = x, V = v)
×

=

E( | X = x, V = v)

fZ|U,X (z|v, x)
dFZ|X (z|x) dFV |X (v|x)
fZ|X (z|x)

1
Pr(D = 1 | X = x)
∞


×
1 v  μD (z)
−∞

× E( | X = x, V = v) dFZ|V ,X (z|v, x) dFV |X (v|x)
=

∞
−∞

E( | X = x, V = v)gx (v) dv,

where
gx (v) =

Pr(D = 1 | V = v, X = x)
.
Pr(D = 1 | X = x)

Thus the definitions of parameters and the relationships among the parameters that are
developed in the text generalize naturally to the case where Z and V are stochastically
dependent. Independence (combined with the additive separability assumption) allows
us to define the parameters in terms of P (z) instead of z and allows for slightly simpler

5108

J.J. Heckman and E.J. Vytlacil

expressions, but is not crucial for the definition of parameters or the relationship among
them.
We next investigate LATE when we allow V and Z to be stochastically dependent.
We have
E(Y | X = x, Z = z)


= P (z) E(Y1 | X = x, Z = z, D = 1)



+ 1 − P (z) E(Y0 | X = x, Z = z, D = 0)
=

μD (z)
−∞

+

E(Y1 | X = x, V = v) dFV |X,Z (v|x, z)

∞

μD (z)

E(Y0 | X = x, V = v) dFV |X,Z (v|x, z).

For simplicity, take the case where μD (z) > μD (z ). Then
E(Y | X = x, Z = z) − E(Y | X = x, Z = z )
μD (z)

=
−

E(Y1 | X = x, V = v) dFV |X,Z (v|x, z)

μD (z )
μD (z)
μD (z )

+
+

μD (z )
−∞
∞
μD (z)

E(Y0 | X = x, V = v) dFV |X,Z (v|x, z )


E(Y1 | X = x, V = v) dFV |X,Z (v|x, z) − dFV |X,Z (v|x, z )



E(Y0 | X = x, V = v) dFV |X,Z (v|x, z) − dFV |X,Z (v|x, z )

and thus
LATE (x, z, z )


= δ0 (z)E Y1 X = x, Z = z, μD (z )  V  μD (z)


− δ0 (z )E Y0 X = x, Z = z , μD (z )  V  μD (z)



+ δ1 (z)E Y1 X = x, Z = z, V  μD (z )


− δ1 (z )E Y1 | X = x, Z = z , V  μD (z )



+ δ2 (z)E Y0 X = x, Z = z, V > μD (z)


− δ2 (z )E Y0 X = x, Z = z , V > μD (z) ,
with
Pr(μD (z )  V  μD (z) | Z = t)
,
Pr(V  μD (z) | Z = z, X = x) − Pr(V  μD (z ) | Z = z , X = x)
Pr(V  μD (z ) | Z = t)
δ1 (t) =
,
Pr(V  μD (z) | Z = z, X = x) − Pr(V  μD (z ) | Z = z , X = x)

δ0 (t) =

Ch. 71:

Econometric Evaluation of Social Programs, Part II

δ2 (t) =

5109

Pr(V > μD (z) | Z = t)
.
Pr(V  μD (z) | Z = z, X = x) − Pr(V  μD (z ) | Z = z , X = x)

Note that δ0 (z) = δ0 (z ) = 1 and the two terms in brackets are zero in the case where
Z and V are independent. In the more general case, δ0 may be bigger or smaller than 1,
and the terms in brackets are of unknown sign. In general, LATE may be negative even
when  is positive for all individuals.
Now consider LIV. For simplicity, take the case where Z is a continuous scalar r.v. Let
fV |Z (v|z) denote the density of V conditional on Z = z, and assume that this density is
differentiable in z. Then we obtain
∂E(Y | X = x, Z = z)
∂z




= E  X = x, V = μD (z) μD (z)fV |Z,X v x, μD (z)
$
μD (z)
∂fV |Z,X (v|z, x)
+
dv
E(Y1 | X = x, V = v)
∂z
−∞
%
∞
∂fV |Z,X (v|z, x)
+
dv ,
E(Y0 | X = x, V = v)
∂z
μD (z)
and


∂ Pr(D = 1 | Z = z)
= fV |Z,X v | x, μD (z) μD (z)
∂z
μD (z) ∂f
V |Z,X (v|z, x)
dv.
+
∂z
−∞
LIV is the ratio of the two terms. Thus, without the independence condition, the relationship between LIV and the MTE breaks down.
P ROOF OF E QUATION (4.20).
E(Yp | X)
=

E(Yp | X, V = v, Zp = z) dFV ,Zp |X (v, z)

=


1Ω (z)E(Y1 | X, V = v, Zp = z)


+ 1Ω c (z)E(Y0 | X, V = v, Zp = z) dFV ,Zp |X (v, z)


=
1Ω (z)E(Y1 | X, V = v) + 1Ω c (z)E(Y0 | X, V = v) dFV ,Zp |X (v, z)
=


1Ω (z)E(Y1 | X, V = v)

+ 1Ω c (z)E(Y0 | X, V = v) dFZp |X (z) dFV |X (v)

5110

J.J. Heckman and E.J. Vytlacil

=



Pr[Zp ∈ Ω | X]E(Y1 | X, V = v)



+ 1 − Pr[Zp ∈ Ω(z) | X] E(Y0 | X, V = v) dFV |X (v),

where Ω c (z) denotes the complement of Ω(z) and where the first equality follows
from the law of iterated expectations; the second equality follows by plugging in
our threshold crossing model for D; the third equality follows from independence
Z⊥
⊥ (Y1 , Y0 , V ) | X; the fourth and fifth equalities follow by an application of Fubini’s Theorem and a rearrangement of terms. Fubini’s Theorem may be applied by
assumption (A-4). Thus comparing policy p to policy p , we obtain (4.20):
E(Yp | X) − E(Yp | X)
=



E( | X, V = v) Pr[Zp ∈ Ω | X] − Pr[Zp ∈ Ω | X] dFV |X (v).


P ROOF OF E QUATION (4.21).
E(Yp | X)
=

E(Yp | X, V = v, Zp = z) dFV ,Zp |X (v, z)


1[−∞,μD (z)] (v)E(Y1 | X, Z = z, V = v)

+ 1(μD (z),∞] (v)E(Y0 | X, Z = z, V = v) dFV ,Zp |X (v, z)

=
1[−∞,μD (z)] (v)E(Y1 | X, V = v)

+ 1(μD (z),∞] (v)E(Y0 | X, V = v) dFV ,Zp |X (v, z)

=



1[−∞,μD (z)] (v)E(Y1 | X, V = v)

=


+ 1(μD (z),∞] (v)E(Y0 | X, V = v) dFZp |V (z|v) dFV |X (v)
=



1 − Pr μD (Zp ) < v V = v E(Y1 | X, V = v)



+ Pr μD (Zp ) < v V = v E(Y0 | X, V = v) dFV |X (v),


where the first equality follows from the law of iterated expectations; the second equality
follows by plugging in our model for D; the third equality follows from independence
Z⊥
⊥ (Y1 , Y0 ) | X, V ; the fourth equality follows by an application of Fubini’s Theorem;
and the final equality follows immediately. Thus comparing policy p to policy p , we
obtain (4.21) in the text.


Ch. 71:

Econometric Evaluation of Social Programs, Part II

5111

Appendix C: Derivation of PRTE and implications of noninvariance for PRTE
P ROOF OF E QUATION (3.6). To simplify the notation, assume that Υ (Y ) = Y . Modifications required for the more general case are obvious. Define 1P (t) to be the indicator
function for the event t ∈ P. Then
E(Yp | X)


E Yp X, Pp (Zp ) = t dFPp |X (t)
0
$
1
1
=
1[0,t] (uD )E(Y1,p | X, UD = uD )
1

=

0

0

+ 1(t,1] (uD )E(Y0,p
1

=

$

0

1
0

1[uD ,1] (t)E(Y1,p | X, UD = uD )

+ 1(0,uD ] (t)E(Y0,p
=

%

| X, UD = uD ) duD dFPp |X (t)

%

| X, UD = uD ) dFPp |X (t) duD

1 


1 − FPp |X (uD ) E(Y1,p | X, UD = uD )
0

+ FPp |X (uD )E(Y0,p | X, UD = uD ) duD .198

This derivation involves changing the order of integration. Note that from (A-4),
E 1[0,t] (uD )E(Y1,p | X, UD = uD )



+ 1(t,1] (uD )E(Y0,p | X, UD = uD )  E |Y1 | + |Y0 | < ∞,

so the change in the order of integration is valid by Fubini’s Theorem. Comparing policy p to policy p ,
E(Yp | X) − E(Yp | X)
1

=
0



E( | X, UD = uD ) FPp |X (uD ) − FPp |X (uD ) duD ,

which gives the required weights. (Recall  = Y1 − Y0 and from (A-7) we can drop the
p, p subscripts on outcomes and errors.)


198 Recall that p denotes the policy in this section and t is a value assumed by P (Z).

5112

J.J. Heckman and E.J. Vytlacil

R ELAXING A-7 (Implications of noninvariance for PRTE). Suppose that all of the
assumptions invoked up through Section 3.2 are satisfied, including additive separability in the latent index choice equation (3.3) (equivalently, the monotonicity or
uniformity condition). Impose the normalization that the distribution of UD is unit
uniform (UD = FV |X (V | X)). Suppose however, contrary to (A-7), that the distribution of (Y1 , Y0 , UD , X) is different under the two regimes p and p . Thus, let
(Y1,p , Y0,p , UD,p , Xp ) and (Y1,p , Y0,p , UD,p , Xp ) denote the random vectors under
regimes p and p , respectively. Following the same analysis as used to derive Equation (3.6), the PRTE conditional on X is given by
E(Yp | Xp = x) − E(Yp | Xp = x)
=

1

E(Y1,p − Y0,p | Xp = x, UD,p = u)

× FPp |Xp (u|x) − FPp |Xp (u|x) du
0



1


E(Y0,p | Xp = x, UD,p = u) − E(Y0,p | Xp = x, UD,p = u) du

+

(I)
(II)

0
1 


1 − FPp |Xp (u|x) E(Y1,p − Y0,p | Xp = x, UD,p = u)
0

− E(Y1,p − Y0,p | Xp = x, UD,p = u) du.

+

(III)

Thus, when the policy affects the distribution of (Y1 , Y0 , UD , X), the PRTE is given by
the sum of three terms: (I) the value of PRTE if the policy did not affect (Y1 , Y0 , X, UD );
(II) the weighted effect of the policy change on E(Y0 | X, UD ); and (III) the weighted
effect of the policy change on MTE. Evaluating the PRTE requires knowledge of the
MTE function in both regimes, knowledge of E(Y0 | X = x, UD = u) in both
regimes, as well as knowledge of the distribution of P (Z) in both regimes. Note,
however, that if we assume that the distribution of (Y1,p , Y0,p , UD,p ) conditional on
Xp = x equals the distribution of (Y1,p , Y0,p , UD,p ) conditional on Xp = x, then
E(Y1,p | UD,p = u, Xp = x) = E(Y1,p | UD,p = u, Xp = x), E(Y0,p |
UD,p = u, Xp = x) = E(Y0,p | UD,p = u, Xp = x), and thus the last two terms
vanish and the expression for PRTE simplifies to the expression of Equation (3.6).

Appendix D: Deriving the IV weights on MTE
We consider instrumental variables conditional on X = x using a general function of
Z as an instrument. To simplify the notation, we keep the conditioning on X implicit.
Let J (Z) be any function of Z such that Cov(J (Z), D) = 0. Consider the population
analogue of the IV estimator,
Cov(J (Z), Y )
.
Cov(J (Z), D)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5113

First consider the numerator of this expression,




 
Cov J (Z), Y = E J (Z) − E J (Z) Y




= E J (Z) − E J (Z) Y0 + D(Y1 − Y0 )




= E J (Z) − E J (Z) D(Y1 − Y0 ) ,
where the second equality comes from substituting in the definition of Y and the third
equality follows from conditional independence assumption (A-1). Define J˜(Z) ≡
J (Z) − E(J (Z)). Then


Cov J (Z), Y




= E J˜(Z)1 UD  P (Z) (Y1 − Y0 )




= E J˜(Z)1 UD  P (Z) E(Y1 − Y0 | Z, UD )




= E J˜(Z)1 UD  P (Z) E(Y1 − Y0 | UD )
 




= EUD EZ J˜(Z)1 UD  P (Z) UD E(Y1 − Y0 | UD )
1

=


 


E J˜(Z) P (Z)  uD Pr P (Z)  uD E(Y1 − Y0 | UD = uD ) duD

0
1

=


 

MTE (x, uD )E J˜(Z) P (Z)  uD Pr P (Z)  uD duD ,

0

where the first equality follows from plugging in the model for D; the second equality follows from the law of iterated expectations with the inside expectation conditional on (Z, UD ); the third equality follows from conditional independence assumption (A-1); the fourth equality follows from Fubini’s Theorem and the law of iterated
expectations with the inside expectation conditional on (UD = uD ) (and implicitly
on X); this allows to reverse the order of integration in a multiple integral; the fifth
equality follows from the normalization that UD is distributed unit uniform conditional
on X; and the final equality follows from plugging in the definition of MTE . Next
consider the denominator of the IV estimand. Observe that by iterated expectations




Cov J (Z), D = Cov J (Z), P (Z) .
Thus, the population analogue of the IV estimator is given by
1

MTE (uD )ω(uD ) duD ,

(D.1)

0

where
ω(uD ) =

E(J˜(Z) | P (Z)  uD ) Pr(P (Z)  uD )
,
Cov(J (Z), P (Z))

where by assumption Cov(J (Z), P (Z)) = 0.

(D.2)

5114

J.J. Heckman and E.J. Vytlacil

If J (Z) and P (Z) are continuous random variables, then an interpretation of the
weight can be derived from (D.2) by noting that




j − E J (Z)

1

fP ,J (t, j ) dt dj
uD

=





j − E J (Z) fJ (j )

1
uD



fP |J t J (Z) = j dt dj.

Write
1
uD





fP |J t J (Z) = j dt = 1 − FP |J uD J (Z) = j


= SP |J uD J (Z) = j ,

where SP |J (uD | J (Z) = j ) is the probability of (P (Z)  uD ) given J (Z) = j (and
implicitly X = x). Likewise, Pr[P (Z) > UD | J (Z)] = SP |J (UD | J (Z)). Using these
results, we may write the weight as
ω(uD ) =

Cov(J (Z), SP |J (uD | J (Z)))
.
Cov(J (Z), SP |J (UD | J (Z)))

For fixed uD and x evaluation points, SP |J (uD | J (Z)) is a function of the random variable J (Z). The numerator of the preceding expression is the covariance between J (Z)
and the probability that the random variable P (Z) is greater than the evaluation point
uD conditional on J (Z).
SP |J (UD | J (Z)) is a function of the random variables UD and J (Z). The denominator of the above expression is the covariance between J (Z) and the probability that
the random variable P (Z) is greater than the random variable UD conditional on J (Z).
Thus, it is clear that if the covariance between J (Z) and the conditional probability
that (P (Z) > uD ) given J (Z) is positive for all uD , then the weights are positive. The
conditioning is trivially satisfied if J (Z) = P (Z), so the weights are positive and IV
estimates a gross treatment effect. If the J (Z) and P (Z) are discrete-valued, we obtain
expressions and (4.15) and (4.16) in the text.
D.1. Yitzhaki’s Theorem and the IV weights [Yitzhaki (1989)]
T HEOREM . Assume (Y, X) i.i.d., E(|Y |) < ∞, E(|X|) < ∞, g(X) = E(Y | X),
g (X) exists and E(|g (x)|) < ∞. Let μY = E(Y ) and μX = E(X). Then,
Cov(Y, X)
=
Var(X)

∞
−∞

g (t)ω(t) dt,

where
ω(t) =

1
Var(X)

∞
t

(x − μX )fX (x) dx

Ch. 71:

Econometric Evaluation of Social Programs, Part II

=

5115

1
E(X − μX | X > t) Pr(X > t).
Var(X)

P ROOF.




Cov(Y, X) = Cov E(Y | X), X = Cov g(X), X
=

∞
−∞

g(t)(t − μX ) fX (t) dt.

Integration by parts implies that
= g(t)
−
=

t
−∞
∞

−∞
∞

−∞

(x − μX )fX (x) dx
t

g (t)

−∞
∞

∞
−∞

(x − μX ) fX (x) dx dt

(x − μX ) fX (x) dx dt,

g (t)
t

since E(X − μX ) = 0 and the first term in the first expression vanishes.
Therefore,
Cov(Y, X) =

∞
−∞

g (t)E(X − μX | X > t) Pr(X > t) dt,

so
ω(t) =

1
E(X − μX | X > t) Pr(X > t).
Var(X)


Notice that:
(i) The weights are nonnegative (ω(t)  0).
(ii) They integrate to one (use an integration by parts formula).
(iii) ω(t) → 0 when t → −∞, and ω(t) → 0 when t → ∞.
We get the formula in the text when we use P (Z), with a suitably defined domain, in
place of X. We apply Yitzhaki’s result to the treatment effect model:
Y = α + βD + ε,

E Y




P (Z) = α + E β D = 1, P (Z) P (Z)


= α + E β P (Z) > uD , P (Z) P (Z)


= g P (Z) .

5116

J.J. Heckman and E.J. Vytlacil

By the law of iterated expectations, we eliminate the conditioning on D = 0. Using our
previous results for OLS,
Cov(Y, P (Z))
= g (t)ω(t) dt,
Cov(D, P (Z))
∂[E(β | D = 1, P (Z))]P (Z)
g (t) =
,
∂P (Z)
P (Z)=t

IV =

ω(t) =

1
t [ϕ

− E(P (Z))]fP (ϕ) dϕ
.
Cov(P (Z), D)

Under (A-1) to (A-5) and separability, g (t) = MTE (t) but g (t) = LIV, for P (Z) as
an instrument.
D.2. Relationship of our weights to the Yitzhaki weights199
Under our assumptions the Yitzhaki weights and ours are equivalent. Using (4.12),




Cov J (Z), Y = E(Y · J˜) = E E(Y | Z) · J˜(Z)
 


 


= E E Y P (Z) · J˜(Z) = E g P (Z) · J˜(Z) .
The third equality follows from index sufficiency and J˜ = J (Z) − E(J (Z) |
P (Z)  uD ), where E(Y | P (Z)) = g(P (Z)). Writing out the expectation and assuming that J (Z) and P (Z) are continuous random variables with joint density fP ,J
and that J (Z) has support [ J , J¯],


Cov J (Z), Y =

J¯

1
0

g(uD )j˜fP ,J (uD , j ) dj duD

J
J¯

1

=

j˜fP ,J (uD , j ) dj duD .

g(uD )
0

J

Using an integration by parts argument as in Yitzhaki (1989) and as summarized in
Heckman, Urzua and Vytlacil (2006), we obtain


Cov J (Z), Y = g(uD )

J¯

uD
0

J

g (uD )

1

0
J¯

1
uD

j˜fP ,J (p, j ) dj dp duD

J

g (uD )
0

J¯

uD

0

1
0

1

−
=

j˜fP ,J (p, j ) dj dp

j˜fP ,J (p, j ) dj dp duD

J

199 We thank Benjamin Moll for the derivation presented in this subsection.

Ch. 71:

Econometric Evaluation of Social Programs, Part II
1

=

5117

 


g (uD )E J˜(Z) P (Z)  uD Pr P (Z)  uD duD ,

0

which is then exactly the expression given in (4.12), where
g (uD ) =

∂E(Y | P (Z) = p)
∂P (Z)

= MTE (uD ).
p=uD

Appendix E: Derivation of the weights for the mixture of normals example
Writing E1 as the expectation for group 1, letting μ1 be the mean of Z for population 1
and μ11 be the mean of the first component of Z,
E1 (Z1 | γ Z > v)
γ Σ11
= μ11 +
E1 (Z1 − μ1 | γ Z > v)
γ Σ1 γ


γ Σ11
(v − γ μ1 )
γ (Z − μ1 ) γ (Z − μ1 )
= μ11 +
E
>
1
(γ Σ1 γ )1/2
(γ Σ1 γ )1/2 (γ Σ1 γ )1/2
(γ Σ1 γ )1/2


1
γ Σ1
(v − γ μ1 )
λ
,
= μ11 +
1/2
(γ Σ1 γ )
(γ Σ1 γ )1/2
where
1 e−c /2
,
λ(c) = √
2π Φ(−c)
where Φ(·) is the unit normal cumulative distribution function.
By the same logic, in the second group:


γ Σ21
(v − γ μ2 )
λ
E2 (Z1 | γ Z > v) = μ21 +
.
(γ Σ2 γ )1/2
(γ Σ2 γ )1/2
2

Therefore for the overall population we obtain


E Z1 − E(Z1 ) γ Z > v Pr(γ Z > v)
= (P1 μ11 + P2 μ21 ) Pr(γ Z > v)


P1 γ Σ11
1 v − γ μ1 2
+
√ exp −
2 (γ Σ1 γ )1/2
(γ Σ1 γ )1/2 2π


P2 γ Σ21
1 v − γ μ2 2
+
√ exp −
2 (γ Σ2 γ )1/2
(γ Σ2 γ )1/2 2π
− (P1 μ11 + P2 μ21 ) Pr(γ Z > v)


P1 γ Σ11
1 v − γ μ1 2
=
√ exp −
2 (γ Σ1 γ )1/2
(γ Σ1 γ )1/2 2π

5118

J.J. Heckman and E.J. Vytlacil



P2 γ Σ21
1 v − γ μ2 2
.
+
√ exp −
2 (γ Σ2 γ )1/2
(γ Σ2 γ )1/2 2π
We need Cov(D, Z1 ). To obtain it, observe that
D = 1[γ Z − V > 0],


E(Z1 D) = E Z1 1(γ Z − V  0) .
Let E1 denote the expectation for group 1, and let E2 denote the expectation for group 2.

E(Z1 D) = P1 μ11 +

γ Σ11
γ Σ1 γ + σV2

+ P2 μ21 +

E1 (Z1 − μ11 | γ Z − V  0)

γ Σ21

γ Σ2 γ + σV2


× Pr (γ Z − V ) > 0

E2 (Z1 − μ21 | γ Z − V  0)

= (P1 μ11 + P2 μ21 ) Pr(γ Z − V  0)

2
P1 γ Σ11
−γ μ1
+
exp
−
√
(γ Σ1 γ + σV2 )1/2
(γ Σ1 γ + σV2 )1/2 2π
2

P2 γ Σ21
−γ μ2
.
+
√ exp −
(γ Σ2 γ + σV2 )1/2
(γ Σ2 γ + σV2 )1/2 2π
Because
E(D)E(Z1 ) = Pr(γ Z − V  0)(P1 μ11 + P2 μ21 )
and
Cov(D, Z1 ) = E(Z1 D) − E(Z1 )E(D)
∴

2
−γ μ1
Cov(D, Z1 ) =
√ exp −
(γ Σ1 γ + σV2 )1/2
(γ Σ1 γ + σV2 )1/2 2π
2

P2 γ Σ21
−γ μ2
+
.
√ exp −
(γ Σ2 γ + σV2 )1/2
(γ Σ2 γ + σV2 )1/2 2π
P1 γ Σ11



Thus the IV weights for this set-up are


P1 γ Σ11
1 v − γ μ1 2
exp
−
2 (γ Σ1 γ )1/2
(γ Σ1 γ )1/2


P2 γ Σ21
1 v − γ μ2 2
+
exp −
2 (γ Σ2 γ )1/2
(γ Σ2 γ )1/2


ω̃IV (v) =

fV (v)

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5119

2
−γ μ1
×
exp −
(γ Σ1 γ + σV2 )1/2
(γ Σ1 γ + σV2 )1/2

2 -−1
P2 γ Σ21
−γ μ2
+
exp
−
,
(γ Σ2 γ + σV2 )1/2
(γ Σ2 γ + σV2 )1/2


P1 γ Σ11



where σV2 represents the variance of V . Clearly, ω̃IV (−∞) = 0, ω̃IV (∞) = 0 and the
weights integrate to one over the support of V = (−∞, ∞). Observe that the weights
must be positive if P2 = 0. Thus the structure of the covariances of the instrument
with the choice index γ Z is a key determinant of the positivity of the weights for any
instrument. It has nothing to do with the ceteris paribus effect of Z1 on γ Z or P (Z) in
the general case.
A necessary condition for ωIV < 0 over some values of v is that sign(γ Σ11 ) =
− sign(γ Σ21 ), i.e., that the covariance between Z1 and γ Z be of opposite signs in the
two subpopulations so Z1 and P (Z) have different relationships in the two component
populations. Without loss of generality, assume that γ Σ11 > 0. If it equals zero, we fail
the rank condition in the first population and we are back to a one subpopulation model
with positive weights. The numerator of the expression for ωIV (v) switches signs if for
some values of v,


P1 γ Σ11
1 v − γ μ1 2
exp
−
2 (γ Σ1 γ )1/2
(γ Σ1 γ )1/2


P2 γ Σ21
1 v − γ μ2 2
<−
,
exp −
2 (γ Σ2 γ )1/2
(γ Σ2 γ )1/2
while for other values the inequality is reversed. (Observe that the denominator is
a constant.) Rewriting and taking logarithms, we obtain under the assumption that
sign(γ Σ11 ) = − sign(γ Σ21 ), the following expression:


−γ Σ21
γ Σ1 γ
(v − γ μ1 )2
1 − P1
1 (v − γ μ2 )2
+ ln
+ ln
−
< ln
,
1
2
γ Σ2 γ
γ Σ1 γ
P1
γ Σ2 γ
γ Σ1
1
where we assume 0 < P1 < 1. Observe that 1−P
P1 can be made as large or as small
a non-negative number as we like by varying P1 . Varying (μ1 , μ2 ) does not affect the
right-hand side. For μ1 = μ2 = 0, the inequality becomes


−γ Σ21
1 2
1
γ Σ1 γ
1
1 − P1
+ ln
+ ln
v
−
< ln
.
1
2
γ Σ2 γ
γ Σ1 γ
P1
γ Σ2 γ
γ Σ1

Suppose that γ Σ2 γ < γ Σ1 γ . Then the left-hand side is positive except when
v = 0. For any fixed γ , Σ1 , Σ2 we can find a value of P1 sufficiently small so that
right-hand side of the equation is positive and for any such value of P1 there will be
a v sufficiently small for the inequality to be satisfied. There is also a value of v that
reverses the inequality.

5120

J.J. Heckman and E.J. Vytlacil

The inequality is satisfied for some v ∗  0. But with v arbitrarily large, the inequality
can be reversed so that the weight will switch signs at some value of v. The key necessary condition is that Cov(Z1 , γ Z) be of opposite signs in the two subpopulations.
Using Z1 as an IV, but not conditioning or controlling for the other components of Z,
produces sometimes negative and sometimes positive movements in the components of
Z2 , . . . , Zk which can offset the ceteris paribus (Z2 = z2 , . . . , Zk = zk ) movements
of Z1 .

Appendix F: Local instrumental variables for the random coefficient model
Consider the model:
D = 1[Zγ  0],
where γ is a random variable. For ease of exposition, we leave implicit the conditioning
on X covariates. Assume that (Y0 , Y1 , γ ) ⊥
⊥ Z. Assume that γ has a density that is
absolutely continuous with respect to Lebesgue measure on RK . We have


E(Y | Z = z) = E(DY1 | Z = z) + E (1 − D)Y0 Z = z .
To simplify the exposition, consider the first term, E(DY1 | Z = z). In this proof, let
Z [K] denote the Kth element of Z and Z [−K] denote all other elements of Z, and write
Z = (Z [−K] , Z [K] ). Using the model, the independence assumption, and the law of
iterated expectations, we have




E(DY | Z = z) = E 1[zγ  0]Y1 = E 1[zγ  0]E(Y1 | γ )


 
= E 1 z[K] γ [K]  −z[−K] γ [−K] E(Y1 | γ ) ,
where the final outer expectation is over γ . Consider taking the derivative with respect to the Kth element of Z assumed to be continuous. Partition z, γ , and g as
z = (z[−K] , z[K] ), γ = (γ [−K] , γ [K] ), and g = (g [−K] , g [K] ), where z is a realization of Z and g is a realization of γ . For simplicity, suppose that the Kth element of z
is positive, z[K] > 0. We obtain


  
E(DY | Z = z) = E E 1 z[K] γ [K]  −z[−K] γ [−K] E(Y1 | γ ) γ [−K]

 
−z[−K] γ [−K]
[−K]
γ
E(Y
,
= E E 1 γ [K] 
|
γ
)
1
z[K]
where the inside expectation is over γ [K] conditional on γ [−K] , i.e., is over the Kth
element of γ conditional on all other components of γ . Computing the derivative with
respect to z[K] , we obtain
∂
E(DY | Z = z) =
∂z[K]


 


E Y1 γ = M g [−K] w̃ g [−K] dg [−K] ,

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5121

where


 [−K]  −z[−K] g [−K]
 [−K] 
= g
,
and
M g
z[K]

[−K] g [−K] 
 z[−K] g [−K]

[−K] −z
,
f
g
,
w̃ g [−K] =
z[K]
(z[K] )2
with f (·) the density of γ (with respect to Lebesgue measure), and where for notational
simplicity we suppress the dependence of the function M(·) and the weights w̃(·) on the
z evaluation point. In this expression, we are averaging over E(Y1 | γ = g), but only
over g evaluation points such that zg = 0. In particular, the expression averages over the
K−1 space of g [−K] , while for each potential realization of g [−K] it is filling in the value
of g [K] such that z[K] g [K] = −z[−K] g [−K] so that z[K] g [K] +z[−K] g [−K] = 0. Note that
[−K] [−K]
the weights w̃(g [−K] ) will be zero for any g [−K] such that f (g [−K] , −z z[K]g
) = 0,
[−K]
[K]
i.e., the weights will be zero for any g
such that there does not exist g
in the
conditional support of γ [K] with z[K] g [K] = −z[−K] g [−K] .
Following the same logic for E((1 − D)Y0 | Z = z), we obtain

∂
E (1 − D)Y
[K]
∂z


Z=z =−



 

E Y0 γ = M g [−K] w̃ g [−K] dg [−K]

and likewise have
∂
Pr(D = 1 | Z = z) =
∂z[K]



w̃ g [−K] dg [−K]

so that
∂
E(Y
∂z[K]
∂
∂z[K]

| Z = z)

Pr(D = 1 | Z = z)

=



 

E Y1 − Y0 γ = M g [−K] w g [−K] dg [−K] ,

where



(
w g [−K] = w̃ g [−K]



w̃ g [−K] dg [−K] .

Now consider the question of whether this expression will have both positive and
[−K] [−K]
[−K] [−K]
). Thus,
negative weights. Recall that w̃(g [−K] ) = z (z[K]g )2 f (g [−K] , −z z[K]g


w̃ g [−K]  0 if z[−K] g [−K] > 0,



w̃ g [−K]  0

if z[−K] g [−K] < 0,

and will be nonzero if z[−K] g [−K] = 0 and there exists g [K] in the conditional support
of γ [K] with z[K] g [K] = z[−K] g [−K] , i.e., with zg = 0. We thus have that there will be
both positive and negative weights on the MTE if there exist values of g in the support
of γ with both z[−K] g [−K] > 0 and zg = 0, and there exist other values of g in the
support of γ with z[−K] g [−K] < 0 and zg = 0.

5122

J.J. Heckman and E.J. Vytlacil

Appendix G: Generalized ordered choice model with stochastic thresholds
The ordered choice model presented in the text with parameterized, but nonstochastic,
thresholds is analyzed in Cameron and Heckman (1998) who establish its nonparametric identifiability under the conditions they specify. Treating the Ws (or components
of it) as unobservables, we obtain the generalized ordered choice model analyzed in
Carneiro, Hansen and Heckman (2003) and Cunha, Heckman and Navarro (2007). In
this appendix, we present the main properties of this more general model.
The thresholds are now written as Qs + Cs (Ws ) in place of Cs (Ws ), where Qs is a
random variable. In addition to the order on the Cs (Ws ) in the text, we impose the order
Qs + Cs (Ws )  Qs−1 + Cs−1 (Ws−1 ), s = 2, . . . , S̄ − 1. We impose the requirement
that QS̄ = ∞ and Q0 = −∞. The latent index Ds∗ is as defined in the text, but now


Ds = 1 Cs−1 (Ws−1 ) + Qs−1 < μD (Z) − V  Cs (Ws ) + Qs


= 1 ls−1 (Z, Ws−1 ) − Qs−1 > V  ls (Z, Ws ) − Qs ,
where ls = μD (Z) − Cs (Ws ). Using the fact that ls (Z, Ws ) − Qs < ls−1 (Z, Ws−1 ) −
Qs−1 , we obtain


1 ls−1 (Z, Ws−1 ) − Qs−1 > V  ls (Z, Ws ) − Qs




= 1 V + Qs−1 < ls−1 (Z, Ws−1 ) − 1 V + Qs  ls (Z, Ws ) .
The nonparametric identifiability of this choice model is established in Carneiro,
Hansen and Heckman (2003) and Cunha, Heckman and Navarro (2007). We retain assumptions (OC-2)–(OC-6), but alter (OC-1) to
⊥ (Z, W ) | X, s = 1, . . . , S̄.
(OC-1) (Qs , Us , V ) ⊥
Vytlacil (2006b) shows that this model with no transition specific instruments
(with Ws degenerate for each s) implies and is implied by the independence and
monotonicity conditions of Angrist and Imbens (1995) for an ordered model. Define
Q = (Q1 , . . . , QS̄ ). Redefine πs (Z, Ws ) = FV +Qs (μD (Z) + Cs (Ws )) and define
π(Z, W ) = [π1 (Z, W1 ), . . . , πS̄−1 (Z, WS̄−1 )]. Redefine UD,s = FV +Qs (V + Qs ). We
have that
E(Y | Z, W )

 S̄
 

1 ls−1 (Z, Ws−1 ) − Qs−1 > V  ls (Z, Ws ) − Qs Ys Z, W
=E
s=1

=

S̄

  


E 1 V + Qs−1 < ls−1 (Z, Ws−1 ) Ys Z, W
s=1

 


− E 1 V + Qs  ls (Z, Ws ) Ys Z, W

Ch. 71:

Econometric Evaluation of Social Programs, Part II

=

S̄ 


−∞

s=1

−
=

ls−1 (Z,Ws−1 )

ls (Z,Ws )
−∞

S̄ 


5123

E(Ys | V + Qs−1 = t) dFV +Qs−1 (t)


E(Ys | V + Qs = t) dFV +Qs (t)

πs−1 (Z,Ws−1 )

E(Ys | UD,s−1 = t) dt

0

s=1

πs (Z,Ws )

−

E(Ys | UD,s


= t) dt .

0

We thus have the index sufficiency restriction that E(Y | Z, W ) = E(Y | π(Z, W )),
and in the general case ∂π∂ s E(Y | π(Z, W ) = π) = E(Ys+1 − Ys | UD,s = πs ).
Also, notice that we have the restriction that

∂2
∂πs ∂πs

E(Y | π(Z, W ) = π) = 0 if

|s − s | > 1. Under full independence between Us and V + Qs , s = 1, . . . , S̄, we
can test full independence for the more general choice model by testing for linearity of
E(Y | π(Z, W ) = π) in π.
Define
MTE
s+1,s (x, u) = E(Ys+1 − Ys | X = x, UD,s = u),
so that our result above can be rewritten as
∂ 
E Y
∂πs


π(Z, W ) = π = MTE
s+1,s (x, πs ).

Since πs (Z, Ws ) can be nonparametrically identified from

πs (Z, Ws ) = Pr

S̄



Dj = 1 Z, Ws ,

j =s+1

we have identification of MTE for all evaluation points within the appropriate support.
p
The policy relevant treatment effect is defined analogously. Hs is defined as the cumulative distribution function of μD (Z) − Cs (Ws ). We have that
Ep (Yp )



= Ep E(Y | V , Q, Z, W )
 S̄
 

= Ep
1 ls−1 (Z, Ws−1 ) − Qs−1 > V  ls (Z, Ws ) − Qs
s=1



× E(Ys | V , Q, Z, W )

5124

J.J. Heckman and E.J. Vytlacil


S̄



1 ls−1 (Z, Ws−1 ) − Qs−1 > V  ls (Z, Ws ) − Qs E(Ys | V , Q)


= Ep

s=1

=

S̄



 p

p
Ep E(Ys | V , Q) Hs (V + Qs ) − Hs−1 (V + Qs−1 )

s=1

=

S̄




 p
E(Ys | V = v, Q = q) Hs (v + qs )

s=1


p
− Hs−1 (v + qs−1 ) dFV ,Q (v, q)
S̄ 

p
E(Ys | V + Qs = t)Hs (t) dFV +Qs (t)
=
s=1


p
E(Ys | V + Qs−1 = t)Hs−1 (t) dFV +Qs−1 (t) ,

−

where V , Qs enter additively, and
PRTE
p,p = Ep (Y ) − Ep (Y )
=

S̄−1




 p

p
E(Ys+1 − Ys | V + Qs = t) Hs (t) − Hs (t) dFV +Qs (t).

s=1

Alternatively, we can express this result in terms of MTE,
Ep (Yp ) =

S̄ 


p

E(Ys | UD,s = t)H̃s (t) dt

s=1

−


E(Ys | UD,s−1 =

p
t)H̃s−1 (t) dt

so that
PRTE
p,p = Ep (Y ) − Ep (Y )
=

S̄−1




 p

p
E(Ys+1 − Ys | UD,s = t) H̃s (t) − H̃s (t) dt,

s=1
p
H̃s

is the cumulative distribution function of the random variable
where
FUD,s (μD (Z) − Cs (Ws )).
Appendix H: Derivation of PRTE weights for the ordered choice model
To derive the ωp,p weights used in expression (7.5), let ls (Z, Ws ) = μD (Z) − Cs (Ws ),
p
and let Hs (·) denote the cumulative distribution function of ls (Z, Ws ) under regime p,

Ch. 71:

Econometric Evaluation of Social Programs, Part II

p

5125

p

Hs (t) = 1[μD (z) − Cs (ws )  t] dFZ,W (z, w). Because C0 (W0 ) = −∞ and
p
p
CS̄ (WS̄ ) = ∞, l0 (Z, W0 ) = ∞ and lS̄ (Z, WS̄ ) = −∞, H0 (t) = 0 and HS̄ (t) = 1
for any policy p and for all evaluation points. Since ls−1 (Z, Ws−1 ) is always larger than
ls (Z, Ws ), we obtain


1 ls (Z, Ws )  V < ls−1 (Z, Ws−1 )




= 1 V < ls−1 (Z, Ws−1 ) − 1 V  ls (Z, Ws ) ,
so that under assumption (OC-1),
 


p
p
Ep 1 ls (Z, Ws )  V < ls−1 (Z, Ws−1 ) V = Hs (V ) − Hs−1 (V ).
Collecting these results we obtain


Ep (Y ) = Ep E(Y | V , Z, W )
=

S̄




 p

p
E(Ys | V = v) Hs (v) − Hs−1 (v) fV (v) dv.200

s=1

Comparing two policies under p and p , the policy relevant treatment effect is PRTE
p,p =
S̄−1
p
p
Ep (Y ) − Ep (Y ) = s=1 E(Ys+1 − Ys | V = v)[Hs (v) − Hs (v)]fV (v) dv. AlterS̄−1
p
natively, we can express this in terms of MTE : PRTE
MTE
s=1
s,s+1 (u)[H̃s (u) −
p,p =
p

p

H̃s (u)] du where H̃s (t) is the cumulative distribution function of FV (μD (Z) −
p
p
Cs (Ws )) under policy p, H̃s (t) = 1[FV (μD (z) − Cs (ws ))  t] dFZ,Ws (z, ws ).

Appendix I: Derivation of the weights for IV in the ordered choice model
We first derive Cov(J (Z, W ), Y ). Its derivation is typical of the other terms needed to
form (7.6) in the text. Defining J˜(Z, W ) = J (Z, W ) − E(J (Z, W )), we obtain, since
Cov(J (Z, W ), Y ) = E(J˜(Z, W )Y ),

200 The full derivation is E (Y ) = E [E(Y |V , Z, W )] = E [S̄ 1[l (Z, W )  V < l
p
p
p
s
s−1 (Z, Ws−1 )]×
s=1 s
S̄
S̄
E
[1[l
(Z,
W
)

V
<
l
(Z,
W
)]E(Y
|V
)]
=
E(Ys |V , Z, W )] =
s
s
s
s−1
s−1
s=1 p
s=1 Ep [E(Ys |V ) ×
S̄
p
p
p
p
{Hs (V ) − Hs−1 (V )}] = s=1 [E(Ys |V = v){Hs (v) − Hs−1 (v)}]fV (v) dv. The first equality is from

the law of iterated expectations; the second equality comes from the definition of Y ; the third equality
follows from linearity of expectations and independence assumption (OC-1); the fourth equality applies
the law of iterated expectations; and the final equality rewrites the expectation explicitly as an integral
p
p
over the distribution of V . Recalling that H0 (v) = 0 and H (v) = 1, we may rewrite this result as
S̄
S̄−1
p
Ep (Y ) =
s=1 E(Ys − Ys+1 | V = v)Hs (v)fV (v) dv + E(YS̄ | V = v)fV (v) dv, where the
last term is E(YS̄ ).

5126

J.J. Heckman and E.J. Vytlacil



E J˜(Z, W )Y
$
%
S̄



= E J˜(Z, W ) 1 ls (Z, Ws )  V < ls−1 (Z, Ws−1 ) E(Ys | V , Z, W )
s=1

=

S̄





E J˜(Z, W )1 ls (Z, Ws )  V < ls−1 (Z, Ws−1 ) E(Ys | V ) ,
s=1

where the first equality comes from the definition of Y and the law of iterated expectations, and the second equality follows from linearity of expectations and independence
p
assumption (OC-1). Let Hs (·) equal Hs (·) for p equal to the policy that characterizes
the observed data, i.e., Hs (·) is the cumulative distribution function of ls (Z, Ws ),




p
Hs (t) = Pr ls (Z, Ws )  t = Pr μD (Z) − Cs (Ws )  t .
Using the law of iterated expectations, we obtain
S̄

 
 
 

E J˜(Z, W )Y =
E E J˜(Z, W ) 1 V < ls−1 (Z, Ws−1 )

=

s=1





V E(Ys | V )
− 1 V  ls (Z, Ws )

S̄





E(Ys | V = v) Ks−1 (v) − Ks (v) fV (v) dv

s=1

=

S̄−1




E(Ys+1 − Ys | V = v)Ks (v) fV (v) dv,

s=1

where Ks (v) = E(J˜(Z, W ) | ls (Z, Ws ) > v)(1 − Hs (v)) and we use the fact that
KS̄ (v) = K0 (v) = 0. Now consider the denominator of the IV estimand,


E S J˜(Z, W )
$
%
S̄



= E J˜(Z, W ) s1 ls (Z, Ws )  V < ls−1 (Z, Ws−1 )
s=1

=

S̄





sE J˜(Z, W )1 ls (Z, Ws )  V < ls−1 (Z, Ws−1 )

s=1

=

S̄



 
 



V
sEV E J˜(Z, W ) 1 V < ls−1 (Z, Ws−1 ) − 1 V  ls (Z, Ws )

s=1

=

S̄

s=1

s

S̄−1



Ks−1 (v) − Ks (v) fV (v) dv =
s=1

Ks (v)fV (v) dv.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5127

Collecting results, we obtain an expression for the IV estimand (7.6):
Cov(J, Y ) 
=
Cov(J, S)

S̄−1

E(Ys+1 − Ys | V = v)ω(s, v)fV (v) dv,

s=1

where
ω(s, v) = 
S̄

s=1 s

Ks (v)
[Ks−1 (v) − Ks (v)]fV (v) dv

=
S̄−1
s=1

Ks (v)
Ks (v)fV (v) dv

and clearly
S̄−1


ω(s, v)fV (v) dv = 1,

ω(0, v) = 0,

and ω(S̄, v) = 0.

s=1

Appendix J: Proof of Theorem 6
We now prove Theorem 6.
P ROOF. The basic idea is that we can bring the model back to a two choice set up
of j versus the “next best” option. We prove the result for the second assertion, that
LIV
j (x, z) recovers the marginal treatment effect parameter. The first assertion, that
Wald
(x, z[−j ] , z[j ] , z̃[j ] ) recovers a LATE parameter, follows from a trivial modifij
cation to the same proof strategy. Recall that RJ \j (z) = maxi∈J \j {Ri (z)} and that
IJ \j = argmaxi∈J \j (Ri (Z)). We may write Y = YIJ \j + DJ ,j (Yj − YIJ \j ). We have
Pr(DJ ,j = 1 | X = x, Z = z)


= Pr Rj (zj )  RJ \j (z) X = x, Z = z


= Pr ϑj (zj )  RJ \j (z) + Vj X = x, Z = z .
Using independence assumption (B-1), RJ \j (z) − Vj is independent of Z conditional
on X, so that

Pr(DJ ,j = 1 | X = x, Z = z) = Pr ϑj (zj )  RJ \j (z) + Vj


X=x .

ϑk (·) does not depend on z[j ] for k = j by assumption (B-2b), and thus RJ \j (z) does
not depend on z[j ] , and we will therefore (with an abuse of notation) write RJ \j (z[−j ] )
for RJ \j (z). Write FX|Z [−j ] (·; X = x, Z [−j ] = z[−j ] ) for the distribution function of
RJ \j (z[−j ] ) + Vj conditional on X = x. Then


Pr(DJ ,j = 1 | X = x, Z = z) = F ϑj (zj ); x, z[−j ] ,

5128

J.J. Heckman and E.J. Vytlacil

and
∂
Pr(DJ ,j = 1 | X = x, Z = z)
∂z[j ]


∂
ϑj (zj ) fX|Z [−j ] ϑj (zj ); X = x, Z [−j ] = z[−j ] ,
=
[j
]
∂z
where fX|Z [−j ] (·; X = x, Z [−j ] = z[−j ] ) is the density of RJ \j (z[−j ] ) − Vj conditional
on X = x. Consider
E(Y | X = x, Z = z) = E(YIJ \j | X = x, Z = z)


+ E DJ ,j (Yj − YIJ \j ) X = x, Z = z .
As a consequence of (B-1), (B-3)–(B-5), and (B-2b), we have that E(YIJ \j | X = x,
Z = z) does not depend on z[j ] . Using the assumptions and the law of iterated expectations, we may write


E DJ ,j (Yj − YIJ \j ) X = x, Z = z
=

=





E Yj − YIJ \j X = x, Z = z, RJ \j z[−j ] + Vj = t
−∞


× fX|Z [−j ] t; X = x, Z [−j ] = z[−j ] dt
ϑj (z)





E Yj − YIJ \j X = x, Z [−j ] = z[−j ] , RJ \j z[−j ] + Vj = t
−∞


× fX|Z [−j ] t; X = x, Z [−j ] = z[−j ] dt.
ϑj (z)

Thus,
∂
E(Y | X = x, Z = z)
∂z[j ]


= E Yj − YIJ \j X = x, Z [−j ] = z[−j ] , Rj (z) = RJ \j (z)


∂
×
ϑj (zj ) fX|Z [−j ] ϑj (zj ) | X = x, Z [−j ] = z[−j ] .
[j
]
∂z
Combining results, we have
( ∂
∂
E(Y | X = x, Z = z)
Pr(DJ ,j = 1 | X = x, Z = z)
[j
]
∂z
∂z[j ]


= E Yj − YIJ \j X = x, Z [−j ] = z[−j ] , Rj (z) = RJ \j (z) .
Finally, noting that


E Yj − YIJ \j X = x, Z [−j ] = z[−j ] , Rj (z) = RJ \j (z)


= E Yj − YIJ \j X = x, Z = z, Rj (z) = RJ \j (z)
provides the stated result. The proof for the LATE result follows from the parallel argument using discrete changes in the instrument.


Ch. 71:

Econometric Evaluation of Social Programs, Part II

5129

Appendix K: Flat MTE within a general nonseparable matching framework
The result in the text that conditional mean independence of Y0 and Y1 in terms of D
given X implies a flat MTE holds in a more general nonseparable model. We establish
this claim and also establish some additional restrictions implied by an IV assumption.
Assume a nonseparable selection model, D = 1[μD (X, Z, V )  0], with Z independent of (Y0 , Y1 , V ) conditional on X. Let Ω(x, z) = {v: μD (x, z, v)  0}. Let Ω(x, z)c
denote the complement of Ω(x, z). Consider the mean independence assumption
(M-3) E(Y1 | X, D) = E(Y1 | X), E(Y0 | X, D) = E(Y0 | X).
(M-3) implies that for  = Y1 − Y0




E  X = x, V ∈ Ω(X, Z) = E  X = x, V ∈ Ω(X, Z)c ,
where c here denotes “complement”. Thus,


 
EZ|X E MTE (x, V ) X = x, V ∈ Ω(x, Z) X = x

 

= EZ|X E MTE (x, V ) X = x, V ∈ Ω(x, Z)c X = x
for all x in the support of X. (We assume 0 < Pr(D = 1 | X) < 1.) This establishes
that the MTE is flat.
Now suppose that (M-3) holds, but suppose that there is an instrument Z such that
(M-3) E(Y1 | X, Z, D) = E(Y1 | X), E(Y0 | X, Z, D) = E(Y0 | X).
(Note: E(Yj | X, Z) = E(Yj | X) by assumption.) In this case, (M-3) implies that


 
EZ|X E MTE (X, V ) X = x, V ∈ Ω(x, Z) X = x


c 
 
= EZ|X E MTE (X, V ) X = x, V ∈ Ω(x, Z)
X=x ,
but (M-3) implies that there exists z in the support of Z conditional on X such that




E MTE (X, V ) X = x, V ∈ Ω(x, z) = E MTE (X, V ) X = x
and




E MTE (X, V ) X = x, V ∈ Ω(x, z)c = E MTE (X, V ) X = x
so that MTE (X, V ) is not constant in V . Note that, if E(Y1 | X, Z = z, D = 1) =
E(Y1 | X, Z = z , D = 1) for any z, z evaluation points in the support of Z conditional
on X, then E(Y1 | X, Z, D) = E(Y1 | X). Thus, (M-3) is testable, given the maintained
assumption that Z is a proper exclusion restriction. Note that (M-3) implies (M-3), so
it is a stronger condition.

5130

J.J. Heckman and E.J. Vytlacil

Now assume
(M-1) E(Y1 | X, Z, D) = E(Y1 | X), E(Y0 | X, Z, D) = E(Y0 | X).
In this case, we get a stronger restriction on MTE than is produced from (M-3). We
obtain




E MTE (X, V ) X = x, V ∈ Ω(x, z) = E MTE (X, V ) X = x
and





E MTE (X, V ) X = x, V ∈ Ω(x, z)c = E MTE (X, V ) X = x

for all (x, z) in the proper support. Again, the MTE is not flat.

Appendix L: The relationship between exclusion conditions in IV and exclusion
conditions in matching
We now investigate the relationship between IV and matching identification conditions.
They are very distinct. We analyze mean treatment parameters. We define (U0 , U1 ) by
U0 = Y0 − E(Y0 | X) and U1 = Y1 − E(Y1 | X). We consider standard IV as a form
of matching where matching does not hold conditional on X but does hold conditional
on (X, Z), where Z is the instrument. Consider the following two matching conditions
based on an exclusion restriction Z:
(M-4) (U0 , U1 ) are mean independent of D conditional on (X, Z). (E(U0 |X,
Z, D) = E(U0 | X, Z) and E(U1 | X, Z, D) = E(U1 | X, Z).)
(M-5) (U0 , U1 ) are not mean independent of D conditional on X. (E(U0 | X, D) =
E(U0 | X) and E(U1 | X, D) = E(U1 | X).)
(M-4) says that the matching conditions hold conditional on (X, Z). However, (M-5)
says that the matching conditions do not hold if one only conditions on X. By the
definitions of U0 , U1 , these conditions are equivalent to stating that Y0 , Y1 are mean
independent of D conditional on (X, Z) but not mean independent of D conditional
on X. These look like instrumental variable conditions. We now consider whether these
assumptions are compatible with standard IV conditions as used by Heckman and Robb
(1985a, 1986a) and Heckman (1997) to use IV to identify treatment parameters when
responses are heterogenous (the model of essential heterogeneity). For ATE, they show
that standard IV identifies ATE if:
(ATE-1) U0 is mean independent of Z conditional on X.
(ATE-2) D(U1 − U0 ) is mean independent of Z conditional on X.201
201 When Y = Y + D(Y − Y ), assuming separability so that Y = μ (X) + U , Y = μ (X) + U ,
0
1
0
0
0
0 1
1
1
and Y = μ0 (X) + D(μ1 (X) − μ0 (X) + U1 − U0 ) + U0 , identification of ATE by IV requires the rank
condition (IV-2) plus E(U0 + D(U1 − U0 ) | X, Z) = E(U0 + D(U1 − U0 ) | X), which is implied by (ATE-1)
and (ATE-2).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5131

They show that standard IV identifies TT if:
(TT-1) U0 is mean independent of Z conditional on X.
(TT-2) U1 − U0 is mean independent of Z conditional on D = 1 and on X.202
The conventional assumption in means is that
(IV-1) (U0 , U1 ) are mean independent of Z conditional on X.
(IV-2) Rank condition (IV-2) is still required: Pr(D = 1 | Z, X) is a nondegenerate
function of Z.
Condition (IV-1) is a commonly invoked instrumental variable condition, even
though Heckman and Robb (1986a) and Heckman (1997) show it is neither necessary
nor sufficient to identify ATE or TT by linear IV. In Section 4, we used the stronger
condition (IV-1): (U0 , U1 ) ⊥
⊥ Z | X along with the rank conditions. Clearly, (IV-1) implies (IV-1) .
We now show that assumptions (M-4) and (M-5) are inconsistent with any of the sets
of IV assumptions. In particular, we show that assuming (M-4) and that U0 is mean
independent of Z conditional on X jointly imply that U0 is mean independent of D
conditional on X. If (M-4) and (M-5) hold, then Z cannot satisfy condition (IV-1) (or
stronger condition (IV-1)), (ATE-1) or (TT-1). Thus matching based on an exclusion restriction and IV are distinct conditions. We show this by establishing a series of claims.
C LAIM 1. Conditions (M-4) and (IV-1) jointly imply U0 is mean independent of D
conditional on X. Thus, (M-4) and [(IV-1) or (ATE-1) or (TT-1)] jointly imply
that (M-5) cannot hold.
P ROOF. Assume (M-4) and (IV-1) . We have
E(U0 | D, X, Z) = E(U0 | X, Z)
= E(U0 | X),
202 In the separable model,
TT (X)




Y = μ0 (X) + D μ1 (X) − μ0 (X) + E(U1 − U0 | X, D = 1)


+ U0 + D U1 − U0 − E(U1 − U0 | X, D = 1) .
Identification requires that




E U0 + D U1 − U0 − E(U1 − U0 | X, D = 1) X, Z




= E U0 + D U1 − U0 − E(U1 − U0 | X, D = 1) X ,
which is implied by (TT-1) and (TT-2).

5132

J.J. Heckman and E.J. Vytlacil

where the first equality follows from (M-4) and the second equality follows from (IV-1) .
Thus,


E(U0 | D, X) = EZ E(U0 | D, X, Z) D, X


= EZ E(U0 | X) D, X
= E(U0 | X).

Thus (M-4) and (M-5) are inconsistent with any of the sets of IV assumptions that we
have considered. However, this analysis raises the question of whether it is still possible
to invoke (M-5) and the assumption that U1 is not mean independent of D conditional
on X. The following results show that it is not possible.
C LAIM 2. (M-4) and (IV-1) imply U1 is mean independent of D conditional on X.
P ROOF. Follows with trivial modification from the proof to Claim 1.



A similar claim can be shown for (TT-1) and (TT-2).
C LAIM 3. (M-4) and (TT-1), (TT-2) imply U1 is mean independent of D conditional
on X.
P ROOF. Assume (M-4) and (TT-1), (TT-2). We have
(N-1) E(U0 | X, Z, D) = E(U0 | X, Z) = E(U0 | X),
where the first equality follows from (M-4) and the second equality follows from (TT-1).
Using the result from the proof of Claim 1, we obtain
(N-2) E(U0 | X, Z, D) = E(U0 | X, D).
By (TT-2), we have
E(U1 | X, Z, D = 1) − E(U1 | X, D = 1)
= E(U0 | X, Z, D = 1) − E(U0 | X, D = 1).
By equation (N-2), the right-hand side of the preceding expression is zero, and we thus
have
(N-3) E(U1 | X, Z, D = 1) = E(U1 | X, D = 1).
By (M-4), we have
(N-4) E(U1 | X, Z, D = 1) = E(U1 | X, Z).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5133

Combining equations (N-3) and (N-4), we obtain
E(U1 | X, Z) = E(U1 | X, D = 1).
Integrating both sides of this expression against the distribution of Z conditional on X,
we obtain
E(U1 | X) = E(U1 | X, D = 1).

It is straightforward to show that (M-4) and (ATE-1), (ATE-2) jointly imply that U1
is mean independent of D conditional on X.
In summary, (U0 , U1 ) mean independent of D conditional on (X, Z) but not conditional on X implies that U0 is dependent on Z conditional on X in contradiction to all
of the assumptions used to justify instrumental variables. Thus (U0 , U1 ) mean independent of D conditional on (X, Z) but not conditional on X implies that none of the three
sets of IV conditions will hold. In addition, if we weaken these conditions to only consider U1 , so that we assume that U1 is mean independent of D conditional on (X, Z) but
not conditional on X, we obtain that U1 is dependent on Z conditional on X. We have
shown that this implies that (IV-1) does not hold, and implies that (TT-1), (TT-2) will
not hold. A similar line of argument shows that (ATE-1), (ATE-2) will not hold. Thus,
the exclusion conditioning in matching is not the same as the exclusion conditioning
in IV.

Appendix M: Selection formulae for the matching examples
Consider a generalized Roy model of the form Y1 = μ1 + U1 ; Y0 = μ0 + U0 ; D ∗ =
μD (Z) + V ; D = 1 if D ∗  0, = 0 otherwise; and Y = DY1 + (1 − D)Y0 , where
(U0 , U1 , V ) ∼ N (0, Σ),
Var(V ) =

σV2 ,

Var(Ui ) = σi2 ,

i = 0, 1,

Cov(U1 , U0 ) = σ10 ,

Cov(U1 , V ) = σ1V ,

Cov(U0 , V ) = σ0V .

Assume Z ⊥
⊥ (U0 , U1 , V ). Let φ(·) and Φ(·) be the pdf and the cdf of a standard normal
random variable. Then, the propensity score for this model for Z = z is given by




μD (z)
∗
.
Pr(D > 0 | Z = z) = Pr V > −μD (z) = P (z) = Φ
σV
Thus

μD (z)
σV

= Φ −1 (P (z)), and



−μD (z)
= Φ −1 1 − P (z) .
σV

5134

J.J. Heckman and E.J. Vytlacil

The event (V  0, Z = z) can be written as σVV  − μDσV(z) ⇔ σVV  Φ −1 (1 − P (z)).
We can write the conditional expectations required to get the biases for the treatment
parameters as a function of P (z) = p. For U1 :


V
σ1V
V
−μD (z)
E(U1 | D ∗  0, Z = z) =
E

σV
σV σV
σV




V
σ1V
V
=
E
 Φ −1 1 − P (z)
σV
σV σV


= η1 M1 P (z) ,
where
η1 =

σ1V
.
σV

Similarly for U0



E(U0 | D ∗ > 0, Z = z) = η0 M1 P (z) ,


E(U0 | D ∗ < 0, Z = z) = η0 M0 P (z) ,

where η0 =

σ0V
σV

and

M1 (P (z)) =

φ(Φ −1 (1 − P (z)))
P (z)

and M0 (P (z)) = −

φ(Φ −1 (1 − P (z)))
1 − P (z)

are inverse Mills ratio terms.
Substituting these into the expressions for the biases for the treatment parameters
conditional on z we obtain






Bias TT P (z) = η0 M1 P (z) − η0 M0 P (z)


= η0 M P (z) ,






Bias ATE P (z) = η1 M1 P (z) − η0 M0 P (z)



 
= M P (z) η1 1 − P (z) + η0 P (z) .

References
Aakvik, A., Heckman, J.J., Vytlacil, E.J. (1999). “Training effects on employment when the training effects are heterogeneous: An application to Norwegian vocational rehabilitation programs”. University of
Bergen Working Paper 0599; and University of Chicago.
Aakvik, A., Heckman, J.J., Vytlacil, E.J. (2005). “Estimating treatment effects for discrete outcomes when
responses to treatment vary: An application to Norwegian vocational rehabilitation programs”. Journal of
Econometrics 125 (1–2), 15–51.
Abadie, A. (2002). “Bootstrap tests of distributional treatment effects in instrumental variable models”. Journal of the American Statistical Association 97 (457), 284–292 (March).
Abadie, A., Imbens, G.W. (2006). “Large sample properties of matching estimators for average treatment
effects”. Econometrica 74 (1), 235–267 (January).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5135

Ahn, H., Powell, J. (1993). “Semiparametric estimation of censored selection models with a nonparametric
selection mechanism”. Journal of Econometrics 58 (1–2), 3–29 (July).
Aigner, D.J. (1979a). “A brief introduction to the methodology of optimal experimental design”. Journal of
Econometrics 11 (1), 7–26.
Aigner, D.J. (1979b). “Sample design for electricity pricing experiments: Anticipated precision for a time-ofday pricing experiment”. Journal of Econometrics 11 (1), 195–205 (September).
Aigner, D.J. (1985). “The residential electricity time-of-use pricing experiments: What have we learned?”.
In: Hausman, J.A., Wise, D.A. (Eds.), Social Experimentation. University of Chicago Press, Chicago,
pp. 11–41.
Aigner, D.J., Hsiao, C., Kapteyn, A., Wansbeek, T. (1984). “Latent variable models in econometrics”. In:
Griliches, Z., Intriligator, M.D. (Eds.), Handbook of Econometrics, vol. 2. Elsevier, pp. 1321–1393 (Chapter 23).
Altonji, J.G., Matzkin, R.L. (2005). “Cross section and panel data estimators for nonseparable models with
endogenous regressors”. Econometrica 73 (4), 1053–1102 (July).
Angrist, J.D., Imbens, G.W. (1995). “Two-stage least squares estimation of average causal effects in models
with variable treatment intensity”. Journal of the American Statistical Association 90 (430), 431–442
(June).
Angrist, J.D., Krueger, A.B. (1999). “Empirical strategies in labor economics”. In: Ashenfelter, O., Card, D.
(Eds.), Handbook of Labor Economics, vol. 3A. North-Holland, New York, pp. 1277–1366.
Angrist, J.D., Graddy, K., Imbens, G. (2000). “The interpretation of instrumental variables estimators in simultaneous equations models with an application to the demand for fish”. Review of Economic Studies 67
(3), 499–527 (July).
Angrist, J.D., Imbens, G.W., Rubin, D. (1996). “Identification of causal effects using instrumental variables”.
Journal of the American Statistical Association 91 (434), 444–455.
Athey, S., Imbens, G.W. (2006). “Identification and inference in nonlinear difference-in-differences models”.
Econometrica 74 (2), 431–497 (March).
Balke, A., Pearl, J. (1997). “Bounds on treatment effects from studies with imperfect compliance”. Journal of
the American Statistical Association 92 (439), 1171–1176 (September).
Banerjee, A.V. (2006). “Making aid work: How to fight global poverty – Effectively”. Boston Review 31 (4)
(July/August).
Barnow, B.S., Cain, G.G., Goldberger, A.S. (1980). “Issues in the analysis of selectivity bias”. In: Stromsdorfer, E., Farkas, G. (Eds.), Evaluation Studies, vol. 5. Sage Publications, Beverly Hills, CA, pp. 42–59.
Barros, R.P. (1987). “Two essays on the nonparametric estimation of economic models with selectivity using
choice-based samples”. PhD thesis. University of Chicago.
Basu, A., Heckman, J.J., Navarro-Lozano, S., Urzua, S. (2007). “Use of instrumental variables in the presence of heterogeneity and self-selection: An application to treatments in breast cancer patients”. Health
Economics 16 (11), 1133–1157 (October).
Behrman, J.R., Sengupta, P., Todd, P. (2005). “Progressing through PROGRESA: An impact assessment of a
school subsidy experiment in rural Mexico”. Economic Development and Cultural Change 54 (1), 237–
275 (October).
Bertrand, M., Duflo, E., Mullainathan, S. (2004). “How much should we trust differences-in-differences estimates?”. Quarterly Journal of Economics 119 (1), 249–275 (February).
Bickel, P.J. (1967). “Some contributions to the theory of order statistics”. In: LeCam, L., Neyman, J. (Eds.),
Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability. University of
California Press, Berkeley, CA, pp. 575–591.
Björklund, A., Moffitt, R. (1987). “The estimation of wage gains and welfare gains in self-selection”. Review
of Economics and Statistics 69 (1), 42–49 (February).
Bloom, H.S. (1984). “Accounting for no-shows in experimental evaluation designs”. Evaluation Review 82
(2), 225–246.
Blundell, R., Powell, J. (2003). “Endogeneity in nonparametric and semiparametric regression models”. In:
Dewatripont, L.P.H.M., Turnovsky, S.J. (Eds.), Advances in Economics and Econometrics: Theory and
Applications, Eighth World Congress, vol. 2. Cambridge Univ. Press, Cambridge, UK.

5136

J.J. Heckman and E.J. Vytlacil

Blundell, R., Powell, J. (2004). “Endogeneity in semiparametric binary response models”. Review of Economic Studies 71 (3), 655–679 (July).
Blundell, R., Duncan, A., Meghir, C. (1998). “Estimating labor supply responses using tax reforms”. Econometrica 66 (4), 827–861 (July).
Bresnahan, T.F. (1987). “Competition and collusion in the American automobile industry: The 1955 price
war”. Journal of Industrial Economics 35 (4), 457–482 (June).
Cain, G.G., Watts, H.W. (1973). Income Maintenance and Labor Supply: Econometric Studies. Academic
Press, New York.
Cameron, S.V., Heckman, J.J. (1993). “The nonequivalence of high school equivalents”. Journal of Labor
Economics 11 (1, Part 1), 1–47 (January).
Cameron, S.V., Heckman, J.J. (1998). “Life cycle schooling and dynamic selection bias: Models and evidence
for five cohorts of American males”. Journal of Political Economy 106 (2), 262–333 (April).
Campbell, D.T. (1969). “Reforms as experiments”. American Psychologist 24 (4), 409–429. Reprinted in:
Struening, E.L., Guttentag, M. (Eds.), Handbook of Evaluation Research, vols. 1, 2. Sage Publication,
Beverly Hills, CA, 1975, pp. 71–99 (vol. 1).
Campbell, D.T., Stanley, J.C. (1963). Experimental and Quasi-Experimental Designs for Research. Rand
McNally, Chicago (originally appeared in Gage, N.L. (Ed.), Handbook of Research on Teaching).
Card, D. (1999). “The causal effect of education on earnings”. In: Ashenfelter, O., Card, D. (Eds.), Handbook
of Labor Economics, vol. 5. North-Holland, New York, pp. 1801–1863.
Card, D. (2001). “Estimating the return to schooling: Progress on some persistent econometric problems”.
Econometrica 69 (5), 1127–1160 (September).
Carneiro, P. (2002). “Heterogeneity in the returns to schooling: Implications for policy evaluation”. PhD
thesis. University of Chicago.
Carneiro, P., Hansen, K., Heckman, J.J. (2001). “Removing the veil of ignorance in assessing the distributional
impacts of social policies”. Swedish Economic Policy Review 8 (2), 273–301 (Fall).
Carneiro, P., Hansen, K., Heckman, J.J. (2003). “Estimating distributions of treatment effects with an application to the returns to schooling and measurement of the effects of uncertainty on college choice”.
International Economic Review 44 (2), 361–422 (May). 2001 Lawrence R. Klein Lecture.
Carneiro, P., Heckman, J.J., Vytlacil, E.J. (2006). “Estimating marginal and average returns to education”.
American Economic Review. Submitted for publication.
Cave, G., Bos, H., Doolittle, F., Toussaint, C. (1993). “JOBSTART: Final report on a program for school
dropouts”. Technical report, MDRC.
Chan, T.Y., Hamilton, B.H. (2006). “Learning, private information and the economic evaluation of randomized experiments”. Journal of Political Economy 114 (6), 997–1040 (December).
Chen, S. (1999). “Distribution-free estimation of the random coefficient dummy endogenous variable model”.
Journal of Econometrics 91 (1), 171–199 (July).
Chen, X., Fan, Y. (1999). “Consistent hypothesis testing in semiparametric and nonparametric models for
econometric time series”. Journal of Econometrics 91 (2), 373–401 (August).
Chernozhukov, V., Hansen, C. (2005). “An IV model of quantile treatment effects”. Econometrica 73 (1),
245–261 (January).
Chernozhukov, V., Imbens, G.W., Newey, W.K. (2007). “Nonparametric identification and estimation of nonseparable models”. Journal of Econometrics 139 (1), 1–3 (July).
Cochran, W.G., Rubin, D.B. (1973). “Controlling bias in observational studies: A review”. Sankyha Ser. A 35
(Part 4), 417–446.
Conlisk, J. (1973). “Choice of response functional form in designing subsidy experiments”. Econometrica 41
(4), 643–656 (July).
Conlisk, J., Watts, H. (1969). “A model for optimizing experimental designs for estimating response surfaces”.
American Statistical Association Proceedings Social Statistics Section, 150–156.
Cook, T.D., Campbell, D.T. (1979). Quasi-Experimentation: Design and Analysis Issues for Field Settings.
Rand McNally College Publishing Company, Chicago.
Cunha, F., Heckman, J.J. (2007). “Identifying and estimating the distributions of Ex Post and Ex Ante returns
to schooling: A survey of recent developments”. Labour Economics 14 (6), 870–893 (December).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5137

Cunha, F., Heckman, J.J. (2008). “A new framework for the analysis of inequality”. Macroeconomic Dynamics. Submitted for publication.
Cunha, F., Heckman, J.J., Matzkin, R. (2003). “Nonseparable factor analysis”. Unpublished manuscript. Department of Economics, University of Chicago.
Cunha, F., Heckman, J.J., Navarro, S. (2005). “Separating uncertainty from heterogeneity in life cycle earnings”. Oxford Economic Papers 57 (2), 191–261 (April). The 2004 Hicks lecture.
Cunha, F., Heckman, J.J., Navarro, S. (2006). “Counterfactual analysis of inequality and social mobility”.
In: Morgan, S.L., Grusky, D.B., Fields, G.S. (Eds.), Mobility and Inequality: Frontiers of Research in
Sociology and Economics. Stanford Univ. Press, Stanford, CA, pp. 290–348 (Chapter 4).
Cunha, F., Heckman, J.J., Navarro, S. (2007). “The identification and economic content of ordered choice
models with stochastic cutoffs”. International Economic Review. In press, November.
Cunha, F., Heckman, J.J., Schennach, S.M. (2007). “Estimating the technology of cognitive and noncognitive
skill formation”. Unpublished manuscript, University of Chicago, Department of Economics. Presented
at the Yale Conference on Macro and Labor Economics, May 5–7, 2006. Econometrica. Submitted for
publication.
Cunha, F., Heckman, J.J., Schennach, S.M. (2006b). “Nonlinear factor analysis”. Unpublished manuscript.
Department of Economics, University of Chicago.
Dahl, G.B. (2002). “Mobility and the return to education: Testing a Roy model with multiple markets”. Econometrica 70 (6), 2367–2420 (November).
Darolles, S., Florens, J.-P., Renault, E. (2002). “Nonparametric instrumental regression”. Working Paper 052002. Centre interuniversitaire de recherche en économie quantitative, CIREQ.
Deaton, A. (2006). “Evidence-based aid must not become the latest in a long string of development fads”.
Boston Review 31 (4) (July/August).
Domencich, T., McFadden, D.L. (1975). Urban Travel Demand: A Behavioral Analysis. North-Holland, Amsterdam. Reprinted 1996.
Doolittle, F.C., Traeger, L. (1990). Implementing the National JTPA Study. Manpower Demonstration Research Corporation, New York.
Duncan, G.M., Leigh, D.E. (1985). “The endogeneity of union status: An empirical test”. Journal of Labor
Economics 3 (3), 385–402 (July).
Durbin, J. (1954). “Errors in variables”. Review of the International Statistical Institute 22, 23–32.
Ellison, G., Ellison, S.F. (1999). “A simple framework for nonparametric specification testing”. Journal of
Econometrics 96, 1–23 (May).
Farber, H.S. (1983). “Worker preferences for union representation”. In: Reid, J. (Ed.), Research in Labor
Economics, Volume Supplement 2: New Approaches to Labor Unions. JAI Press, Greenwich, CT.
Fisher, R.A. (1966). The Design of Experiments. Hafner Publishing, New York.
Florens, J.-P., Heckman, J.J., Meghir, C., Vytlacil, E.J. (2002). “Instrumental variables, local instrumental
variables and control functions”. Technical Report CWP15/02, CEMMAP. Econometrica. Submitted for
publication.
Florens, J.-P., Heckman, J.J., Meghir, C., Vytlacil, E.J. (2006). “Control functions for nonparametric models
without large support”. Unpublished manuscript. University of Chicago.
Friedlander, D., Hamilton, G. (1993). “The Saturation Work Initiative Model in San Diego: A Five-Year
Follow-Up Study”. Manpower Demonstration Research Corporation, New York.
Gerfin, M., Lechner, M. (2002). “A microeconomic evaluation of the active labor market policy in Switzerland”. Economic Journal 112 (482), 854–893 (October).
Gill, R.D., Robins, J.M. (2001). “Causal inference for complex longitudinal data: The continuous case”. The
Annals of Statistics 29 (6), 1785–1811 (December).
Glynn, R.J., Laird, N.M., Rubin, D.B. (1986). “Selection modeling versus mixture modeling with nonignorable nonresponse”. In: Wainer, H. (Ed.), Drawing Inferences from Self-Selected Samples. SpringerVerlag, New York, pp. 115–142. Reprinted in: Lawrence Erlbaum Associates, Mahwah, NJ, 2000.
Gronau, R. (1974). “Wage comparisons – A selectivity bias”. Journal of Political Economy 82 (6), 1119–1143
(November–December).

5138

J.J. Heckman and E.J. Vytlacil

Haavelmo, T. (1943). “The statistical implications of a system of simultaneous equations”. Econometrica 11
(1), 1–12 (January).
Hahn, J. (1998). “On the role of the propensity score in efficient semiparametric estimation of average treatment effects”. Econometrica 66 (2), 315–331 (March).
Hahn, J., Todd, P.E., Van der Klaauw, W. (2001). “Identification and estimation of treatment effects with a
regression-discontinuity design”. Econometrica 69 (1), 201–209 (January).
Hall, P., Horowitz, J. (2005). “Nonparametric methods for inference in the presence of instrumental variables”.
Annals of Statistics 33 (6), 2904–2929 (September).
Hansen, K.T., Heckman, J.J., Mullen, K.J. (2004). “The effect of schooling and ability on achievement test
scores”. Journal of Econometrics 121 (1–2), 39–98 (July–August).
Härdle, W. (1990). Applied Nonparametric Regression. Cambridge Univ. Press, New York.
Harmon, C., Walker, I. (1999). “The marginal and average returns to schooling in the UK”. European Economic Review 43 (4–6), 879–887 (April).
Hausman, J.A. (1978). “Specification tests in econometrics”. Econometrica 46 (6), 1251–1272 (November).
Heckman, J.J. (1974a). “Effects of child-care programs on women’s work effort”. Journal of Political Economy 82 (2), S136–S163. Reprinted in: Schultz, T.W. (Ed.), Economics of the Family: Marriage, Children
and Human Capital. University of Chicago Press, 1974 (March/April).
Heckman, J.J. (1974b). “Shadow prices, market wages, and labor supply”. Econometrica 42 (4), 679–694
(July).
Heckman, J.J. (1976a). “The common structure of statistical models of truncation, sample selection and
limited dependent variables and a simple estimator for such models”. Annals of Economic and Social
Measurement 5 (4), 475–492 (December).
Heckman, J.J. (1976b). “A life-cycle model of earnings, learning, and consumption”. Journal of Political
Economy 84 (4, Part 2), S11–S44 (August). Journal Special Issue: Essays in Labor Economics in Honor
of H. Gregg Lewis.
Heckman, J.J. (1976c). “Simultaneous equation models with both continuous and discrete endogenous variables with and without structural shift in the equations”. In: Goldfeld, S., Quandt, R. (Eds.), Studies in
Nonlinear Estimation. Ballinger Publishing Company, Cambridge, MA, pp. 235–272.
Heckman, J.J. (1980). “Addendum to sample selection bias as a specification error”. In: Stromsdorfer, E.,
Farkas, G. (Eds.), Evaluation Studies Review Annual, vol. 5. Sage Publications, Beverly Hills, CA.
Heckman, J.J. (1990). “Varieties of selection bias”. American Economic Review 80 (2), 313–318 (May).
Heckman, J.J. (1992). “Randomization and social policy evaluation”. In: Manski, C., Garfinkel, I. (Eds.),
Evaluating Welfare and Training Programs. Harvard Univ. Press, Cambridge, MA, pp. 201–230.
Heckman, J.J. (1996). “Randomization as an instrumental variable”. Review of Economics and Statistics 78
(2), 336–340 (May).
Heckman, J.J. (1997). “Instrumental variables: A study of implicit behavioral assumptions used in making
program evaluations”. Journal of Human Resources 32 (3), 441–462 (Summer). Addendum published in:
Juornal of Human Resources 33 (1) (1998) (Winter).
Heckman, J.J. (1998). “The effects of government policies on human capital investment, unemployment and
earnings inequality”. In: Third Public GAAC Symposium: Labor Markets in the USA and Germany, vol. 5.
German–American Academic Council Foundation, Bonn, Germany.
Heckman, J.J. (2001). “Micro data, heterogeneity, and the evaluation of public policy: Nobel lecture”. Journal
of Political Economy 109 (4), 673–748 (August).
Heckman, J.J., Honoré, B.E. (1990). “The empirical content of the Roy model”. Econometrica 58 (5), 1121–
1149 (September).
Heckman, J.J., Hotz, V.J. (1989). “Choosing among alternative nonexperimental methods for estimating the
impact of social programs: The case of Manpower Training”. Journal of the American Statistical Association 84 (408), 862–874 (December). Rejoinder also published in: Journal of the American Statistical
Association 84 (408) (1989) (December).
Heckman, J.J., LaFontaine, P. (2007). America’s Dropout Problem: The GED and the Importance of Social
and Emotional Skills. University of Chicago Press, Chicago. Submitted for publication.

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5139

Heckman, J.J., Navarro, S. (2004). “Using matching, instrumental variables, and control functions to estimate
economic choice models”. Review of Economics and Statistics 86 (1), 30–57 (February).
Heckman, J.J., Navarro, S. (2007). “Dynamic discrete choice and dynamic treatment effects”. Journal of
Econometrics 136 (2), 341–396 (February).
Heckman, J.J., Robb, R. (1985a). “Alternative methods for evaluating the impact of interventions”. In: Heckman, J., Singer, B. (Eds.), Longitudinal Analysis of Labor Market Data, vol. 10. Cambridge Univ. Press,
New York, pp. 156–245.
Heckman, J.J., Robb, R. (1985b). “Alternative methods for evaluating the impact of interventions: An
overview”. Journal of Econometrics 30 (1–2), 239–267 (October–November).
Heckman, J.J., Robb, R. (1986a). “Alternative methods for solving the problem of selection bias in evaluating
the impact of treatments on outcomes”. In: Wainer, H. (Ed.), Drawing Inferences from Self-Selected
Samples. Springer-Verlag, New York, pp. 63–107. Reprinted in: Lawrence Erlbaum Associates, Mahwah,
NJ, 2000.
Heckman, J.J., Robb, R. (1986b). “Postscript: A rejoinder to Tukey”. In: Wainer, H. (Ed.), Drawing Inferences
from Self-Selected Samples. Springer-Verlag, New York, pp. 111–114. Reprinted in: Lawrence Erlbaum
Associates, Mahwah, NJ, 2000.
Heckman, J.J., Sedlacek, G.L. (1990). “Self-selection and the distribution of hourly wages”. Journal of Labor
Economics 8 (1, Part 2), S329–S363. Essays in Honor of Albert Rees.
Heckman, J.J., Smith, J.A. (1993). “Assessing the case for randomized evaluation of social programs”. In:
Jensen, K., Madsen, P. (Eds.), Measuring Labour Market Measures: Evaluating the Effects of Active
Labour Market Policy Initiatives, Proceedings from the Danish Presidency Conference “Effects and
Measuring of Effects of Labour Market Policy Initiatives”. Denmark Ministry of Labour, Copenhagen,
pp. 35–95.
Heckman, J.J., Smith, J.A. (1998). “Evaluating the welfare state”. In: Strom, S. (Ed.), Econometrics and
Economic Theory in the Twentieth Century: The Ragnar Frisch Centennial Symposium. Cambridge Univ.
Press, New York, pp. 241–318.
Heckman, J.J., Smith, J.A. (1999). “The pre-programme earnings dip and the determinants of participation
in a social programme. Implications for simple programme evaluation strategies”. Economic Journal 109
(457), 313–348 (July). Winner of the Royal Economic Society Prize, 1999.
Heckman, J.J., Vytlacil, E.J. (1998). “Instrumental variables methods for the correlated random coefficient
model: Estimating the average rate of return to schooling when the return is correlated with schooling”.
Journal of Human Resources 33 (4), 974–987 (Fall).
Heckman, J.J., Vytlacil, E.J. (1999). “Local instrumental variables and latent variable models for identifying and bounding treatment effects”. Proceedings of the National Academy of Sciences 96, 4730–4734
(April).
Heckman, J.J., Vytlacil, E.J. (2000). “The relationship between treatment parameters within a latent variable
framework”. Economics Letters 66 (1), 33–39 (January).
Heckman, J.J., Vytlacil, E.J. (2001a). “Instrumental variables, selection models, and tight bounds on the
average treatment effect”. In: Lechner, M., Pfeiffer, F. (Eds.), Econometric Evaluation of Labour Market
Policies. Center for European Economic Research, New York, pp. 1–15.
Heckman, J.J., Vytlacil, E.J. (2001b). “Local instrumental variables”. In: Hsiao, C., Morimune, K., Powell,
J.L. (Eds.), Nonlinear Statistical Modeling: Proceedings of the Thirteenth International Symposium in
Economic Theory and Econometrics. Essays in Honor of Takeshi Amemiya. Cambridge Univ. Press, New
York, pp. 1–46.
Heckman, J.J., Vytlacil, E.J. (2001c). “Policy-relevant treatment effects”. American Economic Review 91 (2),
107–111 (May).
Heckman, J.J., Vytlacil, E.J. (2005). “Structural equations, treatment effects and econometric policy evaluation”. Econometrica 73 (3), 669–738 (May).
Heckman, J.J., Vytlacil, E.J. (2007). “Evaluating marginal policy changes and the average effect of treatment
for individuals at the margin”. Columbia University, Department of Economics. Unpublished manuscript.
Heckman, J.J., Ichimura, H., Todd, P.E. (1997). “Matching as an econometric evaluation estimator: Evidence
from evaluating a job training programme”. Review of Economic Studies 64 (4), 605–654 (October).

5140

J.J. Heckman and E.J. Vytlacil

Heckman, J.J., Ichimura, H., Todd, P.E. (1998). “Matching as an econometric evaluation estimator”. Review
of Economic Studies 65 (223), 261–294 (April).
Heckman, J.J., LaLonde, R.J., Smith, J.A. (1999). “The economics and econometrics of active labor market
programs”. In: Ashenfelter, O., Card, D. (Eds.), Handbook of Labor Economics, vol. 3A. North-Holland,
New York, pp. 1865–2097 (Chapter 31).
Heckman, J.J., Lochner, L.J., Taber, C. (1998). “General-equilibrium treatment effects: A study of tuition
policy”. American Economic Review 88 (2), 381–386 (May).
Heckman, J.J., Lochner, L.J., Todd, P.E. (2006). “Earnings equations and rates of return: The Mincer equation
and beyond”. In: Hanushek, E.A., Welch, F. (Eds.), Handbook of the Economics of Education. NorthHolland, Amsterdam, pp. 307–458.
Heckman, J.J., Smith, J.A., Clements, N. (1997). “Making the most out of programme evaluations and social experiments: Accounting for heterogeneity in programme impacts”. Review of Economic Studies 64
(221), 487–536 (October).
Heckman, J.J., Smith, J.A., Taber, C. (1998). “Accounting for dropouts in evaluations of social programs”.
Review of Economics and Statistics 80 (1), 1–14 (February).
Heckman, J.J., Tobias, J.L., Vytlacil, E.J. (2003). “Simple estimators for treatment parameters in a latent
variable framework”. Review of Economics and Statistics 85 (3), 748–754 (August).
Heckman, J.J., Urzua, S., Vytlacil, E.J. (2004). “Understanding instrumental variables in models with essential heterogeneity: Unpublished results”. Unpublished manuscript. Department of Economics, University
of Chicago.
Heckman, J.J., Urzua, S., Vytlacil, E.J. (2006). “Understanding instrumental variables in models with essential heterogeneity”. Review of Economics and Statistics 88 (3), 389–432.
Heckman, J.J., Ichimura, H., Smith, J., Todd, P.E. (1998). “Characterizing selection bias using experimental
data”. Econometrica 66 (5), 1017–1098 (September).
Heckman, J.J., Hohmann, N., Smith, J., Khoo, M. (2000). “Substitution and dropout bias in social experiments: A study of an influential social experiment”. Quarterly Journal of Economics 115 (2), 651–694
(May).
Hirano, K., Imbens, G.W., Ridder, G. (2003). “Efficient estimation of average treatment effects using the
estimated propensity score”. Econometrica 71 (4), 1161–1189 (July).
Hollister, R.G., Kemper, P., Maynard, R.A. (1984). The National Supported Work Demonstration. University
of Wisconsin Press, Madison, WI.
Hotz, V.J. (1992). “Designing an evaluation of the Job Training Partnership Act”. In: Manski, C., Garfinkel,
I. (Eds.), Evaluating Welfare and Training Programs. Harvard Univ. Press, Cambridge, MA, pp. 76–114.
Hotz, V.J., Mullin, C.H., Sanders, S.G. (1997). “Bounding causal effects using data from a contaminated
natural experiment: Analysing the effects of teenage childbearing”. Review of Economic Studies 64 (4),
575–603 (October).
Hu, Y., Schennach, S.M. (2006). “Identification and estimation of nonclassical nonlinear errors-in-variables
models with continuous distributions”. Working Paper. University of Chicago.
Hurwicz, L. (1962). “On the structural form of interdependent systems”. In: Nagel, E., Suppes, P., Tarski, A.
(Eds.), Logic, Methodology and Philosophy of Science. Stanford Univ. Press, pp. 232–239.
Ichimura, H., Taber, C. (2002). “Semiparametric reduced-form estimation of tuition subsidies”. American
Economic Review 92 (2), 286–292 (May).
Ichimura, H., Thompson, T.S. (1998). “Maximum likelihood estimation of a binary choice model with random
coefficients of unknown distribution”. Journal of Econometrics 86 (2), 269–295 (October).
Ichimura, H., Todd, P.E. (2007). “Implementing nonparametric and semiparametric estimators”. In: Heckman,
J., Leamer, E. (Eds.), Handbook of Econometrics, vol. 6B. Elsevier, Amsterdam.
Imbens, G.W. (2003). “Sensitivity to exogeneity assumptions in program evaluation”. American Economic
Review 93 (2), 126–132 (May).
Imbens, G.W. (2004). “Nonparametric estimation of average treatment effects under exogeneity: A review”.
Review of Economics and Statistics 86 (1), 4–29 (February).
Imbens, G.W., Angrist, J.D. (1994). “Identification and estimation of local average treatment effects”. Econometrica 62 (2), 467–475 (March).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5141

Imbens, G.W., Newey, W.K. (2002). “Identification and estimation of triangular simultaneous equations models without additivity”. Technical Working Paper 285. National Bureau of Economic Research.
Kramer, M.S., Shapiro, S.H. (1984). “Scientific challenges in the application of randomized trials”. JAMA:
The Journal of the American Medical Association 252 (19), 2739–2745 (November).
Kemple, J.J., Friedlander, D., Fellerath, V. (1995). “Florida’s Project Independence: Benefits, Costs, and TwoYear Impacts of Florida’s JOBS Program”. Manpower Demonstration Research Corporation, New York.
LaLonde, R.J. (1984). “Evaluating the econometric evaluations of training programs with experimental data”.
Technical Report 183. Industrial Relations Section, Department of Economics, Princeton University.
Lechner, M. (2001). “Identification and estimation of causal effects of multiple treatments under the conditional independence assumption”. In: Lechner, M., Pfeiffer, F. (Eds.), Econometric Evaluations of Active
Labor Market Policies in Europe. Physica/Springer, Heidelberg.
Lee, L.-F. (1978). “Unionism and wage rates: A simultaneous equations model with qualitative and limited
dependent variables”. International Economic Review 19 (2), 415–433 (June).
Lee, L.-F. (1983). “Generalized econometric models with selectivity”. Econometrica 51 (2), 507–512
(March).
Mallar, C., Kerachsky, S., Thorton, C. (1980). “The short-term economic impact of the Job Corps program”.
In: Stromsdorfer, E., Farkas, G. (Eds.), Evaluation Studies Review Annual, vol. 5. Sage Publications.
Manski, C.F. (1989). “Anatomy of the selection problem”. Journal of Human Resources 24 (3), 343–360
(Summer).
Manski, C.F. (1990). “Nonparametric bounds on treatment effects”. American Economic Review 80 (2), 319–
323 (May).
Manski, C.F. (1994). “The selection problem”. In: Sims, C. (Ed.), Advances in Econometrics: Sixth World
Congress. Cambridge Univ. Press, New York, pp. 143–170.
Manski, C.F. (1995). Identification Problems in the Social Sciences. Harvard Univ. Press, Cambridge, MA.
Manski, C.F. (1996). “Learning about treatment effects from experiments with random assignment of treatments”. Journal of Human Resources 31 (4), 709–733 (Autumn).
Manski, C.F. (1997). “Monotone treatment response”. Econometrica 65 (6), 1311–1334 (November).
Manski, C.F. (2003). Partial Identification of Probability Distributions. Springer-Verlag, New York.
Manski, C.F., Pepper, J.V. (2000). “Monotone instrumental variables: With an application to the returns to
schooling”. Econometrica 68 (4), 997–1010 (July).
Mare, R.D. (1980). “Social background and school continuation decisions”. Journal of the American Statistical Association 75 (370), 295–305 (June).
Marschak, J. (1953). “Economic measurements for policy and prediction”. In: Hood, W., Koopmans, T. (Eds.),
Studies in Econometric Method. Wiley, New York, pp. 1–26.
Masters, S.H., Maynard, R.A. (1981). The Impact of Supported Work on Long-Term Recipients of AFDC
Benefits. Manpower Demonstration Research Corporation, New York.
Matzkin, R.L. (1993). “Nonparametric identification and estimation of polychotomous choice models”. Journal of Econometrics 58 (1–2), 137–168 (July).
Matzkin, R.L. (1994). “Restrictions of economic theory in nonparametric methods”. In: Engle, R., McFadden,
D. (Eds.), Handbook of Econometrics, vol. 4. North-Holland, New York, pp. 2523–2558.
Matzkin, R.L. (2003). “Nonparametric estimation of nonadditive random functions”. Econometrica 71 (5),
1339–1375 (September).
Matzkin, R.L. (2007). “Nonparametric identification”. In: Heckman, J., Leamer, E. (Eds.), Handbook of
Econometrics, vol. 6B. Elsevier, Amsterdam.
Maynard, R., Brown, R.S. (1980). The Impact of Supported Work on Young School Dropouts. Manpower
Demonstration Research Corporation, New York.
McFadden, D. (1974). “Conditional logit analysis of qualitative choice behavior”. In: Zarembka, P. (Ed.),
Frontiers in Econometrics. Academic Press, New York.
Moffitt, R. (1992). “Evaluation methods for program entry effects”. In: Manski, C., Garfinkel, I. (Eds.), Evaluating Welfare and Training Programs. Harvard Univ. Press, Cambridge, MA, pp. 231–252.
Newey, W.K., Powell, J.L. (2003). “Instrumental variable estimation of nonparametric models”. Econometrica 71 (5), 1565–1578 (September).

5142

J.J. Heckman and E.J. Vytlacil

Olley, G.S., Pakes, A. (1996). “The dynamics of productivity in the telecommunications equipment industry”.
Econometrica 64 (6), 1263–1297 (November).
Palca, J. (1989). “AIDS drug trials enter new age”. Science, New Series 246 (4926), 19–21 (October 6).
Pearl, J. (2000). Causality. Cambridge Univ. Press, Cambridge, England.
Pessino, C. (1991). “Sequential migration theory and evidence from Peru”. Journal of Development Economics 36 (1), 55–87 (July).
Peterson, A.V. (1976). “Bounds for a joint distribution function with fixed sub-distribution functions: Application to competing risks”. Proceedings of the National Academy of Sciences 73 (1), 11–13 (January).
Powell, J.L. (1994). “Estimation of semiparametric models”. In: Engle, R., McFadden, D. (Eds.), Handbook
of Econometrics, vol. 4. Elsevier, Amsterdam, pp. 2443–2521.
Prescott, E.C., Visscher, M. (1977). “Sequential location among firms with foresight”. Bell Journal of Economics 8 (2), 378–893 (Autumn).
Quandt, R.E. (1958). “The estimation of the parameters of a linear regression system obeying two separate
regimes”. Journal of the American Statistical Association 53 (284), 873–880 (December).
Quandt, R.E. (1972). “A new approach to estimating switching regressions”. Journal of the American Statistical Association 67 (338), 306–310 (June).
Quint, J.C., Polit, D.F., Bos, H., Cave, G. (1994). New Chance Interim Findings on a Comprehensive Program
for Disadvantaged Young Mothers and Their Children. Manpower Demonstration Research Corporation,
New York.
Rao, C.R. (1985). “Weighted distributions”. In: Atkinson, A., Fienberg, S. (Eds.), A Celebration of Statistics:
The ISI Centenary Volume. Springer-Verlag, New York.
Robins, J.M. (1989). “The analysis of randomized and non-randomized AIDS treatment trials using a new
approach to causal inference in longitudinal studies”. In: Sechrest, L., Freeman, H., Mulley, A. (Eds.),
Health Services Research Methodology: A Focus on AIDS. United States Department of Health and
Human Services, National Center for Health Services Research and Health Care Technology Assessment,
Rockville, MD, pp. 113–159.
Robins, J.M. (1997). “Causal inference from complex longitudinal data”. In: Berkane, M. (Ed.), Latent Variable Modeling and Applications to Causality. In: Lecture Notes in Statistics. Springer-Verlag, New York,
pp. 69–117.
Robinson, C. (1989). “The joint determination of union status and union wage effects: Some tests of alternative models”. Journal of Political Economy 97 (3), 639–667.
Rosenbaum, P.R. (1995). Observational Studies. Springer-Verlag, New York.
Rosenbaum, P.R., Rubin, D.B. (1983). “The central role of the propensity score in observational studies for
causal effects”. Biometrika 70 (1), 41–55 (April).
Roy, A. (1951). “Some thoughts on the distribution of earnings”. Oxford Economic Papers 3 (2), 135–146
(June).
Rubin, D.B. (1974). “Estimating causal effects of treatments in randomized and nonrandomized studies”.
Journal of Educational Psychology 66 (5), 688–701 (October).
Rubin, D.B. (1978). “Bayesian inference for causal effects: The role of randomization”. Annals of Statistics 6
(1), 34–58 (January).
Rubin, D.B. (1979). “Using multivariate matched sampling and regression adjustment to control bias in observational studies”. Journal of the American Statistical Association 74 (366), 318–328 (June).
Rudin, W. (1974). Real and Complex Analysis, second ed. McGraw–Hill, New York.
Schennach, S.M. (2004). “Estimation of nonlinear models with measurement error”. Econometrica 72 (1),
33–75 (January).
Shaked, A., Sutton, J. (1982). “Relaxing price competition through product differentiation”. Review of Economic Studies 49 (1), 3–13 (January).
Silvey, S.D. (1970). Statistical Inference. Penguin, Harmondsworth.
Smith, J.A. (1992). “The JTPA selection process: A descriptive analysis”. Unpublished working paper. Department of Economics, University of Chicago.
Smith, V.K., Banzhaf, H.S. (2004). “A diagrammatic exposition of weak complementarity and the Willig
condition”. American Journal of Agricultural Economics 86 (2), 455–466 (May).

Ch. 71:

Econometric Evaluation of Social Programs, Part II

5143

Smith, J.P., Welch, F.R. (1986). Closing the Gap: Forty Years of Economic Progress for Blacks. RAND
Corporation, Santa Monica, CA.
Smith, J., Whalley, A., Wilcox, N. (2006). “Are program participants good evaluators?” Unpublished manuscript. Department of Economics, University of Michigan.
Telser, L.G. (1964). “Iterative estimation of a set of linear regression equations”. Journal of the American
Statistical Association 59 (307), 845–862 (September).
Todd, P.E. (1999). “A practical guide to implementing matching estimators”. Unpublished manuscript. Department of Economics, University of Pennsylvania. Prepared for the IADB meeting in Santiago, Chile.
(October).
Todd, P.E. (2007). “Evaluating social programs with endogenous program placement and selection of the
treated”. In: Handbook of Development Economics. Elsevier, Amsterdam. In press.
Todd, P.E. (2008). “Matching estimators”. In: Durlauf, S., Blume, L.E. (Eds.), The New Palgrave Dictionary
of Economics. Palgrave Macmillan, New York. In press.
Torp, H., Raaum, O., Hernæs, E., Goldstein, H. (1993). “The first Norwegian experiment”. In: Burtless, G.
(Ed.), Measuring Labour Market Measures: Evaluating the Effects of Active Labour Market Policy Initiatives, Proceedings from the Danish Presidency Conference “Effects and Measuring of Effects of Labour
Market Policy Initiatives”. Kolding, May 1993. Denmark Ministry of Labour, Copenhagen.
Tunali, I. (2000). “Rationality of migration”. International Economic Review 41 (4), 893–920 (November).
Vijverberg, W.P.M. (1993). “Measuring the unidentified parameter of the extended Roy model of selectivity”.
Journal of Econometrics 57 (1–3), 69–89 (May–June).
Vytlacil, E.J. (2002). “Independence, monotonicity, and latent index models: An equivalence result”. Econometrica 70 (1), 331–341 (January).
Vytlacil, E.J. (2006a). “A note on additive separability and latent index models of binary choice: Representation results”. Oxford Bulletin of Economics and Statistics 68 (4), 515–518 (August).
Vytlacil, E.J. (2006b). “Ordered discrete choice selection models: Equivalence, nonequivalence, and representation results”. Review of Economics and Statistics 88 (3), 578–581 (August).
Vytlacil, E.J., Yildiz, N. (2006). “Dummy endogenous variables in weakly separable models”. Unpublished
manuscript. Department of Economics, Columbia University.
Vytlacil, E.J., Santos, A., Shaikh, A.M. (2005). “Limited dependent variable models and bounds on treatment effects: A nonparametric analysis”. Unpublished manuscript. Department of Economics, Columbia
University.
White, H. (1984). Asymptotic Theory for Econometricians. Academic Press, Orlando, FL.
Willis, R.J., Rosen, S. (1979). “Education and self-selection”. Journal of Political Economy 87 (5, Part 2),
S7–S36 (October).
Wooldridge, J.M. (1997). “On two stage least squares estimation of the average treatment effect in a random
coefficient model”. Economics Letters 56 (2), 129–133 (October).
Wooldridge, J.M. (2003). “Further results on instrumental variables estimation of average treatment effects in
the correlated random coefficient model”. Economics Letters 79 (2), 185–191 (May).
Wu, D. (1973). “Alternative tests of independence between stochastic regressors and disturbances”. Econometrica 41 (4), 733–750 (July).
Yitzhaki, S. (1989). “On using linear regression in welfare economics”. Working Paper 217. Department of
Economics, Hebrew University.
Yitzhaki, S. (1996). “On using linear regressions in welfare economics”. Journal of Business and Economic
Statistics 14 (4), 478–486 (October).
Yitzhaki, S., Schechtman, E. (2004). “The Gini Instrumental Variable, or the “double instrumental variable”
estimator”. Metron 62 (3), 287–313.
Zellner, A., Rossi, P.E. (1987). “Evaluating the methodology of social experiments”. In: Munnell, A.H. (Ed.),
Lessons from the Income Maintenance Experiments: Proceedings of a Conference Held at Melvin Village. New Hampshire, September, 1986. In: Federal Reserve Bank of Boston Conference Series, vol. 30.
Brookings Institution, Washington, DC, pp. 131–157.
Zheng, J.X. (1996). “A consistent test of functional form via nonparametric estimation techniques”. Journal
of Econometrics 75, 263–289 (December).

