Debiased/Double Machine Learning for Instrumental Variable
Quantile Regressions

Jau-er Chena,b and Jia-Jyun Tienc

arXiv:1909.12592v1 [econ.EM] 27 Sep 2019

a

Institute for International Strategy, Tokyo International University.

b

Center for Research in Econometric Theory and Applications, National Taiwan University.

c

Department of Economics, National Taiwan University.

Abstract
The aim of this paper is to investigate estimation and inference on a low-dimensional
causal parameter in the presence of high-dimensional controls in an instrumental variable quantile regression. The estimation and inference are based on the Neyman-type
orthogonal moment conditions, that are relatively insensitive to the estimation of the nuisance parameters. The Monte Carlo experiments show that the econometric procedure
performs well. We also apply the procedure to reinvestigate two empirical studies: the
quantile treatment effect of 401(k) participation on accumulated wealth, and the distributional effect of job-training program participation on trainee earnings.

Keywords: instrumental variable, quantile regression, treatment effect, LASSO,
double machine learning.
JEL Classification: C21; C26.

Correspondence: Jau-er Chen. E-mail: jechen@tiu.ac.jp Address: 1-13-1 Matobakita Kawagoe, Saitama 350-1197, Japan.
This version: September 2019. We are grateful to Masayuki Hirukawa, Tsung-Chih Lai, and Hsin-Yi Lin for discussions and
comments. This paper has benefited from presentations at the 2nd International Conference on Econometrics and Statistics
(EcoSta 2018), and the Ryukoku University. The authors declare no conflict of interest. The usual disclaimer applies.
Funding: This research was partly funded by the personal research fund from Tokyo International University, and financially
supported by the Center for Research in Econometric Theory and Applications (Grant no. 107L900203) from The Featured
Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education
(MOE) in Taiwan.

1

Introduction

Model selection and variable selection are widely discussed in the area of prediction. Much
less attention, however, has been paid to the modification of prediction methods under
the context of causal machine learning in economics, cf. Athey (2017) and Athey (2018).
As one of the pioneering papers, within the linear framework of instrumental variable
estimation, Belloni et al. (2014) proposed a double-selection procedure to correct for an
omitted variable bias in a high-dimensional framework. Constructing a general framework
encompassing results from the aforementioned Belloni’s paper, Chernozhukov et al. (2015)
and Chernozhukov et al. (2018a) proposed a unified procedure, double/debiased machine
learning (DML), which remains valid for nonlinear or semi-nonparametric models. The
aim of this paper is to investigate estimation and inference on a low-dimensional causal
parameter in the presence of high-dimensional controls in an instrumental variable quantile
regression. In particular, our procedure follows the idea outlined by Chernozhukov et al
(2018b). To the best of our knowledge, the present study is the first to investigate Monte
Carlo performance and empirical studies of the double machine learning procedure within
the framework of instrumental variable quantile regressions. The Monte Carlo experiments
show that our econometric procedure performs well.
Causal machine learning has been actively studied in economics in recent years, which
are based on two approaches: the double machine learning, cf. Chernozhukov et al.
(2018), and the generalized random forests, cf. Athey, Tibshirani and Wager (2019). Chen
and Hsiang (2019) investigate the generalized random forests model using instrumental
variable quantile regression. In contrast to the DML for instrumental variable quantile
regressions, their econometric procedure yields a measure of variable importance in terms
of heterogeneity among control variables. Although related to our paper, Chen and Hsiang
(2019) do not consider the setting of high-dimensional controls.
We apply the proposed procedure to empirically investigate causal quantile effects of
the 401(k) participation on net financial assets. Our empirical results signify that the
401(k) participants with low savings propensity are more associated with the nonlinear
income effect, which complements the findings concluded in Chernozhukov et al. (2018a)
and Chiou et al. (2018). Another empirical example of the job training program participation is investigated as well.
The rest of the paper is organized as follows. The model specification and estimation
procedure are introduced in Section 2. Section 3 presents Monte Carlo experiments.
Section 4 presents two empirical applications. Section 5 concludes the paper.
2

2

The Model

We briefly review the conventional instrumental variable quantile regression (IVQR), and
then the IVQR within the framework of high-dimensional controls. Our DML procedure
for the IVQR is introduced in this section, which is constructed based on a tentative
procedure suggested by Chernozhukov et al. (2018b).
2.1

The Inverse Quantile Regression as a GMM Estimator

The following conditional moment restriction yields an IVQR estimator.
P[Y ≤ q(τ, D, X)|X, Z] = τ,

(1)

where q(·) is the structural quantile function, τ stands for the quantile index, D, X and
Z are, respectively, the target variable, control variables and instruments. Condition (1)
and linear structural quantile specification leads to the following unconditional moment
restriction
E[(τ − 1(Y − D0 α − X 0 β ≤ 0)Ψ] = 0

(2)

where
Ψ := Ψ(X, Z)
is a vector of a function of instruments and control variables. The parameters depend on
the quantile of interest, but we suppress the τ associated with α and β for simplicity of
presentation. Equation (2) leads to a particular moment condition for doing partialling
out:
gτ (V, α; β, δ) = (τ − 1(Y ≤ D0 α + X 0 β)Ψ(α, δ(α)))

(3)

Ψ(α, δ(α)) := (Z − δ(α)X)

(4)

with “instrument”
δ(α) = M (α)J −1 (α),
where δ is a matrix parameter,
M (α) = E[ZX 0 fε (0|X, Z)], J(α) = E[XX 0 fε (0|X, Z)]
and fε (0|X, Z) is the conditional density of  = Y − D0 α − X 0 β(α) with β(α) defined by
E[(τ − 1(Y ≤ D0 α + X 0 β(α))X] = 0.

3

(5)

We construct the grid search interval for α first and profile out the coefficient for each
α in the interval on the exogenous variable by equation (5). That is,
N
1 X
β̂(a) = arg min
ρτ (Yi − Di0 a − Xi0 b).
b∈B N
i=1

We build sample counterpart of the population moment condition based on equations
(2)–(5). That is,
N
1 X
g(Vi , a, β̂(a), δ̂(a)),
ĝN (a) =
N i=1

(6)

where
c(a)Jb−1 (a)
δ̂(a) = M
for
c(a) =
M

b =
J(a)

N

1 X
Zi Xi0 KhN Yi − Di0 a − Xi0 β̂(a)
N hN i=1
N

1 X
Xi Xi0 KhN Yi − Di0 a − Xi0 β̂(a)
N hN i=1

where KhN is a kernel function with bandwidth hN . We thus can solve for the parameters
through optimizing the GMM criterion function. Specifically,
b a)−1 ĝN (a)
α̂(τ ) = arg min N ĝN (a)0 Σ(a,
a∈A

(7)

N

0
1 X
b
Σ(a1 , a2 ) =
g Vi , a1 , β̂(a1 ) g Vi , a2 , β̂(a2 )
N i=1

b 1 , a2 ) is a weighting matrix used in the GMM estimation. Notice that the
where Σ(a
estimator α̂ based on the inverse quantile regression (i.e. IVQR) is first-order equivalent
to the estimator defined by the GMM.
2.2

Estimation with High-dimensional Controls

We modify the procedure introduced in Subsection 2.1 in order to deal with a dataset of
high-dimensional control variables. We construct the grid search interval for α and profile
out the coefficients on exogenous variable using the L1 -norm penalized quantile regression
estimator:
dim(b)
N
X
1X
0
0
β̂(a) = arg min
ρτ (Yi − Di a − Xi b) + λ
|bj |.
b∈B n
i=1
j=1

4

(8)

In addition, we estimate
c(a) =
M

b =
J(a)

N

1 X
Zi Xi0 KhN Yi − Di0 a − Xi0 β̂(a)
N hN i=1

N

1 X
Xi Xi0 KhN Yi − Di0 a − Xi0 β̂(a) .
N hN i=1

We also do dimension reduction on J because of the large dimension of X. In particular, we implement the following regularization.
1 ˆ
− M̂j (a)δ + ϑ||δ||1 .
δ̂j (a) = arg min δ 0 J(a)δ
δ 2
The regularization above does a weighting LASSO for each instrument variable on control
variables, and consequently the L1 norm optimization obeys the Karush-Kuhn-Tucker
condition
ˆ − M̂j (a)||∞ ≤ ϑ, ∀j.
||δ̂j (a)0 J(a)
(9)
After implementing the double machine learning procedure outlined above for the IVQR,
we now can solve for the low-dimensional causal parameter α through optimizing the
GMM defined as follows. The sample counterpart of the moment condition
N

1 X
ĝN (a) =
τ − 1 Yi − Di0 a − Xi0 β̂(a) ≤ 0 Ψ(a, δ̂(a)).
N i=1

(10)

Accordingly,
b a)−1 ĝN (a).
α̂ = arg min N ĝN (a)0 Σ(a,
a∈A

More importantly, the aforementioned double machine learning procedure (DML-IVQR
hereafter) satisfies the Neyman orthogonality conditions, cf. Chernozhukov et al. (2018b).
2.3

Weak-Identification Robust Inference

Under the regularity conditions listed in Chernozhukov and Hansen (2008), the asymptotic
normality of the GMM estimator with a nonsmooth objective function is guaranteed. We
have

√
d
nĝN (a) −→ N (0, Σ(a, a)).

Consequently, it leads to
d
b a)−1 ĝN (a) −→
N ĝN (a)0 Σ(a,
χ2dim(Z) .

5

(11)

We define
b a)−1 ĝN (a).
WN ≡ N ĝN (a)0 Σ(a,
It then follows that a valid (1 − p) percent confidence region for the true parameter, α0 ,
may be constructed as the set
CR := {α ∈ A : WN (α) ≤ c1−p },
where c1−p is the critical point such that
P [χ2dim(Z) > c1−p ] = p,
and A can be numerical approximated by the grid {αj , j = 1, ..., J}.
2.4

Algorithms for L1-norm Penalized Quantile Optimization

The suggested double machine learning algorithm involves solving L1-norm optimization
which is a nontrivial task. Researchers often represent the L1-norm penalized quantile
objective function as a linear programming problem. Specifically,
minimizep
θ0 ∈R,θ∈R

minimize
p

θ0 ∈R,θ∈R ,ξ∈Rn

subject to

N
X

ρτ (Yi − θ0 − Wi0 θ) + λkθk1

(12)

i=1
N
X
{τ (ξ)+ + (1 − τ )(ξ)− } + λkθk1
i=1

θ0 + x0i θ + ξi = yi , i = 1, . . . , n.

z :=
c :=

[
[

θ0+
0

θ0−
0

a :=

[

A :=

[

0
10

0
−110

(θ+ )0 (θ− )0 (ξ + )0
(ξ − )0
]0
00
00
τ110 (1 − τ )110 ]0
10
10
00
00
]0
−X

X

I0

−I 0

]

b := Y,
where θ = [α0 , β 0 ]0 and W = [D0 , X 0 ]0 .
However, it turns out that the computation is challenging and time-consuming. For
instance, it often meets the singular design within the high dimensional framework. As
an alternative, we utilize the algorithm developed by Yi and Huang (2017) who use the
Huber loss function to approximate the quantile loss function. In the equation (12), ρτ is
not differentiable, and
1
ρτ (t) = (1 − τ )t− + τ t+ = |t| + (2τ − 1)t.
2
6

Since hτ (t) → |t| as τ → 0+ , where hτ (t) is the Huber loss function of t defined in Yi and
Huang (2017), we have ρτ (t) ≈ 12 hτ (t) + (2τ − 1)t for small τ . Therefore the equation
(12) can be approximated by
minimizep
θ0 ∈R,θ∈R

N
X

hτ (Yi − θ0 − Wi0 θ) + (2τ − 1)(Yi − θ0 − Wi0 θ) + λkθk1 .

(13)

i=1

The optimization above stands for the Huber approximation. This optimization problem
is more computationally feasible for the sake of the differentiability of the loss function.

3

Monte Carlo Experiments

We evaluate the finite-sample performance, in terms of RMSE and MAD, of the double
machine learning for the IVQR. The following data generating process is modified from
the one considered in Chen and Lee (2018).
" #
ui
∼N
i

"

#!
1 0.3
0,
0.3 1

 
xi
 
 zi  ∼ N (0, I)
vi
Zi = zi + vi + xi
Di = Φ(zi + i )
Xi = Φ(xi )
Yi = 1 + Di + XiT 1 + Di ∗ ui ,
where Φ(·) is the cumulative distribution function of a standard normal random variable.
Consequently,
α(τ ) = 1 + F−1 (τ ),
where F (·) is the cumulative distribution function of .

7

3.1

Partialing out and nonPartialing out Z on X

We focus on comparing MAD and RMSE resulting from different models under the exact
specification (10 control variables). po-GMM stands for doing partialing out Z on X.
GMM stands for doing no partialing out Z on X. Table 1 shows that doing partialing
out Z on X leads to an efficiency gain across quantiles especially when sample size is
moderate.
Table 1: Partiailing out and nonPartialing out Z on X

α0.1 (po-GMM)
α0.1 (GMM)
α0.25 (po-GMM)
α0.25 (GMM)
α0.5 (po-GMM)
α0.5 (GMM)
α0.75 (po-GMM)
α0.75 (GMM)
α0.90 (po-GMM)
α0.90 (GMM)

n=
RMSE
0.1888
0.4963
0.1210
0.1782
0.0989
0.1436
0.1374
0.2403
0.2437
0.8483

500
MAD
0.1510
0.2559
0.0966
0.1179
0.0716
0.1016
0.1066
0.1710
0.1839
0.5340

n=
RMSE
0.1219
0.1631
0.0812
0.0963
0.0689
0.0801
0.0828
0.1146
0.1391
0.3481

1000
MAD
0.0950
0.1138
0.0654
0.0754
0.0436
0.0542
0.0676
0.0848
0.1067
0.1967

The date generating process considers ten control variables. po-GMM stands for
doing partialing out Z on X. GMM stands for doing no partialing out Z on X.

3.2

IVQR with High-dimensional Controls

We now evaluate the finite-sample performance of the IVQR with high-dimensional controls. The data generating process involves 100 control variables with an approximate
sparsity structure. In particular, the exact model (true model) depends only on 10 relevant control variables out of the 100 controls. GMM uses 100 control variables without
regularization. Table 2 shows that the RMSE and MAD stemmed from the DML-IVQR
are close to those from the exact model. In addition, Figure 1 plots distributions of the
IVQR estimator with/without double machine learning. The DML-IVQR stands for the
double machine learning for the IVQR with high-dimensional controls. Histograms signify that the DML-IVQR estimator is more efficient and less biased than the IVQR using
many control variables. Since a weak-identification robust inference procedure results
naturally form the IVQR, cf. Chernozhukov and Hansen (2008), we construct the robust
confidence regions for the GMM and the DML-IVQR estimators. Figure 2 signifies that,

8

Table 2: IVQR with High-dimensional Controls

α0.1 (GMM)
α0.1 (exact-GMM)
α0.1 (DML-IVQR)
α0.25 (GMM)
α0.25 (exact-GMM)
α0.25 (DML-IVQR)
α0.5 (GMM)
α0.5 (exact-GMM)
α0.5 (DML-IVQR)
α0.75 (GMM)
α0.75 (exact-GMM)
α0.75 (DML-IVQR)
α0.9 (GMM)
α0.9 (exact-GMM)
α0.9 (DML-IVQR)

n=
RMSE
0.7648
0.1888
0.3112
0.2712
0.1210
0.1562
0.1627
0.0989
0.1168
0.3421
0.1374
0.1495
0.9449
0.2437
0.3567

500
MAD
0.6645
0.1510
0.2389
0.2212
0.0966
0.1254
0.1234
0.0716
0.0846
0.2806
0.1066
0.1167
0.8032
0.1839
0.2608

n=
RMSE
0.3917
0.1219
0.1376
0.1646
0.0812
0.0991
0.1038
0.0689
0.0775
0.1747
0.0828
0.0930
0.4320
0.1391
0.1649

1000
MAD
0.3442
0.0950
0.1085
0.1361
0.0654
0.0804
0.0754
0.0436
0.0510
0.1452
0.0676
0.0741
0.3681
0.1067
0.1231

across quantiles, the weak-identification (or weak-instrument) robust confidence region
based on the DML-IVQR is relatively sharp. The Monte Carlo experiments show that
the DML-IVQR procedure performs well.

9

Figure 1: Histograms of the IVQR Estimator with/without the DML

Notice: DML-IVQR results are plotted in green. Results from the GMM with many controls are in orange.

10

Figure 2: Weak-Instrument Robust Inference: DML-IVQR versus GMM

4

Empirical Applications

4.1

Quantile treatment effects of 401(k) participation on accumulated wealth

We reinvestigate impact of the 401(k) participation on accumulated wealth. Total wealth
or net financial asset is the outcome variable Y . Treatment variable D is a binary variable
standing for participation in the 401(k) plan. Instrument Z is an indicator for being
eligible to enroll in the 401(k) plan. The vector of covariates X consists of income,
age, family size, married, an IRA individual retirement account, a defined benefit status
indicator, a home ownership indicator and the different education-year indicator variables.
The data consists of 9915 observations.
Following the regression specification in Chernozhukov and Hansen (2004), Table 3
presents quantile treatment effects obtained from different estimation procedures which
have been defined in the previous section including IVQR, po-GMM and GMM. The
corresponding results are similar. As to the high-dimensional analysis, we create 119
technical control variables including those constructed by the polynomial bases, interaction terms, and cubic splines (thresholds). To ensure each basis has equal length, we
utilize the minimax normalization for all technical control variables. Consequently, we use
the plug-in method to determine the value of penalty when doing the LASSO under the
moment condition, and tune the penalty in the quantile L1-norm objective function based
on the Huber approximation by 5-fold cross validation. The DML-IVQR also implements
11

Table 3: Estimations with Chernozhukov and Hansen (2004)’s Specification
Quantiles
TW(IVQR)
TW(po-GMM)
TW(GMM)
NFTA(IVQR)
NFTA(po-GMM)
NFTA(GMM)

0.1
4400
4400
4400
3600
3500
3500

0.15
5300
5100
5200
3600
3600
3600

0.25
4900
4900
4800
3700
3700
3700

0.5
6700
6300
6300
5700
5600
5700

0.75
8000
8200
8400
13200
13900
13900

0.85
8300
7500
8000
15800
15800
16100

0.9
10800
9100
8700
17700
17700
18200

feature normalization of the outcome variable for the sake of computational efficiency.
To make the estimated treatment effects across different estimation procedures roughly
comparable, Table 4 shows the effect obtained through the DML-IVQR multiplied by
the standard deviation of the outcome variable. Weak identification/instrument robust
inference on quantile treatment effects are depicted in Figures 4 and 5. Yet, the robust
confidence interval widens as the sample size becomes fewer at the upper quantiles; estimated quantile treatment effects are significantly different from zero. We could use the
result from the DML-IVQR as a data-driven robustness check on those summarized in
the Table 3.
Tables 5 and 6 present the selected important variables across different quantiles. The
approximate sparsity is asymmetric across the conditional distribution in the sense that
the number of selected variables decreases as the quantile index τ increases. However, it
hinges on the relatively small number of observations at the upper quantiles as well. Our
empirical results also signify that the 401(k) participants with low savings propensity are
more associated with the nonlinear income effect than those with high savings propensity,
which complements the results concluded in Chernozhukov et al. (2018a) and Chiou et
al. (2018). In this particular example, τ captures the rank variable which governs the
unobservable heterogeneity: savings propensity. Small values of τ represent participants
with low savings propensity. The nonlinear income effects, across quantile ranging from
(0, 0.5], are picked up by the selected variables such as max(0, inc − 0.2), max(0, inc2 −
0.2),max(0, inc3 − 0.2) and etc. Technical variables in terms of age, education, family
size, and income are more frequently selected. In addition, these four variables are also
identified as important variables in the context of the generalized random forests, cf. Chen
and Hsiang (2019).

12

Figure 3: Effects of Participation in the 401(K) on Total Wealth
(TW) and Net Financial Assets (NFTA) respectively.

13

Table 4: DML-IVQR with High-dimensional Controls
Quantiles
NFTA(std-DML-IVQR ×63522)
TW(std-DML-IVQR ×111529)
NFTA(std-DML-IVQR)
TW(std-DML-IVQR)

0.1
3176
2453
0.05
0.022

0.15
3049
3011
0.048
0.027

0.25
3303
3457
0.052
0.031

0.5
5844
7695
0.092
0.069

0.75
18802
15056
0.296
0.135

0.85
26298
18736
0.414
0.168

0.9
28076
16394
0.442
0.147

We create 119 technical control variables including those constructed by the polynomial bases, interaction terms, and
cubic splines (thresholds). The DML-IVQR estimates the distributional effect which signifies an asymmetric pattern
similar to the one identified in Chernozhukov and Hansen (2004).

Figure 4: Weak Instrument Robust Inference, P401(K) on TW with hqreg L1-norm

14

Figure 5: Weak Instrument Robust Inference, P401(K) on NFTA with hqreg L1-norm

15

Table 5: Total Wealth
Quantile
0.15

0.25

0.5

0.75
0.85

Selected Variables
ira, educ,
, age ∗ ira, age ∗ inc, f size ∗ educ, f size ∗ hmort
ira ∗ educ, ira ∗ inc, hval ∗ inc, marr, male, i4, a3
twoearn, marr ∗ f size, pira ∗ inc, max(0, age3 − 0.2)
max(0, educ2 − 0.4), max(0, educ − 0.2), max(0, age2 − 0.4)
ira, age ∗ f size, age ∗ ira,age ∗ inc
f size ∗ educ, ira ∗ educ, ira ∗ inc
hval ∗ inc, marr, male, i3, twoearn, marr ∗ f size
pira ∗ inc, twoearn ∗ f size, max(0, inc − 0.2)
inc2 , age ∗ f size, age ∗ ira, age ∗ inc
f size ∗ educ, ira ∗ educ, ira ∗ hval, ira ∗ inc
hval ∗ inc, male, a1, a3 , pira ∗ inc, twoearn ∗ age, twoearn ∗ f size
twoearn ∗ hmort, twoearn ∗ educ, max(0, educ − 0.6)
inc, ira, age ∗ ira, age ∗ hval
age ∗ inc, educ ∗ inc, hval ∗ inc, pira ∗ inc, pira ∗ age
inc, ira, age ∗ hval, age ∗ inc, ira ∗ educ
educ ∗ inc, hval ∗ inc, pira ∗ inc, pira ∗ hval
educ2

Selected variables across τ , tuned via cross validation.
ira: individual retirement account (IRA), inc: income, f size: family size, hequity: home equity, hval:
home value, educ: education years, marr: married, smcol: college, db: defined benefit pension, hown:
home owner, hmort: home mortgage, a1: less than 30 years old, a2: 30-35 years old, a3: 36-44 years old,
a4: 45-54 years old, a5: 55 years old or older, i1: < $10K, i2: $10 − 20K, i3: $20 − 30K, i4: $30 − 40K,
i5: $40 − 50K, i6: $50 − 75K, i7: $75K+.

16

Table 6: Net Financial Assets
Quantile
0.15

0.25

0.5

0.75
0.9

Selected Variables
ira,
hval3 , educ3 , age ∗ educ, age ∗ hmort
age ∗ inc, f size ∗ hmort, f size ∗ inc, ira ∗ educ , ira ∗ inc
hval ∗ inc, marr, db, male, i2, i3
i4, i5, twoearn, marr ∗ f size
pira ∗ inc, pira ∗ educ, twoearn ∗ inc, twoearn ∗ ira
max(0, age3 − 0.2), max(0, age2 − 0.2), max(0, age − 0.6)
max(0, inc3 − 0.2), max(0, inc2 − 0.2), max(0, educ − 0.2)
ira, hmort, age ∗ hmort, age ∗ inc, f size ∗ hmort, f size ∗ inc
ira ∗ educ, ira ∗ inc, hval ∗ inc, db, smcol, male
i2, i3, i4, i5, a2, a3
twoearn, pira ∗ inc ,pira ∗ age
pira ∗ f size, twoearn ∗ inc, twoearn ∗ ira
twoearn ∗ hmort, max(0, age2 − 0.2)
max(0, age − 0.6), max(0, inc2 − 0.2), max(0, inc − 0.4)
max(0, inc − 0.2), max(0, educ − 0.2)
age, ira, age ∗ f size, age ∗ ira, age ∗ inc
f size ∗ educ, f size ∗ hmort, ira ∗ educ, ira ∗ inc, hval ∗ inc, hown
male, i3, i4, a1, a2, a4,pira ∗ inc
pira ∗ f size, twoearn ∗ inc, twoearn ∗ f size
twoearn ∗ hmort, twoearn ∗ educ, max(0, inc − 0.2)
ira, age ∗ inc, hval ∗ inc, pira ∗ inc, pira ∗ age
ira, age ∗ inc, educ ∗ inc, hval ∗ inc, pira ∗ inc
educ2 ,

f size3 ,

Selected variables across τ , tuned via cross validation.
ira: individual retirement account (IRA), inc: income, f size: family size, hequity: home equity, hval:
home value, educ: education years, marr: married, smcol: college, db: defined benefit pension, hown:
home owner, hmort: home mortgage, a1: less than 30 years old, a2: 30-35 years old, a3: 36-44 years old,
a4: 45-54 years old, a5: 55 years old or older, i1: < $10K, i2: $10 − 20K, i3: $20 − 30K, i4: $30 − 40K,
i5: $40 − 50K, i6: $50 − 75K, i7: $75K+.

17

4.2

Effects of subsidized training on male and female trainee earnings

Abadie, Angrist and Imbens (2002) use the Job Training Partnership Act (JTPA) data
to estimate the quantile treatment effect of job training on the earning distribution. The
data are from Title II of the JTPA in early 1990s, which consist of 11,204 samples,
5,102 of them are male, and 6,102 of them are female. In estimation, they take thirtymonth earnings as the outcome variable, enrollment for JTPA service as the treatment
variable, and a randomized o er of JTPA enrollment as the instrumental variable. The
control variables include the binary variables of black and Hispanic applicants, highschool graduates, married applicants, 5 age-group, AFDC receipt (for women), whether
the applicant worked at least 12 weeks in the 12 months preceding random assignment,
the dummies for the original recommended service strategy (classroom, OJT/JSA, other)
and a dummy for whether earnings data are from the second follow-up survey.
Table 7 presents quantile treatment effects for male and female groups respectively
obtained from several estimation procedures including IVQR, po-GMM, and GMM. As
to the high-dimensional analysis, we create 85 technical control variables including those
constructed by the polynomial bases, interaction terms, and cubic splines (thresholds).
Table 8 shows the quantile treatment effect obtained through the DML-IVQR. Table
7 together with the existing findings in the literature suggest that for female only, job
training program generates significantly positive treatment effect on earnings at 0.5 and
0.75 quantiles. The DML-IVQR signifies similar results, which can be confirmed by
the identification-robust confidence intervals depicted in Figures 6 and 7. The selected
variables are collected in the online appendix1 . Thus, the existing empirical conclusions
in the literature is reassured by the IVQR using double machine learning procedure.

Table 7: Estimations with Abadie et. al. (2002)’s Specification
Quantiles
Male(IVQR)
Male(po-GMM)
Male(GMM)
Female(IVQR)
Female(po-GMM)
Female(GMM)

0.1
0
0
0
0
0
100

0.15
-200
-100
-100
0
200
200

0.25
400
500
500
400
700
700

1

0.5
500
1900
1600
1600
3300
3200

0.75
3300
5000
5100
2500
5200
5200

0.85
3100
6800
5800
1900
6500
6500

0.9
1700
7800
7200
1400
6900
6900

Selected variables for the male group: https://github.com/FieldTien/DML-QR/blob/master/Empirical_
work/hqreg_data/selected_male.csv; selected variables for the female group: https://github.com/FieldTien/
DML-QR/blob/master/Empirical_work/hqreg_data/selected_female.csv

18

Table 8: DML-IVQR with High-dimensional Controls
Quantiles
Male(std-DML-IVQR ×19400)
Female(std-DML-IVQR ×13400)
Male(std-DML-IVQR)
Female(std-DML-IVQR)

0.1
0
0
0
0

0.15
-97
67
-0.005
0.005

0.25
-97
335
-0.005
0.025

0.5
0
1274
0
0.095

0.75
2735
2213
0.14
0.165

0.85
2735
1676
0.14
0.125

0.9
488
268
0.025
0.02

We create 85 technical control variables including those constructed from the polynomial bases, interaction terms,
and cubic splines (thresholds).

Figure 6: Weak Instrument Robust Inference. The male group.

19

Figure 7: Weak Instrument Robust Inference. The female group.

20

5

Conclusion

The performance of a debiased/double machine learning algorithm within the framework
of high-dimensional IVQR is investigated. The simulation results signify that the proposed
procedure performs more efficiently than those based on the conventional estimator with
many controls. Furthermore, we evaluate the corresponding weak-identification robust
confidence interval of the low-dimensional causal parameter. Given a large number of
technical controls, we reinvestigate quantile treatment effects of the 401(k) participation
on accumulated wealth and then highlight the non-linear income effects driven by the the
savings propensity.

21

References
Abadie A. Angrist J. and G. Imbens. 2002. “Instrumental Variables Estimates of the
Effect of Subsidized Training on the Quantiles of Trainee Earnings,” Econometrica,
70(1): 91–117.
Athey, S. 2017. “Beyond Prediction: Using Big Data for Policy Problems,” Science, 355:
483–485.
Athey, S. 2018. “The Impact of Machine Learning on Economics,” working paper, Stanford
GSB.
Athey, S., Tibshirani, J., and S. Wager. 2019. “Generalized Random Forests,” The Annals
of Statistics, 47(2): 1148–1178.
Belloni, A., Chernozhukov V., and C. Hansen. 2014. “High-Dimensional Methods and
Inference on Structural and Treatment Effects,” Journal of Economic Perspectives,
28: 29–50.
Chen, J.-E. and C.-W. Hsiang. 2019. “Causal Random Forests Model using Instrumental
Variable Quantile Regression,” working paper, Center for Research in Econometric
Theory and Applications, National Taiwan University.
Chen, L.-Y., and S. Lee. 2018. “Exact Computation of GMM Estimators for Instrumental
Variable Quantile Regression Models,” Journal of Applied Econometrics, forthcoming.
Chernozhukov, V., and C. Hansen. 2004. “The Impact of 401(k) Participation on the
Wealth Distribution: An Instrumental Quantile Regression Analysis,” Review of
Economics and Statistics, 86: 735–751.
Chernozhukov, V. and C. Hansen. 2008. “Instrumental Variable Quantile Regression: A
Robust Inference Approach,” Journal of Econometrics, 142: 379–398.
Chernozhukov, V., Hansen C., and M. Spindler. 2015. “Valid Post-Selection and PostRegularization Inference: An Elementary, General Approach,” Annual Review of
Economics, 7: 649–688.
Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., and
J. Robins. 2018a. “Double/debiased Machine Learning for Treatment and Structural
22

Parameters,” Econometrics Journal, 21: C1–C68.
Chernozhukov, V., Hansen, C., and K. Wüthrich. 2018b. “Instrumental Variable Quantile
Regression,” Handbook of Quantile Regression.
Chiou, Y.-Y., Chen, M.-Y., and J.-E. Chen. 2018. “Nonparametric Regression with Multiple Thresholds: Estimation and Inference,” Journal of Econometrics, 206(2): 472–
514.
Yi, C., and J. Huang. 2017. “Semismooth Newton Coordinate Descent Algorithm for
Elastic-net Penalized Huber Loss Regression and Quantile Regression,” Journal of
Computational and Graphical Statistics, 26(3): 547–557.

23

