Local Instrumental Variables and Latent Variable Models for Identifying and Bounding
Treatment Effects
Author(s): James J. Heckman and Edward J. Vytlacil
Source: Proceedings of the National Academy of Sciences of the United States of America,
Vol. 96, No. 8 (Apr. 13, 1999), pp. 4730-4734
Published by: National Academy of Sciences
Stable URL: https://www.jstor.org/stable/47634
Accessed: 17-10-2019 16:03 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

National Academy of Sciences is collaborating with JSTOR to digitize, preserve and extend
access to Proceedings of the National Academy of Sciences of the United States of
America

This content downloaded from 206.253.207.235 on Thu, 17 Oct 2019 16:03:46 UTC
All use subject to https://about.jstor.org/terms

Proc. Natl. Acad. Sci. USA
Vol. 96, pp. 4730-4734, April 1999
Economic Sciences

Local instrumental variables and latent variable models for
identifying and bounding treatment effects
JAMES J. HECKMAN* AND EDWARD J. VYTLACIL
Department of Economics, University of Chicago, Chicago, IL 60637

Contributed by Janmes Joseph Heckman, Februa7y 2, 1999

ABSTRACT This paper examines the relationship be-

The potential outcome equation for the participation state

tween various treatment parameters within a latent variable

is Y i = 1i(Xi, Ul), and the potential outcome for the

model when the effects of treatment depend on the recipient's

nonparticipation state is Y( = /to(Xj, Uo0), where Xi is a vect

observed and unobserved characteristics. We show how this

of observed random variables and (U11, Uo0) are unobserved

relationship can be used to identify the treatment parameters

random variables. It is assumed that Yo and Y, are defined for

when they are identified and to bound the parameters when

everyone and that these outcomes are independent across

they are not identified.

persons so that there are no interactions among agents.

This paper uses the latent variable or index model of econometrics and psychometrics to impose structure on the Neyman

Important special cases include models with (Yo, YI) gene
by latent variables and include -t (Xi, Ujj) = tj(Xj) + Ujj if Y
is continuous and p1-(Xi, Uji) = 1 (Xf3j + Uj - 0) if Y is binary,

(1)-Fisher (2)-Cox (3)-Rubin (4) model of potential outcomes

where 1(A) is the indicator function that takes the value 1 if

used to define treatment effects. We demonstrate how the

the event A is true and takes the value 0 otherwise. We do not

restrict the (/l, Ao) function except through integrability

local instrumental variable (LIV) parameter (5) can be used
within the latent variable framework to generate the average

condition iv given below.

treatment effect (ATE), the effect of treatment on the treated
(TT) and the local ATE (LATE) of Imbens and Angrist (6),

conditional onX = x; (ii) (UD, Uj) and (UD, Uo) are absolutely

thereby establishing a relationship among these parameters.

continuous with respect to Lebesgue measure on 9j2; (iii) (UD,

We assume: (i) vID(Z) is a nondegenerate random variable

LIV can be used to estimate all of the conventional treatment

U1) and (UD, UO) are independent of (Z, X); (iv) Y, and Y(

effect parameters when the index condition holds and the

have finite first moments; and (v) Pr(D = 1) > 0.

parameters are identified. When they are not, LIV can be used

Assumption i requires an exclusion restriction: There exists

to produce bounds on the parameters with the width of the
bounds depending on the width of the support for the index
generating the choice of the observed potential outcome.

a variable that determines the treatment decision but does not

directly affect the outcome. Let Fu,) be the distribution of UD

with the analogous notation for the distribution of the other

random variables. Let P(z) denote Pr(D = l|Z = z) =
Models of Potential Outcomes in a Latent

Fuj)(1D(Z)). P(Z) is sometimes called the "propens

Variable Framework

following ref. 12. Let UD denote the probability transform of

UD: UD = FUJ(UD). Note that, because UD is absolutely
For each person i, assume two potential outcomes (Yoi,
Y1i)
continuous
with respect to Lebesgue measure, UD Unif(O,1).
corresponding, respectively, to the potential outcomes in the
Let Ai denote the treatment effect for person i: Ai Yti - Y(i.
untreated and treated states. Let D1 = 1 denote the receipt of

It is the index structure on D that plays the crucial role in this

treatment; Di = 0 denotes nonreceipt. Let Y4 be the measured
paper. An index structure on the potential outcomes (Yo, YO)

outcome variable so that

is not required, although it is both conventional and conve-

nient in many applications.

Yj = DiY1i + (1 - Di)Y(0.

Definition of Parameters

This is the Neyman-Fisher-Cox-Rubin model of potential
outcomes. It is also the switching regression model of Quandt

We examine four different mean parameters within this framework: the ATE, effect of treatment on the treated (TT), the

(7) or the Roy model of income distribution (8, 9).
This paper assumes that a latent variable model generates
the indicator variable D. Specifically, we assume that the
assignment or decision role for the indicator is generated by a
latent variable D,:

local ATE (LATE), and the LIV parameter. The average
treatment effect is given by:

A ATE(X) = E(AIX = x). [21

D', = I/D(Z)- UDi

From assumption iv, it follows that E(AIX =

finite a.e. Fx. The expected effect of treatment on the treated

Di = I if D, 0, = 0 otherwise, [1]

is the most commonly estimated parameter for both observa-

tional data and social experiments (13, 14). It is defined as:

where Z, is a vector of observed random variables and UDI is

an unobserved random variable. D* is the net utility or gain to
the decision-maker from choosing state 1. The index structure

underlies many models in econometrics (10) and in psychometrics (11).

\T7(x, D= 1)-E(AIlX =x, D= 1). [31

From iv, A TT(X, D = 1.) exists and is finite a.e. FXID = 1, w

FxI1= I denotes the distribution of X conditional on D =

The publication costs of this article were defrayed in part by page charge

payment. This article must therefore be hereby marked "advertisenrent" in
accordance with 18 U.S.C. ?1734 solely to indicate this fact.

Abbr-eviations: LIV, local instrumental variable; ATE, average treatment effect; TT, effect of treatment oin the treated; LATE, local ATE.
To whom reprint requests should be addressed at: 1126 East 59th
Street, Chicago, IL 60637. e-mail: jjh@uchicago.edu.

PNAS is available online at www.pnas.org.

4730

This content downloaded from 206.253.207.235 on Thu, 17 Oct 2019 16:03:46 UTC
All use subject to https://about.jstor.org/terms

Economic Sciences: Heckman and Vytlacil Proc. Natl. Acad. Sci. USA 96 (1999) 4731
will be useful to define a version of ATT(X, D = 1) conditional
on P(Z):

E(Y|X = x, P(Z) = P(z))

= P(z)[E(YIX = x, P(Z) = P(z), D = 1)]

\TT(x,P(z), D 1) E(AIX - x, P(Z) = P(z), D - 1)

+ (1 - P(z))[E(Yo|X = x, P(Z) = P(z), D = 0)]

so that

(P(z)

E(YI|X = x, U = u)du

ATT(X, D 1) f J TT(X, P(Z), D = 1)dFp(z)IX=XD=I. [4]
From our assumptions, ATT (x, P(z), D = 1) exists and is finite

+ E(Yo|X = x, U = u)du, [81

a.e. FX,P(Z)ID=1. In the context of a latent variable model, the

P(z)

LATE parameter of Imbens and Angrist (6) using P(Z) as the
instrument is

so that

ALATE(X P(Z), P(z')) -

E(Y|X = x, P(Z) = P(z)) - E(Y|X = x, P(Z') P(z'))

E(Y|X = x, P(Z) = P(z)) - E(Y|X = x, P(Z) = P(z'))

rP(Z)

f(|E(YIX=x, U= u)du -

P(Z)-P(Z')

P(z')

Without loss of generality, assume that P(z) > P(z'). From
assumption iv, it follows that ALATE(x, P(z), P(z')) is well
defined and is finite a.e. Fx,p(z) X Fx,p(z). For interpretative
reasons, Imbens and Angrist (6) also assume that P(z) is
monotonic in z, a condition that we do not require. However,
we do require that P(z) :f P(z') for any (z, z') where the

f E(YO|X = x, U = u)du
P(z)

and thus

parameter is defined.

ALA TE(x P(z), P(z')) = E(A[K = x, P(z') ? UD?- P(z)). [91

The fourth parameter that we analyze is the LIV parameter
introduced in ref. 5 and defined in the context of a latent
variable model as

LIV is the limit of this expression as P(z) -> P(z'). In Eq. 8,
E(Y1IX = x, U) and E(YoIX = x, U) are integrable with respect

to dFu a.e. Fx. Thus, E(YiIX = x, P(Z) = P(z)) and E(Yo|X =

sLIV(X, p(Z)) = aE(YIX = X, P(Z) = P(z)) [61
x, P(Z)

= P(z)) are differentiable a.e. with respect to P(z), and
thus E(Y|X = z, P(Z) = P(z)) is differentiable a.e. with respect
to P(z) with derivative given byt

LIV is the limit form of the LATE parameter. In the next
section, we demonstrate that ALIV(X, P(z)) exists and is finite
a.e. Fx,p(z) under our maintained assumptions.
A more general framework defines the parameters in terms
of Z. The latent variable or index structure implies that
defining the parameters in terms of Z or P(Z) results in
equivalent expressions. In the index model, Z enters the model
only through the ,-LD(Z) index, so that for any measurable set
A,

~E(Y[K x, P(Z) P(z)= E(Y1 - Yo= x, U = P(z)). [101
aP(z)

From assumption iv, the derivative in Eq. 10 is finite a.e. Fx,u.
The same argument could be used to show that ALA TE(x, P(z),
P(z')) is continuous and differentiable in P(z) and P(z').
We rewrite these relationships in succinct form in the
following way:

Pr(Y(EAIX=x, Z =z, D = 1)

ALIV(X P(Z)) = E(AIX = x, UD P(z))

Pr(YI E A|X = x, UD [ LD(z))

AATE(X) = E(AIX = x, UD u)du

Pr(Y) E A IX = x, Z = z, D 0 O) =
Pr (Yj E A IX = x, UD > I-D (Z))-

P(Z)

Because any cumulative distribution function is left-

continuous and nondecreasing, we have

Pr(YI E A IX = x, UD ' ID(Z))

P(Z)[ATT(X, P(z), D = 1)] Jo E(AIX = x
and

Pr(Yj E A IX = x, UD ?P(z))
Pr(YI E A IX = x, UD > [LD(Z))

(P(Z) - P(Z,))[ALATE(X, P(Z)P(z'))] =J E(A[K =
JP(ZI)

[11]

Pr(Y, E A IX = x, UD > P(Z)) Relationship Between Parameters Using the Index

Each parameter is an average value of LIV, E(AIX = x, Ud =

Structure

u), but for values of UD lying in different intervals. LIV defines
the treatment effect more finely than do LATE, ATE, or TT.

Given the index structure, a simple relationship exists among
the four parameters. From the definition it is obvious that

indifferent between participation or not at the given value of

A\TT(x,P(Z),D = 1) = E(AIX = X, UD?'P(Z)). [71
Next, consider A\LA TE(x, P(z), P(z')). Note that

ALIV(X, p) is the average effect for people who are just

the instrument (i.e., for people who are indifferent at P(Z) =

p). A\LIV(x, p) for values of p close to zero is the average effect
tSee, e.g., Kolmogorov and Fomin (15), Theorem 9.8 for one proof.

This content downloaded from 206.253.207.235 on Thu, 17 Oct 2019 16:03:46 UTC
All use subject to https://about.jstor.org/terms

4732 Economic Sciences: Heckman and Vytlacil Proc. Natl. Acad. Sci. USA 96 (1999)
for individuals with unobservable characteristics that make

where gx(u) = 1 - Fp(z)Ix=x(u)/f (1 - Fp(z)1x=x(t))dt.

them the most inclined to participate, and AI\LIV(x,p) for values

Replacing P(Z) with length-of-spell, gv(u) is the density of a

of p close to one is the average treatment effect for individuals

length-biased sample of the sort that would be obtained from

with unobservable characteristics that make them the least

stock biased sampling in duration analysis (16). Here we

inclined to participate. ATE integrates z\LIv(x, p) over the

sample from the P(Z) conditional on D = 1 and obtain an

entire support of UD (from p 0 O top = 1). It is the average

analogous density used to weight up LIV. g,,(u) is nonincr

effect for an individual chosen at random. ATT(X, P(z), D = 1)

ing function of U. ALIV(X, p) is given zero weight for p >

is the average treatment effect for persons who chose to

pmax(x).

participate at the given value of P(Z) = p(z); ATT(X, P(z), D =

1) integrates ALIV(x, p) up to p = P(z). As a result, it is

Identification of Treatment Parameters

primarily determined by the average effect for individuals
whose unobserved characteristics make them the most inclined

Assume access to an infinite independently and identically

to participate in the program. LATE is the average treatment

distributed sample of (D, Y, X, Z) observations, so that the

effect for someone who would not participate if P(Z) ? P(z')

joint distribution of (D, Y, X, Z) is identified. Let 9P(x) denote

and would participate if P(Z) ? P(z). ALATE(x, P(z), P(z'))
integrates ALIV(x, p) from p = P(z') to p = P(z).
To derive TT, use Eq. 4 to obtain

the closure of the support P(Z) conditional on X = x, and let

9Pc(X) = (0, 1)\2?(x). Letpl?7(l(x) andplliJ'(x) be the maximum
and minimum values in 9?(x).
LATE and LIV are defined as functions (Y, X, Z) and are

thus straightforward to identify. ALATIE(X, p(z), P(z'))

identified
A TT(x, D 1 l) P(Z) [P( E(AIX = x, UD = u)du

for any (P(z), P(z')) E X5(x) X 9@(x). ALIV(x, P(z))

is identified for any P(z) that is a limit point of 92?(x). The larger

x dFp(z)Xx>D= 1. 12]

the support of P(Z) conditional on X = x, the bigger the set
of LIV and LATE parameters that can be identified.
ATE and TT are not defined directly as functions of (Y, X,

Using Bayes rule, one can show that

Z), so a more involved discussion of their identification is
required. We can use LIV or LATE to identify ATE and TT

Pr(D l I |X = x, P(Z)) = P(z)

dFp(z)IX=x,D=1Pr
= (D
r(=l|X
x) dP(z)lx=x.
=l,ix= x)
[13]
Because Pr(D =lIX x, P(Z)) = P(z),

under the appropriate support conditions: (i) If 9J (x) = [0,

then AATE(X) is identified from ALIV. If {0, 1} E @(x), t
AATE(X) is identified from ALA7T. (ii) If (0, P(z)) C @(x),
A TT(X, P(z), D = 1) is identified from ALI V. If {0, P(z)
@(x) then ATT(X, P(z), D = 1) is identified from ALA T.
Note that TT is identified under weaker conditions than is

\TT(x D - 1) - P
Pr(D =1 |X)

ATE. To identify TT, one needs to observe P(Z) arbitrarily

close to 0 (p'1"i(x) = 0) and to observe some positive P(Z)

I P(Z)

X f J E(AIX = x, UD = u)du dFP(z)I1=x. [14]

values whereas to identify ATE, one needs to observe P(Z)

arbitrarily close to 0 and arbitrarily close to 1 (p/lX(Ix(x) = I

p'7li'l(x) = 0). Note that the conditions involve the closure o
Note further that, because Pr(D = lIX) = E(P(Z)IX) =
fo1 (1 - Fp(z)jx=x(t))dt, we can reinterpret Eq. 14 as a
weighted average of LIV parameters in which the weighting is
the same as that from a "length-biased," "size-biased," or
"P-biased" sample:

ATTD - 1) P(X, - I- {D-X- xA

the support of P(Z) conditional on X = x and not the support

itself. For example, to identify A7T(x, D = 1) from ALATE, we
do not require that 0 be in the support of P(Z) conditional on
X = x but that points arbitrarily close to 0 be in the support.

This weaker requirement follows from ALIV(x, P(z)) being a
continuous function of P(z) and ALATE(x, P(z), P(z')) being a
continuous function of P(z) and P(z').

Without these support conditions, we can still construct

bounds if Y, and Yo are known to be bounded with probability
one. For ease of exposition and to simplify the notation,

assume that Y1 and Y( have the same bounds, so that

x J [Jf1 (u c P(z))E(A x, = UD = U)dU dFP(Z)lX,.

Pr(y?' Y1 C y?<X = x) 1
1

and

I I1

P(7'? Y(O?y '/ X=x) It.

(1.-Fp(Zz)jx=x(t))dt

For example, if Y is an indicator variable, then the bounds are

x T E[I E(A/iX=x, UD = u)I(u ?P(z))dFp(z) x=J du

y7 = 0 andy,'= 1 for allx. For any P(z) E @P(x), we can identify

P(z)[E(Yl IX = x, P(Z) = P(z), D = 1)]

= E(AIX =x, Ul) = u) ] du

jZE(YI X U = u)du [16]

f E ()dFp(zx=x(t) )dt t
and

t-The modifications required to handle the more general case are
straightforwardl.

This content downloaded from 206.253.207.235 on Thu, 17 Oct 2019 16:03:46 UTC
All use subject to https://about.jstor.org/terms

Economic Sciences: Heckman and Vytlacil Proc. Natl. Acad. Sci. USA 96 (1999) 4733

(1 - P(z))[E(YojX = x, P(Z) = P(z), D = 0)]

+ (1 - p"W1x))E(YW = x, P(Z) -= IP"(x), D = 0)
- (1 - P(z))E(YoIW = x, P(Z) = p(z), D = 0)]

= E(YoIX= x, U = u)du.

ATT(X, P(z), D = 1) '

P(z)

[17]

E(Y1IX = x, P(Z) = P(z), D = 1) - P(z) [pmin(x)y

In particular, we can evaluate Eq. 16 at P(z) = p7lax(x) and can
evaluate Eq. 17 at P(z) = pn,in (x). The distribution of (D, Y,

(1 - pin(x))E(YoIX = x, P(Z) = pn""in(x), D = 0

X, Z) contains no information on fk04x) E(Y1 IX = x, U =
u)du and f"'1() E(YoIX = x, U = u)du, but we can bound these
quantities:

(1 - P(x))E(YoJX = x, P(Z) = p(z), D = 0)].

The width of the bounds on ATT(X, P(z), D = 1) is t

(1 -P ax() c ? E(Y1j = x, U = u)du < (1 -p",(x))y"

pmin7(x)yf ? j E(Y(IX = x, C =Xu)du .pmP(x)yt.
[18]

We thus can bound AATE(x) by?

p_ (X) 1)

P(Z) kx-Yx

The width of the bounds is linearly decreasing in the distance
between pmlit(x) and 0. Note that the bounds are tighter for
larger P(z) evaluation points because the higher the P(z)
evaluation point, the less weight is placed on the unidentified
quantity fJB H(XV) E(YoIX = x, U = u)du. In the extreme case,
where P(z) = pmin(x), the width of the bounds simplifies to Y.
- Yx.

pmax(x)[E(YlIX = x, P(Z) = pmax(x)' D 1)]

We can integrate the bounds on ATT(X, P(z), D -1) to boun
ATT(X, D = 1):

+ ( n1 -pf?ax(x))y -

(1 pmin (x))[E(YoIX = x, P(Z) =

J [E~E(Y, = x, P(Z) P(z), D = 1)

pmin(x), D = 0)] -p "'n(x)y,
:5 AA TE (X) -<

--(p n t (x)yx + -pmin (x))

pn,ax(X)[E(YI X = x, P(Z) = p"(x), D = 1)]

X E(Y,X = x, P(Z) pn"'(x), D =0)

+ ( 1 p ma(X))yx -

-(1 -P(z))E(YoX =x, P(Z)

(1 - pmin(X))[E(YolX = x, P(Z) = pmnn(x), D = 0)]
P min(x)Y

=P(z), D = 0))]dFp z)Ix,)=1

The width of the bounds is thus

cATT(X D =1)

(1 _ pnlmx(X))(yt - yl) + pn'in(x)(yx - ylx).

fnax(x) [

j [ pE(YK W = x P(Z) = P(z) D =l)

The width is linearly related to the distance betweenpmf11x(x)
and 1 and the distance between plli"(x) and 0. These bounds
are directly related to the "identification at infinity" results of
refs. 9 and 18. Such identification at infinity results require the

- ( ) eifl(4yl +

condition that PLD(Z) takes arbitrarily large and arbitrarily

small values if the support of UD is unbounded. The condition
is sometimes criticized as being not credible. However, as is
made clear by the width of the above bounds, the proper metric
for measuring how close one is to identification at infinity is the
distance between pmax(x) and 1 and the distance between

(1f- pi"(x))E(YoWX = x, P(Z) = pIfn(x), D = 0) -

(1 - P(z))E(Y() = x, P(Z) = P(z), D 0))]dFPIZ)tXD=-.

p1fitl(x) and 0. It is credible that these distances may be small.
In practice, semiparametric methods that use identification at
infinity arguments to identify ATE are implicitly extrapolating

E(Y1 IX = x, U = u) for u > pma(x) and E(YojX = x, U = u)
for u < pE7iii(x)
We can construct analogous bounds for ATT(x, P(z), D = 1)
for P(z) E @(x):
E(Y1fX =x, P(Z) = P(z), D = 1) - [p m pmin)(X)yu

The width of the bounds on ATT(X, D- = 1) is thus:
plarn(x) 1

p (X) (,-V ) YJ p() dFpz) IX=x7D =
Using Eq. 13, we have
iprnnx' (x) 1

p (x) (YX" -yY) J P(Z) dFp(z)3Wx,D=-j = p "(x)(y _-Yx
pf11if(x)

?The following bounds on ATE also can be derived easily by applying
Manski's (17) bounds for "Level-Set Restrictions on the Outcome
Regression." The bounds for the other parameters discussed in this
paper cannot be derived by applying his results.

This content downloaded from 206.253.207.235 on Thu, 17 Oct 2019 16:03:46 UTC
All use subject to https://about.jstor.org/terms

4734 Economic Sciences: Heckman and Vytlacil Proc. Natl. Acad. Sci. USA 96 (1999)
presented in this paper. The index structure on D simplifies the
and yields the elegant relationships presented here.

derivations
= pin()@XYx)Pr(D = 1 IX = x)

However, LIV can be defined without using an index structure

Unlike the bounds on ATE, the bounds on TT depend on the
distribution of P(Z), in particular, on Pr(D = l|X = x) =
E(P(Z)|X = x). The width of the bounds is linearly related to
the distance between pmin(x) and 0, holding Pr(D = l|X = x)

(5); so can LATE. We can define LIV for different sets of

regressors and produce relationships like those given in Eq. 11
defining the integrals over multidimensional sets instead of
intervals. The bounds we present also can be generalized to

cover this case as well. The index structure for D arises in many
constant. The larger Pr(D = 1 IX = x) is, the tighter the bounds

because the larger P(Z) is on average, the less probability weight is being placed on the unidentified quantity

fJg@) E(Yo|X =x U u)du.

psychometric and economic models in which the index represents net utilities or net preferences over states, and these are
usually assumed to be continuous. In these cases, its application leads to the simple and concise relationships given in this

Conclusion

paper.

This paper uses an index model or latent variable model for the

We thank Aarild Aakvik, Victor Aguirregabiria, Xiaohong Chen,
Lars Hansen and Justin Tobias for close reading of this manuscript. We
also thank participants in the Canadian Econometric Studies Group
(September, 1998), the Midwest Econometrics Group (September,
1998), the University of Upsalla (November, 1998), the University of
Chicago (December, 1998), the University of Chicago (December,
1998), and University College London (December, 1998). James

selection variable D to impose some structure on a model of
potential outcomes that originates with Neyman (1), Fisher
(2), and Cox (3). We introduce the LIV parameter as a device
for unifying different treatment parameters. Different treatment effect parameters can be seen as averaged versions of the
LIV parameter that differ according to how they weight the
LIV parameter. ATE weights all LIV parameters equally.
LATE gives equal weight to the LIV parameters within a given
interval. TT gives a large weight to those LIV parameters
corresponding to the treatment effect for individuals who are
the most inclined to participate in the program. The weighting
of P for LIV that produces TT is like that obtained in length
biased or sized biased samples.
Identification of LATE and LIV parameters depends on the
support of the propensity score, P(Z). The larger the support
of P(Z), the larger the set of LATE and LIV parameters that
are identified. Identification of ATE depends on observing
P(Z) values arbitrarily close to 1 and P(Z) values arbitrarily
close to 0. When such P(Z) values are not observed, ATE can
be bounded, and the width of the bounds is linearly related to
the distance between 1 and the largest P(Z) and the distance
between 0 and the smallest P(Z) value. For TT, identification
requires that one observe P(Z) values arbitrarily close to 0. If
this condition does not hold, then the TT parameter can be
bounded and the width of the bounds will be linearly related
to the distance between 0 and the smallest P(Z) value, holding
Pr(D = l|X) constant.
Implementation of these methods through either parametric
or nonparametric methods is straightforward. In joint work
with Arild Aakvik of the University of Bergen (Bergen,
Norway), we have developed the sampling theory for the LIV
estimator and empirically estimated and bounded various
treatment parameters for a Norwegian vocational rehabilitation program.
We conclude this paper with the observation that the index
structure for D is not strictly required, nor is any monotonicity
assumption necessary to produce results analogous to those

J. Heckman is Henry Schultz Distinguished Service Professor of
Economics at the University of Chicago and a Senior Fellow at the
American Bar Foundation. Edward Vytlacil is a Sloan Fellow at the
University of Chicago. This research was supported by National

Institutes of Health Grants RO1-HD34958-01 and RO1-HD32058-03,
National Science Foundation Grant 97-09-873, and the Donner Foundation.
1. Neyman, J. (1990) Stat. Sci. 5, 465-480.
2. Fisher, R. A. (1935) Design of Experiments (Oliver and Boyd,
London).

3. Cox, D. R. (1958) The Planning of Experiments (Wiley, New
York).

4. Rubin, D. (1978) Ann. Stat. 6, 34-58.
5.
6.
7.
8.
9.
10.

Heckman, J. (1997) J. Human Resources 32, 441-462.
Imbens, G. & Angrist, J. (1994) Econometrica 62, 467-476.
Quandt, R. (1972) J. Am. Stat. Assoc. 67, 306-310.
Roy A. (1951) Oxford Econ. Papers 3, 135-146.
Heckman, J. & Honor6, B. (1990) Econometrica 58, 1121-1149.
Maddala, G. S. (1983) Qualitiative and Limited Dependent Variable Models (Cambridge Univ. Press, Cambridge, U.K.)
11. Junker, B. & Ellis, J. (1997) Ann. Stat. 25, 1327-1343.
12. Rosenbaum, P. & Rubin, D. (1983) Biometrika 70, 41-55.
13. Heckman, J. & Robb, R. (1985) in LongitudinalAnalysis of Labor

Market Data, eds. Heckman, J. & Singer, B. (Cambridge Univ.
Press, New York), pp. 156-245.
14. Heckman, J., Lalonde, R. & Smith, J. (1999) in Handbook of
Labor Economics, eds. Ashenfelter, 0. & Card, D. (Elsevier,
Amsterdam), in press.

15. Kolmogorov, A. N. & Fomin, S. V. (1970) Introductory Real
Analysis, trans. Silverman, R. (Dover, New York, NY).
16. Rao, C. R. (1986) in A Celebration of Statistics, ed. Feinberg, S.
(Springer, Berlin).
17. Manski, C. (1990). Am. Econ. Rev. 80, 319-323.
18. Heckman, J. (1990) Am. Econ. Rev. 80, 313-318.

This content downloaded from 206.253.207.235 on Thu, 17 Oct 2019 16:03:46 UTC
All use subject to https://about.jstor.org/terms

