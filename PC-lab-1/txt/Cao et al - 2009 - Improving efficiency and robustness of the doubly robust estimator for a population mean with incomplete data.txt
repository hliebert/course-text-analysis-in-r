Biometrika Trust

Improving efficiency and robustness of the doubly robust estimator for a population
mean with incomplete data
Author(s): WEIHUA CAO, ANASTASIOS A. TSIATIS and MARIE DAVIDIAN
Source: Biometrika, Vol. 96, No. 3 (SEPTEMBER 2009), pp. 723-734
Published by: Oxford University Press on behalf of Biometrika Trust
Stable URL: https://www.jstor.org/stable/27798859
Accessed: 05-03-2019 16:08 UTC
REFERENCES
Linked references are available on JSTOR for this article:
https://www.jstor.org/stable/27798859?seq=1&cid=pdf-reference#references_tab_contents
You may need to log in to JSTOR to access the linked references.
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

Biometrika Trust, Oxford University Press are collaborating with JSTOR to digitize,
preserve and extend access to Biometrika

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

Biometrika (2009), 96, 3, pp. 723-734
? 2009 Biometrika Trust

doi: 10.1093/biomet/asp033
Advance Access publication 7 August 2009

Printed in Great Britain

Improving efficiency and robustness of the doubly robust
estimator for a population mean with incomplete data
By WEIHUA CAO, ANASTASIOS A. TSIATIS and MARIE DAVIDIAN
Department of Statistics, North Carolina State University, Raleigh, North Carolina

27695-8203, U.S.A.

wcao5@ncsu.edu tsiatis@stat.ncsu.edu davidian@stat.ncsu.edu

Summary
Considerable recent interest has focused on doubly robust estimators for a population mean
response in the presence of incomplete data, which involve models for both the propensity score
and the regression of outcome on covariates. The usual doubly robust estimator may yield severely
biased inferences if neither of these models is correctly specified and can exhibit nonnegligible
bias if the estimated propensity score is close to zero for some observations. We propose alternative
doubly robust estimators that achieve comparable or improved performance relative to existing
methods, even with some estimated propensity scores close to zero.
Some key words: Causal inference; Enhanced propensity score model; Missing at random; No unmeasured confounders;

Outcome regression.

1. Introduction
The challenge of estimating a population mean response on the basis of incomplete data arises

in many settings. Nonresponse in sample surveys or dropout and noncompliance in clinical
trials may lead to missing outcomes for some subjects; likewise, making causal inference on
a treatment mean may be viewed as a missing data problem, where potential outcomes under
treatment are missing for subjects actually observed to receive control (Kang & Sch?fer, 2007).
In these situations, unless the missingness mechanism is completely at random (Rubin, 1976), it
is well known that the naive sample mean based on the complete cases is a biased estimator.

If missing data can reasonably be assumed missing at random, or, equivalently, if the no
unmeasured confounders assumption (Rosenbaum & Rubin, 1983; Robins et al., 2000) is ten
able when making causal inference from observational data, popular approaches include es
timation based on a posited outcome regression model for the relationship between response
and covariates and methods that use fitted models for the propensity score, the probability of

the response being observed given covariates (Rosenbaum & Rubin, 1983), such as stratifica
tion or matching (Rosenbaum & Rubin, 1984; Rubin & Thomas, 1996; Lunceford & Davidian,
2004) and inverse probability weighting of responses (Robins et al., 1994; Rosenbaum, 1987;
Lunceford & Davidian, 2004). These methods require correct specification of the model for
outcome regression or propensity score, respectively. Robins et al. (1994) identified a class of
augmented inverse probability weighted estimators that involve modelling both the outcome
regression and propensity score, with the efficient member of the class obtained when both
models are correct. Scharfstein et al. (1999) noted that estimators in this class are doubly robust
in that they are consistent for the true population mean even if one of the outcome regression
or propensity score models, but not both, is misspecified. Given the protection afforded by this

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

724

Weihua Cao, Anastasios A. Tsiatis and Marie Davidian

property, these estimators have been advocated for routine use (Bang & Robins, 2005). However,
Kang & Sch?fer (2007) demonstrated via simulation that the usual doubly robust estimator can
be severely biased when both models are misspecified, even if they are nearly correct, and that
bias is especially problematic when some estimated propensity scores are close to zero, yielding
very large weights. Estimation based on an outcome regression model only performed much
better under misspecification in the Kang-Schafer simulation scenario, leading the authors to
warn against the use of doubly robust estimators in practice. Tan (2006) discussed alternative
approaches to constructing doubly robust estimators that may alleviate some of these difficulties.
In this paper, we propose doubly robust estimators that may yield improved performance relative
to existing competitors.

2. Existing doubly robust estimators
As in Kang & Sch?fer (2007), we consider the standard missing data set-up; the spirit of the

developments is equally relevant to the causal inference context. Consider subjects drawn
at random from a population of interest, where the ideal, full data are (Y?, X?) (i = 1,..., )
independent and identically distributed across i\ is the response or outcome; and X? is a vector

of covariates. As in ? 1, 7/ is not available for all subjects; thus, the data actually observed are

independent and identically distributed (R?Y?, R?, X?) (i = I, ..., ), where R? = 1 or 0 as 7?
is observed or missing. The goal is to estimate the population mean, ? E(Y), on the basis of
these observed data. Throughout, assume that responses are missing at random (Rubin, 1978) in
that and R? are conditionally independent given X?.

The propensity score is pr(7? = 1 | X); denote the true propensity score as ( ). Ordinarily,
( ) is unknown, and it is customary to posit a parametric model; for example, a logis

tic regression model ( , y) = {1 + expiry)}-1, X = (1, 7)7. Letting y denote the maxi
mum likelihood estimator for y based on (Ri, Xi) (i = 1,...,?), it is straightforward to show
(Lunceford & Davidian, 2004) that the inverse probability weighted estimators

fr[ *(Xi, Y) [?T? n(Xit y) J n(Xu Y)
are consistent for if ( , y) is correctly specified; that is, ( ) = ( , yo) for some yo.
Alternatively, because under missing at random E{E( Y \ R = 1, X)} = E{E(Y \ X)} = E(Y\
letting mo(X) denote the true outcome regression E(Y | X), it is natural to adopt a model m(X, ?)

for mo(X), estimate ? by some ? using the complete cases {/ : R? = 1} and estimate by

?oR = n~l ( 9 ?), (2)
=1

which is consistent for if m(X, ?) is correctly specified; that is, mo(X) = m(X, ? ) for some
? , and if ? is consistent for ? . Because ? is based only on the complete cases, if the distributions

of X conditional on R = 1 and R = 0 differ, (2) involves extrapolation.

From Robins et al. (1994) and Tsiatis & Davidian (2007), all estimators for that are consis
tent and asymptotically normal when the propensity score model is correct are asymptotically
equivalent to an estimator of the form

-l / Rj Yj

f^\n(Xi,: ) ( , )

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

Efficiency and robustness of doubly robust estimators

725

for arbitrary h{X). Estimators in class (3) are referred to as augmented inverse probability
weighted because they have the form of /xIPW1 in (1) plus an augmentation term depending
on h(X); /2IPW1 is obtained when h(X) = 0. From Robins et al. (1994), the estimator with the

smallest asymptotic variance among those in class (3), so with ( , ) correct, is

, f RiYi Ri~n(Xi,y) , )

= n~x
\ ) 1(Xi,1 ) -J K ::nm(Xh ?) ,
[ (Xi,
taking h(Xi) = ?m(X?9 ?), where m(X, ?) is correctly specified, and ? is consistent for ?0.

Scharfstein et al. (1999) noted that /?DR remains consistent if only one of the outcome regression

model m(X, ?) or the propensity score model ( , ) is correctly specified, but is inconsistent
if both are misspecified; this property is referred to as double robustness. If m(X, ?) is correct,
then /x0r is at least as efficient as /xDR (Tan, 2007) but is inconsistent otherwise, while double
robustness of (4) affords protection against such misspecification.
The estimator (4), with y estimated by maximum likelihood and ? estimated by ordinary or
iteratively reweighted least squares is generally regarded as the usual doubly robust estimator.
Kang & Sch?fer (2007) and Tan (2006) identified alternative doubly robust estimators, all involv
ing models for the propensity score and outcome regression and some appearing to have forms
outside the augmented class (3). The former authors attributed poor performance of (4) when the
propensity or both models are misspecified in part to inverse weighting by the propensity score.
Tsiatis & Davidian (2007) noted that such alternative estimators can be rewritten in the form (3)
and used semiparametric theory to argue that poor performance when one or the other model
is incorrect may be partly a consequence of the method used to estimate ?. In ? 3, we identify
doubly robust estimators from this perspective. When both models are correct and is estimated
by maximum likelihood, all doubly robust estimators are consistent with the same asymptotic
variance; moreover, the asymptotic properties do not depend on the method used to estimate ?

(Tan, 2007; Tsiatis & Davidian, 2007).

3. Alternative doubly robust estimators
In this section, we focus on estimation of ? in a posited outcome regression model m(X, ?),
possibly nonlinear in ?, to identify doubly robust estimators with desirable properties. To fix
ideas, we consider first a fully specified propensity score model ( ), say, involving no unknown
parameters; we relax this shortly. Suppose, for some estimator ? for ?, we estimate by

! " f RiYi Ri -n(Xi) * ?

? Y \-?m(Xi, ?) } . (5)

fr[U(Xi) n(Xi) K ' K }

We now examine how to estimate ? to achieve the estimator for of form (5) that is (i) doubly
robust and, (ii) if the propensity score is correctly specified, has smallest asymptotic variance
among all estimators for of form (5) using m(X, ?), even if m(X, ?) is incorrect.

Suppose first that the propensity score is correct, ( ) = ( ^), but m(X, ?) may or may not
be correctly specified. It is straightforward to show that using any estimator ? in (5) leads to a
consistent estimator for whose asymptotic variance is the same as that of

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

726

Weihua Cao, Anastasios A. Tsiatis and Marie Davidian

where ?* is the limit in probability of ?. Using the formula var(-) = ?'{var?- | X, 7)} +
var{?(- I X, 7)}, this variance is proportional to
var

1 - 0( ) rv ,v ^,,2]+ var(7). (7)

{ 0( ) ( ) J L 0( )

A natural objective is to identify the value of ?*, and corresponding estimators ? converg
ing in probability to it, such that (7) is minimized whether or not m(X, ?) is correct. Let
ting nt?(X, ?) = d/d?{m(X, ?)}, note that (7) is minimized by choosing ?* as the solution to

E[{\ - 0( )} ^\ ){ - m(X, ?*)}m?(X, ?*)] = 0, or equivalent^

1no(X)
?( ){m0(X) - m(X, ?*)}m?(X, ?*)

= 0; (8)

denote this value by ?*t. Note that ?*pt = ?o when m(X, ?) is correctly specified.
Consider first the ordinary least-squares estimator for ?, ?\, say, solving

n~x Y^RiiY- m(Xi, ?)} m?(Xi9 ?) = 0, (9)
i=\

based on the complete cases. If the propensity score is correct, ( ) = ( ), but
m(X, ?) m (X) for any ?, then the left-hand side of (9) converges in probability to

E [ 0( ) {mo(X) - m(X, ?)} m?(X, ?)] . (10)
Then ?\ converges in probability to the value ?\ such that (10) equals zero; however, comparing
(10) to (8) shows ? ?*pV If the propensity score is incorrect, but the outcome regression model
is correct, so that m(X, ?o) = mo(X) for some ?o, then the left-hand side of (9) again converges
to (10), and ?\ ? ?o, so that ?\ converges in probability to ?o. Thus, the estimator (5) for using
?\ is doubly robust but does not achieve the minimum variance when the outcome regression

model is misspecified. Estimation of ? by solving (9) would most likely be undertaken with
continuous 7; a similar result holds if ? is estimated via iteratively reweighted least squares, as
in the case of a generalized linear model m(X, ?).

Suppose we consider instead estimating ? by minimizing the empirical variance of (5),

n~2 Ei=dRiYi*~l(xi) - iRi - ( )} - ( ) ( , ?)]2 in ?9 leading to ?2 solving

If the propensity score is correct but w(X, ?) mo(X) for any ?, then the left-hand side of (11)
converges in probability to an expression of the form (8). Thus, it follows that ?2 converges in
probability to ?* v When the propensity score is incorrect but the outcome regression model is
correct, algebra shows that the left-hand side of (11) converges to

0( -j?-m0(X)
){1 - ( )} \ ( )-2-( )i-m(X,
{ ) + 2{ ) ] ?)

m?(X, ?)

The value of ? setting this equal to zero, to which ?2 converges in probability, is clearly not ?o.
Thus, the estimator (5) using ?2 achieves minimum variance but is not doubly robust.
These calculations show that using familiar or seemingly intuitive techniques to estimate ? for
use in (5) leads to estimators for that meet one of conditions (i) or (ii), but not both. To satisfy

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

Efficiency and robustness of doubly robust estimators

121

(i) and (ii) simultaneously, we consider ? to be the solution to

which may be viewed as weighted least squares based on complete cases with weights
{1 ? n(Xi)}/n2(Xi). When the propensity score is correct but the outcome regression is not,
like that of (11), the left-hand side of (12) converges in probability to an expression of the

form (8), and hence ? converges in probability to ?*pt. When the outcome regression is
correctly specified and the propensity score is not, the left-hand side of (12) converges to

E[n0(X){l - n(X)}n-2(X){m0(X) - m(X, ?)}m?(X, ?)], which equals zero when ? = ?0, so
that j?3 converges in probability to ?o. Thus, the estimator (5) for with ? = ? is doubly robust
and achieves minimum asymptotic variance even if m(X, ?) is misspecified.

In practice, a parametric propensity score model ( , ) would be posited. Here, we cannot
use the above results directly to find an estimator for of the form of /xDR in (4), where is the
maximum likelihood estimator for binary regression, that satisfies conditions (i) and (ii). There
is an effect of estimating that must be taken into account, so that finding ? converging to the

minimizer of (7), which assumes { ) is fully specified, does not necessarily lead to minimum

asymptotic variance under a model ( , ) with estimated. However, we may exploit the
insights gained from the foregoing results, as we now demonstrate.

Let SY(R, X, y) = {R- ( , )}[ ( , Y) {1 - ( , )} ( , ) be the score for ,

where ny(X, ) = d/dy{n(X, )}. From the point of view of semiparametric theory, the el
ements of the class of influence functions (Tsiatis, 2006, chapter 3) corresponding to esti
mators for of the form (5), with fully and correctly specified ( ) but possibly incorrect
m(X, ?) and using ? converging in probability to some ?*9 have the form RY/no(X) ? [{R ?
no(X)}/no(X)]m(X, ?*) ? . The influence functions corresponding to estimators of the form

(4) when ( , ) is correctly specified, so that ( , ) = ( ) for some yo, have the form

_RY
_ R-7to(X)m{Xt
n _ (? - o5(y> R Xf ) _ (13)
JTo(A)
7 ( )
and this equals

where $( ) = ( , ),
0(?*) = E[ny,o(X){mo(X) - m(X, ?*)}/ 0{ )],

,0 = E( 0( ) 10( )/[ ( ){1 - 0(*)}]),
with assumed nonsingular. The influence functions (13) thus involve an additional term

due to estimation of , the projection onto the propensity score tangent space, the linear space
spanned by the score (Tsiatis, 2006, Theorem 9.1). Because the influence function of an estimator
dictates its asymptotic variance, we would like to find ? to substitute in (4) converging to ?**,
say, that minimizes the variance of (13). We do this by considering a class of influence functions
containing class (13), with elements

RY R-no(X)___,v n,s ,T
m(X, ?*) ? c S(y, R, X, yo) ? ?
0( ) 0( )
This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

728

Weihua Cao, Anastasios A. Tsiatis and Marie Davidian

and this equals

0( ) 0( ) I 1 - 0( ) J

for arbitrary (?*,c*). Identifying the expression in braces in (15) as a f

m(X, ?*) in (7) and (8), by analogy to (7) and (8), (??, c0*p*t) solving

1-\0(
) / ?- ny,o(X)
0 mj{X
-??
m0(X)
m(X, ? ) -\c =\
??
\ i A
1 - 0( )

minimize the variance of (15). This yields c** = (?**) ~^0, so that (15) with (

substituted has the same form as (14), and hence ?** minimizes the variance of (13). Thus, a
estimator for of the form (4), with the smallest asymptotic variance when ( , ) is correctly
specified but m(X, ?) may not be, is achieved by using ? converging in probability to ?**. B
analogy to (12), we propose estimating ? by solving jointly in (?, c)

1=1

n(Xhy) n(Xhy) ^ _ ( "9)} l \- ( 9 )\

= 0. (16)

By an argument entirely similar to that following (12). when the propensity model is correct but
m(X, ?) may or may not be, ^4, say, solving (16) converges in probability to ?* *. When m(X, ?)
is correct but 7r(X, y) is not, assuming that y converges in probability to some y*, the quantity
to which the left-hand side of (16) converges in probability equals zero when (?, c) ? (? , 0).
Thus, taking ? = ?<\ in (4) yields an estimator for that is (i) doubly robust and (ii) achieves
minimum asymptotic variance when the propensity model is correct. In the sequel, we denote
this estimator by /2PRoj and denote the usual doubly robust estimator taking ? = ?\, the ordinary
least-squares estimator for ? solving (9), by Ausual
Tan (2006) proposed a doubly robust estimator for that is closely related to /xproj- In the
present context, Tan's estimator is equivalent to modelling E(Y \ X) by m(X, ?) and estimating

? by ordinary or iteratively reweighted least squares (?\)\ replacing m(X, ?) in (4) and (16)
by m(X, ?) = a0 + a\m(X, ?), ? = (a0, < \, ? ) ; holding ? fixed at ?\ and solving (16) in
(a , o?i, c), where m ? ( , ?) is replaced by {1, m(X, ? )} ; and substituting the resulting estimates

for (ao, ?i) and ?\ for ? in (4). Denote this estimator by /?tan- If? in constructing /xproj, we
similarly replace m ( , ?) by m ( , /?) in (4) and ( 16), but estimate all elements of ? simultaneously
by solving (16) with rri?(X, ?) replaced by d/d?{rh(X, ?)}, then, by the same reasoning as above,
the resulting estimator for will have asymptotic variance at least as small as that of A when
the propensity score is correct, as this estimator for ? will converge in probability to the optimal
value minimizing this variance, while ?\ used by Tan will not. If m(X, ?) is correctly specified
but (X, y) is not, because the estimator for ? obtained by either method converges in probability

to (0, 1, )8q)t, both /?tan and this version of /?proj are doubly robust; this would also hold if the
true form of E(Y | X) were c?o + a\m(X, ?) for (?o, <*i) =+= (0. 1). Thus, although these versions
of Aproj and A are doubly robust, the former is at least as efficient as the latter.

All of the estimators Ausual, Aproj and /iTAN involve solving jointly a set of M-estimating

equations (Stefanski & Boos, 2002); for example, Ausual is found by solving the usual score
equation for y, the ordinary least-squares equation (9) and the estimating equation implied by

(4). Thus, the asymptotic variance of the estimator for can be approximated by the usual
empirical sandwich technique; see Stefanski & Boos (2002). The resulting estimator for variance

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

Efficiency and robustness of doubly robust estimators 729
will be consistent for the true sampling variance even if one or both of the propensity or outcome

regression models is incorrectly specified.

4. Enhanced propensity score model
Doubly robust estimators such as Aproj that also achieve minimum variance when the propen
sity model is correct but the outcome regression model may not be should lead to improved per
formance over Ausual under these conditions. However, the problem of large weights 1 /n(X?, )
can also affect performance; as illustrated by Kang & Sch?fer (2007), if both models are even
mildly misspecified, then /?usual may be severely biased due to a few very large weights. If the
propensity model in particular is slightly misspecified, (Xi, ) can be erroneously close to zero
for some /. We consider an approach to address this issue.

If the propensity score model is correct, we expect that ?= Ri/ (Xi, ) ^ . When the
estimated propensities for some observations are close to zero, this quantity can be very different
from n. We thus consider propensity models and estimators that impose the restriction that this

quantity be equal to n; if the chosen model is misspecified, this restriction will drive estimated
propensities away from zero. We thus propose an enhanced propensity score model, given by

exp(<5 + )

Pv(R = l\X) = ( , ?,1 y)
= 1 - R ~ Y , (17)
+ Qxp(XTy)
where ?isa scalar parameter. If ? = 0, (17) reduces to a usual logistic regression model; otherwise,

is an enhancement imposing the constraint Y%=i Ri/n(Xi, , ) = n. This follows because the
score for is ? "= Rj/n (Xi, , ), so that if maximum likelihood is used to estimate ( , yT)T,
the constraint is satisfied automatically. Because ( , , ) can take values outside (0, 1), we
impose 0 < ( , , ) < 1 and implement maximum likelihood subject to this restriction, which
can be carried out with standard optimization packages.
From a semiparametric theory perspective, it may be shown that use of the enhanced model
should lead to an increase in efficiency in estimation of by any of the methods in ? 3 relative
to using the logistic regression model with alone as long as (17) contains n$(X). This follows
because the influence functions for these estimators when (17) is used involve an additional term
relative to those for the same estimators using the model with 5 = 0. Those with the additional
term have smaller variance; see Tsiatis (2006, chapter 9).

5. Simulation studies
We carried out several simulation studies to assess performance of the proposed methods under

two scenarios. For both scenarios, for each of = 200 and 1000, we considered the four possible
combinations of correct and misspecified outcome regression and propensity score models. For
each scenario/setting combination, 1000 Monte Carlo datasets were generated, and the estimators
Aor, Ausual, Atan and Aproj were calculated for each, where Aproj was constructed using m ( , ?)
as described in ? 3. We also constructed the estimators Ausual an(^ Aproj? which are the indicated
estimators with the enhanced propensity model ( 17), replacing the usual logistic propensity model
described below and fitted by constrained maximum likelihood. For each estimator, sandwich

standard errors and nominal 95% Wald confidence intervals for were calculated. To calculate

Ausual an(^ Aproj> we used the SAS IML optimizer nlpqn (SAS Institute, 2006) to fit the enhanced

propensity model.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

730

Weihua Cao, Anastasios A. Tsiatis and Marie Davidian

We duplicated the scenarios in Kang & Sch?fer (2007) and Tan (2007), which were designed
so that, when misspecified, the assumed outcome regression and propensity score models were
nonetheless nearly correct; our choice of these scenarios allows consideration of the proposed
methods in a familiar context that was designed to highlight differences among estimators. Kang
& Sch?fer found that, under their scenario, Ausual exhibited severe bias when both models were
misspecified but nearly correct, while Aor was not as severely affected, leading the authors to

contend that 'two wrong models are not necessarily better than one.' Tan modified Kang &
Schafer's scenario slightly and showed that versions of /?tan offered improvement over Ausual

For the Kang & Sch?fer scenario, for each i (i ? 1,..., ), Zi = (Zu, Z/2, Z/3, Z^f was
generated as standard multivariate normal, and the elements of / = (Xu, /2, , X?a)1 were
defined as Xn = exp(Zn/2), Xi2 = Z/2/{l + exp(Z/i)} + 10, Xi3 = (Z/iZ/3/25 + 0-6)3 and
Xi4 = ( /2 + /4 + 20)2, so that Zz may be expressed in terms of X?. For each z, Yi = mo(Xi) +
6/ for ,? standard normal and mo(Xi) = 210 + 274Z/i + 13-7Z/2 + 13-7Z/3 + 13-7Z/4, and R?

was generated as Bernoulli with true propensity ( = expit(?Z/i + 0-5Z/2 ? 0-25Z/3 ?
O IZ/4), where expit(w) = eu/(l + eu). Correctly specified outcome regression and propensity
models were thus achieved when an additive linear regression of Y/ on Z/ and a logistic regression
with linear predictor additive in the Z/ for Ri9 respectively, were fitted; nearly correctly specified

models involved fitting these models with X? replacing ,?; see Kang & Sch?fer (2007). The Tan
scenario was identical to that of Kang & Sch?fer, except that Xu = (Z/3 + Z/4 + 20)2. The true

value of the mean is = 210.

Results for the Kang & Sch?fer and Tan scenarios are in Tables 1 and 2, respectively. When
both models are correct, all estimators perform similarly, and all of the doubly robust estimators

show negligible Monte Carlo bias when at least one of the models is correctly specified, as
expected. Moreover, Aproj and Aproj for the most part exhibit efficiencies no worse or better
than those of Aor and the other doubly robust estimators on the basis of the root mean square
error and the median absolute error, and in particular dominate the others when the outcome
regression model is misspecified but the propensity model is correct, consistent with the basis
of their construction. When both models are incorrectly specified, /?usual shows nonnegligible
bias, as observed by Kang & Sch?fer (2007) and Tan (2007); however, the use of the enhanced
propensity model in Ausual eliminates this behaviour. The proposed estimators Aproj and Aproj
exhibit the best performance in terms of bias and efficiency when both models are misspecified;
in the Appendix, we sketch a heuristic argument suggesting that this behaviour is not unexpected.

Overall, Aproj shows the best performance across the range of settings in both scenarios.
Confidence intervals based on sandwich standard errors based on the doubly robust estimators
for the most part attain nominal coverage except when both models are misspecified in the Kang
& Sch?fer scenario; those for Aproj and Aproj perform consistently well except in this case. Not
unexpectedly, when the outcome regression model is misspecified, confidence intervals based on
Aor can suffer from undercoverage.

6. Discussion
Our work complements that of (Tan, 2006, 2007) and Robins et al. (2007), who also demon
strated that it is possible to identify doubly robust estimators that do not suffer the drawbacks

demonstrated by Kang & Sch?fer (2007) under model misspecification. We have focused our
development on estimation of a single treatment mean in order to demonstrate the approach to
developing optimal, doubly robust estimators in ? 3 in an accessible context; however, the results
are relevant to more complex estimands. In the case where a difference of treatment means is
of interest, if one restricts attention to outcome regression models linear in a vector of known

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

731

Efficiency and robustness of doubly robust estimators

Table 1. Simulation results based on 1000

Monte Carlo replications for the Kang &

scenario. Smallest, median, second largest,
(0 04, 008, 0-39, 5-58); avese (0 0008, 0

and largest standard errors for table entri

004, 0-58,6 64); cov (0 006, 0 007, 0 015,

bias rmse mae mcsd avese

or correct, ps correct

mor
AuSUAL

Aproj

Atan

^usual

^proj
mor

Ausual

Aproj

Atan
Ausual

^proj

-006 2-51
-006 2-51
-007 2-51
-005 2-51
-006 2-51
-006 2-51
-0-55
0-36
-006
0-16
0-54
-004

166
1-66
1-69
1-68
166
1-68

2-56
2-56
2-56
2-58
2-56
2-58

2-51
2-51
2-51
2-51
2-51
2-51

cov

0-96
0-95
0-95
095
096
0-95

or incorrect, ps correct

3-29 2-14
3-53 2-33
2-57 1-72
2-88 1- 96
326 2- 27
2-57 1-70

24
51
57
88
22
57

3-24 093
3-22 0-94
2-60 0-95
2- 81 0-95
3- 37 0-94
2-85 0-96

bias

200

-006
-005
-006
-005
-0-06
-006
-0-55
-5-19
-0-39
-1-77
-1-53
-0-31

rmse mae

mcsd avese

cov

or correct, ps incorrect

2-51
2-53
2-50
2-51
2-51
2-51

166
1-70
1-68
167
1-67
1-70

51
53
50
51
51
51

or incorrect, ps incorrect

3-29 2-14
13-26 3-62
3-58 2-00
3-52 2-36
3-51 2-29
3-48 1-89

3-24
12-20
3-55
3-05
316
3-47

2-56
2-57
2-56
2-51
262
2-63

096
095
0-96
0-96
0-96
0-96

3-24
654
3-28
3 04
5-48
3-63

0-93
0-92
093
0-90
0-91
0-94

= 1000
mor

Ausual

Aproj

Atan

^usual

^proj
mor

Ausual

Aproj

Atan

^usual
^proj

-0-03
-003
-003
-003
-003
-003
-0-78
012
0-01
004
024
0-02

or correct, ps correct

13

-13

13

-13

13
13

0-73
0-73
0-72
0-73
0-73
0-72

13
13

-13
-12

13
13

15 0-95
15 0-95
15 0-95
15 095
15 0-95
15 0-95

or incorrect, ps correct

68 1-18
64 109
14 0-73
27 0-85
55 102
14 0-73

-49
64
14
27
-53

14

-48
54
-16
26
-42
16

-003
0-01

-0-03

-0-03
-003
-0-03

or correct, ps incorrect

13
72
13

-13
-13

13

0-73
0-74
0-73
0-73
0-73
0-73

-13

-72

-13

0-95
095
15 095
15 095
15 0-95
15 095

13
-13
13

or incorrect, ps incorrect

-0-78
0-91
1-68 1-18
093 -18-05 177-45 5-25
0-95 -1-25
1- 78 1-35
0-95 -1-69
2- 24 1- 80
0-92 -2-00
2-44 2- 08
095 -0-96
1-58 116

15
-28

1-49

176-53
1-27

1-47

1-41

1-25

1-48 0-91
16-60 0-61
1-24 0-83
1-43 076
1-39 0-69
1-24 0-88

bias, Monte Carlo bias; rmse, root mean square error; mae, median of absolute errors; mcsd, Monte Carlo standard
deviation; avese, average of sandwich standard errors; cov, Monte Carlo coverage of 95% Wald confidence intervals;

or, outcome regression; ps, propensity score.

functions g(X) for both treatments, then taking the difference of the optimal, doubly robust esti
mators proposed here will lead to an optimal, doubly robust estimator for the mean difference;

see Tan (2006, p. 1623). However, this need not hold in general, for example, if the posited
outcome regression models are nonlinear in their parameters. In this case, it is possible to adapt
the approach here to derive directly an optimal, doubly robust estimator for the difference; a
sketch of the argument is available at http://www.stat.ncsu.edu/~davidian. The proposed meth
ods may also be adapted to the case of estimation of the parameter in a regression model, where
an estimator based on the full data may be derived as the solution to an M-estimating equation;
we are currently developing such methods in the case of monotonely coarsened longitudinal data
and will report the results elsewhere.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

732

Weihua Cao, Anastasios A. Tsiatis and Marie Davidian

Table 2. Simulation results based on 1000 Monte Carlo replications for the Tan scenario.
Entries are as in Table 1. The Tan and Kang & Schafer scenarios are distributionally identical
in the or correct and ps correct cases. Smallest, median, second largest, and largest standard
errors for table entries: bias (0-04, 0-08, 0-76, 5-66); avese (0-0008, 0-004, 1-59, 9-78); cov

(0 006, 0 007, 0 010, 0 015)
BIAS PvMSE MAE MCSD AVESE COV BIAS RMSE MAE MCSD AVESE COV

=200

mor

AuSUAL

Aproj

Atan
Ausual

-0-06
-006
-007
-005
-006

mor
AuSUAL

2-64
0-74

Atan
/^usual

^proj

2-51
2-51
2-51
2-51
2-51
2-51

-0-06

^proj

Aproj

or correct, ps correct

1-66
166
1-69
1-68
1-66
1-68

2-51
2-51

2-51
2-51
2-51
2-51

or incorrect, ps correct

4-10 302
3-80 2-44
2-70 1-76

0- 56

064

2- 79 1- 88
3- 42 2- 33
2-69 1-75

1- 37

0-52

314
3-72
2-64

2- 72
3- 13

2-64

2-56
2-56
2-56
2-58

0-96
0-95
0-95
0-95

2-58

0-95

2-56

096

3-08 0-88
3-30 0-93
2-67 0-95
2- 72 0-96
3- 22 0-91
3-14 0-95

-0-06
-004
-006
-005
-006
-006
2-64
-2-76
0-51

0- 94
1- 36

0-48

or correct, ps incorrect

2-51
2-55
2-51
2-50
251

251

66
70
69
65

67

2-56
2-59
2-56
2-56
2-57
2-62

2-51
2-55
2-51
2-50
2-51
2-51

or incorrect, ps incorrect

4-10 3-02
24-18 2-76
2-91 1-90
2- 99
3- 28

2-86

1- 91

2- 18

186

0-96
0-95
0-95
0-96
0-95
0-95

3-08 0-88
0-95
2-80 095
2- 84 0-95
3- 65 093
302 0-95

3-14
24-02
2-87
2-84
2-99
2-82

7-71

= 1000
mor

ausual

Aproj

Atan
Ausual

-003
-003

-003

mor

Aproj

2-31
018
019

^proj

0-53
0-18

Atan
Ausual

0-73
0-73
0-72
1-12 0-73
1-13 0-73
113 0-72
1-13
1-13
1-13

-0-03
-0-03
-0-03

^proj

Ausual

or correct, ps correct

1-13

1-15

1-13
1-12
1-13
1-13

1-15
1-15
1-15
1-15

113

or incorrect, ps correct

2-32
84 114
18 0-76
23 0- 79
56 1- 03
17 0-74
72

0-22

115

1-43
1-84
1-16

1-41

1-21

1-21

147
1-16

1-64
1-17

1-27
1-17

095
095
0-95
0-95
0-95
0-95
0-63
0-93
095
0-94
0-89
0-94

-003
003

-0-03
-0-03
-0-03
-003

2-31
-17-89

013

0-89

0-73
0-22

or correct, ps incorrect
1- 13 0-73
1- 13

0-74
0-72
1-12 0-73
1-13 0-73
113 0-73

2- 07
1-13

or incorrect, ps incorrect

2-72 2-32
2-65
0-78
1-61
100
1-47 0-97
1-23 0-78

179-88
1-25

115

1-32
1-15
1-15
1-15
1-15

2- 07
1-13
1-12
1-13
1-13

1-43
178-98
1-25
1-35
1-28

1-41 0-63
22-60 0-94
1-20 0-94
131 0-91

1-21

bias, Monte Carlo bias; rmse, root mean square error; mae, median of absolute errors; mcsd, Monte Carlo standard
deviation; avese, average of sandwich standard errors; cov, Monte Carlo coverage of 95% Wald confidence intervals;

or, outcome regression; ps, propensity score.

Like the stabilized weights discussed by Robins et al. (2000), the enhanced propensity score
model proposed in ? 4 is an effort to avoid weighting that is too disparate across individuals,
leading to instability of the estimator for the mean. In the simple context of estimating a single
mean, taking a stabilized weights approach is not possible; accordingly, the proposed enhanced
model provides an effective alternative. Other methods, such as truncating or smoothing estimated
propensities, may also yield improved performance.
It is worth noting that, when the outcome regression model is correct but the propensity model

is not, attempting to improve efficiency would be fruitless. Here, the optimal estimator is fi0R,
and the propensity score plays no role; see Tsiatis & Davidian (2007, p. 573).

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

0-95
0-95
0-95
0-95
0-95
0-95

1-27 0-91
1-19 0-94

Efficiency and robustness of doubly robust estimators 733
Detailed formulae for the asymptotic variances of the estimators in this paper are available at
http ://www. stat.ncsu.edu/ ~davidian.

Acknowledgement
This work was supported by grants from the U.S. National Institutes of Health.

Appendix
Performance under misspecification

We argue heuristically that Aproj and Arroj maY perform well under misspecification of both the
propensity and outcome regression models. Suppose that m(X, ?) in (5) may be misspecified and that (X)

in (5) is misspecified as ( ) = ( ) + Ons(X), where limw^oo /2 = . If we substitute ? solving
(12) in (5), because ( ) converges to 0( ), ??, still converges in probability to ?*pV Thus, the resulting
estimator for , ?, say, would be asymptotically equivalent to (6) with ( ) replacing $( ) and ?* =

?*pV Expanding this expression about ( ) shows that 1/2( ? ) converges in distribution to a normal
random variable with mean? E [s (X){ Y ? m(X, ?*pt)/ ( )], so exhibits an asymptotic bias. Because

of(8),?[{l - 0( )} ^\ ){ - m(X, ?*pt)}cTm^(X, ?*pt)] = 0 for any constant vectorc.lt follows that,
letting q0(X) = [{1 - ( )}/ 0( )] /2, the asymptotic bias may be written as -TE{(s(X)/[n0(X){\ ^o(X)}]1/2 - q0(X)cTm?(X, ?*pt))qo(X){Y - m(X, ?*pt)}}, the absolute value of which, by the Cauchy
Schwarz inequality, is bounded by

rtinf E{(s(X)/[n0(X){\ - 0( )}]1/2 - q0(X)cTrn?(X, )?0*pt))2}]1/2 (Al)
(E[{qo(X)}2{Y - m(X, ?0*pt)}2])1/2. (A2)
If we were to use in (5) another estimator ?, which converges in probability to some ?**, by a similar

argument, the resulting estimator fin would have associated asymptotic bias whose absolute value is
bounded by r[E{(s(X)/[n0(X){\ - 0( )}]1/2)2}]1/2 x(E[{q0(X)}2{Y - m{X, ?**)}2])1/2. The first term
in this expression must be at least as large as (Al), because (Al) is the projection of s(X)/[no(X){\ ?

( )}]1/2 onto the linear space spanned by q0(X)m?(X, ?*pt), while the second must be greater than or
equal to (A2) by the definition of ?*pV Thus, the bound on asymptotic bias of is greater than that for ;
moreover, the asymptotic variance of ? is of course greater than that of by construction. Although the
first result does not guarantee that fin will show smaller bias, it does suggest that smaller bias may obtain
in many circumstances, particularly if s(X)/[no(X){l ? tt0(X)}]1/2 may be well approximated by a linear
combination of q0(X)m?(X, /3*pt).

References
Bang, H. & Robins, M. (2005). Doubly robust estimation in missing data and causal inference models. Biometrics

61, 962-72.

Kang, D. Y. J. & Sch?fer, J. L. (2007). Demystifying double robustness: a comparison of alternative strategies for
estimating a population mean from incomplete data (with discussion and rejoinder). Statist. Sci. 22, 523-80.
Lunceford, J. K. & Davidian, M. (2004). Stratification and weighting via the propensity score in estimation of causal
treatment effects: a comparative study. Statist. Med. 23, 2937-60.
Robins, J. M., Hern?n, M. & Brumback, . (2000). Marginal structural models and causal inference in epidemiology.

Epidemiol. 11, 550-60.

Robins, J. M., Rotnitzky, A. & Zhao, L. R (1994). Estimation of regression coefficients when some regressors are
not always observed. J. Am. Statist. Assoc. 89, 846-66.
Robins, J. M., Sued, M., Lei-Gomez, Q. & Rotnitzky, A. (2007). Performance of double-robust estimators when
inverse probability weights are highly variable. Statist. Sci. 22, 544-59.

Rosenbaum, R R. (1987). Model-based direct adjustment. J. Am. Statist. Assoc. 82, 387-94.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

734 Weihua Cao, Anastasios A. Tsiatis and Marie Davidian
Rosenbaum, R R. & Rubin, . . (1983). The central role of the propensity score in observational studies for causal
effects. Biometrika 70, 41-55.

Rosenbaum, P. R. & Rubin, D. B. (1984). Reducing bias in observational studies using subclassification on the
propensity score. J. Am. Statist. Assoc. 79, 516-24.
Rubin, D. B. (1976). Inference and missing data. Biometrika 63, 581-92.
Rubin, D. B. (1978). Bayesian inference for causal effects: the role of randomization. Ann. Statist. 6, 34-58.
Rubin, D. B. & Thomas N. (1996). Matching using estimated propensity scores: relating theory to practice. Biometrics

52, 249-64.

SAS Institute, Inc. (2006). SAS Online Documentation 9.1.3. Cary, NC: SAS Institute.
Stefanski, L. A. & Boos, D. D. (2002). The calculus of M-estimation. Am. Statist. 56, 29-38.
Scharfstein, D. O., Rotnitzky, A. & Robins, J. M. (1999). Adjusting for nonignorable drop-out using semiparametric
nonresponse models (with discussion and rejoinder). J. Am. Statist. Assoc. 94, 1096-146.

Tan, Z. (2006). A distributional approach for causal inference using propensity scores. J. Am. Statist. Assoc. 101,

1619-37.

Tan Z. (2007). Understanding OR, PS and DR. Statist. Sci. 22, 560-8.
Tsiatis, A. A. (2006). Semiparametric Theory and Missing Data. New York: Springer.
Tsiatis, A. A. & Davidian, M. (2007). Comment on 'Demystifying Double Robustness: A Comparison of Alternative
Strategies for Estimating a Population Mean from Incomplete Data.' Statist. Sci. 22, 569-73.

[Received June 2008. Revised December 2008]

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 16:08:26 UTC
All use subject to https://about.jstor.org/terms

