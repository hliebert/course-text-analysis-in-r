7
FIXED-EFFECTS NEGATIVE
BINOMIAL REGRESSION MODELS
Paul D. Allison*
Richard P. Waterman*
This paper demonstrates that the conditional negative binomial
model for panel data, proposed by Hausman, Hall, and Griliches (1984), is not a true fixed-effects method. This method—
which has been implemented in both Stata and LIMDEP—does
not in fact control for all stable covariates. Three alternative
methods are explored. A negative multinomial model yields the
same estimator as the conditional Poisson estimator and hence
does not provide any additional leverage for dealing with overdispersion. On the other hand, a simulation study yields good
results from applying an unconditional negative binomial regression estimator with dummy variables to represent the fixed effects.
There is no evidence for any incidental parameters bias in the
coefficients, and downward bias in the standard error estimates
can be easily and effectively corrected using the deviance statistic. Finally, an approximate conditional method is found to perform at about the same level as the unconditional estimator.

1. INTRODUCTION
A major attraction of panel data is the ability to control for all stable covariates, without actually including them in a regression equation. In general,
this is accomplished by using only within-individual variation to estimate
the parameters and then averaging the estimates over individuals. Regression models for accomplishing this are often called fixed-effects models.
*University of Pennsylvania.

247

248

ALLISON AND WATERMAN

Fixed-effects models have been developed for a variety of different data
types and models, including linear models for quantitative data ~Mundlak
1978!, logistic regression models for categorical data ~Chamberlain 1980!,
Cox regression models for event history data ~Yamaguchi 1986; Allison
1996!, and Poisson regression models for count data ~Palmgren 1981!.
Here we consider some alternative fixed-effects models for count
data. First, we show that the fixed-effects negative binomial model proposed by Hausman, Hall, and Griliches ~1984! ~hereafter HHG! is not a
true fixed-effects method. Next we consider a negative multinomial model,
which leads back to the estimator for the fixed-effects Poisson model. We
then use simulated data to compare an unconditional negative binomial
estimator with the fixed-effects Poisson estimator. The negative binomial
estimator does not appear to suffer from any “incidental parameters” bias,
and is generally superior to the Poisson estimator. Finally, we investigate
an approximate conditional likelihood method for the negative binomial
model. Its performance on the simulated data is roughly comparable to
that of the unconditional negative binomial estimator.
2. THE FIXED-EFFECTS POISSON MODEL
The fixed-effects Poisson regression model for panel data has been
described in detail by Cameron and Trivedi ~1998!. The dependent variable yit varies over individuals ~i 5 1, + + + , n! and over time ~t 5 1, + + + , Ti !.
It is assumed to have a Poisson distribution with parameter m it , which
in turn depends on a vector of exogenous variables x it according to the
loglinear function
ln m it 5 di 1 bx it ,

~1!

where di is the “fixed effect.”
One way to estimate this model is to do conventional Poisson regression by maximum likelihood, including dummy variables for all individuals ~less one! to directly estimate the fixed effects. An alternative method
is conditional maximum likelihood, conditioning on the count total (t yit
for each individual. For the Poisson model, this yields a conditional likelihood that is proportional to

)i )t

S(

exp~ bx it !

s

exp~ bx is !

D

yit

,

~2!

NEGATIVE BINOMIAL REGRESSION MODELS

249

which is equivalent to the likelihood function for a multinomial logit model
for grouped data. Note that conditioning has eliminated the di parameters
from the likelihood function.
For logistic regression models, it is well known that estimation of
fixed-effects models by the inclusion of dummy variables yields inconsistent estimates of b ~Hsiao 1986! due to the “incidental parameters” problem ~Kalbfleisch and Sprott 1970!, while conditional estimation does not
suffer from this problem. For Poisson regression, on the other hand, these
two estimation methods—unconditional maximization of the likelihood
and conditional likelihood—always yield identical estimates for b and
the associated covariance matrix ~Cameron and Trivedi 1998!. Hence, the
choice of method should be dictated by computational convenience.
The fixed-effects Poisson regression model allows for unrestricted
heterogeneity across individuals but, for a given individual, there is still
the restriction that the mean of each count must equal its variance:
E~ yit ! 5 var~ yit ! 5 m it +

~3!

In many data sets, however, there may be additional heterogeneity not
accounted for by the model.
As an example, let’s consider the patent data analyzed by HHG and
reanalyzed by Cameron and Trivedi ~1998!. The data consist of 346 firms
with yearly data on number of patents from 1975 to 1979. Thus, yit is the
number of patents for firm i in year t. This variable ranged from 0 to 515
with a mean of 35 and a standard deviation of 71. A little over half of the
firm years had patent counts of five or less. The regressor variables include
the logarithm of research and development expenditures in the current
year and in each of the previous five years. All the fitted models also
include four dummy variables corresponding to years 1976 to 1979.
To analyze the data, we created a separate observation for each firm
year, for a total of 1730 working observations. We then estimated a fixedeffects Poisson regression model by conventional Poisson regression software,1 with 345 dummy variables to estimate the fixed effects. Results for
the research and development variables are shown in the first two columns
of Table 1. These numbers differ somewhat from those in Cameron and
Trivedi ~1998!, but they are identical to the corrected results reported in
their website ~http:00www.econ.ucdavis.edu0faculty0cameron0!.
1

We used the GENMOD procedure in SAS.

250

ALLISON AND WATERMAN

TABLE 1
Conditional Regression Models for Number of Patents
Conditional Poisson

LogRD-0
LogRD-1
LogRD-2
LogRD-3
LogRD-4
LogRD-5
Log SIZE
SCIENCE
Intercept

Conditional Negative Binomial

Coefficient

Standard
Error

Coefficient

Standard
Error

.322
2.087
.079
.001
2.005
.003

.046
.049
.045
.041
.038
.032

.363
.156
.174
.015
.029
.136

.085
.099
.090
.083
.076
.062

Coefficient

Standard
Error

.272
2.098
.032
2.020
.016
2.010
.207
.018
1.660

.071
.077
.071
.066
.063
.053
.078
.198
.343

A potential problem with these results is that there is still some
evidence of overdispersion in the data. The ratio of the deviance to the
degrees of freedom is 2.04 ~deviance 5 2807 with 1374 d.f.! and the ratio
of the Pearson goodness-of-fit chi-square to the degrees of freedom is
1.97 ~chi-square 5 2709 with 1374 d.f.!. For a good-fitting model, these
measures should be close to 1. Substantial departures from this ratio may
indicate a problem with the model specification, and also suggest that the
estimated standard errors may be downwardly biased.
3. THE HHG NEGATIVE BINOMIAL MODEL
HHG deal with the problem of overdispersion by assuming that yit has a
negative binomial distribution, which can be regarded as a generalization
of the Poisson distribution with an additional parameter allowing the variance to exceed the mean. There are several different ways to parameterize
the negative binomial distribution, and the choice can be consequential
for regression models. In the HHG model, the negative binomial mass
function can be written as
f ~ yit 6l it , ui ! 5

S DS D

ui
G~l it 1 yit !
G~l it !G~ yit 1 1! 1 1 ui

yit

1
1 1 ui

l it

~4!

251

NEGATIVE BINOMIAL REGRESSION MODELS

where G is the gamma function. The parameter ui is assumed to be constant over time for each individual while l it depends on covariates by the
function
ln l it 5 bx it +

~5!

The decision to decompose l it as a function of the covariates is somewhat
surprising, since l is usually regarded as an overdispersion parameter.
That’s because ~4! becomes the Poisson mass function as l r `.
The mean and variance of yit are given by
E~ yit ! 5 ui l it
var~ yit ! 5 ~1 1 ui !ui l it +

~6!

Under this model, the ratio of the variance to the mean is 1 1 ui , which
can vary across individuals but, as already noted, is constant over time.
HHG further assume that for a given individual i, the yit are independent over time. These assumptions imply that (t yit also has a negative binomial distribution with parameters ui and (t l it + Conditioning on
these total counts, the likelihood function for a single individual is given
by
G

S ( y 1 1D G S ( l D G~l 1 y !
) G~l !G~ y 1 1! ,
GS( y 1 ( l D
it

it

t

t

it

t

it

it

t

it

it

~7!

it

t

thereby eliminating the ui parameters. The likelihood for the entire sample is obtained by multiplying together all the individual terms like ~7!.
This likelihood may be maximized with respect to the b parameters using
conventional numerical methods. In fact, the method has been implemented in at least two commercial statistical packages, Stata ~www.stata.
com! and LIMDEP ~www.limdep.com!.
In the middle two columns of Table 1, we report results of applying this method to the patent data,2 using the same covariates as Cameron and Trivedi ~1998!. The numbers reported here are the same as the
corrected numbers given in their website. Note that the coefficients are
2
To estimate the model, we used the NLMIXED procedure in SAS. This
required the specification of the log-likelihood for a single individual.

252

ALLISON AND WATERMAN

similar in magnitude to those for the conditional Poisson method, but
the estimated standard errors are appreciably larger because the model
allows for overdispersion.
Unfortunately, this negative binomial model and its conditional likelihood does not really fit the bill as a fixed-effects method. The basic problem is that the ui parameters that are conditioned out of the likelihood
function do not correspond to different intercepts in the log-linear decomposition of l it . HHG’s rationale is that if we write ui 5 exp~di !, equations
~5! and ~6! imply that
E~ yit ! 5 exp~di 1 bx it !
var~ yit ! 5 ~1 1 e di !E~ yit !+
Therefore, it appears that this model does allow for an arbitrary intercept
di for each individual. The problem with this approach is that the di ’s play
a different role than x it . Specifically, changes in x it affect the mean directly,
and affect the variance only indirectly through the mean. But changes in
di affect the variance both indirectly, through the mean, and directly. If we
regard di as representing the effects of omitted explanatory variables, then
there is no compelling reason why these variables should have a different
kind of effect from that of x it .
To put it another way, suppose we begin with equations ~6! and
specify
l it 5 exp~di 1 bx it 1 gz i !,
where di is an individual-specific intercept and z i is a vector of timeinvariant covariates. Then conditioning on the total count for each individual does not eliminate di or gz i from the likelihood function.
Symptomatic of this problem is that using HHG’s conditional likelihood in ~7!, one can estimate regression models with both an intercept
and time-invariant covariates, something that is usually not possible with
conditional fixed-effects models. The last two columns of Table 1 show
results for estimating the conditional negative binomial model with an
intercept and two time-invariant covariates.3 Both the intercept and one
of the two covariates are statistically significant at beyond the .01 level.
3
SIZE is the firm book value in 1972. SCIENCE is an indicator variable equal
to 1 if the firm is in the science sector.

253

NEGATIVE BINOMIAL REGRESSION MODELS

4. A NEGATIVE MULTINOMIAL MODEL
We now consider an alternative parameterization of the negative binomial
model that is a more natural generalization of the Poisson model. The
mass function for a single yit is given by
f ~ yit 6m it , l i ! 5

S

m it
G~l i 1 yit !
G~l i !G~ yit 1 1! m it 1 l i

DS

li
m it 1 l i

yit

D

li

,

~8!

with mean and variance functions
E~ yit ! 5 m it
var~ yit ! 5 m it ~1 1 m it 0l i !+

~9!

Note that the mean is allowed to vary with time, but the overdispersion
parameter l i is assumed to be constant for each individual. To model
dependence on covariates, we let
ln m it 5 di 1 bx it +

~10!

Cameron and Trivedi ~1998! refer to this as an NB2 model, to distinguish
it from the previous NB1 model.
If we assume ~along with HHG! that the event counts are independent across time for each individual, then this model is not tractable
for deriving a conditional likelihood. That’s because (t yit does not itself
have a negative binomial distribution, so it’s awkward to condition on it.
More technically, under this specification, there is no complete sufficient
statistic for the di ’s that is a function of the data alone.
As an alternative approach, let’s assume that the yit have a negative
multinomial distribution, a well-known multivariate generalization of the
negative binomial distribution ~Johnson and Kotz 1969!. For a single individual, the joint mass function is given by

S

G li 1
f ~ yi1 , + + + , yiT 6l i , m i1 , + + + , m iT ! 5

(y

it

t

D

S

li

G~l i !yi1 ! + + + yiT ! l i 1
3)
t

S

m it
li 1

(m
t

it

D

(m
t

yit

D

li

it

~11!

254

ALLISON AND WATERMAN

with m it specified as in ~10!.4 This multivariate distribution has the property that the marginal distribution of each yit is negative binomial as defined
in ~8!. Furthermore, the sum (t yit has a negative binomial distribution
with parameters (t m it and l i . Unlike the HHG model, this one does not
assume that event counts in different time intervals are independent for a
given individual. In fact, the correlation ~Johnson and Kotz 1969! between
yit and yis ~s Þ t ! is
r~ yit , yis ! 5

!S m

m it
it 1 l i

DS

m is
m is 1 l i

D

~12!

To derive a fixed effects estimator for b, we can condition the joint
mass function on the total (t yit , which yields

S

f yi1 , + + + , yiT

* ( D G S1 1 ( y D )
yi1 ! + + + yiT !

yit 5

t

it

@)
t

S(

t

t

exp~ bx it !

s

exp~ bx is !

S( D
D
m it

yit

m it

t

yit

~13!

Thus, conditioning gives us a distribution that doesn’t depend on the parameter l i but is proportional to the conditional likelihood for the Poisson
model in equation ~2!. In other words, the fixed-effects negative multinomial model leads to the same conditional estimator of b as the fixedeffects Poisson model.5
So it seems that the negative multinomial approach doesn’t accomplish anything with respect to overdispersion. To understand this, recall
that the negative binomial distribution can be generated by compounding a Poisson random variable with a gamma random variable. The negative multinomial can be generated by compounding a set of independent
Poisson random variables with a single gamma random variable. Thus,
the overdispersion in the negative multinomial can be thought of as arising from a single random variable that is common to all the event counts
4
This distribution is the same as the one described by Cameron and Trivedi
~1998, p. 288! as a Poisson random-effects model with gamma distributed random
effects.
5
See Guo ~1996! for an application of the negative multinomial model in a
random-effects setting.

255

NEGATIVE BINOMIAL REGRESSION MODELS

for a given individual ~which is why the correlation in @12# is not zero!.
Conditioning on the total count for each individual removes all the unobserved heterogeneity, both that arising from the di fixed-effects and the
unobserved heterogeneity that is intrinsic to the negative multinomial
distribution.
5. CONVENTIONAL APPROACHES TO OVERDISPERSION
We have seen that the HHG method does not condition out the fixed effects,
while the negative multinomial method conditions out too much to be useful. What’s left? A relatively simple approach is to estimate the b coefficients under the fixed-effects Poisson model but to adjust the standard
errors upward for overdispersion. A commonly used adjustment is to multiply the standard errors by the square root of the ratio of the goodness-offit chi-square to the degrees of freedom. ~Either Pearson’s chi-square or
the deviance could be used. ! The first two columns of Table 2 show the
Poisson coefficients and adjusted standard errors for the patent data. The
coefficients are the same as those in Table 1. The standard errors were
obtained by multiplying the standard errors in Table 1 by 1.404, the square
root of Pearson’s chi-square divided by the degrees of freedom.
An alternative approach is to estimate an unconditional negative
binomial model. That is, to specify a conventional NB2 regression model,
with dummy variables to estimate the fixed effects. Results of doing

TABLE 2
Regression Models with Overdispersion Corrections
Fixed-Effects Poisson

LogRD-0
LogRD-1
LogRD-2
LogRD-3
LogRD-4
LogRD-5

Unconditional
Negative Binomial

Coefficient

Adjusted
Standard Error

Coefficient

Standard
Error

.322
2.087
.079
.001
2.005
.003

.064
.068
.063
.058
.053
.045

.356
.021
.007
.008
.117
.011

.093
.102
.096
.089
.081
.067

256

ALLISON AND WATERMAN

that for the patent data are shown in the last two columns of Table 2.6
The coefficients are similar to those obtained with a Poisson specification, but the negative binomial standard errors are notably larger than
the Poisson standard errors, even though the latter are already adjusted
for overdispersion.
There are two potential problems with the unconditional negative
binomial method. First, since there is a potential incidental parameters
problem, it is questionable whether the coefficient estimates are consistent. As yet, there is no proof of this one way or the other. Second, in the
case of large sample sizes, it may be computationally impractical to estimate coefficients for large numbers of dummy variables. Greene ~2001!
has shown that the computational problem can be readily overcome for
this and many other nonlinear fixed-effects models, although conventional software would have to be modified to implement his methods.
To investigate the performance of the unconditional negative
binomial estimator and the fixed-effects Poisson estimator, we generated
simulated data under the following model. For 100 individuals ~i 5
1, . . . ,100! and two time periods ~t 5 1, 2!, let yit have a negative binomial
distribution with conditional mean m it and overdispersion parameter l
~constant over individuals and time!. Assume that yi1 and yi2 are independent, conditional on m it . Restricting the panel to only two time periods
produces conditions most likely to yield evidence of bias due to the incidental parameters problem. Using samples of only 100 cases facilitates
the use of conventional software to estimate the unconditional models ~by
including 99 dummies!.
The conditional mean is specified as
m it 5 h exp~ bx it 1 gz i !,
where x it and z i have standard normal distributions with correlation r.
The variable z i will be treated as unobserved. It can be interpreted as representing all the stable, unobserved characteristics of individual i that have
some effect on yit . Conditional on z i , the observed variables x i1 and x i2
are uncorrelated. Unconditionally, their correlation is r 2 .
As a baseline model, we set b 5 1, g 5 1, l 5 1, and r 5 0. For
these parameter values, we generated data for 500 samples, each of size
100. ~With two observations per case, the working sample size was 200.!
For each sample, we estimated b using a conventional negative binomial
6

Estimates were obtained with SAS PROC GENMOD.

257

NEGATIVE BINOMIAL REGRESSION MODELS

regression program with x as the predictor, along with 99 dummy variables to capture the fixed effects. We then estimated b via a fixed-effects
Poisson regression model, with an overdispersion correction for the standard errors. ~Standard errors were multiplied by the square root of the
ratio of the Pearson chi-square goodness-of-fit statistic to its degrees of
freedom.!
This process was replicated over a range of plausible values for each
parameter, with other parameters held at their baseline values. For each set
of parameter values, Table 3 gives the mean of the coefficient estimates,
standard error ~standard deviation across the repeated samples!, root mean
squared error, and proportion of times that the nominal 95 percent confidence intervals contained the true value. For ease of comparison, the baseline model is replicated within each subpanel of Table 3. These baseline

TABLE 3
Simulation Results for Negative Binomial and Poisson Models
Negative Binomial

Poisson

b

SE

RMSE

95% CI
Coverage

NonConv.

b

SE

RMSE

95% CI
Coverage

l 5 .2
l 5 .5
l 5 1 ~base!
l 5 10
l 5 50

.978
.966
.982
.995
.996

.326
.191
.145
.063
.052

.327
.194
.146
.063
.052

.854
.854
.826
.902
.952

0
3
156
500
500

1.045
1.011
1.018
1.005
1.002

.458
.278
.202
.078
.053

.460
.278
.203
.078
.053

.724
.746
.778
.866
.928

g50
g 5 .5
g 5 1 ~base!
g 5 1.5

.966
.966
.974
.967

.124
.139
.138
.142

.129
.143
.140
.146

.846
.819
.838
.860

327
281
140
53

1.003
1.005
1.016
.999

.144
.169
.202
.281

.144
.169
.203
.281

.900
.850
.782
.640

b50
b 5 .5
b 5 1 ~base!
b 5 1.5

.008
.474
.978
1.454

.116
.124
.131
.151

.116
.126
.132
.158

.872
.850
.866
.806

1
25
144
261

.006
.490
1.014
1.513

.163
.164
.194
.279

.163
.164
.194
.279

.730
.794
.800
.726

h 51
h52
h 5 4 ~base!
h56
h58

.978
.974
.968
.972
.977

.167
.137
.139
.125
.131

.168
.139
.142
.128
.133

.836
.870
.844
.850
.840

452
353
152
60
19

1.025
1.008
1.009
1.004
1.006

.221
.189
.211
.202
.209

.222
.189
.211
.202
.209

.860
.836
.758
.752
.760

r 5 0 ~base!
r 5 .50
r 5 .75

.959
.972
.978

.140
.160
.204

.146
.162
.205

.822
.846
.872

139
38
6

.989
1.011
1.016

.197
.311
.451

.197
.311
.451

.780
.646
.588

Model

Note: SE is the standard error, RMSE is the root mean squared error, and CI is the
confidence interval.

258

ALLISON AND WATERMAN

estimates were made from new random draws in each subpanel, which
should provide some feel for the sampling variability of these estimates.
One potential problem that occurred with the negative binomial
estimator was that, for many of the samples, the estimate for the overdispersion parameter l did not converge. The number of nonconvergent samples is shown in Table 3. For the baseline model, this happened in about
20 percent of the samples. For other models, the percentage of convergent
samples ranged from zero for true l 5 50 to 100 for true l 5 .2. Nonconvergence for l did not seem to affect the estimates for b, however. For all
models with appreciable numbers of nonconvergent samples, we compared the means and standard errors of b for the convergent and nonconvergent samples. In no case was there a statistically significant difference,
so the results in Table 3 are based on all samples combined.
The general conclusions to be drawn from Table 3 are these:
• There is little evidence for incidental parameters bias. Both the negative binomial and Poisson estimates appear to be approximately unbiased under all conditions, although the negative binomial estimates are
always a bit too low.
• Root mean squared errors are appreciably lower for the negative binomial
estimator, except when l 5 50 when the negative binomial distribution
is very close to a Poisson distribution.
• Both estimators have confidence intervals that are too small, yielding
coverage rates that are often considerably lower than the nominal 95
percent level. The Poisson estimator is much worse in this regard, especially for some of the more extreme parameter values. Although not
obvious from the table, these reduced coverage rates stem from standard error estimates that are generally too small.
Now for the details. Variation in l is crucial for comparing the negative binomial with the Poisson because it controls the degree of overdispersion. More specifically, as l r `, the negative binomial converges to
the Poisson. Interestingly, both estimators do better in both RMSE and CI
coverage when l is large rather than small, although the degradation in
performance with decreasing l is more rapid for the Poisson estimator.
The parameter g controls the variance of the stable, unobserved
heterogeneity. The performance of the negative binomial estimator is
hardly affected at all by changes in g. But for the Poisson, increases in g
produce both substantial increases in RMSE and major decreases in CI
coverage. Variations in the true value of b also show little impact on the

NEGATIVE BINOMIAL REGRESSION MODELS

259

performance of the negative binomial estimator. For the Poisson estimator, the CI coverage remains fairly stable with variations in b, but there is
some evidence for an increase in the RMSE as b gets larger.
The parameter h is a scale factor that affects both the mean and
variance of the counts. For these models, h 5 1 produces a mean of about
3.8 while h 5 8 yields a mean of 23. This is potentially important because
when the mean is small, large proportions of the sample will have a count
of 0 and it becomes increasingly difficult to discriminate between a Poisson distribution and a negative binomial distribution. In Table 3, we see
that for h 5 1, the Poisson estimator actually does a little better than the
negative binomial estimator in CI coverage, although its RMSE is still
about 30 percent larger. As h gets larger, the coverage rate for the Poisson
estimator deteriorates, while remaining stable for the negative binomial
estimator.
Finally, we examine the impact of r, the correlation between the
observed variable x and the source of unobserved heterogeneity. When
r 5 0, as with all the models examined thus far, we satisfy the assumptions of a random effects model and could, presumably, do better using a
random-effects negative binomial or Poisson estimator. When r Þ 0,
random-effects estimators are likely to be biased, while fixed-effects estimators should remove that bias. Table 3 shows that both the negative
binomial and Poisson estimators do a good job of avoiding bias in the
estimate of b. However, with increasing r, the performance of the negative binomial estimator remains stable, while the Poisson estimator deteriorates substantially in both RMSE and CI coverage.
In sum, the message of Table 3 is that, under the specified model,
the unconditional fixed-effects negative binomial estimator is virtually
always a better choice than the fixed-effects Poisson estimator. But it is
still troubling that the negative binomial estimator is accompanied by
underestimates of the standard errors, leading to insufficient coverage of
confidence intervals. It is natural to ask whether there is some way to
adjust the standard errors upward. Table 4 shows the consequences of multiplying the standard errors by the square root of the ratio of the deviance
to its degrees of freedom,7 where the deviance is defined as
D5

(( $y
i

7

it

log~ yit 0m it ! 2 ~ yit 1 l! log@~ yit 1 l!0~ m it 1 l!#%+ ~14!

t

With SAS PROC GENMOD, this correction can be implemented with the
DSCALE option on the MODEL statement.

260

ALLISON AND WATERMAN

TABLE 4
Confidence Interval Coverage for Negative Binomial Model with Deviance
Overdispersion Correction.
95% CI
Coverage

Model
l 5 .2
l 5 .5
l 5 1 ~baseline!
l 5 10
l 5 50
g50
g 5 .5
g 5 1 ~baseline!
g 5 1.5

.982
.972
.956
.956
.956
.966
.956
.960
.952

Model

95% CI
Coverage

b50
b 5 .5
b 5 1 ~baseline!
b 5 1.5
h 51
h52
h 5 4 ~baseline!
h56
h58
r 5 0 ~baseline!
r 5 .50
r 5 .75

.960
.972
.948
.940
.954
.964
.956
.968
.952
.962
.964
.950

With this correction, confidence intervals have close to their nominal
coverage for all parameter values considered in the simulation. Somewhat surprisingly, standard error correction using the Pearson chi-square
goodness-of-fit statistic did not produce any noticeable improvement over
the conventional model-based standard error estimates ~results not
shown!. Also, use of the deviance-based correction did not improve
the confidence interval coverage for the Poisson estimator.
6. AN APPROXIMATE CONDITIONAL ESTIMATOR
Previously we remarked that conditional inference is not feasible for the
NB2 model ~with event counts independent over time for each individual!
because there is no complete, sufficient statistic for the incidental parameters that is a function of the data alone. However, Waterman and Lindsay
~1996a!, following the work of Small and McLeish ~1989!, have introduced an approximate method that mimics the beneficial properties of
conditional inference, even in situations where a straightforward conditioning approach fails. This methodology is termed the projected score
method.
In conventional maximum likelihood estimation, the log-likelihood
is differentiated to produce the score function. This function is then set

261

NEGATIVE BINOMIAL REGRESSION MODELS

equal to zero, and the solutions to this equation are the MLE’s. The projected score method brings the score function itself to the center of attention, and engineers a version of the score function that has properties
equivalent to the conditional score function if it existed; the desirable property is that among all estimating functions that are insensitive to the incidental parameters, it provides the maximal information.
Here are some details of the method. Let b be a vector of parameters of interest and let d be a vector of nuisance ~incidental! parameters.
Let U0 ~ b, d! be the conventional score function—that is, the first derivative of the log-likelihood function with respect to b. Let U` ~ b, d! denote
the optimal estimating function, which is defined as follows. We restrict
attention to all square, integrable functions g~ b, d! that satisfy the strong
unbiasedness condition,
E $g~ b0 , d0 !% 5 0,
for all true values of d, and for any values of b0 and d0 + This condition
implies that the estimating function is insensitive to the values of the
nuisance parameters, which is what we desire in a conditional method.
Among functions that satisfy this condition, the optimal estimating equation is the one whose solution has lowest asymptotic variance. This function exists whenever certain regularity conditions are satisfied ~Waterman
and Lindsay 1996a!. When a complete sufficient statistic exists, this optimal estimating function is identical to the score function for the conditional likelihood.
It can be shown ~Waterman and Lindsay 1996a! that the optimal
estimating function U` can be expressed as an infinite series. Consider a
single individual i with nuisance parameters di . Define Va 5 f ~a!0f where
f is the density function and f ~a! is the ath derivative of f with respect to
di . Then, we have for individual i
`

U` ~ b, d! 5 U0 ~ b, d! 2

(r

a51

a Va ,

where the ra are coefficients that depend on the parameters but not the
data.
We approximate U by the first r terms of this series:
r

Ur ~ b, d! 5 U0 ~ b, d! 2

(r

a51

a Va

262

ALLISON AND WATERMAN

Clearly one could construct an entire sequence of approximations
to the optimal estimating function, but the hope is that the first approximation, denoted as the U2 estimating function, is close enough for practical purposes. Waterman and Lindsay ~1996b! show a number of examples
for which this is the case. The way in which these approximate score functions are engineered to be close to the optimal one is identical to the way a
least squares line is engineered to be close to the data. That is, a regression approach is used to obtain estimated values of ra , but here the objects
of interest are functions rather than data points. This is achieved by taking
a set of derivatives of the score functions and their cross products and
then finding expectations, so that the mathematical operations are differentiation and expectation. The effort in accomplishing this is minimized
by using symbolic software, such as Mathematica or Maple, which can
derive the functions with relatively modest input from the analyst. Once
the projected score function has been obtained, the ML solutions can be
obtained using standard software packages.
Using the U2 approximation, we applied the projected score method
to the NB2 model, which was the basis for the simulation study of the
previous section. ~Mathematica and R programs for accomplishing this
are available from the authors.! Simulation results are displayed in Table 5.
Comparing the projected score estimates in Table 5 with the unconditional estimates in Tables 3 and 4, we find noticeably less bias in the
projected score estimates for every condition. On the other hand, the standard errors for the projected score estimates are somewhat larger than those
for the unconditional estimates in every case but one. Combining these
results into the root mean squared errors, we find that the unconditional
method does better in 13 out of the 21 conditions. With respect to confidence interval coverage, the projected score method is always appreciably better than the unconditional method using the uncorrected standard
errors ~Table 3!. But when the unconditional estimates are corrected by
the deviance ~Table 4!, the resulting confidence interval coverage is always
closer to the nominal level than the coverage of the projected score method.
In sum, it does not appear that the projected score method based on
the U2 approximation offers any substantial advantage over the unconditional method with corrected standard errors, at least with respect to estimating b, the regression coefficients. However, the projected score method
was much better at estimating l, the overdispersion parameter. The number of convergence failures was far lower using the projected score method.
Furthermore, if we restrict our attention to samples in which the estimate

263

NEGATIVE BINOMIAL REGRESSION MODELS

TABLE 5
Simulation Results for Projected Score Method
Projected Score Negative Binomial
b

SE

RMSE

95% CI
Coverage

NonConvg.

l 5 .2
l 5 .5
l 5 1 ~baseline!
l 5 10
l 5 50

.994
.993
.988
1.002
1.001

.336
.211
.139
.069
.053

.336
.211
.139
.069
.053

.929
.916
.934
.919
.933

22
7
1
7
65

g50
g 5 .5
g 5 1 ~baseline!
g 5 1.5

.995
.997
.996
1.003

.136
.141
.140
.143

.136
.141
.140
.143

.932
.924
.944
.927

0
0
0
4

b50
b 5 .5
b 5 1 ~baseline!
b 5 1.5

.005
.504
1.004
1.493

.125
.133
.140
.155

.125
.133
.140
.155

.940
.936
.936
.934

0
1
0
2

h 51
h52
h 5 4 ~baseline!
h56
h58

1.004
1.008
.989
1.000
1.002

.178
.164
.141
.136
.132

.178
.164
.142
.136
.132

.930
.932
.920
.914
.934

0
1
0
1
0

r 5 0 ~baseline!
r 5 .50
r 5 .75

.993
.996
1.007

.140
.141
.136

.140
.141
.136

.924
.920
.948

0
0
0

Model

of l converged, the unconditional estimates of l had substantially greater
upward bias than the projected score estimates ~not shown in the tables!.
In principle, the projected score method could be improved by using more
terms in the approximation.
7. CONCLUSION
The negative binomial model of Hausman, Hall, and Griliches ~1984! and
its associated conditional likelihood estimator does not accomplish what
is usually desired in a fixed-effects method, the control of all stable covari-

264

ALLISON AND WATERMAN

ates. That is because the model is based on a regression decomposition of
the overdispersion parameter rather than the usual regression decomposition of the mean. Symptomatic of the problem is that programs that implement the conditional estimator have no difficulty estimating an intercept
or coefficients for time-invariant covariates.
A good alternative is to do conventional negative binomial regression with direct estimation of the fixed effects rather than conditioning
them out of the likelihood. Greene ~2001! has demonstrated the computational feasibility of this approach, even with large sample sizes. Simulation results strongly suggest that this estimation method does not suffer
from incidental parameters bias, and has much better sampling properties
than the fixed-effects Poisson estimator. Bias in standard error estimates
can be virtually eliminated by using a correction factor based on the
deviance.
The approximate conditional score method is another attractive
alternative. The approximation used here showed slightly less bias in the
coefficient estimates but slightly more sampling variability than the unconditional estimator. This performance could be improved still further by
using a higher-order approximation. Furthermore, estimation of the overdispersion parameter was much better with the approximate conditional
method than with the unconditional method.
REFERENCES
Allison, Paul D. 1996. “Fixed Effects Partial Likelihood for Repeated Events.” Sociological Methods and Research 25:207–22.
Cameron, A. Colin, and Pravin K. Trivedi. 1998. Regression Analysis of Count Data.
Cambridge, England: Cambridge University Press.
Chamberlain, Gary A. 1980. “Analysis of Covariance with Qualitative Data.” Review
of Economic Studies 47:225–38.
Guo, Guang. 1996. “Negative Multinomial Regression Models for Clustered Event
Counts.” Pp. 113–32 in Sociological Methodology 1996, edited by Adrian E.
Raftery. Washington, DC: American Sociological Association.
Greene, William. 2001. “Estimating Econometric Models with Fixed Effects.” Unpublished manuscript, available at http:00www.stern.nyu.edu0;wgreene.
Hausman, Jerry, Bronwyn H. Hall, and Zvi Griliches. 1984. “Econometric Models for
Count Data with an Application to the Patents–R&D Relationship.” Econometrica
52:909–38.
Hsiao, C. 1986. Analysis of Panel Data. Cambridge, England: Cambridge University
Press.
Johnson, Norman L., and Samuel Kotz. 1969. Discrete Distributions. New York: Wiley.

NEGATIVE BINOMIAL REGRESSION MODELS

265

Kalbfleisch, John D., and David A. Sprott. 1970. “Applications of Likelihood Methods to Models Involving Large Numbers of Parameters” ~with discussion!. Journal
of the Royal Statistical Society, Ser. B, 32:175–208.
Mundlak, Y. 1978. “On the Pooling of Time Series and Cross Section Data.” Econometrica 46:69–85.
Palmgren, Juni. 1981. “The Fisher Information Matrix for Log-Linear Models Arguing Conditionally in the Observed Explanatory Variables.” Biometrika 68:563– 66.
Small, C. G., and D. L. McLeish. 1989. “ Projection as a Method for Increasing Sensitivity and Eliminating Nuisance Parameters.” Biometrika 76:693–703.
Waterman, Richard P., and Bruce G. Lindsay. 1996a. “ Projected Score Methods for
Approximating Conditional Scores.” Biometrika 83:1–13.
———. 1996b. “A Simple and Accurate Method for Approximate Conditional Inference Applied to Exponential Family Models.” Journal of the Royal Statistical Society, Ser. B, 58:177–88.
Yamaguchi, Kazuo. 1986. “Alternative Approaches to Unobserved Heterogeneity
in the Analysis of Repeated Events.” Pp. 213– 49 in Sociological Methodology
1986, edited by Nancy Brandon Tuma. Washington, DC: American Sociological
Association.

