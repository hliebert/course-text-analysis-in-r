A Method of Simulated Moments for Estimation of Discrete Response Models Without
Numerical Integration
Author(s): Daniel McFadden
Source: Econometrica, Vol. 57, No. 5 (Sep., 1989), pp. 995-1026
Published by: The Econometric Society
Stable URL: https://www.jstor.org/stable/1913621
Accessed: 06-03-2019 15:04 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

The Econometric Society is collaborating with JSTOR to digitize, preserve and extend access
to Econometrica

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

Econometrica, Vol. 57, No. 5 (September, 1989), 995-1026

A METHOD OF SIMULATED MOMENTS FOR ESTIMATION OF
DISCRETE RESPONSE MODELS WITHOUT

NUMERICAL INTEGRATION
BY DANIEL MCFADDEN1

This paper proposes a simple modification of a conventional method of moments
estimator for a discrete response model, replacing response probabilities that require
numerical integration with estimators obtained by Monte Carlo simulation. This method of
simulated moments (MSM) does not require precise estimates of these probabilities for
consistency and asymptotic normality, relying instead on the law of large numbers
operating across observations to control simulation error, and hence can use simulations of
practical size. The method is useful for models such as high-dimensional multinomial
probit (MNP), where computation has restricted applications.
KEYwoRDs: Method of moments, simulation, multinomial probit, discrete response.

1. INTRODUCTION

A CLASSICAL METHOD of moments estimator Omm of an unknown parameter

vector O* minimizes the (generalized) distance from zero of empirical moments

E [ Instrument Observed [Expected

observations l Vector Response Response at Omm
For some problems, the expected response function may be difficult to express
analytically or to compute, but relatively easy to simulate. When this function is
replaced by an unbiased simulator such that the simulation errors are independent across observations and sufficiently regular in 0, the variance introduced by
simulation will be controlled by the law of large numbers operating across
observations, making it unnecessary to consistently estimate each expected re-

sponse. This is the basis for the estimation method developed in this paper, the
method of simulated moments (MSM).2
This paper focuses on application of MSM to discrete response models,
particularly the multinomial probit (MNP) model. However, the method is more
general and can be applied to most moment estimation problems. In a related
paper, Pakes and Pollard (1989) have independently proposed minimum distance
'This research grows out of joint work with Kenneth Train on the estimation of choice models
containing variables measured with error. I have particularly benefited from discussions with Ariel
Pakes and David Pollard, who pointed out a lacuna in my original analysis of this problem. I have
shortened the proof of the main theorem by adapting arguments from Pakes and Pollard's independent investigation of the asymptotic behavior of simulation experiments. I have also benefited from
suggestions made by Chunrung Ai, Moshe Ben-Akiva, Chris Cavanagh, Vassilis Hajivassiliou, Robert
Hall, James Heckman, Hidehiko Ichimura, Charles Manski, Dan Nelson, Peter Phillips, and Paul
Ruud. This research was supported in part by National Science Foundation Grant No. SES-8606349.

2 The idea of simulating response probabilities from an underlying latent variable model, gene
ing the response probabilities by stochastic integration, is standard in the area of computer
simulation; see Hammersley and Handscomb (1964), Fishman (1973), and Lerman and Manski
(1981). This literature has concentrated on simulating the response probabilities to a level of accuracy
that enables their use in standard maximum likelihood procedures.
995

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

996

DANIEL

MCFADDEN

estimators using simulation, and have established their statistical properties using
combinatorial empirical process methods. Most of the statistical results in this
paper could also be obtained by application of their methods.
Section 2 of this paper gives definitions and notation for discrete response
models. Section 3 defines the MSM estimator and previews the conditions under

which it is consistent asymptotically normal (CAN). Section 4 discusses issues of
computation and statistical efficiency. Sections 5-7, respectively, discuss applications of the method to discrete panel data with autoregressive errors, to discrete
response models with measurement errors in explanatory variables, and to
nonnormal discrete response problems. Section 8 contains the theorem and
lemmas referred to in the text, and their proofs.
2. DEFINITIONS AND NOTATION

Define C= {1,..., m} to be a set of mutually exclusive and exhaustive
alternatives. A latent variable model for response from C is defined by

(1) ui = axi is C,
where a is a row vector of individual weights distributed randomly in the

population, xi is a column vector of measured attributes of alternative i,
response i is observed if ui > u; for j E C (with zero probability of ties). Let
denote a response indicator, equal to one for the observed response, zero
otherwise.

Assume a = a(, 71) is a smooth parametric function of a random vector 7,

with unknown parameter vector O taking true value 0*. Let g(,q) denote the

density of -. Let P(9) and S(9) denote the mean and covariance matrix o

a(9, -q). In applications, it is often convenient to work with a Cholesky factor
S: let r(o) be an upper triangular matrix satisfying rr =Q.

Define Xc = (xl,..., xrn) and uc = (ul,..., urn). The response probability
alternative i, Pc(ij9, Xc), equals the probability of drawing a latent vecto
with u1 > uj for j E C, given Xc. Define

UC-i = (U1 - Ui*,... ui1 - Ui, Ui.1 Ui., Um Ui)r
XC-i-=(Xi1-Xi,* Xi-i1 Xi, Xi1 Xi,..., Xm Xi)-

Then uc-i has a multivariate density gu(uc_jIO, Xc) with m

covariance matrix Xc_ -i2Xc-i, induced by the transformation uc_i =
a(0, ) Xc-i of the random vector q. The response probability Pc(i IO, Xc) equals
the nonpositive orthant probability of u C_,

(2) PC(ii0, Xc) = 1O(UC-i0)gU(UC-i, Xc) duc_j

= fi(a(0 Xq)Xc-i _ O)g(-q) d-,
where 1(Q) denotes an indicator function for the event Q.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MONENTS 997

When a is multivariate normal, one obtains the MNP model. For this model, a
can be written
(3) a = a(0vq)f3(0)?+qF(0),

with q a row vector of independent standard nor
In economic applications, the latent variables ui
of utility or profit, and Pc(ij0, Xc) is the choice
optimizing agents. The attributes xi are function
the alternatives and of the decision-makers, with
mation to a general economic function of observed characteristics and of the

deep parameter 0. Alternative-specific dummy variables may be included in
the associated components of a can be interpreted as alternative-specific additive
disturbances.

Let n = 1,..., N index a random sample from the population, yielding obser-

vations (dCw Xcn) with dCn = (dln,..*C dmn) and XCn = (Xln*,.** Xmn). The

likelihood of the sample is
N

L(@) = E E din n Pc(iI0, XCn)
n=1 ieC

The associated score is
N

(4) aL(0)/a0= E E Win [ din-PC ('I XCn
n=1 irC

where

(5) Win = d ln Pc(iI0, XCn)/ld0
Equation (4) is derived using the identity

0 dP aC(ilo, XC)/a E [a ln Pc(iiO, Xc)/1d] Pc(iiO, Xc).
ieC

The

i

C

primary

im

the MNP model is computation of the (m - 1) dimensional orthant probabilities

for uc_i to obtain Pc(i 10, Xc). Direct numerical integration is practical for
m < 4 using a method of Owen (1956), modified by Hausman and Wise (1978), or
expansions due to Dutt (1976). Otherwise, unless a has a factor-analytic covariance structure with less than four factors, it is usually impractical to carry out the
large number of numerical integrations required to iteratively solve (4). Lerman

and Manski (1981) suggest a Monte Carlo procedure for estimating P(i 1, Xc)
that can be applied to MNP models with large m, but find that it requires an
impractical number of Monte Carlo draws to estimate small probabilities and

their derivatives with acceptable precision. Daganzo (1980) has developed approximate maximum likelihood estimators for MNP using a normal approximation to maxima of normal variates suggested by Clark (1961). This approach has
the drawbacks that the accuracy of the approximation cannot be refined with

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

998

DANIEL

MCFADDEN

increasing sample size, and the method can be inaccurate when components have
unequal variances; see Horowitz, Sparmonn, and Daganzo (1981).
3. THE METHOD OF SIMULATED MOMENTS

The conventional method of moments estimator of a k x 1 parameter vector 0

(with domain 9) in the discrete response model Pc(iji, Xc) satisfies

(6) M = argmin0 (d - P(0))'W'W(d - P(0)),

where d - P(0) denotes the mN x 1 vector of residuals din - PC(I 0, XCn) stack
by observation and by alternative within observation, and where W is a K x mN

array of instruments of rank K > k. The instruments may depend on 0, but are

evaluated at some fixed 00 in forming first-order conditions for solution of (6).

The instrument array (5), evaluated at 0* (or at a consistent estimator of 9*),

yields a method of moments estimator asymptotically equivalent to the maximum

likelihood estimator for 0, and hence asymptotically efficient. If computation
makes exact calculation of the efficient instruments impractical, (5) nevertheless
provides a template for instruments that with relatively crude approximations to

P and its mN x k array of derivatives Po will yield moderately efficient estima
tors. Computation of instruments is discussed further in Section 4. In the

remainder of this section, I will assume W is a given fixed instrument array.

Under mild regularity assumptions, sufficient conditions for classical method
of moments estimation to be CAN are the following:
(i) The instruments are asymptotically correlated with the score; i.e., the array

R = lim N-lWP0,(0*) is of maximum rank.
(ii) The conditional expectation of the residuals d - P(0), given the instruments,
is zero if and only if 0 = 0*.

The method of simulated moments (MSM) avoids the computation of P(0)
required for (6), replacing it with a simulator f(0) that is (asymptotically)
conditionally unbiased, given W and d, independent across observations, and

"well behaved" in 0. An example is the simple frequency simulator calculated
from the latent variable model (1) by independently drawing, for each observa-

tion, one or more vectors q from the density g(q), and then for any trial 0
calculating Uin = a(0, )Xin and counting the frequency with which the Uin f
each alternative is maximized. The MSM estimator is given by any argument Osm
satisfying3

(7) (d-f (Osm))'W'W(d-d (Osm))
< inf (d-f(0))'W'W(d-f(0)) + 0(1)
This definition assures the existence of a MSM estimator even if the infimum
cannot be attained.

3A sequence of numbers aN is 0(1) if it is bounded in magnitude by a convergent sequence, and i
o(1) if it converges to zero. A sequence of random variables Zn is Op(l) if, given E > 0, there exists 8

such that Prob(I ZZN I> 8) < e for all N. The sequence is o(1) if ZN converges in probability to ze

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 999

Sufficient conditions for the MSM estimator to be CAN are given formally in

Theorem 1. They involve the same regularity assumptions and conditions on
instruments as classical method of moments estimators, and in addition place

two critical restrictions on the simulator f (O):

(iii) The simulation bias B(O) = N- 1/2W(Ef(O) - P(O)), where the expectation
is conditioned on W and d, is either zero, or else satisfies

(8) sup IB(O) I= o(1).
(iv) The simulation residual process '(O) = N -1/2W(f(O) -Ef(O)) is uniformly stochastically bounded and equicontinuous in 0; i.e.,

(9) sup I (0) I = OP(1),
(10) sup I 00) - 0P) I = op(1),
GeAN

where, for a given 8 > 0, AN= {NIN1N2IO- *I 3).

If f(O) is an unbiased simulator of P(O) for all 0, and the random numbers

used to compute f(O) are independent of the observed responses and of any
simulation used in the construction of the instrument array, then (iii) is satisfied.
The simulation residuals t(O) are by construction the normalized sum over
observations of independent identically distributed terms that are independent of

d and uniformly bounded, with E('(O) I W) = 0 for each 0. Then D(O) is an
empirical process in 0 that by a standard central limit theorem is pointwise
asymptotically normal. Elementary arguments (Lemma 4) establish that if f (6) is
smooth for 0 in a compact domain, then (iv) holds. However, (iv) can also be
satisfied by simulators that have "well-behaved" discontinuities (Lemma 8), such
as the simple frequency simulator. To satisfy (iv), a simulator must avoid
"chatter" as 0 varies; this will generally require that the Monte Carlo random
numbers used to construct f(0) not be redrawn when 0 is changed.
4. COMPUTATIONAL ISSUES AND STATISTICAL EFFICIENCY

Practical use of the MSM estimator requires that the Monte Carlo simulation

of the probabilities and their derivatives be practical and "well behaved"; that

easily calculated, moderately efficient instruments W be available; that iterative
algorithms to compute the estimators be fairly stable and efficient; and that
estimators for the asymptotic covariance matrix of the estimators be computable.

Simulators for the Response Probabilities

I have given the example of a simple frequency simulator f(0) for the discrete
response model generated from the latent variable model (1): Count the fre-

quency fM(i 9, XCn) with which component i of UCn = a(9, j)XCn is largest,
where the q are one or more Monte Carlo random vectors from the density g('Q),
independent across observations and fixed for the duration of the analysis. This

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1000

DANIEL

MCFADDEN

simulator is unbiased for all 9, but has discontinuities at values of 9 where there
are ties for the maximum component of uCn, For the MNP model, the frequency
simulator is computed economically from (3) by drawing standard normal vectors

Xj and calculating UCn = (/3(9) + ,qr(o))XCn.

It is also possible to construct a smooth unbiased simulator f(9). This simplifies

the iterative computation of the estimator, and its statistical analysis. Let

-y(uc-i) denote a density chosen for the simulation that has the nonpos
orthant as its support. Then (2) can be rewritten as

(11) Pc(ilfR,Xc)-- h(uc_j, , XC_j)y(uc_j)duc_j,
where h(uc-, 9, Xc-X) = gu(uc_1IG, Xc)/y(uc_j). Average h(uc-1, 9, Xc_i) for
an observation, using one or more Monte Carlo draws from y(uc-i) that are
taken independently across observations and fixed for different 9. This gives a

smooth positive unbiased estimator of Pc(i 9, Xc), provided -y is chosen so that
h is dominated by a function H independent of 9 with JHyduc-i finite. The
density -y can be chosen to facilitate Monte Carlo draws and reduce simulation
variance. For example, if y is independent exponential in each component, then
random variates from this distribution can be calculated from logarithms of

uniform (0,1) random numbers. Choices of y that make h flatter can reduce
simulation error, as in Monte Carlo importance sampling. For MNP,

h (uc_j, O, Xc-i)

= n(uc- i- (O) Xc-i5xc,*- r(oyr(o) Xc- J1/7(Uc- J)
where n (v, A) denotes a multivariate normal density centered at zero with

covariance matrix A. When y is exponential, this h is uniformly bounded.
The estimation of the asymptotic covariance matrix of the MSM estimator, as

well as approximation of efficient instruments, requires simulation of derivatives

of the response probabilities with respect to 9. From (11), these derivatives can
be written

(12) aPc(ijO, Xc)1O= |hO(uc-ij #,Xc_j-iy(uc_j) duc_j5
where ho denotes the vector of derivatives of h with respect to 9. Then, a smooth
unbiased simulator of (12) can be constructed in the same manner as was done
for (11). Lemma 10 details this construction for MNP.
A potential drawback of smooth simulators based on (11) is that they are not
constrained to sum up to one for i E C. An alternative class of kernel-smoothed
frequency simulators satisfy summing-up, but are only asymptotically unbiased.
The idea underlying these simulators is that (2) can be approximated by an
integral

(13) J3c(iI9, Xc) = JK(a(9, 'q)Xcj/bN)g(q) dq,

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1001

where K(uc-,/bN) is a smooth approximation that approaches the indicator

function l(uc_j <0) as bN -> 0. Let Kj(yj,..., Yin-) K(yc-i). I require that
Y2 ecKi(uc/bN) 1. The multinomial logit function K i (yc) = eY/Ej E c eYi is
one example in this class. Smooth simulators satisfying summing-up for i E C are

obtained by averaging K i (a(6, 7q)XC/bN) over a common Monte Carlo sample
from g(q).
Kernel-smoothed simulators can be derived from a perturbation of the latent
variable model (1),

(14) uc = uc + vcbN,

where vc is a vector whose components are independently distr
distribution function 'k, and bN is a scalar chosen for the simulation. This
formulation can be interpreted as a mixture of (1) and a contaminating distribu-

tion. Assume I has a finite moment generating function ju(t) for t in a
neighborhood of zero. Define the smooth function

(15) Ki(Yi,*, Y)=f ( I(Yi -Yj + v)) (v) dv.
This kernel will be most practical when I is chosen so that K i has an easily
calculated closed form. The response probability implied by (14), obtained by

first conditioning on uc and integrating out vc, coincides with the approximatio
(13) when the smoothing function (15) is used. This simulator is nonnegative, and
is strictly positive if the support of I is the real line. Lemma 3 shows that a

sufficient condition for it to be asymptotically unbiased is that bN satisfy
NE` "'2bN -* 0 for some - > 0. If the simulators for all i E C are constructed from
common Monte Carlo draws, then they satisfy summing-up. Choosing * to be
type I extreme value distributed yields the multinomial logit form, and (13) is a
multivariate normal mixture of logits. This model, with the mixture interpreted as

the result of taste variations in the population, has been of independent interest
as a discrete choice model; see Westin (1974) and McFadden (1984).

A polynomial kernel such as I(v) = [6 + 5v + (2 - IvI)v3]/12 for lvi <

computationally economical, yielding a closed form for K i. One advantage of this
kernel is that it limits the number of alternatives for which calculations must be

done. If an observation has every component of uc-i greater than 2bN in
magnitude, then K i(uc/bN) coincides with l(uc-i < 0) and the kernel-smoothed
frequency simulator coincides with the simple frequency simulator. The probabil-

ity of the converse is of the order O(bN). Then, in a sample of size N with r
Monte Carlo draws per observation, the expected number of alternatives for

which further calculation is required to obtain the simulator and corresponding

instruments is bounded by (r + 1)N + mrNO(bN) < (r + 1)N + o(mrN-E-1/2).
This makes the calculation practical even if the number of alternatives is large.
For MNP, a variant due to Stern (1987) of the kernel-smoothed frequency
simulator is unbiased. The idea is that the normal latent variable model can be

decomposed into a mixture of two normal vectors, one of which is scaled

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1002 DANIEL MCFADDEN

standard normal. Thus, it is unnecessary to contaminate the model to achieve

mixing, permitting an unbiased simulator. Rewrite (1) as uc --kUC + vbN, with v

standard normal vector independent of ic N(f3Xc, A'A), where A is upper
triangular and A'A XcF'rXC - bNI. This can be done if bN is small enough so
that XcrFrXc - bNI is positive definite. It is adequate for the asymptotic
properties of MSM using this simulator that bN be constant in open neighborhoods of r. Then, bN can be set for each observation and estimation iteration by
calculating a Cholesky factor of xcrFrXc at the trial r and choosing bN less
than the smallest diagonal element of this factor. As in (14), conditioning on uc,

Pc(il0, Xc) = Kj6((lXc + tqA)1bN)g(7n) d7/,
(16)

1Ki(Y1, ... Ym)J= |(H (i(Yi-Yj + v)f r'(v) dv,
with g the multivariate standard normal density and P the univariate standard

normal distribution. An average of K i in (16) over Monte Carlo draws from g
yields an unbiased positive smooth Stern frequency simulator. Adding-up holds
for an observation if common draws are used for all i E C.
For MNP, construction of economical simulators is aided by the use of
spherical transformations. The expression (11), and the specializations of (12)
given in Lemma 10, involve simulation of integrals of the generic form
m

Q L H0(11Uj)n(u + L, A) du,
where EY2%k1
is 0, or
1, or 2,=U=C-i
,u 3Xc-i, and A =CXc'_i2Xc_. Make the transfor_=
mation r = (X71uj2)1/2 and sj = uj/r. Define
C(n, a, b) = rne-(rb/a)2a/2dr;
0

this is proportional to a parabolic cylinder function (Spanier and Oldham
(1987)), and satisfies the recursion

C(O, a, b) = (2gr/a ) 1/2 (b/a1/2),
(17) C(1, a, b) = C(O, a, b)b/a + eb2/2a/a,

C(n, a,b) =C(n-l, a, b)bla +C(n-2, a, b)(n-l)la (n > 2).
Then, a cylinder simulator is defined from the form

(18) Q=coEscC( Ek1+m-1am b X)(H SJk)
where s is distributed uniformly on the intersection of the unit sphere and the

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1003

nonnegative orthant, and

a = s C-iQXC-i) SI
b = -_fXC_i(XXciS2Xci)S5
CO = (27T )l/22-3m/2101-1/2r(m/2) -

ci=exp(- [fiX(X'QSX)-1X1fi'
- (f/X( X'QX) - 1s)/s'( X'QX) -15]/2),

with X= Xc-1, and co independent of X and s. To generate uniform draws fr
the distribution of s, draw a standard normal random vector u, and take
/lm \1/2

sj = juyl u2
/j=l

Then, (18) is simulated by drawing one or more s, and for each s using the
recursion (17) to calculate C. A further refinement is to use control variates for
C; Moran (1984) suggests several. Peter Phillips and Vasillis Hajivassiliou suggested the use of spherical transformations for this problem, and Dan Nelson
developed many of the details.
The spherical transformation can also be used to calculate a conditional

chi-square frequency simulator for MNP that is economical, unbiased, and smooth.

Let s be a uniform draw from the unit sphere in R K, and let X2 be an
independent random variable with a chi-square distribution with K degrees of

freedom, denoted HK(X2). Then, the latent variable model for MNP can be

written uc = (/ + xsr)Xc. Given s, an easy computation yields a partitio
[0, + xo] into intervals [X2 Xj+1, j = 0,..., m, on which each of the compo
of uC is maximum. (Some of the intervals may be degenerate.) The probab
response i, given s, is Pc(iIO, Xc, s) = HK(X2+1) - HK(X2), where j is the
ascending rank of sFxi in the vector sFXc. The Xi are smooth in 9 for almost all

Xc, so Pc(ijI, Xc, s) is also smooth. The simulator is an average of the

Pc(i 9, Xc, s) for r random draws of s. An advantage of this method is that it
simultaneously provides, for all alternatives, simulators satisfying summing-up.
The accuracy of simulators for MNP that are based on spherical transforma-

tions can be improved substantially by use of antithetic variates. Deak (1980)

gives an effective procedure: For uniform draws from the unit sphere in DR K, f
draw a random basis s1,..., 5K. This can be done by drawing K standard normal
vectors and applying a Gram-Schmidt orthonormalization. Then use the 2K

vectors +sj, or the 2K(K- 1) vectors (?s' _ s j) for i < j, as directions for
simulation. To generate a denser set of antithetic points for any integer T> 1,

take each pair s' and s i with i < j and construct the directions ( s' cos 'Trt/2T ?

sisingTt/2T) for t= 1,..., T- 1. Combined with the points +_s, this gives
4(T + 1) evenly spaced points on each great circle, for a total of 2K + 2TK(K - 1)
directions.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1004 DANIEL MCFADDEN

Numerical experiments on the algorithms discussed in this section suggest that
for MNP with 5 to 20 alternatives, the conditional chi-square simulator combined

with the De'ak construction of antithetic directions is the fastest and most
accurate.4

Choice of Instruments

Consider the question of suitable instruments. The classical method of moments estimator is asymptotically efficient if and only if, except for stochastically

negligible terms, W is proportional to d ln P(9*)/ad. Since the asymptotic
efficiency of MSM relative to the classical moments estimator can be controlled
by the number of Monte Carlo draws used to simulate P(9), the issue is how to
construct W to obtain good asymptotic efficiency for MSM without excessive
computation.

Simulation of (12) based on Monte Carlo draws from the density y(u) yields
smooth unbiased estimates of the derivatives. Since the smooth simulator (11) of

Pc(i9O, Xc) is positive, the ratio of the simulators of (12) and (11) provides an
approximation to the ideal instruments d ln Pc/da. The number of draws per

observation must go to infinity with sample size if the ideal instruments are to be
estimated consistently, permitting MSM to be asymptotically efficient. However,

modestly efficient instruments can be obtained with relatively few draws. It is
essential for the asymptotic statistics of the MSM estimator that simulators of the
response probabilities and their derivatives used to construct instruments be

independent of the simulator f(9) used in the moment condition (7). For
instrument construction, use of common draws from -y to simulate the numerator

and denominator of (dPc/ad)/Pc at each observation may improve the efficiency of the instruments.
In general, starting from any K x mN array of instruments Z?, a standard

argument from nonlinear generalized least squares shows that the asymptotic

minimum variance estimator in the class using linear combinations of instru-

ments in Z0 is attained by W = Po6(9*)'Z'( ZPZ')-Z, where P6(9*) is the

mN x k array of derivatives dPc(i I9, XCn)/9d 0, evaluated at 9*, P = diag P(9*)
and

Zin = Z$n- E ZjnPC(jI 9 *, XCJ)
If Z? = d ln P(9*)/ad, then W= d ln P(9*)/ad. Approximations to 9* and to

the functions P and Po yield approximations to the minimum variance instru

ments that can be constructed from Z?.

4A program to perform these calculations, in either GAUSS or FORTRAN, is available from the
author.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1005

Iterative Estimation Methods

A practical estimation procedure is first to use relatively crude instruments,

defined independently of 9, to iterate to an initial consistent estimator 9, second
to simulate the ideal instruments using (11) and (12) evaluated at 9, and third to
carry out one or more iterations using these approximately ideal instruments.
Good candidates for crude instruments are low-order polynomials in the explanatory variables: If the model is identified, then there are always polynomials in

Xc-i that have an asymptotic correlation matrix with dPc(iO1, Xc)/Id that is
full rank. For example, in the MNP case, Xc-i and Xc-iXc-i will usually be
adequate first-round instruments for d ln Pc(i 9, Xc)/d/ and d ln Pc(i 19, Xc)/
dr; from Lemma 10, these are a superset of the ideal instruments when /3 = 0
and r consists of an identity submatrix corresponding to alternative-specific
dummy variables and a zero submatrix corresponding to the remaining variables.
In the third step when smooth simulators are being used, one Newton-Raphson

iteration from 9 achieves the maximum asymptotic efficiency attainable from the
second-round instruments.

Consider iterative algorithms for calculation of MSM estimators. When smooth
simulators are used for f (9) in (11), and the instruments W are defined indepen-

dently of 9, then estimates can be computed by Newton-Raphson iteration or a
similar second-order method applied to minimize the criterion

(19) (d-f (9))'W'W(d - f (9)).
This criterion may be irregular; in particular, kernel-smoothed frequency simula-

tors may have local flats. Then, optimization methods that use nonlocal information, such as simulated annealing, may be more reliable; see Press et al. (1986).

When a simple frequency simulator is used, (19) is piecewise constant in 9, and
nonlocal methods must be used in iteration. I have tried random search algorithms and pseudo-gradient methods that adaptively approximate slopes using

long baselines; the former have performed better. For discrete response models
that can be parameterized in terms of mean and variance, such as MNP,
convergence can be accelerated using a method due to Manski: Suppose r

simulations are made per observation, and that starting from a trial 00

direction AO has been determined. Consider (19) as a function of 00 + X AO, with

X a step size to be determined. The value Xnj at which there is a jump in (19)
from draw j and observation n is easily calculated. Then, it is practical to
enumerate the values of (19) at all the jump points Xnj and choose a global

minimum along this search direction.

Generally, iteration using smooth simulators is faster than that using frequency
simulators. However, in applications where the number of alternatives is very

large, the burden of computing f(0) or approximations to the optimal instruments for all alternatives may be excessive. In such cases, a frequency simulator

f(0) with r repetitions will be nonzero for at most r alternatives, and the
instruments need be computed only for these alternatives plus the observed one.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1006 DANIEL MCFADDEN

For example, a single Monte Carlo draw for each observation requires calculation
of the instruments only for the observed and drawn alternatives, and gives half
the efficiency of the classical method of moments estimator, no matter how large
the set of possible alternatives. Comparable reductions in computation can be
achieved using a kernel-smoothed frequency simulator with a kernel of bounded
support.

Estimators for the Asymptotic Covariance Matrix

A standard result, obtained by expansion of the first-order condition, is that
the asymptotic covariance matrix of a classical method of moments estimator is

2mm = (R) - _ (R_-)
where

R= lim N-lWP6(9*),
N- oo

Gmm= lim N1 E ( Pc(io*, XCn)WinWin. - WnW.nW
N -oo n=1 i)C

with W n- = Yi CPC((il 9*, XCn)Win The asymptotic covarian

method of simulated moments estimator has an almost identical

(20) >Ssm= (R'R) R'Gs (RtR-)
where Gsm = Gmm + Gss with
N

Gss= lim N1 - l Wi n n
n >oo n=1 i, j(=C

and Yin =Jin(9*)- PCn(I1*5 XCn). The term Gss is the contribution of the simu-

lation to the asymptotic variance.

If f(0) is the simple frequency simulator obtained by r independent Monte
Carlo draws for each observation, then Gss = r-1Gmm and 2sm = (1 + r-1)2lMmm
In this case, one draw per observation gives fifty percent of the asymptotic
efficiency of the corresponding classical method of moments estimator, and nine
draws per observation gives ninety percent relative efficiency. Use of Monte
Carlo variance reduction techniques such as antithetic variates, or use of smooth
simulators, may improve further the relative efficiency of MSM.
Consider estimation of 2sm. I establish in Lemma 9 that a consistent estimator
of Gsm is
N

(21) Gsm N E= Win(din f('I Osm XCn))(djn-f( jlOIsm XCJ))Wjn
n=1 i,je C

The matrix R = lim N-lWP0(O*) is consistently estimated by
(22) RN=1WP,

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1007

where Po is an unbiased simulator of the arr
The simulator Po must be independent of any
of W. The consistency of R continues to hold with any consistent estimator 0 in
place of 0sm
5. DISCRETE PANEL DATA WITH AUTOREGRESSIVE ERRORS

Consider longitudinal discrete response data (d,, x,") for subj
observed over t = 1,..., T periods, where dtn = +1 indicates a bin
and x is a vector of explanatory variables. This problem has 2T alternative
response patterns, large for long panels. A latent variable model that could
generate such data is
Utn = fBxtn + -tn

dtn= sign(Utn),
with Etn = (n + Vtn, (n a normal subject-specific disturbance, vtn a normal first-

order autoregressive disturbance, and (, v independent of each other and
independent across subjects. Define X2 to be the proportion of the variance in the
autoregressive error, and p the serial correlation. The probability of the observed
response is

P (dnIXn, P, A, P) = Pr ({{n, Vln, . T.n I "dtn' *sign (#Xtn + {n + Ptn) > ?}))

where dn = (dln -, dTn) and Xn = (xln,..., xTn). If Etn is stationary, with vari-

ance normalized to one, then

(23) = (1 -X2)t 10n +x((1 -P2) E P qt-j, n + Pt?I)7
where the 'qjn are independent standard normal variates.

Full maximum likelihood estimation of this model requires T-dimensional

numerical integration to evaluate P(dn XXn, 1, X, p), which is computational

impractical for T > 4. Ruud (1981) has developed practical consistent estimators

using partial likelihoods for small numbers of adjacent periods; see also
Chamberlain (1984). The MSM method, starting from initially consistent estima-

tors, offers a computationally practical method that may increase efficiency. A
simple frequency simulator or a kernel-smoothed frequency simulator with a
polynomial kernel, with a small number of repetitions, requires simulation of the

instruments for a small number of alternatives per subject, even for large T.
Hajivassiliou and McFadden (1987) have investigated another approach to this

problem which consistently simulates the score d ln P(dn IO, Xn)/d 0 for each

observation. Estimators with good relative efficiency can then be obtained by
iterating to a root of the sample score. A first method for this simulation is to use
panel data analogues of (11) and (12), with many Monte Carlo repetitions, to

estimate consistently the denominator and numerator of [dP(dn 0, Xn)/Id]/
P(dJOl, X").

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1008

DANIEL

MCFADDEN

A second acceptance/rejection method yields unbiased simulators of the score.
As in the case of the basic MSM estimator, this permits consistent estimation of

9* through the operation of the law of large numbers over observations. Consis
tent simulation of the score for each observation is not required. Let gu(u I 9, X")

denote the density of (uln,..., uTJ) induced by the model, given the density of

the disturbances. Then, the response probability and the score satisfy

P(dnIo, X") =|gu(UIo, X") du,
Qn

d In P(dnlo, Xn)/Id = f [agu(ulO, Xn)I/dO] dugP(dnio, Xn)
Qn

=|[d I ngu (ulO, Xn)IdO] gu ( ulO Xn,Qn) du
Qn

where Q n = {u sign(u) = dn }, and gu(uIO, Xn, Q n) is the conditional density of u

given Qn. The acceptance-rejection algorithm starts with a density y(u) such that
(i) it is easy to draw Monte Carlo samples from y(u), and (ii) there is a known

constant M such that M > SupQ gU(ulo' Xj)/y(u). Draw a pair of points (u, y

with u from y(u) and, independently, y from the uniform density on [0, M]. If

u E Qn and y < gu(ulI, X"), accept the variate u; otherwise, reject this pair and
draw again. The density of the accepted u is g9U(u 6, Xn, Qn); this is verified by
an application of Bayes law. Averaging a lngu(ul9, Xn)/8d over the accepted u

yields an unbiased simulator of the score. The main drawback of this method is
that many draws may be necessary to get accepted u.

MSM estimation of discrete panel data models extends readily to more general
time-series covariance structures, so long as it is practical to Cholesky-factor and
invert the covariance matrix to obtain a representation analogous to (23) for the

Etn in terms of independent normal variates, and so long as it is practical to
construct instrument arrays for the deep parameters of the problem. The MSM
estimator can also be applied to models with general state dependence, provided

the initial value problem (Heckman (1981)) can be handled. For example,
consider the model

Utn =xtn + ddt, n + (n + Vtn,

(24) d = sign(utn),
with (n a subject-specific disturbance and vtn independent across t. If the
disturbances are normal, and vtn has unit variance, then
T

(25) P(dnlXn, dOn, f ) = H (dtn(xtn + 4dti,n +
t=1

Suppose the conditional distribution of (n given xn and dOn can be assum

depend only on dOn; this is justified if xn is independent of the past history

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1009

x process. Suppose the inverse G-1(pld0n) o
tion p = G((nIdOn) is placed in a flexible p

inverse distribution. Then the response probabilities are given by the expectation

of (25) with respect to (, which can be simulated economically from G- 1. Adding

serial correlation to the disturbances vn in (24) makes (25) a T-dimensional
integral, whose simulation by MSM can be handled jointly with simulation of the
expectation with respect to (.
6. DISCRETE RESPONSE MODELS WITH MEASUREMENT ERROR

Suppose discrete response for a random sample n = 1,..., N satisfies a latent
variable model

=Un f3Zn + en

(26) d~ = H(Un),

where H maps the row vector un into m discrete categories with dn an indicato
for the observed category, and H-1(dn) the set of un yielding the observed
category. To simplify notation, assume 18 is a scalar; generalization merely
requires that the construction below be carried out component by component.

Suppose zn is not observed directly, but is related to a vector of observations
by

Xn =ZnA + {n~

where {n N(O, KI!), independent of E. We interpret the x as observations on z
measured with error, or as indicators for z. In form, this is a multiple indicator or
factor-analytic latent variable model, with A giving the factor loadings.

Suppose in the population Zn, N(p, r), independent of {n. Then the conditional distribution of z given x, suppressing subscripts, is

z - N(L + (x - 1iA)(A'FA + ) -1A'r, r - rF (A'A + *) -Air).
If the E N(O, Q2) in (26), then

u - N(ft + f(x - tA)(A'1A + *)-'Air,
2 [ Q2 + rA (A'FA + Y) 1A'r])
and the response probabilities given x are of MNP form. The MSM estimator for
the general MNP model can be adapted directly to this problem, the main
practical difficulty being calculation of the derivatives of the Cholesky factor of

the covariance matrix with respect to the deep parameters in order to calculate a
relatively efficient instrument matrix.
A number of variants of the measurement error model (26) may be encoun-

tered in applications, including variables measured with error that are common to
several alternatives or interact with alternative-specific dummies, multiple variables measured with possibly correlated errors, and simultaneity between the
latent variables and observed indicators. These may alter the details of the
density of z given x and the density of u, but give the same basic structure for

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1010

DANIEL

MCFADDEN

the response probabilities and MSM estimator. It is also possible to treat
measurement error in discrete response models such as multinomial logit by

allowing the E to have an appropriate distribution. For the logit example, MSM
estimation can be used by simulating the expectations of the logit formulas with
respect to the conditional distribution of the true explanatory variables. These
topics are studied in greater detail in McFadden (1986a, 1986b) and Train,

McFadden, and Goett (1987).
7. NONNORMAL DISCRETE RESPONSE MODELS

This paper has focused on estimation of the MNP model. However, the MSM
estimator can be applied to any latent variable model in which unbiased
estimates of the response probabilities can be obtained economically by Monte
Carlo methods. For example, in the latent variable model (1) it may be reasonable to assume that some components of a are always nonnegative, giving
monotonicity. This could be modeled by taking the density of a to be multivariate truncated normal, or by giving some components nonnegative densities such
as gamma. This complicates the analytic representation of response probabilities,
but is readily accommodated in Monte Carlo draws from the latent variable
model to obtain frequency estimators.

The MSM estimator also permits analysis of discrete response data generated
by more complex partial observation functions than the maximum indicator
appearing in (1). For example, consider data on ranks of alternatives. With the
exception of the multinomial logit model, it is impossible to obtain analytically
tractable expressions for probabilities of more than the first few ranks in terms of
response probabilities; see Falmange (1978), Barbara and Pattanaik (1985), and
McFadden (1986a). However, Monte Carlo drawings from the latent variable
model provides unbiased frequency estimators of the ranking probabilities that
can be used in MSM estimation.
8. STATISTICAL PROPERTIES OF MSM ESTIMATORS

The conditions under which MSM estimators are consistent asymptotically
normal (CAN) are stated formally and proved in this section. I use the following
notation, mostly collected from Sections 2 and 3 of the paper:

C = {1,..., m }: the set of possible responses.

ui= axi or uc= aXc: a latent variable mode

KX m array, Uc = (ul,..., Um), a = a(O,rq) a

a k x 1 parameter vector with true value 9*, and 'q a random vector with

density g(Qq) and associated measure g, independent of Xc. Let Xci =

(XiXi,..., Xi_i - Xi, xi+1 - Xi,..., xm - xi), and UC1i= (ul Uij, ,Ui-i Ui Ui+i-Ui.... Um-Ui).

p(Xc): density for Xc, with associated measure p.
gu(uc - i I, Xc): the density of uc-i induced by the transform
a(, 'q)Xc_i of the random vector q.
di= l(uc-i < 0): observed response (= indicator for maximum

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1011

Pc(i IO, Xc): probability of q such that a(O, q) Xc is
the discrete response probability.

fc(iI Xc): a simulator for Pc(iIO, Xc).

Wi: K x 1 instrument vector, determined as a function Wi = wi(O, Xc), with
K > k.

n = 1,..., N: a random sample.

d, P(0), f(0): mN x 1 vectors formed by stacking di, Pc(il, Xc), or
fc(i0, Xc) by alternative, then by observation.
W= W(O): KX mN array formed by stacking Wi.
P0(O): mN x k array of derivatives of P(O).

Osm: any vector satisfying IIW(0o)(d -f(ssm))11 A inf0 IIW(0o)(d-f(O))I
0(1), and 00 either prespecified or estimated.

RN(8), R(0), R: K X k array of sample covariances, RN(8) = WP0(0)/N,

R(0) = lim RN(O), R = R(0*).
The response probabilities are invariant under monotone transformations of

the latent variable model. Hence, without loss of generality, we may normalize

x1 O, so Xc is contained in a K(m -1) dimensional space. Further, a may be
defined without loss of generality to have a compact range: Given a latent

variable model uc = aXc, the transform a = a/(1 + lhall) has a range contained
[- 1]K, and the model ic = &Xc yields the same response probabilities.
The first assumptions made require Xc and 0 to have regular domains, a
guarantee a zero probability that the latent variables for different alternatives are
equal, so the response probabilities are well-defined without additional tie-breaking rules:

ASSUMPTION Al: The parameter space 49 is a compact convex subset of R k, and
0* is in the interior of 49.

-ASSUMPTION A2: The domain X of the attributes Xc is a compact subset of a

K( m - 1) dimensional space.

ASSUMPTION A3: The random vector q is finite-dimensional with domain N

independent of Xc, and has a finite mean. The function a = a(0, q) is continuous on
9 x N, and is twice differentiable in 0 with these derivatives continuous on 9 x N

ASSUMPTION A4: For an open set X 0 c X with p(X O) = 1, the subset N (0, X

of N such that a (0, q) Xc is distinct in every component has probability one for eac
0e&=- 19.

The last assumption is usually imposed in the definition of discrete response

models, and can be derived from more basic structural conditions. The following
lemma covers common applications, including MNP. When the model contains
alternative-specific random effects, the array A22 in this result is a (m- 1)
dimensional identity matrix.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1012 DANIEL MCFADDEN

LEMMA 1: Suppose Al and A2. Suppose there is a partition

( 0 A12

0 A22)
such that A22 is (m - 1) X (m - 1) and almost surely nonsingular. Suppose a =

a(O, q) /3(0) + 'qF(0) is twice continuously differentiable in 0. Suppose a is

partitioned commensurately with Xc, so

(27) [al a21 [1(0) /32(0)] + [ q2[Irl rn2]

Suppose r22 is nonsingular for 0 E 9. Suppose the density of q2 conditioned on 7

uniformly bounded and continuous, with support R 1 and suppose q has a finite
mean. Then A3 and A4 hold.

PROOF: aXc = /3XC + [0, 7,(rF,A12 + r12A22) + q2r22A22]. With probabil
one, the term q 2r22A22 has a continuous density with support Rrm-i, give
implying that the probability of a hyperplane where components of aXc are
is

zero.

Q.E.D.

The next assumption guarantees that the response probabilities are wellbehaved:

ASSUMPTION A5: The probability Pc(i 1, Xc) is positive, and twice differentiable in 0, and the probability and its derivatives are continuous, on G9 x X.
The following result gives a sufficient condition for A5 which holds in particular for the MNP model with alternative-specific dummies:

LEMMA 2: Suppose the hypotheses of Lemma 1, with A22 always nonsingular.
Then A5 holds.

PROOF: By the symmetry of the problem in alternatives, it is sufficient to

consider Pc(1 1 0, Xc) = Pr (aXc < 0 X). Using the decomposition of Lemma 1,
aXc= [0, s] < 0 implies

(28) 2.= [S-lAl2 _ 2A22-.,(rllAl2 +Frl2A22)I(r22A22)>

Then, given 71, the set B(71) of X,2 satisfying aXc < 0 is the intersection of m
linearly independent half-spaces, with each bounding hyperplane twice continuously differentiable in (0, Xc). Hence,
PC (1 I 0, XC) = fi1fB(r)g2.l (X2 1,) d7,2g1(J7,) diXl

is twice continuously differentiable in (0, Xc). Since g21 has support Rm-i, the
probability

is

positive.

Q.E.D.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1013

The next assumptions concern the instruments and identification of 0*:

ASSUMPTION A6: The function Wi = w,(0, Xc) determining the instruments is
continuous, bounded, and twice continuously differentiable on 69 x >X. (Let M,
denote a bound on wi and its 0 derivative, uniform in i, 0, Xc.)
ASSUMPTION A7: The instruments identify 0*, with

(29) W(O,J)-f E wi(j,Xc)[Pc(i I, Xc) - PC(iI0*, Xc)] dp(Xc)
i E C

equal to zero if and only if 0 = 0*, for any O E9.
ASSUMPTION A8: R is of maximum rank.
To satisfy A6, instruments constructed by simulation require the use of smooth
simulators such as (11) and (12). If A5 holds and the instruments equal the score

of the log likelihood evaluated at each trial 0, wi(0, Xc) a ln Pc(iI0, Xc)/a0,
then 0= 0 and co reduces to

co(0, P) = f E PC(iIo*, Xc)[a ln Pc(iI0, Xc)/d0] dp(Xc),
i E c

the expected score of an observation under maximum likelihood estimation. For
this case, A7 requires that 0* be the only critical point of the expected log
likelihood, a standard identification condition. Also, in this case, R equals the
information matrix evaluated at 0*, which is symmetric and nonnegative definite,
and by A7 is definite at some point in every neighborhood of 0*. Then A8 adds
only a regularity requirement. In the case of more general instruments, A7 and

A8 are standard assumptions for the identification and regularity of classical
method of moments estimators. Hence, the identification conditions for MSM are

the same as for the corresponding classical method of moments estimator. If

crude instruments independent of 0 are used to obtain an initially consistent
estimator, then X in (29) is independent of 0. If approximations to the ideal
instruments are calculated, starting from an initially consistent estimator, then it
is sufficient that A7 hold for 0 in a neighborhood of 9*.

The next assumptions concern the simulator fc(iI 0, Xc):
ASSUMPTION A9: Vectors (711n .... " l)rn) are drawn, by simple random sampling
or otherwise, independently of W and d, and independently for different n, so that

each q has marginal density g(,q). The simulator fc(il0, XCn) is a uniformly
bounded function of 0, XCn and ('1ln . ..... rn).
ASSUMPTION AIO: For the simulator fC(il 0, XCn), the simulation bias converges

to zero uniformly in 0 as N - oo; i.e., B(0) = N-1/2W(Ef(0) - P(0)), where the

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1014 DANIEL MCFADDEN

expectation is conditioned on W and d, satisfies

(8) sup IB(O) I= o(1).
ASSUMPTION A1l: For the simulator fc(i 0, Xc,) the simulation residual pro-

cess '(O) = N- 12W(f(0) - Ef(0)) is uniformly stochastically bounded and
equicontinuous in 0; i.e.,

(9) sup I (0) I = Op(1);
OEie

and for each 8 > 0, defining AN= {=INa/2I0-,*I 3}

(10) sup 100) - 00*) I = op(1).
OEAN

The main result on the asymptotic properties of MSM estimators is given in

the theorem below. Following the proof of this theorem, I examine the conditions
under which various frequency simulators, including the simple frequency simulator and smooth simulators, will satisfy All.
THEOREM 1: Suppose the MSM estimator Osm defined by (7) satisfies Assump-

tions Al to All. Then Osm is consistent, with N1 2(0smn-*) converging in

distribution to a normal vector with mean zero and covariance matrix Tsm =

(R'Rf) R'GsmR(R'R) -, with R = lim Nl-WP0(0*) and Gsm = lim N -EW(d-

f(0*))(d - f (0*))'W'.
PROOF: The argument parallels that of Pakes and Pollard (1989). The vector
W(d - f(O)) entering the defining condition (7) for the MSM estimator can be
decomposed into four terms,

(30) N-1/2W(d-f(9)) [D(O*) - t(O)] - B(0)
+ [N 1/2 W(d-f (O*)) + B(O*)]

- [N-1/2W(P(O) - p(O*))].
The asymptotic properties of the estimator are argued by applying conditions (8)
to (10) to the first two terms in (30), and applying the following arguments to the
last two terms:

[a] By construction of the simulator, N-1/2W(d - f(9*)) + B(0*) has expectation zero, given W. Random sampling and the independence of the simulators

across observations, plus the implication from A6 that W(d - f(0)) is uniformly
bounded, imply by the Lindeberg-Feller central limit theorem that this expression converges in distribution to a multivariate normal vector Z with mean zero
and covariance matrix Gsm.

[b] The expression WN(O) N-1W(P(0) - P(0*)) converges uniformly in
probability to a smooth function o(0) with the properties that (0) = 0 if and

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1015

only if 0 = 0*, and that R wO(O*) = hmw9N(
result, note that continuous differentiability
" N() I < MI0 - 01, where M > maxelR(0)1. Give

of & with neighborhoods of radius less than 6/3

centers of these neighborhoods. Then choose

N>Ne, Pr {max9 1s'N(0) - w(0)I > e/3} < e. B
0 E0 , there is a 0 EJ 9, such that IWN() -

Hence, Pr {max,lWN(O) - W(0)1 > -} < E. Regu
nonsingular.

Consider first the consistency of ,sm. Argument [a] implies N- 1/2W(d - f (*))
= Op(l). Hence, (7) satisfies

(31) N-1(d-f (Osm))'W'W(d-f (Osm))

< N-1 infe (d-f (0))'W'W(d-f (0)) + O(N-1)
< [N-1/2W(d-f (0*))]'[N-1/2W(d-f (0*))] + o(N- 1)

= Op(l),

implying N- 1/2W(d-f(0sm))= Op(l). Then, multiplying (30) by N-1/2 and
using (8), (9), and argument [b], one has WN(Osm)= op(l). But WN converges

uniformly outside each neighborhood of 0* to a function bounded away from
zero. Hence, the probability that 0Om is contained in any neighborhood of 0*
approaches one, proving consistency.

Next, I argue that N1/2(0sm - 0*) is stochastically bounded. From (30), the

condition N- 1/2W(d - f(0*)) = Op(l) from argument [a], (8), (9), and (31)
implies

Op(1) = N- 12W(p(0sm) - P(0*))
A Taylor's expansion5 yields

N-1/2W(P(Osm) - P(0*))

= [N-1WP0(0*) + O(Osm - 0*)] N1/2(Osm - 0*).
Then N-1WP9(0*) = R + op(l) and 0sm = 0* + oP(l) imply

Op(1) = [R + op(l)] N112(0sm - 0*).
Since R is of rank k, this implies N1"2(Osm- 0*)= Op(l).
Finally, consider the asymptotic normality of the MSM estimator. An asymp-

totically normal statistic 0 is defined, and then Osm is shown to be asymptotically

equivalent to it. Let #= 0* + (RfR)klR'N-lW(d-f(0*)). Argument [a] implies
N12( -0*) =(R'Rf-1R'Z+ o(l)=Op(l). Then N1"2(0- 0*) is asymptoti-

cally normal with covariance matrix (R'R)-fRGsmR(RR)-1. Also, (1

(O*) - '(#) = op(l). Substituting 0 in (30) and applying the argu

5In this and following proofs, a Taylor's expansion of a vector of functions will me
by component expansion, with remainders representable as expansion terms evaluated
arguments that differ across components.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1016 DANIEL MCFADDEN

with 0 in place of 0sm implies

(32) N- /2W(d-f(0)) = Z - [R + o(6- 0*)] N1/2(0- *) + op(1)
= I-7A(7K&Ry1R'Zo()
[ -(-- - z + ] (1).
From (32), (10), argument [b], a Taylor's expansion of P(0) - P(Osm), and the

result that N WP(Osm) = R + op(1),
(33) A=N- w (f( )f (Osm))

= N-1/2W(P( )-P(Osm)) + t(J) + B(O) -(Osm) - B(Osm)

= N-1/2W(P( -P(Osm)) + op(1) = RN1/2(- Osm) + op(1

Rewrite condition (7) characterizing Osm as

(34) N-1(d -f (O))'W'W(d -f (O)) + op(1)
>? N-1(d-f (sm))'W'W(d-f (Osm))

N N-1(d-f (0O))'W'W(d-f (#))
+2N-1/2(d-f (O))'W'A +'A

From (32) and (33), N-1/2(d - f(O))'W'A = op(l), and (34) impl

But then A - RN1/2(- Osm) + op(l) = op(l), implying Osm and 0 a
cally

equivalent.

Q.E.D.

The next result establishes sufficient conditions for a kernel-smoothed fre-

quency simulator to satisfy the asymptotic unbiasedness condition (8):
LEMMA 3: Suppose the assumptions of Lemma 1 hold, with A22 always nonsingular. Suppose a kernel-smoothed frequency simulator with a kernel of the form (15).
Assume the distribution function 'I' has a finite moment generating function in a
neighborhood of the origin. Assume N` 1/2bN - 0 for some E > 0. Then A10 holds.

PROOF: Let ,u(t) be the moment generating function of i. There exists T > 0
such that I(v) < eTVM(-T) for all v < 0 and 1 - I(v) < e-TV (T) for all v > 0.

If c-maxj16 i (yj -yi)/2 > O, then K i(Y,... * ,Ym) =v < c(IlH 1 #i( v + Yiyj))t (v) dv + Jv> c(rHj,, j(v +y yi-yj)) '(v) dv < e TC (-T) + e-Tc /(T), with
the first term the result of bounding I at negative arguments, and the second
the result of bounding the probability at positive arguments. If c < 0, a

similar argument yields K i(yl,..., Ym) > (1 e-ICLI(T))m > 1 - meTICIp[t(T).

Let K (yc_j) Ki(yc). Define I(A) = JAIK(uci/bN) - l(UC-i <

O)Igu(uc_jIO, Xc)duc-i. Define Al to be the set of uc-i less than -MbN in

every component, A2 to be the set of uc-i greater than MbN in at least one
component, with M a positive constant, and A3 = m- -Al - A2. Then, the

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1017

bounds on K imply I(Aj) < e-TM (T)m and I(A2) < e-TM ((T) + i( - )).
Further, I(A3) < Ej Pr(uu - <MbN). But (28) holds when the second
partition is of dimension one and s is the value of a single component uj - ui of
uc_i* Then, letting My be a uniform bound on the conditional density of 92
given ql, Pr(1u1 - uil < MbN) < 2MbNMY. Therefore, I(A3) < 2mMbNMY. Then,

N1 21Pc(iI9, Xc) - Pc(iIe, Xc)I < N /2(I(Aj) + I(A2) + I(A3)) <

Nl/2(e-TM,(Tr)m + e-TM (,k(T() + tk(-Tr)) + 2mMbNMY). Choose M = Tr-

Then, the right-hand side of the last inequality goes to zero if N1/2 (In N)bN
The condition Nl/2+ebN -- 0 implies the required limit. Q.E.D.
The stochastic boundedness and equicontinuity conditions in All can be
demonstrated for smooth simulators by the following argument:

LEMMA 4: If Al to A9 hold, and the simulator f(9) is uniformly bounded and
twice continuously differentiable, then (9) and (10) hold.
PROOF: A second-order Taylor's expansion of ' about 9* yields

(35) D(8) - 0(0*) = W@(9*)(9 - 9*)
+ (1/2) [N-1/%260] vec ([(9 - *)] [N1/2( - 9*)]),
where t6D is a K x k2 array of second derivatives evaluated at points between 9
and 9*. The array t6 satisfies E(t2e(0*)) = 0, with independence across observa-

tions, so a central limit theorem implies t6(0*) = Op(l). The contribution of each
observation to the array t6D is uniformly bounded, so N- 1/%, = Op(l). Hence,

(35) implies, for AN= { INl//2I -*I 8},

sup 1D(O)-(J) I = Op(l) - Op(N-1/2),

OeAN

establishing (10).

I next establish (9), using a "chaining" argument. Given an integer i, cover
[0, 1]k with 2ki cubes with sides 2-i, and let 6i be a set containing one point

selected from each cube that intersects 69. For 9 E 0, define Oi = 9j(9) to be the
nearest point in 6i9; then I @- Oi(0)I < 2-i and I i +l() - Oi(0)I < 2-i. From this
construction,
00

1()I< 1D8)I+ ? l(I+1 (i
i=l

I shall need Bernstein's inequality, which states that independent identically

distributed random variables Yi with EYt = 0 and IYI < c satisfy

P E >t exp [t2/(2NO2 + 2ct/3)],
for t> 0, where a2 = Ei; see Gine and Zinn (1986), Lemma 3.2, and also
Pollard (1984) and Shorack and Wellner (1986). Replace t by N1/2t and use

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1018 DANIEL MCFADDEN

a2< c2 to obtain
P{N-1/2 Y, > t < 2exp [t2/(2c2+ 2ct/3N1/2)].

Let M > 1 be a uniform bound for Yi e CWi ( fc (i IO, XCn) - EfC(i IO,
for its derivative with respect to 0. Note that X,I=1i2-` = 1/4. Then

constant C satisfying the bound C > 48M + 8kM In 2,

(36) P sup 1(O) I > C}
? P{ 1(01) I > C/2}

+ E P{ sup >D(0i?l(0)) - t(oi(0)) I, i2-i-3C

(37) < Pf 1t(01) I > C/2}
00

+ E 2 supP{ p '(Hi+1(0)) - '(0i(O)) > i2 -i-3C}
i=1 e

(38) < 2exp [-C2/4(2M2 + MC/3)]
i=l1
00

(39) <2exp[-C/4M]+ E 2exp[-iC/8M]< 5exp[-C/8M].
i=1

The inequalities (36) and (37) hold since left-hand-side events are contained in
the union of the right-hand-side events, while (38) follows by application of the
Bernstein inequality, and (39) by use of the bound on C and manipulation of the

exponential terms. Given e > 0, C can then be chosen sufficiently large to make
the right-hand side of (39) less than e. This proves (9). Q.E.D.

The following results establish conditions under which simulators can have
jumps, but these jumps are sufficiently "well-behaved" so (9) and (10) are
satisfied. The simple frequency simulator in the MNP model, in particular, is
shown to satisfy these sufficient conditions.

ASSUMPTION A12: Define Tpc(i 0, XC") to be the simple frequency in the r draws

for observation n of the event that a(0, -jn)XCn is maximized at component i.
Assume the simulator fc(iI0, Xc") is a uniformly bounded function of 0, Xc, and
('q1n,"*v nqrn) satisfying

(40) ICf(iIo, XCJ) fC(i #, XCJ) I
< M PmC(iI0, XC) - qC(ijI& XC) I + Mf I0 - #1
for some Mq,, Mf , X > 0, and all 0, 0 E 0 and XCn E X.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1019

Condition (40) requires that the simulator be at least as smooth in 0 as the
simple frequency simulator. Condition (40) is satisfied trivially by either the
frequency simulator, or by a smooth simulator. If the simulator is differentiable

at non-jump points, then X = 1; the assumption also allows 0 <X < 1, corresponding to "polynomial" nondifferentiability. A simulator satisfying (40) will be
termed X-Lipschitz in neighborhoods without jumps.

The next result characterizes the regularity in 0 of the simulated moments, and
guarantees that with probability one, the condition defining fJsm has a solution

with I W(d - f(sm)) I < mMw M./r. Then, any bounded sequence aN = 0(1) on

the right-hand side of the definition (7) of a MSM estimator that satisfies

aN > (mM, Mcp/rr)2 implies existence of the estimator.
LEMMA 5: Suppose Al-A9 and A12. Then, almost surely, W(d-f(O)) is

uniformly X-Lipschitz in 0 except for a closed subset Q90 of (9 with L

measure zero, and the jumps in this function on 00 are bounded by mM M<,/

PROOF: Define I(0, Xc, 7) = 0 if the components of a(0, 71)XC are all d
and I(0, Xc, )1 otherwise. For each 0 E (9, A4 implies

o = A (O, xc , q)dg(,q) dp(Xc),
and hence

(41) f = ffI( x xc,' ) dg(@i) dp(Xc) d.
Applying Fubini's Theorem to (41), there exists a set X1 C X with probability

measure one; for Xc E X 1, a set N (Xc) c N with probability measure one; a
for (Xc, 1) E X1 X N(Xc), a set i91(Xc, 7) C O of full Lebesgue measure on
which I(0, Xc, 7) = 0. The continuity of a(0, q) in 0 implies that if I(0, Xc, 7)
= 0, then this is also true in a neighborhood of 0, so i91(Xc, 71) is open.

The function W(d - f(0)) is defined by N independent draws XCn with
density p(Xc), and for each n, r draws ("uln.... "lrn), each with marginal density
g(q). Hence, with probability one, XCn E X 1 and 71 jn E N( XCn) for j = 1. r
and n = 1,..., N, implying eN = fX=lny=16>7n if p1XC ) is an open set of full
measure. But, by A12, fc(i 0, Xc) is uniformly X-Lipschitz with constant Mf on
ON'

Suppose 9 t 9N, SO 0 ' 19(XCn ,7qn) for some (n, j). With probability one, 0
is contained in O1(XCn' X,q n) for (n', j') A (n, j). Hence, using (40), the disconti-

nuity in IW(d -f(0))I is at most mM M<,/r with probability one. Q.E.D.
Assumption A4 implies that the set of i1 for which there are ties in the

components of a(0, 7)XC has probability zero for all 0 and almost all Xc. The
next assumption requires that the geometry of a(0, 7) be such that the exceptional set N(O, Xc)c of q where ties occur varies smoothly in (0, Xc). Define the

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1020 DANIEL MCFADDEN

.. . . . . . . . . . .

.5

e

FIGURE 1

set

(42) B6,(0,Xc)={'qjiE-N(0,Xc)'forsomej0-0j<8}
Figure 1 illustrates the construction of B36(0, Xe). The following argument
establishes that B,6(0, XC) is closed, and hence measurable, for (0, X/) E (9X X 0:
If 'qJ E- B, and 'qJ --, ~, thenq E' e N(0', Xcj)c, a closed set, for some (0', Xci) in a

closed 8 neighborhood of (0, Xe), by A3. Hence, using the continuity of
a(0, 'q)Xc in (0, Xe), q0 E- N(00, X )C for each limit point (90, XIJL) of (0', Xli).
ASSUMPTION Al13: There exists Mg and X > 0 such that for Xc E- X 0 and almost

all 0 E- (9, the set B36(0, Xc) has g(B,6(0, Xe)) < Mg 8l.
The assumption requires that the measure of the set of q yielding ties for 0 in
a 8-neighborhood shrink toward zero at a "polynomial rate" as 8 goes to zero.
This condition holds if the set-valued funiction N(O, Xc)c is transversal at 0 or if
there is at most a polynomial singularity. The next result shows that with
regularity conditions, the case a(0, q) = /3(0) + 'qF(0) satisfies A13; this assumption then holds in particular for the MNP model.

LEMMA 6: Suppose the hypotheses of Lemma 1, with A22 always nonsingular,
and A6-A9. Then A13 holds.

PROOF: Suppose a tie between alternatives 1 and 2, 50 ax2 = 0. Using th

notation of (27) and (28), partition a, = (a,, a m...a) and let a2 denote

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1021

second component. Then,

q2= [-1A12-32A22 - 1(r,A12+rl2A22)](F22A22)
The function i12=4(OC, X 1) is continuously differentiable in (0, Xc), and
hence has a Taylor's expansion

1p(J, Xc,~' r)-ip(0 xcSr1l) = [Al + 1x2] [ ~0jj,

where X1 and A2 are vectors of continuous derivatives of 4(O, Xc, ~1) evaluated
between (0, Xc) and (0, Xc). Then uniform continuity on compact 69 x X
implies there exists a constant MI, such that for 1(0, Xc) - (0, Xc)I s 3,

|+(, c, )- (0, XC, N1) I < MP (I + 11)8
Then the set N 2(0, xc, i) = {Mi2ILq2- (0l, Xc, q)I ( M41 + I11) 8} contains
all 2 solving C2 = 4(0, X ~1) for 1(0, Xc) - (0, Xc)l < 8, and satisfies
Igi(@B')
dNl 2 (0,X,V
~~~~2(8,
XC,?) 921 lq 1l ) dq2
< M1p(1 + EJi1I) WMY 2Mg3/m(m - 1),

where My bounds g21. There are m(m - 1) possible combi

alternatives, each of which can with permutations of components o

and relocation of Xc be put in the form above. The sum of the
combination

gives

A13.

Q.E.D.

Given e > 0, a finite family of random functions Fe is said to bracket a family

of random functions F if for each Y E F there exist Y, Y E Fe such that

Y < Y < Y and E(Y - Y) < e. The logarithm of the number of elements in the
smallest set Fe that brackets F, denoted H(E), is called metric entropy with
bracketing. The following result establishes stochastic equicontinuity conditions

for families whose metric entropy does not rise too rapidly as E falls.
LEMMA 7: Assume F is a uniformly bounded family of measurable random

functions. Assume F satisfies JJH(&2)1/2 dE finite, where H is the metric entropy
with bracketing. Suppose Y= y1, Y = y2,.... denote independent identically dis-

tributed realizations of deviations from the mean, Y - EY, for Y e F. Define

IIYII = EIY-EYI. Then for every X > O,

(43) lim8-0
limsup
Pr sup sup N-1/2l E (Yn-Yn| >X =)
N-oo YeF Y'eF n=1
Y Yn, I |Y' Y | | S8

PROOF: Dudley (1984), Theorem 6.2.1, establishes (43). I use a restatement
from Alexander (1987), Theorem 2.1. Q.E.D.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1022 DANIEL MCFADDEN

The next result establishes that the simulation residuals satisfy stochastic
equicontinuity and boundedness conditions sufficient for the MSM estimator to

be CAN. The critical step is to show that these residuals satisfy the assumption
on metric entropy required by Lemma 7.
LEMMA 8: Suppose Al-A9, A12-A13. Then All holds.

PROOF: Assume & E [0, i]k. For any integer j, cover [0, I]k with 2kj cubes w

sides 2-i, and for each Xc E X0, let i9j(Xc) be a set containing one po

selected from each cube that intersects 0. By A13, the selection can be made so

that g(B6(O, Xc)) < Mg3 for 0 E i9j(Xc). Define 0j(0) -j(0, Xc) to be a point
in i9j(Xc) nearest to 0; then 1 - Oj(O)I < 2-'_ A.

Let Y(, Xc) = jiGcWSfc(iI6, Xe) Define qj(6, Xc) to be the number of

draws % for s = 1,..., r with % E Bs (0, Xc). Using the notation of (40), and X

satisfying A12 and A13, define

Yj (I Xc) = mMW( MfO - Oy(0) | + Mqpqj(0, Xc)/r).
Then, by A13, Eqj(0, Xc) < rg(B6 (0, Xc)), implying

EYj (0, Xc) < mMwMfI0 - O (0) | + mMwMcg(Be(0, Xc))
z mMw ( Mf + MqW Mg) siX= MO3si
From (40),

Y(0, XC) - Y(j0,(0), xC)
, mMw( Mfl - Oj(6) | ) + mMwMq, mmax I gc (i I 6, Xc)

< mMw(Mflj6- O(O)| + Mpqj(6, Xc)/r)

Hence, Yj(0, Xc) Y(6j(6), Xc) - Yj0(0, Xc) < Y(6, Xc) < Yj(6, Xc)
Y(0j(6), Xc) + Yj)(6, Xc). Given e > 0, choose j to be the smallest integer such
that 2-i < e. Then the 2kj+1 functions Y1 and 1Yj bracket Y(0, Xc), 0 E- (. This
implies that the metric entropy with bracketing for F = { Y(0, Xc) 0 E (9} satisfies H(e) < (kj + l)ln2 < (-ln e)k/X + (k + l)ln2, and hence JJH(e2)1/2 de <
JJoH(E2) de < (k + 1) In 2 - 2(k/X)Jfo ln e de < oX. This establishes the assumptions of Lemma 7, so (43) holds.

For any 8 > 0, forming the expectation of (40) and using A12, 10 - 61 < 8
implies E l Y(0, Xc) - Y(6, Xc) I < mMw (Mf + Mgp Mg) 8 MO S. Hence, (43) can

be written in the form

(44) lim lim sup Pr {(0) - () I > x =0.
80N-boo

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1023

Taking 8=2-J, j=1,2,..., one has 0-01<8 forN?

Then (44) implies (10).

Next prove (9). From (44), given X > 0, there exists 8 > 0 such that

limsupPr sup sup g(0)-g(J)I>?4 <xA
N- co ~~~0 =e#E- eI &

Choose any 0O E &. A central limit theorem implies there e
SUpNPr {If S(o) I > Mo } < A. But any 0 E & can be written 0
with Oj = (j/J)0 + (1 -j/J)00 and J the smallest integer exc

Pr {I (0) I > Mo + AJ }
K1P r{ (00) I> MO& |t(@i+J -009 I <X i,j=? ,J) <A.
Then

(9)

holds.

Q.E.D.

In this lemma, the construction holds even if the number of repetitions r is a

random function of 0, Xc, and N. Then, in particular, the lemma holds for
simulators formed by acceptance/rejection methods with random stopping rules,

and for consistent simulators where r increases with sample size.

Let ON be a sequence in & and assume that the instruments are evaluated at ON
for each N. The ON might be nonstochastic, or a sequence of initially consistent
estimators, or might equal the MSM estimator Osm. In the last case, Osm solves

lW(Osm)(d-f (Osm)) || 0 < inf ||W(Osm)(d-f (0)) 11 + 0(1).
Lemma 8 holds in all these cases.

The next result establishes the consistency of the estimators (21) and (22) of
the components of the asymptotic covariance matrix of the MSM estimator.

LEMMA 9: Assume Al-All. Assume P0(0) is a simulator of P0(0) that is twice

continuously differentiable in 0, such as the smooth simulator (12) with the den-

sity y chosen so that the function ho(uc,S 0, Xc_) is dominated by an inte-

grable function (i.e., some H(uC-i' Xc-i) satisfies ih0l < H and

JH(uc-i Xc-i)y(uc-i) duc-i finite). Then the estimator 2sm for 2sm given in
(21) is consistent, as is the estimator R = N- WP0 for R given in (22), with Po

evaluated at Osm or any consistent estimator of 0*.

PROOF: To show (21), note first that this expression with 0* in place of Osm
converges to Gsm by a law of large numbers; see part [a] of the proof of Theorem

1. Second, by (8)-(10), terms involving the difference of f(0*) and f(Osm) are

op(l). The argument for (22) is the same, but it is necessary to use versions o
(8)-(10) for P6,. These hold for smooth simulators by Lemma 4. Q.E.D.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1024 DANIEL MCFADDEN

Expressions for the derivatives of the response probabilities with respect to the
parameters 9, in a form suitable for application of simulation methods, are
needed for the construction of instruments, and consistent estimation of the
MSM covariance matrix. They are also needed for Newton-Raphson type iterative search for the estimators. For multinomial probit, Paul Ruud has suggested a

characterization of the derivatives of the response probability with respect to /3
and r. Applying the chain rule to /3(9) and r(9) yields derivatives of the
response probabilities with respect to the deep parameters 9. These equations
provide a template for construction of good crude instruments for MNP. Note
that these equations require simulation of only the first and second order
censored moments of the multivariate distribution, which can be done efficiently
using cylinder function simulators.
LEMMA 10: Assume the MNP model, generated by the latent variable model (1)
with a satisfying (3). Then, the derivatives of the response probabilities with respect
to the parameters /3, r are

dPc(iI9, X)/ad/=X(X'2X) (u-,BX)n(u-,BX, X'QX)du
< O

=-X( X'QX) 11 (u -,BX) h(u, X, 0) y(u) du,
u<O

and

aPc(iI09 X)Idr

= rx(x'Q2x)f(f [(u - 13X)'(u - ,8X) - X'Q2X]
"<0

*n(u- /3X, X'QX) du (X'QX)'1X
- rx(xf2x) -( f[(u - 13X)'(u - /3X) - X'QX]
"<

*h(u, X, 9)y(u) du

where D = rr, X = Xc- and h(u, X, 9) is the r

density to a Monte Carlo sampling distribution y
PROOF: Consider the normal density

n (u - J,t A) = (2g)f-1/2IA1-1/2e(u-u)'A-1(u-A)/2,
with A = x'rFrX and t = /3X. The following matrix differentiation formulas are

derived by writing out terms from the familiar expressions d ln A/dA =Aand dA - 1/dA = -A - 1 ? A - 1 (which hold when A is symmetric, but identity of

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

METHOD OF SIMULATED MOMENTS 1025

cross-terms is not imposed in the differentiation):

d in IX'r'XI/rdr= 2rX(X'r'rX)-IX',
d(z'(x'r'rx) -'z)/dr= -2rx(x'rFrx) -'zz'(x'rFrx) -'xi.
The derivatives of In n(u - /3X, Xr'rx) are then

d In n/ld3 = X(x'rFrx) l(u - 1X)',
d In n/dr= -rx(x'rFrx))x

+?rx(x'rrx)'-(u - 13x)'(u - 13x)(x'rFrx)-lx
Q.E.D.

Department of Economics, Massachusetts Institute of Technology, Cambridge,
MA 02139, U.S.A.
Manuscript received October, 1987; final revision received September, 1988.

REFERENCES

ALEXANDER, K. (1987): "The Central Limit Theorem for Empirical Processes on Vapnic-Cervonenkis
Classes," The Annals of Probability, 15, 178-203.
BARBERA, S., AND P. PATTANAIK (1986): "Falmagne and the Rationalizability of Stochastic Choices in
Terms of Random Orderings," Econometrica, 54, 707-715.
CHAMBERLAIN, G. (1984): "Panel Data," in Handbook of Econometrics, Vol. 2, ed. by Z. Griliches and
M. Intriligator. Amsterdam: North Holland, 1247-1320.
CLARK, C. (1961): "The Greatest of a Finite Set of Random Variables," Operations Research, 9,
145-162.

DAGANZO, C. (1980): Multinomial Probit. New York: Academic Press.
DEAK, I. (1980): "Three Digit Accurate Multiple Normal Probabilities," Numerische Mathematik, 35,
369-380.
DEVROYE, L. (1986): Non-Uniform Random Variate Generation. New York: Springer.

DUDLEY, R. (1984): "A Course on Empirical Processes," Ecole d'Ete de Probabilites de Saint-Flour,
XII-1982, Lecture Notes in Mathematics 1097. New York: Springer, 1-142.
Du'rr, J. (1976): "Numerical Aspects of Multivariate Normal Probabilities in Econometric Models,"
Annals of Economic and Social Measurement, 5, 547-562.
FALMANGE, J. (1978): "A Representation Theorem for Finite Random Scale Systems," Journal of
Mathematical Psychology, 18, 52-72.
FISHMAN, G. (1973): Concepts and Methods of Digital Simulation. New York: Wiley.
GINt, E., AND J. ZINN (1986): "Lectures on the Central Limit Theorem for Empirical Processes,"
Probability and Banach Spaces, Lecture Notes in Mathematics, 1221. New York: Springer, 50-113.
HAJIVASSILIOU, V., AND D. McFADDEN (1987): "The Debt Repayment Crises of LDC's: Estimation
by the Method of Simulated Moments," Yale Univ., Working Paper.
HAMMERSLEY, J., AND D. HANDSCOMB (1964): Monte Carlo Methods. London: Methuen.
HAUSMAN, J., AND D. WISE (1978): "A Conditional Probit Model for Qualitative Choice: Discrete
Decisions Recognizing Interdependence and Heterogeneous Preferences," Econometrica, 46,
403-426.

HECKMAN, J. (1981): "The Incidental Parameters Problem and the Problem of Initial Conditions in
Estimating a Discrete Time-Discrete Data Stochastic Process," in Structural Analysis of Discrete
Data with Econometric Applications, ed. by C. Manski and D. McFadden. Cambridge: MIT Press,
179-195.

HENDRY, D. (1984): "Monte Carlo Experimentation in Econometrics" in Handbook of Econometrics,
Vol. 2, ed. by Z. Griliches and M. Intriligator. Amsterdam: North Holland, 937-976.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

1026

DANIEL

MCFADDEN

HOROWITZ, J., J. SPARMONN, AND C. DAGANZO (1981): "An Investigation of the Accuracy of the
Clark Approximation for the Multinomial Probit Model," Transportation Science, 16, 382-401.
LERMAN, S., AND C. MANSKI (1981): "On the Use of Simulated Frequencies to Approximate Choice
Probabilities," in Structural Analysis of Discrete Data with Econometric Applications, ed. by C.
Manski and D. McFadden. Cambridge: MIT Press, 305-319.

McFADDEN, D. (1984): "Econometric Analysis of Qualitative Response Models," in Handbook of
Econometrics, Vol. 2, ed. by Z. Griliches and M. Intriligator. Amsterdam: North Holland,
1395-1457.

-~ (1986a): "The Choice Theory Approach to Marketing Problems," Marketing Science, 5,
275-297.

(1986b): "Discrete Response to Unobserved Variables for Which There are Multiple Indicators," MIT, Working Paper.

MORAN, P. (1984): "The Monte Carlo Evaluation of Orthant Probabilities for Multivariate Normal
Distributions," Australian Journal of Statistics, 26, 39-44.
OWEN, D. (1956): "Tables for Computing Bivariate Normal Probabilities," Annals of Mathematical
Statistics, 27, 1075-1090.

PAKES, A., AND D. POLLARD (1989): "The Asymptotic Distribution of Simulation Experiments,"
Econometrica, 57, 1027-1057.

POLLARD, D. (1984): Convergence of Stochastic Processes. New York: Springer.
(1985): "New Ways to Prove Central Limit Theorems," Econometric Theory, 1, 295-314.
PREss, W., B. FLANNERY, S. TEUKOLSKY, AND W. VETTERLING (1986): Numerical Recipes. Cambridge:
Cambridge University Press.

RUUD, P. (1981): "Misspecification Errors in Limited Dependent Variable Models," MIT, PhD
Dissertation.

RUUD, P., AND D. McFADDEN (1987): "Estimation of Limited Dependent Variable Models from the
Regular Exponential Family by the Method of Simulated Moments," Univ. of California, Berkeley, Working Paper.

SHORACK, G., AND J. WELLNER (1986): Empirical Processes with Applications to Statistics. New York:
Wiley.

SPANIER, J., AND K. OLDHAM (1987): An Atlas of Functions. Washington: Hemisphere.
STERN, S. (1987): "A Method for Smoothing Simulated Moments of Probabilities in Multinomial
Probit Models," University of Virginia, Working Paper.
TRAIN, K., D. McFADDEN, AND A. GOETT (1987): "Consumer Attitudes and Voluntary Rate
Schedules for Public Utilities," Review of Economics and Statistics, forthcoming.
WESTIN, R. (1974): "Predictions from Binary Choice Models," Journal of Econometrics, 2, 1-16.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:04:54 UTC
All use subject to https://about.jstor.org/terms

