Measuring Traffic
Author(s): Peter J. Bickel, Chao Chen, Jaimyoung Kwon, John Rice, Erik van Zwet and
Pravin Varaiya
Source: Statistical Science, Vol. 22, No. 4 (Nov., 2007), pp. 581-597
Published by: Institute of Mathematical Statistics
Stable URL: https://www.jstor.org/stable/27645864
Accessed: 21-10-2019 14:59 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve and
extend access to Statistical Science

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

Statistical Science

2007, Vol.22, No. 4, 581-597
DOI: 10.1214/07-STS238
? Institute of Mathematical Statistics, 2007

Measuring Traffic
Peter J. Bickel, Chao Chen, Jaimyoung Kwon, John Rice, Erik van Zwet and Pravin Varaiya

Abstract. A traffic performance measurement system, PeMS, currently
functions as a statewide repository for traffic data gathered by thousands of
automatic sensors. It has integrated data collection, processing and commu
nications infrastructure with data storage and analytical tools. In this paper,
we discuss statistical issues that have emerged as we attempt to process a data
stream of 2 GB per day of wildly varying quality. In particular, we focus on
detecting sensor malfunction, imputation of missing or bad data, estimation
of velocity and forecasting of travel times on freeway networks.

Key words and phrases: ATIS, freeway loop data, speed estimation, mal
function detection.

1. INTRODUCTION

a particular location on the freeway, averaged over
30 seconds. Ninety percent of point sensors are in
ductive loops buried in the pavement; the others are

As vehicular traffic congestion has increased, espe
cially in urban areas, so have efforts at data collection,

overhead video cameras or side-fired radar detectors.

analysis and modeling. This paper discusses the sta

Point sensors provide continuous measurement. The

tistical aspects of a particular effort, the Freeway Per
formance Measurement System (PeMS). We begin this
introduction with some general discussion of data col
lection and traffic modeling and then describe PeMS.

large amount of data they provide can be used for sta
tistical analysis.
The second type of sensors are implemented by float
ing cars that record GPS or tachometer readings from
which one can construct the vehicle trajectory. Floating
cars are expensive since they require drivers. Depart
ments of Transportation (DoTs) typically deploy float
ing cars once or twice a year on stretches of freeway
that are congested to determine travel time and the ex
tent of the freeway that is congested. The data are in
sufficient for reliable estimates of travel time variabil

1.1 Data Collection and Traffic Modeling
Traffic data are collected by three types of sensors.

The first type is a point sensor, which provides es
timates of flow or volume, occupancy and speed at
Peter J. Bickel is is Professor, Department of Statistics,

University of California, Berkeley, Berkeley, California

ity.
The third type of sensor can be used in areas in which

94720, USA (e-mail: bickel@stat.berkeley.edu). Chao Chen
is a graduate student, TFS Capital, 121 N. Walnut Street Ste
320, West Chester, Pennsylvania 19380, USA (e-mail:
chao@tfscapital.com). Jaimyoung Kwon is Assistant
Professor, Department of Statistics, California State
University, East Bay, Hayward, California 94542, USA
(e-mail: jaimyoung.kwon@csueastbay.edu). John Rice is
Professor, Department of Statistics, University of
California, Berkeley, Berkeley, California 94720, USA
(e-mail: rice@stat.berkeley.edu). Erik van Zwet is with the
Mathematical Institute, University of Leiden, 2300 RA

vehicles are equipped with RFID tags. These tags are
used for electronic toll collection (ETC). In the San
Francisco Bay Area, for example, ETC tags are used
for bridge toll collection. ETC readers are deployed at
several locations, in addition to the bridge toll booths.
These readers collect the tag ID and add a time stamp.
By matching these at two consecutive reader locations,
one gets the vehicle's travel time between the two loca
tions. (One may view these data as samples of floating
car trajectories.) The www.511.org site displays travel
times estimated using these data. Of course, this type of
sensor can only be deployed in a few locations. More
over, the penetration of ETC tags in the whole vehicle
population, and hence the data they provide, varies by
time of day and day of week.

Leiden, The Netherlands (e-mail:
evanzwet@math.leidenuniv.nl). Pravin Varaiya is Nortel
Networks Distinguished Professor, Department of
Electrical Engineering and Computer Science, University
of California, Berkeley, Berkeley, California 94720, USA
(e-mail: varaiya @ eecs. berkeley. edu).

581
This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

582 P. J. BICKEL ET AL.
In addition, there are special data sets obtained from
surveys.

Point sensors implemented by inductive loops pro
vide 95% of the data used by DoTs and traffic analysts
worldwide. These data are used for two purposes: real
time traffic control and building traffic flow models for

planning.
The primary traffic control mechanism is ramp me
tering, which controls the volume of traffic that enters

the freeway at an on-ramp. The rate of flow depends
on the density of traffic on the freeway, estimated from

real-time loop data. Measurement, modeling and con
trol are discussed in Papageorgiou (1983) and Papa
georgiou et al. (1990), for example.
Real-time and historical data are also used to esti
mate and predict travel times. Travel time predictions
are posted on the web and on changeable message signs
on the side of the freeway. Attempts to process these

data to estimate the occurrence of an accident have

been unsuccessful, because of high false alarm rates.
Simulation models are used by regional transporta

are based on least squares fit using a few days of data,
with no attempt to calculate the reliability of the esti
mates. In order to predict network-wide traffic flows,

the models need origin-destination flow data. These
are converted into link-level flows assuming some kind
of user equilibrium in which drivers take routes that
have minimum travel times. Since these travel times

depend on the link flows themselves, an iterative pro
cedure is needed to calculate the assignment of origin
destination flows to link flows (Yu et al., 2004). Origin
destination flow data themselves are based on survey
data or they are inferred from activity models that re
late employment and household location data, obtained
from the Census.

1.2 The Freeway Performance

Measurement System

Over a number of years, the State of California
has invested in developing Transportation Management
Centers (TMCs) in urban areas to help manage traffic.
The TMCs receive traffic measurements from the field,

tion planners to predict changes in the pattern of traffic

such as average speed and volume. These data, which

through a freeway network as a result of projected in

are updated every 30 seconds, help the operations staff
react to traffic conditions, to minimize congestion and
to improve safety.

crease in demand or the addition of a lane or exten
sion of a highway. The models are more frequently
used to predict the impact of proposed shopping or
housing development, or, in an operational context,
to compare different alternatives to relieve conges
tion at some location. Microscopic models, such as

TSIS/CORSIM, TRANSIMS, VISSIM and Paramics

More recently, the California Department of Trans
portation (Caltrans) recognized that the data collected

by the TMCs is valuable beyond real-time opera
tions needs, and a concept of a central data reposi

macroscopic models, such as TRANSYT, SYNCHRO
and DYNASMART, the unit of analysis is a platoon

tory and analysis system evolved. Such a system would
provide the data to transportation stakeholders at all
jurisdictional levels. It was decided to pursue this con
cept at a research level before investing significant re

of vehicles or macroscopic variables such as flow, den
sity and speed. URLs for these simulation models are
given in the list of references. A fascinating overview
and discussion of microscopic and macroscopic traffic

PATH (Partners for Advanced Transit and Highways)
at the University of California at Berkeley was initi
ated to develop a performance measurement system or

predict the movement of each individual vehicle. In

models is provided by Helbing (2001).
Microscopic models are based on car-following and
gap-acceptance models of driver behavior: how closely

do drivers follow the car in front as a function of

distance and relative speed; and how big a gap is
needed before drivers change lanes. The parameters in
these behavioral models are interpreted as indicators
of driver aggressiveness and impatience. Microscopic

models have scores of parameters, but they are cali
brated using aggregate point detector data. As a result,
most parameters are simply set to default values and no
attempt is made to estimate them. Macroscopic models
have fewer parameters, which can be estimated with

point detector data. Typically, however, the estimates

sources. Thus, a collaboration between Caltrans and

PeMS.

PeMS currently functions as a statewide repository
for traffic data gathered by thousands of automatic

sensors. It has integrated existing Caltrans data col
lection, processing and communications infrastructure

with data storage and analytical tools. Through the In
ternet (http://pems.eecs.berkeley.edu), PeMS provides
immediate access to the data to a wide variety of users.
The system supports standard Internet browsers, such
as Netscape or Explorer, so that users do not need any
specialized software. In addition, PeMS provides sim
ple plotting and analysis tools to facilitate standard en
gineering and planning tasks and help users interpret
the data.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

MEASURING TRAFFIC 583
PeMS has many different users. Operational traffic
engineers need the latest measurements to base their
decisions on the current state of the freeway network.
For example, traffic control equipment, such as ramp
metering and changeable message signs, must be opti

mally placed and evaluated. Caltrans managers want
to quickly obtain a uniform and comprehensive as
sessment of the performance of their freeways. Plan
ners look for long-term trends that may require their
attention; for example, they try to determine whether

congestion bottlenecks can be alleviated by improv
ing operations or by minor capital improvements. They
conduct freeway operational analyses, bottleneck iden
tification, assessment of incidents and evaluation of ad

vanced control strategies, such as on-ramp metering.
Individual travelers and fleet operators want to know
current shortest routes and travel time estimates. Re
searchers use the data to study traffic dynamics and
to calibrate and validate simulation models. PeMS can
serve to guide development and assess deployment of
intelligent transportation systems (ITS).
PeMS has many different faces, but at some level it
is just a simple balance sheet. A transportation system
consumes public resources. In return, it produces trans

portation services that move people and goods. PeMS
provides an automated system to account for these
outputs and inputs through a collection of accounting
formulas that aggregate received data into meaning
ful indicators. This produces a balance sheet for use
in tracking performance over time and across agencies
in a reasonably objective manner. Examples of "mean
ingful indicators" are:

hourly, daily, weekly totals of VMT (vehicle-miles
traveled), VHT (vehicle-hours traveled) and travel
time for selected routes or freeway segments (links),
means and variances of VMT, VHT and travel time.
These are simple measures of the volume, quality and
reliability of the output of highway links. Publication
each day of these numbers tells drivers and operators
how well those links are functioning. Time series plots
can be used to gauge monthly, weekly, daily and hourly
trends.

PeMS database. PeMS maintains a separate instance of
the database for each district. Although the table for
mats vary slightly across districts, they are stored in
PeMS in a uniform way, so the same software works
for all districts.

The PeMS computer at UC Berkeley is a four

processor SUN 450 workstation with 1 GB of RAM
and 2 terabytes of disk. It uses a standard Oracle data
base for storage and retrieval. The maintenance and ad
ministration of the database is standard but highly spe
cialized work, which includes disk management, crash
recovery and table configuration. Also, many parame
ters must be tuned to optimize database performance.
A part-time Oracle database administrator is necessary.

The PeMS database architecture is modular and
open. A new district can be added online with six

person-weeks of effort, with no disruption of the dis
trict's TMC. Data from new loops can be incorporated

as they are deployed. New applications are added as
need arises.
PeMS includes software serving three main func
tions: operating the database, processing and analyzing
the data, and providing access to the data via the Inter
net. The processing of the data is done to ensure their
reliability. It is a fact of life that the automatic detectors
that generate most of our data are prone to malfunction.

Detecting malfunction in an array of correlated sensors
has been a statistical challenge. The related problem of
imputation of bad or missing values is another major
concern.

PeMS provides access to the database through the

Internet. Using a standard browser such as Netscape or
Internet Explorer, the user is able to query the database
in a variety of ways. He or she can use built-in tools to
plot the query results, or download the data for further
study. Numerous tools for visualization are provided,
allowing users to examine a variety of phenomena. Vi

sualization tools include real-time maps showing lev

Every 30 seconds, PeMS receives detector data over

els of congestion, flow and speed profiles in space and
in time, time series for individual detectors, plots dis
playing detector health, profiles of incidents in space
and time, graphics to aid in the identification of bot
tlenecks, displays of delay as a function of space and
time, and graphical summaries of vehicle miles trav

the Caltrans wide area network (WAN) to which all
12 districts are connected. Each individual Caltrans

eled by freeway segment as a function of space and
time.

district is connected to PeMS through the WAN over a
permanent ATM virtual circuit. A front end processor
(FEP) at each district receives data from freeway loops

every 30 seconds. The FEP formats these data and
writes them into the TMC database, as well as into the

In this paper we will describe how PeMS works.
Our emphasis will be on the statistical issues that have
emerged as we attempt to process a data stream of 2 GB
per day of wildly varying quality. Real-time processing
of the data is essential and while our methods cannot

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

584 P. J. BICKEL ET AL.
be optimal or "best" in any statistical sense, we aim
for them to be as "good" as possible under the circum
stances, and improvable over time.
The remainder of the paper is organized as follows.
In Section 2 we describe the basic sensors upon which

PeMS relies, loop detectors. In Section 3 we describe
our approaches to detecting sensor malfunction and in
Section 4 describe how we impute values that are miss
ing or in error. Section 5 is devoted to a description
of how we estimate velocity from the loop detectors,
and Section 6 describes our method of predicting travel

where T is the duration of the sampling time interval,
say 5 min, N(t) is the number of cars detected during
the sampling interval t, Xj is the on-time of vehicle 7,
and J(t) is the set of cars that are detected in time in
terval t. The traffic speed at time t is defined as

V(t) = - V Vj,

N(t)
.^ J
v J jeJ(t)

where vj is the velocity of vehicle j.

times for users. The reader will see that these efforts are

We will use d,t,s,n to denote day, time of day,
detector station and lane, letting them range over

very much a work in progress, with some aspects well
developed and others under development.

tion" we mean the collection of loop detectors in the

2. LOOP DETECTORS
Caltrans TMCs currently operate many types of au
tomatic sensors: microwave, infrared, closed circuit
television and inductive loop. The most common type
by far, however, is the inductive loop detector. Induc

tive loop detectors are wire loops embedded in each
lane of the roadway at regular intervals on the net
work, generally every half-mile. They operate by de
tecting the change in inductance caused by the metal in
vehicles that pass over them. A detector reports every
30 seconds the number of passing vehicles, and the per
centage of time that it was covered by a vehicle. The

number of vehicles is called flow, the percent cover
age is called the occupancy. A roadside controller box
operates a set of loop detectors and transmits the infor
mation to the local Caltrans TMC. This is done through
a variety of media, from leased phone lines to Caltrans
fiber optics. PeMS currently receives data from about
22,000 loop detectors in California.
A single inductance loop does not directly measure
velocity. However, if the average length of the passing
vehicles were known, velocity could be inferred from
flow and occupancy. Estimation of velocity or, equiv
alent^, average vehicle length has been an important
part of our work, which is the subject of Section 5. At
selected locations, two single-loop detectors are placed
in close proximity to form a "double-loop" detector,
which does provide direct measurement of velocity,
from the time delay between upstream and downstream
vehicle signatures. Most of the loop detectors in Cali
fornia are single-loop detectors while double-loop de
tectors are more widely used in Europe.
For a particular loop detector, the flow (volume) and
occupancy at sampling time t (corresponding to a given
sampling rate) are defined as

1,...,D, 1,...,T, 1,...,5 and 1,...,N. By "sta

various lanes at one location. Flow, occupancy, speed
measured from station s, lane I at time t of day d will

be denoted as

qSii(d,t),kSii(d,t),vsj(d,t).
We will also index detectors by / = 1,...,/ in some
cases and use t to denote sample times, so that nota
tions like qt(t), qsj(t), etc. will be seen as well.
Single-loop detectors are the most abundant source
of traffic data in California, but loop data are often
missing or invalid. Missing values occur when there is
communication error or hardware breakdown. A loop
detector can fail in various ways even when it reports
values. Payne et al. (1976) identified various types of
detector errors including stuck sensors, hanging on or
hanging off, chattering, cross-talk, pulse breakup and
intermittent malfunction. Even under normal condi
tions, the measurements from loop detectors are noisy;
they can be confused by multi-axle trucks, for example.

Bad and missing samples present problems for any
algorithm that uses the data for analysis, many of
which require a complete grid of good data. Therefore,
we need to detect when data are bad and discard them,

and impute bad or missing samples in the data with
"good" values, preferably in real time. The goal of de
tection and imputation is to produce a complete grid of
clean data in real time.

3. DETECTING MALFUNCTION
Figure 1 illustrates detector failure. The figure shows

scatter plots of occupancy readings in four lanes at a
particular location. From these plots it can be inferred
that loops in the first and second lanes suffer from tran

sient malfunction.

The problem of detecting malfunctions can be
viewed as a statistical testing problem, wherein the

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

MEASURING TRAFFIC 585

actual flow and occupancy are modeled as follow
ing a joint probability distribution over all loop de
tectors and times, and their measured values may be

missing or produced in a malfunctioning state. Let
A/(0 = 0, 1,2 according as the state of detector /
at time t is good, malfunctioning, or the data are
missing. The problem of detecting malfunctioning is
that of simultaneously testing H:A?(t) = 0 versus
K : Ai(t) ? 1 or of estimating the posterior probabil
ities, P(A/(0 = 11 data).
Since the model is too general and high dimen
sional for practical use, simplification is necessary.

\

The most extreme and convenient simplification is to
consider only the marginal distribution of individual

0.0

(30-second) samples at an individual detector. In that

0.1

0.4

Occupancy

case, the acceptance region and the rejection region
partition the (q, k) plane.
The early work in malfunction detection used heuris

0.2 0.3

FIG. 2. Acceptance region of Washington algorithm.

tic delineations of this partition. Payne et al. (1976)
presented several ways to detect various types of loop

malfunctions from 20-second and 5-minute volume

and occupancy measurements. These methods place
thresholds on minimum and maximum flow, density

and speed, and declare data to be invalid if they fail
any of the tests. Along the same line, Jacobon, Nihan
and Bender (1990) at the University of Washington de
fined an acceptable region in the (q, k) plane, and de
clared samples to be good only if they fell inside. We
will refer to this as the Washington Algorithm. This
has an acceptance region of the form shown in Fig

ure 2.

PeMS currently uses a Daily Statistics Algorithm
(DSA), proposed by Chen et al. (2003), which pro
ceeds as follows. A detector is assumed to be either
good or bad throughout the entire day. For day d, the
following scores are calculated:

S\(i,d) = number of samples that have occupan

cy = 0,

S2(i,d) = number of samples that have occupan
cy > 0 and flow = 0,
S^(i,d) = number of samples that have occupan
cy > fc* (=0.35),

0.0 0.1 0.2 0.3 0.4 0.5 0.6

0.0 0.05 0.10 0.15 0.20 0.25

M"?fcV"C.

y.'.

?ISA/

/

0.0 0.05 0.10 0.15 0.20 0.25

FlG. 1. Scatter plots of occupancies at station 25 of westbound 7-210.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

586 P. J. BICKEL ET AL.

S$(i,d) = entropy of occupancy samples
[? J2x:p(x)>oP(x)^??P(x) where p(x) is the his

togram of the occupancy]. If k? (d, t) is constant in t,

for example, its entropy is zero.

Then the decision A? = 1 is made whenever S;J
> s*
j

An ideal detection algorithm needs to work well with
thousands of detectors, all with potentially unknown
types of malfunction. Even constructing a training set
is not trivial since there is so much data to examine and
it is not always possible to be absolutely sure if the data

are correct even after careful visual inspection. [For
for any j = 1,..., 4. The values s* were chosen em
example, suppose a detector reports (q,k) = (0, 0). It

pirically. Since this algorithm does not run in real time,
could be that the detector is stuck at "off" position but
a detector is flagged as bad on the current day if it was
good detectors will also report (0, 0) when there are no
bad on the previous day.
vehicles in the detection period. Similarly, occupancy

The idea behind this algorithm is that some loops
measurements stuck at a reasonable value will not trig
seem to produce reasonable data all the time, while

ger any alarm if one considers only a single detector
others produce suspect data all the time. Although it

and a single time.] New approaches should include a
is very hard to tell if a single 30-second sample is
method of delineating acceptance/rejection regions for
good or bad unless it is truly abnormal, by looking

k and q for multiple sensors, combining traffic dynam
at the time series of measurements for an entire day,

ics theory and manual identification of good or bad
one can usually easily distinguish bad behavior from
data points, with the help of interactive data analy

good.

This procedure effectively corresponds to a model in

which flow and occupancy measurement failures are
independent and identically distributed across loops.
The trajectory of detector /, {q? (t)\ki(t)\t = 1,... ,T}
is a point in the product space (2 x K x T, where (2,
X and T are the space of q, k and t. Unlike the Wash
ington algorithm, the partition is complicated and im

possible to visualize.
The Daily Statistics Algorithm uses many samples
(time points) of a single detector. Its main drawbacks
are (1) that the day-by-day decision is too crude, and

(2) the spatial correlation of good samples is not ex
ploited. Because of (1), a moderate number of bad
samples at an otherwise good detector will never be
flagged. By (2), we mean that some errors that are not
visible from a single detector can be readily recognized
if its relationship with its spatial and temporal neigh

bors is considered. For example, for neighboring de

sis tools such as XGobi (http://www.research.att.com/
areas/stat/xgobi/), and an intelligent way of combining
evidence from various sensors to make decisions about
a particular sensor/observation.

4. IMPUTATION
Holes in the data due to missing or bad observa
tions must be filled with imputed values. Because of
the high lane-to-lane and location-to-location correla
tion of q and k, it is natural to use measurements from
neighboring detectors. Although there is flexibility in
the choice of a neighborhood, in practice we use the
neighborhood defined by the set of loops at the same
location. Let N(i) denote the set of neighboring detec
tors of / and consider imputing flow, for example.

A natural imputation algorithm is the prediction of
qi (t) based on its neighbors:

(2) qi(t) = g(q^(i)(t)),

tectors / and j, if the absolute difference \q? (t) ? qj (t) \

is too big, either A/ = 1 or Ay = 1 or both. This
has to do with the high lane-to-lane (and location
to-location) correlation of both q and k. Figure 1 il
lustrates these points. Loops in the first and second
lanes suffer from transient malfunctions, which cannot

be easily detected from one-dimensional marginal dis
tributions, but which are immediately clear from the
two-dimensional joint distributions. From their rela
tionships with lanes three and four, one can conclude
that both detectors are bad.

The Washington algorithm and the DSA are ad hoc
in conception, and can surely be improved upon. A sys

tematic and principled algorithm is hard to develop
mainly due to the size and complexity of the problem.

where the prediction function g is fit from histori
cal data {(qi(t), q<u(i)(t),t = 1,..., T)}. (Note that the
prediction function must be able to properly take into

account possible configurations of missing and bad
values among the neighbors; the latter are especially
problematic, since bad readings may not be flagged as

such.)

The simplest idea would be estimation by the mean

qi(d, t) = ?-^

ZJ^{i)\(AJ(d,t) = 0)

YI qj(d,t)l{?j(d,t) = 0)

jeMd)

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

MEASURING TRAFFIC 587

or median

5. ESTIMATING VELOCITY

qi(d, t) = median{gy(<i, t):je J^(i), Ay(d, t) ? 0}
to be more robust. However, such simple interpolation
is not desirable since the relationships between occu
pancy and flows in neighboring loops are nontrivial,

As we have noted earlier, single-loop detectors do
not directly measure velocity. This is unfortunate, be
cause velocity is perhaps the single most useful vari
able for traffic control and traveller information sys

that is, q?(t) ^ qj(t), j ? JV(/), in general. For ex

tems. In this section we present the method currently
being used to estimate velocity from single-loop data.

ample, at many freeway locations, the inner lane has
higher flow and lower occupancy for general free flow
condition than do the outer lanes. Also, if one is close

sider the following situation. Suppose that at a given
detector during a 30-second time interval, N vehicles

to on- or off-ramps, the relationships can be quite dif
ferent.

The prediction function is rather hard to manage in
its full generality because of its high dimensionality
and because one does not know which values will cor
respond to correctly functioning detectors [Ay (t) = 0].
From a computational point of view, the following al

gorithm is thus appealing:

Let us fix a day d and a time of day t and con

pass with (effective) lengths L\,..., L^ and velocities
v\, ..., vn- (The effective vehicle length is equal to the
length of the vehicle plus the length of the loop's detec

tor zone.) The occupancy is given by k = YliLi Li/v?.

Now, if all velocities are equal, v ? v\ ? = v^, it
follows that

l" NL

(4) fc=-^L/ =-,
v

i?\

(3) qi(t) = average(<?/y(0:j e ?A/"(/), A/ =0),

where q??(t) ? gij(qj(t)) is the regression of qi(t)
on q?(t). One computes qtj(t) for all j e <N(i) and
averages over only those values regressed on "good"
neighbors. The "average" can be either mean or a ro
bust location estimate such as the median. The latter
seems preferable since all bad samples from detectors
j e JS(i) may not be flagged.
Individual regression function g/y (q? (t)) can be fit in

various ways. Chen et al. (2003) considered the linear

regression

qi (t) = ao(i, j) + oi\ 0", j)qj(0 + noise
to produce

qij(d,t)=ao(iJ)+ct\(iJ)qj(d,t)
for each pair of neighbors (/, j), where the parameters

ao0\ j), oc\(i, j) are estimated by the least square us
ing historical data. This is the approach currently being

used by PeMS.
Since this approach relies upon using historical data
to learn how pairs of neighboring loops behave, estima
tion of the regression functions must be able to cope

with bad data as well. Cleaning the historical data to
detect malfunctions is thus necessary, and robust esti
mation procedures may be preferable to least squares.
We also note that an empirical Bayes perspective may
be useful in jointly estimating the large set of regres
sion functions.

.,

v

where L ? J2?=\L?/N is the average of the vehi
cle lengths. We see that if the average vehicle length

is known, we can infer the common velocity. We
model the lengths L; as random variables with com
mon mean ?. Note that the L; and L are not directly
observed. If ? were known, while the average L is
not, then a sensible estimate of the common velocity
may be obtained by replacing the average by the mean

in (4):

. N?

(5) v = ~r-'
k

Rewriting, we find v = v?/L. Since the ex

\/L is not equal to l/?, the expectation

equal to v. In other words, v is not an un
tor of v, despite our assumption that all
However, if the number of vehicles N is

then L should be reasonably close to its m
bias negligible. Henceforth, we neglect th
and use formula (5) to estimate velocity. W
on estimating the mean vehicle length, ?

5.1 Estimation of the Mean Vehicle Len

Currently, it is a widespread practice
mean vehicle length to be constant, in

the time of day. The validity of this assu

been examined by many authors (e.g.,
saud, 1989 and Pushkar et al., 1994), i
selves (Jia et al., 2001) and it is now ge

nized that it does not generally hold. Thi
illustrated by double-loop data from Inter

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

588

P. J. BICKEL ET AL.

1.5 2 2.5
time (days)

1.5 2 2.5
time (days)

FIG. 3. Velocity (top) and effective vehicle length (bottom) for four weekdays on 7-80.

San Francisco, which allows direct measurement of ve
locity. Figure 3 shows the velocity and the average (ef
fective) vehicle length at detector station 2 in the east
bound outer lane 5. We believe that the clear daily trend
can be ascribed to the ratio of trucks to cars varying
with the time of day. This is confirmed by the fact that
the vehicle length in the fast lanes 1 and 2, with neg
ligible truck presence, is almost constant. We thus as
sume that the mean vehicle length depends on the time
of day, denote it by ?t to reflect this dependence, and
consider how ?t can be estimated.

Suppose we have observed N(d,t) and k(d,t) for
a number of days. Let ao.6 denote the 60th percentile

of the observed occupancies. Assume that during all
time intervals when k(d, t) < ofo.6 all vehicles travel at
a common velocity vpf. Since we may assume that any
freeway is uncongested at least 60% of the time, Vff
may be regarded as the free flow velocity. Throughout
this paper we assume that Vff is known or estimated
from exterior sources of information.
By our assumption on constant free flow velocity, we
have for all (d, t) such that k(d, t) < ao.6

-iA , vFFk(d,t)

L(d, t) =-.

N(d,t)

If we assume that the average vehicle length L(d,t)
does not depend on whether the occupancy is above or
below the threshold, then

E(L(d, t) | k(d, t) < ao.?) = EL(d, t) = ?t.

For fixed t we can obtain an unbiased estimate of ?it as

._1_ Y^ VFFk(d,t)

^~nd:k(dj)<ao.6}d.k?<ao6 N{d,t)
In Figure 4 we have plotted the time of day t versus

vppk(d, t)/N(d, t) for all times (d, t) when k(d, t) <
ao.6- We can now estimate the expectation jnt of the ef
fective vehicle length by fitting a regression line to this

scatter plot, via loess (Cleveland, 1979). The smooth
regression line seen in Figure 4 is our estimator fit
of ?it. Note the absence of points for times between
3 P.M. and 6 P.M. when 1-80 East is always congested
[k(d, t) > ao.6].
Once we have an estimator ?Xt of \?t, we define a
(preliminary) estimator of v(d, t) as

(?\
A N(d^^t
(6) *(A
v(df0
= __

This estimator and the velocity found
loop detector are plotted in Figure 5.
performs very well during heavy traff
tion. In particular, it exhibits little bias

period 3 P.M. to 6 P.M. over which t

shown in Figure 4 was extrapolated. Unf
variance of the estimator during times o

particularly in the early hours of eac

ceptably large. This is clearly visible in

estimated velocities on day 3 around
ing up to 120 mph shortly before plu

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

589

MEASURING TRAFFIC

10i-1-1-1-1-1
0

5

10

15

20

time

FlG.

mph.

at
is

64

Estimation

?t.

of

true
velocity
have
a
large

mph.age
Recall
that
vehicle
l

obtained

cle
a

The

4.

25

(hours)

length
When

given

by
the

replacing
mean.
Fo

L(d,t) a
by
(a
makes
big
d

only
a
few
7
cars
and ve
3

time
t
of interval,
our
prelim

1.5

2

2.5

time (days)

FlG. 5. Our preliminary estimate, defined in (6), superimposed on the true velocity.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

590 P. J. BICKEL ET AL.

5.2 Smoothing

and C is a smoothing parameter to be specified. If the
time interval is of length 5 minutes, then a reasonable
value would be C = 50. With this value of C, if the vol

Coif man (2001) suggests a simple fix for the unsta
ble behavior of v during light traffic. He sets the es
timated velocity equal to the free flow velocity vpp
when the occupancy is low:
^coifmanV/2, U ?

ume N(d,t) approaches capacity, say N(d,t) = 100
vehicles per 5 minutes, then there is hardly any need

for smoothing and the new observation receives sub
stantial weight 2/3. On the other hand, if the volume
is very small, say N(d,t) = 10, then the smoothing
is quite severe with the new observation receiving a
weight of only 1/6.
Our filtered estimator v is plotted in Figure 6. The
correspondence with the true velocity is very good.
The large variability during light traffic that plagued

v(d, t), if k(d, t) > ao.6,

vpp, otherwise.

The performance of this estimator, in terms of mean
squared error, is certainly not bad. However, about 16
out of every 24 hours (60%), the estimated velocity is
a constant and that is not realistic. We can do better, in
appearance as well as in mean squared error.
It is clear that we need to smooth our preliminary es
timate v(d,t), but only when the volume is small. For
the purpose of real-time traffic management, it is im
portant that our smoother be causal and easy to com

the preliminary estimator v has been suppressed, while
its good performance during heavy traffic and conges
tion has been retained.

We will now explain how our filter is "inspired" by

pute with minimal data storage. Taking all this into

the familiar Kaiman filter. Suppose that the true, unob

consideration, we used an exponential filter with vary

served velocity evolves as a simple random walk:

ing weights. A smoothed version v of v is defined re

(9) vt = vt-i+et, et~M(0,r2).

cursively as

(7)

v(d, t) = w(d, t)v(d, t)

Suppose we observe vt ~ NtjXt/kt ? vt?t/Lt, where

?t is our estimate of ELt ? ?t. We will work con
ditionally on the observed volume Nt. The condi
tional expectation of vt is?though not quite equal?

+ (1 -w{d,t))v{d,t- 1),

where

N(d,t)
(8) w(d,t) =N(d,t) + C'

hopefully close to vt. Using a one-step Taylor approxi
mation, we find that the conditional variance of vt is of

1.5

2

2.5

time (days)

FIG. 6. Our estimate V, defined in (7), superimposed on the true velocity.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

MEASURING TRAFFIC 591
the order l/Nt. This "inspires" a measurement equa

tion

(10)

Table 1
Measured average free flow speeds (mph)/or each lane (rows) of a
multilane freeway depending on the total number of

lanes (columns)

vt = vt + &,

t;t^Jf(0,cr?) = M(0,a2/Nt).

Finally, we assume that all error terms et and %t are in

dependent. Note that the variance of the measurement
error ?f depends inversely on the observed volume Nt.
In light traffic, when Nt is small the variance is large.
This is exactly the problem we noted in Figure 5.

Number of lanes

Lane number 2 3 4 5
1 71.3 71.9 74.8 76.5
2 65.8 69.7 71.0 74.0
3 62.7 67.4 72.0
4 62.8 69.2
5 64.5

The Kaiman filter recursively computes the condi
tional expectation of the unobserved state variable vt
given the present and past observations v\, V2,. , vt:

vt =E(vt | vi,v2,...,vt).
In our simple model we can easily derive the Kaiman
recursions. They are

vt = wtvt + (l -wt)vt-\,

with

5.4 Further Assumptions on Mean Vehicle Length
We have assumed that the mean (expected) vehicle
length ?jit depends on the time of day only. However,
we have noticed that put also depends on:

1. Day of the week. The vehicle mix on a Monday dif
fers from a Sunday.

2. Lane. There is a higher fraction of trucks in the
outer lanes.

3. Location of the detector station. Certain routes are
more heavily traveled by trucks than others.
Wt Pt-i + r2 + a2 Nt + a2/(Pt-i 4.+Detector
r2) 'sensitivity. Loop detectors are fairly crude
instruments that are almost impossible to calibrate
where Pt is the prediction error E(vt ? vt)2.accurately. If a detector is not properly calibrated,
We note the similarity of these Kaiman recursions
the occupancy measurements will be biased.

fi-i+r2 Nt

with our filter (7), although C in (7) is constant and
To account
for all this, we must form separate estimates
the analogue in the Kaiman filter is not.
We decided

of fjLt to cover these different situations. We store esti
not to try to estimate a2 and r2 partly because we feel
mates of pit
for every 5-minute interval, for every day
that would be difficult to do reliably and partly
because
of the week and for every lane at every detector station.

that would mean taking our simple model a little too
In real time, the appropriate values are retrieved, mul
seriously.
tiplied by the observed volume-to-occupancy ratio and
filtered.
5.3 Known Free Flow Velocity
We assume that the free flow velocity Vff is known,

which is typically not true. We believe that free flow
velocity depends primarily on the number of lanes and
on the lane number, so in practice we use values like

those shown in Table 1, which are loosely based on
experience and empirical evidence from locations with
double-loop detectors.
Clearly, it would be preferable to have an indepen
dent method to estimate site-specific free flow velocity.

Petty et al.'s (1998) cross-correlation approach works
well when occupancy and volume are measured in
1-second intervals. However, 20- or 30-second mea
surement intervals are more common and at such ag
gregation this method breaks down.

5.5 Other Methods
We briefly review two other methods that also do
not assume a fixed value for L(d,t), beginning with
a method described in Jia et al. (2001). Suppose that
we have a state variable X(d,t) which is 0 during con
gestion and 1 during free flow. The state variable may
be defined, for instance, by thresholding the occupancy

k(d,t). While the state is "free flow," the algorithm
tracks L(d, t), assuming constant free flow velocity. As
soon as the state becomes "congested," L(d, t) is kept
fixed and the velocity v(d, t) is tracked.

The main problem we experienced with this algo
rithm is that it depends crucially on X(d, t). In par
ticular, if X(d, 0 = 1 (frce flow) while congestion has

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

592 P. J. BICKEL ET AL.
already set in, the method goes badly astray. We found
it difficult to develop a good rule to define X(d,t). In
fact, this difficulty was the main reason for us to look
for a different approach.

Building on work of Dailey (1999), Wang and Ni
han (2000) propose a model-based approach to esti
mate L(d,t) and v(d,t). Their log-linear model relates
L(d,t) to the expectation and variance of the occu
pancy k(d,t), to the volume N(d,t) and to two in
dicator functions that distinguish between high flow
and low flow situations. The model has five parameters
which need to be estimated from double-loop data. It is
not at all clear if these parameter estimates carry over

to a particular, single-loop location of interest. Wang
and Nihan (2000) defer this issue to future research.

6. PREDICTION
We now turn our attention to travel time predic
tion between any two points of a freeway network
for any future departure time. Regular drivers, such

as commuters, choose their routes based on histori

cal experience, but factors including daily variation in
demand, environmental conditions and incidents can

change traffic conditions. Since heavy congestion oc

curs at the time that most drivers need travel time infor

mation, free flow travel times, such as those provided
by MapQuest, are of little use. The result may be ineffi
cient use of the network. Route guidance systems based
on current travel time predictions such as variable mes
sage boards could thus improve network efficiency.
We are currently developing an Internet application
which will give the commuters of Caltrans District 7
(Los Angeles) the opportunity to query the prediction
algorithm we describe below. The user will access our
Internet site and state origin, destination and time of
departure (or desired time of arrival), either using text
input or interactively querying a map of the freeway
system by pointing and clicking. He or she will then

receive a prediction of the travel time and the best
(fastest) route to take. It would also be possible to make
our service available for users of cellular telephones,
and in fact we plan to do so in the near future.

6.1 Methods of Prediction
The task is to forecast the time of a trip from loop a
to loop b departing at some time in the future, using
the information recorded up to the current time from

all intervening loop detectors. One possible approach
would be to model the physical process of traffic flow,

using, for example a simulation program such as those

mentioned in the Introduction. However, such simula

tions would have to be run in real time and be cali

brated precisely. In general, it is not clear that the best

way to predict a functional of the complex process of
traffic flow is via modeling the entire process. For this

reason, various purely statistical approaches, includ
ing multivariate state-space methods (Stathapoulis and
Karlaftis, 2003), space-time autoregressive integrated
moving average model (Kamarianakis and Prastacos,
2005), and neural networks (Dougherty and Cobbett,
1997; Van Lint and Hoogendoorn, 2002) have been

proposed.

It is not obvious how to use the information from

all the intervening loops, but we have found a method

based on a simple compression (feature) of this data
to be remarkably effective (Rice and van Zwet, 2004;

Zhang and Rice, 2003). From v evaluated at an array
of times and loops, we can compute travel times T?(t)
that should approximate the time it took to travel from
loop a to loop b starting at time t on day d, by "walk
ing" through the velocity field. We can also compute a
proxy for these travel times which is defined by

(11) T?(t) = Y-?-,

d ^avi(d,t) + vi+l(d,ty

where u? denotes the distance from loop / to loop
(/ + 1). We call T* the current status travel time (a.k.a.
the snap-shot or frozen field travel time). It is the travel

time that would have resulted from departure from
loop a at time t on day d were there no changes in the

velocity field until loop b was reached. It is important
to notice that the computation of T?(t) only requires
information available at time t, whereas computation
of T?(t) requires information at later times.
Suppose we have observed v?(d, t) for a number of

days d e D in the past, that a new day e has begun,
and we have observed v\(e, t) at times t < x. We call x
the "current time." Our aim is to predict Te(x + <5), the
time a trip that departs from a at time r + <5 will take
to reach b. Note that even for 8 = 0 this is not trivial.

Define the historical mean travel time as

(12) ^^E^
' ' deD

Two naive predictors of Te(r + 8) are T*(x) and
v(r + 8). We expect?and indeed this is confirmed by
experiment?that T*(x) predicts well for small S and
v (x + 8) predicts better for large 8. We aim to improve
on both these predictors for all 8.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

MEASURING TRAFFIC 593
6.1.1 Linear regression. From the extensive PeMS
data, we have observed an empirical fact: that there ex

ist linear relationships between T*(t) and T(t + 8) for
all t and 8. This empirical finding has held up in all of
numerous freeway segments in California that we have
examined. It is illustrated by Figures 7 and 8, which
are scatter plots of T*(t) versus T(t + 8) for a 48-mile
stretch of I-10 East in Los Angeles. Note that the rela
tion varies with the choice of t and 8. We thus propose
the following model:

(13) T(t + 8)= a(i, 8) + ?(t, 8)T*(t) + s,
40 60 80 100 120

where s is a zero mean random variable modeling ran
dom fluctuations and measurement errors. Note that the
parameters a and ? are allowed to vary with t and 8.
Linear models with varying parameters are discussed
in Hastie and Tibshirani (1993).

Tstar(3 pm) (minutes)

FlG. 8. r*(3 RM.) vs. T(3 P.M. + 60 min). A
regression line with slope a(3 P.M., 60 min)
?(3 P.M., 60 min) = 9.5.

Fitting the model to our data is a familiar lin
ear regression problem which we solve by weighted
least squares. Define the pair (?(t, 8), ?(t, 8)) to mini

mize

(15) fe(x + 8) = a(x, 8) + ?(x, 8)T*(x).

J2(Td(s)-a(t,8)-?(t,8)T*(t))2
deD
(14)

change abruptly. The actual predictio

comes

seT

-K(t + 8-s)9

where K denotes the Gaussian density with mean zero

Writing a(t, 8) = a'(t, 8)v(t + 8), we see that

expresses a future travel time as a linear combinat

of the historical mean and the current status travel tim

our two naive predictors. Hence our new predictor

be interpreted as the best linear combination of

and a variance which is a bandwidth parameter. The

naive predictors. From this point of view, we can

purpose of this weight function is to impose smooth

pect our predictor to do better than both, and it do
is demonstrated below.

ness on a and ? as functions of t and 8. We as
sume that a and ? are smooth in t and 8 because

we expect that average properties of the traffic do not

Another way to think about (13) is by remember
that the word "regression" arose from the phrase

gression to the mean." In our context, we woul

pect that if T* is much larger than average, signif
severe congestion, then congestion will probably
during the course of the trip. On the other hand,
is much smaller than average, congestion is unusu
light and the situation will probably worsen durin

journey.
In addition to comparing our predictor to the histor
ical mean and the current status travel time, we sub

ject it to a more competitive test. We consider two
other predictors that may be expected to do well, one
resulting from principal component analysis and one

from the nearest-neighbors principle. Next, we de

40 60 80 IOC) T2?"
Tstar(9 am) (minutes)

scribe these two methods.

6.1.2 Principal components. Our predictor T only

uses information
at one time point: the "current
FlG. 7. 7*(9 A.M.) vs. T(9 A.M. + 0 min). Also shown
is the
regression line with slope a(9 A.M., 0 min) = 0.65 and
intercept
time"
x. However, we do have information prior to that

?(9 a.m., 0 min) = 17.3.

time. The following method attempts to exploit this by

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

594 P.J.BICKELETAL.

known up to time r.

dosest days in D and bases a prediction on a (possibly
weighted) combination of these. However, neither of

Formally, let us assume that the travel times on dif
ferent days are independently and identically distrib

vanilla TNN.

uted and that for a given day d, {Td(t):t e T} and

6.2 Results

using the entire trajectories of Te and T* which are

{T?(t) : t 6 T} are jointly multivariate normal. We es
timate the large covariance matrix of this multivari
ate normal distribution by retaining only a few of the

largest eigenvalues in the singular value decomposi
tion of the empirical covariance of {(Td(t),T?(t)):

these variants appears to significantly improve on the

To compare these methods we used flow and oc
cupancy data from 116 single-loop detectors along
48 miles of I-10 East in Los Angeles (between post
miles 1.28 and 48.525). Measurements were done at

d Dj eT}. Define tf to be the largest t such that

5-minute aggregation at times t ranging from 5 A.M. to

t + Te(t) <x. That is, t' is the (random) start time of

9 P.M. for 34 weekdays between June 16 and Septem
ber 8, 2000. We used the methods we have previously

the latest trip that we would have seen completed if we
observed day d until time x. With the estimated covari
ance we can now compute the conditional expectation

of Te(x + 8) given {Te(t):t < t'} and {T*(t):t < x}.
This is a standard computation which is described, for
instance, in Mardia et al. (1979). The resulting predic

described to convert flow and occupancy to velocity.

The quality of our I-10 data is quite good and we
have used simple interpolation to impute wrong or
missing values. The resulting velocity field v?(d, t) is
shown in Figure 9 where day d is June 16. The hori
zontal streaks typically indicate detector malfunction.

tor is f/c(r + 8).
6.1.3 Nearest neighbors. As an alternative, we now
consider another attempt to use information prior to the

current time r, based on nearest neighbors. This non
parametric method makes fewer assumptions (such as
joint normality) on the relation between T* and T than
does the principal components method, but is tied to a
particular metric.

The nearest-neighbor method uses that day in the
past which is most similar to the present day in some
appropriate sense. The remainder of that past day be
yond time x is then taken as a predictor of the remain
der of the present day.
The method requires a suitable distance m between
days. We have investigated two possible distances:

From the velocities we computed travel times for
trips starting between 5 A.M. and 8 P.M. Figure 10
shows these T?(t) where time of day t is on the hori
zontal axis. Note the distinctive morning and afternoon
congestions and the huge variability of travel times, es

pecially during those periods. During afternoon rush
hour we find travel times of 45 minutes to up to two
hours. Included in the data are holidays July 3 and 4
which may readily be recognized by their very short
travel times.

We have estimated the root mean squared (RMS) er
ror of our various prediction methods for a number of

"current times" r (r = 6 A.M., 7 A.M.,..., 7 P.M.) and
lags 8 (8 = 0 and 60 minutes). The RMS errors were

(16) mi(e,d)= ? \vi(e,t)-vt(d,t)\
i=a,...,b,t<r

and
/ \1/2

(17) m2(e, d) = ( ?(7;*(0 - Tj(t))2\ .

Now, if day d' minimizes the distance to e among all
d e D, our prediction is

(18) TeNN(r + 8) = TAr + 8).
Sensible modifications of the method are windowed
nearest neighbors and k-nearest neighbors. Windowed

NN recognizes that not all information prior to x is
equally relevant. Choosing a window size w, it takes
the above summation to range over all t between x ? w
and r. The k -nearest neighbor modification finds the k

time of day

FIG. 9. Velocity field V(d, /, /) where day d = June 16, 2000.
Darker shades indicate lower speeds.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

MEASURING TRAFFIC

E
0 O

E

10

15

time of day

FIG. 10. Travel times T??(-) for 34 days on a 48-mile stretch of

12 14
time of day.

I-lOEast.

Fig. 12. Estimated RMSE, lag = 0 minutes. Principal compo
nents (- -), nearest neighbors (-) and linear regression (?).

estimated by leaving out one day at a time, performing
the prediction for that day on the basis of the remain
ing other days, and averaging the squared prediction

dictor (15) for lag 8 equal to 0 and 60 minutes,

errors.

rent status predictor T*(x) and our regression pre
respectively. Note how T*(x) performs well for small
8 (8 = 0) and how the historical mean does not become

The prediction methods all have smoothing parame worse as 8 increases. Most importantly, however, no
ters that must be specified. For the regression methodtice how the regression predictor dominates both.

we chose the standard deviation of the Gaussian ker Figures 12 and 14 again show the RMS prediction

nel K to be 10 minutes. For the principal compo
error of the regression estimator. This time, it is com
nents method we chose the number of eigenvalues repared to the principal components predictor and the
tained to be four. For the nearest-neighbors method we
nearest-neighbors predictor (18). Again, the regres
have chosen distance function (17), a window w of
sion predictor comes out on top, although the nearest

20 minutes and the number k of nearest neighbors toneighbors predictor shows comparable performance.
be two. The results were fairly insensitive to these pre The RMS error of the regression predictor stays be
cise choices.
low 10 minutes even when predicting an hour ahead.

Figures 11 and 13 show the estimated RMS predic
We feel that this is impressive for a trip of 48 miles
tion errors of the historical mean v(x + 8), the curthrough the heart of Los Angeles during rush hour.

12 14
time of day.

FlG. 11. Estimated RMSE, lag ? 0 minutes. Historical mean
(- - -), current status (-) and linear regression (?).

12 14
time of day.

FlG. 13. Estimated RMSE, lag =
(- -), current status (-) and lin

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

596 P. J. BICKEL ET AL.
instance, when predicting travel times across net
works (graphs), we need only predict travel times
for the edges and then use (19) to piece these to
gether to obtain predictions for arbitrary routes.

2. In the discussion above we regressed the travel
time Td(t + 8) on the current status T*f(t), where
Td(t + 8) is the travel time departing at time t + 8.
Now, define Sd(t) to be the travel time arriving at

time t on day d. Regressing Sd(t + 8) on T?(t) al

12 14

lows us to make predictions on the travel time sub
ject to arrival at time t + 8. The user can thus ask
what time he or she should depart in order to reach
an intended destination at a desired time.

time of day.

FlG. 14. Estimated RMSE, lag = 60 minutes. Principal compo
nents (- -), nearest neighbors (-) and linear regression (?).

Comparison of the regression predictor to the prin
cipal components and nearest-neighbors predictors is
surprising: the results indicate that given jP*(t), there
is not much information left in the earlier T*(t) (t < r)
that is useful for predicting T(x + S), at least by the
methods we have considered. In fact, we have come to
believe that for the purpose of predicting travel times,
all the information in the vi(d, t) up to time x is well

summarized by one single number: T*(t).
Recently, Nikovski et al. (2005) compared the per
formance of several statistical methods on data from a
15-km stretch of freeway in Japan. Their conclusions

mirrored ours: a regression approach outperformed
neural networks, regression trees and nearest-neighbor
methods. They also reached the conclusion that the pre
dictive information is contained in the current travel

7. CONCLUSION
Modern communication and computational facilities
make possible, in principle, systematic use of the vast
quantities of historical and real-time data collected by
traffic management centers. Such efforts invariably re
quire substantial use of statistical methodology, often
of a nonstandard variety, sensitive to computational ef
ficiency.

This paper has concentrated on data collected by
inductance loops in freeways, but similar data is of
ten available on arterial streets as well, which have
more complex flows and geometry. There is also in
formation from other types of sensors. For example,

declining costs make video monitoring an attractive
technology, bringing with it challenging problems in

computer vision and statistics. As another example,
data derived from transponders installed in individual

vehicles for automatic toll payments is a potentially
rich source of information about traffic flow, since the

time.

tags can in principle be sensed at locations other than
toll booths. Effective extraction of information will re

6.3 Further Remarks

quire active collaborations of statisticians, traffic engi
neers, and specialists in various other disciplines.

It is of practical importance to note that our predic
tion can be performed in real time. Computation of the

parameters ? and ? is time consuming but it can be
done off-line in reasonable time. The actual prediction
is then trivial to compute.
We conclude this section by briefly pointing out two
extensions of our prediction method:
1. For trips from a to c via b we have

(19)

Td(a,c,t) = Td(a,b,t)
+ Td{b9c,t + Td(a,b,t)).

We have found that it is sometimes more practical
or advantageous to predict the terms on the right

hand side than to predict Td(a,c,t) directly. For

ACKNOWLEDGMENTS
This study is part of the PeMS project, which is sup
ported by grants from Caltrans to the California PATH
Program. We are very grateful to Caltrans Traffic Op
erations engineers for their support. Our research has
also been supported in part by grants from the National

Science Foundation.

The contents of this paper reflect the views of the
authors, who are responsible for the facts and the ac
curacy of the data presented herein. The contents do
not necessarily reflect the official views of or policy
of the California Department of Transportation. This
paper does not constitute a standard, specification or

regulation.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

MEASURING TRAFFIC 597

REFERENCES
Chen, C, Kwon, J., Rice, J., Skabardonis, A. and
Varaiya, R (2003). Detecting errors and imputing missing
data for single loop surveillance systems. Transportation Re
search Record no. 1855, Transportation Research Board 160?

167.

Cleveland, W. S. (1979). Robust locally weighted regression
and smoothing scatterplots. J. Amer. Statist. Assoc. 74 829-836.

MR0556476

Coifman, B. A. (2001). Improved velocity estimation using sin
gle loop detectors. Transportation Research A 35 863-880.
CORSIM. http://www-mctrans.ce.ufl.edu/featured/TSIS/Version5/
corsim.htm.

Dailey, D. J. (1999). A statistical algorithm for estimating speed
from single loop volume and occupancy measurements. Trans
portation Research B 33 313-322.

Dougherty, M. S. and Cobbett, M. R. (1997). Short-term
inter-urban traffic forecasts using neural networks. International

J. Forecasting 13 21-31.
DYNASMART. http://www.dynasmart.com/.

Hall, F. L. and Persaud, B. N. (1989). Evaluation of speed
estimates made with single-detector data from freeway traffic

management systems. Transportation Research Record 1232 9

16.

Hastie, T. and Tibshirani, R. (1993). Varying-coefficient mod
els (with discussion). /. Roy. Statist. Soc. Ser. B 55 757-796.

MR1229881

Helbing, D. (2001). Traffic and related self-driven many-particle
systems. Rev. Mod. Phys. 73 10671141.

Jacobson, L., Nihan, N. and Bender, J. (1990). Detecting er
roneous loop detector data in a freeway traffic management sys

tem. Transportation Research Record 1287 151-166.

Jia, Z., Chen, C, Coifman, B. A. and Varaiya, R P.
(2001). The PeMS algorithms for accurate, real-time estimates
of g-factors and speeds from single-loop detectors. Intelligent
Transportation Systems. Proceedings IEEE 536-541.

Kamarianakis, Y. and POULICOS, P. (2005). Space-time mod
eling of traffic flow. Computers and Geosciences 31 119-133.

Mardia, K. V, Kent, J. T. and Bibby, S. M. (1979). Multivari
ate Analysis. Academic Press, London.

Nikovski, D., Nishiuma, N., Goto, Y. and Kumazawa, H.
(2005). Univariate short term prediction of road travel times. In
ternational IEEE Conference on Intelligent Transportation Sys

tems 1074-1079.

Papageorgiou, M. (1983). Applications of Automatic Control
Concepts to Traffic Flow Modeling and Control. Springer,

Berlin. MR0716500
Papageorgiou, M., Bloseville, J.-M. and Hadj-Salen, H.

(1990). Modelling and real-time control of traffic on the south

ern part of Boulevard P?riph?rique in Paris?Parts I: Mod
elling, and II: Coordinated on-ramp metering. Transportation
Research A 24 345-370.
Paramics. http://www.paramics.com/.

Payne, H. J., Helfenbein, E. D. and Knobel, H. C. (1976).
Development and testing of incident detection algorithms. Tech

nical Report FHWA-RD-76-20, Federal Highway Administra
tion.

Petty, K. F., Bickel, P. J., Jiang, J., Ostland, M., Rice, J.,
RlTOV, Y. and SCHOENBERG, F. (1998). Accurate estimation
of travel times from single-loop detectors. Transportation Re

search A 32 1-17.

Pushkar, A., Hall, F. L. and Acha-Daza, J. A. (1994). Esti
mation of speeds from single-loop freeway flow and occupancy
data using cusp catastrophe theory model. Transportation Re

search Record 1457 149-157.

RICE, J. and van Zwet, E. (2004). A simple and effective method
for predicting travel times on freeways. IEEE Transactions on
Intelligent Transportation Systems 5 200-207.

Stathopoulis, A. and Karlaftis, M. G. (2003). A multivari
ate state space approach for urban traffic flow modeling and pre

diction. Transportation Research C 11 121-135.
TRANSIMS, http://transims.tsasa.lanl.gov/.
TRANSYT. http://www.trlsoftware.co.uk/products/detail.asp?aid=

4&c=2&pid=66.
Van Lint, J. W. C. and Hoogendoorn, S. P. (2002). Freeway
travel time prediction with state-space neural networks. In 81st

Annual Transportation Research Board Meeting.

Yu, N., Zhang, H. M. and Lee, D.-H. (2004). Models and al
gorithms for the traffic assignment problem with link capacity
constraints. Transportation Research B 38 285-312.

Wang, Y. and Nihan, N. (2000). Freeway traffic speed estimation
with single loop outputs. Transportation Research Record 1727

120-126.

VISSIM. http://www.trafficgroup.com/services/vissim.html.

Zhang, X. and Rice, J. (2003). Short-term travel time prediction
using a time-varying coefficient linear model. Transportation

Research C 11 187-210.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:26 UTC
All use subject to https://about.jstor.org/terms

