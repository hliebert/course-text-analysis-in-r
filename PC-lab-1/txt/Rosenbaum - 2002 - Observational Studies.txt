Springer Series in Statistics
A dvisors : P. Bickel, P. Diggle, S. Fienberg, K. Krickeberg, I. Olkin, N. Wermuth, S. Zeger
Springer Science+Business Media, LLC

Springer Series in Statistics
Anders en/Borgan/Gill/Keidin g: Statistical Mod els Based on Counting Processes. Atkinson/Riani: Robust Diagnotstic Regression Analysis . Berger: Statistical Decision Theory and Bayesian Analysis, 2nd edition. Bolfarine/Za cks : Prediction Theory for Finite Populations. Borg/Groenen: Modem Multidimensional Scaling: Theory and Applications Brockwell/Da vis: Time Series: Theory and Methods , 2nd edition. Chan/Tong: Ch aos: A Statistical Perspective. CheniShao/Ibrah im: Monte Carlo Method s in Bayesian Computation . David/Edwards: Annotated Readings in the History of Statistics. Devroye/Lugosi : Combinatorial Methods in Density Estimation. Efromo vich: Nonparametric Curve Estimation : Methods, Theo ry, and Appli cations. Eggermont/LaRiccia: Maximum Penalized Likelihood Estimation, Volume I:
Density Estimation. Fah rmeir/Tutz: Multivariate Statistical Modelling Based on Generalized Linear
Models , 2nd edition. Farebrother: Fitting Linear Relationships: A History of the Calculus of Observations
1750-1900. Federer: Statistical Design and Analysis for Intercropping Experiments, Volume I:
Two Crop s. Federer: Statistical Design and Analysis for Intercropping Experiments, Volume II:
Three or More Crops. Fienberg/H oagliniKru skalfTanur (Eds.): A Statistical Model : Frederick Mosteller's
Contributions to Statistics, Science and Public Polic y. Fisher/Sen: The Collected Works ofWassily Hoeffding. GlaziNauslWalienstein: Scan Statistics. Good: Permutat ion Tests: A Practical Guide to Resampling Methods for Testing
Hypothese s, 2nd edition. Gouri eroux : ARCH Models and Financial Applications. Grandcll: Aspects of Risk Theory, Haberman : Advanced Statistics, Volume I: Descript ion of Populations . Hall: The Bootstrap and Edgeworth Expansion . Hardi e: Smoothing Techniques: With Implementation in S. Harrell: Regression Modeling Strategies: With Applications to Linear Mod els,
Logistic Regression, and Survival Analysis Hart: Nonparametric Smoothing and Lack-of-F it Tests . Hartigan : Bayes Theory. Has tie/Tibshirani/Friedman: The Elements of Statistical Learning: Data Mining,
Inference , and Prediction Hedayat/Sloane/Stujken: Orthogonal Arrays: Theory and Applications. Heyde: Quasi-Likelihood and its Applicat ion : A General Approach to Optimal
Parameter Estimation. Huet/Bou vier/Gruet/Jolivet: Statistical Tools for Nonl inear Regression: A Pract ical
Guide with S-PLUS Examples. Ibrahim/CheniSinha : Bayesian Survival Analysis. KoleniBrennan : Test Equating: Methods and Practices.
(continued aft er index)

Paul R. Rosenbaum
Observational Studies
Second Edition
, Springer

Paul R. Rosenbaum Department of Statistics The Wharton School University of Pennsylvania Philadelphia, PA 19104-6302 USA

Library of Congress Cataloging-in-Publication Data

Rosenbaum, Paul R.

Observational studies / Paul R. Rosenbaum.-2nd ed.

p. em. - (Springer series in statistics)

Includes bibliographical references and index.

I. Experimental design. 2. Analysis of variance. I. Title. II. Series.

QA279.R67 2002

519.5'3-dc21

2001049264

Printed on acid-free paper.

© 2002,1995 Springer Science+Business Media New York Originally published by Springer-VerlagNew York,Inc. in 2002. Softcover reprint of the hardcover 2nd edition 2002

All rights reserved. This work may not be translated or copied in whole or in part without the

written

permission

of the publisher Springer Science+Business Media, LLC,

except for brief excerpts in connection with reviews or scholarly analysis. Use

in connection with any form of information storage and retrieval, electronic adaptation, computer

software, or by similar or dissimilar methodology now known or hereafter developed is forbidden.

The use of general descriptive names, trade names, trademarks, etc., in this publication, even if the

former are not especially identified, is not to be taken as a sign that such names, as understood by

the Trade Marks and Merchandise Marks Act, may accordingly be used freely by anyone.

Production managed by Jenny Wolkowicki; manufacturing supervised by Jeffrey Taub. Photocomposed pages prepared from the author's U-TEJX files.

9 8 765 4 3 2 I
ISBN 978-1-4419-3191-7 ISBN 978-1-4757-3692-2 (eBook) DOI 10.1007/978-1-4757-3692-2

For Sarah, Hannah, and Aaron.

Preface
1. What the Book Is About: An Outline
An observational study is an empiric investigation of treatments, policies , or exposures and the effects they cause, but it differs from an experiment in that the investigator cannot control the assignment of treatments to subjects. Observational studies are common in most fields that study the effects of treatments or policies on people. Chapter 1 defines the subject more car efully, presents several observational studies, and briefly indicates some of the issues that structure the subject.
In an observational study, the investigator lacks experimental control; therefore, it is important to begin by discussing the contribution of experimental control to inference about treatment effects. The statistical theory of randomized experiments is reviewed in Chapter 2.
Analytical adjustments are widely used in observational studies in an effort to remove overt biases, that is, differences between treated and control groups, present before treatment, that are visible in the data at hand. Chapter 3 discusses the simplest of these adjustments, which do little more than compare subjects who appear comparable. Chapter 3 then examines the circumstances under which the adjustments succeed . Alas, these circumstances are not especially plausible, for they imply that the observational study differs from an experiment only in ways that have been recorded. If treated and control groups differed before treatment in ways not recorded, there would be a hidden bias. Chapter 4 discusses sensitivity analyses that ask how the findings of a study might be altered by hidden biases of various

viii Preface
magnitudes. It turns out that observational studies vary markedly in their sensitivity to hidden bias . The degree of sensitivity to hidden bias is one important consideration in judging whether the treatment caused its ostensible effects or alternatively whether these seeming effects could merely reflect a hidden bias . Chapter 5 discusses models for treatment effects and illustrates their use in sensitivity analysis.
Although a sensitivity analysis indicates the degree to which conclusions could be altered by hidden biases of various magnitudes, it does not indicate whether hidden bias is present. Chapters 6 through 8 concern attempts to detect hidden biases using devices such as multiple control groups, multiple referent groups in a case-referent study, or known effects . Chapter 9 concerns coherence in observational studies, a concept that falls somewhere between attempts to detect hidden bias and sensitivity analyses.
Chapter 10 discusses methods and algorithms for matching and stratification for observed covariates. Chapters 3 and 10 both concern the control of overt biases; however, Chapter 3 assumes that matched pairs, sets, or strata are exactly homogeneous in the observed covariates. When there are many covariates each taking many values, the exact matching in Chapter 3 is not practical. In contrast, the methods and algorithms in Chapter 10 will often produce matched pairs, sets, or strata that balance many covariates simultaneously. The planning of observational studies is discussed in Chapter 11. Chapter 12 discusses the relationship between the design of an observational study and its intended audience.
2. Suggestions for the Reader
Chapter 1 is motivation and Chapter 2 is largely review. Chapter 4 depends on Chapter 3. Chapter 10 may be read immediately following Chapter 3. Other chapters depend strongly on Chapter 4 but only weakly on each other. Chapters 11 and 12 depend on all the previous chapters but may be read at any time.
It is not necessary, perhaps not wise , to read from cover to cover . This book discusses research design , scientific inference, concepts, methods, algorithms and technical results of statistics, together with many examples that serve varied purposes. Different topics will interest different readers, and some topics will be details for all readers. Several suggestions follow.
Chapters are organized by topic. For example, all of the material about randomized experiments appears in Chapter 2, but not all of this material is of equal importance, and parts can be skipped on the way to later chapters. Appendices and sections marked with an asterisk (*) provide some suggestions about what can be skipped.
Sections marked with an asterisk (*) may be skipped. Sections receive asterisks for widely varied reasons. An asterisk signals one thing only: the

Pr eface ix
ma teri al in the section is not needed later in t he book. A to pic that is unconventional, or nonst andard, or technic al, or a necessar y but t iresome det ail , or an unnecessar y but int eresting digression , is likely to receive an asterisk. Read ers who skip t hese sect ions may suffer immediate loss, but without future peril.
Appendices discuss ideas t hat ar e primaril y of int erest to people who create stat istical method s, rather t ha n to people who use t hem. App endices are leisurely and detailed , but they are aimed at a minority of read ers. Sensitivity a na lyses-an important topic in the book- involve obtaining sha rp bounds on certain probability distributions using aest het ically pleasing tools such as Holley 's inequ ali ty and arrangement increasin g functions . Topic s of this sor t ar e discussed in appendices.
A reader who wishes to understand all of the central concept s while minimizing the t echnical formalities should focus on matched pairs. It turns out that, for purely t echnical reasons, the case of matched pairs involves su ccess-or-failure binary trials, so that the formalities are quite eleme ntary. If a reader focuses on discussions of McNemar 's t est for paired binary out comes and Wilcoxon 's signed rank t est for paired continuous outcomes, then the read er will encounte r all of the imp ortant concepts, but will st ay with probability distributions for bin ary trials. For example, such a read er might read only the first three sect ions of Cha pter 4, thereby completely covering t he case of mat ched pairs , before moving on to later chapte rs . Also, it is oft en p ossibl e to pick up concepts from the discussion of examples. Many chapters begin with an exa mple, and many methods are illustrat ed with an example.
To be bri efly introdu ced to the concepts underlying observat iona l st udies withou t form al mathem at ics, read the overview in Cha pter 1, and read abo ut randomiz ed expe rime nts in §2.1 of Cha pte r 2, adjust me nts for overt bias in §3.1, sensit ivity analysis in §4.1, det ecting hidden bias in §6.1, coher ence in §9.1, multivari ate matching and stratifi cati on in §10.1, planning an observat ional st udy in Chapter 11, and strategic issues in Cha pter 12.
In the index, there is a list of examples und er "exa mples," a list of mathematical symbols under "symbols," and a bits abo ut software under "softwar e."
The second edition of Observat ional St udies is about 50% longer than the first edit ion. Ther e are two new chapters, nam ely, Chapter 5 about nonadditive models for treatment effects and Chapter 11 about planning observational studies. Chapter 9 about coherence has been completely rewritten. There ar e subs t ant ial additions to the ot her chapters, for exa mple, §3.5 about covariance adjust ment of rank test s using an estimated propen sit y score, §4.5 about sensit ivity analysis based on asy mptot ic sepa rability, and §6.5 abo ut bias of known dir ecti on. There are many new examples and problems, and a few errors have been correc ted .

x Preface
3. Acknowledgments

To grow older as an academic is to accumulate intellectual debts, and to associate these debts with fond memories. I would like to acknowledge several people who have helped with this book and also collaborators on journal articles that are discussed here. My thanks go to Joe Gastwirth, Sam Gu, Daniel Heitjan, Bob Hornik, Abba Krieger, Marshall Joffe, Yunfei Paul Li, Bo Lu, Sue Marcus, Kewei Ming, Kate Propert, Don Rubin, Jeffrey Silber, and Elaine Zanutto.
This work was supported in part by the US National Science Foundation. The second edition was prepared while I was on sabbatical leave at the Center for Advanced Study in the Behavioral Sciences, and the Center's hospitality and support are gratefully acknowledged.
Chapter 11 is adapted from my article, "Choice as alternative to control in observational studies" which appeared with discussion in Statistical Science, 1999, 14,259--304. I am grateful to the editor, Leon GIeser, and the discussants, Charles Manski, James Robins, Thomas Cook, and William Shadish for their comments. Also, I am grateful to the Institute of Mathematical Statistics for their copyright policy which permits use by authors of publications in IMS journals, and for their specific encouragement to do so with this article.
Most of all, I'd like to thank Sarah, Hannah, Aaron, and Judy.

The Wharton School University of Pennsylvania October 2001

Paul R. Rosenbaum

Contents

1 Observational Studies

1

1.1 What Are Observational Studies? .

1

1.2 Some Observational Studies

2

1.3 Purpose of This Book

10

1.4 Bibliographic Notes .

11

1.5 References . .. . . ..

16

2 Randomized Experiments

19

2.1 Introduction and Example: A Randomized Clinical Trial

19

2.2 The Lady Tasting Tea . . . . . . . . . . . . . .

21

2.3 Randomized Experiments . . . . . . . . . . . .

23

2.4 Testing the Hypothesis of No Treatment Effect

27

2.5 Simple Models for Treatment Effects

40

2.6 Confidence Intervals . . . .

44

2.7 Point Estimates . . . . . . . . . . . .

46

2.8 *More Complex Outcomes . . . . . .

50

2.9 *Appendix: Effect Increasing Tests Under Alternatives

54

2.10 *Appendix: The Set of Treatment Assignments

55

2.11 Bibliographic Notes .

63

2.12 Problems .

64

2.13 References. . . . . .

66

3 Overt Bias in Observational Studies

71

3.1 Introduction: An Example and Planning Adjustments

71

xii Contents

3.2 Adjustm ents by Exact Stratification a nd Matching . . . . . 77

3.3 Case-Referent Studies . . . . . . . . . . . . . . . . . . . . . 83

3.4 *Small Sample Inferen ce with a n Unknown Propensity Score 86

3.5 *Large Sample Inferen ce with an Unknown Propensity Score 90

0.6 *Inexact Matching Followed by Stratification

92

3.7 Bibliographic Not es .

99

3.8 Problems .

100

3.9 References . . . . . .

100

4 Sensitivity to Hidden Bias

105

4.1 Wh at Is a Sensitivity Analy sis?

105

4.2 A Model for Sensitivity Analy sis

106

4.3 Matched Pairs

110

4.4 Sensitiv ity Analysis for Sign-Score St atistics .

119

4.5 Mult iple Controls and Continuous Resp on ses

135

4.6 Sensitivity Analysis for Two Unm atched Gr ou ps

140

4.7 Ap pend ix: Technical Results a nd Proofs

151

4.8 Bibliographic Not es.

158

4.9 P rob lems .

158

4.10 References . . . . . .

163

5 Models for Treatment Effects

171

5.1 Effects That Vary from Person to P erson

171

5.2 Order St atist ics . . . .

173

5.3 Dilat ed Effects . . . . . . . . . . . . . .

173

5.4 Instrument al Variabl es . . . . . . . . . .

180

5.5 Attributable Effects: Binary Respo nses

188

5.6 At tribut able Effects: Displacements .

192

5.7 Inference About a Quantil e

195

5.8 Biblio graphic Notes . . . . . . . .

198

5.9 P roblems

.....

198

0.10 Append ix: Minimu m vVage Da ta

199

5.11 References . . . . . . . . . . . . .

201

6 Known Effects

205

6.1 Det ectin g Hidden Bias Usin g Kn own Effect s . . . . . . . 205

6.2 An Outcome Known to Be Una ffecte d by the Tr eatment 214

6.3 An Outcome With Known Dir ect ion of Effect .

221

6.4 *The Behavior of T* with Nonnegati ve Effects

222

6.5 Bias of Known Direct ion

223

6.6 Biblio graphic Notes .

226

6.7 P roblems .

226

6.8 References . . . . . .

227

7 Multiple Reference Groups in Case-Referent Studies

231

Contents xiii

7.1 Multiple Referen ce Groups. . . . . . . . . .

231

7.2 Matched Studies with T wo Referent Groups

237

7.3 *Appendix: Selection a nd Hidden Bias . . . .

244

7.4 *Appendix: Derivat ion of Bounds for Sensiti vity Analysis 246

7.5 Bib liogr aphic Notes .

248

7.6 Problems .

249

7.7 References . . . . . .

250

8 Multiple Control Groups

253

8.1 The Role of a Second Control Group

253

8.2 Selecting Control Gr oups

263

8.3 Comparing Outcomes in Two Control Groups

265

8.4 Bibliographic Not es .

269

8.5 Problems .

270

8.6 Refer en ces. . . .. .

272

9 Coherence and Focused Hypotheses

277

9.1 Coherent Asso ciations . . . . . . . . . . . . . . . .

277

9.2 Signed Rank St atis t ics for Coherent Predictions. .

279

9.3 Example: Do Anesthet ic Gases Cause Mutat ions?

282

9.4 *Properti es of the Coherent Signed Rank Test .

285

9.5 Some Other Forms of Coherence . . . . . . . . . .

285

9.6 Strengths a nd Limi t ati ons of Coherence . . . . . .

286

9.7 *Appe ndix: Arran gement-In creasing Fun ct ions of Matrices . 288

9.8 Bibli ographic Notes .

289

9.9 Problems .

290

9.10 Referen ces . . . . . .

290

10 Constructing Matched Sets and Strata

295

10.1 Introdu ct ion : P ropensity Scores , Struct ures, Algori t hms . 295

10.2 The P rop ensity Score

296

10.3 Optimal St rata . . .

302

10.4 Optimal Matching .

311

10.5 Bibliographic Not es .

322

10.6 Software . .

322

10.7 Problems .

323

10.8 References .

328

11 Planning an Observational Study

333

11.1 Introducti on and Some Ground Rules

333

11.2 Three Ob servational Studies. .

336

11.3 Choice of Research Hyp othesis . . . .

339

11.4 A Control Gr oup . . . . . . . . . . . .

342

11.5 Defining Tr eat ed and Cont rol Groups

344

11.6 Compet ing Theories . . . . . . . . . .

347

xiv Contents

11.7 Internal Replicati on

.

351

11.8 Nond ose Nonr esponse: An Absent Association .

352

11.9 St abil ity Analyses

.

353

11.10 Abrupt , Short- Lived Treatments

.

355

11.11 Natural Blocks

.

357

11.12 Refut e Several Alt ern at ive Exp lanat ions .

358

11.13 Bib liographic Not es

358

11.14 Problems .

358

11.15 Referen ces . . . . .

360

12 Some Strategic Issues

367

12.1 Wh at Are St rat egic Issues?

367

12.2 Some Specific Suggest ions

368

12.3 References

.

369

Index

370

1
Observational Studies
1.1 What Are Observational Studies?
W illiam G. Cochran first presented "observat ional st udies" as a t opic defined by principl es and method s of statist ics. Cochra n had been an aut ho r of t he 1964 Unite d States Surgeo n General's Advisory Commit tee Repor t , Sm oking and Health, which reviewed a vast litera ture and concluded: "Ciga ret t e smo king is causa lly related to lun g ca ncer in men; the magnitude of the effect of cigarett e smoking far outweighs all ot her factors. T he da ta for women , t ho ugh less exte nsive, point in the sa me dir ecti on (p. 37) ." Though there had been some experiments confined to lab oratory animals, t he direct evidence linking smoking with hum an health came from observat iona l or non exp erimental st udies.
In a later review , Cochr an (1965) defined an observat iona l study as an empiric investigation in whi ch:
. . . the objective is to elucidate cause -and- effect relat ionships [in whi ch] it is not feasibl e to use controlled experimen-
t ation , in the sense of being able to impose the pr ocedures or treatments whose effects it is desired to discover , or to assign subjec ts at random t o different procedures. Fea tures of this definition deserve emphasis. An observation al st udy concerns treatments, interventions, or policies and th e effects they cause, and in thi s resp ect it resembl es an experiment. A st udy without a treatment is neither an expe riment nor a n observational st udy. Most public opinion

2 1. Ob serva tional St udies
polls, most forecasting efforts, most st udies of fairness a nd discr iminat ion, and many ot her imp or t ant empirical st udies ar e neither expe riments nor observational st udies.
In a n expe riment , th e assignment of t reatme nts t o subjects is cont rolled by t he experimente r, who ensures that subjec ts receiving differ ent treatments are compa ra ble. In an observationa l st udy, thi s cont ro l is abse nt for one of several reasons. It may be that t he treatment , perhaps cigaret te smoking or rad on gas , is harmful a nd cannot be given to human subjects for experimental purposes. Or th e treatment may be cont rolled by a political process that , perhaps quite appro pria te ly, will not yield control merely for an exper iment , as is true of mu ch of macroecon omi c and fiscal policy. Or the treatment may be beyond the legal reach of experime ntal manipulati on even by a government , as is t rue of many man agement decisions in a private economy. Or experiment al subjects may have such st rong at tachm ents to particular treatments that they refuse to cede cont rol to an experimente r, as is sometimes true in areas ranging from diet and exercise to bilingual education. In each case , the investigator does not cont rol the assignme nt of treatment s and canno t ensure that similar subjects receive different treat ments.
1.2 Some Observational Studies
It is encouraging t o recall cases, such as Smoking and Health, in which observational studies established important trut hs , but an understanding of th e key issues in observational st udies begins elsewhere . Observa t ion al data have oft en led compete nt honest scient ists to false and harmful conclusions , as was the case with Vit amin C as a treatment for advanced cancer.
Vitamin C and Treatment of Advanced Can cer: An Observational Study and an Experiment Compared
In 1976, in their article in the Proceedings of the Nat ional Academy of Sciences, Cameron and Pauling presented observational data conc erning th e use of vitamin C as a treatment for advanced ca ncer. They gave vitamin C to 100 patients believed to be t erminally ill from advan ced cancer and st udied subsequent survival.
For each such patient, 10 historical controls were selecte d of the same age and gender, the same site of primary cancer , a nd the sa me histological tumor type. This method of select ing controls is called m atched samplingit consists of choosing controls on e at a time to b e similar to individual t reate d subjects in terms of characteristics measured pri or to treatment. Used effect ively, matched sampling oft en creates treated and cont rol groups t hat ar e comparable in terms of the var iables used in matching , though the

1.2 Some Obs ervational Studies 3
groups may still differ in other ways, including ways that were not measured. Cameron and Pauling (1976, p. 3685) write: "Even though no formal process of randomization was carried out in the selection of our two groups, we believe that they come close to representing random subpopulations of the population of terminal cancer patients in the Vale of Leven Hospital." In a moment, we shall see whether this is so.
Patients receiving vitamin C were compared to controls in terms of time from "untreatability by standard therapies" to death. Cameron and Pauling found that, as a group, patients receiving vitamin C survived about four times longer than the controls. The difference was highly significant
in a conventional statistical test , p-value < 0.0001, and so could not be at-
tributed to "chance." Cameron and Pauling "conclude that there is strong
evidence that treatment '" [with vitamin C] . .. increases the survival
time." This study created interest in vitamin C as a treatment. In response,
the Mayo Clinic (Moertel et al., 1985) conducted a careful randomized controlled experiment comparing vitamin C to placebo for patients with advanced cancer of the colon and rectum. In a randomized experiment, subjects are assigned to treatment or control on the basis of a chance mechanism, typically a random number generator, so it is only luck that determines who receives the treatment. They found no indication that vitamin C prolonged survival, with the placebo group surviving slightly but not significantly longer. Today, few scientists claim that vitamin C holds promise as a treatment for cancer.
What went wrong in Cameron and Pauling's observational study? Why were their findings so different from those of the randomized experiment? Could their mistake have been avoided in any way other than by conducting a true experiment?
Definite answers are not known, and in all likelihood will never be known. Evidently, the controls used in their observational study, though matched on several important variables, nonetheless differed from treated patients in some way that was important to survival.
The obvious difference between the experiment and the observational study was the random assignment of treatments. In the experiment, a single group of patients was divided into a treated and a control group using a random device. Bad luck could, in principle, make the treated and control groups differ in important ways, but it is not difficult to quantify the potential impact of bad luck and to distinguish it from an effect of the treatment. Common statistical tests and confidence intervals do precisely this. In fact, this is what it means to say that the difference could not reasonably be due to "chance." Chapter 2 discusses the link between statistical inference and random assignment of treatments.
In the observational study, subjects were not assigned to treatment or control by a random device created by an experimenter. The matched sampling ensured that the two groups were comparable in a few important ways,

4 1. Observational Studies
but beyond this, there was little to ensure comparability. If the groups were not comparable before treatment, if they differed in important ways, then the difference in survival might be no more than a reflection of these initial differences.
It is worse than this. In the observational study, the control group was formed from records of patients already dead , while the treated patients were alive at the start of the study. The argument was that the treated patients were terminally ill, that they would all be dead shortly, so the recent records of apparently similar patients, now dead , could reasonably be used to indicate the duration of survival absent treatment with vitamin C. Nonetheless, when the results were analyzed, some patients given vitamin C were still alive; that is, their survival times were censored. This might reflect dramatic effects of vitamin C, but it might instead reflect some imprecision in judgments about who is terminally ill and how long a patient is likely to survive, that is, imprecision about the initial prognosis of patients in the treated group. In contrast, in the control group , one can say with total confidence, without reservation or caveat, that the prognosis of a patient already dead is not good. In the experiment, all patients in both treated and control groups were initially alive .
It is worse still. While death is a relatively unambiguous event, the time from "untreatability by standard therapies" to death depends also on the time of "untreatability." In the observational study, treated patients were judged, at the start of treatment with vitamin C, to be untreatable by other therapies. For controls, a date of untreatability was determined from records. It is possible that these two different processes would produce the same number, but it is by no means certain. In contrast, in the experiment, the starting date in treated and control groups was defined in the same way for both groups, simply because the starting date was determined before a subject was assigned to treatment or control.
What do we conclude from the studies of vitamin C? First, observational studies and experiments can yield very different conclusions. When this happens, the experiments tend to be believed. Chapter 2 develops some of the reasons why this tendency is reasonable. Second, matching and similar adjustments in observational studies, though often useful, do not ensure that treated and control groups are comparable in all relevant ways . More than this, the groups may not be comparable and yet the data we have may fail to reveal this. This issue is discussed extensively in later chapters. Third, while a controlled experiment uses randomization and an observational study does not, experimental control also helps in other ways. Even if we cannot randomize, we wish to exert as much experimental control as is possible, for instance, using the same eligibility criteria for treated and control groups, and the same methods for determining measurements.
Observational studies are typically conducted when experimentation is not possible. Direct comparisons of experiments and observational studies are less common, vitamin C for cancer being an exception. Another direct

1.2 Some Observational Studies 5
comparison occurred in the Salk vaccine for polio, a story that is well told by Meier (1972) . Others are discussed by Chalmers, Block, and Lee (1970), LaLonde (1986), Fraker and Maynard (1987), Zwick (1991), Friedlander and Robins (1995), and Dehejia and Wahba (1999).
Smoking and Heart Disease: An Elaborate Theory
Doll and Hill (1966) studied the mortality from heart disease of British doctors with various smoking behaviors. While dramatic associations are typically found between smoking and lung cancer, much weaker associations are found with heart disease. Still , since heart disease is a far more common cause of death, even modest increases in risk involve large numbers of deaths.
The first thing Doll and Hill did was to "adjust for age." The old are at greater risk of heart disease than the young . As a group, the smokers tended to be somewhat older than the nonsmokers, though of course there were many young smokers and many old nonsmokers. Compare smokers and nonsmokers directly, ignoring age, and you compare a somewhat older group to a somewhat younger group, so you expect a difference in coronary mortality even if smoking has no effect. In its essence, to "adjust for age" is to compare smokers and nonsmokers of the same age. Often results at different ages are combined into a single number called an age-adjusted mortality rate. Methods of adjustment and their properties are discussed in Chapters 3 and 10. For now, it suffices to say that differences in Doll and Hill's age-adjusted mortality rates cannot be attributed to differences in age, for they were formed by comparing smokers and nonsmokers of the same age . Adjustments of this sort, for age or other variables, are central to the analysis of observational data.
The second thing Doll and Hill did was to consider in detail what should be seen if, in fact, smoking causes coronary disease. Certainly, increased deaths among smokers are expected, but it is possible to be more specific. Light smokers should have mortality somewhere between that of nonsmokers and heavy smokers. People who quit smoking should also have risks between those of nonsmokers and heavy smokers, though it is not clear what to expect when comparing continuing light smokers to people who quit heavy smoking.
Why be specific? Why spell out in advance what a treatment effect should look like? The importance of highly specific theories has a long history, having been advocated in general by Sir Karl Popper (1959) and in observational studies by Sir Ronald Fisher, the inventor of randomized experiments, as quoted by Cochran (1965, §5):
About 20 years ago, when asked in a meeting what can be done in observational studies to clarify the step from association to causation, Sir Ronald Fisher replied: 'Make your theories

6 1. Obser vati onal St udies

TABLE 1.1. Coro nary Mortality in Rela ti on to Smo king . Heavy Smokers 3.79

Moderate Smokers 2.81
i
Light Smokers 2.72

E xs m o ker s 2.76
/

No ns m okers 2.12

elab orat e.' The reply puzzled me at first, since by Occam's razor , the advice usually given is to make theori es as simple as is consistent with known dat a. What Sir Ronald mean t , as subsequent discussion showed, was that when constru cting a causal hypothesis one should envisage as many differ ent consequen ces of its t ruth as possible, and plan observational studies to discover whether each of t hese consequences is found to hold .
. . . t his mult i-ph asic attack is one of t he most potent weapons in observational st udies.
Cha pters 6 through 9 consider t his adv ice for mally and in de tail. Table 1.1 gives Doll and Hill's six age-adj usted mor t ality ra tes for death from coronary disease not associated wit h a ny ot her spec ific disease. The rat es are deaths per 1000 per year, so t he value 3.79 means about 4 deaths in each 1000 doctors each year. The six groups are nonsmoker s, exsmokers, and light smokers of 1 to 14 ciga ret tes, mod er ate smokers of 15 to 24 cigaret tes, and heavy smokers of 25 or more cigarettes per day. Doll and Hill did not separate exsmokers by the amo unt they had previously smoked, though thi s would have been interes t ing and would have pe rmitted more det ailed predi ctions. Again , differen ces in age do not affect t hese mortality rat es. Table 1.1 confirms each expectation. Mortality increases wit h t he quantity smoked. Quitters have lower mor t ality t ha n heavy smo kers but high er mortality than nonsmokers. Any alte rnative explanation, a ny claim t hat smoking is not a cause of coronary mortality, would need to explain t he ent ire pattern in Table 1.1. Alte rnative expl an ations are not difficult to imagine, but t he pattern in Table 1.1 restricts their number.

1.2 Some Observational St udies 7
DES and Vaginal Cancer: Sensi tivity to Bias
Cancer of t he vagina is a rar e condit ion, par ticularl y in young women. In 1971, Herbst , Ulfelder , and Poskanzer pu blished a report describing eight cases of vaginal cancer in women aged 15 to 22. T hey were particular ly interested in t he possibility t hat a drug, diethylstilbestrol or DES, given to pr egnant wome n, mig ht be a cause of vaginal cance r in t heir daug hters. Each of t he eight cases was mat ched to four referents, t hat is, to four women who did not develop vaginal cancer. These four referents were born within five days of t he birth of t he case at the same hospital , a nd on t he same type of serv ice, ward or private. There were t hen eight cases of vagina l cancer and 32 referents, and t he st udy compared t he use of DE S by t heir mothers.
This sort of st udy is called a case-referen t study or a case-control stu dy or a retrospective stu dy, no one te rminology being universally accepted. In an experiment and in many obse rvational st udies, t reated and contro l groups are followed forward in t ime t o see how outcomes develop . In t he current context , this would mean compa ring two groups of women , a treat ed group whose mothers had received DES and a cont rol group whose mothers had not. T ha t sort of st udy is not practical becau se the outco me, vagina l cancer, is so rare-the t reated and cont rol groups would have to be enormous and cont inue for many yea rs t o yield eight cases of vagina l ca ncer. In a casereferent st udy, t he groups compared are not defined by whet her or not t hey received t he t reatment , bu t rather by whether or not t hey exhibit t he outcome. T he cases are compared to t he referents to see if exposure to the t reatment is more common among cases.
In general , the name "case-cont rol" study is not ideal because t he word "cont rol" does not have its usua l meaning of a person who did not receive t he treatment. In fact , in most case-referent studies, many referents did rece ive t he treatme nt. The na me "retrospect ive" st udy is not ideal because t here are obse rvational st udies in which dat a on ent ire treated and control groups are collected after t reatments have been given and outco mes have ap peared, t hat is, collected ret rospecti vely, and yet the grou ps being com pared are st ill t reated and untreat ed groups. See MacMahon and Pugh (1970, pp . 41-46) for some de tailed discussion of this t erminology.
So the st udy compared eight cases of vagina l cancer to 32 matched refere nts to see if treatment with diet hylst ilbest rol was more common among mothers of the cases, and indeed it was. Among th e mothers of the eight cases, seven had received DES during pregnancy. Among mothers of the 32 refer ents, none had received DE S. The associat ion be twee n vaginal can cer a nd DES appe ars t o be almos t as st rong as a relati onship can be, though of course only eight cases have bee n observed . If a conventio na l tes t designed for use in a ran domized experiment is used to compare cases and referents in te rms of t he frequ ency of expos ure to DES, t he difference is hig hly significant . However , experience with t he firs t example, vitamin C a nd ca nce r, suggests ca ution here.

8 1. Ob ser vational Studies
What should be concluded from t he st rong assoc iatio n obse rved between DES and vaginal cancer in eight cases and 32 mat ched referents? Unlike the case of vitamin C and cancer, it would be neit her practical nor ethical to follow up with a ran domized exp eriment . Could such a hypothet ical experiment produce very different findings? That possibility ca n never be entirely ru led out . St ill, it is possib le to ask: How severe wou ld t he unseen prob lems in t his study have to be to produce such a strong relationship if DES did not cause vagina l cancer ? How far would t he obse rvational study have to depart from an experiment to produce such a relationsh ip if DE S were harmless? How does t he small size of t he case group, eight cases , affect t hese questions? Chapter 4 provid es answers. As it t urns out, only severe un seen problems and hidde n biases, only dr am at ic depa rtures from an experiment, could produce such a strong association in t he abse nce of an effect of DES , the sma ll sample size notwithst anding. In ot her words, this st udy is highl y insensiti ve to hidden bias ; its conclusions could be altered by dramatic biases, but not by small ones. This is by no means t rue of all observatio nal st udies. Cha pt er 4 concerns genera l methods for qu antifyin g the sensi t ivity of findin gs to hidden biases, and it discusses the uses and limit ations of sensitiv ity analyses.
Academic Achievem ent in Public and Catholic High Schools: Specific Responses to Specific Criticis ms
A cur rent controversy in the United States concerns t he effectiveness of public or state-ru n schools, particularly as compared to exist ing pri vat ely operated schools. T he 1985 paper by Hoffer , Greely, and Co leman is one of a series of observationa l studies of t his questi on. T hey used data from the High School and Beyond St udy (HSB), which includes a survey of US high-school st udents M sophomores wit h follow-up in t heir senior year. The HSB st udy pr ovided standardized achieveme nt test scores in several areas in sophomore and senior years, and included follow-up of st udents who dropped out of schoo l, so as t hese t hings go, it is a rather complete and attractive source of dat a. Hoffer , Greely, a nd Colem an (1985) begin with a list of six obj ecti ons made to their ea rlier st udies, which had compared achievement test scores in pu blic and Catholic schoo ls, concl uding that ". . . Cat holic high schools are more effect ive t han pu blic high schools." As an illustration, objection # 3 states : "Cat holic schoo ls seem t o have an effect becau se they elimina te t heir disciplinary problems by expe lling them from t he schoo l." The idea here is t hat Cat holic schoo ls eliminate difficul t students while the pu blic schools do not , so t he st ude nts who rem ain in Catholic schoo ls would be more likely to p erform well even if there were no difference in t he effectiveness of t he two typ es of schoo ls.
Criticism is enormously import an t to obse rvational studies. The qu ality of the crit icism offered in a pa rticular field is inti ma tely connected wit h t he

1.2 Some Obs erv ational Studies 9
quality of the studies cond ucted in that field . Quality is not quantity, nor is harshness qu ality. What is scient ifically plausible must be distinguished from what is just logically possible (Gastwirth, Krieger and Rosenbaum 1997) . Cochran (1965, §5) argues that th e first crit ic of an observational study should be its author:
When summari zing the results of a st udy that shows an association consistent with the causal hypothesis, the investigator should always list a nd discuss all alternative explanat ions of his results (including different hypotheses and biases in the results) that occur to him . This advice may sound trite, but in practice is often neglected.
Criticisms of observational studies ar e of two kinds , the tangible and the dismissive , objection #3 being of the tangible kind . A t an gible crit icism is a specifi c a nd plausible alte rnat ive int erpretation of the available data; indeed, a tangible criticism is itself a scientific th eory, itself capa ble of empirical investigation. Bross (1960) writes:
a crit ic who objects to a bias in the design or a failure to control some est ablished factor is, in fact , raising a counte rhypothesis. . . [and] has the responsibility for showing [it] is tenable. In doing so, he op erates und er the same ground rules as the proponent . .. : When a crit ic has shown that his count erhypothesis is tenable, his job is done , while at this point the proponent's job is just beginning. A proponent 's job is not finished as long as there is a tenable hypothesis that rivals the one he asserts.
On the second page of his Th e Design of Experiments, Fisher (1935) described dismi ssive crit icism as he argued that a theory of experimental design is needed:
This type of criticism is usually made by what I might call a heavyweight authority. Prolonged experience, or at least the long possession of a scient ific reputation, is almost a pre-requisite for developing successfully this line of at tack. Technical det ails are seldom in evidence. The a ut horit at ive assertion: "His controls are totally inadequate" must have temporarily discredited many a promising line of work; and such an aut horit arian method of judgement must surely continue, human nature being what it is, so long as theoretical notions of the principles of experimental design are lacking . . . .
Dismissive criticism rests on the authority of the critic and is so broad and vague that its claims cannot be studied empirically. Judging the weight

10 1. Observational Studies
of evidence is inseparable from judging the criticisms that have been or can be raised.
Concerning objection #3 , Hoffer, Greely, and Coleman (1985) respond: ". .. the evidence from the HSB data, although indirect, does not support this objection. Among students who reported that they had been suspended during their sophomore year, those in the Catholic sector were more likely to be in the same school as seniors than those in the public sector (63 percent to 56 percent)." In other words, difficult students, or at any rate students who were suspended, remained in Catholic school more often, not less often, than in public schools . This response to objection #3, though not decisive, does gives one pause.
Successful criticism of an observational study points to ambiguity in evidence or argument, and then points to methods for removing the ambiguity. Efforts to resolve an ambiguity are sometimes undermined by efforts to win an argument. Popper (1994, p. 44) writes:
Serious critical discussions are always difficult . . . Many participants in a rational, that is, a critical, discussion find it particularly difficult to unlearn what their instincts seem to teach them (and what they are taught, incidently, by every debating society): that is, to win. For what they have to learn is that victory in debate is nothing, while even the slightest clarification of one's problem-even the smallest contribution made towards a clearer understanding of one's own position or that of one 's opponent-is a great success. A discussion which you win but which fails to help you change or to clarify your mind at least a little should be regarded as a sheer loss.
1.3 Purpose of This Book
Scientific evidence is commonly and properly greeted with objections, skepticism, and doubt. Some objections come from those who simply do not like the conclusions, but setting aside such unscientific reactions, responsible scientists are responsibly skeptical. We look for failures of observation, gaps in reasoning, alternative interpretations. We compare new evidence with past evidence. This skepticism is itself scrutinized. Skepticism must be justified, defended. One needs "grounds for doubt ," in Wittgenstein's (1969, §122) phrase. The grounds for doubt are themselves challenged. Objections bring forth counterobjections and more evidence. As time passes, argnments on one side or the other become strained, fewer scientists are willing to offer them, and the arguments on that side come increasingly from individuals who seem to have some stake in the outcome. In this way, questions are settled.

1.4 Bibliographic Notes 11
Scientific questions are not settled on a particular date by a single event , nor are they settled irrevocably. We speak of the weight of evidence . Eventually, the weight is such that critics can no longer lift it, or are too weary to try. Overwhelming evidence is evidence that overwhelms responsible critics.
Experiments are better than observational studies because there are fewer grounds for doubt. The ideal experiment would leave few grounds for doubt , and at times this ideal is nearly achieved, particularly in the laboratory. Experiments often settle questions faster.
Despite this, experiments are not feasible in some settings. At times, observational studies have produced overwhelming evidence, as compelling as any in science, but at other times, observational data have misled investigators to advocate harmful policies or ineffective treatments.
A statistical theory of observational studies is a framework and a set of tools that provide measures of the weight of evidence. The purpose of this book is to give an account of statistical principles and methods for the design and analysis of observational studies. An adequate account must relate observational studies to controlled experiments, showing how uncertainty about treatment effects is greater in the absence of randomization. Analytical adjustments are common in observational studies, and the account should indicate what adjustments can and cannot do. A large literature offers many devices to detect hidden biases in observational studies, for instance, the use of several control groups, and the account must show how such devices work and when they may be expected to succeed or fail. Even when it is not possible to reduce or dispel uncertainty, it is possible to be careful in discussing its magnitude. That is, even when it is not possible to remove bias through adjustment or to detect bias through careful design, it is nonetheless possible to give quantitative expression to the magnitude of uncertainties about bias, a technique called sensitivity analysis. The account must indicate what can and cannot be done with a sensitivity analysis.
1.4 Bibliographic Notes
Most scientific fields that study human populations conduct observational studies. Many fields have developed a literature on the design, conduct, and interpretation of observational studies, often with little reference to related work in other fields. It is not possible to do justice to these several literatures in a short bibliographic note. There follows a short and incomplete list of fine books that contain substantial general discussions of the methodology used for observational studies in epidemiology, public program evaluation, or the social sciences . A shared goal in these diverse works is evaluation of treatments, exposures, programs, or policies from nonexperimental data. The list is followed by references cited in Chapter 1.

12 1. Observational Studies
Some Books and a Few Papers
Angrist, J . D. and Krueger, A. B. (1999) Empirical strategies in labor economics. In: Handbook of Labor Economics, O. Ashenfelter and D. Card, eds., Volume ::$A, Chapter 2::$, New York: Elsevier.
Ashenfelter, 0 ., ed. (2000) Labor Economics. New York : Worth.
Becker, H. S. (1997) Tricks of the Trade. Chicago: University of Chicago Press.
Blaug, M. (1980) The Methodology of Economics. New York: Cambridge University Press.
Breslow, N. and Day, N. (1980, 1987) Statistical Methods in Cancer Research, Volumes 1 and 2. Lyon , France: International Agency for Research on Cancer.
Campbell, D. T . (1988) Methodology and Epistemology for Social Science: Selected Papers. Chicago: University of Chicago Press, pp. 315-333.
Campbell, D. and Stanley, J. (1963) Experimental and Quasi-Experimental Design for Research. Chicago: Rand McNally.
Chamberlain, G. (1984) Panel data. In : Handbook of Econometrics, Chapter 22, Volume 2, Z. Griliches and M. D. Intriligator, eds., New York: Elsevier.
Cochran, W . G. (1965) The planning of observational studies of human populations (with discussion). Journal of the Royal Statistical Society, Series A, 128, 134-155.
Cochran, W. (1983) Planning and Analysis of Observational Studies. New York: Wiley.
Cook, T . D. and Campbell, D. C. (1979) Quasi-Experimentation. Chicago: Rand McNally.
Cook, T . D., Campbell, D. T ., and Peracchio, 1. (1990) Quasi-experimentation. In : Handbook of Industrial and Organizational Psychology, M. Dunnette and L. Hough, eds., Palo Alto, CA : Consulting Psychologists Press, Chapter 9, pp . 491-576.
Cook, T. D. and Shadish, W . R. (1994) Social experiments: Some developments over the past fifteen years. Annual Review of Psychology, 45, 545-580.
Cornfield, J ., Haenszel, W ., Hammond, E ., Lilienfeld, A., Shimkin, M., and Wynder, E . (1959) Smoking and lung cancer: Recent evidence and a discussion of some questions. Journal of the National Cancer Institute, 22 , 173-203.

1.4 Bibli ogr aph ic Not es 13
Cox, D. R. (1992) Causality: Some stat ist ical aspects. Journ al of the Ro yal Statist ical Society , Series A , 155, 291-301.
Elwood , J . M. (1988) Causal Relationships in Medicine. New York: Oxford University Press.
Em erson , R. M. (1981) Obser vational field work. Annual Review of Sociology, 7, 351-378.
Freedman , D. (1997) From associat ion to ca usation via regression. Advances in Applied Math em atics, 18 , 59-110.
Friedman , M. (1953) Essays in Positive Economics. Chicago: University of Chi cago Press.
C astwirth , J. (1988) Statist ical R easoning in Law and Public Policy. New York: Academic Press.
C ordi s, L. (2000) Ep idem iology (Second Edition) Philad elphia: Saunders.
Gr eenhouse, S. (1982) J erome Corn field's contribut ions to epidemiology. B iom etrics, 28 , Supplement , 33- 46.
Heckm an , J . J. (2001) Micro dat a, heterogeneity, a nd t he evalua t ion of public policy: The Nob el lecture. Journ al of Political E conom y, 109 , 673- 748.
Hill, A. B . (1965) The environment and disease: Association or causa tion? Proceedings of the Royal Society of Medicine, 58, 295-300.
Holland , P. (1986) Statist ics and causal inference (wit h discussion) . Journ al of the A m erican S ta tistica l A ssociation, 81 , 945- 970.
Kelsey, J. , Whitt emore, A. , Evan s, A., and Thomp son . W . (1996). Methods in Observation al Ep idem iology. New York: Oxford University Press.
Kh oury, M. J. , Cohen, B. H. , and Beaty, T. H. (1993) Fundamentals of Gen etic Ep idem iology. New York: Oxford University Press.
Kish, 1. (1987) Statist ical Design for Research. New York: Wiley.
Lilienfeld , A. and Lilienfeld , D. E. (1980) Foundat ions of Epidemiology. New York: Oxford University Press.
Lilienfeld , D. E . and Stolley, P. D. (1994) Foun dations of Epidemiology. New York : Oxford University Press.
Lipsey, M. W. and Cordray, D. S. (2000) Evalu ati on methods for social interv ention. Annual Review of Psychology, 51 , 345- 375.

14 1. Ob servational St ud ies
Little, R. .J. and Rubin, D. B. (2000) Causal effects in clinical and epidemiological studies via pot ential outcomes. Annual Review of Public Health, 21 , 121-145.
Maclure, M. and Mittleman , M. A. (:WUU) Should we use a case-crossover design ? Annual Review of Public Health, 21 , 193-221.
MacMahon, B. and Pugh, T . (1970) Epidemiology. Boston: Little, Brown.
MacMahon, B. and Trichopoulos , D. (1996) Epid emiology . Boston: Little, Brown .
Manski, C. (1995) Identification Problems in the Social Sciences. Cambridge, MA: Harvard University Press.
Mantel, N. and Haenszel, W . (1959) St atisti cal as pects of retrosp ective st udies of disease. Journ al of the Nat ion al Cancer Institute, 22, 719748.
Meyer, B. D. (1995) Natural and quasi-experiments in economics. Journal of Bu siness and Economic Statistics, 13, 151-161.
Meyer , M. and Fienberg, S., eds. (1992) Assessing Evaluation Studies: Th e Case of Bilingual Edu cation Strategies. Washington, DC : National Academy Press.
Miettinen, O. (1985) Theoretical Epidem iology. New York: Wiley.
Pearl , J . (2000) Causality : Models, Reason ing, Inference. New York: Cambridge University Press.
Reichardt, C. S. (2000) A typology of st ra tegies for ruling out threats to validity. In : Res earch Design: Donald Campbell's Legacy, L. Bri ckman, ed., Thousand Oaks , CA: Sage, Volume 2, pp ., 89-115.
Reiter, J . (2000) Using statistics to determine causal relationships. American Math ematical Monthly, 107, 24-32.
Robins, J . M. (1999) Association, causation, and marginal st ruc t ural mod els. Synthese, 121 , 151-179.
Robins, J ., Blevins, D., Ritter, G., and Wulfsohn, M. (1992) G-estimation of the effect of prophylaxis therapy for pneumocystis carinii pneumonia on th e survival of AIDS patients. Epidemiology, 3 , 319---336.
Rosenthal, R. and Rosnow , R., eds. (1969) Artifact in Behavioral R esearch. New York: Academic.
Rosenzweig , M. R. and Wolpin , K. 1. (2000) Natural "natural experiments" in economics. Journal of Economic Lit erature , 38, 827-874.

1.4 Bibliographic Notes 15
Rosnow, R L. and Rosenthal, R (1997) People Studying People: Artifacts and Ethics in Behavioral Research. New York: W . H. Freeman.
Rossi, P., Freeman, H., and Lipsey, M. W. (1999) Evaluation. Beverly Hills, CA : Sage.
Rothman , K. and Greenland, S. (1998) Modern Epidemiology. Philadelphia: Lippincott-Raven.
Rubin, D. (1974) Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational Psychology, 66 , 688-701.
Schlesselman, J . (1982) Case-Control Studies. New York: Oxford University Press.
Schulte, P. A. and Perera, F . (1993) Molecular Epidemiology: Principles and Practices. New York: Academic .
Shadish, W. R, Cook , T . D., and Campbell, D. T . (2002) Experimental and Quasi-Experimental Designs for Generalized Causal Inference . Boston: Houghton-Mifflin.
Shafer, G. (1996) The Art of Causal Conjecture. Cambridge, MA: MIT Press.
Sobel, M. (1995) Causal inference in the social and behavioral sciences. In: Handbook of Statistical Modelling for the Social and Behavioral Sciences, G. Arminger, C. Clogg, and M. Sobel, eds. , New York: Plenum, 1-38.
Steenland, K., ed. (1993) Case Studies in Occupational Epidemiology. New York: Oxford University Press.
Strom, B. (2000) Pharmacoepidemiology. New York: Wiley.
Suchman, E . (1967) Evaluation Research. New York: Sage.
Susser, M. (1973) Causal Thinking in the Health Sciences: Concepts and Strategies in Epidemiology. New York: Oxford University Press.
Susser, M. (1987) Epidemiology, Health and Society: Selected Papers. New York: Oxford University Press.
Tufte, E., ed. (1970) The Quantitative Analysis of Social Problems. Reading, MA : Addison-Wesley.
Weiss, C. (1997) Evaluation. Englewood Cliffs, NJ: Prentice-Hall.
Weiss, N. S. (1996) Clinical Epidemiology. New York: Oxford University Press.

16 1. Observat ional Studies
Willett , W . (1998) Nutritional Epidem iology. New York : Oxford University Press.
Winship, C. and Morgan , S. 1. (1999) The est ima t ion of cau sal effects from observational dat a. Annual Review of Sociology, 25 , 659-706.
Zellner , A. (1968) Readings in Economic Statistics and Econometric s. Boston: Little, Brown .
1.5 References
Bross, I. D. J. (1960) Statistical crit icism. Cancer, 13, 394-400. Reprinted in: Th e Quant itative Analysis of Social Problem s, E. Tufte, ed ., Reading, MA: Addison-Wesley, pp . 97-108.
Cameron , E . and Pauling, 1. (1976) Supplemental ascorbate in the supportive tr eatment of cancer: Prolongation of sur vival times in t erminal hum an cancer. Proceedings of the National A cademy of Sciences (USA) , 73, 3685-3689.
Chalmers , T ., Block, J ., and Lee, S. (1970) Controlled studies in clinical cancer research. N ew England Journal of Medicin e, 287, 75-78.
Cochr an , W .G. (1965) The planning of observational studies of human populations (with discussion) . Journ al of the Ro yal Statistical Society, Series A, 128, 134-155. Repr inted in Readings in Economic Statistics and Econom etrics, A. Zellner, ed., 1968, Boston : Little Brown, pp . 11- 3 6 .
Dehejia, R. H. and Wah ba, S. (1999) Ca usa l effects in nonexp eriment al studies: Reevaluating th e evalua t ion of training pr ogr am s. Journal of the Am erican St atistical Association, 94, 1053-1062.
Doll, R and Hill, A. (1966) Mortality of British do ct ors in relation to smoking: Observations on coronary thrombosis. In : Epidem iological Approa ches to the Study of Cancer and Other Chroni c Diseases, W . Haenszel, ed., U.S. National Can cer Institute Mono graph 19, Washington, DC: US Department of Health , Education, and Welfare, pp. 205-268.
Fisher , RA. (1935, 1949) The Design of Experim ents. Edinburgh : Oliver & Boyd .
Fraker , T. and Maynard, R (1987) The adequac y of comparison group designs for evaluations of employment-relate d program s. Journal of Human Resources, 22 , 194-227.

1.5 References 17
Friedlander, D. and Robins, P. K. (1995) Evaluating program evaluations: New evidence on commonly used nonexperirnental methods. American Economic Review, 85, 923-937.
Gastwirth, J. L., Krieger, A. M., and Rosenbaum, P. R. (1997) Hypotheticals and hypotheses. American Statistician, 51, 120-121.
Herbst, A., Ulfelder, H., and Poskanzer, D. (1971) Adenocarcinoma of the vagina: Association of maternal stilbestrol therapy with tumor appearance in young women. New England Journal of Medicine , 284, 878-881.
Hoffer, T ., Greeley, A., and Coleman, J . (1985) Achievement growth in public and Catholic schools. Sociology of Education, 58, 74-97.
LaLonde, R. (1986) Evaluating the econometric evaluations of training programs with experimental data. American Economic Review, 76, 604-620.
Meier, P. (1972) The biggest public health experiment ever : The 1954 field trial of the Salk poliomyelitis vaccine . In : Statistics: A Guide to the Unknown, J . Tanur, ed ., San Francisco: Holden-Day, pp . 2-13.
Moertel, C., Fleming, T ., Creagan, E., Rubin, J ., O'Connell, M., and Ames, M. (1985) High-dose vitamin C versus placebo in the treatment of patients with advanced cancer who have had no prior chemotherapy : A randomized double-blind comparison. New England Journal of Medicine, 312, 137-141.
Popper, K. (1959) The Logic of Scientific Discovery. New York: Harper & Row.
Popper, K. (1994) The Myth of the Framework. New York: Routledge.
United States Surgeon General's Advisory Committee Report (1964) Smoking and Health. Washington, DC : US Department of Health, Education and Welfare.
Wittgenstein, 1. (1969) On Certainty. New York: Harper & Row.
Zwick , R . (1991) Effects of item order and context on estimation of NAEP reading proficiency. Educational Measurement: Issues and Practice, 3, 10-16.

2
Randomized Experiments
2.1 Introduction and Example: A Randomized Clinical Trial
Observational studies and controlled experiments have the same goal , inference about treatment effects, but random assignment of treatments is present only in experiments. This chapter reviews the role of randomization in experiments, and so prepares for discussion of observational studies in later chapters. A theory of observational studies must have a clear view of the role of randomization, so it can have an equally clear view of the consequences of its absence. Sections 2.1 and 2.2 give two examples: a large controlled clinical trial , and then a small but famous example due to Sir Ronald Fisher, who is usually credited with the invention of randomization, which he called the "reasoned basis for inference" in experiments. Later sections discuss the meaning of this phrase, that is, the link between randomization and statistical methods. Most of the material in this chapter is quite old.
Randomized Trial of Coronary Surgery
The US Veterans Administration (Murphy et al. 1977) conducted a randomized controlled experiment comparing coronary artery bypass surgery with medical therapy as treatments for coronary artery disease. Bypass surgery is an attempt to repair the arteries that supply blood to the heart, arteries that have been narrowed by fatty deposits. In bypass surgery, a

20 2. Randomized Exp eriments
TABLE 2.1. Base-Line Comparison of Coronary P ati ents in the Vet erans Administration Randomized Tr ial.

Covariate

Medic al Surgical

%

%

New York Heart Association

Class II & III

94.2

95.4

History of myocardial

infarction (MI)

59.3

64.0

Definite or possible MI

based on elect rocardiogram 36.1

40.5

Duration of chest pain

> 25 months

50.0

51.8

History of hypertension

30.0

27.6

History of congestive

heart failur e

8.4

5.2

History of cerebral

vascular episode

3.2

2.1

History of diab et es

12.9

12.2

Cardiothoracic ratio > 0.49

10.4

12.2

Serum choleste rol

> 249 mg/lOO ml

31.6

20.6

bypass or bridge is formed around a blockage in a coronary artery. In contrast, medic al therapy uses drugs to enhance the flow of blood through narrowed arteries. The st udy involved randomly assigning 596 patients at 13 Veterans Administration hospitals, of whom 286 received surgery and 310 received drug tr eatments . The random assignment of a treatment for each patient was det ermined by a central office afte r the patient had been admitted into th e tri al.
Table 2.1 is t aken from th eir st udy. It compares the medic al and surgical treatment groups in term s of 10 important charac te rist ics of patients measured at "base-line," th at is, prior to the st art of treatment. A vari abl e measur ed prior to th e start of tr eatment is called a covariate . Similar t ables appear in reports of most clinical trials.
Table 2.1 shows th e two groups of patients were simil ar in many important ways prior to th e start of treatment, so that compara ble groups were being compared. Wh en th e percentages for medi cal and surg ical are compa red, th e difference is not significant at th e 0.05 level for nine of the variables in Table 2.1, but is significant for serum choleste ro l. This is in line with what one would expect from 10 significan ce t est s if the only dif-

2.2 The Lad y Tast ing Tea 21
fer ences were due to cha nce , t hat is, du e to t he choice of random numb ers used in ass igning trea tments.
For us, Table 2.1 is important for two reasons. Fir st , it is an exa mple showing t hat randomiz ation t ends to pr oduce relati vely compa ra ble or balanced treatment groups in large experiment s. The second point is sepa rate and more important. The 10 covaria tes in Table 2.1 were not used in assigning treatments. T here was no deliberate ba lancing of t hese var iables. Rather t he balance we see was produced by the random ass ignment, which made no use of t he variables t hemselves. This gives us some reaso n to hope and expect t hat ot her variables, not measured, are similar ly balanced . Indeed , as shown shortly, statistical t heory supports t his expectation. Had the trial not used random ass ignme nt , had it instead assigned patients one at a t ime t o balance these 10 covari ates, th en the balan ce might well have bee n better than in Tabl e 2.1, but there would have been no basis for expec ting ot her unmeasured vari ables to be similar ly balanced.
The VA study com pared survival in the two groups three years aft er treatment. Survival in the med ical group was 87% and in the surgical group 88%, both with a standard error of 2%. The 1% differe nce in mort ality was not significant. Evidently, when compara ble groups of pat ients received medical and surgical treatment at t he VA hospitals, t he outcomes were quite similar.
The state me nt t hat random ization te nds to balance covariates is at best imprecise; t aken too lit erally, it is misleading. For instance , in Tabl e 2.1, the gro ups do differ slightl y in terms of ser um cholesterol. Presumably there are ot her vari abl es, not measured , exhibit ing imb alan ces similar to if not greate r than that for serum choleste rol. What is pr ecisely true is that random assig nme nt of treatm ent s can prod uce some imba lances by chance , but common statist ica l methods, prop erly used , suffice to address t he un cer t ainty introdu ced by these cha nce imbalances. To t his sub ject, we now t ur n.
2.2 The Lady Tasting Tea
"A lady declar es that by t asting a cup of t ea made with milk she can discriminate whether the milk or the t ea infusion was first added to the cup," or so begins t he second cha pter of Sir Ronald Fisher 's (1935, 1949) book The Design of Experim ent s, which introdu ced t he form al pro pert ies of randomi zation. This example is part of the tradition of statist ics, a nd in addit ion it was well selected by Fisher to illustrate key points. He cont inues:
Our expe riment consists in mixing eight cups of tea, four in one way and four in t he ot her, and presentin g t hem to t he subject for judgement in a random order. The subjec t has been told in advan ce of what the test will consist, namely that she

22 2. Randomized Experiments
will be asked to taste eight cups, that these shall be four of each kind , and that they shall be presented to her in a random order, that is in an order not determined arbitrarily by human choice, but by the actual manipulation of the physical apparatus used in games of cha nce, cards, dice, roulettes, etc., or more expeditiously, from a published collection of random sampling numbers purporting to give the actual results of such a manipulation. Her task is to divide the 8 cups into two sets of 4, agreeing, if possible , with the treatments received.
Fisher then asks what would be expected if the Lady was "wit hout any faculty of discrimination," that is, if she makes no changes at all in her judgments in response to changes in the order in which tea and milk are added to the cups. To change her judgments is to have some faculty of discrimination, however slight. So suppose for the moment that she cannot discriminate at all, that she gives the same judgments no matter which four cups receive milk first. Then it is only by accident or chance that she correctly identifies the four cups in which milk was added first. Since there
are (~) = 70 possible divisions of the eight cups into two groups of four ,
and randomization has ensured that these are equally probable, the chance of this accident is 1/70. In other words, the probability that the random ordering of the cups will yield perfect agreement with the Lady's fixed judgments is 1/70 . If the Lady correctly classified the cups, this probability, 0.014 = 1/70, is the significance level for testing the null hypothesis that she is without the ability to discriminate.
Fisher goes on to describe randomization as the "reasoned basis" for inference and "t he physical basis of the validity of the test"; indeed, these phrases appear in section headings and are clearly important to Fisher. He explains:
We have now to examine the physical conditions of the experimental technique needed to justify the assumption that, if discrimination of the kind under test is absent, the result of the experiment will be wholly governed by the laws of chance . . . .
It is [not sufficient] to insist that "all the cups must be exactly alike" in every respect except that to be tested. For this is a totally impossible requirement in our example, and equally in all other forms of experimentation . . . .
The element in the experimental procedure which contains the essential safeguard is that the two modifications of the test beverage are to be prepared "in random order." This, in fact, is the only point in the experimental procedure in which the laws of chance, which are to be in exclusive control of our frequency distribution, have been explicitly introduced.

2.3 Randomized Experiments 23
Fisher discuss es this example for 15 pages, though its formal asp ects are eleme nt ary and occupy onl y a part of a par agraph. He is determ ined to establish that randomization has justified or grounded a particular inference, formed its "reasoned basis," a basis that would be lacking had the same pattern of responses, the same data, been observed in the absence of randomization .
The example serves F isher 's purpose well. The Lady is not a sample from a population of Ladies, and even if one could imagine that she was, ther e is but on e Lady in the experiment and the hypothesis concerns her alone. Her eight judgments ar e not independ ent observations, not least becau se the rul es require a split into four and four . Later cups differ from ear lier ones, for by cup number five, the Lady has surely t ast ed one with milk first a nd one with tea first. There is no way to const rue, or perhaps misconstrue, the data from this experiment as a sampl e from a population, or as a seri es of indep endent and identical replicates. And yet , Fisher 's infer ence is justified , bec ause the only probability distribution used in the inference is the one crea te d by the experiment er.
What are the key elements in Fisher 's argument? First, experiments do not require, ind eed ca nnot reasonably require, that experimental units be homogeneous, without vari ability in their responses. Homogeneous experimental units ar e not a realistic description of factory operations, hospital patients, agricultural fields. Second, experiments do not require, indeed, cannot reasonably require, that exp erimental units be a random sample from a population of units. Random samples of experimental units are not the reality of the industrial laboratory, the clinical trial, or the agricult ur al experiment. Third, for valid infer ences about the effect s of a treatment on the units included in an experiment, it is sufficient to require that treatments be allocated at random to experimental units-these units may be both heterogeneous in their responses and not a sample from a population. Fourth, probability enters the experiment only through the random assignment of treatments, a process controlled by the experiment er. A quantity that is not affecte d by the random assignment of treatments is a fixed quantity describing the units in the experiment.
The next section repeats F isher's argument in more general terms.
2.3 Randomized Experiments
2.3.1 Units and Treatment Assignments
There are N units available for experimentation. A unit is an opportunity to apply or withhold the treatment. Often, a unit is a person who will receive either the treatment or the control as determined by the experiment er. However, it may happen that it is not possible to assign a treatment to a single person, so a group of people form a single unit, perhaps all children

24 2. Randomized Experiments
in a particular classroom or school. On the other hand, a single person may present several opportunities to apply different treatments, in which case each opportunity is a unit; see Problem 2. For instance, in §2.2, the one Lady yielded eight units.
The N units ar e divided into 5 strata or subclasses on the basis of covariates, that is, on the basis of characteristics measured prior to the assignment of treatments. The stratum to which a unit belongs is not affected by the treatment, since the strata are formed prior to treatment. There are
n s units in stratum s for s = 1, . . . , 5, so N = L n s ·
Write Z si = 1 if the ith unit in stratum s receives the treatment and
write Z si = 0 if this unit receives the control. Write ni; for the number of
treated units in stratum s , so m s = L ~~l Zsi, and 0 :::; m s :::; n s . Finally,
write Z for the N-dimensional column vector containing the Z si for all units in the lexical order; that is,

Z=

[:: ] z., ] where Z; = [

(2.1)

Z s ,n s

ZS,n s
This notation covers several common situations. If no covariates are used to divide the units, then there is a single stratum containing all units, so
S = 1. If ns = 2 and m s = 1 for s = 1, .. . ,5, then there are 5 pairs of units
matched on the basis of covariates, each pair containing one treated unit
and one control. The situation in which n s ~ 2 and tti; = 1 for s = 1, .. . ,5
is called matching with multiple controls. In this case there are 5 matched sets , each containing one treated unit and one or more controls.
The case of a single stratum, that is S = 1, is sufficiently common and important to justify slight modifications in notation. When there is only a single stratum the subscript s is dropped, so Z, is written in place of Zli ' The same convention applies to other quantities that have subscripts sand i.

2.3.2 Several Methods of Assigning Treatments at Random
In a randomized experiment, the experimenter determines the assignment of treatments to units, that is the value of Z , using a known random mechanism such as a table of random numbers. To say that the mechanism is known is to say that the distribution of the random variable Z is known because it was created by the experimenter. One requirement is placed on this random mechanism, namely, that, before treatments are assigned,

2.3 Randomized Experiments 25

every unit has a nonzero chance of receiving both the treatment and the
control, or formally that 0 < prob(Zsi = 1) < 1 for s = 1, . . . ,S and
i = 1, . . . ,ns . Write no for the set containing all possible values of Z, that
is, all values of Z which are given nonzero probability by the mechanism. In practice, many different random mechanisms have been used to deter-
mine Z. The simplest assigns treatments independently to different units,
taking prob(Zsi = 1) = 1/2 for all s, i . This method was used in the Veter-
ans Administration expe rime nt on coronary artery surgery in §2.1. In this
case, no is the set containing 2N possibl e values of Z, namely, all N-tuples of zeros and ones, and every assignment in no has the same probability; that is, prob(Z = z) = 1/2 N for all z E no. The number of elements in a set A is written IAI , so in this case Inol = 2N . This mechanism has the
peculiar property that ther e is a nonzero probability that all units will be assigned to the same treatment, though this probability is ext remely sma ll when N is moderately large. From a practi cal point of view, a more import ant problem with this mechani sm aris es when S is fairly larg e compared to N . In this case, the mechanism may give a high probability to the set of treatment assignments in which all units in some stratum receive the same treatment. If the strata were typ es of patients in a clinical tri al, this would mean that all patients of some type received the same tre atment . If the strata wer e schools in an educa t ional experiment , it would mean that all children in some scho ol received the same treatment. Other assignment mechanisms avoid this possibility.
The most commonly used assignment mechanism fixes the numb er rn, of treated subjects in stratum s. In other words, the only assignments Z with nonzero probability are those with m ; treated subjects in stratum s for s = 1, ... ,S. If m ; is chosen sensibly, this avoids the problem mentioned in the previous par agraph. For instan ce, if n s is required to be even and
m.; is required to equal ns /2 for each s , then half th e units in each stratum
receive the treatment and half receive the cont rol, so the final treated and control groups ar e exactl y balanced in the sense that they cont ain the same number of units from each stratum.
When ms is fixed in this way, let n be th[e z:s~t jcontaining the K =

[1:=1 C:;:) possible treatment assignments z =

in which z, is an n s-

tuple with m s ones and n s - m s zeros for s = 1, . . . , S. In the most common assignme nt mechanism, each of these K possible assignments is given the
same probability, prob(Z = z) = I /K all zEn. This typ e of randomized
expe rime nt , with equa l probabilities and fixed m s , will be called a unif orm randomized experimen t . When there is but a single st rat um, S = 1, it has
trad itionally been called a com pletely randomized experiment , but when
ther e are two or mor e strata, S 2: 2, it has been called a randomized
block experimen t . If the strata each contain two units, n s = 2, and one

26 2. Randomized Exp eriment s

receives the tre atment , m s = 1, then it has b een called a paired randomized
experime nt .
As a small illustration, consid er a uniform randomized experiment with
two st rata, S = 2, four units in the first stratum, nl = 4, a nd two in the second, n2 = 2, and N = nl +n2 = 6 units in total. Half of the units in each strat um receive the treatment , so ml = 2 and m 2 = 1. There ar e K = 12
possible treatment assignments Z = ( Zll ' Z12 , Z13, Z14, Z2b Z22)T contained in the set n, and each has probability 1/12. So n is the following set of
K = 12 vectors z of dim ension N = 6 with binary coordinates such that 2 = Zll + + + Z12 Z13 Z14 and 1 = Z21 + Z22.

1

1

1

0

0

0

1

0

0

1

1

0

0

1

0

1

0

1

0

0

1

0

1

1

1

1

1

1

1

1

0

0

0

0

0

0

n=

1

1

1

0

0

0

1

0

0

1

1

0

0

1

0

1

0

1

0

0

1

0

1

1

0

0

0

0

0

0

1

1

1

1

1

1

The following proposition is oft en useful. It say s that in a uniform random ized expe riment , the assignments in different strata ar e ind ep endent of each ot her. For the elementary proof, see Problem 3.

Proposition 1 In a unif orm random ized experi ment, the Zl , . . . , Z s are
mutually independent, and probf Z; = z s) = 1/ (;:'~J for each ns- tu ple z,
containi ng m s ones and n s - m ; zeros.

The uniform randomized designs are by far the most common randomized expe riments involving two treatments, but ot hers are also used , particularly in clinical t rials. It is useful t o mention one of these methods of ra ndomizatio n to und erscore the point that randomized experiment s need
no not give every treatment assignment z E the sa me probability. A dis-
tinguishing feature of many clinical t rials is that the units are patients who arr ive for treatment over a period of months or years. As a result, the number n s of people who will fall in st rat um s will not be known at the start of the experiment, so a randomized block expe rime nt is not po ssible. Efron (1971) pr oposed the following method. Fix a probability p with
1/2 < p < 1. When the it h patient belon ging to st rat um s first arr ives,
calculate a current measure of imbalance in st rat um s, IMBALs i , defined to be the numb er of patients .so far assigned to treatment in this st ratum minus the numb er so far assigned t o cont rol. It is easy to check that

2.4 Testing the Hypothesis of No Treatment Effect 27
IMBALs i = L:j:'~ (2Zsj - 1). If IMBAL s i = 0, assign the new patient to
treatment or control each with probability 1/2. If IMBAL s i < 0, so there
are too few treated patients in this stratum, then assign the new patient to treatment with probability p and to control with probability 1 - p. If
IMBALs i > 0, so there are too many treated patients, then assign the new
patient to treatment with probability 1 - P and to control with probability p. Efron examines various aspects of this method. In particular, he shows that it is much better than independent assignment in producing balanced treated and control groups, that is, treated and control groups with similar numbers of patients from each stratum. He also examines potential biases due to the experimenter's knowledge of IMBAL si ' Zelen (1974) surveys a number of related methods with similar objectives.
2.4 Testing the Hypothesis of No Treatment Effect
2·4.1 The Distribution of a Test Statistic lVhen the Treatment Is Without Effect
In the theory of experimental design, a special place is given to the test of the hypothesis that the treatment is entirely without effect. The reason is that , in a randomized experiment, this test may be performed virtually without assumptions of any kind, that is, relying just on the random assignment of treatments. Fisher discussed the Lady and her tea with such care to demonstrate this. Other activities, such as estimating treatment effects or building confidence intervals, do require some assumptions, often innocuous assumptions, but assumptions nonetheless. The contribution of randomization to formal inference is most clear when expressed in terms of the test of no effect. Does this mean that such tests are of greater practical importance than point or interval estimates? Certainly not. It is simply that the theory of such tests is less cluttered, and so it sets randomized and nonrandomized studies in sharper contrast. The important point is that, in the absence of difficulties such as noncompliance or loss to follow-up, assumptions play a minor role in randomized experiments, and no role at all in randomization tests of the hypothesis of no effect. In contrast, inference in a nonrandomized experiment requires assumptions that are not at all innocuous. So let us follow Fisher and develop this point with care.
Each unit exhibits a response that is observed some time after treatment. To say that the treatment has no effect on this response is to say that each unit would exhibit the same value of the response whether assigned to treatment or control. If the treatment has no effect on a patient's survival, then the patient would live the same number of months under treatment or under control. This is the definition of "no effect." If changing the treatment assigned to a unit changed that unit's response, then certainly the treatment has at least some effect. If a patient would live one

28 2. Rand om ized Exp erime nts
more month und er t reatment tha n und er cont rol, t hen t he t reatme nt has some effect on that patient .
In t he tradition al development of randomiz ation inference, chance and pro bability enter only t hroug h the ra ndom ass ignme nt of t reatments, that is, throu gh th e known mechanism t hat selects the treat ment ass ignme nt Z
from n. The only random qu antities are Z and qu an ti ti es t hat dep end on
Z. W hen t he treat ment is with out effect , the resp onse of a uni t is fixed , in the sense that thi s response would not cha nge if a differ ent treatment
assignment Z were selected from n. Again, t his is simply what it mean s
for a treatment to be without effect. When t esting the null hyp othesis of no effect , t he response of the ith unit in stratum s is written Ts i and the N -tuple of responses for all N units is written r . The lower case not ation for r si emphas izes that , und er the null hypothesis, r si is a fixed qu antity and not a random variable. Later on, when discussing treatments with effects , a different not ation is needed.
A test stat ist ic t(Z , r) is a qu antity compute d from the treatment assignment Z and the response r. For instan ce, the treated-minus-control difference in sample means is th e test stat istic

(2.2)

where 1 is an N -t uple of Is. Other stat ist ics ar e discussed shortly. Given any tes t stat istic t(Z , r ), the task is t o compute a significance
level for a test t hat rejects the null hyp othesis of no treat me nt effect when t( Z , r ) is lar ge. More precisely:

(i) The null hyp otheses of no effect is t ent atively ass umed to hold , so r is fixed.
n (ii) A treatment assignment Z has been selecte d from usin g a known
random mechanism .

(iii) The observed value, say T , of the t est st at istic t (Z , r ) has been calculat ed .

(iv) We seek the probability of a value of the t est st at ist ic as lar ge or larger than that observed if the null hypothesis were true.

The significance level is simply the sum of the randomization probabilities
of assignme nts z En that lead t o valu es of t(z , r) greate r than or equal to
the observed valu e T , namely,

prob{t(Z, r ) ~ T} = 2)t(z , r ) ~ T] . prob(Z = z),

(2.3)

z En

where [event]

{~ if event occurs , o t her wise ,

(2.4)

2.4 Testing t he Hypoth esis of No Tr eatment Effect 29

and prob( Z = z ) is det ermined by th e known random mechanism t hat as-
signed treatments. This is a direct calculat ion, t hough not always a st raig ht-
forwar d one when 0 is extremely large.
In the case of a uniform randomized expe riment, t here is a simp ler ex-
pression for the significance level (2.3) since pr ob(Z = z) = 1/K = 1/101.
It is the proportion of treatment assignments z E 0 giving values of the test statist ic t (z , r ) greate r than or equa l to T , namely,

prob{t (Z , r ) 2: T } -_

I{z E O: t( z, r ) 2: T } I

K

.

(2.5)

2.4.2 More Tea
To illustrat e, consider again Fi sher 's example of the Lady who tastes N = 8 cups of t ea , all in a single st rat um, so S = 1. A treatment assignment is an 8-t uple containing four I s and four Os. For inst an ce, the assignment Z = (1, 0, 0, 1, 1, 0,0, l )T would signify that cups 1, 4, 5, and 8 had milk added first and the ot her cups had tea ad ded first. The set of treatment assignments 0 contains all possible 8-t up les containing four I s and four Os,
so 0 contains 101= K = (~) = 70 such 8-tuples. T he actua l assignme nt was selected at random in t he sense that prob(Z = z ) = 1/ K = 1/70 for
all z E O. Notice t hat zTl = 4 for all z E O.
The Lad y 's resp onse for cup i is eit her r, = 1 signifying t hat she classifies this cup as milk first or ri = 0 signifying that she classifies it as tea first. Then r = (r I, . .. ,rs)T. Recall t hat she must classify exac t ly four cups as
milk first , so IT r = 4. The t est stat istic is the number of cups correct ly identified , and this is writ t en for mally as t (Z ,r) = ZTr + (l-Z )T(l -r) =
2ZTr , where t he second equality follows from 1T1 = 8, ZT1 = 4, and IT r =
4. To make t his illustration concrete, suppose that r = (1, 1,0,0 ,0, 1, 1,0) , so t he Lad y classifies t he first , second , sixth, and sevent h cups as milk first. To say t hat the treatment has no effect is to say that she would give t his classification no matter how milk was added to the cups , that is, no matter how t reatme nts were ass igned t o cups. If cha nging the cups to which milk is added first changes her resp onses, t hen she is discerning somet hing, and the treatment has some effect, however slight or errat ic.
There is only one treatment assignment z E 0 leading to perfect agreement with the Lad y 's resp onses, namely, z = (1, 1, 0, 0, 0, 1, 1, 0), so if
t( Z , r) = 8 the significance level (2.5) is prob{t (Z ,r) 2: 8} = 1/70. This
says that t he chance of perfect agreement by accident is 1/70 = 0.014, a small chance . In other words , if t he t reatment is without effect, the chance that a ran dom assignme nt of treat ments will just hap pen to produce pe rfect agreement is 1/70.
It is not possible to have seven agreements since to err once is to err twice.
How many ass ignments z E 0 lead to exact ly t (Z , r ) = six agree ments? One such ass ignme nt with six agree ments is z = (1,0, 1, 0, 0, 1, 1,0). Starti ng

30 2. Randomized Experiments
° with perfect agreement, z = (1,1,0,0,0,1,1 ,0), anyone of the four Is
may be made a and any of the four Os may be made a L, so there are
16 = 4 x 4 assignments with exactly t(Z, r) = 6 agreements. Hence, there
are 17 assignments leading to six or more agreements. With six agreements
the significance level (2.5) is prob{t(Z, r) ~ 6} = 17/70 = 0.24, no longer a
small probability. It would not be surprising to see six or more agreements if the treatment were without effect-it happens by chance as frequently as seeing two heads when flipping two coins .
The key point deserves repeating. Probability enters the calculat ion only through the random assignment of treatments. The needed probability distribution is known , not assumed. The resulting significance level do es not depend upon assumpt ions of any kind. If the same calculation were performed in a nonrandomized study, it would require an assumption that
the distribution of treatment assignments, prob(Z = z) , is some particu-
lar distribution, perhaps the assumption that all assignments are equ ally
probable, prob(Z = z) = I/K. In a nonrandomized study, there may be
little basis on which to ground or defend this assumption , it may be wrong, and it will certainly be open to responsible chall enge and debate. In other words , the importance of the argument just considered is that it is one way of formall y expressing the claim that randomized experiments are not open to certain challenges that can legitimately be made to nonrandomized studies.
2.4.3 Some Common Randomization Tests
Many commonly used tests are randomization tests in that their significance levels can be calculated using (2.5), though the tests are sometimes derived in other ways as well. This section briefly recalls and reviews some of these tests. The purpose of the section is to provide a reference for these methods in a common terminology so they may be discussed and used at later stages. Though invented at different times, it is natural to see the methods as members of a few classes whose properties are similar, and this is done beginning in §2.4.4. In most cases, the methods described have various optimality properties which are not discussed here; see Cox (1970) for the optimality properties of the procedures for binary outcomes and Lehmann (1975) for optimality properties of the nonparametric procedures. In all cases, the experiment is the uniform randomized experiment
in §2.3.2 with prob(Z = z) = 1/K for all zEn.
Fisher 's exact test for a 2 x 2 contingency table is, in fact , the test just used for the example of the Lady and her tea. Here, there is one stratum,
S = 1; the outcome r , is binary, that is, ri = 1 or ri = 0; and the test
statistic is the number of responses equal to 1 in the treated group, that
is, t(Z , r) = ZTr . The 2 x 2 contingency table records the values of Z, and
r i, as shown in Table 2.2 for Fisher's example. Notice that the marginal totals in this table are fixed by the structure of the exp eriment, because

2.4 Testing the Hypothesis of No Treatment Effect 31

TABLE 2.2. The 2 x 2 Table for Fisher's Exact Test for the Lady Tasting Tea .

Response, ri

1

o Total

Treatment or control, Zi 1

4

o

4

Total

4

4

8

N = 8 cups, IT r = 4 and IT Z = 4 are fixed in this experiment. Under the
hypothesis of no effect, the randomization distribution of the test statistic ZT r is the hypergeometric distribution. The usual chi-square test for a 2 x 2 table is an approximation to the randomization significance level when N is large.
The Mantel-Haenszel (1959) statistic is the analogue of Fisher's exact test when there are two or more strata, S 2: 2, and the outcome r si is binary. It is extensively used in epidemiology and certain other fields. The data may be recorded in a 2 x 2 x S contingency table giving treatment Z by outcome r by stratum s, The test statistic is again the number of 1
responses among treated units, t(Z,r) = ZTr = 2::;=1 2::~~lZsirs i' Under
the null hypothesis, the contribution from stratum s, that is, 2::~lZsirsi, again has a hypergeometric distribution, and (2.5) is the distribution of the sum of S independent hypergeometric variables. The Mantel-Haenszel statistic yields an approximation to the distribution of ZT r based on its expectation and variance, as described in more general terms in the next section. One technical attraction of this statistic is that the large sample approximation tends to work well for a 2 x 2 x S table with large N even if S is also large, so there may be few subjects in each of the S tables. In particular, the statistic is widely used in matching with multiple controls,
in which case m s = 1 for each s.
McNemar's (1947) test is for paired binary data, that is, for S pairs with
n s = 2, m s = 1, and rsi = lor rsi = O. The statistic is, yet again, the num-
ber of 1 responses among treated units; that is, t(Z , r) = ZT r . McNemar's statistic is, in fact, a special case of the Mantel-Haenszel statistic, though the 2 x 2 x S table now describes S pairs and certain simplifications are possible. In particular, the distribution of ZT r in (2.5) is that of a constant
plus a certain binomial random variable. Developing these methods for 2 x 2 x S tables in a different way, Birch
(1964) and Cox (1966, 1970) show that these three tests with binary responses possess an optimality property, so there is a sense in which Fisher's exact test, the Mantel-Haenszel test , and McNemar's test are the best tests for the problems they address. Specifically, they show that the test statistic t(Z , r) = ZT r together with the significance level (2.5) is a uniformly most powerful unbiased test against alternatives defined in terms of constant odds ratios.

32 2. Ran dom ized Experiments
Mantel 's (1963) extension of t he Ma ntel- Haenszel test is for resp onses Tsi that are confined to a small number of values representing a numerical scoring of severa l orde red categories. As an example of suc h an outcome, the New York Hear t Association classifies coronary patients into one of four categories based on t he degree to which t he pat ient is limi ted in physica l activity by coronary symptoms such a." chest pai n. The categories are :
(1) no limit ation of physical act ivity;
(2) slight limit ation , comfortable a t rest, bu t ord ina ry phys ical activity results in pain or ot her symptoms;
(3) marked limit ation , minor act ivit ies result in coro nary sy mp toms; and
(4) un able to carryon any physical act ivity without discomfort, whi ch may be pr esent even at rest .
The outco me Tsi for a patient is then one of the integers 1, 2, 3, or 4. In thi s case the dat a might be recorde d as a 2 x 4 x S cont ingency t abl e for Z x T X s. Ma ntel's test statistic is t he sum of the resp onse scores for treated units; t ha t is, t( Z, r ) = ZTr . Birch (1965) shows that t he test is optimal in a certain sense.
In t he case of a single st ratum, S = 1, Wilcoxon's (1945) rank sum test is commonly used to compare outcomes t aking many numer ical values . In t his test , the responses are ranked from smallest t o lar gest . If all N resp ons es were different num bers, t he ran ks woul d be t he nu mb ers 1, 2, . . . ,N. If some of the responses were equal, then the average of t heir ranks would be
used . Write qi for t he rank of ri , and writ e q = ( q 1, ' " , q N )T. For inst an ce,
if N = 4, = and T1 2.3, T2 = 1.1, T3 = 2.3, and T4 = 7.9, t hen q1 = 2.5, qz = 1, qs = 2.5, and q4 = 4, since T2 is smallest , T4 is largest, and r1
and T3 sha re the rank s 2 and :3 whose average rank is 2.5 = (2 + 3)/ 2.
Note that the ranks q are a function of the resp onses r which a re fixed if th e treatment has no effect, so q is also fixed . The rank sum statist ic is th e sum of the ranks of t he treated observat ions, t( Z , r ) = ZTq , and it s significance level is det ermined from (2.5). The prop erties of the rank sum test have been exte nsively st udied; for instance, see Lehmann (1975, §1) or Hettmansperger (1984, §3). Wilcoxon's rank sum t est is equivalent to the Mann and Whitn ey (1947) test .
In the case of S mat ched pairs with n s = 2 and m; = 1 for s = 1, . . . , S,
Wilcoxon 's (1945) signed rank test is commonly used for resp ons es t aking many values. Here, (Zs l, Zs2) = (1, 0) if the first unit in pair s received the treat ment or (Z sl , Zs2) = (0, 1) if t he second unit received the treatment. In t his tes t , the absolute differences in responses within pairs [rs l - T s21 are ranked from 1 to S, with average ranks used for ties. Let d; be the rank of ITsl -rs21 thus obtain ed. The signed rank stat istic is t he sum of the ranks for pairs in which t he t reated unit had a higher resp onse t ha n t he cont rol unit.

2.4 Testin g the Hypothesis of No Treatment Effect 33
To write t his formally, let Cs l = 1 if Ts l > Ts2 and Cs l = 0 ot herwise, and simi larly, let Cs2 = 1 if rs2 > rsl and Cs2 = 0 ot herwise, so Cs l = Cs2 = 0 if rsl = rs2 . Then Zsl Csl + Z s2Cs2 equals 1 if t he t reated unit in pair s
had a higher resp onse t han t he control unit , and equals zero otherwise. It follows t hat t he signed rank st at ist ic is 'L ~= l ds 'L ;=ICsiZsi . Note that ds and Csi are fun ct ions of r and so are fixed unde r the null hypot hesis of no t reatment effect . Also, if r s l = rs2 , t hen pa ir s cont ributes zero to t he value of t he statistic no matter how treatments are ass igned . As wit h t he ra nk su m test , t he signed rank test is widely used and has been extensively stud ied; for inst an ce, see Lehmann (1975, §3) or Hett man sp erger (1984, §2). Section 3.2.4 below contains a numerical example using the sign-rank statist ic in an obse rvational study.
For st ratified resp onses, a meth od t ha t is sometimes used involves calcula t ing t he rank su m statis tic sepa rately in each of t he S strata, and taking the sum of t hese S rank sums as the t est statis t ic. This is t he stratified rank sum statistic. It is eas ily checked that thi s stat istic has the form
t( Z, r) = ZT q resembling t he rank sum stat istic; however , the rank s in q
are no lon ger a permut ation of t he numb ers 1, 2, .. . ,N, but rath er of the number s 1, . .. ,nl , 1, . .. ,n2, . . . , 1, . . . , n s , with adjustments for ties if
n needed. Also has cha nged.
Hodges and Leh mann (1962) find the stratified rank sum statist ic to be inefficient whe n S is large compared to N . In particular, for paired
da t a with S = N / 2, t he stratified rank tes t is equivalent to t he sign test ,
which in turn is substantially less efficient than the signed rank test for data from short-t ailed dist ributions such as t he Normal. T hey suggest as an alte rnative t he method of aligned ran ks: t he mean in each st ratum is subtracted from t he responses in that st ratum creating aligned responses t hat are ranked from 1 to N , momentarily ignoring t he st rata. Writing q for t hese aligned ranks, the aligned rank statistic is the sum of t he aligned ran ks in t he t reate d group, t( Z , r ) = ZTq . See also Leh man n (1975, §3.3).
Another st at ist ic is t he median test. Let Csi = 1 if rsi is greater t ha n t he med ian of the responses in stratum s and let Csi = 0 ot herwise, and let c be the N -t uple containing t he Csi. Then t( Z, r ) = ZT c is the number of t reate d
resp onses that excee d their st rat um medians . Wi th a single stra t um, S = 1,
the medi an t est is quite goo d in large samples if the responses have a double exponent ial distribution , a distribution with a thicker t ail than the normal ; see , for inst anc e, Hettman sp erger (1984, §3.4, p. 146) and the more crit ical com me nts by Freidlin and Gastwirth (2000). In t his t est , the median is some t imes replaced by ot her quant iles or other measures of location.
St art with any statist ic t (Z , r ) and the randomizati on distribution of t( Z , r ) may be determined from (2.5). This is true even of statist ics that are commonly referred to a t heoret ical distribution inst ead , for instance, the two-sam ple or paired t- tes ts , among ot hers . Welch (1937) and Wilk (1955) st udied the relationship betwee n the randomizat ion distribution and t he theoret ical distr ibution of statistics tha t were init ially derived from

34 2. Randomized Experiments
assumptions of Normally and independently distributed responses. They suggest that the theoretical distribution may be viewed as a computationally convenient approximation to the desired but computationally difficult randomization distribution. That is, they suggest that t-tests , like rank tests or Mantel-Haenszel tests, may be justified solely on the basis of the use of randomization in the design of an experiment, without reference to Normal independent errors. These findings depend on the good behavior of moments of sums of squares of responses over the randomization distribution; therefore, they depend on the absence of extreme responses. Still, the results are important as a conceptual link between Normal theory and randomization inference.
2.4 .4 Classes of Test Statistics
The similarity among the commonly used test statistics in §2.4.3 is striking but not accidental. In this book, these statistics are not discussed individually, except when used in examples. The important properties of the methods are shared by large classes of statistics, so it is both simpler and less repetitive to discuss the classes .
Though invented by different people at different times for different purposes, the commonly used statistics in §2.4.3 are similar for good reason. As the sample size N increases, the number K of treatment assignments
in n grows very rapidly, and the direct calculation in (2.5) becomes very
difficult to perform, even with the fastest computers. To see why this is true, take the simplest case consisting of one stratum, S = 1, and an equal
division of the n subjects into m = n/2 treated subjects and m = n/2 controls. Then there are K = (n/2) treatment assignments in n. If one more
unit is added to the experiment, increasing the sample size to n + 1, then K is increased by a factor of (n + 1) / { (n/2) + 1}, that is, K nearly doubles.
Roughly speaking, if the fastest computer can calculate (2.5) directly for at most a sample of size n, and if computing power doubles every year for 10 years, then 10 years hence computing power will be 210 = 1024 times
greater than today and it will be possible to handle a sample of size n + 10.
Direct calculation of (2.5) is not practical for large n . The usual solution to this problem is to approximate (2.5) using a large
sample or asymptotic approximation. The most common approximations use the moments of the test statistic, its expectation and variance, and sometimes higher moments. The needed moments are easily derived for certain classes of statistics, including all those in §2.4.3.
As an alternative to asymptotic approximation, there are several proposals for computing (2.5) exactly, but they are not, as yet, commonly used. One is to compute (2.5) exact ly but indirectly using clever computations
that avoid working with the set n. For some statistics this can be done by
calculating the characteristic function of the test statistic and inverting it

2.4 Testing the Hypothesis of No Treatment Effect 35

using the fast Fourier transform; see Pagano and Tritchler (1983). A second
approach is to design experiments differently so that n is a much smaller
set, perhaps containing 10,000 or 100,000 treatment assignments. In this case, direct calculation is possible and any test statistic may be used; see Tukey (1985) for discussion.
The first class of statistics will be called sum statistics and they are of the form t(Z, r) = ZT q, where q is some function of r . A sum statistic sums the scores qsi for treated units. All of the statistics in §2.4.4 are sum statistics for suitable choices of q. In Fisher's exact test, the MantelHaenszel test, and McNemar's test , q is simply equal to r . In the rank sum test, q contains the ranks of r. In the median test, q is the vector of ones and zeros identifying responses r si that exceed stratJm medians. In the
signed rank statistic, qsi = dscsi' Simple formulas exist for the moments of sum statistics under the null
hypothesis that the treatment is without effect. In this case, r is fixed, so q is also fixed. The moment formulas use the properties of simple random sampling without replacement. Recall that a simple random sample without replacement of size m from a population of size n is a random subset of m
(;:J elements from a set with n elements where each of the subsets of size m
has the same probability l/(;:J Cochran (1963) discusses simple random
sampling. In a uniform randomized experiment, the m s treated units in stratum s are a simple random sample without replacement from the n; units in stratum s. The following proposition is proved in Problem 4.

Proposition 2 In a uniform randomized experiment, if the treatment has no effect, the expectation and variance of a sum statistic ZT q are

S
E(ZTq) = L mstIs,
s=1
and

where

var (ZTq)

=

L~ s
s=1

mnss((nnss --1m)s)

~ Ln ,(qsi
,.=1

-

- )2
qs ,

1 n.
tIs = - Lqsi .
ns i=1

Moments are easily determined for sum statistics, but other classes of statistics have other useful properties. The first such class, the sign-score statistics , is a subset of the sum statistics. A statistic is a sign-score statistic
if it is of the form t(Z, r) = 2::;;=1 ds 2::~~1 CsiZsi , where Csi is binary, c.. = 1
or Csi = 0, and both d; and Csi are functions of r . Fisher's exact test, the

36 2. Randomized Ex pe riments
Mantel-Haenszel test , and McNemar's t est are sign-score st atistics with
d, = 1 and Csi = rsi- The signed rank and median test statistics are
also sign-score statistics, but with Csi and d s defined differently. A sign-
score stat ist ic is a sum st atistic with q s i = d s c si ' but many sum statistics,
including th e rank sum st atistic, are not sign-score st atistics. In Chapter 4, certain calculations are simpler for sign-score st atistics than for certain other sum st atistics, and this motivates the distinction.
Another important class of st atistics is the class of arrang ement increasing fun ction s of Z and r, which are defined in a mom ent. Informally, a st atistic t(Z , r) is arrangement-increasing if it increases in valu e as the coordina tes of Z and r are rearran ged into an increasingly similar order within each stratum. In fact , all of the st atistics in §2.4.3 ar e arr angementincreasin g, so anything th at is true of arrangement -increasing statis tic s is true of all the commonl y used statistics in §2.3.2. Hollander , Proschan, and Sethuraman (1977) discuss many properties of arrangement-increasing functions.
A few pr eliminary terms are useful. The numbers S and n s , s = 1, .. . , S
with N = L ns, are taken as given. A stratified N -t uple a is an N -tuple
in which the N coordinates are divided into S st rat a with n s coordinates in stratum s, where asi is th e it h of the n s coordinates in stratum s . For instance, Z and r are each stratified N-tuples. If a is a stratified N-tuple, and if i and j are different positive integers less than or equal to n s , then let asij be the stratified N-tuple formed from a by interchanging asi and asj, th at is, by placing the value asj in the it h position in stratum s and placing the value asi in the jth position in stratum s. To avoid rep etition, whenever th e symbol asij appears, it is assumed without explicit mention that the subscripts ar e appropriate , so s is a positive integer betwe en 1 and S and i and j are different positive int egers less than or equ al to n s . A function f(a , b) of two stratified N-tuples is invari an t if f(a , b) = f(a sij , b sij) for all s, i , j , so renumbering units in th e sa me stratum does not change the value of f(a, b) . For inst ance, the fun ction zTq is an invariant function of z and q .
Definition 3 An inv ariant function f(a ,b) of two stratified N -tuples is arrang em ent-increasing (or AI) if f (a , b sij) ~ f (a ,b) when ever
Noti ce what this definition says. Consider the ith and jth unit in stratum
s. If (a si - asj)(bSi - bsj ) < 0, then of these two units, the one with the
higher value of a has th e lower value of b, so these two coordinates are out of order. However, in a and b sij, these two coordinates are in the same order , for bsi and bsj have been int erchang ed . The definition says that an arrangement increasing function will be larger, or at least no smaller, when these two coordinates are switched into the same order.

2.4 Testing t he Hyp oth esis of No Treatmen t Effect 37

TABLE 2.3. A Hyp otheti cal Exa mple Showing an Arran gement-Increasing Statist ic.

z q q23

1

Tr eated 1 4 4

2

Treated 1 2 3

3

Control 0 3 2

4

Control 0 1 1

Rank sum

67

Notice also what the definition says when (asi-asj )(bsi-bsj ) = O. In thi s
case, eit her asi = asj or bsi = bsj or both. In thi s case, f (a, b sij ) = f (a , b ).
Con sid er some examples. The function zTq is arrang ement-increasing as
a fun cti on of z and q. To see this, not e that zTq sij - ZT q = (Zsiqsj+ Zsjq s;)-
(Zsiqsi + zsjqsj) = -( Zsi - Zsj)(qsi -qsj) , so if (Zsi - Zsj)(qsi -qsj) ::::; 0 then zTq sij - z T q :::: O. This shows zTq is ar rangement-increasing.
Table 2.3 is a small illustration for t he rank sum statisti c with a single
strat um, S = 1, n = 4 units, of whom m = 2 received the treatment. Here, (Z2 - Z3)( q2 - q3) = (1 - 0)(2 - 3) = -1 ::::; 0, and t he rank sum zT q = 6 is increased to zTq 23 = 7 by interchan ging q2 and q3.
As a second example, consider the function t (z , r ) = zTq , where q is a
fun cti on of r , which may be written explicitl y as q (r ). Then t (z , r) mayor may not be arrangem ent-increas ing in z and r depending up on how q (r) varies with r . T he common statistics in §2.4.3 all have the following two p r o p e r t ies :
(i) permute r within strata and q is permuted in the same way; and
(ii) within each st rat um , larger rsi receive lar ger qsi-
On e readily checks that t( z , r ) = zTq is arran gement-increasing if q (r) has t hese two properties, because the first property ensures that t( z, r ) is invari ant , and the second ensures that rsi - rsj :::: 0 implies qsi - qsj :::: 0, so (Zsi - Zsj )(r si - r sj ) ::::; 0 implies (Zsi - Zsj )(qsi - qsj ) ::::; 0, and the argument of the pr evious paragraph applies. T he important conclusion is that all of the st at ist ics in §2.4.3 ar e arrangement-increasing.
In describing the behavior of a st at ist ic when the null hypothesis does not hold and instead the treatment has an effect, a final class of statist ics is useful. Many st atistics that measure the size of the difference between treated and control groups would tend to increase in value if responses in the treated group were increased and thos e in the control group were decreased . Statistics with this property will be called effect incr easing, and
the idea will now be expressed this formally. A treated unit has 2Zsi - 1 = 1, since Z si = 1, and a cont rol unit has 2Zsi - 1 = -1 since Zs i = O. Let z E n

38 2. Randomized Experiments

TABLE 2.4. Hypothetical Example of an Effect In creasing Statistic.

i

zi 2Zi - 1 ri ri

1

Treated 1

1

56

2

Treated 1

1

24

3

Control 0 -1 3 2

4

Control 0 -1 1 1

Rank sum

67

be a possible treatment assignment and let rand r" be two possible values of the N-tuple of responses such that (r;i - r s;)(2zs i - 1) 2:: 0 for all s , i. With treatments given by z, this says that r;i 2:: r si for every treated unit
and r;i S rsi for every control unit. In words, if higher responses indicated
favorable outcomes, then every treated unit does better with r" than with r, and every control does worse with r" than with r. That is, the difference between treated and control groups looks larger with r" than with r . The test statistic is effect increasing if t(z, r) S t(z, r*) whenever rand r* are two possible values of the response such that (r;i - rs;) (2zsi - 1) 2:: 0 for all s , i. All of the commonly used statistics in §2.4.3 are effect increasing.
Table 2.4 cont ains a small hypothetical example to illustrate the idea of an effect increasing statistic. Here there is a single stratum, S = 1, and
four subjects, n = 4, of whom m = 2 received the treatment. Notice that
when r, and r; are compared, treated subjects have r; 2:: r, while controls
have r; Sri. If the responses are ranked 1, 2, 3, 4, and the ranks in the
tre ated group are summed to give Wilcoxon's rank sum statistic, then the
rank sum is larger for r; than for rio
In summary, this section has considered four classes of statistics:
(i) the sum statistics;
(ii) the arrangement -increasing stat ist ics;
(iii) the effect increasing statistics; and
(iv) the sign-score statistics.
All of the commonly used statistics in §2.4.3 are members of the first three classes , and most are sign-score statistics; however , the rank sum statistic, the stratified rank sum statistic, and Mantel's extension are not sign-score statistics.

2.4.5 *No Effect Means No Effect
No effect mean s no effect. A nonzero effect that varies from one unit to the next and that is hard to fathom or predict is, nonetheless, a nonzero effect. It may not be an immediately useful effect , but it is an effect , perhaps an effect that can someday be understood, tamed, and made useful.

2.4 Testing the Hypothesis of No Treatment Effect 39
Empirically, it may be difficult to discern erratic unsyst ematic effects, but logically they are distinct from no effect .
To emphasize this point, consider t he extreme case . Suppose that we som ehow discerned that t he treatment erra tically benefits some patients and harms others, but that we have no way of pr edicting who will benefit or who will be harmed , so the average effect of the treatment is essent ially zero in every lar ge group of patient s defined by pretr eatment varia bles. In point of fact , it is very difficult to discern some t hing like thi s, unless we covertly introduce more information t hat does distinguish these supposedly indistinguish able pat ients. Supp ose, however, we can discern t his, perhaps because t he treatment pro duces one of two easily dist ing uished biochemical reacti ons, one beneficial , t he other harmful, and neither reaction is ever seen among cont rols; however , we are complete ly at a loss to ident ify in ad vance those patients who will have beneficial reactions. This is a nonzero treatment effect , perhap s not a very useful one given current knowledge, bu t a nonzero effect nonetheless. Wh at would a scient ist do with such an effect? Might the scient ist some t imes return with the treatment to the lab ora tory in an effort to underst and why only some patients exhibit the beneficial bioc hemical reacti on? In cont rast, no treatment effect- really no treatment effect-would send t he scient ist in search of another treatment .
No effect is one hypot hesis among ma ny. It is rar ely, perhaps never, sufficient to know whether t he null hypothesis of no t reat ment effect is com patible with obse rved data. And yet , it is ty pically of interest to know this along with mu ch more. Secti on 2.5 and Chapter 5 discuss models for treatment effects and asso cia te d methods of inference, including confidence i n t erv al s .
Fish er (1935) a nd Neyman (1935), two brilliant founders of statistics, did not agree about t he meaning of the null hypothesis of no treatment effect. The hypothesis of no effect as I have described it is F isher 's version. F isher 's conception is par t icular: randomizat ion justifies ca usa l inferences about particular t reatment effects , on particular units, at a par ticular t ime , under par t icular circumstances . Cha nge t he un its or t he t imes or t he circums tances and t he findings may cha nge to an exte nt not adequa te ly addressed by stat istical standard erro rs. These standard errors measure one very im portant sour ce of unc er t ainty, namel y, uncert ainty abo ut how units would have resp onded to a treatment they did not receive, that is, unc ert ainty abo ut the effects ca used by the tre atment. Campbell and Stanley (1963) say that ran domization ensures internal validit y but not externa l validity ; see §2.7.1 a nd t he discussion of efficacy and effect iveness in §5.4. Neyman's (1935, p. 110) conception is genera l: we can "repeat the experiment indefinite ly wit hout any change of veget ative cond it ions or of arran gem ent so t hat .. . t he yields from t his plot will form a po pu lation .. .." For Neym an , t he variations we do not und erst an d become , by assumption, variations from sa mp ling a population. In point of fact , we ca nnot repeat the expe riment indefinit ely, and we cannot ensure the sa me experimental

40 2. Randomi zed Experiments
conditions, but this concept ion concern s a hypothetical world in which we can. This was not a disagreement about matter s of fact , but about matters of art , the art of developin g st at ist ical con cepts for scientific applica t ions.
In most cases, their disagr eement is entirely without technical consequence: the same pro cedures are used , and the sam e conclusions are reached. Perh aps this is expressed most beautifully by Lehmann (1959 , §5). First, Lehmann (1959, §5.7, Theorem 3) shows that infere nces under a population model can be distribution-free only if they ar e made particul ar by cond it ioning on observed responses, yielding Fisher 's randomization t est . Lehmann (1959, §5.8) then uses a population model and the NeymanPearson lemm a to obtain most powerful permutation tes ts; that is, he uses Neyman's concept ion to obtain t he best tests of the type Fisher was proposing. Whatever F isher and Neym an may have thought, in Lehmann's t ext they work togeth er. The importance to mathem atical statisti cs a nd to science of infinite population mod els and Neym an 's cont r ibut ions are, today, surely unquestioned.
And yet , when one is thinking about the science of an experiment, it is sur ely true that random assignment of treatments justifies inferen ces that are particular , that is, particular to certain units at certain times und er certain circumstances. If the inferen ce reaches b eyond that to infinite populations exte nding into the ind efinite future, then this has been accomplished by assuming those populations into existe nce, and assuming away much that is true of the world we actually inhabit. In t hose instances where their conceptions po int in scient ifically different directionsfor instance, the unpredictable but distinguish abl e bio chemi cal reactions abov e-it seems to me that Fisher's conception more closely describes how scientists think and work. Much that we ca nnot current ly predi ct and do not currently fathom is not random error. The variation we do not fathom today we intend to decipher tomorrow.
2.5 Simple Models for Treatment Effects
2.5.1 Responses Hlhen the Treatment Has an Effect
If the treatment has an effect, then the obs erved N -t uple of responses for the N units will be different for differ ent treatment assignments z E rl-this is what it means to say the treatment has an effect . In earlier sect ions, the null hypothesis of no treatment effect was assumed to hold, so the observed responses were fixed , not varying with z , and the response was written r. When the null hypothesis of no effect is not assumed to hold, the response changes with z, and the response observed when the treatment assignment is Z E rl will be written r z . The null hypothesis of no treatment effect says that r z do es not vary with z , and inst ead r z is a const ant the same for all z; in this case, r was written for this constant. Notice that , for each

2.5 Simple Mod els for Treatment Effects 41
Z En , the response f z is some nonr and om N -t uple-probability has not yet ente red t he discussion . Wri te rsiz for th e (8, i) coordina te of fz , that is, for t he response of the it h unit in stratum 8 when the N units receive the treatment assignment z.
To make this definite, return for a moment to Fisher 's Lady tasting tea. If the Lady could not dis criminate at all, then no matter how milk is added to the cup-t ha t is, no matter what z is-she will classify the cups in the same way; that is, she will give the sa me binary 8-t uple of resp onses f . On the other hand , if she discriminates perfectl y, always classifying cups correctly , then her 8-tuple of resp onses will vary with z; indeed , the responses will match the treatment ass ignme nts so th at r z = z.
If treatments ar e randomly assigned , then the treatment assignment Z is a random vari abl e, so the obs erved responses are also random vari abl es as they depe nd on Z . Specifically, the observed response is the random vari able fZ , that is, one of the many possible fz, zEn, selected by picking a treatment assignment Z by the random mechanism that govern s the exp eriment. Write R = fZ for th e observed response, where R like Z is a random variable.
In principle, each possibl e t reatment assignm ent zEn might yield a pattern of responses f z that is unr elated to the pattern observed with a nother z. For inst an ce, in a completely randomized experiment wit h 50
subject s divided into two groups of 25, there might be Inl = (~~) == 1.3 X
1014 different and unrelated 50-tuples fz. Since it is difficult to comprehend a treatment effect in such terms, we look for regularities, pattern s, or models
of the beh avior of f z as z varies over n. The remainder of §2.5 discus ses the most basic models for f z as z vari es over n. Ch apt er 5 discusses additional
models for treatment effect s.
2.5.2 No Interference B etween Units
A first model is that of "no int erference between units" which means that "t he observat ion on one unit should be unaffect ed by the particular assignment of treatments to the other units" (Cox, 1958a, §2.4). Rubin (1986) calls this SUTVA for the "st able unit treatment value assumption." Formally, no interference means that r siz varies with Zsi but not with the other coordinates of z. In other words, the response of the it h unit in stratum 8 depends on the treatment assigned to this unit, but not on the treatments assigned to other units, so thi s unit has only two possible values of
the response rather than Inl po ssible values . When this mod el is assumed,
write rTsi and r c s« for the responses of the it h unit in strat um 8 when ass igned, respectively, to treatment or cont rol; th at is, rTsi is the common valu e of f siz for all zEn with Zsi = 1, and rcu is the common value of r si z for all z En with Zsi = o. Then the observed response from the
ith unit in stratum 8 is Rsi = rTsi if Z si = 1 or Rsi = rc « if Z si = 0, whi ch may also be written Rsi = + Z sirTsi (1- Z si)rc si. This model , with

42 2. Randomized Experiments
one potential response for each unit under each treatment, has been important both to experimental design-see Neyman (1923) , Welch (1937), Wilk (1955), Cox (1958b, §5), and Robinson (1973)-and to causal inference more generally-see Rubin (1974, 1977) and Holland (1986). When
there is no interference between units, write rr for (rTll, . . . , rTS,ns)T and
rc for (rcll, . .. f , rCS,n s ·
"No interference between units" is a model and it can be false. No interference is often plausible when the units are different people and the treatment is a medical intervention with a biological response. In this case, no interference means that a medical treatment given to one patient affects only that patient, not other patients. That is often true. However, a vaccine given to many people may protect unvaccinated individuals by reducing the spread of a virus (so called herd immunity) and this is a form of interference. No interference is less plausible in some social settings, such a workplace or a classroom, where a reward given to one person may be visible to others, and may affect their behavior. No interference is often implausible when the strata are people and the units are repeated measures on a person; then a treatment given at one time may affect responses at later times; see Problem 2. In randomized single subject experiments, such as the Lady tasting tea, no interference is typically implausible.
2.5.3 The Model of an Additive Effect, and Related Models
The model of an additive treatment effect assumes units do not interfere with each other, and the administration of the treatment raises the response
of a unit by a constant amount 7, so that rr« = rc« + 7 for each s, i .
The principal attraction of the model is that there is a definite parameter to estimate, namely, the additive treatment effect 7. As seen in §2.7, in a uniform randomized experiment, many estimators do indeed estimate 7 when this model holds.
In understanding the model of an additive treatment effect, it is important to keep in mind that the pair of responses, (rTsi, rCsi), is never jointly observed for one unit (s, i) . Therefore the model of an additive
effect, rr« = rcu + 7, cannot be checked directly by comparing rr« and
rc« for particular units. The treatment Zsi and the observed response
Rsi = + ZsirTsi (1 - Zsi)rCsi are observed, and one can check what the model , rr« = rc« + 7, implies about these observable quantities. In a
completely randomized experiment with a single stratum, S = 1, dropping
the s, the model of an additive treatment effect, rTi = rei +7, implies that,
as sample sizes m and n-m increase, the distribution of observed responses R; for treated units Z; = 1 will be shifted by 7 when compared to the distribution of observed responses R; for controls Z, = 0, so the distributions will have the same shape and dispersion. That is, the histograms or boxplots would look the same, but one would be moved left or right relative to the other. This is a shift model, commonly used in nonparametrics; see

2.5 Simpl e Mod els for Tr ea tment Effects 43
Lehmann (1975). In a uniform randomized expe riment with several strat a
S > 1 and rt:« = r c « + T , the distribution of responses may have different
shapes and dispersion s in different strat a, but within each stratum, the treat ed and control distributions are shifted by T . This is a fairly weak form of no interaction between treatment group and st ra t um in the 2 x S t abl e of observable distributions, and it implies much less about observable distributions than t he ana logous nonparametric analysis of vari ance model , which typicall y ass umes a common shape and disp ersion in all 2S cells. If the onl y data ar e ( Zsi, R si ) , does the addit ive model have content beyond its implications for observabl e distributions? See Problem 7.
Under the additive model, the observed response from the it h unit in
stratum s is Rsi = TCsi + TZsi , or R = r c + TZ. It follows that the
adjusted responses, R -TZ = r c , are fixed , not varying with th e treatment assignment, Z, so the adj uste d responses satisfy the null hypothesis of no effect . This fact will be useful in drawing inferenc es ab out T.
There are many similar mod els, including the model of a multiplica-
tiv e effect , TTs i = a TC si . Chapter 5 discusses quite different mod els for
treatment effects .
2.5.4 *Positive Effects and Larger Effects
The model of an additive effect assumes a great deal abo ut the relationship between TT si and r c a - At times, it is desir abl e to describe t he behavior of statis t ica l procedures while assuming much less. Wh en there is no int erference between units, an effect is a pair (r T' r c ) giving t he responses of each un it under each treatment . Two useful concepts are posit ive effects a nd larger effects . Unlike the model of an addit ive treatme nt effect, positive effects and larger effects are meaningful not just for cont inuous responses, but also for binar y responses, for ordinal responses, and as seen lat er in §2.8, for censored responses and multi variat e responses.
A treatment has a positive effect if rru 2: rc« for all units (s , i) with
strict inequality for at least one unit. A more compact way of writing thi s
is that (rT ' rc) is a p ositive effect if rT 2: r c with r T "# r c . This says
that application of the treatment never decreases a unit's response and somet imes increases it. For instance, there is a positive effect if the effect
is additive and T > O. Hamilton (1979) discusses this model in detail when
the outcome is binary. Consider two po ssible effects, say (rT ' r c) and (r r, r e) . Then (rr , r e)
is a larqer effect than (rT ' r c) if Tr si 2: rr« and Te si ~ TCsi for all s , i . For
instance, the simplest examp le occurs when the treatment effect is additive
with the sa me responses under control, namely, re = r c , rT = r c + r I , a nd r r = r c +T*I , for in this case (rr , r e) exhibits a larqer effec t than
(r T, rc ) if T * 2: T . In general, write Rand R* for the obser ved responses from , resp ectively, the effects (rT ' r c ) and (rr , r e ), so R ; i = Tr si if Zsi = 1
a nd R ; i = Te si if Z si = O.

44 2. Ra ndom ized Experime nts
If a statist ical test rejects the null hyp othesis 5% of the t ime when it is true, one would hop e t hat it would reject at least 5% of t he time when it is false in the a nticipated dir ection . Recall that a st at ist ical test is unbiased against a collection of altern ative hypotheses if the test is at least as likely to reject the null hypothesis when on e of the alternatives is true as when the null hypothesis is true. The next prop osition says that all of the common tests in §2.4.3 are unbi ased test s against positive treatment effects, and the test stat ist ic is lar ger when the effect is lar ger . The proposition is prov ed in somewha t more genera l terms in t he appe ndix, §2.9.
Proposition 4 In a randomized experiment, a test statis tic that is effect increasing yields an unbiased test of no effect against the altern ative
of a positive effect, and if (rT , rC) is a larger effect than (rr , rc ), then
t (Z ,R*) ~ t (Z ,R).
2.6 Confidence Intervals
2.6.1 Testing General Hypoth eses
So far , t he test stat istic t (Z , R ) has been used to t est the null hypothesis of no trea tment effect. There is a n exte nsion t o test hypotheses that specify a particular treatment effect. In §2.6.2, this exte nsion is used to construct confidence int ervals. As always, the confide nce interval is the set of hyp otheses not reject ed by a test .
Consider testing the hypothesis H o : T = TO in the model of a n addit ive effect , R = rC+TZ . The idea is as follows. If the null hypothesis H o : T = TO were true, then r c = R - TOZ , so testing H o : T = TOis the same as testing that R - ToZ sat isfies the null hyp othesis of no treatment effect .
More precisely, if r c were known, t he probability, say o , that t( Z, r c ) is greate r t han or equa l to some fixed number T could b e determined from (2.3). If t he null hyp othesis were true, then r c would equal the adjusted responses, R - TOZ , so und er the null hypothesis, r c can be calculat ed from TO and the observed data. If the hypothesis H o : T = TO is true, then the chance that t(Z , R - TOZ) ~ T is 0:, where 0: is calculated as described above with r c = R - TOZ .
Now, supp ose the null hypothesis is not true, say inst ead T > TO , and consider t he behavior of the above t est. In this case, R = r c + TZ and the adjusted responses R-TOZ equal r c + (T - TO) Z, so the adj usted responses
will var y with the assigned treatment Z. If a uni t receives the treatment, it will have a n adjusted response that is T - TO higher than if this unit receives the cont rol. If the test statist ic is effect increasing, as is true of
all the st at ist ics in §2.4.3, then t (Z , R - TOZ ) = t{Z , r c + (T - To)Z} ~
t(Z , r c ) = t(Z , R - TZ ), where the inequality follows from the definition of an effect increasing st at ist ic. In words, if the null hypothesis is false and

2.6 Confidence Intervals 45

TABLE 2.5. Example of Confidence Interval Computations.

Ranks of

Control

Observed

Adjusted Adjusted

Unit Response Group

Response

Response Responses

rc.

z, R; = rei +TZi R; - TOZi

qi

1

2

1

9

2

1

0

1

3

3

0

3

4

4

0

4

5

0

1

7

6

4

1

11

7

1

1

8

8

7

1

1

3

2

4

3

6

5

10

8

7

6

8

5

0

5

5

4

T = 7,To = 1

instead T > TO , then an effect increasing test statistic t(Z , R - TOZ) will
be larger with the incorrect TO than it would have been had we tested the
correct value T .
Table 2.5 illustrates these computations with a rank sum test. It is a
hypothetical uniform randomized experiment with N = 8 units, all in a
single stratum S = 1, with m = 4 units assigned to treatment , and an
additive treatment effect T = 7, though the null hypothesis incorrectly says Hi, : T = TO = 1. The rank sum computed from the adjusted responses
R - lZ is 7 + 5 + 8 + 6 = 26, which is the largest possible rank sum for
N = 8, m = 4, and the one-sided significance level is (~) -1 = 1/70 = 0.014.
The two-sided significance level is 2 x 0.014 = 0.028. After removing the
hypothesized TO = 1 from treated units, the treated units continue to have
higher responses than the controls.

2.6.2 Confidence Intervals by Inverting a Test
Under the model of an additive treatment effect , R = rc + TZ , a 1 - 0:
confidence set for T is obtaining by testing each value of T as in §2.6.1 and collecting all values not rejected at level 0: into a set A. More precisely, A is the set of values of T that, when tested, yield significance levels or P-values greater than or equal to 0: . For instance, in the example in Table 2.5, the value T = 1 would not be contained in a 95% confidence set . When the true value T is tested, it is rejected with probability no greater than 0:, so the random set A contains the true T with probability at least 1 - 0:. This is called "invert ing" a test , and it is the standard way of obtaining a confidence set from a test ; see, for instance, Cox and Hinkley (1974, §7.2) or Lehmann (1959 , §3.5). For many test statistics, a two-sided test yields

46 2. Randomized Experiments
a confidence set that is an interval , whose endpoints may be determined by a line search, as illustrated in §4.3.5. Section 3.2.4 uses this confidence interval in an observational study of lead in the blood of children.

2.7 Point Estimates
2.7.1 Unbiased Estimates of the Average Effect
The most quoted fact about randomized experiments is that they lead to unbiased estimates of the average treatment effect . Take the simplest case , a uniform randomized experiment with a single stratum, with no interference between units. In this case, th ere are m treated units, N - m control units,
E(Zi) = m fN ; R; = rr, if Z, = 1, and R, = rc. if Z, = o. The difference
between the mean response in the treated group, namely, (11m) L ZiRi , and the mean response in the control group, namely, {l /(N - m)} L(l Zi)Ri, has expectation

E{,,", ZiRi _ (1 - Zi)Ri}=E {""' ZirTi _ (1 - Zi)rCi}

L m N-m

Lm

N-m

=""' (mIN)rTi _ (1 - mlN)rci =2- ""' rr- - r c ,

L

m

N-m

NL t

tl

and the last term is the average of the N treatment effects rr , - ret for the N experimental units. In words , the difference in sample means is unbiased for the average effect of the treatment. Notice carefully that this is true assuming only that there is no interference between units. There is no assu mption t hat th e treat ment effect rr , - ret is constant from unit t o unit, no assumption about interactions.
The estimate is unbiased for the average effect on the N units in this study, namely, (liN) LrTi - rCi, but this says nothing about the effect on other units not in th e study. Campbell and Stanley (1963) say that a randomized experiment has internal validity in permitting inferences about effects for the N units in the study, but it need not have extern al validity in that there is no guar antee that the treatment will be equally effect ive for other units outside the study; see also §2.4.5. The related issue of efficacy and effectiveness is discussed in §5.4.
The difference in sample means may be biased when there are two or more strata and the experimenter assigns disproportionately more subjects to the treatment in some strata than in others. However, there is an unbiased estimate that corrects the imbalance. It consists of calculating, within stratum s , the difference between the average response in the treated group, namely, (l/m s) L i ZsiRsi, and the average response in the control group,

2.7 Point Estimates 47
namely, { l /(n s - m s)} L i(l-Zs;)Rsi, and weighting t his difference by the proportion of un its in stratum s, namely, ns/N. T he estimate, called direct adjustment, is then :
(2.6)
To check t hat (2.6) is un biased , recall t hat, in a uniform ran domized exper iment , Zsi has expectation m s/ns. It follows that (2.6) has expectatio n
so direct adjustme nt does indeed give an unbiased estimate of the average effect. In a very clear disc ussion, Rubin (1977) does calc ulat ions of this kin d .
In effect, direc t adj ustme nt views t he treated unit s and t he control uni ts as two st ratified random samples from t he N units in t he experiment. Then (2.6) is t he usual stratified estimate of mean response to treatment in the population of N uni ts min us t he usual esti ma te of t he mean response t o cont ro l in t he population of N uni ts. Not ice again t hat direct adjust ment is unbiased for t he average treat ment effect even if t hat effect varies from unit to un it or from st ratum to st ra t um. On the ot her han d, t he average effect is but a summary of the effects, and not a comp lete desc ription, when t he effect varies from one st ratum to anot her.
2. 7.2 Hodges-Lehmann Estimates of an Addi tive Effect
Under the model of an addit ive effect, R = r c + T Z, t here are many est i-
mates of T. One due t o Hodges and Lehm ann (1963) is closely tied to the test in §2.4 and t he confidence int erval in §2.6. Recall t hat H o : T = T O is tested using t (Z , R - T OZ ) , that is, by subt racting the hypothesized treatme nt effect T OZ from t he observed responses R , and asking whet her the adjusted resp onses R - TO Z appear to be free of a t reatment effect. The Hodges-Lehmann estimate of T is t hat value T such t hat t he adjusted responses R- iZ appear to be exactly free of a treatment effect . Cons ider t his

48 2. Randomized Experiments

in detail. Throughout this section, the experiment is a uniform randomized

experiment.

_

Suppose that we can determine the expectation, say 1, of the statistic

t(Z , R - TZ) when calculated using the correct T, that is, when calcu-

lated from responses R - TZ that have been adjusted so they are free of

a treatment effect. For instance, in an experiment with a single stratum,
the rank sum statistic has expectation 1 = m(N + 1)/2 if the treatment

has no effect. This is true because, in the absence of a treatment effect, the

rank sum statistic is the sum of m scores randomly selected from N scores

whose mean is (N + 1)/2. In the same way, in a stratified experiment,
t the stratified rank sum statistic has expectation = ~ I: ni; (ns + 1) in
the absence of a treatment effect . In an experiment comprised of S pairs,

in the absence of a treatment effect, the expectation of the signed rank
t statistic is = (S + 1)/4, since we expect to sum half of S scores which

average (S + 1)/2. In the absence of an effect, in an experiment with a
t single stratum, the difference in sample means (2.2) has expectation = O.

In each of these cases , f may be determined without knowing T, so there is

a Hodges-Lehmann estimate.

Roughly speaking, the Hodges-Lehmann estimate is the solution f of

the equation 1 = t(Z , R - fZ). In other words , f is the value such that

the adjusted responses R - fZ appear to be entirely free of a treatment

effect, in the sense that the test statistic t(Z , R - fZ) exactly equals its

expectation in the absence of an effect .

If t( ·, .) is an effect increasing statistic, as is true of all of the statistics

in §2.3, then t(Z, R - fZ) is monotone decreasing as a function of f with Z

and R fixed. This says: The larger the treatment effect fZ removed from

the observed responses R, the smaller the statistic becomes. This is useful

in solving 1= t(Z , R- fZ) . If a f has been tried such that f < t(Z , R- fZ),
then a larger 't will tend to make t(Z , R - fZ) smaller, moving it toward
f. Similarly, if t > t(Z , R - fZ) , then a smaller f is needed.

Problems arise immediately. For rank statistics, such as the rank sum

and the signed rank, t(Z , R - fZ) varies in discrete jumps as f is varied,
t so there may be no value f such that = t(Z , R - fZ) . To see this, take a

trivial case, a uniform experiment in one stratum, sample size N = 2, one

treated unit tti = 1. Then the rank sum statistic is either 1 or 2 dep ending
upon which of the two units receive the treatment, but f = 1.5, so it is not
t possible to find a! such that = t(Z , R - fZ) .

Not only may 1 = t(Z, R - fZ) have no solution i , but it may have

infinitely many solutions. If t(Z, R - fZ) varies in discrete jumps, it will

be constant for intervals of values of f .

Hodges and Lehmann resolve these problems in the following way. They

define the solution of an equation f = t(Z , R - fZ) as SOLVE{l = t(Z, R-

2.7 Point Estimates 49

TABLE 2.6. Computing a Hodges -Lehmann Estimate.

T

4.9999 5 5.0001 5.9999 6 6.0001

t(Z, R - TZ) 20 19 18

18 17 15

fZ)} defined by

f

SOLVE{t = t(Z, R - rZ)}

inf{T : t> t(Z , R - rZ)} + SUp{T: t < t(Z, R - TZ)}

2

This defines the Hodges-Lehmann estimate. Roughly speaking, if there is no exact solution, then average the smallest T that is too large and the largest T that is too small.
Consider the small example in Table 2.5. Under the null hypothesis of no
t effect, the rank sum statistic has expectation = m(N +1)/2 = 4(8+1)/2 =
18, that is, half of the sum of all eight ranks, 36 = 1 + 2 + . .. + 8. Table 2.6 gives values of t(Z , R - TZ) for several values of T. As noted, since t( ·, ·) is effect increasing, in Table 2.6, t(Z, R - TZ) decreases in T. We want as our estimate a value f such that 18 = t(Z, R - rZ), but the table indicates that any value between 5 and 6 will do. As the table suggests,
t : t inf{T : t(Z,R - TZ)} = 6 and SUp{T : < t(Z, R - TZ)} = 5, so the r Hodges-Lehmann estimate is = (6 + 5)/2 = 5.5.
For particular test statistics, there are other ways of computing f. This is true, for instance, for a single stratum using the rank sum test. In this case, it may be shown that f is the median of the m( N - m) pairwise differences formed by taking each of the m treated responses and subtracting each of the N - m control responses.
The Hodges-Lehmann estimate r inherits properties from the test statis-
tic ti-, .). Consistency is one such property. Recall that a test is consistent if the probability of rejecting each false hypothesis tends to one as the sample size increases. Recall that an estimate is consistent if the probability that it is close to the true value tends to one as the sample size increases. As one would expect, these ideas are interconnected. A test that rejects incorrect values of T leads to an estimate that moves away from these incorrect values. In other words, under mild conditions, consistent tests lead to consistent Hodges-Lehmann estimates; see Maritz (1981, §1.4) for some details.

50 2. Randomized Experiments
2.8 *More Complex Outcomes
2.8.1 *Parlially Ordered Outcomes
So far, the outcome Rsi has been a number, possibly a continuous mea-
surement, possibly a binary event, possibly a discrete score, but always a single number. Howe~~{{ for more complex responses, much of the earlier discussion continues to apply with little or no change. The purpose of §2.8 is to discuss issues that arise with certain complex outcomes, including multivariate responses and censored observations.
When the outcome R si is a single number , it is clear what it means to speak of a high or low response, and it is clear what it means to ask whether responses are typically higher among treated units than among controls. For more complex responses, it may happen that some responses are higher than some others; and yet not every pair of possible responses can be ordered. For example, unit 1 may have a more favorable outcome than units 2 and 3, but units 2 and 3 may have different outcomes neither of which can be described as entirely more favorable than the other. For instance, patient 1 may live longer and have a better quality of life than patients 2 and 3, but patient 2 may outlive patient 3 though patient 3 had a better quality of life than patient 2. In this case, outcomes may be partially ordered rather than totally ordered, an idea that is formalized in a moment. Common examples are given in §2.8.2 and 2.8.3.
A partially ordered set or poset is a set A together with a relation ;S on
A such that three conditions hold:
(i) a;S a for all a E A ;
(ii) a;S band b ;S a implies a = b for all a, b E A; and
(iii) if a .:S b and b .:S c th en (J, ;S c for all (J" b, c E A.
There is strict inequality between a and b if a ;S b and a =1= b. A poset A is totally ordered if a ;S b or b ;S a for every a , b E A. The real numbers with conventional inequality j, are totally ordered. If A is partially ordered but
not totally ordered, then for some a , b E A , a =1= b, neither a nor b is higher
than the other; that is, neither a ;S b nor b ;S a. Sections 2.8.2 and 2.8.3
discuss two common examples of partially ordered outcomes, namely, censored and multivariate outcomes. Following this, in §2.8.4, general methods for partially ordered outcomes are discussed.
2.8.2 "Censored Outcomes
In some experiments, an outcome records the time to some event. In a clinical trial, the outcome may be the time between a patient's entry into the trial and the patient's death. In a psychological experiment, the outcome

2.8 *More Complex Outcomes 51
may be the time lapse between administration of a stimulus by the experimenter and the production of a response by an experimental subj ect . In a study of remedial education, the outcome may be the time until a cert ain level of proficiency in reading is reached .
Times may be censored in the sense that , when data analysis begins, the event may not yet have occurred. The patient may be alive at the close of the study. The stimulus may never elicit a response . The student may not develop proficiency in reading during the period und er study.
If the event occurs for a unit after, say, 3 months, the unit's response is written 3. If the unit entered the study 3 months ago , if the event has not yet occurred, and if the analysis is done today, then the unit 's response is written 3+ signifying that the event has not occurred in the initial 3 months.
Censored times are partially ordered. To see this , consider a simple illustration. In a clinical trial, patient 1 died at 3 months, patient 2 died at 12 months, and patient 3 entered th e study 6 months ago and is alive today yielding a survival of 6+ months. Then patient 1 had a shorter survival than patients 2 and 3, but it is not possible to say whether patient 2 survived longer than patient 3 because we do not know whether patient 3 will survive for a full year.
The set A of censored survival times contains the nonnegative real numbers together with the nonnegative real numbers with a plus appended.
Define the partial order ;S on A as follows: if a and b are nonnegative real
numbers, then:
(i) a;S b if and only if a :::; b;
(ii) a;S b+ if and only if a :::; b; and
(iii) a;S a and a+ ;S a+.
Here , (i) indicates that "a" and "b" are both deaths and "a" died first . In (ii) , "a" died before "b" was censored, so "b" cert ainly outlived "a." Of course, (iii) is just the case of equality-every censored time is equal to itself, and so is less than or equal to itself. It is easy to check that this is indeed a partial order, and that strict inequality indic ates certainty about who died first.
2.8.3 *Multivariate Outcomes and Other Partially Ordered Outcomes
Quite often, a single number is not enough to describe the outcome for a unit . In an educational intervention, there may be test scores in several areas, such as reading and mathematics. In a clinical trial, the outcome may involve both survival and quality of life. A multivariate response is a p-tuple of outcomes describing an individual. If the p components are

52 2. Randomi zed Experiments
:s numbers, then the multivariate response inherits a partial order as follows:
(al , ' " ,ap ) (bl , ... , bp ) if and only if al ~ bI, a2 ~ oz , . . . , and ap ~ bp · It is easy to check that this defines a partial order. As an example, if the outcome is the 2-tuple consisting of a reading score and a mathematics score, then one student has a higher multivariate response than another only if the first student did at least as well as the second student on both tests.
In fact , the components of the p-tuple need not be numbers-rather they may be any partially ordered outcomes. In the same way, the p-tuple inherits a partial order from the partial orders of individual outcomes. For instance, the outcome might be a 2-tuple consisting of a censored survival time and a number measuring quality of life. The censored survival times are partially but not totally ordered. In this case, a patient who died early with a poor quality of life would have a lower outcome than a patient who was censored late with a good quality of life.
Multivariate responses may be given other partial orders appropriate
:s to particular contexts. Here is one that gives greatest emphasis to the
first coordinate and about equal emphasis to the other two: (aI , a2, a3)
(bI, b2, b3) if al ~ bl or if {al = bi and a2 ~ b2 and a3 ~ b3} . In an
educat ional setting, this might say that a student who graduates had a better outcome than one who did not regardless of t est scores, but among those who graduate, one student is better than another only if both reading and math scores are as good or better.

2.8.4 *A Test Statistic for Partially Ordered Outcomes

The task is to test the null hypothesis of no treatment effect against the
:s alternative that treated units tend to have higher responses than controls
in the sense of a partial order on the outcomes. For this purpose, define
indicators Lsij for s = 1, . . . , S, i = 1, . .. ,ns , j = 1, . . . ,ns , as follows:

:s I if s., u; with u: :j:. Rsj , :s u.; L sij = -1 if tc; R sj with tc; :j:.

(2.7)

{ o otherwise.

In words, L si j compares the ith and jth units in stratum s, and L si j is 1 if the ith is strictly greater than the jth, is -1 if the it h is strictly smaller
than the jth, and is zero in all other cases . The statistic is

S n .'J n s
t(Z ,R) = I : I : I : Zsi(l- Z sj)Lsij.
s = l i=l j=l

(2.8)

Consider the statistic in detail. The term Z si(l - Zsj)L sij equals 1 if, in stratum s, the ith unit received the treatment, the jth unit received the

2.8 *More Comp lex Outcomes 53

cont rol, a nd these two units had unequ al responses with t he trea ted unit
having a higher resp onse, R sj ;S R si . Similarly, Z si(l- Z sj )L sij equals -1 if, in st ratum s , t he ith unit is treated, t he j th is a control, and the control had t he high er response, R si ;S R sj ' In all ot her cases, Z si( 1 - Z sj )Lsij
equa ls zero . So t he test statist ic is the number of comparisons of treated and cont ro l units in t he same stratum in which the treated un it had t he higher response min us t he number in which t he cont rol uni t had t he higher
resp onse. This statistic generalizes severa l fam iliar statist ics. If the outco me is a
single number and t he par t ial order ;S is ordinary inequ ality $ , t hen (2.8) is
equivalent to the Ma nn - W hit ney (1947) statistic and t he W ilcoxon (1945)
rank sum statis t ic. If t he outcome is censored and ;S is t he par tial order in
§2.8.2, then the statist ic is Gehan 's (1965) st at ist ic. A device due to Man tel (1967) shows that (2.8) is a sum statist ic. The
ste ps are as follows. First not e that , for any sub set B of {I, 2, . .. ,n s },

LLLsij =0
iEBjEB

(2.9)

since L sij and L sj i both appear in t he sum, with L sij = -Lsj i , and th ey
cancel. Using t his fact wit h B = {i : 1 $ i $ ns with Z si = I} yields

n .<t n s

0 = L L L sij = L L ZsiZsj L sij ,

iEB JEB

i=1 j=1

which pe rm its t he test statistic (2.8) to be rewrit ten as the sum statistic

S n,

n,

S n,

z; t( Z , R ) = L L

L L sij = L L Z siqsi

s=1 i = 1 j =1

s=1 i= 1

ns
with qsi = L L sij . j=1

As a res ult , t he expectation and variance of t he test statistic under t he null
hyp othesis are given by P ro position 2. In fact , in that P roposition, iJs = 0
for each s usin g (2.9) . The score qsi has an interpret ation . It is the num ber of units in st ratu m
s with outcomes less t han unit i minus the num ber with outcomes grea ter t han i. The score qsi is large if unit i has a response larger th an that of most units in st rat um s. For inst an ce, in Gehan 's statis t ic for censored outcomes, the score qsi is the number of pat ient s in stratum s who definitely died before patient i minus t he numb er who definitely died afte r pa t ient i .

2.8.5 *Effect Increasing St atistics, Positive Effects, Larger Effects
In §2.4 and 2.5, t hree te rms were discussed, namely, effect increasi ng statist ics, pos itive effects , and lar ger effects. These terms apply to partially ordered outcomes wit h virtually no change, as shown in a moment. In each

54 2. Randomized Experiments
case, the definitions in §2.4 and 2.5 are the special case of the definitions
in this section with the partial order ;S given by ordinary inequality :::; of
real numbers. Let rand r* be two possible values of the N-tuple of partially ordered
outcomes. If r si ;S r;i for every treated unit and r;i ;S r si for every control
unit, then the treated and control groups appear farther apart for outcome r* than for outcome r . A test statistic t( ·, ·) is effect increasing if t(z, r) :::; t(z, r") whenever rand r" are two possible values of the response such that
rsi ;S r;i if Zsi = 1 and r;i ;S rsi if Zsi = 0 for all s, i . In words, the statistic
is larger when the outcomes in treated and control groups are farther apart. The statistic in §2.8.4 is effect increasing; see Problem 6.
If there is no interference between units, then (rT' r c) is a positive effect
if fT =I- rc and rc« ;S rt:« for every s, i. In the case of censored survival
times, this would mean that each patient would definitely survive at least
a) as long under the treatment as under the control, or else would continue to
be censored at the same time due to the end of the study. An effect (rT,r
is a larger effect than (rT ' ra) if rr« ;S rT si and ra si ;S rCsi, for all s, i,
that is, if the treated responses are higher and the control responses are lower.
The following proposition is the extension of Proposition 4 to partially ordered responses. Again , the proof is given in the appendix, §2.9.
Proposition 5 In a randomized experiment, a test statistic that is ef-
a) fect increasing yields an unbia sed test of no effect against the alternative
of a positive effect, and if (rT, r is a larger effect than (rT ' rc) then t(Z,R*) ~ t(Z,R) .
2.9 *Appendix: Effect Increasing Tests Under
Alternatives
This appendix proves Propositions 4 and 5 which describe the behavior of effect increasing test statistics under the alternative hypotheses of positive effects or larger effects. It may be of interest to contrast these propositions with a result in Lehmann (1959, §5.8, Lemma 2) which is similar in spirit though quite different in detail. It suffices to prove Proposition 5 since Proposition 4 is the special case of the former in which the partial order is ordinary inequality. The proof depends on the following lemma.
a) Lemma 6 Let t( ·, ·) be effect increasing. If (rT ' ra) is a positive effect,
then t(z, r z ) ~ t(z , ra) for all z, a E n . If (rT ' r is a larger effect than (rT ' ra), then t(z , r;) ~ t(z, r z ) for all zEn.
Proof of Lemma. Let (rT' rc) be a positive effect, let z, a E n, and
consider r z and ra . If Zsi = 1, then r siz = rt:« while rs ia may equal either

2.10 *Appendix: The Set of Treatment Assignments 55

.:s rTsi or rC si depending on asi, but in either case r's ia rsiz since (rT , rc) .:s is a positive effect. Similarly, if Zsi = 0, then rsiz = r c « rsia. Since t( ·,·)
is effect increasing, this implies t(z, r z ) 2: t(z, r a ) , proving the first part of
the lemma.
.:s .:s Now let zEn, let (rr, r c) be a larger effect than (rT, rc) , and consider
r; and r z . If Zsi = 1, then rsiz = rr« rrsi = r;iz . If Zsi = 0, then
r;iz = rCsi rca = rsiz · Hence t(z, r;) 2: t(z, r z ) since t(· , ·) is effect
increasing, completing the proof. _

Proof of Proposition 5. The lemma directly shows that if (rr , rc) is a
larger effect than (rT, rc) , then t(Z, R*) 2: t(Z , R). To prove unbiasedness,
let Z be randomly selected from n where prob(Z = z) is known but need
not be uniform. If the random treatment assignment turns out to be Z = a,
then the observed outcome is R = ra . If the null hypothesis were true, if the treatment had no effect, the observed response would be the same ra no matter how treatments were assigned , that is, the observed response
would be R = r a no matter what value Z assumed. If the null hypothesis
were false and the treatment had a positive effect, the observed response
would vary depending upon the treatment assignment, R = rz if Z = z. For any fixed number T

prob{t(Z , R) 2: T} = 2)t(z, r z ) 2: T] prob(Z = z)
zEn
2: :L)t(z, r a ) 2: T] prob(Z = z)
zEn

for a E n by the lemma .

In other words, the chance that the test statistic t(Z, R) exceeds any number T is at least as great under the alternative hypothesis of a positive effect as under the null hypothesis of no effect, proving unbiasedness. _

2.10 *Appendix: The Set of Treatment
Assignments
n 2.10.1 "Outline and Motivation: The Special Structure of
The set n of treatment assignments plays an important role both in ran-
domized experiments and in the discussion of observational studies in later
chapters. This set n possess a special structure, first noted by Savage
(1964) . Using this structure, a single theorem may refer to large classes of test statistics and to all of the simple designs, including matched pairs, matching with multiple controls, two-group comparisons, and stratified comparisons. The purpose of this section is to describe the special structure
of n. Appendices in later chapters refer back to this appendix.

56 2. Randomized Experiments

n Savage (1964) observed that the set is a finite distributive lattice. This
is useful because there are tidy theorems about probability distributions on a finite distributive lattice, including the FKG inequality and Holley's inequality. This section:
(i) offers a little motivation;
(ii) reviews the definition of a distributive lattice;
(iii) shows that n is indeed such a lattice; and
(iv) discusses the relevant probability inequalities.
The material in this appendix may be read without previous experience with lattices.
For motivation, consider a simple case. There is a single stratum, S = 1, so the s subscript is dropped in this example, and there are n = 4 units
n of which m = 2 receive the treatment. Then contains (~) = 6 possible
treatment assignments. Assume for this motivating example that the null hypothesis of no treatment effect holds, and renumber the four subjects so their observed responses are in decreasing order, rl ~ r2 ~ T3 ~ r4. Since no quantity we calculate ever depends on the numbering of subjects, this renumbering changes nothing, but it is notationally convenient. The six possible treatment assignments appear in (2.10) .

1100

T

1010

/

<,

0110

1001

<,

/

0101

T

0011

(2.10)

The treatment assignment z = (1,1,0,0) at the top in (2.10) is the one
that would suggest the largest positive treatment effect, since this assignment places the two largest responses, rl and r2, in the treated group. The assignment below this, namely, z = (1,0,1,0) would suggest a smaller treatment effect than (1, 1, 0, 0), since r3 has replaced r2, but it would suggest a larger treatment effect than any other assignment. The assignments (0, 1, 1,0) and (1,0,0, 1) are not directly comparable to each other, since the latter places the largest and smallest responses in the treated group while the former places the two middle responses in the treated group; however, both are lower than (1, 0, 1,0) and both are higher than (0, 1,0, 1).
Consider the behavior of a test statistic t(z , r) as we move through (2.10) .
Suppose, for instance, there are no ties among the responses, rl > r2 >

2.10 *Appendix: T he Set of Treatment Ass ignments 57

T3 > T4 , a nd t( z , r ) is t he rank sum statistic. Then t( z , r ) = 7 for z = 1100, t( z, r ) = 6 for 1010, t( z , r ) = 5 for both 1001 and 0110, t( z, r ) = 4 for 0101,
and t( z, r ) = 3 for 0011, so t( z, r ) increases steadily along upward paths
in (2.10). If, instead, t( z, r ) were the difference betwee n the mean respo nse
in treated and cont rol groups, it would aga in be increasing along upwar d
p a t hs.
Suppose, instead , t hat T2 and T3 were tie d, so Tl > T2 = T3 > T4. In this
case, t he rank sum statistic would give average rank 2.5 to both T2 and
T3 , so movin g from 1100 to 1010 would not change t( z , r ). Notice , however ,
t hat even wit h t ies, t( z, r ) is monotone increasin g (i.e., non decreasing) along upwar d paths.
Act ually, the order in (2.10) applies t o many statist ics whet her ties are pr esent or not . If t( z , r ) is any arrangement-increasing stat ist ic, then t (z , r )
is monotone-increasing on upw ar d paths in (2.10). Most reasonable stat istics will assign a higher value to 1100 than to 1010, but reasonable st at ist ics
ca n differ in how they order ass ignments that are not com para ble like 1001
and 0110. Take a look at a second example, t he case of S = 2 matched pairs,
so ns = 2 a nd m s = 1 for s = 1, 2. Then n contains 22 = 4 treat ment
assig nme nts z = (Zl1 , Z12 , Z2 1, Z22) . Again , assume the null hyp othesis of no
t reatment effect and renumber the uni ts in each pa ir so that in the first
n pair Tl1 ~ T 12 , and in t he second pair T21 ~ T22 . T he set appears in
(2.11).

1010

/

<,

1001

0110

<,

/

0101

(2.11)

T he ass ignme nt z in (2.11) suggesting t he largest pos it ive t reatment
effect is z = (1, 0, 1, 0) since in both pair s t he trea ted uni t had a higher resp onse t han the contro l. For z = 1001 and z = 0110, t he treated unit
had t he high er resp onse in one pair and the lower resp onse in the ot her.
In the assignme nt z = 0101 the treat ed uni t had a lower response than the
cont rol in both pairs. On ce again, common statis t ics are monotone-incr easing along upward
paths in (2.11) . For inst an ce, this is true of the signed rank statist ic, which equals zero at the b ottom of (2.11), equals one or two in the middl e, and equals t hree at the top. Indeed , all arrangement-increasing functi ons ar e mo noto ne-increasing along upwar d paths in (2.11).
What does all this sugges t? There are cert ain t reatment assignments z En that are higher than ot hers, and t his is t rue wit hout reference to t he na ture of the resp onse r or the specific test statist ic t( z, r ). The responses might be continuous or t hey might be discret e scores or t hey might be bi nary. The t est statist ic might be t he signed rank statist ic or the McNemar

58 2. Random ized Experi ment s
statist ic. In all these cases, Z = 1010 is high er than Z = 1001 in (2.11). Certain stat ements abo ut treatment ass ignments zEn should be true genera lly, without reference to th e spec ific nature of the outc ome or the test statist ic.
2.10.2 *A Bri ef Review of Lattices
Briefly, a lattice is a par ti ally ord er ed set in which eac h pair of eleme nts has a greatest lower bound and a least upper bound. This terminology is discussed formally in a moment , but first consider what this means in (2.10). A point Z in (2.10) is below another z" if there is a pa th up from z to z* ; for instance, 0110 is below 1100. The points 1001 and 0110 are
n not comparable-there is not a path up from one to the ot her-so is
partially but not totally ordered . The least upper bound of 0110 a nd 1001 is 1010, for it is the smallest element above both of them. The least upper bound of 1010 and 1100 is 1100. A nice introduction t o lattices is given by MacLan e and Birkoff (1988).
A set n is partially ordered by a relation ~ if for all z , z ", z** E n:
(i) z ~ z ;
(ii) z ~ z * and z " ~ z implies z = z* ; a nd
(iii) z ~ z " and z· ~ z** impli es z ~ z ** .
Z··. An upper bound for z, z" E n is an element z· * such t hat z ~ z · · and
z ~ A least upper bound z· · for z , z " is an upper bound that is b elow all ot her upper bounds for z, z "; that is, if z ** · is a ny upper bound for z, z ", then z** ~ Z** · . If a least upper bound for z , z " exists , then it is unique by (ii). Lower bound and greatest lower bound ar e defined similarly. A lattice
n is a partially ordered set in which every pair z , z * of element s has a least
upp er bound, written z V z", and a gre atest lower bound, written z /\ z * .
n n A lattice is fin it e if the set contains onl y finit ely many elements. In
(2.10), both 1010 and 1100 are upper bounds for the pair 1001 and 0110 , but the least upp er bound is 1001 V 0110 = 1010.
The partial ord er ~ and the ope rat ions V and /\ ar e tied tog ether by the
following relationship: z ~ z" if and only if z V z" = z" and z /\ z" = z. In
fact, using this relationship , a lattice may be defined beginning with the
operations V and /\ rather than beginning with the partial order ;S, that is,
defining the partial order in term s of the operations. The following theorem is well known; see MacLane and Birkoff (1988 , §XIV, 2) for pr oof.
n Theorem 7 A set with operations V and /\ is a lattice if and only if fo r
all z, z* , z·· E n:
£1 . z V z = z and z /\ z = Zi

2.10 *Appendix: The Set of Treatment Assignments 59
L2. z V z* = z* V z and z 1\ z* = z* 1\ Z;
L3. z V (z* V z**) = (z V z") V z** and z 1\ (z* 1\ z**) = (z 1\ z") 1\ z** ; and
L4. zl\(zVz*)=zv(zl\z*)=z.
Here, L2 and L3 are the commutative and associate laws, 11 is called idempotence, and L4 is called absorption. A lattice is distributive if the distributive law also holds,
z V (z" 1\ z**) = (z V z") 1\ (z V z**) for all z, z" ,z** E n.

2.10.3 *The Set of Treatment Assignments Is a Distributive Lattice
n This section gives Savage's (1964) demonstration that is a distributive
lattice. With each N-dimensional zEn, associate a vector c of dimension
L m s , as follows. The vector c is made up of S pieces, where piece s has
m s coordinates. It is suggestive and almost accurate to say that c contains the ranks of the responses of treated units, each stratum being ranked
separately, the ranks being arranged in decreasing order in each stratum.
This would be exactly true if there were no ties , but it is not exactly true in the case of ties. Here is the exact definition, with or without ties. If
Zsl = 0, Zs2 = 0, . . . , Zs ,i - l = 0, Zsi = 1, then Csl = ns - i + 1. Continuing, if Zs ,i+l = 0, . .. , Zs ,j - l = 0, Zsj = 1, then Cs2 = ns - j + 1, and so on.
In terms of the c, (2.10) becomes (2.12), and (2.11) becomes (2.13). For instance, in (2.10), z = 1100 becomes c = 43, since the first 1 in z appears
in position i = 1, so n - i + 1 = 4 - 1 + 1 = 4 and the second 1 in z appears in position j = 2, so n - j + 1 = 4 - 2 + 1 = 3.

43

i

42

'" .:

41

32

(2.12)

<,

/

31

i

21

If there are ties among the responses in a stratum, then c is no longer a collection of ranks, because c distinguishes units with the same tied response. In the end, this is not a problem. The lattice order makes a few distinctions among treatment assignments that statistical procedures will

60 2. Randomized Experiments

ignor e .

22

/

<,

21

12

<,

/

11

(2.13)

It is readil y checked that each z has one and only one corresp onding
c. Given z , z" E n, with corresponding c and c" , the op er ations V and 1\
are defined as follows. Define c V c" a nd c 1\ c" as the vectors containing,
respectively, max(csi, C;i ) and min(csi, C;i ). Define z V z " and z 1\ z" as the
elements of n corres ponding to c V c" and c 1\ c" . It is readily checked that
t his definition makes sense, that is, that c V c" and c 1\ c" always correspond
to elements oU1. For instance, in (2.10) , z = 0110 a nd z" = 1001 correspond to c = 32 and c" = 41, so c V c " = 42 and c 1\ c" = 31, so z V z" = 1010
and z 1\ z" = 0101, as is consist ent with (2.10). Notice carefully that the coordina te (s, i) of z V z" is not gene rally equal t o max( zsi, Z;i) .
To show that n is a lattice with these operations, one needs to check
L1 to L4 in Theorem 7, but L1 to L3 hold trivially for max(csi , C;i ) and
min(csi, C;i) . To show zl\(zVz') = z in L4, it suffices t o show c l\( eve") = c .
If Csi ~ C;i' th en min{csi, max(csi, C;i )} = min(csi , Csi ) = Csi , while if Csi <
C;i, then min{c si,max(csi , c;i)} = min(csi, c;i) = Csi, so c 1\ (c V CO) = c
n as required . The second part of L4 is proved in the sa me way. .So is a
lattice.
n More than this, is a distributive lattice. As proof, it suffices to show
c V (c' 1\ CO') = (c V CO) 1\ (c V CO') , that is, to show

There are two cases. If Csi ~ min(c; i , c; i), then max{ csi ,min(c;i ' c;;)} = Csi, but also Csi is less than or equa l to both max(csi, c;i ) and maxf c. , , c;i) yet it equ als one of them, so

On the other hand, if Csi < min( c; i ' c;i), then max {Csi, mm. (c'si' c"si)} = mi.n(c'si' c"si) ,

as required to complete the proof.

2.10 *Appendix: The Set of Treatment Assignments 61
2.10.4 *Inequalities for Probability Distributions on a Lattice
This section discusses two inequalities for probability distributions on a finite distributive lattice, namely, the FKG inequality and Holley's inequality. These inequalities are the principal tool that makes use of the lattice
properties of n. The original proofs of these inequalities are somewhat
involved, but Ahlswede and Daykin (1978) developed a simpler proof involving nothing more than elementary probability. Their proof is nicely presented in several recent texts (Anderson 1987, §6, Bollobas, 1986, §19), to which the reader may refer.
A real-valued function on n, f : n --+ lR is isotonic if z ;S z* im-
plies f(z) ~ f(z*). Throughout this appendix, r has been sorted into order within each stratum, rsi 2: rS,H1 for each s, i. With this order, the arrangement-increasing statistics t(z, r) are some of the isotonic functions
on n. Actually, the arrangement-increasing statistics are the interesting
isotonic functions, for they are the isotonic functions that are unchanged by interchanging tied responses in the same stratum. If there are ties , that is, if rsi = r s ,i+l for some sand i, then there are isotonic functions that are not arrangement-increasing, specifically functions that increase when
Zsi = 0, zs ,Hl = 1 is replaced by Zsi = 1, zs ,Hl = 0; however, these func-
tions are not interesting as test statistics t(z, r) because they distinguish between people who gave identical responses. From a practical point of
view, the important point is that a property of all isotonic functions on n
is automatically a property of all arrangement-increasing functions, and all of the statistics in §2.4.3 are arrangement-increasing.
The first inequality is due to Fortuin, Kasteleyn, and Ginibre (1971).
Theorem 8 (The FKG Inequality) Let f(·) and g(.) be isotonic func-
tions on a finite distributive lattice n. If a random element Z of n is selected
by a probability distribution satisfying
prob(Z = z V z") . prob(Z = z /\ z*) 2: prob(Z = z) . prob(Z = z*)
for all z, z* E n,
then
cov{f(Z), g(Z)} 2: 0.
For example, randomization gives equal probabilities to all elements of
n, so the randomization distribution satisfies the condition for the FKG
inequality. Hence, under the null hypothesis of no effect in a randomized experiment, any two arrangement-increasing statistics have a nonnegative correlation.
The next theorem is due to Holley (1974).
Theorem 9 (Holley's Inequality) Let f( ·) be an isotonic function on a
finite distributive lattice n. If Z and Z are random elements of n selected

62 2. Ran domi zed Exp eriments
by two probabilit y distrib utions satisf yi ng
prob(Z = z V z * ) . prob(Z = z A z*) ~ prob(Z = z) . prob (Z = z") for all z , z" E n,
th en
E{f(Z)} ~ E{f(Z)}.
In ot her words, th e pr emise of Holley 's inequ ality is a sufficient condition for Z to be sto chastically lar ger t han Z , in t he sense that for every arrangement-increasin g function j (.), the random variable j (Z ) has high er expect at ion than f (Z ). Holley's inequ ality helps later in comparing a nonrandom assignment of treat ments to a random ass ignme nt . A related result is given by Krieger arid Rosenb aum (1991) . Lit er ature related to Holley 's inequality is reviewed in Rosenbaum (1999).
2.10.5 *An Identity in n
There is a useful identity in the set n of treatment ass ignments . The identity
links V and A to th e addition of vect ors, and therefore it is useful in verifying th e conditions of the FKG inequality and Holley 's inequality. It is true for this lattice, but not true generally for all lattices.
Lemma 10 For all z , z * E n,
z V z" + z A z" = z + z" .
Proof. Fix a coordinate (s,i) , so the task is to show Zs i+z;i = Zl\si +Zvsi, wher e Zl\ si and ZVs i are the (8, i ) coordinates of z Az* and zVz* , resp ectively. Let c and c" correspond with z and z * , resp ectively. Ther e ar e three cases,
depending upon the value of Zsi + z;i ' 1. If Zsi + z;i = 0, then Csj =1= n s - i + 1 and C;j =1= n s - i + 1 for
+ + j = 1, .. . , m s , so max ( c sj , C;j ) =1= n s - i 1 and min ( c sj , C;j ) =1= n s - i 1 for j = 1, .. . , m s , so + Zl\si Zvsi = 0, as required.
2. If Zsi + z ; i = 2, t hen there is a j and a k such that Csj = n s - i + 1 and c;k = n s - i + 1. If j = k, then max ( c s j, C;j) = n s - i + 1 and min (csj , C;j ) = n s - i + 1, so Zl\ si = 1 and ZVsi = 1, so that + Zl\si ZVsi = 2, as required . If j < k , then n , - i + 1 = Csj > Csk a nd C;j > c;k = n s - i + 1, so min (c sj , C;j ) = Csj = ns - i + 1 and max (Csk ' c;k) = c;k = n s - i + 1, so
Zl\si = 1 and ZVsi = 1, so that Zl\si + Zvsi = 2, as required. The case j > k
is similar.
3. If Zsi = 1 and z;i = 0, so Zsi + z;i = 1, then there is a j su ch that Csj = n s - i + 1 but c;k =1= n s - i + 1 for k = 1, ... , m s . In this case , eit her n s - i + 1 = max ( c sj , C;j ) or n s - i + 1 = min ( c sj , C;j ) but not both, and moreover , n s - + i 1 =1= max (Csk ' c ;k) and n s - i + 1 =1= min ( Csk, C;k ) for all

2.11 Bibliographic Notes 63
+ k =1= j , so Z/\ s i ZVsi = 1, as required. The case Zs i = 0 and Z.;i = 1 is
similar. ·
If there were no ties , so c and c' are ranks, th en Lemma 10 has the following interpret at ion. Within each stratum, the operations V and 1\ take the ranks in c and c' and apportion them in forming c V c' and c 1\ c' , but in this process they do not create or delet e ranks that appear in c and c' .
2.11 Bibliographic Notes
Fisher is usually credited with the invention of randomized experiments. See, in particular , his important and influential book, The Design of Experim ents , first published in 1935. Randomization is discussed in many articles and textbooks. In particular, see Kempthorne (1952), Cox (1958a, §5) and Cox and Reid (2000) for discussions of randomization in experimental design , and see Lehmann (1975) and Maritz (1981) for discussions of its role in nonparametrics. Mantel's (1963) pap er was significant not just for the method he proposed , but also for its strengthening of the link between nonpar am etric methods and contingency table methods. The model for a tr eatment effect in §2.5.2 in which each unit has two potential respons es, one under treatment and the other under control, has a long history. In an article first published in Polish and recently translated into English, Neyman (1923) used it to study the behavior of statistical tests und er random assignment of treatments. Related work was done by Welch (1937), Wilk (1955) , Cox (1958b , §5), and Robinson (1973), among others. Rubin (1974, 1977) first used the mod el in observational studies. In particular, he discussed the condit ions under which matching, st ra tification, and covariance adjustment all estimate the same treatment effect. See also Hamilton (1979) and Holland (1986) . Arrangement-increasing functions have been studied under various names by Eaton (1967), Hollander, Proshan, and Sethuraman (1977) , and Marshall and Olkin (1979, §6F); see also Savage (1957). Although the Hodges-Lehmann (1963) estimates are often derived from rank tests, these R-estimates are very closely related to other families of estimates based on order statistics, L-estimates , or based on solving equations, Msestimates; see Gastwirth (1966) and Jureckova (1984). An attraction of R-estimates over L-estimates or M-estimates is that R-estimates have associated tests and confidence intervals that are exact, nonparametric, and explicitly linked to randomization in experiments. Sign-score statistics are discussed in Rosenbaum (1988) in connection with sensitivity analysis where these statistics permit cert ain simplifications. The discussion of complex outcomes in §2.8 draws from Mann and Whitney (1947), Gehan (1965), Mantel (1967), and Rosenbaum (1991, 1994). The material in §2.1O uses ideas from Savage (1964) and Rosenbaum (1989, 1995). The results in §2.10 concern permutations of vectors with binary coordinates, but some

64 2. Ran domized Exp erim ents
of t hese resul ts extend to perm utations of vectors with rea l coordinates; see Kri eger and Rosenbaum (1994) .
2.12 Problems
1. The surprising power of the Lady tasting tea . In §2.2, what is t he power of the test? Specifically, suppose t he Lady ca n distinguish milk first from t ea first , and is always acc urate . W hat is t he powe r of a onesided, 0.05 level test ? W hich 2 x 2 t abl es of t he form Table 2.2 lead to rejection at th e 0.05 level? If the Lady can dist inguish, what is t he cha nce of a table that lead s to rejecti on ?
2. Interference between units with longitudinal data . Suppose that there
ar e S people, S = 1, . . . , S, and p erson s is measu red once a week for
n s consecut ive weeks, i = 1, . . . ,ns . Here, one unit (s, i) is one p erson in one week. For person s, a fixed number , m s , of weeks are picked at ra ndom, ind epend ently for different people, and person s is t reate d in t hose weeks. Writ e Zsi = 1 if p erson s is treated in week i, Z si = 0 otherw ise, so tti; = L~~ l Zsi' The observed respon se of person s in week i is R si , which may be affecte d by t he cur rent t reatment Z si and previous treatments, Zsj , j = 1, ... , i. In addit ion, pe rso n s has a pretreatment baseline resp onse, R so, which is un affected by treat-
ment, and so is fixed. Cons ider the model R si - R s,i- l = TJsi + I::.Zsi for i = 1, . .. , n s , so t he treatme nt produ ces additive gains, where
I::. and the TJsi are unknown fixed par am eters. Show t hat t his mode l violates the condition of "no interference between units" in §2.5.2.
Let T = t (Z, R ) be t he st rat ified rank sum stat istic, applied to t he
cha nges , R si - R s,i-l , so the fl s changes for person s ar e ranked from
L 1 to n s and T is t he sum of t he ranks for the m s treated weeks.
Under th e null hyp othesis, H o : I::. = 0, wh at is the randomi zation distribution of T ? How does it compare t o the usu al randomization distributi on of T of the st rat ified rank t est ? How could you use t he rand omization distribution of T wh en I::. = 0 to t est the general hypothesis Ho : ~ = I::.o? (Hint : Think abo ut adj uste d responses , R si - R s,i-l - l::.oZs;.) How could you use the randomi zation distribut ion of T when I::. = 0 to build a confiden ce int erval for I::.? Does int erference bet ween uni t s preclude randomizat ion infere nce?
3. Proof of Proposition 1. Let A and B be two fini te, non emp ty, disjoint sets, a nd let A x B be t he set of all order ed pairs (a, b) with a E A and b E B . If (a, b) is picked at random from A x B , wit h ea ch element of A x B having t he same probability, show that a a nd bare
ind ependent. Use t his to prove Propositi on 1 for S = 2. Then use it

2.12 Problems 65
again to show that if Proposition 1 is true for 5, then it is also true
for 5 + 1.
4. Proof of Proposition 2. Prove Proposition 2. (Hint: Why does

Why does

Remember qsi - qs is fixed . What is E (Zsi)? What is

What is E (ZsiZsj)? Be careful about i = j and i l' j.)
5. Different statistics that yield the same randomization test. Let f (.) be a strictly increasing function , so x < y implies f (x) < f (y). Show that
a test that rejects at level 0: when t (Z, R) ~ k is exactly the same
test as the test that rejects when f {t (Z, R)} ~ f (k). In a uniform
randomized experiment with a single stratum, 5 = 1, dropping the s subscript, show that a randomization test of no treatment effect based
on the total in the treated group, I: ZiRi, is exactly the same test
as a randomization test based on the difference between the treated and control group means,

t (Z, R) = I: ZiR; _ I: (1 - Zi) Ri .

m

n-m

In a uniform randomized experiment with a single stratum, 5 = 1,
what is the Hodges-Lehmann estimate of an additive treatment ef-
fect , rTi = rCi + T obtained from taking t (Z, R) to be the difference
between the treated and control group means?

6. An effect increasing statistic with partially ordered responses. Show that the statistic (2.8) is effect increasing. (Hint: Consider two response vectors, rand r", and the corresponding indicators, Lsij and L;ij')

7. Metaphysics. Section 2.5.3 discussed the distribution of observable
quantities (Zsi, Rsi) in a uniform randomized experiment under the
model of an additive treatment effect, rt:« = rc« + T. Because
(rTsi' rCsi) is not jointly observed, one sees only R si = rr« if Zsi = 1
for a treated subject, or else one sees Rsi = rou if Zsi = 0 for a

66 2. Randomized Experiments
control subj ect . Consider the case of a single stratum, S = 1, dropping the subscript s, and recall that , in a complet ely randomized experiment, the observable consequence of the addit ive effect model,
rr, = r e i + T, is that the distribution of treated and control re-
sponses have the same sha pe and dispersion, but different locations, so the treated distribu tion is shifte d by T . Does t he addit ive model
rTsi = rc« + T have content beyond it s implications for observable
distributions? Keep in mind that t his is a problem in metaphysics , not st atist ics, so perhaps there is an answer , perhap s not. Hint: It is reasonable to ask of a question whether it is a reasonable question to ask. What does the phrase "content beyond" mean in this question? If "content beyond" were replaced by "observable consequences ," what becomes of the question? If "conte nt beyond" were replaced by "a mathematical form different from, " what b ecomes of the question? In parallel, Wittgenstein (1958, #47, p22-23) writes:
To the philosophical qu estion: "Is the visual image of this tree composite, and what are its component parts?" the correct answer is "T hat depend s upon what you understand by 'composite'." (And that is of course not an answer but a rejection of the question.)
2.13 References
Ahlswede , R. and Daykin, D. (1978) An inequality for t he weights of two families of set s, their unions, and intersections. Z. Wahr sch. Verus Gebiete, 43, 183-1 85.
Anderson ,1. (1987) Combinatorics of Fin it e Sets. New York: Oxford University Press.
Bir ch , M. W. (1964) The det ecti on of partial association, I: The 2 x 2 case . Journal of the Royal Stat istical Society , Series B , 26, 313-324.
Birch, M. W. (1965) The det ection of partial association , II : The general case. Journal of the Royal Statistical Society , Series B, 27, 111-124.
Bollobas, B. (1986) Combinato rics. New York: Cambridge University Press.
Campbell, D. and St anley, J. (1963) Experimental and Quasi-Experimental Designs for Research. Chicago: Rand MeNally.
Cochran, W. G. (1963) Sampling Techniques. New York : Wil ey.
Cox, D. R. (1958a) Planning of Experiments. New York: Wil ey.

2.13 References 67
Cox, D. R. (1958b) The interpretation of the effects of non-additivity in the Latin square. Biometrika, 45 , 69-73 .
Cox, D. R. (1966) A simple example of a comparison involving quantal data. Biometrika, 53, 215-220.
Cox, D. R. (1970) The Analysis of Binary Data. London: Methuen.
Cox , D. R. and Hinkley, D.V . (1974) Theoretical Statistics. London : Chapman & Hall .
Cox , D. R. and Reid, N. (2000) The Theory of the Design of Experiments. New York: CRC Press.
Eaton, M. (1967) Some optimum properties of ranking procedures. Annals of Mathematical Statistics, 38, 124-137.
Eaton, M. (1982) A review of selected topics in probability inequalities. Annals of Statisti cs, 10, 11-43.
Eaton, M. (1987) Lectures on Topics in Probability Inequalities. Amsterdam: Centrum. voor Wiskunde en Informatica.
Efron, B. (1971) Forcing a sequential experiment to be balanced. Biometrika, 58 , 403-417.
Fisher, R. A. (1935, 1949) The Design of Experiments. Edinburgh: Oliver & Boyd.
Fortuin, C., Kasteleyn, P., and Ginibre, J . (1971) Correlation inequalities on some partially ordered sets . Communications in Mathematical Physics, 22 , 89-103.
Freidlin, B. and Gastwirth, J . L. (2000) Should the median test be retired from general use? American Statisti cian, 54 , 161-164.
Friedman, L. M., DeMets, D . L., and Furberg, C. D. (1998) Fundamentals of Clinical Trials. New York: Springer-Verlag.
Gastwirth, J. 1. (1966) On robust procedures. Journal of the American Statistical As sociation, 61 , 929-948.
Gehan, E. (1965) A generalized Wilcoxon test for comparing arbitrarily singly censored samples. Biometrika, 52, 203-223.
Gibbons, J . D. (1982) Brown-Mood median test. In: Encyclopedia of Statistical Sciences, Volume 1, S. Kotz and N. Johnson, eds., New York: Wiley, pp . 322-324.
Hamilton, M. (1979) Choosing a parameter for 2 x 2 table or 2 x 2 x 2 table analysis. American Journal of Epidemiology, 109, 362-375 .

68 2. Randomized Experim ents
Hettmansperger, T . (1984) Statistical Inference Based on Ranks. New York: Wiley.
Hodges , J . and Lehmann, E. (1962) Rank methods for combination of independent experiments in the analysis of variance. Annals of Mathematical Stati stics, 33, 482-497.
Hodges , J . and Lehmann, E. (1963) Estimates of location based on rank tests. Annals of Mathemat ical Stat ist ics, 34, 598-611.
Holland, P. (1986) Statistics and causal inference (with discussion) . Journal of the American Stat istical Association, 81, 945-970.
Hollander, M., Proschan , F ., and Sethuraman, J . (1977) Functions decreasing in transposition and their applications in ranking problems . Annals of Statistics, 5, 722-733.
Hollander , M. and Wolfe, D. (1973) Nonparametric Statistical Methods. New York: Wiley.
Holley, R. (1974) Remarks on the FKG inequalities. Communications in Math emati cal Physics, 36, 227-231.
Jureckova, J. (1984) M-, L- and R-estimators. In : Handbook of Stat istics, Volume IV, P. R. Krishnaiah and P. K. Sen , eds ., New York : Elsevier, pp . 463-485 .
Kempthorne, O. (1952) The Design and Analysis of Experiments. New York: Wiley.
Krieger , A. M. and Rosenbaum, P. R. (1994) A stochastic comparison for arrangement incre asing functions. Combinatorics, Probabilit y and Computing, 3 , 345-348.
Lehmann, E. 1. (1959) Testing Statist ical Hypoth eses. New York: Wiley.
Lehmann, E. 1. (1975) Nonparam etri cs: Statisti cal Methods Based on Ranks . San Francisco: Holden-Day.
MacLane, S. and Birkoff, G. (1988) Algebra. New York: Chelsea.
Mann, H. and Whitney, D. (1947) On a test of whether one of two random variables is stochastically larger than the other. Annals of Mathematical Stat istics, 18 , 50-60.
Mantel, N. (1963) Chi-square tests with one degree of freedom : Extensions of the Mantel-Haenszel procedure. Journal of the American Statist ical Association , 58, 690-700.

2.13 References 69
Mantel, N. (1967) Ranking procedures for arbitrarily restricted observations. B iom etrics, 23 , 65-78.
Mantel, N. and Haenszel, W . (1959) St atistical aspe cts of retrospective studies of disease. Journal of the National Cancer Institute, 22 , 719748.
Maritz, J . (1981) Distributio n-Free Stat istical Methods. London : Chapman & Hall.
Marshall, A. and Olkin, I. (1979) In equalities: Theory of Majori zation and It s Applications. New York: Academic.
McNemar, Q. (1947) Note on the sampling err or of the differences between corr elat ed proportions or percentage. Psy chometrika, 12, 153-157.
Murphy, M. , Hultgren , H., Detre, K., Thomsen, J ., and Takaro, T . (1977) Treatment of chronic stable angina: A preliminary report of survival data of the randomized Vet erans Administration Cooperative study. N ew England Journal of Medicine, 297, 621-627.
Neyman , J. (1923) On the applicatio n of probability theory to agricult ur al exper ime nts. Essay on principles. Section 9. (In Polish) Roczniki Nauk Roiniczych, Tom X, pp. 1-51. Reprinted in Statistical Sci ence 1990, 5 , 463-480, with discus sion by T . Speed and D. Rubin.
Neyman, J . (1935) Statistical problems in agricultural experimentation. Supplement to the Journal of the Royal Statistical Society, 2, 107-180.
Pagano, M. and Tritchler, D. (1983) Obtaining permutation distributions in polynomial time. Journal of the American Statisti cal Association, 78 , 435-440.
Robinson, J . (1973) The large sample power of permutation tests for randomization models. Annals of Statisti cs, 1 , 291-296 .
Rosenbaum, P. R. (1988) Sensitivity analysis for matching with multiple controls. Biometrika, 75, 577-581.
Rosenbaum, P. R. (1989) On permutation tests for hidden biases in observational st udies: An application of Holley's inequality to the Savage lattice. Annals of Statisti cs, 17, 643-653.
Rosenbaum, P. R. (1991) Some poset statistics. Annals of Stat istics, 19, 1091-1097.
Rosenbaum, P. R. (1994) Coherence in observational st udies. Biometrics, 50, 368-374.

70 2. Randomized Exp eriments
Rosenb aum , P. R. (1995) Qu antiles in nonrandom sa mples and observational studies. Journal of the American Statisti cal Association , 90 , 1424- 1431.
Rosenbaum, P. R. (1999) Holley's inequality. En cyclopedia of Statist ical Sciences, Update Volume 3 , S. Kotz , C. B. Read , D. L. Banks, eds ., New York: Wiley, pp . 328-331.
Rubin, D. B. (1974) Estimating the ca usal effects of treatments in randomized and nonr andomized studies. Journal of Edu cational Psychology, 66 , 688-701.
Rubin, D. B. (1977) Assignm ent to treatment group on t he bas is of a covar iate. Journal of Edu cationa l Statistics, 2 , 1- 26.
Ru bin , D. B. (1986) Whi ch ifs have ca usal answers? Journ al of the American S tatistical Association, 81 , 961- 962.
Savage, I. R. (1957) Cont ributions to t he theory of rank order stat istics: T he t rend case . Annals of Math ema tical Statisti cs, 28, 968-977.
Savage, I. R. (1964) Contributions to t he theory of rank order statistics: App lications of lat tice theory. Review of the Intern ational Statistical Institute, 32 , 52-63.
Tukey, J. W . (1985) Improving crucial randomized experiments-especially in weather modification-by double randomization and rank combination. In: Proceedings of the B erkeley Conference in Honor of Jerzy Neyman and Jack Kiefer, L. Le Cam and R. Olshen, eds ., Volume 1, Belmont , CA: Wadsworth, pp . 79-108.
Welch, B. L. (1937) On t he z-test in random ized blocks and Lati n sq uares . Biom etrika, 29 , 21-52.
Wilcoxon, F . (1945) Individual comparisons by ranking methods. Biom etrics, 1 , 8083.
Wilk , M. B. (1955) The ran domization analysis of a generalized randomized block design. Biometrika, 42 , 70-79.
Wittgenstein, L. (1958) Philosophical In vestigations (T hird Editi on ). Englewood Cliffs, NJ: P rent ice-Hall.
Zelen , M. (1974) T he randomization and st ratification of patients t o clinical trials. Journal of Chronic Diseases, 27, 365-375.

3
Overt Bias in Observational Studies
3.1 Introduction: An Example and Planning Adjustments
3.1.1 Outline: When Can Methods for Randomized Experiments Be Used?
An observational study is biased if the treated and control groups differ prior to treatment in ways that matter for the outcomes under study. An overt bias is one that can be seen in the data at hand-for instance, prior to treatment, treated subjects are observed to have lower incomes than controls. A hidden bias is similar but cannot be seen because the required information was not observed or recorded. Overt biases are controlled using adjustments, such as matching or stratification. In other words , treated and control subjects may be seen to differ in terms of certain observed covariates, but these visible differences may be removed by comparing treated and control subjects with the same values of the observed covariates, that is, subjects in the same matched set or stratum defined by the observed covariates. It is natural to ask when the standard methods for randomized experiments may be applied to matched or stratified data from an observational study. This chapter discusses a model for an observational study in which there is overt bias but no hidden bias . The model is, at best, one of many plausible models, but it does clarify when methods for randomized experiments may be used in observational studies, and so it becomes the starting point for thinking about hidden biases . Dealing with hidden bias is

72 3. Overt Bias in Observational Studies
the focus of most of the later chapters. To permit discussion of conceptual issues in this chapter, Chapter 10 discusses the algorithmic issues that arise in constructing matched sets or strata with many covariates. The remainder of §3.1 considers an example and then discusses some of the planning steps that precede adjust ments for covariates.
3.1.2 An Example with a Single Covariate
Cochran (1968) presents three stark examples of overt biases and their removal through adjustments. We will look at one of these. The data are from a study by Best and Walker of mortality in three groups of men: nonsmokers, cigarette smokers, and cigar and pipe smokers. Nonsmokers had a mortality rate of 20.2 deaths per 1000 people per year, cigarette smokers had 20.5 deaths, and cigar and pipe smokers had 35.5 deaths. The naive interpretation would be that cigarettes are harmless, but either cigars or pipes or both are dangerous. Cochran then gives the mean age in each group: 54.9 years for nonsmokers, 50.5 years for smokers, and 65.9 for cigar and pipe smokers . Clearly, the cigar and pipe smokers are older, so their higher death rate is not surprising, and may not reflect an effect of cigars or pipes. On the other hand , the cigarette smokers are the youngest group, and yet their mortality rate is slightly higher than the somewhat older nonsmokers. Perhaps cigarettes are not harmless.
Cochran then adjusts mortality for age, that is, removes an overt bias in the outcome by adjusting for an imbalance in a covariate. He uses age to divide the men into three strata or subclasses so that men in the same stratum have similar ages. Nonsmokers, cigarette smokers, and cigar and pipe smokers of roughly the same age are then compared to each other within each stratum, and the results are combined into a single rate using direct adjustment, essentially as described in §2.7.1. The adjusted mortality rat e is 20.3 deaths per WOO per year for nonsmokers, 28.3 for cigarette smokers, and 21.2 for cigar and pipe smokers. Now it is cigarettes that appear dangerous .
Which rates should be trusted, unadjusted or adjust ed ? Neither. The unadjusted rates are clearly wrong as a basis for estimating the effects of smoking, for they compare men who are not comparable in terms of one of the most important features of human mortality, namely, age. The adjusted rates are not clearly wrong . They might estimate the effect s of smoking. However, it is possible that there is another covariate that was not recorded that has an impact similar to age; in this case , there would be a hidden bias. The current chapter discusses the conditions under which the methods in Chapter 2 for randomized experiments successfully estimate treatment effects in observational studies. These conditions become the basis in later chapters for thinking about hidden biases.
Cochran used three age strata. One might reasonably ask whether three strata are sufficient, whether such broad age groups suffice to remove the

3.1 Introduction: An Example and Planning Adjustments 73
overt bias due to age, and indeed this is the main question in Cochran's paper. If instead of three strata, twelve strata are used, then the adjusted rates are 20.2 for nonsmokers, 29.5 for cigarette smokers , and 19.8 for cigar and pipe smokers. Three-age strata and twelve-age strata produce similar adjusted rates, both of which are very different from the rates prior to adjustment. Cochran presents a theoretical argument concluding that five strata, each containing 20% of the subjects, will remove about 90% of the bias in a single continuous covariate such as age.
3.1.3 Planning Adjustments for Overt Biases
Options narrow as an investigation proceeds. What is easy early on may become difficult or impossible later. This section discusses the earliest stages of planning and data collection, as they relate to adjustments for bias. The points raised are elementary, but at times ignored. When ignored, the problems created can be far from elementary, at times insurmountable.
The control of overt biases begins before the study is designed. A first step in planning an observational study is to determine what treatments will be studied, and in the process to distinguish outcomes from covariates. Outcomes measure quantities that may be affected by the treatment, while covariates are not affected; see §2.5. Cox (1958, §4.2) uses the term concomitant observations in place of covariate and writes:
The essential point in our assumptions about these observations is that the value for any unit must be unaffected by the particular assignment of treatments to units actually used. In practice this means that either: (a) the concomitant observations are taken before the assignment of treatments to units is made; or (b) the concomitant observations are made after the assignment of treatments, but before the effect of treatments has had time to develop . .. ; or (c) we can assume from our knowledge of the nature of the concomitant observations concerned, that they are unaffected by the treatment.
As an example of type (c), Cox mentions the covariate that records the relative humidity in a textile factory, where it is known that the treatments under study could not possibly affect the relative humidity.
If adjustments are not confined to covariates, then adjustments may remove part or all of the effect of the treatment. To illustrate, consider an extreme, hypothetical example. Imagine a study comparing a placebo and a drug intended to reduce blood pressure, the outcome being the incidence of stroke. If the groups were compared after adjustment for blood pressure levels six months after the start of treatment, then the adjusted incidence of stroke might be similar in drug and placebo groups, not because the drug has failed to work , but rather because the drug reduces the risk of stroke

74 3. Overt Bias in Observational Studies
by reducing blood pressure. If the effect of the drug on blood pressure is removed, the effect on stroke is removed with it.
While adjustments for an outcome can remove part of the treatment effect, adjustments of this sort are occasionally performed. It may be suspected that the treatment has only slight effects on a particular outcome, but this outcome may be strongly related to an important covariate that was not measured. An example occurred in the studies by Coleman, Hoffer, and Kilgore (1982) and Goldberger and Cain (1982) of the effects of Catholic versus public high schools . These studies compared cognitive test scores in the senior year of high school adjusting for various covariates, but the studies also adjusted for an outcome, namely, cognitive test scores in the sophomore year. The sophomore year test scores may already be affected by the difference between Catholic and public high schools, so they are, in principle, outcomes, not covariates. Still, it is natural to suspect that any effect of Catholic versus public high schools is produced gradually and cumulatively, and that only a part of the effect is present in the sophomore year. These studies used this outcome as a surrogate for an important covariate that was unavailable, namely, cognitive test scores prior to the start of high school. There are, then, two hazards: adjusting for sophomore test scores can remove part of the difference between Catholic and public schools; and failing to adjust for an early test score may yield a comparison of students who were not comparable in terms of their cognitive abilities prior to the start of high school. Notice that the second hazard is not present in a randomized experiment, so in an experiment, it is possible to give unequivocal advice that adjustments for outcomes should be avoided when estimating treatment effects. In an observational study, both hazards are present, and must be weighed; see Rosenbaum (1984a, §4) for discussion of alternative methods of analysis. The important point for the initial planning of observational studies is the distinction between outcomes and covariates, and their different status in adjustments.
The next step in planning is to list the covariates that will be measured. It is at this stage that biases become either overt or hidden. Since there is no way to completely address a hidden bias, a small change in this list may determine whether the study is convincing. A small oversight, easily corrected in the planning stage, may be an insurmountable problem at a later stage. In the design of randomized clinical trials, the standard practice is to begin with a written protocol that describes the data that will be collected and the main analyses that will be performed. Before the trial starts, the protocol is circulated for critical comment. Observational studies would, I believe, benefit from a written protocol and critical commentary.
Adjustments for overt biases may begin with data collection rather than with data analysis. Often treated subjects are matched to controls to form pairs or matched sets of subjects who are comparable in terms of observed covariates, and matching may take place before outcomes are measured. Chapter 10 discusses matching methods. Here, three points should be men-

3.1 Introduction: An Example and Planning Adjustments 75
tioned. First, unlike analytical adjustments, adjustments that are built into the study design are irrevocable. In the hypothetical example above concerning drug versus placebo to prevent stroke, it would be a mistake to adjust for blood pressure after treatment. If this mistake were made using an analytical method such as in §3.1.2, then it could be corrected by performing a different analysis, but if the mistake were made by matched sampling then it would be difficult to correct.
Second, certain covariates are more easily controlled through matching in the design than through analytical adjustments. Typically, these are covariates that classify subjects into many small categories. Matching can ensure that treated and control subjects belong to the same categories, but if matching is not used in the design of the study, some categories may have treated subjects and no controls or controls and no treated subjects. For instance, consider a study (Rosenbaum, 1986) that comp ared cognitive skills in what would be the senior year of high school for sophomores who dropped out of school and similar sophomores who remained in school. This was done with a national sample of students, and the high school was an important covariate with many values. The study used matched pairs of students from the same school having similar test scores, academic performance, and disciplinary records in the sophomore year, before the dropout left school.
Cost is an important consideration in deciding whether to match. If some covariate information is readily available, but other data are difficult or expensive to obtain, then matching becomes more attractive, but if data come with negligible costs, then matching during the design becomes somewhat less attractive. The reason is that , in many studies, some controls will be so different from treated subjects that they are of little use for comparisons (Dehejia and Wahba 1999). In the example above, many high-school students look very different from most dropouts in terms of test scores , academic performance, and disciplinary problems, so these students are of limited use in trying to determine how students who drop out would have performed had they remained in school. Matching may avoid collecting data on controls who will later be of little use .
A compromise between selecting matched pairs and using all potential controls is to match each treated subject to several controls. Dry (1975) examines the efficiency of studies that match several controls to each treated subject, finding that there is little to be gained from having more than four controls per treated subject with continuous responses. Smith (1997) presents an interesting case study of multivariate matching with multiple controls. In a single application, he compared pair matching with 1 control, matching with 8 controls and matching with 15 controls, concluding that 8 controls was best in this particular study. See also Ming and Rosenbaum (2000) . Chapter 10 discusses the construction of matched sets with equal and variable numbers of controls per treated subject.

76 3. Ov ert Bias in Obs erv at ional Studies
Matched st udies can often be improved by a pilot study t hat forms a small number of matched pairs and scrutinizes those pairs using et hnograp hic or qualitative techniques . For inst an ce, one might interview a few paired subjects or read the text of their hospital charts . This process may begin to reveal the hidden biases not visible in data on obs erved covariates , or it may suggest more accurate ways of using the data. An example is discussed in detail by Rosenbaum and Silbe r (2001 ). Emerson (1981) and Katz (2001) survey ethnographic techniques with reference to a large literature; see also Blumer (1969) and Becker (1996) .
Having collected t he data on covariates, t he question arises: Should adjustments be made for all observed covariates? If not, how shou ld covariates be selected for adj ustment? T hese questions are somewhat cont rove rsial, not so much because t he issues involved are un clear , but rat her becau se t here is no fully satisfactory answer. In principle, there is little or no reason to avoid adjustment for a true covariate, a variable descri bing sub jec ts before treat ment . There is little harm in compar ing sub jec ts who wer e compar abl e before treat ment in ways that are not relevant for the outc omes of inte rest . In experiments, ran domization t ends t o make treat ed a nd cont rol groups com parable in terms of all covariates , relevant and irr elevan t . In practice, t he sit ua tion is often more involved , and increasing t he number of covariates used in adjustments increases costs a nd complexities, a nd may make it more difficult to adj ust for t he most important covariates. In par t , the re are issues of data quality and com pleteness. As more covariates are collected and analyzed, it beco mes increasingly difficult to ensure t hat all covariates meet high standards of accuracy and completeness, and increasingly difficult to ensure that each covariate receives the needed attention when used in modeling or matching. If there are many covariates, each with some missing dat a, t here may be few sub jects wit h comp lete data on all covariates, and this may make t he analysis more difficult than it would ot herwise bo . T hose considerations weigh most heavily on covariates having doubtful relevance to outcomes of interest .
Perh ap s t he most common method for select ing covariates is also t he most widely crit icized . It entails comparing treat ed and cont rol groups wit h respect to a long list of covariates, say using a t-test, and adjust ing only for those covariates for which significant differen ces are found. Ther e are three problems with t his. First, the process does not conside r the relat ionship be tween covariate and outcome . Second , there is no reason to believe that th e absence of stat ist ica l significance implies t he imbalance in t he covariate is small enough to be ign ored . Third , t he process considers covaria tes one at a ti me, while the adj ust ments will con trol t he covariates simultaneous ly. Add ressing t he first two problems, Cochran (1965, §3.1) studied this technique under a sim ple linear regression model in which all quantities are Norma lly distributed and a sing le covariate is t he only source of bias. He looked at t he coverage probability of t he 95% confidence interval for the effect of the treatment on an outcome when no adj ustment

3.2 Adjustments by Exact Stratification and Matching 77
had been made for the covariate. This coverage probability was 90% or more providing the t-statistic for the covariate was less than 1.5 in absolute value and providing the squared correlation between the covariate and the outcome was 0.5 or less. This limitation on the square correlation is often reasonable for a covariate whose relevance is in doubt. He concluded: "If a single [covariate] shows a value of t above 1.5, these results suggest that we have another look at this [covariate] when the values of the [outcome] become known." Canner (1984, 1991) discusses closely related issues .
The following approach is often reasonable and practical. Begin by selecting a tentative list of covariates for adjustments using scientific knowledge of the relevant covariates together with exploratory comparisons of covariates in the treated and control groups, perhaps including some version of the technique evaluated by Cochran (1965, §3.1). With this tentative list, determine the tentative method of adjustment; that is, select the matched pairs or sets, define the strata, and determine whatever modeling technique will be used. Apply this method of adjustment to the covariates excluded from the tentative list , identifying any covariates exhibiting a large imbalance after adjustment. Reconsider the tentative list of covariates in light of this analysis. This approach addresses, at least in part, each of the three problems in the previous paragraph. The focus is on covariates known to be relevant since they are included in the initial list . At the same time, the data are given several opportunities to call attention to imbalances that might not be anticipated. Examples along these lines are discussed by Rosenbaum and Rubin (1984) and Silber et al. (2001) .
3.2 Adjustments by Exact Stratification and Matching
3.2.1 Treatment Assignment with Unknown Probabilities
When is an observational study free of hidden bias? When do adjustments such as matching and stratification remove all of the bias? This section describes a model for an observational study with overt but no hidden bias. In most observational studies, this model is, at best, one of many plausible models-hidden biases are possible. The model is a start, indicating the inferences that would be appropriate were hidden biases absent. Later chapters try to determine whether hidden biases are present and ask how inferences might change if they are.
Initially, there are M units available for study, and each has a value of an observed covariate x , which may contain several variables. Often the covariates x are used to reorganize the data prior to analysis, for instance,

78 3. Overt Bias in Observational Studies

by matching or stratifying on x. Number the M units j = 1, . .. , M, so X[j] is the covariate for the jth unit and the treatment assignment for this unit is
Z[j]' The bracketed subscript [j] signifies the numbering of units before they
are reorganized. After reorganization, a unit will have a different subscript without a bracket.
As a model for an observational study, imagine that unit j is assigned to treatment with probability 1l"[j] = prob(Z(jJ = 1) and to control with probability 1 - 1l"[j] = prob(Z[j] = 0), with assignments for distinct units
being independent, and with 0 < 1l"[j] < 1. The model says that treatments
were assigned by flipping biased coins , possibly a different coin with a different bias for each unit, where the biases of the coins or the 1l"'S are unknown. The model says:

M
prob(Z[1] = Z1, . . . , Z [M ] = ZM) = IT1l"U] {1 - 1l"[j]}1-Zj ·
j=l

(3.1)

In an observational study, 1l"(j] is unknown, so the distribution of treatment assignments Z[1J' . . . ,Z[M] is unknown, and it is not possible to draw inferences as in Chapter 2 where randomization created a known distribution of treatment assignments.
Consider now the model for an observational study with overt biases but no hidden biases. An observational study is free of hidden bias if the 1l"'S, though unknown, are known to depend only on the observed covariates X[j] , so two units with the same value of x have the same chance 1l" of receiving the treatment. Formally, the study is free of hidden bias if there exists a function 'x('), whose form will typically be unknown, such that
1l"[j] = 'x(x(j]) for j = 1, . .. , M . If the study is free of hidden bias, then
(3.1) becomes

ITM
prob(Z[1) = Zl, · ·· ,Z[M] = ZM) = 'x(X[jJ)Zj{1- 'x(X[j])}1-zj ·
j=l

(3.2)

In short, an observational study is free of hidden bias when (3.2) holds. Rubin (1977) calls (3.2) "randomization on the basis of a covariate."
When the study is free of hidden bias, the function 'x(x) is called the propensity score. In §1O.2, the propensity score 'x(x) is redefined so that it is still meaningful when hidden biases are present; however, in that case,
1l"[j] =f. 'x(X[j]), and (3.2) does not follow from (3.1) . A study is free of
hidden bias when the treatment assignment probabilities 1l"[jJ are given by the propensity score 'x(x(j]) which is always a function of the observed covariates X[j] . Chapter 4 discusses a model in which there is hidden bias and 1l"[j] is not a function of X[j] .
A significance level, such as (2.3) , cannot be calculated using (3.2) because 'x(x) is unknown. To adjust for overt bias in a study that is free of hidden bias is to address the fact that 'x(x) is unknown. The simplest approach is to stratify on x .

3.2 Adjustments by Exact Stratification and Matching 79

3.2.2 Stratifying on x
Often, units are grouped into strata on the basis of the covariate x . From the M units, select N :::; M units and group them into S nonoverlapping strata with n s units in stratum s. In selecting the N units and assigning them to strata, use only the x's and possibly a table of random numbers. A stratification formed in this way is called a stratification on x . Renumber the units so the ith unit in stratum s has treatment assignment Zsi and covariate Xsi' Using the same notation as Chapter 2, write Z for the N-tuple (Zu, ... ,ZS,ns )T . Write m.; for the number of treated units in stratum s; that is, m s = Li Zsi, and m = (mi'" , ms)T .
An exact stratification on x has strata that are homogeneous in x, so two units are in the same stratum only if they have the same value of x , that is Xsi = Xsj for all s, i, and j. Exact stratification on x is practical only when x is of low dimension and its coordinates are discrete; otherwise, it will be difficult to locate many units with the same x .
In an exact stratification on x, if the study is free of hidden bias, that is, if (3.2) holds, then all units in the same stratum have the same chance of receiving the treatment. In this case, write As in place of A(Xsi), so (3.2) implies:

II II S n,

prob(Z = z) =

A~"i(l- As)l- zsi .

(3.3)

s=1 i=1

In (3.3), the distribution of treatment assignments, prob(Z = z), is unknown because As is unknown, and m; = Li Zsi is a random variable.
Consider the conditional distribution of Z given m . It is a distribution on
a set n whose elements are N-tuples of as and Is such that zEn if and
only if m s = Li Zsi for s = 1, . . . , S, so n has K = I1;=1 C:;J elements.
Every treatment assignment zEn has the same unconditional probability
in (3.3), namely,

I IS
prob(Z = z) = A';s (1 - Asts-m.·.
s=1

(3.4)

It follows that the conditional probability given m is constant, prob(Z = zjm) = 1/K . Of course, this is the distribution of Z in a uniform randomized experiment; see §2.3.2.
In short, if an observational study is free of hidden bias, and if one stratifies exactly on x, then the conditional distribution of the treatment assignment Z given the numbers m of treated units in each stratum, namely prob(Z = zjm), is the same as the distribution of treatment assignments in a uniform randomized experiment. This is true even though the treatment assignment probabilities A(X) are unknown . In this case, given m, the statistical procedures discussed in Chapter 2 have the properties described

80 3. Overt Bias in Observational Studies
there. In other words , if the study is free of hidden bias and one stratifies exactly on x , then the study may be analyzed using methods for a uniform randomized experiment.
Be clear on a key point. This result does not say that there is no difference between an experiment and an observational study. The difference is that in a uniform randomized experiment, the assignment probabilities
prob(Z = z) are known to equal 1/K because we forced this to be true by randomizing. In an observational study, the conclusion prob(Z = zjm) =
1/K is deduced from the premise that the study is free of hidden bias, a premise we have little reason to believe. In an observational study, this premise is subjected to strict scrutiny, asking whether evidence can support or refute it, asking how findings would change if the premise were in error. This scrutiny is the focus of most later chapters.

3.2.3 Matching on x
In §3.2.2, strata were formed using x alone. One way that matching differs from stratification is that there are constraints on the number m s of treated units and the number n s - m s of control units in a stratum. For instance, pair matching requires ns = 2 and m.; = 1 for each s, while matching with multiple controls requires n s 2: 2 and m; = 1. A matching on x is a matched sample formed by:

(i) placing some restriction on 5 , m and n = (nll . . . ,ns)T , and

(ii) picking a stratification that meets these restrictions based exclusively on the pattern of xs in the strata and possibly a table of random numbers.

For instance, a pair matched sample with 5 = 100 pairs would be formed

by considering all possible stratifications with n s = 2 and m s = 1 for
m s = 1, S = 1, . . . ,100 , and selecting one of these possible stratifications
based on the x 's in the strata and possibly random numbers. An exact

matching on x is a matching on x in which x is the same for all n s units
in each matched set, that is, Xsi = Xsj for i,j = 1, . .. ,ns for each s. As
with exact stratification, exact matching is possible only when x is of low

dimension and discrete.

.

The same argument as in §3.2.2 shows that, in an observational study

that is free of hidden bias, if one matches exactly on x , then the conditional

distribution of the treatment assignment Z given m is the same as in a

uniform randomized experiment, prob(Z = zlm) = 1/K . If the study were

free of hidden bias, it could be analyzed as if it were a matched randomized

experiment, but of course, the comment at the end of §3.2.2 applies here

as well.

3.2 Adjustm en ts by Exact Stratification and Mat chin g 81
3.2.4 An Example: Lead in the Blood of Children
Morton et al. (1982) st udied lead in the blood of children whose parents worked in a factory where lead was used in making batteries. They were concerned that childre n were exposed to lead inad vertently brought home by t heir parents. Their st udy included 33 such childre n from different families-they ar e the exposed or treated children. The outcome R was the level of lead found in a child 's blood in J-Lg/dl of whole blood. The covariate x was two-dimen sional, recording age and neighborhood of residence. They matched each exposed child to one control child of the same age and neighborhood whose parents were employed in other industries not using lead . Table 3.1 show s the levels of lead found in the children's blood in J-Lg / dl of whole blood.
If this study were free of hidden bias , which mayor may not be the case , we would be justified in analyzing Table 3.1 using methods for a uniform randomized experiment with 33 matched pairs. If th e null hypothesis of no treatment effect is t ested using Wilcoxon's signed rank t est , the one-sided significance level is less than 0.0001. The Hodges-Lehmann est imate of the size of an additive effect is 15 J-Lg / dl with 95% confidence int erval (9.5, 20.5). If the study were free of hidden bias , this would st rongly suggest that the parents who worked with lead did raise th e level of lead in their childre n 's blood by about 15 J-Lg/dl , a large increase compared to the level of lead found in controls. In later chapters, these data ar e examined again without the premise that the study is free of hidden bias .
3.2. 5 Stratifying and Matching on the Propensity Score
Often , exact stratification or matching on x is difficult or impossible . If x is of high dimension or cont ains cont inuous measurements, each of the N units may have a different value of x , so no stratum can contain a treated and control unit with the sa me x. There are several qu estions. Do a large number of covariates-that is, a high-dimensional x-make stratification and matching infeasible? Does close but inexact matching on x remove most of the bias due to x? What algorithms produce good stratifications or matchings? The second and third questions are discussed in Chapter 10. The current section begins to answer the first question. As it turns out, there is a sense in which all matching problems are one-dimensional, so the dimensionality of x is not critical by itself.
Suppose an observational st udy is free of hidden bias, so (3.2) holds . Instead of stratifying or matching exactly on x , imagine forming strata or matched sets in which units in the same stratum have the same chance of receiving the treatment -\(x) . Then within a stratum or matched set , units may have different valu es of x , but they have the same propensity score -\(x) . Formally, it may happen that Xsi =I- Xsj but always -\(Xsi ) = .\(xsj). Call this exact matching or stratification on the propensity score. In this

82 3. Over t Bias in Observat ional St ud ies

TABLE 3.1. Lead in Children 's Blood (llg/d1).

Pair Exp osed Cont rol Difference Rank

1

38

16

22

22

2

23

18

5

8

3

41

18

23

23.5

4

18

24

-6

9.5

5

37

19

18

21

6

36

11

25

26

7

23

10

13

14

8

62

15

47

32

9

31

16

15

17

10

34

18

16

18.5

11

24

18

6

9.5

12

14

13

1

2.5

13 21

19

2

4

14

17

10

7

11

15

16

16

0

1

16 20

16

4

7

17

15

24

-9

12.5

18

10

13

-3

5.5

19 45

9

36

30

20

39

14

25

26

21 22

21

1

2.5

22

35

19

16

18.5

23 49

7

42

31

24

48

18

30

28

25 44

19

25

26

26 35

12

23

23.5

27 43

11

32

29

28

39

22

17

20

29 34

25

9

12.5

30 13

16

-3

5.5

31

73

13

60

33

32

25

11

14

15.5

33

27

13

14

15.5

3.3 Case-Referent Studies 83
case , the arguments in §3.2.2 and §3.2.3 go through without changes . In those arguments, equal x's within strata were used only to ensure equal ..\(x)'s. In short, in an observational study free of hidden bias, exact matching or stratification on the propensity score yields a conditional distribution of treatment assignments Z given m that is the same as a uniform random-
ized experiment, namely prob(Z = zlm) = 1/K. In this case, the methods
in Chapter 2 for uniform randomized experiments may be applied. The same conclusion is reached if strata or matched sets are formed based on ">.(x) and parts of x, providing the strata or matched sets are homogeneous in ..\(x).
In practice, ..\(x) is unknown, so matching or stratification on ..\(x) is not possible. The use of estimated propensity scores in matching and stratification is discussed in Chapter 10. Also, §1O.2 discusses balancing properties of the propensity score that are true whether or not the study is free of hidden bias.
3.3 Case-Referent Studies
3.3.1 Selecting Subjects Based on Their Outcomes
In Chapter 1, the study of DES and vaginal cancer is a case-referent study, and such a study has two features that distinguish it from the other observational studies in Chapter 1. First, the binary outcome, namely, vaginal cancer, is extremely rare, so a study that simply followed women until they developed the disease would need an enormous number of women to produce even a handful of cases of this rare cancer. This first feature is the motivation for conducting a case-referent study, but it is the second feature that characterizes such a study. In a case-referent study, cases are deliberately over-represented and referents are under-represented. The DES study identified cases of vaginal cancer and compared them to a small number of matched referents in terms of the frequency of maternal exposure to DES. In other words, subjects are included or excluded from the study, in part, on the basis of their outcomes. Instead of comparing the outcomes of treated and untreated groups, the case-referent study compares the frequency of exposure to the treatment among cases and referents.
At first, it is not clear that this makes sense . If the outcome R = rz is affected by the treatment Z , then selecting subjects using their outcomes may distort the frequency of exposure to the treatment. Indeed, this seems to have happened in the DES study. Of the 40 women in the study, 7 had mothers who had used DES , which exceeds the frequency of exposure to DES in the general population. When the treatment has an effect, it is related to the outcome, so selecting subjects using their outcomes changes the frequency of exposure to the treatment. How can a case-referent study be interpreted?

84 3. Overt Bias in Observational Studies

TABLE 3.2. Data Before Selecting Cases and Referents .

Z

1

o

R 1 Lx Z[j}rT[j]

Lx(1 - Z(j])rc[j]

o Lx Z[j) (1 - rTfjJ) Lx(1- Z[j))(l - rC[j))

TABLE 3.3. Expectations in the Absence of Hidden Bias.

Z

1

o

R 1 >.(x) Lx rT[j]

{I - >.(x)} Lx rC(j]

o >.(x) Lx(1- rTfjJ) {I - >.(x)} Lx(l - rC[j])

3.3.2 Synthetic Case-Referent Studies
A synthetic case-referent study starts with the population of M subjects in §3.2.1, and draws a random sample of cases and a separate random sample of referents, possibly after stratification using the observed covariates x . Synthetic case-referent studies are typically conducted when there is a computerized database describing the entire population of M subjects, but the study requires the costly collection of additional data not in the database. See Silber et al. (2001) for an example in which the population is comprised of all Medicare patients in Pennsylvania. This sort of study does occur, but far more common are case-referent studies that do not use random sampling. Synthetic case-referent studies are easier to consider theoretically because the mechanism that selects subjects has known properties. The term "synthetic" was introduced by Mantel (1973), while the odds ratio property discussed in this section is due to Cornfield (1951).
Consider the data before cases and referents are sampled, as in §3.2.1, so the jth of the M subjects has observed covariate x(j], treatment assignment Z(j], and observed binary response R[j}, which equals rT(jJ if j is given the treatment and TC[j] if j is given the control. Divide the M subjects in the population into strata based on x, and abbreviate by Lx a sum over all
subjects j with X[j] = x ; that is, write Lx for Lj:xIiJ=x' The subjects in the
stratum with covariate value x are recorded in the contingency Table 3.2.
If there is no hidden bias, then E(Z(j}) = >'(X[j]), so the entries in Ta-
ble 3.2 have as expectations the values in Table 3.3. The odds ratio or cross-product ratio in Table 3.3 is

(>'(X) Lx rT[j]) ({1- >.(x)) Lx(l - rC[jj)) (>'(x) Lx (1 - rT[j])) ({ 1 - >.(x)) Lx TC[j})

(Lx rT[j]) (Lx(l- rC(j}))
(Lx(l - rT(j}}) (Lx rC[j]) ' (3.5)

3.3 Case-Referent Studies 85

TABLE 3.4 . Expected Counts in a Synthetic Case-Referent Study Absent Hidden Bias.

Z

1

o

Lx R 1 k1xA(X)

rT[jJ

Lx k 1x {1 - A(X)} rC[j]

o koxA(X) Lx(l - rTfjJ) kox {1 - A(X)} Lx(l - rerjJ)

and this odds ratio is a measure of the magnitude of a treatment effect. Notice that the odds ratio is one if there is no treatment effect in the stratum defined by x, that is if rT[jJ = rC[jJ for all [j] with x[j] = x, and the odds ratio is greater than one if the treatment has a positive effect in
the stratum defined by x, that is if rT[jJ ~ rC[j] for all j with x[j] = x and rT[j] f. rC[j] for some j with X[j] = x. Hamilton (1979) discusses a wide
variety of related measures under the model of a positive effect. Tables 3.2 and 3.3 describe the initial population of M subjects. Consider
a synthetic case-referent study formed from Table 3.2. Draw a random sample without replacement consisting of a fraction k1x of the cases, the
:s :s first row of the table, and a random sample consisting of a fraction kox
from the referents, the second row, with 0 < k1x 1 and 0 < kox
1. The resulting table of counts for the synthetic case-referent study has
expectations shown in Table 3.4.
The key observation is that the odds ratio computed from Table 3.4
equals the odds ratio (3.5) before case-referent sampling. In other words,
in the absence of hidden bias, the data from a synthetic case-referent study provide a direct estimate of the population odds ratio (3.5) at each x .
As in §3.2, when attention shifts from the population of M subjects to
the N < M subjects included in the case-referent study, the notation in
§3.2.3 is used; that is, the ith subject in the sth stratum defined by x has unbracketed subscript s, i. As in §3.2, let m s = Li Zsi be the number of treated or exposed subjects in stratum s of the case-referent study. If the study were free of hidden bias, so (3.2) holds, and if the treatment
had no effect, so rTsi = rc« for each s , i , then after synthetic case-referent sampling, the conditional distribution of the treatment assignments Z given
ill is uniform on n. This means, for instance, that the Mantel-Haenszel
statistic may be used to test the null hypothesis of no effect in a synthetic
case-referent study that is free of hidden bias.

3.3.3 Selection Bias in Case-Referent Studies
Unlike the synthetic study in §3.3.2, most case-referent studies do not use random sampling. It is common to use all cases that are made available by some process, for instance, all new cases admitted to one or more hospitals

86 3. Overt Bias in Observational Studies
in a given time interval, together with referents selected by an ostensibly similar process, for instance, patients with some other illness admitted to the same hospitals at the same time, or neighbors or coworkers of the cases .
Nonrandom selections of cases and referents may distort the odds ratio in (3.5) . For instance, if cases of lung cancer at a hospital were compared to referents who were selected as patients with cardiac disease in the same hospital, the odds ratio linking lung cancer with cigarette smoking would be too small, because smoking causes both lung cancer and cardiac disease. In this case, there is a selection bias, that is, a bias that was not the result of the manner in which subjects were assigned to treatment in the population, but rather a bias introduced by the nonrandom process of selecting cases and refer ent s. Select ion bias is discussed further in Chapter 8.

3.4 *Small Sample Inference with an Unknown Propensity Score
3.4.1 *Conditional Inference Under a Logit Model for the Propensity Score
In §3.2, in the absence of hidden bias, the distribution of treatment assignments prob(Z = z) in (3.2) was unknown because the propensity score
A = (A}, .. . , AS)T was unknown. However, by conditioning on the num-
ber of treated subjects in each stratum m, the conditional distribution of treatment assignments, prob(Z = zjm), was known, and , in fact , was the distribution of treatment assignments in a uniform randomized experiment. Notice that the unknown parameter A was eliminated by conditioning on a sufficient statistic m. This line of reasoning generalizes.
Suppose that A satisfies a logit model,

(3.6)

where {3 is an unknown parameter. Write

s

m= Lmsxs ,

(3.7)

s=1

so m is the sum of the x, weighted by the number of treated subjects ni; in stratum s. Under the model (3.6), rn is sufficient for {3, so prob(Z = zlrn) is a known distribution, free of the unknown parameter {3. See Cox (1970) for a detailed discussion of logit models, including a discussion of the sufficiency of rn.

3.4 *Small Sample Inference with an Unknown Propensity Score 87

Let 0 be the set containing all treatment assignm ents z that give rise
to the same value of rn , that is,

S

n,

}

0= z:zsiE{O,l} , i=l , . .. ,ns,s=l , . . . , S, m=LxsL z8i .

{

8= 1 i=1

Notice that 0 is a larger set than n, in the sense that n ~ 0, so 0 contains at least as many treatment assignments z as n. This is true because every
zEn gives rise to the same m, and hence also to the same rn .
Under the logit mod el (3.6), the conditional distribution of treatment
assignments given rn is constant on 0,

prob(Z

=

zjrn)

=

1
10\

for each z E O.

(3.8)

As a result , in the absence of hidden bias, under the model (3.6), the known
distribution (3.8) forms the basis for a permutation test; in particular, a
test statistic T = t(Z , r) has significance level

prob{t(Z,r) ~ Tim} = I{z EO : ~~,r) ~ T}I ,

(3.9)

for testing the null hypothesis of no treatment effect. The significance level
(3.9) is the proportion of treatment assignm ents z in 0 giving a value of
the test statistic t(z, r) at least equal to the observed value of T .
The procedure just described is useful in small samples when the strata
are so thin that the set n is too small to be useful. For inst ance, if n contains
fewer than 20 treatment assignments, then no pattern of responses can be
significant at the 0.05 level using (2.5). Such a small n arises when the
sample size N is small and this small sample size is thinly spread over many
strata; for instance, strata with m 8 = 0 or ms = ns contribute nothing to
(2.5). If n is too small to permit reasonable permutation inferences , the
larger set 0 may be used instead. The size 101 of 0 depends on how the covariates x are coded, and finding an 0 of appropriate size may sometimes
be accomplished by adjusting the coding of the covariates. An example of
the method is given in the next section.
Exact stratification and matching in §3.2 are useful only if there are many st rat a or matched sets that contain at least ns ~ 2 subjects with at least one treated subject and one control. In contrast, the method in the current section may be used when n8 = 1 for every s, so each unit may have a distinct x.
The method of this section is a generalization of the method in §3.2.
Suppose that x simply contains indicators coding the S strata. For in-
stance, in one such coding, x has S - 1 binary coordinates, with coordinate
oX 8 i j = 1 if j = sand X 8 i j = 0 if j =I- s , for j = 1, . .. , S - 1. In this case,
= n, and (3.9) equals (2.5).

88 3. Overt Bias in Observational Studies

TABLE 3.5. Fourteen Lung Cancer Pati ents from a Phase II Trial of Pacco.

Tumor Treat-

Resp onse m ent

Previous

ID

r si

z: Cell Type Treatment

P erforma nc e St atus s

1

0

2

0

3

0

4

0

5

0

6

1

7

0

8

0

9

1

10

0

11

0

12

0

13

0

14

2

0 Squamous None

0

1

0 Large cell None

1

2

0 Squamous Radiation

1

3

0 Squamous Radi ation

1

3

0 Squamous Radiation

2

4

1 Squamous Radi ation

1

3

1 Squamous Radi ation

1

3

1 Adeno.

Radi ation

1

5

1 Squamous None

1

6

1 Large cell None

2

7

1 Squamous Radi ation and

2

8

chemotherapy

1 Squamous Chemotherapy

1

9

1 Squamous None

0

1

1 Squamous None

1

6

3.4.2 *An Example: A Small Observational Study Embedded in a Clinical Trial
Table 3.5 describes 14 patients t aken from a clinical trial of the drug treatment combination PACCO in the treatment of nonsmall cell bronchogenic carcinoma (Whitehead, Rosenbaum, and Carbone 1984, Rosenbaum 1984b, §3). This ph ase II trial contained two minor variations of what was intended to be the same treatment; however, when the responses were tabulated, all of the patients who responded to therapy had received the same vari ation of the treatment. The question is whether this is evidence that the treatments differ, given the characterist ics of the patients involved . As pr esented here , the example is adapt ed to illustrate the method.
The outcome is tumor response, where 0 signifies no response, 1 signifies a partial response, and 2 signifies a complete response. The covariate information describes the cell type, previous treatment, and performance status. In x ; previous treatment was coded as three binary variables, cell type as two binary variables, and performance stat us was taken as a single variable with three scored categories, so x, has dimension six.
Table 3.6 describes the strata based on the covariat es. The 14 patients are divided into nine strata, with most st rata cont aining a single patient.
The set n has 2 x 1 x 6 x 1 x 1 x 1 x 1 x 1 x 1 = 12 treatment assignments, so
no matter what responses are observed, the smallest possibl e significance

3.4 *Small Sample Inference with an Unknown Propensity Score 89

TABLE 3.6. Strata for the PACCO Trial.

Previous s Cell Type Treatment

Perform-

ance Status

ns

ms

(n.)
m,

1 Squamous None

0

21 2

2 Large cell None

1

10 1

3 Squamous Radiation

1

42 6

4 Squamous Radiation

2

10 1

5 Adeno.

Radiation

1

11 1

6 Squamous None

1

22 1

7 Large cell None

2

11 1

8 Squamous Radiation and

2

11 1

chemotherapy

9 Squamous Chemotherapy

1

11 1

level is 1/12 = 0.083. The set n is too small to be useful for a permutation
test.
The set n is somewhat larger, containing 28 treatment assignments.
These are all the treatment assignments that give rise to the observed value of m, This means that a treatment assignment z must have the correct number of treated patients with each cell type, each previous treatment, and the correct average performance status. It contains all treatment assignments z such that:
(i) nine patients receive treatment one, and of those nine :
(ii) one has adenocarcinoma;
(iii) one has large cell carcinoma;
(iv) seven have squamous cell carcinoma;
(v) three have had only previous radiation therapy;
(vi) one has had only previous chemotherapy;
(vii) one has had both previous chemotherapy and previous radiation therapy; and
(viii) the average performance status is 10/9 = 1.1.
In other words, these 28 treatment assignments resemble the observed treatment assignment in the sense that similar patients received the treatment. The test statistic is the total of the response scores for treated pa-
tients, T = t(Z, r) = ZTr = 2 + 1+ 1 = 4. Of the 28 treatment assignments
n, z in 8 have zT r = 4, 13 have zT r = 3, 4 have zT r = 2, and 3 have
zT r = 1. Therefore, under the null hypothesis, the distribution (3.9) of

90 3. Overt Bias in Observational Studies
ZTr assigns probability 8/28 = 0.29 to 4,13/28 = 0.46 to 3, 4/ 28 = 0.14
to 2, and 3/28 = 0.11 to 1. In other word s, it is not sur prising to find that all the responses occurred in treatment group one-this would happen by chance 29% of the tim e if t he treatments did not differ in t heir effect s.
n Algorithms for computations involving ar e discussed in Rosenbaum
(1984b) .

3.5 *Large Sample Inference with an Unknown Propensity Score
3.5.1 *Covariance Adjustm ent of Randomization Tests
This sect ion describes a method of covar iat e adjustment for randomization tests. The method is simple to describe and to apply, and motivation follows the description. It turns out that the method is a large sample approximat ion to the exact test in §3.4.
As in §3.4, suppose a logit mod el accur at ely describes the propensity score,

(3 .10)

and suppose the study is free of hidden bias, so that prob(Zsi = 1) = 7rsi =
A (x s) = As. As in §3.4.1, each st ratum may consist of a single unit , n s = 1,
so t ha t each unit may have a distinct value of x .
Under the null hypothesis of no treatment effect, H o : rr« = rc« = T si
for all s, i, the observed responses R equal a fixed vecto r r not varying
with Z. As in Ch apter 2 and §3.2, when the null hypothesis of no effect
is true, th e fixed R = r is observed 11U matter what Z is, so T si do es not
predict Z si at each X s' On t he ot her hand, if the null hyp othesis were
false and instead rr« > rc « for each s, i , then the observed response,
Rsi = + Z siTTsi (1 - Z si)Tc si would be positively related to Z si at each
x s. So the task is to check for a relationship between treatment Z si and observed response Rsi given x, , exp loit ing the assumed form (3.10) .
Let q (R) be some way of scoring the observed resp onses, such as their
ranks, so that under the null hypothesis of no treatment effect, q (R)
q (r ) = q , say, is fixed. Consider the model:

log

{

prob (Zsi p r o b ( Zsi

=
=

1) 0)

}

T
= f3 x ;

+

()q s i '

(3.11 )

By what has been said, und er th e null hypothesis of no treatment effect,
in the absence of hidden bias , assuming model (3.10), it follows that () = 0
in (3.11).

3.5 *Large Sample Inference with an Unknown Propensity Score 91
° There are several ways to test Ho : B = in (3.11). There is an exact,
uniformly most powerful unbiased test of Ho : B = 0 versus HA : B > 0; see
Cox (1970, §4.2) . As it turns out, this test is precisely the test in §3.4 with significance level (3.9) providing t (Z, r) = ZT q ; see Rosenbaum (1984b, §4.2). In other words, so far, this section has not yielded a new procedure, but rather a new motivation for the procedure in §3.4. The most powerful
n unbiased test is not always practical, however. For instance, may be too
large or too small to permit practical use of (3.9).
° When N is large compared to the dimension of x, it is more common to
test a hypothesis about a coefficient in a logit model, such as Ho : B = in (3.11), using one of several large sample tests associated with maximum likelihood estimation of the model. These tests may also be applied here.
Suppose, again, that the study is free of hidden bias and (3.10) describes the propensity score, but instead of the null hypothesis of no effect, consider
the model of an additive treatment effect, Ho : rr« = rCsi + T . In this case, the observed response R si = rc« +TZsi will be related to Z si at each
x,; positively related for T > 0, and negatively related for T < O. Consider testing the hypothesis H o : T = TO. The procedure is analogous to that in §2.6.1. Specifically, calculate the adjusted responses, r = R - TOZ, which
are fixed when the null hypothesis is true, and apply the method above with
q = q (r) = q (R - TOZ), A confidence int erval for T is found by inverting
the test.
3.5.2 *Example: Benzene Exposure Among Shoe Workers
Tunca and Egeli (1996) studied the effects of benzene exposure among shoe
workers. The 58 = I: m s shoe workers, Z = 1, in Bursa, Turkey were exposed to benzene from glues . They were compared to 20 = I: ns - ms
controls, Z = 0, from the same region who were not exposed to benzene. The outcome, R, is one measure of chromosome damage, namely, the percentage of cells with breaks. Adjustment is made for a three-dimensional covariate, x , giving age, alcohol intake (+ or -) , and smoking in packs per
day. Table 3.7 gives the data for 6 of the 78 = 58 + 20 subjects, with data
for all subjects given in Tunca and Egeli (1996). Casual examination of means shows the shoe workers have many more breaks than the controls, but they are also older (37.2 years versus 28.5 years) , smoke more (0.8 packs per day versus .2 packs per day), and are more likely to drink alcohol (40% versus 5%).
To test the null hypothesis of no treatment effect, the model (3.11) was fit , predicting treatment Z from the three covariates and the ranks of the percentage of breaks R. When a logit model is fitted to independent binary trials by maximum likelihood, a common test of the hypothesis that a coefficient is zero uses the ratio of the coefficient to its approximate standard error, and compares that ratio to the standard Normal distribution. For age, alcohol, smoking, and the ranks of the percentages of breaks , these

92 3. Overt Bias in Ob servational Studies

TABLE 3.7. Chromosome Break s Among Shoe Worker s and Co nt rols.

Tr eatment Z Breaks R Age Alcohol Smoking

a

0.00

24

a

o

0.00

~1

a

a

5.00

23

0.1

1

11.11 26

1.0

1

0.00

50

+

1.5

1

9.09

40

a

ratios are, respectively, 2.96, 1.72, 1.59, and 2.18. Because 2.18 ~ 1.65,
and 1 - cI>(1.65) = 0.05, where cI>(.) is the standard Normal cumulat ive
distribution, the hypothesis H o : () = a may be rejected at the 0.05 level
in a one-sided test. This is an appropriate large sa mple test of the null
hypothesis of no treatment effect assuming the study is free of hidden bias
and (3.10) accurately describes the propensity scor e.
The model of an additive treatment effect , Ho : rr« = rc a + T , is
not useful-indeed, it is misleading-in this example. Many of the shoe
workers and nearly all of the controls had R = 0.00 breaks , even though
many other shoe workers had subst ant ial numbers of breaks. As just not ed ,
the hypothesis Ho : T = a was rejected at the 0.05 level. However, the
hypothesis Ho : T = T O is not rej ected in a one-sided 0.05 level test for
every TO > 0, no matter how small TO is. The reason is that if a positive
quantity is subtracted from the many R = 0.00 values among shoe workers,
these values become strictly smaller than all cont rol responses. A better
model for the treatment effect in data of this sort is dis cussed in §5.6.

3.6 *Inexact Matching Followed by Stratification
3.6.1 *An Example: Vasectomy and Myocardial Infarction
Walker et al. (1981) studied the possible effect of vasectomy on increased risk of myocardial infarction (MI) , a possibility suggested by animal studies where increased risks were observed. The study contained 4830 pairs of men, one vasectomized and one control, matched for year of birth and calendar time of follow-up. The data were not matched for two other variables, obesity and smoking history recorded as binary traits, both of which are believed to be related to the risk of MI. This section describes a method for controlling covariates that were not controlled by the matching.

3.6 *Inexact Matching Followed by Stratification 93
The outcome is a binary variable indicating whether an MI occurred during the follow-up period; however, the method discussed here may be used with outcomes of any kind. McNemar's test statistic is used; see §2.4.3 for discussion of this test. In most of the 4830 pairs, no MI occurred. Pairs containing no MI or two MIs are said to be concordant, and it is not difficult to verify that these pairs do not contribute to McNemar's test. There were 36 discordant pairs, that is, pairs in which one person had an MI and the other did not-only these affect the test. Walker's (1982) data for these 36 pairs of men are given in Table 3.8. The score qsi is 1 if the ith man in pair s had an MI and is 0 otherwise.
In each pair, there are two possibilities. A pair may be exactly matched for obesity and smoking, so the two matched men are the same on these variables, or else the men may differ. If they differ, then there are six ways they may differ; that is, there are six patterns of imbalance in the covariates. For instance, one possible imbalance occurs if one man in a pair is a nonsmoker who is not obese and the other is a smoker who is not obese; this is (as , oS) in Table 3.8. Notice that , in counting the patterns of imbalance in covariates, we consider only the covariates and not vasectomy or MI. The 36 pairs are grouped into seven classes, one class that is perfectly matched and six classes for the six patterns of imbalance.
3.6.2 *Adjusting Inexactly Matched Pairs by Stratifying Pairs
Suppose that an observational study is free of hidden bias, so (3.2) holds, and pairs of treated and control units are matched inexactly for x, so Xsl may not equal X s2 . How does one control imbalances in x that remain after matching? The method described in this section is useful when matching has failed to control a few coordinates of x containing discrete variables, as in §3.6.1. It involves grouping the matched pairs into classes so that the pairs in the same class have the same pattern of covariate imbalance.
Using (3.2) , for any two distinct units j and k, prob(Z[jJ = 1, Z[k] = 0) = A (x[j]) {1 - A (X[k])} and prob(Z[j] = 0, Z[k] = 1) = A (X[k]) {1 - A (X[j])}. Pair matching selects units so that m s = Zsl + Zs2 = 1 for each s. There-
fore, conditionally given that a pair contains exactly one treated unit, the chance that the first unit is the treated unit is
In many applications, some coordinates of x are matched and others are not. In the vasectomy and MI example, men were matched for year of birth and calendar time of follow-up, but not for smoking and obesity. In this situation, it seems natural to let the matching control the matched coordinates of x and to make additional adjustments only for the unmatched

94 ::I. Overt Bias in Observational Studies

TABLE 3.8. Vasectomy and Myocardial Infar ction

Class c

Covariate im bala nce
(XsI ' Xs 2)

W a l k e r 's

z. , q sl qs2

id#, s

0 No imbal ance 1 0 0

4

10 1

8

10 1

10

01 1

11

10 0

12

10 I

16

01 0

17

01 0

23

10 0

26

01 0

27

10 1

30

01 0

35

10 1

36

1 (os, 08)

01 0

3

10 1

6

01 1

9

01 1

14

01 0

15

01 1

20

01 1

21

10 0

22

01 0

24

01 1

29

01 0

32

2 (os, Os)

01 1

1

01 0

28

10 0

33

3 (08,08)

01 0

19

010

25

4 (08, Os)

01 0

2

01 0

7

10 0

34

5 (08, 08)

010

13

10 0

18

01 1

31

6 (Os,08)

01 1

5

Key: 0 = obese , 0 = not obese, S = smoker, S = nonsmoker.

3.6 *Inexact Matching Followed by Stratification 95

coordinates of x . Write x = (x, x) where subjects are matched for x but
not for X. Then Xsl = Xs2 for every s, but Xsl =f Xs2 for at least some s. Ideally, matched pairs could be grouped into classes based on the im-
balances in the unmatched coordinates, Xsl and XS 2' ignoring the matched
coordinates, Xsl = Xs2 , as was done in Table 3.12 where pairs are grouped
based on obesity and smoking, ignoring year of birth and calendar time
of follow-up . As intuition might suggest, we can control imbalances in x by matching on x, then separately control the remaining imbalances in x
by classifying the pairs, only if x and x do not interact with each other in
determining A (x). Specifically, consider the following additive logit model
for the treatment assignment probabilities, A(x) :

A(x) = exp {~(x) + «(x)} 1 + exp {~(x) + «(xn

(3.13)

for some unknown functions ~ (.) and «( .). Because Xsl = Xs2 , it follows that ~ (Xsl) = ~ (Xs2), so that , substituting (3.13) into (3.12) and simplify-
ing yields:

prob(Zsl

=

11 Zsl + Z s2

=

1) =

exp {«(xst)}
exp {(Cx,1)} + exp {(CX s2)}'

(3.14)

which depends only on the unmatched coordinates, x, not on the matched
coordinates, X. This sort of simplification is often possible with logit mod-
els; see Cox (1970). In other words, under model (3.13), matching on x has removed all of the bias due to x , and only the bias due to x remains. When
model (3.13) holds, covariate imbalance refers to x only, so the 11 pairs
in Table 3.8 with a nonobese nonsmoker matched to a nonobese smoker ,
(as , oS) , all have the same pattern of covariate imbalance, and all 11 pairs may be placed in the same class for adjustments. When model (3.13)
does not hold , the method of this section may still be applied , but many
more classes are needed. This is because pairs with different values of the
matched covariates, x, must be placed in different classes, so the 11 pairs
in Table 3.8 with a nonobese nonsmoker matched to a nonobese smoker,
(as, oS), would have to be divided up into different classes based on year of birth and calendar time of follow-up. The discussion that follows applies
to both cases , that is, whether or not model (3.13) holds; however, the definition of covariate imbalance and the classes that control it do depend
on whether model (3.13) holds . Specifically, when model (3.13) holds, a pattern of covariate imbalance refers to unmatched coordinates (xsl, Xs2) only, but when this model does not hold , a pattern of covariate imbalance
refers to all coordinates (x» . Xs2) whether matched or not.
Divide the S pairs into C + 1 classes, where class 0 contains the exactly
matched pairs with X s1 = X s2, and the other C classes contain the C
patterns of imbalance in x. Let Ie be the set of pairs exhibiting imbalance c, so that 10 u 11 U . . . u lc = {I , . .. , S} . In class c = 0, there is an

96 3. O vert Bias in Observati on al Stud ies

:s :s exact match; that is, X sl = X s2 for s E lo. In the other classes, there is an
imbalance, Xsl i Xs2 for s E lc for 1 c C. Write ric for the number of
pairs in lc. Renumber th e two units in each pair so th a t. every pair s in class r. has
the same value of Xsl , and every pair in class c has t he sa me valu e of Xs2 ,
as in Table 3.8. This not ational change simplifies t he appe ar ance of various
quantities but it do es not cha nge their values.
With this not ation, (3.12) takes the sa me value for all pairs in the same
class . Write Pc for the common valu e of (3.12) or (3.14) in clas s c; t hat is,
prob(Zsl = l 1Zs1 + Zs2 = 1) = Pc for all s E lc. Notice that Po = ~, but
th e other Pc are unknown since A(X) is unknown .
For c = 1, . .. , C, write mc for t he number of pairs in class s in wh ich
the treated unit is the first unit,

and write

m=

ml [ me

]

Then mc , like ms , is a random var iable, since it dep ends on t he Z 's. Note
th e distinction between m and m , both of which are used below. W it h t his
not ation, t he distribution of treatment assignment s within pairs is

II II e
pr(Z = zlm ) =

p~'l {I - PcY·2,

c= Os El c

(3. 15)

Unlike the distribution of treatment assignments in §3.2.3 for exact match-

ing, the distribution (3.15) for inexact matc hing involves unknown param-

eters, the Pc, reflecting the rem aining imb alances in x.

Consider the condit iona l distribution of the treatment ass ignments Z

given bot h m and rn. As will now be seen, cond it ioning on both m and m

n zEn yields a known distribution free of the unknown Pc. It is a distribution on

a set 5; n, where

if and only if:

(i) z is a treatment assignment for S matched pairs; that is, Zs l + Zs2 =
m s = lor, equivalent ly, zEn; and

(ii) z exhibits t he same degree of imbalan ce as the observed data; t hat is,
mc = L SEl c Zsl for c = 1, . . . , C .
n The set has

3.6 *Inexact Matching Followed by Stratification 97

elements, and pr(Z = zlm, m) = 1/ic for each z E O. In class c = 0 no containing pairs, all 2iio possible assignments are equally likely. In class n c ;::: 1 containing e pairs, the assignments give the treatment to the first unit in exactly me pairs, and there are (~:) such assignments.
Using the known distribution pr(Z = zjm, rn), significance levels are
obtained in a manner similar to that in §2.4.1. Under the null hypothesis
of no treatment effect, the statistic T = t(Z , r) has significance level

tc ' prob

{t

(

Z,r);:::

TI

m

,

n] m

=

l{zEO

:t(z,r);:::T}1

(3.16)

which parallels (2.5) and is simply the proportion of treatment assignments
in 0 giving values of the test statistic at least as large as the observed value .
If the test statistic is a sum statistic in the sense of §2.4.4, that is, if t(Z, r) = ZT q, where q is a function of r, then the null expectation and variance of the test statistic are given in the following proposition. The
proposition assumes the study is free of hidden bias in the sense that (3.2)
holds, and it concerns the conditional expectation and variance of a sum statistic given m, rn, that is, the expectation and variance of t(Z ,r) = ZTq over the distribution (3.16).

Proposition 11 If the study is free of hidden bias, then the null expectation and variance of ZT q are

E(ZTqlm,m)
var(ZTql mm) =

+ + + 'L"..".J' qsl 2 qs2

c

L'"..".J'

_
m

_
eILel

(_n e -

_)_
me ILe2

sElo

e= l

L L + ( qsl ~ qs2 ) 2

C

m

e

(-
n

e

-:

-) me

-
a

2 e

,

sElo

e= l

ne

(3.17)

where

for i = 1,2

and

L a~ = n ~ 1 {(qsl - qd - (Pel - pd}2 .

e

s Elc

Proof. The proof makes use of several elementary observations. First,
the conditional distribution of Z given m, m is uniform on 0, and as a
result , the Zs;'s in different classes are independent of each other. Second,
write ZT q as

c

C

L L L L ZTq =

+ Z sl(qsl - qs2)

qs2,

e= O sElc

e= O sEl c

(3.18)

98 3. Overt Bias in Ob servational Studies
where th e second slim on the right is a const ant since it do es not involve Z. In class c = 0, the Zsl 'S ar e independent of each other given m , rn , and each Z sl equals 1 or 0 with probability 1/2. For c ~ 1, the sum
L .'Elr. Z sl(qsl - qs2) in (3.18) is the sum of me of the (qsl - qd 's rann domly selected without replacement from among the c pairs 8 E lc. The
proposition then follows directly from st andard facts about simple random sampling without repla cement . ·
3.6.3 *Return to the Example of Vasectomy and Myocardial Infarction
The 36 pairs in Table 3.8 are divided into seven classes, numbered 0, 1, .. . ,6, based on the pattern of imbalance in two unmatched covariates, obe sity and smoking. In class 0, the two men ar e exactly matched for ob esity and smok-
ing. There are no= 13 exactly matched pairs in class O. In class 1, labeled
(08,oS) , each pair contains two men who are not ob ese, of whom exactly
one is a smoker, and there are nl = 11 pairs with this imbalance, and so
on . P air 8 = 3 is the first pair in clas s c = 1, lab eled (08 , oS) , and in this pair, the second man is a nonob ese smoker, oS, who had an MI , q32 = 1,
and a vasectomy, Z 32 = 1 = 1 - Z31.
McNemar's statistic is the number of vasectomized men who had an MI, namely, L s L i Z siqsi = 20 of a possible 36. Proposition 11 gives the moments of the statistic adjusting for obesity and smoking in addit ion to the variables used to form matched pairs. Table 3.9 gives a few intermediate calculations. Using these in (3.17) gives an expect a t ion of 19.015 and a variance of 6.813 for the McNemar statistic under the null hypothesis of no treatment effect. In words , the number of vasectomized men who had an MI, namely, 20, is quite close to the expectation 19.015 in the absence of a treatment effect. The standardized deviate with cont inuity correction is (20 - 19.015 - ~)/J6.813 = 0.186 , and this is small when compared with the standard normal distribution, so there is no indication of an effect of vasectomy on the risk of MI. This would be a correct test if the study were free of hidden bias once adjustments had been made for the two matched and the two unmatched covariates.
Had smoking and obesity been ignored, the usual expectation for McNemar's stat ist ic would have been 36/2 = 18 vasectomized MIs rather than 19.015, so the adjustment for smoking and ob esity moved the expect ed count closer to the observed 20. In other words, if vasect omy had no effect on the risk of MI, we would non etheless have expected more than half of the vasectomized men to exhibit MIs , because both vasectomy and MI are related to smoking and obesity in the data shown in Table 3.9.

3.7 Bibliographic Notes 99

TA BLE 3.9. Intermediat e Calculations for Vasectomy and Myocardial Infarct ion.

C lie m e Mel

Me2

-2
CT e

0 13 6

1 11 6 0.182 0.818 0.655

2 3 1 0.333 0.667 1.333

3 2 0 0.000 1.000 0.000

4 3 0 0.333 0.667 1.333

5 3 1 0.333 0.667 1.333

6 1 1 0.000 1.000 0.000

3.7 Bibliographic Notes
Dir ect adjust ment is surveyed by Bishop, Fienb erg, and Holland (1975, §4.3), Cochran and Rubin (1973) , Fleiss (1981, §14), Kitagawa (1964), and Mosteller and Tukey (1977, §11). The analysis of matched pairs and matched sets is sur veyed by Breslow and Day (1980, §5), Cochran and Rubin (1973) , Flei ss (1981, §8), Gastwirth (1988, §11), and Kleinbaum, Kupper , and Morgenstern (1982, §18). St atisti cal procedures that may be derived from an assumption of random assignment of treatment s within strata have long been applied to observatio nal studies; see, for instance, t he influential paper by Mantel and Haenszel (1959). Cochran (1965, §3.2) viewed matching, subclass ificat ion, and mod el-based adjust ments as different ways of doing the same thing. In an important pap er , Rubin (1977) demonstrated that if treatments are randomly assigned on the basis of a covariate, then adjustments for the covariate produce appropriate estimates of a treatment effect. Rubin (1978) develops related ideas from a Bayesian view. Rosenbaum (1984b , 1987a) obtains known permutation distributions by conditioning on a sufficient st atistic for unknown assignment probabiliti es, as in §3.2.
The propensity score is proposed in Rosenbaum and Rubin (1983), and its link in §3.2.5 to permutation inference is discussed by Rosenbaum (1984b). Joffe and Rosenbaum (1999) survey and ext end propensit y score methods, discussing in particular propensity scores for doses of treatment and propensity scores in case-cohort studies; see also Imb ens (2000).
Cole (1979, p. 16) says the first true case-referent st udy was conducted in 1926. Cornfield (1951) showed that case-referent sampling did not alter the odds ratio. He also argued that if the disease is rare , as it is in most casereferent studies, then the odds ratio approximates another measure, the relative risk. See also Gr eenhouse (1982). Mantel's (1973) pap er is a careful discussion of case-referent st udies; see also Hamilton (1979) , Rosenbaum (1987b ), and Holland and Rubin (1988). Further references concern ing casereferent studies are given in Ch apter 7.

100 3. Overt Bi as in Observation al Studies
Condit ional test s given a sufficient stat ist ic for th e prop ensity score in §3.4 ar e discussed in Rosenb aum (1984b) , along with the large sa mple approximation in §3.5; see also Robins, Mark, and Newey (1992) and Robins and Ritov (1997). In exact. m atching followed hy stratificati on in §3.6 is discussed in Rosenbaum (1988); however , that paper mistakenly do es not mention the need for assumpt ion (3.13) in the presented a nalysis of Walker's data, where the classes were based only on the unmatched covariates.
3.8 Problems
1. Problems 1 and 2 consider a test statistic motivated by linear regression, but instead of referring the stat ist ic to a theoretical distribution, these problems consider its permutation distribution. Write X for the matrix with N rows, numbered (s , i ), s = 1, . . . , S , i = 1, . .. , ns where row (s , i) is xI. Assume that X has mor e rows than columns and has rank equal to the number of columns. Consider the linear re-
gression model R = XO + ZT + e, where e is a vector of unobserved
errors, but do not assume the model is correct. The least squares estimate of T under thi s model is
RT (I - H )Z t(Z,R) = ZT(I _ H)Z '
In a uniform randomized experiment (or in an observational study free of hidden bias) , consider the permutation distribution (2.5) of this t(Z , R) under the null hypothesis of no treatment effect . Show that the significance level (2.5) for the covariance adjust ed est imat e t (Z, R) equals the significance level (2.5) for the total response in the treated group, ZTr , which in turn equals the significa nce level for the difference in sa mple means (2.5). (Hint : How do es X T z vary as z ranges over D?)
2. Continuing Problem 1, show that the same conclusion holds if the significance level is based on (3.9) rather than (2.5) . That is, show that the significance level (3.9) with t(Z, R) given by the covariate adjusted estimate (3.19) equals the signific ance level (3.9) with t(Z , R) given by ZTr . (Hint: How does X Tz vary as z ranges over n?) (Rosenbaum 1984b, §2.5)
3.9 References
Becker , H. S. (1996) The epistemology of qualitative research. In: Ethnography and Human Developm ent, R. Jessor, A. Colby, and R. Shweder, eds ., Chicago: University of Chicago Press, pp . 53-72.

3.9 References 101
Bishop, Y., Fienberg, S., and Holland, P. (1975) Discrete Multivariate Analysis. Cambridge, MA: MIT Press.
Blumer, H. (1969) The methodological position of symbolic interactionism. In: H. Blumer, Symbolic Interactionism: Perspective and Method . Berkeley: University of California Press .
Breslow, N. and Day, N. (1980) The Analysis of Case-Control Studies. Volume I of Statistical Methods in Cancer Research. Lyon, France: International Agency for Research on Cancer of the World Health Organization.
Canner, P. (1984) How much data should be collected in a clinical trial? Statistics in Medicine, 3, 423-432 .
Canner, P. (1991) Covariate adjustment of treatment effects in clinical trials. Controlled Clinical Trials, 12 , 359-366 .
Cochran, W . G. (1957) The analysis of covariance. Biometrics, 13, 261281.
Cochran, W . G. (1965) The planning of observational studies of human populations (with Discussion). Journal of the Royal Statistical Society, Series A , 128, 134-155.
Cochran, W . G. (1968) The effectiveness of adjustment by subclassification in removing bias in observational studies. Biometrics, 24, 205213.
Cochran, W . G. and Rubin, D . B. (1973) Controlling bias in observational studies: A review . Sankya, Series A , 35, 417-446 .
Cole, P. (1979) The evolving case-control study. Journal of Chronic Diseases, 32 , 15-27.
Coleman, J ., Hoffer, T ., and Kilgore, S. (1982) Cognitive outcomes in public and private schools . Sociology of Education, 55 , 65-76.
Cornfield, J . (1951) A method of estimating comparative rates from clinical data: Applications to cancer ofthe lung , breast and cervix. Journal of the National Cancer Institute, 11 , 1269-1275 .
Cox, D. R. (1970) The Analysis of Binary Data. London: Methuen.
Cox, D. R. (1958) The Planning of Experiments. New York: Wiley.
Dehejia, R. H. and Wahba, S. (1999) Causal effects in nonexperimental studies: Reevaluating the evaluation of training programs. Journal of the American Statistical Association, 94, 1053-1062.

102 3. Overt Bias in Observational Studies
Emerson, R. M. (1981) Observational field work . Annual Review of Sociology, 7,351-378.
Fleiss, J. (1981) Statistical Methods for Rates and Proportions. New York: Wiley.
Gastwirth, J . (1988) Statistical Reasoning in Law and Public Policy. New York: Academic.
Goldberger, A. and Cain, G. (1982) The causal analysis of cognitive outcomes in the Coleman, Hoffer, and Kilgore report. Sociology of Education, 55 , 103-122.
Greenhouse, S. (1982) Cornfield 's contributions to epidemiology. Biometrics, 388, 3346.
Hamilton, M. (1979) Choosing a parameter for 2 x 2 table or 2 x 2 x 2 table analysis . American Journal of Epidemiology, 109, 362-375.
Heckman, J . J., Ichimura, H., and Todd, P. (1998) Matching as an econometric evaluation estimator. Review of Economic Studies, 65, 261294.
Hirano, K., Imbens, G. W., and Ridder, G . (2000) Efficient estimation of average treatment effects using the estimated propensity score. National Bureau of Economic Research, Working Paper T0251.
Holland, P. and Rubin, D. (1988) Causal inference in retrospective studies. Evaluation Review, 12, 203-231.
Imbens, G. W. (2000) The role of the propensity score in estimating doseresponse functions. Biometrika, 87, 70G-710.
Joffe, M. M. and Rosenbaum, P. R. (1999) Propensity scores . American Journal of Epidemiology, 150, 327-333.
Katz, J . (2001) Analytic induction. In : International Encyclopedia of Social and Behavioral Sciences, Oxford: Elsevier Science Limited, to appear.
Kitagawa, E. (1964) Standardized comparisons in population research. Demography, 1, 296-315.
Kleinbaum, D., Kupper, L., and Morgenstern, H. (1982) Epidemiologic Research. Belmont, CA: Wadsworth.
Mantel, N. (1973) Synthetic retrospective studies. Biometrics, 29, 479486.

3.9 References 103
Mantel, N. and Haenszel, W. (1959) Statistical aspects of retrospective studies of disease. Journal of the National Cancer Institute, 22, 719748.
Ming , K. and Rosenbaum, P. R. (2000) Substantial gains in bias reduction from matching with a variable number of controls . Biometrics, 56, 118-124.
Morton, D., Saah, A., Silberg, S., Owens, W ., Roberts, M., and Saah, M. (1982) Lead absorption in children of employees in a lead related industry. American Journal of Epidemiology, 115, 549-555 .
Mosteller, F. and Tukey, J. (1977) Data Analy sis and Regression. Reading, MA: Addison-Wesley.
Petersen, L. A., Normand, S., Daley, J ., and McNeil, B. (2000) Outcome of myocardial infarction in Veterans Health Administration patients as compared with Medicare patients. New England Journal of Medicine, 343, December 28, 1934-1941.
Robins, J. M. and Ritov, Y. (1997) Toward a curse of dimensionality appropriate asymptotic theory for semi-parametric models. Stati stics in Medicine, 16, 285-319.
Robins, J. M., Mark, S. D. and Newey, W . K. (1992) Estimating exposure effects by modeling the expectation of exposure conditional on confounders. Biometrics, 48 , 479-495.
Rosenbaum, P. R. (1984a) The consequences of adjustment for a concomitant variable that has been affected by the treatment. Journal of the Royal Statistical Society, Series A, 147, 656--666.
Rosenbaum, P. R. (1984b) Conditional permutation tests and the propensity score in observational studies. Journal of the American Statistical A ssociation, 79, 565-574.
Rosenbaum, P. R. (1986) Dropping out of high school in the United States: An observational study. Journal of Educational Statistics, 11, 207224.
Rosenbaum, P. R. (1987a) Model-based direct adjustment. Journal of the American Statistical A ssociation, 82, 387-394.
Rosenbaum, P. R. (1987b) The role of a second control group in an observational study (with Discussion) . Statistical Science, 2, 292-316.
Rosenbaum, P. R. (1988) Permutation tests for matched pairs with adjustments for covariates. Applied Statisti cs, 37, 401-411.

104 3. Overt Bias in Observational Studies
Rosenbaum , P. R. and Rubin , D. B. (1983) The central role of the propensity score in observational studies for causal effects . Biometrika, 70 , 41-55.
Rosenbaum, P. and Rubin, D. (1984) Reducing bias in observational studies using subclassification on the propensity score . Journal of the American Statistical Association, 79 , 516-524 .
Rosenbaum, P. R. and Silber, J . H. (2001) Matching and thick description in an observational study of mortality after surgery. Biostatistics, 2, 217-232.
Rubin, D.B. (1977) Assignment to treatment group on the basis of a covariate. Journal of Edu cational Statistics, 2, 1-26.
Rubin, D.B. (1978) Bayesian inference for causal effects : The role of randomization. Annals of Statistics, 6, 34-58.
Silber , J . H., Rosenbaum, P. R., Trudeau, M. E ., Even-Shoshan, 0 ., Chen, W., Zhang , X., and Mosher, R. E. (2001) Multivariate matching and bias reduction in th e surgical outcomes study. Medical Care, to appear.
Smith, H. 1. (1997) Matching with multiple controls to estimate treatment effects in observational studies. Sociological Methodology , 27, 325-353.
Tunca, B. T . and Egeli, U. (1996) Cytogenetic findings on shoe workers exposed long-term to benzene. Environmental Health Perspectives, 104, supplement 6, 1313-1317.
Ury, H. (1975) Efficiency of case-control studies with multiple controls per case: Continuous or dichotomous data. Biometrics, 31, 643-649.
Walker, A. (1982) Efficient assessment of confounder effects in matched follow-up studies. Applied Statistics, 31 , 293-297.
Walker, A., Jick, H., Hunter, J., Danford, A., Watkins, R., Alhadeff, L., and Rothman, K. (1981) Vasectomy and non-fatal myocardial infarction. Lancet, 13-15.
Whitehead, R., Rosenbaum, P., and Carbone, P. (1984) Cisplatin, doxorubicin, cyclophosphamide, lomustine, and vincristine (PACCO) in the treatment of nonsmall cell bronchogenic carcinoma. Cancer Treatment Reports, 68, 771-773 .

4
Sensitivity to Hidden Bias
4.1 What Is a Sensitivity Analysis?
Cornfield, Haenszel, Hammond, Lilienfeld , Shimkin, and Wynder (1959) first conducted a formal sensitivity analysis in an observational study. Their paper is a survey of the evidence available in 1959 linking smoking with lung cancer. The paper asks whether the association between smoking and lung cancer is an effect caused by smoking or whether it is instead due to a hidden bias. Can lung cancer be prevented by not smoking? Or are the higher rates of lung cancer among smokers du e to some other difference between smokers and nonsmokers?
In their effort to sort through conflict ing claims , Cornfield et al. (1959) derived an inequality for a risk ratio defined as the ratio of the probability of death from lung cancer for smokers divided by the probability of death from lung cancer for nonsmokers. Specifically, they write:
If an agent, A, with no causal effect upon the risk of a disease, nevertheless, because of a positive correlation with some other causal agent , B , shows an apparent risk, T, for those exposed to A, relative to those not so exposed, then the prevalence of B, among those exposed to A, relative to the prevalence among those not so exposed, must be greater than T.
Thus, if cigarette smokers have 9 times the risk of nonsmokers for developing lung cancer, and this is not because cigarette smoke is a causal agent, but only because cigarette smokers produce hormone X, then the proportion of hormone X-producers

106 4. Sensitivity to Hidd en Bias
among cigaret te smokers must be at least 9 t imes greate r t ha n that of nonsmokers. If t he relative prevalence of hormone Xproducers is considerably less than nin efold , then hormone X cannot account for the magnitude of the apparent effect.
Their statement is an important con ceptual advance. The advance consists in replacing a genera l qu alitative st a tement that applies in all observat ional st udies by a quantitative stateme nt t hat is sp ecific to what is obser ved in a particular st udy. Inst ead of saying that an associat ion between treat ment and outcome does not imply ca usat ion, that hidd en biases can explain observed associations, they say that t o explain the assoc iat ion seen in a particular st udy, one would need a hidden bias of a particular magnitude. If the associat ion is strong, the hidden bias needed to explain it is large.
Though an important conceptual adva nce, the above inequality of Cornfield et al. (1959) is limited to binary outcomes, and it ignores sampling variability which is hazardous except in ext re mely large st udies. This chapter discusses a general method of sensit ivity an alysis that is similar to their method in spirit and purpose.
4.2 A Model for Sensitivity Analysis
4.2.1 The Model Expressed in Terms of Assignment Probabilities
If a st udy is free of hidd en bias , as discussed in Chapter 3, then the chance 7T[jJ that unit j receives t hc t reatment is a fun ction ..\(x[j)) of t he obs erve d covariat es Xli) describing unit j. There is hidd en bias if two units with the same observed covariates X have differing chances of receiving the treat-
ments, that is, if x[jl = X [k) but 7Tli) =1= 7T[k) for som e j and k. In this case ,
units that appear similar have differing chances of assignment to treatment. A sensit ivity an alysis asks : How would inferenc es about treatment effects
be altered by hidden biases of various magnitudes? Suppose the 7T'S differ at a given x. How large would these differences have to be to alter the qualitative conclusions of a study?
Suppose that we have two units, say j and k , with the same X but possibly differen t 7T'S, so Xli! = X[k) but possibly 7T[j1 =1= 7T [k] . Then units j and k might be matched to form a matched pair or placed together in the same subclass in our attempts to control overt bias due to x . The odds that units j and k receive the treatment ar e, respectively, 7T[j)/( l - 7T[il) and 7T[kJ/(l - 7T[kl )' and the odds ratio is the ratio of these odds. Imagine that we knew that thi s odds ratio for units with the same X was at most

some number r ~ 1; that is,

4.2 A Model for Sensitivity Analysis 107

for all j, k with X[j] = X[k] '

(4.1)

If r were 1, then ?T[j] = ?T[k] whenever X[j] = X[k], so the study would be free of hidden bias, and the methods of Chapter 3 would apply. If r = 2, then
two units who appear similar, who have the same x, could differ in their
odds of receiving the treatment by as much as a factor of 2, so one could be
twice as likely as the other to receive the treatment. In other words, r is a
measure of the degree of departure from a study that is free of hidden bias.
A sensitivity analysis will consider several possible values of r and show
how the inferences might change. A study is sensitive if values of I' close
to 1 could lead to inferences that are very different from those obtained
assuming the study is free of hidden bias . A study is insensitive if extreme
values of r are required to alter the inference.

4.2.2 The Model Expressed in Terms of an Unobserved Covariate

When speaking of hidden biases, we commonly refer to characteristics that were not observed, that are not in x, and therefore that were not controlled by adjustments for x. This section expresses the model of §4.2.1 in terms of an unobserved covariate, say u , that should have been controlled along with x but was not controlled because U was not observed . This reexpression of the model takes place without loss of generality, that is, it entails writing the same model in a different way. The models of §4.2.1 and 4.2.2 are identical in the sense that they describe exactly the same collections of probability distributions for Z[l]" . . , Z [M ]'
Unit j has both an observed covariate X[j] and an unobserved covariate u[j] . The model has two parts, a logit form linking treatment assignment Z[j] to the covariates (X[j], U[j]) and a constraint on u[j], namely,

(1 1, log

~ ~ ?T[j] ) = ",(x[j]) +,U[j], with 0 U[j]

(4.2)

- ?T[j]

where ,..(.) is an unknown function and, is an unknown parameter.
Suppose units j and k have the same observed covariate, so X[j] = X[k]
and hence ",(x[j]) = "'(X[k])' In adjusting for x, these two units might be matched or might be placed in the same stratum. Consider the ratio of the odds that units j and k receive the treatment

(4.3)

108 4. Sensitivity to Hidden Bias

In ot her words , two units with th e same x differ in their odds of receiving the treatment by a factor that involves the paramet er 'Y and the difference in their unobserved covariates u.
The following proposition says t ha t the model (4.2) is the sa me as the inequality (4.1). The proposition shows that the model (4.2) involves no additional assumptions beyond (4.1)- t he logit form , the const raint on u , the absence of interaction term s linking x and u-these are not additional assumpt ions but rather are implied by (4.1).
Proposition 12 With e'Y = r 2: 1, there is a model of th e form (4.2) that
describes th e 7f[lJ, .. . , 7f[M] if and only if (4.1) is sati sfied.
Proof. Assume the mod el (4.2). Then -1 :S U[j ] - U[k] :S 1, and so from
(4.3),

exp (-'Y) :S 7f[j](1 - 7f[k]) :S exp b )
7f[k] (1 - 7f[j])

wherever x[j] = X[k].

(4.4)

In other words , if (4.2) holds, then (4.1) holds with r = exp f-y ),
Conversely, assume the inequality (4.1 ) hold s. For each valu e x of the
observed covariate, find that unit k with X[k] = x having the smallest 7f, so

7f[k] = . min 7f[j] ;
{}:x(jJ=x }
th en set lI:(x) = log{7f[k]/(1 - 7f[k])} and U[k] = O. If r = 1, then X[j] = X [k] implies 7f[j J = 7f[k] , so set u [j ] = O. If r > 1 and there is an other unit j with
the same value of x , then set

U[j ] = .!:.log ( 7f[j] ) _ lI:(x) = .!:.log (7f [j](1- 7f1k]» ) .

'Y

1 - 7f[jJ

'Y 'Y

7f[k](1 - 7f[j])

(4.5)

Now (1.5) implies the logit form in (4.2) . Since 7f iJ] 2: 7f[k), it follows that u[j] 2: O. Using (4.1) and (4.5), it follows that u[jJ :S 1. So the const raint on U[j] in (4.2) holds . ·
The const raint on U[j] in (4.2) may be viewed in various ways. First , it may be seen simply as the formal expression of the statem ent (4.1) that subjects who appear similar in terms of x may differ in their odds of receiv-
ing the treatment by at most r. This faithful translation of the model into
nontechnical terms is often helpful in discussing the results of a sensitivity ana lysis.
A second view of the const ra int on U[j] in (4.2) rel ates it to the risk ratio inequality of Cornfield et al. (1959). In that inequality, the unobserved variable is a binary trait , U = 0 or U = 1. Of course, a binar y trait satisfies the const raint in (4.2). Indeed, in later calculations, the relevant u 's take the extre me values of 0 or 1. In other words , t he const raint in (4.2) could, for most purposes, be replaced by the assumption that U is a binar y variable taking value s 0 or 1.

4.2 A Model for Sensitivity Analysis 109
Finally, the constraint in (4.2) may be seen as a restriction on the scale of the unobserved covariate, a restriction needed if the numerical value of , is to have meaning. This last view suggests consideration of other restrictions on the scale, for instance, restrictions that do not confine u to a finite range. As is seen later in Problem 9, it is not difficult to work with alternative restrictions on u, but the attractive nontechnical translation of the parameter I' is then lost.
Throughout this chapter, the model (4.1) or its equivalent model (4.2) is assumed to hold.
4.2.3 The Distribution of Treatment Assignments After Stratification
As in §3.2.2, group units into S strata based on the observed covariate x, with ns units in stratum s , of whom m s received the treatment. Under the equivalent models (4.1) or (4.2), the conditional distribution of the
treatment assignment Z = (Zll , ' " ,ZS,ns) given m is no longer constant,
as it was in §3.2.2 for a study free of hidden bias . Instead, the distribution is
where
and Os is the set containing the (;:,:) different ns-tuples with m s ones and n s - m s zeros . The easy steps leading from (4.2) to (4.6) form Problem 8.
Notice what (4.6) says . Given m, the distribution of treatment assignments Z no longer depends of the unknown function K(X), but it continues to depend on the unobserved covariate u. In words, stratification on x was useful in that it eliminated part of the uncertainty about the unknown 1I"'S, specifically, the part due to K(X), but stratification on x was insufficient to render all treatment assignments equally probable, as they would be in an experiment.
There are two exceptions, two cases in which (4.6) gives equal probabili-
ties 1/K to all K treatment assignments in O. If, = 0, then the unobserved
covariate u is not relevant to treatment assignment; see (4.2). If Usi = Usj
for all 1 ~ i < j < ns and for s = 1, .. . ,S, then units in the same stratum
have the same value of u. In both cases, (4.6) equals I/K for all z E O. In other words, there is no hidden bias if U is either unrelated to treatment assignment or if U is constant for all units in the same stratum.

110 4. Sensitivity to Hidden Bias
For any sp ecific (r, u) , th e distribution (4.6) is a distribution of tr eat-
ment assignments Z on n. If (r , u) were known, (4.6) could be used as a
basis for permutation inference, as in Chapter 2. Since (r , u) is not known, a sensitivity analysis will display the sensi tivity of infenmres to a range of assumptions a bout (r , u) . Specifically, for several valu es of " the sensitivity analysis will determine the most extreme inferences that are possible for u satisfying the const raint in (4.2) , that is, for u in the N-dimensional
unit cube U = [0, l]N . Specific pro cedures are discussed in the remaining
sections of this chapter .

4.3 Matched Pairs

4.3.1 Sensitivity of Significance Levels: The General Case

With matched pairs, the model and methods have a particularly simple

form. For this reason, matched pairs are discussed first and separately,

though §4.3 could be formally subsumed within the more general discussion

in §4.4.

With 5 mat ched pairs , each stratum S,S = 1, ... ,5, has n s = 2 units,
one of which received the treatment, 1 = m s = Zsl + Z s2, so Z s2 = 1 -
Z sl ' The model (4.6) describes 5 ind ependent binary trials with unequal

probabilities, namely,

IT [ prob(Z = zlm) =

e "YU.,l

] Z., l [

U e "Y s 2

s1 ] l- Z

+ s = 1 e"YUs l

e "YU s 2

+ e"YU .l1

e"YU s 2

(4.7)

In a randomized experiment or in a study free of hidden bias, , = a and
every unit has an equal chance of receiving each treatment, so (4.7) is the
a uniform distribution on n. In contras t, if , > in (4.7) , then the first
unit in pair s is more likely to receive the treatment than the second if
> U sl U s2'
As seen in Chapter 2, common test statistics for matched pairs are sign-
score statistics, including Wilcoxon 's signed rank st atistic and McNemar's statistic. They have the form

L L S

2

T = t(Z, r) =

d,

Cs iZsi ,

s= 1 i=1

where Csi is binary, Csi = 1 or Csi = 0, and both d; ~ a and Csi are func-
tions of r, and so are fixed under the null hypothesis of no treatment effect. In a randomized experiment, t(Z, r) is compared to its randomization distribution under the null hypothesis, but this is not possible here because the treatment assignments Z have distribution (4.7) in which (r , u) is unknown . Specifically, for each possible (r , u) , the statistic t(Z, r) is the sum

4.3 Matched Pairs III

of S independent random variables, where the sth variable equals ds with probability

Csl exp(')'usl) + Cs2 exp(')'us2) Ps = exp(')'usl) + exp(')'us2) ,

(4 .8)

° and equals with probability 1 - Ps . A pair is said to be concordant if ° Csl = Cs2· If Csl = Cs2 = 1 then Ps = 1 in (4.8) , while if Csl = Cs2 = then

Ps = 0, so concordant pairs contribute a fixed quantity to t(Z, r) for all

possible (')', u) .

Though the null distribution of t(Z , r) is unknown, for each fixed, the
null distribution is bounded by two known distributions. With r = exp(-r},

define P; and P-; in the following way:

if Csl = Cs2 = 0,
if Csl = Cs2 = 1,
if Csl i- Cs2 ,

if Csl = Cs2 = 0,
if Csl = Cs2 = 1,
if Csl i- Cs2 '

Then using the constraint on U[j] in (4.2), it follows that P-; S Ps S P; for
8 = 1, .. . ,S. Define T+ to be the sum of S independent random variables,
° p;. where the sth variable takes the value ds with probability P; and takes
the value with probability 1 - Define T- similarly with P-; in place
of p;. The following proposition says that, for all u E U = [0, 1]N , the
unknown null distribution of the test statistic T = t(Z, r) is bounded by the distributions of T+ and T-.
Proposition 13 If the treatment has no effect, then for each fixed , ~ 0,
prob(T+ ~ a) ~ prob{T ~ aim} ~ prob(T- ~ a)

for all a and u E U.

For each" Proposition 13 places bounds on the significance level that would have been appropriate had u been observed. The sensitivity analysis for a significance level involves calculating these bounds for several values of ,.
The bounds in Proposition 13 are attained for two values of u E U , and this has two practical consequences. Specifically, the upper bound prob(T+ ~ a) is the distribution of t(Z , r) when Usi = Csi and the lower bound prob(T- ~ a) is the distribution of t(Z, r) when Usi = 1 - Csi' The first consequence is that bounds in Proposition 13 are the best possible bounds: they cannot be improved unless additional information is given about the value of u E U. Second, the bounds are attained at values of u which perfectly predict the signs Csi . For conventional statistics like MeNemar's statistic and Wilcoxon's signed rank statistic, this means that the bounds are attained for values of u that exhibit a strong, near perfect relationship with the response r .

112 4. Sensitivity to Hidden Bias

The bounding distributions of T+ and T- have easily calculated moments. For T+ , the expectation and variance are

s
E(T+) = Ldsp~ and
s=l

Ls
var(T+) = d; p~(1 - p~) . (4.9)
s= l

For T- the expectation and variance are given by the same formulas with
p; in place of p;. As the number of pairs S increases, the distributions of
T+ and T- are approximated by Normal distributions, providing the number of discordant pairs increases with S and provided the ds are reasonably well behaved, as they are for the McNemar and Wilcoxon statistics.
The method is illustrated in §4.3.2 for the McNemar test and in §4.3.3
for the Wilcoxon signed rank test.

4.3.2 Sensitivity Analysis for McNemar's Test: Simplified Formulas and an Example
In a study of the effects of smoking on lung cancer, Hammond (1964) paired 36,975 heavy smokers to nonsmokers on the basis of age, race, nativity, rural versus urban residence, occupational exposures to dusts and fumes, religion , education, marital status, alcohol consumption, sleep duration, exercise, severe nervous tension, use of tranquilizers, current health, history of cancer other than skin cancer, history of heart disease, stroke, or high blood pressure. Though the paired smokers and nonsmokers were similar in each of these ways, they may differ in many other ways. For instance, it has at times been suggested that there might be a genetic predisposition to smoke (Fisher 1958).
Of the S = 36,975 pairs, there were 122 pairs in which exactly one person died of lung cancer . Of these, there were 12 pairs in which the nonsmoker
died of lung cancer and no pairs in which the heavy smoker died of lung
cancer. In other words, 122 of the pairs are discordant for death from lung cancer. If this study were a randomized experiment, which it was not, or if the study were free of hidden bias, which we have little reason to believe, then McNemar's test would compare the 110 lung cancer deaths among smokers to a binomial distribution with 122 trials and probability of success 1/2, yielding a significance level less than 0.0001. In the absence of hidden bias , there would be strong evidence that smoking causes lung cancer. How much hidden bias would need to be present to alter this conclusion?
Let d, = 1 for all s, Zsi = 1 if the ith person in pair S is a smoker and
a Zsi = if this person is a nonsmoker, and Csi = 1 if this person died of a lung cancer and Csi = otherwise. Then the sign-score statistic

L L S

2

T = t(Z, r) = d; CsiZsi

s=l i=l

4.3 Matched Pairs 113

TABLE 4.1. Sensitivity Analysis for Hammond 's Study of Smoking and Lung Cancer: Range of Significance Levels for Hidden Biases of Various Magnitudes.

r Minimum Maximum

1 < 0.0001 < 0.0001

2 < 0.0001 < 0.0001

3 < 0.0001 < 0.0001

4 < 0.0001

0.0036

5 < 0.0001

0.03

6 < 0.0001

0.1

is the number of smokers who died of lung cancer. A pair is concordant
if Csl = Cs2 and is discordant if Csl i= Cs2 . No matter how the treatment,
smoking, is assigned within pair s, if neither person died of lung cancer,
then pair s contributes 0 to t(Z, r), while if both people died of lung can-
cer, then pair s contributes 1 to t(Z, r), so in either case, a concordant pair
contributes a fixed quantity to t(Z, r). Removing concordant pairs from
consideration subtracts a constant from t(Z, r) and does not alter the sig-
nificance level. Therefore, set the concordant pairs aside before computing
T = t(Z , r), leaving the 122 discordant pairs, so T is the number of discor-
dant pairs in which the smoker died of lung cancer, T = 110; that is, T is
McNemar's statistic.
With the concordant pairs removed , T+ and T- have binomial distri-
butions with 122 trials and probabilities of success p+ = r /(1 + I') and p" = 1/(1 + I'), respectively. Under the null hypothesis of no effect of
smoking, for each I ~ 0, Proposition 13 gives an upper and lower bound on the significance level, prob{T ~ 110Im}, namely, for all U E U,

(4.10)
In a randomized experiment or a study free of hidden bias, the sensitivity
parameter I is zero , so p+ = v: = ~ , the upper and lower bounds in (4.10)
are equal, and both bounds give the usual significance level for McNemar's
statistic. For I > 0, (4.10) gives a range of significance levels reflecting
uncertainty about u. Table 4.1 gives the sensitivity analysis for Hammond's data. For six
values of r, the table gives the upper and lower bounds (4.10) on the significance level. For r = 4, one person in a pair may be four times as likely

114 4. Sensitivity to Hidden Bias
to smoke as the other because they have different values of the unobserved
covariate u. In the case r = 4, the significance level might be less than
0.0001 or it might be as high as 0.0036 , but for all U E U the null hypothesis of no effect of smoking on lung cancer is not plausible. The null hypothesis
of no effect begins to become plausible for at least some u E U with r = 6.
To attribute the higher rate of death from lung cancer to an unobserved covariate u rather than to an effect of smoking, that unobserved covariate would need to produce a sixfold increase in the odds of smoking, and it would need to be a near perfect predictor of lung cancer. As will be seen by comparison in later examples, this is a high degree of insensitivity to
hidden bias: in many other studies, biases smaller than r = 6 could explain
the association between treatment and response.
4.3.3 Sensitivity Analysis for the Signed Rank Test: Simplified Formulas and an Example
Wilcoxon's signed rank statistic for S matched pairs is computed by ranking the absolute differences Ir sl - r s21 from 1 to S and summing the ranks of the pairs in which the treated unit had a higher response than t he matched
control. In the notation of §4.3.1, ds is the rank of Irsl - r s2! with average ranks used for ties, and Csl = 1, Cs2 = 0 if rsl > r s2 or Csl = 0, Cs2 = 1 if r sl < rs2 so in both cases the pairs are discordant, and Csl = 0, Cs2 = 0 if r sl = r s2 so the pairs are concordant or tied.
If there are no ties among the absolute differences Irsl - r s2! and no zero
differences, then the expectation and variance (4.9) of T+ have simpler forms

and

(4.11)

where

+_ r . p - 1+r'

see Problem 7. With p- = 1/{1 + I') in place of p+ , the same expressions give the expectation and variance of T-. If 'Y = 0 so e' = r = 1, then
p+ = p" = ~, and these expressions for the moments of T+ and T- are the same as the usual formulas for the expectation and variance of Wilcoxon's
statistic in a randomized experiment (Lehmann 1975, p. 128).
Ti es and zero differences occur in practice, and in this cas e the general
formula (4.9) may be used. Notice that ties do not alter the expectation of
T+ and T -, but they alter the vari ance.

4.3 Matched Pairs 115

TABLE 4.2. Sensitivity An alysis for Lead in the Blood of Children: Range of

Significan ce Levels for the Sign ed-Rank Statistic.

r

Minimum Maximum

1

<0.0001 <0.0001

2

< 0.0001

0.0018

3

< 0.0001

0.0136

4

<0.0001

0.0388

4.25 < 0.0001

0.0468

5

<0.0001

0.0740

Consider the example in Table 3.1 concern ing lead in the blood of childr en who se parents work in a battery factory. The Wilcoxon signed rank st at ist ic for the differences in children's lead levels is 527. As seen in §3.2.4, if the st udy were free of hidden bias , this would constitute st rong evidence of an effect of parental exposure to lead on children 's lead levels. Specifically, if the study were free of hidden bias , that is, if I' = 1, the expectation of the signed rank statistic under the null hypothesis of no effect is 280 with vari anc e 3130.63. The standardized deviate (527 - 280)/ V3130.63 is 4.41, yielding an approximate one-sided significance level of less than 0.0001.
In Tabl e 3.1, notice the several tied differences for which average ranks were used , and the on e zero difference which is a concordant pair. Because of the ties and zero differ ence, the exac t formula (4.9) was used , though in this case (4.11) gives nearly identical results; for instance, (4.9) gives 280.5 and 3132.25 for t he null expectation and var iance with deviat e st ill equal to 4.4 1.
If t he study were free of hidden bias , there would be strong evidence that parents ' occupational expos ures to lead increased the level of lead in their childre n 's blood. The sensit ivity analysis asks how this conclusion might be
changed by hidden biases of various magnitudes. If r were 2, th en matched
childre n might differ in t heir odds of exposure to lead by a factor of 2 due to hidden bias. In this case, E(T+) = 373.33, E(T-) = 186.67, var(T+) =
var(T-) = 2782.78, so the deviates are (527 - 373.33)/V2782.78 = 2.91
a nd (527 - 186.67)/ V2782.78 = 6.45. The range of significance levels when T = 2 is therefore from less than 0.0001 to 0.0018. A hidden bias of size I' = 2 is insufficient to explain the observed difference between exposed and control children.
Table 4.2 gives the sensitivity analysis for the significanc e levels from Wilcoxon's signed rank t est, that is, the range of possible significance levels for various values of I' . The table shows that to explain away the observed association between parental exposure to lead and child' s lead level, a hidden bias or unobserved covariate would need to increase the odds of exposure by more than a factor of I' = 4.25. The associat ion cannot be at t ribute d to sm all hidden biases, but it is somewhat more sensitive to bias than Hammond's st udy of heavy smokers in §4.3.3.

116 4. Sensitivity to Hidden Bias

4.3.4 Sensitivity Analysis of the Hodges-Lehmann Point Estimate in Matched Pairs
In §3.2.4, the effect of parental exposure to lead on the level of lead in t he child 's blood was est imated to be 15 /19 of lead pe r decalit er of who le blood. T his estimate is based on two premises:

(i) the treatment has an additive effect r, so a child's lead level is increased by r as a consequence of parental exposure; and
(ii) the st udy is free of hidden bias .

If the effect is add it ive, then the adjusted resp onses R - r Z satisfy t he null hypothesis of no effect. The est imat e of 15 /19 / dl is t he Hodges-Lehmann est imate, obtained as t he value f such t hat, if t he signed rank stat ist ic is computed after subt rac t ing f from the resp onses of exposed children, then
t thi s stat ist ic equals its expectation E{t (Z , R - rZ)} = = S(S + 1)/4
und er the null hyp othesis of no effect in the abse nce of hidd en bias . More pr ecisely, as discussed in §2.7.2, to allow for the discreteness of the signed rank statist ic, f is defined as

f

SOLVE {t = t( Z, R - f Z) }

inf{r : t> t( Z , R - r Z)} + sup {r : t < t( Z , R - r Z)} .(4.12)

2

If t here is hidden bias, t hen the signed rank statistic computed from
R- rZ does not generally have expectation S(S+ I)/4. 1f E{ t (Z , R- rZ)} =I-
S(S + 1)/4, t hen t here is no point in try ing to find a f so that t( Z, R - f Z) is nearly S(S + 1)/ 4; rather , f sho uld be found so t( Z , R - f Z) is close to
E{ t (Z,R - r Z)}. Under t he model (4.1) or (4.2) , t he expectation of the
signed rank statistic computed from R - rZ is bo unded by t he expectations
of T+ and T - in Proposit ion 13, that is, bounded by

-

p-S(S + I)

-

p+S(S + I)

tmin =

2

and

t m ax =

2

'

(4 .13)

where

_1
p = 1+r

a nd

+r p = 1 -j I"

t_= In ot her words, for a given I' , t he expec tat ion E{ t(Z , ~ - rZ)} is not
known but is bounded by two known number s, tmin ::; t::; tm ax . Moreover,
t hese bounds are sharp in t hat t hey ar e at tained for particular values of
t he unobserved covariate U E U. Consid er calculat ing f = SOLVE { t =
t t( Z , R - f Z)} for each in the interval [tmin,tmax]; this would produce
t he set of possible Hodges-Lehmann estimates. In fact , t he minimum and
max imum est imates in t his set are eas ily det ermined . Since the signed rank

4.3 Matched Pairs 117

TABLE 4.3. Sensitivity Analysis for Lead in Children's Blood : Range of Hodges-Lehmann Estimates of Effect for Biases of Various Magnitudes.

r Minimum Maximum

1 15

15

2 10.25

19.5

3

8

23

4

6.5

25

5

5

26.5

statistic is effect increasing, the smallest f = SOLyE {t = t(Z, R - fZ)}
is found for [ = [max and the largest f is found for [ = [min.
In short, the sensitivity analysis consists of calculating the range of possible Hodges-Lehmann estimates of an additive treatment effect for _biases of various magnitudes. This is done by calculating f = SOLVE {[ =
t(Z, R - fZ)} for t = tmax and t = tmin for several values of r .
Table 4.3 shows the sensitivity analysis for the data on lead in the_blood
of children. If there is no hidden bias , that is, if r = 1, then [max = [min = S(S + 1)/4 = 33(33 + 1)/4 = 280.5, and the range of Hodges-Lehmann
estimates of effect is the single number 15 J.Lg/dl, namely, the usual HodgesLehmann estimate for a randomized experiment. If I' = 2, then two subjects with the same observed covariates may differ by a factor of 2 in their
t odds of receiving the treatment. In this case, m ax = p" S(S + 1)/2 =
2 x 33(33+ 1)/6 = 374_and tmin = p- S(S + 1)/2 = 33(33+ 1)/6 = 187, and solving f = SOLVE {[ = t(Z, R - fZ)} gives 10.25 and 19.5, respectively.
In words, if r = 2, the estimated effect might be as small as 10.25 J.Lg/dl
or as high as 19.5 M/di. Keep in mind that the median lead level in J.Lg/dl among controls is 16, so an effect of 10.25 is a 64% increase above the level
found among controls. For r = 5, the estimated effect is between 5 and 26
J.Lg/ dl, though the smaller estimate does not differ significantly from zero; see Table 4.2.
To illustrate the computations in gre~ter detail, consider the upper
bound 19.5 for r = 2. As noted above , [min = 187. By direct calcula-
tion with the signed rank statistic, t(Z, R - 19.5Z) = 193.5, which is a bit too high, while t(Z, R - 19.5001Z) = 186, which is a bit too low. Apply-
ing (4.12) with inf{r : 187 > t(Z,R - rZ)} = 19.5 and sup [v : 187 <
t(Z, R - rZ)} = 19.5 yields the estimate 19.5.
4.3.5 Sensitivity Analysis for Confidence Intervals in Matched Pairs
This section discusses sensitivity analysis for a confidence interval for an additive effect r , A 1 - a confidence interval is the set of all values of -r

118 4. Sensitivit y to Hidden Bias

TABLE 4.4 . Sensitivit y Analysis for Lead in Children 's Blood : Confid en ce Int ervals for a n Additive Effect for Biases of Various Magnitudes .

r 95% Confid enc e interval

1

(9.5, 20.5)

2

(4.5, 27.5)

3

(1.0, 32.0)

4

( - 1 . 0 , 3 6 .5)

5

(-3.0,41.5)

that ar e not rejected in an a -level t est. For each b, u) , there is a two-sided
a-level confidence interval derived from a test stat ist ic t (Z , R - TZ). For
each fixed " the sensitivity analysis will report the union of these intervals as u ranges over U . Call this union the sensitivity interval. A value T is in
the interval if and only if there is some u E U such that T is not rejected
in an a-level test.
Let T: and T; be the bounding random variables in §4.3.1 computed
from the adjusted responses R - TZ , and let T; = t(Z , R - TZ) . Fix I ~ 0 and suppose a / 2 ~ prob(T: ~ ad and a/2 ~ prob(Tr- ::; a2). Then Proposition 13 implies a/2 ~ prob{Tr ~ allm} for all u E U , and
a/2 ~ prob{Tr ::; a2Im} , for all u E U. If i; ~ al or t: ::; a2, then T
is rejected at level a for all u E U , so T is excluded from the sensitiv-
ity int erval. When I = 0, thi s yields the confidence interval in §2.6.2 for
a randomized experiment, but as I increases this inter val b ecomes larger
T: reflecting uncertainty about the impact of u . When using t he Normal approximation to the distribution of and
T; , the endpoints of the 95% confide nce interval are

i.nf { T : Tr - E(T:) ::; 1.96} and sup {TT: r -~ E(T;) ~ -1.96 } .

Jvar(T:t)

V(T;)

The procedure is illustrated in Table 4.4 using the signed rank test for the data on lead in children's blood. If the st udy were free of hidden bias,
that is, if I' = 1, the 95% confidenc e interval for the additive effect T in Jlg/dl would be (9.5, 20.5), as in §3.2.4. If I' = 2, matched children might
differ by a factor of two in their odds of exposure to lead due to differences
in the unobserved covariate. In this case , the 95% confidence interval is
longer , (4.5, 27.5), though the smallest plausible effect 4.5 is still 28% of
the median lead level 16 Jlg/dl among controls. For r = 4, slightly negative
effects become just plausible, though large positive effects are also plausible.
In comparing the tables, keep in mind that Table 4.4 describes a two-sided
95% confidence interval while Table 4.2 describes a one-sided significance
test .

4.4 Sensitivity Analysis for Sign-Score Statistics 119

TABLE 4.5. Illustrative Computations for r = 2. T t(Z,R - TZ) E(T;) var(T;) Deviate

27.4999 27 .5000

89.00 86.00

187.00 2609.00 -1.92 187.00 2607.89 -1.98

T t(Z,R - TZ) E(Tf) var(Tf) Deviate

4.5000 4.4999

476 .50 479.00

374.00 2766.61 1.95 374.00 2769.00 2.00

Table 4.5 contains some of the calculations leading to Table 4.4 for the case I' = 2. The top half of Table 4.5 shows that 27.5 is the sup of all T leading to a deviate greater than - 1.96. The bottom half of the table shows that 4.5 is the inf of all T leading to a deviate less than 1.96.

4.4 Sensitivity Analysis for Sign-Score Statistics

4.4.1 The General Method

As noted in §2.4.3, many common statistical tests are sign-score statistics. All sign-score statistics permit a sensitivity analysis similar to that in §4.3 for matched pairs. The purpose of §4.4 is to discuss this class of problems, first in general terms in §4.4.1, and then in specific situations in the later parts of §4.4. Sections 4.5 and 4.6 discuss larger classes of test statistics requiring computations that are just slightly more complex.
Recall that a sign-score statistic has the form

S

n,

S

n,

n, t(Z,r) = Lds LCSiZSi = LdsBs , where = LCSiZSi,

s= 1 i=1

s=1

i=1

(4.14)

Csi is binary, Csi = 1 or Csi = 0, ds is nonnegative, ds 2: 0, and both
ds and Csi are functions of r. For binary responses r, the signs are the responses themselves, Csi = t:« , and the scores are constant, ds = 1; this yields Fisher's exact test for a 2 x 2 table, McNemar's statistic for matched pairs, and the Mantel-Haenszel statistic for a 2 x 2 x S table. In Wilcoxon's
signed rank statistic for matched pairs, the signs , Csi, identify the unit in matched set i with the largest response and the score ds is the rank of the difference between the larger and the smaller responses in a matched pair. In the median test, the signs Csi identify units with responses above the median response of the combined treated and control groups.
The main fact about sign-score statistics, namely Proposition 14, is similar to Proposition 13 for matched pairs. Specifically, Proposition 14 bounds the unknown distribution of t(Z , r) by two known distributions, namely, the

120 4. Sen sitivi t y to Hid den Bias

TABLE 4 6 T wo-By-Two Tabl e Associated W ith a Sign-Sco re St at ist ic.

Z si = 1

Z si = 0

Total

Csi = 1

A

Cs+ -A

Cs +

+ = C~i 0 m s - A 7J.s - Cs I - m s A 7l.s - f':s I

Total

ms

ns -ms

ns

distributions at t he most extreme u 's E U . Sign-score stat ist ics are spe cial in the following sense: The u 's E U that provide the bounds may be determined immedi at ely from the struc t ure of the st atistic its elf.
Und er the null hypothesis of no t reat me nt effect , r is fixed , so ds and Csi are fixed because they ar e functi ons of r . Write u t and u " for the N -t uples
with u:i = Csi and u.ri = 1 - Csi, respectively. Fix {, and let T+ be the
rand om variable L s d, L i Csi Zsi when Z has the distribution (4.6) with
u = u ", and define T - similarly with u = U- .
Proposition 14 If the treatm ent has no effec t and T = t(Z, r) is a signscore statis ti c, then fo r each fix ed { 2': 0,

prob(T+ 2': a) 2': prob{T 2': a im } 2': prob(T- 2': a) for all a and u E U.

The proof is given in t he appendix to this chapter.
As in §4.3, the sensit ivity ana lysis consists of calculating the bounds,
prob (T+ 2': a ) and prob (T- 2': a) , for a range of values of { . For { = 0, the bounds are equal, prob(T+ 2': a) = prob (T- 2': a ), and their common valu e
is t he usual significance level for a randomized exp eriment. As { increases,
t he bounds move apart reflecting un certainty about hidden biases. The
general method is applied to particular cases in subsequent sect ions .
The proposition has two special cases t ha t deserve explicit mention, b ecause they arise frequently and becau se the bounding distributions have
a familiar form . The extended hyp ergeom etric distribution is most com-
monly obtained as the distribution of a binomial ran dom variable conditionally given the sum of thi s var iable and anot her ind ep endent binomial; see Johnson , Kotz , and Kemp (1992, §6.11) or Pl ackett (1981, §4.4.6). It is a distribution of the corn er cell, A , in the 2 x 2 cont ingency table with fixed marginal total in Tabl e 4.6, where Cs + = L7~1 Csi and A mu st satisfy the
inequality min(ms, cs+) 2': A 2': rnax(O, m s + cs+ - n s) to ensure that every
cell of the table has a nonnegative count . Sp ecifically, under the extended
hyp ergeometric distribution , prob (A 2': a) is given by

Y (n s,ms, cs+,a, f ) -_

",min (m . ,c.+ )

( c. +) ( n .-c'+)f k

L...k=. m(ax (a ,m.)+c. + -n. ) k m . -k

.

",mm m. ,c.+

( c. +) ( n .· -c'+ ) f k

L...k=max (O,m.+c.+ - n . ) k m . -k

The corollary says th at the exte nded hyp ergeom etric distribution pro-
vides t he sharp bounds in Proposition 14 when attention focuses on a single
st ra t um sand ds = 1, ds' = 0 for s' i= s .

4.4 Sensitivity Analysis for Sign-Score Statistics 121
Corollary 15 If the treatment has no effect and T = L7':'1 CsiZsi for a specific s, then for each fixed r 2: 1, and for all a and u E U,
~ Y (n s, m s, Cs+, a, f) 2: prob{T 2: aim} 2: Y (n s, m s, Cs+, a, ) .
More generally, if T = L s Li CsiZsi -that is, if ds = 1 for every sthen the bounds in Proposition 14 are given by the corresponding distributions of sums of independent extended hypergeometric distributions. Let
B s , s = 1, ... ,5, be independent random variables with extended hypergeometric distributions Y (n s, m s, cs+, a, f) and let B s, s = 1, ... ,5, be
independent random variables with extended hypergeometric distributions Y (n s,ms,cs+,a, ~).
Corollary 16 If the treatment has no effect and T = L s Li CsiZsi, then for each fixed r 2: 1, and for all a and u E U,

4.4.2 Matching with Multiple Controls Using Sign-Score Statistics
When controls are plentiful, it is common to match several controls to each treated unit, so each stratum s contains a single treated unit and one or
more controls, 1 = Li Zsi for s = 1, . . . ,5. In this case, the model (4.6)
may be written

I I prob(Z -- zIm ) -- S exp (n,"Ln..,i.-. 1 ZsiUsi) for zEn,
s=l Li':'l expCrusi)

(4.15)

since ns contains just the n s vectors z, whose coordinates include a single
one and n s - 1 zeros . Compare (4.15) and (4.7). Also, B, in (4.14) is a
binary random variable. From (4.15), the Bs , s = 1, . .. , 5 , are mutually
independent and

(4.16)

This probability is bounded by its values at u" and u " in §4.4.1, namely, (4.17)
where Cs+ = Li Csi and r = et . Moreover, T+ and T- are the random variables that equal L d.B; when , respectively, Ps = p; and Ps = p; . It

122 4. Sensitivity to Hidden Bias

follows t hat t he moments of T+ are again given by form ula (4.9) , a nd the
moments of T - are given by th e same formula wit h p; in place of p; .
If t he outco me is binary, say 1 for survived and 0 for died , t hen t he
Mante l-Haenszel (1959) statistic is the usual test of t he null hypothes is
of no treatment effect; see §2.4.3. This statistic T = t( Z , r ) is a sign-sco re
statistic wit h d; = 1 and Csi = Tsi in (4.14) , so T is the number of t reated
subjects who surv ived . In (4.14), B; = 1 if t he treated subject in matched set 8 survived and B; = 0 otherwise. T he bounds on t he approx imate
significance level are obtained by referring t he standardized dev iates,

IT - L P; I- ~ and IT - L P;I- ~

(4. 18)

VL Pt (l- pt)

VL P; (1 - p;) '

to tables of the standa rd norm al dist ribution. W hen I = 0, these two
deviates are equal, and the squa re of eit her deviate equals the usu al MantelHaenszel stat istic.
In genera l, for any sign-score stat istic used in ma tching with one or more controls, the deviates are

and

4.4. 3 Sensitivity Analysis with Multiple Controls: Th e
Example of Vitamin C and Cancer
Recall from Chapter 1 t he study by Cameron and P auling (1976) of vitamin C and advanced cancer. In t his st udy, patients t reated wit h vitamin C were each matched wit h 10 controls on the basis of gender, age , primary ca ncer, and histological tumor typ e. In this sect ion, t he Cameron and Pauling study helps to clar ify what sensitivity ana lyses can and cannot do.
Focus on t he 18 t reated patients and t heir 180 mat ched contro ls havin g prima ry cancers of the colon and rectum. The subsequent randomized trial by Moerte l et al. (1985) concerne d patients with ca ncers of the colon and rectum. Cameron an d Pauli ng (1976) used as a t est statistic the number of mat ched set s in which the treat ed patient survived longer than the average survival among the 10 controls. This is the same as count ing the number of t reated patients living longer t han the mean for all 11 patient s in the set, and this count is a sign-score stat istic in which Csi = 1 if subjec t (8, i) lived
longer t ha n th e mean surv ival in set 8 and Csi = 0 otherwise. In fact, 16
of the 18 treated patients survived longer than t he mean in their matched set .
Given the presence of some ext reme resp onses a nd certain ot her features of t he dat a , it is more ap pro priate to count t he nu mber of treated resp onses t hat exceed the median response in their mat ched set, though t his too is 16

4.4 Sensitivity Analysis for Sign-Score Stati stics 123

TABLE 4.7. Sensitivity Analysis for Vitamin C and Advanced Cancer.

Deviate Deviate

Range of

r p; p; at u" at u- significance levels

1 0.45 0.45 3.46 2 0.63 0.29 2.07 3 0.71 0.22 1.38

3.46 [0.0003, 0.0003]
5.28 [0.019, < 0.0001] 6.62 [0.082, < 0.0001]

of the 18 matched sets. This statistic is also a sign-score statistic; in fact, it is a version of the standard median test , though here it is applied within matched sets and then combined across matched sets. The median test is a good test in large samples if the data are from a double exponential distribution and the treatment has a small effect; see Hajek, Sidak and Sen (1999, §4.1, p. 97) or Hettmansperger (1984, §3); however, see also the crit ical discussion of the median test by Freidlin and Gastwirth (2000).
Here, Csi = 1 if subject (s,i) lived longer than the median survival in set
s and Csi = 0 otherwise. Then for each s , 5 = L i Csi, because each set
contains n s = 11 subjects, and the sixth largest response is the median.
Then in (4.17) , p; = 5/ (5 + 6f) and p" = 5f/(5f + 6) , and p; = p; =
5/11 if there is no hidden bias in the sense that r = 1. Now expression
(4.18) yields Table 4.7. The table suggests that the longer survival among patients receiving vitamin C would be highly significant in a randomized experiment , and is insensitive to small biases , but it becomes sensitive at
about I' = 3.
The sensitivity analysis just performed was based on the 16/18 treated subjects who lived longer than the typical subject in the matched set , and this closely parallels the analysis in the original study. One might wonder how the results might change with a different test statistic. In fact, with the same 18 matched sets but a different choice of test statistic, the results are far less sensitive, the upper bound on the significance level being 0.045 for
T = 10; see Rosenbaum (1988) for detailed discussion. The test described
in Table 4.7 made no use of the fact that most treated subjects had survival times much higher than the typical survival time in the subject's matched set, and this is the reason for the diverging findings from different test statistics. The test used for illustration in Rosenbaum (1988) yielded less sensitivity to bias in this example.
The first observation to make is that, with a suitable test, this study is
insensitive to extremely large biases, r = 10, and yet the findings were con-
tradicted by the randomized experiment by Moertel et al. (1985); see §1.2. This observation contains an important lesson about what sensitivity analyses can and cannot do . A sensitivity analysis can indicate the magnitude of the bias required to alter the qualitative conclusions of an observational study, but it cannot indicate what biases are present. Large biases have

124 4. Sensitivity to Hidden Bias

occurred in some studies. Chapters 6 through 9 are concerned with the collection of data that may indicate the presence or magnitude of hidden biases .
A second observation is of a technical nature, and it concerns the choice of test statistic. In this example, the choice of test statistic had a substantial impact on the sensitivity analysis. At present, little firm advice is available about the choice of test statistic for use in sensitivity analyses. Aside from a few special cases, statistical theory has emphasized the creation of test statistics that perform well in large samples against alternative hypotheses that are close to the null hypothesis, so-called local alternatives. The idea is that, in large samples, any reasonable test can detect a large departure from the null hypothesis, so tests should be designed to perform well against local alternatives. The situation is different in a sensitivity analysis. Large departures from the null hypothesis are of interest even in large samples, because only large departures are insensitive to hidden bias . An open area for research is the development of best tests for use in sensitivity analysis. For the most part, this chapter discusses traditional test statistics which , at least , are known to perform well in the absence of bias , that is, when
r=1.

4.4.4 Case-Referent Studies with Multiple Matched Referents

In the study of DES and vaginal cancer in Chapter 1, eight women with

vaginal cancer, that is, eight cases, were each matched to four women with-

out the disease , that is, four referents, and the cases and referents were

compared in terms of their frequency of prenatal exposure to the treat-

ment , DES . This study design, a case-referent study with several referents

matched to each case, is quite common. If a disease or other outcome is

rare, it may be difficult to locate additional cases, but referents may be

plentiful; hence the tendency to match several referents to each case .

Note the difference between the study designs in §4.4.2 and 4.4.4. In

matching with multiple controls in §4.4.2, each matched set contained one

treated subject and several untreated controls, so m.; = 1 = I:7~1 Z si

for each s, but the design imposed no restrictions on the outcomes in a

matched set . In a study in which cases are matched to several referents,

matched set s may contain any number of treated subjects, that is, m.; can

be 0, 1, . . . , or ns ; however, each matched set contains exactly one case, so

1 = I:7~1 R si . In §4.4.2, D s contained n s possible treatment assignments

C:.:) so the distribution of treatment assignments (4.6) had the simple form

(4.15), but in a case-referent study, Ds contains

possible treatment

assignments, and (4.6) does not simplify further .

The null hypothesis of no treatment effect says that the binary indicator

of a case of disease, R si, is unaffected by the treatment Z si , so R si is a

constant r si that does not change with Z si ' The common test of no treat-

ment effect is the Mantel-Haenszel statistic, which is a sign-score statistic

4.4 Sensitivity Analysis for Sign-Sco re Statistics 125

with ds = 1 and Csi = Tsi' so the statist ic (4.14) is the number of cases
exposed to the t reatment, na mely, T = I:~= l I:7~1 TsiZ si = I:~=l Bs' where B; = I:7~1 TsiZsi · Since each matched set contains one case in a
case-referent st udy, B ; equals zero or one, as in §4.4.2. Recall that in Prop osition 14, the distribution of the t est statist ic T is
bounded by the distributions of T+ and T- obtained by ass uming u = u "
or u = u ". Since T = I:~=l B ; in matched case-referent st udies, these
bounds may be obtained usin g the following bound s on Ps = proh (B, = 11m} at u = u " or u = u "

Ps

=

ms

+

ms (n s -

ms)r

<
- Ps

<
-

msr

+m(snrs

-

=p+
m s) s

for all u E U.

(4.19)

For the derivation of (4.19) , see Problem 6. If there is no treatment effect
and no hidden bias, so r = 1, then Ps = Ps+ = Ps- = ms/ns; thi s says
the chance the case was exp osed t o th e treatment equals the proportion
of sub jects in the matc hed set who were exposed to t he treatment. Note
t hat (4.17) and (4.19) are similar in form but different in det ail. The lar ge
sample approximations to the bounds on t he significance levels for the
Mantel- Hae nsze l statist ic are obtained by referr ing the deviates,

IT- I:Ps+I- !

and

IT - I: Ps-! - !

VI:P;(I-P; }

VI: Ps- (1 - Ps- } ,

(4.20)

to t ables of the standard normal distribut ion. As with (4.18), these two
devi at es are equal if hidden bias is abse nt, in the sense that r = 1, and in
this case their sq uare is the usu al Mantel- Hae nszel statist ic. T hese com-
put a t ions are performed for five st udies in §4.4.5. This illustrates the com-
putations and gives an indication of t he varied result s t hat a sensit ivity a nalysis may produce.

4.4.5 Matched Case-Referent Studies: Five Examples
Recall from Chapter 1 that in the case-referent st udy by Herbst , Ulfelder, and P oskanzer (1971) of DES and vaginal cancer, each of eight cases of vagin al cancer was mat ched to four referent s using d ay of bir th and typ e
of service, ward or pri vat e. Table 4.8 contains t he data together wit h some
of t he calc ulations for t he sens it ivity ana lysis.
In Table 4.8, t here are S = 8 mat ched sets, S = 1, . . . , 8, each containing
one case and four re ferents. In seven matched sets, exactly one patient had
in utero exposure to DES, t hat is, m s = 1, but in set s = 5 there were
no exposures t o DES, m s = O. In all of t he seven matched sets, it was t he case who was exposed to DES , t hat is, B ; = 1 for s =I- 5. The relatio nship
between DES a nd vagina l cance r appears to be extremely strong, though

126 4. Sensitivity to Hidden Bias

TABLE 4.8. DES and Vaginal Cancer: Dat a and Computations.

Ps- = P;- Ps- for Ps+ for
s Bs m s for r = 1 r = 2 r = 2

1 11

0.20

2 11

0.20

3 11

0.20

4 11

0.20

5 00

0.00

6 11

0.20

7 11

0.20

8 11

0.20

0.11 0.33 0.11 0.33 0.11 0.33 0.11 0.33 0.00 0.00 0.11 0.33 0.11 0.33 0.11 0.33

Tot al 7 7

1.40

0.78 2.33

of course t here are only eight cases . The one ma t ched set with no exposed patients is concorda nt , and it could be removed wit hout changing t he value
of t he statistics in (4.20).
To test t he null hypothesis of no effect, suppose for t he moment t hat
DES does not cause vaginal cance r. Consider one of the seve n matched
sets wit h n s = 5 patients of whom m.; = 1 was exposed to DES. If the st udy were free of hidden bias, so r = 1, then each of the five patients
has the same chance of being exposed, so the chance that t he one exposed
patient is the case is 1/5 or 0.20, as in Table 4.8. T his wou ld lead us to expect 1.40 = 7 x 0.20 cases to be exposed to DES, though, in fact , T = 7 cases were exposed, with a variance of 7 x 0.20 x 0.80 = 1.12, a nd
a deviate of (17 - 1.41- 4)/JIJ2 = 4.82, whose square 4.822 = 23.2 is
the usual Mantel-Haenszel statistic. If the study were free of hidden bias , there would be st rong evidence t hat DES causes vaginal cancer. If hidden
bias were present to t he extent that matched subjects might differ in t hei r
odds of exposure to DES by a factor of two , so r = 2, then the chance t hat
the case was exposed to DES might be as low as m s/{ms + r(ns -ms)} =
1/(1+ 2 x 4) = 0.11 or as high as r m s/{rm s+ (n s- m s)} = 2/(2+4) = 0.33,
so the expected number of exposed cases mig ht be as low as 7 x 0.11 = 0.78 with vari an ce 7 x 0.11 x 0.89 = 0.69, or as high as 7 x 0.33 = 2.33 with variance 7 x 0.33 x 0.67 = 1.56, whe reas seven exposed cases were observed. For r = 2, the deviat es in (4.20) are

_(1_7 -_2--.==33=-1-_=--~) = 3.34 and
) 1.56

4) (17 - 0.781-

I"i'\N\

= 6.88,

vO.69

yielding a range of sign ificance levels from less than 0.0001 to at most
0.0004. A hidden bias of magnitude r = 2 cannot reasonably explain the
strong association seen between DES and vaginal cancer. Table 4.9 gives
resu lts for other values of r . Only beyond r = 7 is hidden bias a plausible

4.4 Sensitivity Analysis for Sign-Score Statistics 127

TA BLE 4.9. Sen sitivity An alysis for DES and Vaginal Cancer.

r Deviate- Deviat e"

Range of signifance
levels

1 4.82 2 6.88 4 9.78 6 12.00 7 12.96

4.82 < 0.0001 3.34 < 0.0001 to 0.0004 2.27 < 0.0001 to 0.012 1.77 < 0.0001 to 0.038 1.61 < 0.0001 to 0.054

exp lanation of the association between DES and vaginal cancer. The hidden bias would need to create a sevenfo ld increase in the odds of exposure to DES.
Table 4.10 compares the sensitivity of five matched case-referent studies. The purpose of the t able is to gain some insight into the variety of results a sen sitivity analysis may produce. The study of DES and vaginal cancer by Herbst et al, (1976) has just been discussed. T he study by Mack et al. (1976) compared each of S = 63 cases of endomet rial cancer to four referents matched for age and marital st at us. Cases and referents, who had been drawn from a large retirement community, were compared with respect to use of estrogens. The data are given in the detailed form needed for computations in Breslow and Day (1980, §5.3).
Jick et al. (1973) studied coffee consumption and myocardial infarction in white patients aged 40 to 69 years who were not alcoholic. Matching on age, gender , history of myocardial infarction, smoking, time of entry into the st udy, and hospital, they formed 27 matched pairs and 88 matched sets with two referents. This portion of the study included on ly subject s who either drank zero cups of coffee per day or at least six cups of coffee per day.
The st udy by Kelsey and Hardy (1975) examined the relationship between acute herniated lumbar disc-a back injury-and driving a truck as an occupation. They matched cases of herniated lumbar disc in New Haven to referent s of the same gender, age, and hospital service or radiologist 's office. Each case was matched to a single referent , and there were S = 128 matched pairs.
The st udy by Trichopoulos et al. do es not appear to have been published. It is described onl y briefly by Miettinen (1969) . It concern ed prior induced abortion as a risk factor for subsequent ectopic pregnancy. A total of 18 cases were each matched to five referents.
Table 4.10 gives the upper bound on the significance level, the lower bound being highly significa nt in all cases in the table. The tab le shows that the five studies are quite different in their sensitivity to hidden bias.

128 4. Sensitivity to Hidd en Bias

TABLE 4.10. Comparison of the Sensitivity of Five Matched Case Control Stud-
ies: Upper Bounds on the Significance Level for Several Values of r .

r
DES and vaginal cancer Herbst et al. (1971),
ns = 5
Endometrial cancer Mack et al. (1976),
ns = 5
Coffee and MI Jick et al. (1973),
ns = 2 or ns = 3
Ectopic pregnancy Trichopoulos , et al., as in Miettinen (1969),
ns = 5
Herniated disc Kelsey and Hardy (1975),
ns = 2

1
< 0.0001 < 0.0001
0.0038
0.0001
0.0057

2 0.0004 0.0004
> 0.2
0.0066
0.093

3 0.0038 0.013
0.0301 0.24

4 0.012 0.068
0.0668

4.4 Sensitivity Analysis for Sign-Score Statistics 129
Least sensitive is the study of DES and vaginal cancer, despite its small size, because of the strong association between treatment and outcome seen in the data in Table 4.8. To attribute this association to an unobserved covariate, one must postulate a covariate with a dramatic relationship with both exposure to DES and vaginal cancer.
Most sensitive is the study of coffee and myocardial infarction, where the upper bound on the significance level exceeds the conventional 0.05 for all I' ~ 1.3. An unobserved covariate strongly related to myocardial infarction but only weakly related to coffee consumption could explain the observed association, despite the small significance level of 0.0038 for the usual Mantel-Haenszel statistic. Coffee may, in fact , cause myocardial infarctions, and this study may be free of hidden biases ; however, fairly small biases, too small to easily detect, could readily explain the observed association.
The studies of endometrial cancer and of ectopic pregnancy are about equally sensitive to bias. The former study is more than three times larger, but the latter exhibits a stronger relationship between treatment and outcome.
Sensitivity to hidden bias is an aspect of the conclusions of an observational study, an aspect relevant to causal interpretation. However, sensitivity to hidden bias is not a fault of a study or its authors, as insensitivity to bias is not an accomplishment.
The study of herniated lumbar discs is different from the others in its structure, and a slightly different sensitivity analysis was performed. That study distinguished three types of cases:
(i) surgical cases, in which records indicate the herniated disc was seen by a surgeon during surgery;
(ii) probable cases, having the same symptoms as surgical cases but without an explicit record that a surgeon saw the herniated disc; and
(iii) possible cases, having some but not all of the symptoms of a herniated disc.
To give greatest weight to the surgical cases, numerical scores were assigned to each matched pair, specifically score ds = 3 was assigned to pairs with a
surgical case, score ds = 2 was assigned to probable cases, and score d; = 1
was assigned to possible cases. Set Csi = 1 for cases and Csi = 0 for referents.
Then the sign-score statistic T = l:i l:s d, CsiZsi is the total of the case
scores for matched sets in which the case was exposed to the treatment, specifically, the total of the case scores for matched pairs in which the case was a truck driver. The upper bounds on the significance level are obtained

130 4. Sensitivit y to Hidd en Bias

TABLE 4.11. Allopurinol a nd Rash .

Zli

Males, s = 1

Allopurinol Other

rli Rash cases

s 36

Non cas es

33 645

Z2i

Females , s = 2

Allopurinol Other

r2i Rash cases

10 58

Nonc as es

19 518

nl = 719 ml = 38 rl+ = 41
n 2 = 605 m2 =29 r2+ = 68

using the deviates

IT

-"L'\J'

d

s

p+
s

j

_2l

and IT - 2: dsPs- I- !
V2: d;Ps- (1 - pn'

(4.21)

which generalize the Mantel-Haenszel deviates in (4.20) to the case where
ds =I- 1 for some s. (The cont inuity correction should only be used if the
scores ds are integ ers, as is true in this example.)

4.4.6 The 2 x 2 x S Contingency Table
Table 4.11 concern s a case-referent study of the possibl e effects of the drug allopurinol as a cause of rash (Boston Collaborative Drug Surveillance Program 1972). The table has two strata, males and females. Her e, r si = 1 for a case of rash , r si = 0 for a referent, Z si = 1 for use of allopurinol, Z si = 0
otherwise, and r s+ = 2:irsi is the number of cases in st rat um s. T he
Mantel-Haenszel statistic, as discussed in §2.4.3, is based on the number of
cases who used allopur inol, namely T = 2:s 2:i Z sir si = 5 + 10 = 15. If al-
lopurinol had no effect, then in a randomized experiment or in the absence of hidden bias, T would have expectation 5.43 and variance 4.70 , yielding
a deviate of (115 - 5.431- !)/J4.70 = 4.19, with an approximate one-sided
significan ce level less than 0.0001. In a randomized expe riment or in the absence of hidden bias , Table 4.11 would const it ut e strong evid ence that allopurinol causes rash.
The procedure for conducting a sensitivity analysis for the MantelHaenszel statistic is as follows. The exact bounds are provided by Corollary 16, and the large sample approximation that follows is developed in the ap-
pendix, §4.7.4. Determine the unique root Es of the quadratic equation
(4.22)

4.4 Sensitivity Analysis for Sign-Score St atistics 131

(-2- )-1 + + V =

s

Es

1_ Ts+ - Es

1_+

1

_

m s - Es ns - Ts+ - m s + Es

(4.23)

and refer the deviate (IT - I:: Esl - ~)/ VI:: VS to tables of the standard
normal distribution. Repeat with r replaced by l/r to determine the other
bound on the significance level.
To illustrate, for r = 2, 8 = 1, equation (4.22) is

Er(2 -1) - Ed(2 -1)(38 +41) + 719} + 2 x 41 x 38 = a

or

E-

2 1

-

789E- 1 + 3, 116 = 0,

with roots 794.08 and 3.92, of which the correct root is E1 = 3.92 since
max(O, 41 + 38 - 719) = a ~ 3.92 ~ 38 = min(41,38) . Substituting E1 =
3.92 into (4.23) yields VI = 3.20. In the same way, E2 = 5.66, V2 = 4.21,
and (IT - I:: Esl- ~)/ VI:: VS = (115 - 9.591- ~)/J7.41 = 1.80, giving an
upper bound on the one-sided significance level of 0.036.
Computed in this way, the upper bounds on the significance levels from
Table 4.11 for r = 1,2, and 3 are 0.0001, 0.036, and 0.30. The study is
insensitive to a bias that would double the odds of exposure to allopurinol
but sensitive to a bias that would triple the odds . It is mor e sensitive to
bias than three of the five st udies in §4.4.5 and less sensitive than th e other
two.
When u = u" and the treatment has no effect, expressions (4.22) and
(4.23) yield , respectively, large sample approximations to the expect at ion
and variance of the upper left corner cell count in the st h 2 x 2 table,
namely I::i Zsi Tsi· A detailed derivation of (4.22) and (4.23) is given in the
Appendix to this chapter.
The approximate exp ectation (4.22) and variance (4.23) are appropriate
when each marginal total of table 8 is large , that is, when m s , n s - m s , T s+ , and n s - T s+ are each large. If table 8 has a small marginal total, the
exact moments of I::i Z siTsi may be used in place of the approximations.
The exact expectation and variance are

",min(m..r . + )

t(r.,+) (n,-r'+)rt

E _ L....t=max (O,m . +r.,+-n. ) t m .,- t

s - ",min(m..r . + )

(r.,+) ( n .-r .,+)rt

L.... t=max (O,m . +r. +-n . ) t m .,-t

(4.24)

and

132 4. Sensitivity to Hidden Bias

TABLE 4.12 . Comparison of Resu lt s Using Exact and Approximate Moments of T.

r

Expect ation Variance Deviat e

1 Exact

5.43

Approximate

5.43

4.70

4.19

4.69

4.19

2 Exact

9.60

Approximate

9.59

7.44

1.80

7.41

1.80

3 Exact Approximate

12.97 12.94

9.17

0.51

9.13

0 .52

= r m sTs+ -

{ns - (rn, + Ts+)( l
(1 - I' )

-

r)}Es

-

-2
E s'

(4.25)

As an example of a table wit h small counts, suppose n s = 8, m s = 4, and T s+ = 3. For I' = 2, the exact moments in this hypot het ical table are Es = 1.87 and Vs = 0.52, while t he approximations are Es = 1.82 and ~ = 0.45. In this case, the exact expectation in (4.24) is the sum of
four terms, name ly, from t = 0 = max(0,4 + 3 - 8) to t = min(4,3) = 3.
(Exp ression (4.25) is derived from an observation of Johnson, Kotz, and
Kemp (1992, p. 280, expression (6.160)) .)
Ret urn ing to t he case-referent study of allopurinol and rash, Table 4.12
compares t he calculat ions based on t he exact and approximate moments of T . In t his example, t he approximation is quite satisfacto ry.
T he sens it ivity analysis for binary responses has an int imat e connection with setting confidence limits for an odds rati o in a 2 x 2 x S contingency table, so a program such as Cytel Corporation's StatXact can do certain
sensitivity calculations. This link has not been stressed in this chapter
because it does not apply with outcomes that are not binary.

4.4.7 Comparing Rates in a Treated Group to a Population of Controls
Some observational st ud ies compare a treated group of finite size to a control group that is, in effect, infinite in size, t hat is, a control group in which sampling var iability is negligible. This is particularly common in studies in occupational health, where t he mortality in an industry is often compared to mortality rates for the nation as a whole . For instance, in a study of the hazards of asbestos, Nicholson , Selikoff, Seidman, Lilis, and Formby (1979) studied a treated group consisting of 544 male miners of chrysotile asbestos at the Thetford Mines in Quebec. All had been miners for at least 20 years as of 1961, and the ir mortality between 1961 and 1977 is under st udy.

4.4 Sensitivity Analysis for Sign-Score Statistics 133
These 544 miners were observed for a total of 7408 years; that is, there were 7408 person-years of observation. The control group was constructed from the mortality experience for all males in Canada. By reweighting national mortality rates that were specific to age, gender, and cause of death, the investigators computed mortality rates for a constructed population of Canadians having the same distribution of ages and the same number of years of observation as the 544 miners . For instance, they found that the constructed population would have a mortality rate of 0.01232 from noninfectious pulmonary diseases other than cancer, so 544 individuals selected at random from this constructed population would be expected to
have 0.01232 x 544 = 6.70 deaths from this disease. Because of the enor-
mous size of the population of Canada, this mortality rate is effectively free of sampling variability; however , since miners may differ from the typical Canadian in terms of covariates other than age, the rate may be affected by hidden biases. In fact, the 544 miners experienced 30 deaths from non-
infectious pulmonary diseases other than cancer, or 30/6.70 = 4.48 times more than expected. The ratio 30/6.70 = 4.48 is called the standardized
mortality ratio. In the absence of hidden bias, the usual test of no tre atment effect views the 30 deaths as either a binomial count with probability 0.01232 and sample size 544 or as a Poisson count with expectation 6.70; see, for instance, Armitage (1977, p. 389), Gastwirth (1988 , §10), Mosteller and Tukey (1977, §llE), or Hakulinen (1981) . The binomial test may be viewed as asking whether the 544 miners look like a random sample of size 544 from an infinite population with rate 0.01232 .
A small change in the method in §4.4.6 for 2 x 2 tables addresses the infinite sample size in the control group . The large sample argument in §4.4.6 assumed that the margins, m s,ns - m s,Ts+,ns - Ts+, of each 2 x 2 table were large , with all margins increasing at about the same rate. When comparing 544 miners to a reweighting of all of Canada, a more realistic asymptotic argument assumes that m s = 544 is fixed, n s --+ 00 , with Ts+/ns --+ (s = 0.01232 . At u = u" under the null hypothesis of no effect, L i ZsiTsi is asymptotically binomial with sample size m s and probability
see the appendix, §4.7.4, for proof. If there is no hidden bias , then I' = 1 and V s = (s' leading to the usual binomial distribution for Li Z siTsi. With
T = L s Li z.s.; the deviate is
IT - Lmsvsl- ~
JLm sv s(l-vs)
For the bound at u = u ", the same calculation is performed with l/f in plac e of I'; see the appendix, §4.7.5. Gastwirth and Greenhouse (1987)

134 4. Sensit ivity to Hidden Bias

TABL E 4.13. Sensitivity Analysis for t he Asb est os Miners ' Standard ized Mor t ality Rat io.

r

vI

vimi Deviate

1 0.01232 6.70 8.86 2 0.02434 13.24 4.52 3 0.03607 19.62 2.27 4 0.04752 25.85 0.73

perform a similar calcul ation start ing from the inequality of Cornfield et al. (1959) .
In the example, there is one stratum, S = 1, and mi = 544, (= 0.01232. Table 4.13 gives the sensitivity analysis for the upper bound on the signifi-
cance level. In the abs ence of hidden bias, r = 1,6.70 deaths were expected,
the deviate is 8.86 with significance level less than 0.0001 , and the stan-
dardized mortality ratio is 30/6.70 = 4.5. A bias of magnitude r = 2
could raise the expected number of deaths to 13.24, though the observed 30 deaths ar e significantly more than 13.24, yield ing a deviate of at least 4.52, a significance level less than 0.0001, and a standardized mortality ra-
tio of at least 30/13.24 = 2.3. This study is less sen sitive to bias than the
studies of allopurinol in §4.4.6 or coffee in §4.4.5, but it is more sensitive than the st udies of smoking in §4.3.2 or lead exposure in §4.3.3.
4.4.8 Other Sign-Score Statistics: Censored Data, Median Tests
All sign-score st at ist ics permit a sensitivity analysis based on Proposition 14. Sections 4.3 and 4.4 have pr esented details and examples for methods that are widely used. This final part of §4.4 briefly mentions several other sign-score statistics that are useful in particular situations.
(i) Censored Survival Data in Matched Pairs. When the outcome is the time until a particular event occurs, it may happen that for some individuals the event has not yet occurred at the time the data ar e analyzed, in which case the outcome is censored . This is often true in studies of human survival , in which some individuals are alive at the end of the study. It is also often true in studies that compare the effectiveness of various punishments for criminal acts, in which the out come is the time until the act is repeated. O'Brien and Fleming (1987) propose and evaluate their Prentice-Wilcoxon stat ist ic for censored survival times in matched pairs. This statistic may be written as a sign-score statistic, so the sensit ivity analysis follows directly from the general pro cedure in §4.4.2 with each n s = 2.

4.5 Matching with Multiple Controls and Continuous Responses 135
(ii) Median, Quantil e, and Sign Tests. In comparing treated and cont rol groups, the median test combines the groups, finds the median of th e combination, and asks how many treated subjects have responses above the combined median. Though inefficient for responses obtained from a Normal distribution, the median test has good prop erties in large samples for data from a distribution more prone to extreme observations, specifically the double exponential distribution; see Hajek , Sidak and Sen (1999, §4.1, p. 97) or Hettmansperger (1984, §3) for detailed discussion. The median te st is usually attributed to G. Brown and A. Mood. See also §5.3.
Other quantiles are sometimes used in place of the median. A version of the median test was used in §4.4.3 for matching with multiple controls. In pair matching, the median test becomes th e sign test. The median test , the stratified or matched medi an test , the sign test , and other quantile tests are all sign-score tests.
4.5 Matching with Multiple Controls and Continuous Responses
4.5.1 A Simple, Effective Research Design
Matching with continuous responses and multiple controls is a simple research design that is often more effective than other simple designs, such as pair matching or stratification, and yet is it not widely used. Several of the statistical methods for matching with multiple controls, such as the aligned rank test of Hodges and Lehmann (1962), are also simple to use and highly effective, and yet they too are much less widely known than their close relatives, the signed rank test and the rank sum test. Before discussing procedures in detail, some motivation for this good choice of design is needed.
In matching with multiple cont rols, each treated subject is matched
to one or more controls, so m s = 1, ns 2: 2, for s = 1, . . . ,S. When
controls are easily available and inexpensive, the use of more than one cont rol for each treated subject often increases the precision of estimates and the power of tests. At the same time, matching can ensure that treated and control groups are balanced with respect to observed covariates, while entirely excluding from the comparison potential controls who are unlike virtually all treated subjects.
For example, in a study of effective management of nursing at hospitals, Smith (1997) compared three versions of matching: matching with 1 control hospital, n s = 2, matching with 8 control hospitals, ns = 9, and
matching with 15 control hospitals, ns = 16. In this one particular data
set, Smith (1997, p347) found that matching with 8 controls yielded substantially smaller standard errors than matching with 1 control , but the

136 4. Sensitivity to Hidden Bias
bias in observed covariat es was not greatly increased . On the other hand, Smith also found th at matching with 15 controls was only slightly better than matching with 8 controls in terms of standard errors, and was much worse in terms ·of comp arability on observed covariates. See also Aiken, Smith, and Lake (1994) for results linking nursing management and hospital mortality.
Matching with a variable number of controls, so that n., varies with s , can remove substantially more bias in observed covariates than matching with
a fixed number of controls, when studies of equal total sample size L n s are
compared. Moreover , the loss of precision from letting n s vary with s is often quite small. See Ming and Rosenb aum (2000) for detailed discussion. The optimal design for an observational study is a "full matching," which is a generalizat ion of matching with multiple controls (Rosenbaum 1991c, Gu and Rosenbaum 1993). These issues are discussed in some det ail in Chapter 10.
4.5.2 General Method
In the case of sign-score statistics, such as Wilcoxon's signed rank test or the Mantel-Haenszel test , it was possible to bound the distribution of the test st at ist ic, T , by two known distributions for random variables T+ and T- . This is not possible in general. However, for matching with multiple controls, it is possible to find two approximate bounds for tail probabilities, the approximation being quite good when the number of matched sets S is large. The general method is developed by Gastwirth, Krieger, and Rosenbaum (2000). The und erlying idea is quite simple. If, as a consequence of the central limit theorem, T is asymptotically Normal as S ~ 00 , then its limiting Normal distribution is characterized by its expectation and variance. If one cannot find a distribution that provides an upper bound on the chance that T ~ k, perhaps instead one can find the limiting Normal distribution that maximizes the chance that T ~ k. Here, k is some critical value in the upper tail of the distribution, so it is above the expectation of T. As intuition suggests, the limiting Normal distribution that attaches the greatest chance to T ~ k has the largest possible expectation for T, and among distributions with thi s largest possible exp ectation, it is the distribution with the largest variance. The demonstration that this intuition is correct is straightforward, but lengthy, and the interested reader should turn to Gastwirth, Krieger and Rosenbaum (2000) for the proof and for minor regularity conditions. A key aspect of the proof is that, as S ~ 00, maximizing the expect at ion is more important than increasing the variance, whereas for finite S this may not be the case . Here , the simple procedure is described, and then discussed for two common tests, the stratified Wilcoxon rank sum test and the aligned rank test of Hodges and Lehmann (1962). Tests are discussed first, then inverted to obtain

4.5 Matching with Mul t iple Controls and Continuous Resp onses 137
confidence intervals, a nd the device of Hodges and Lehmann (1963) yields point estimates.
In matching with multiple controls, 1 = m s = 2::7':'1 Z si for each sand
the distribution of treatment assignments is given by (4.15). Let qsi be a fixed score ass ocia te d with t he ith subject in stratum s , and consider the
dis t ribut ion of the statistic T = 2:::=12::;::'1 Zsiqsi' The expectation and
vari an ce of T ar e then :

and

{ t var (T lm ) =

2::~7Lq;i eXP(Tusi)} - {E(Tlm)}2 ,

s=1 2::i=1 exp (TUSt )

and these are unknown becau se Usi is unknown. For notational conveni ence, within each matched set, renumber the n s
subject s, i = 1, ... , n s , so the qsi ar e in nondecreasin g order , qs,n. :::: . .. ::::
qsl ' Let a be an int eger , 0 < a < n ., and consider the contribut ion
2::;::'1 Z siqsi to T from matched set s when Usl = 0, .. . , Usa = 0, Us,a+l =
1, . .. , Us ,n. = 1. At this value of the Usi, the expect at ion and variance of
2::7':'1 Z siqsi are , resp ectively

2::~=1 qsi + f 2::;::'a+l qsi

fLsa =

a + I' (n s - a )

and

V

2
sa

--

"L..,. ia=1

2
qsi

+

I'

"L.,..in=. a+ l

2
qsi

2

a+ f(ns - a)

- "It-sa'

Let the maximum of these a expec tat ions be

fLs = O<maa<xn. fLsa'

and let A s = {a : fLsa = fLs} be the set of values of a giving rise to this
maximum expectation. Proposition 9 in the appendix shows that fL s is the
maximum expectation of 2::7':'1 Z siqsi' Let

2 Vs

=

max
aEA ,.

v2s a

'

V; so is the maximum variance among a's giving n se to the maximum
expec tat ion. If t > 2:: fL s' then approximate the upp er bound on the tail
pr obability, prob (T :::: t im) , by

138 4. Sensitivity to Hidden Bias
where ~ (.) is the standard Normal cumulative distribution. Under regularity conditions, Gastwirth, Krieger , and Rosenbaum (2000) show that t his approximate upp er bound converges to the correct , shar p upper bound on the tail probability as the number of matched set s increases , S -> 00. If
2:: J.Ls 2: t , then the upp er bound on prob (T 2: t im ) is at least ~ . The upper
bound on the opposite tail area, prob (T :S t im) , is obtain ed by minimiz-
ing th e expected contribution s to T , and maximizing the variance among expect ed contributions that produce the same minimum exp ect ation; see Problem II.
Und er the model of an additive treatment effect , rTs i = rc« + T , the
hypothesis H o : T = T O is test ed by applying the above pro cedure to the adjusted responses , Rsi - T OZsi. A confidence interval is formed by testing each T O and retaining the values not reje cted by the t est.

4.5.3 Stratified Wilcoxon Rank Sum Test

In th e stratified Wilcoxon rank sum test, q s i is the rank of Rs i when the respon ses of theri, subjects in matched set s ar e ranked from 1 to ns , with avera ge rank s for t ies. Then T is the sum of the ranks for the S
treated subjects. With mat ched pairs, ns = 2, the st rat ified rank sum
test is equivalent to the sign test , which is inefficient for Normal data, but

fairly efficient for some distributions with longer t ails. For Normal data,

t he performance of th e st rat ified rank sum test improves as n s increases ;
see Hodges and Lehmann (1962).
When there are no ties, th e ranks ar e just 1, .. . ,ns , and J.Ls and v;
can be tabulated, saving some arit hmet ic. Table 4.14 is from Gastwirth,

Krieger, and Rosenbaum (2000). With this t abl e, the calculat ions ar e ele-

ment ary arithmetic. If one is conduct ing a sensitivity analysis with I' = 2,

and matched set s is an untied matched triple, one treated and two con-

n v; tr ols, s = 3, th en from th e
such terms gives th e required

= t able, J.Ls
expect at ion

~ and =
and variance.

~i . If

Summing
2:: J.Ls 2: T

S
=

2::;=1 2:: ~1 Z siqsi th en th e upp er bound on the one-sided significance level

is at least ~; otherwise,

is compared t o the standard Norm al distribution to approximate the upper bound on the significance level. The minimum Hod ges-Lehmann est imate is obtained by computing T from R si -TOZs i , and finding the value T O that
equates T to the maximum expectat ion 2::;=1 J.Ls .

4.5 Matching with Multiple Controls and Continuous Responses 139

TABLE 4.14. Extreme Moments for the Stratified Rank Sum Statistic .

n s r JLs

V

2
s

2 1 3/ 2

1/ 4

2 5/3

2/ 9

3 7/ 4 3/ 16

4 9/5 4/ 25

31 2 2 9/4 3 12/ 5 4 5/2

2/3 11/ 1 6 16/ 25 7 / 12

4 1 5/2 2 17/6 33 4 22/7

5/4 41/36 4/3 62/49

51 3

2

2 24/ 7 96/49

3 11/ 3 16/9

4 42/11 194/121

4. 5.4 Aligned Rank Test
In t he aligned rank test of Hodges and Lehmann (1962), ranks qsi from
1 to N = nl + . . . + ns are assigned to t he N aligned responses, rsi -
(l/ ns ) 'Lj::l rsj , for med by subtracting t he mean of the n s responses in
each matc hed set s . In matched pairs, the aligned rank test is sim ilar to W ilcoxon's signed rank t est , and is more efficient wit h Normal data than t he stratified rank sum test; see Leh mann (1975) for detailed discussion.
v; , Because t he ranks within one matched set now depend on the responses in
ot her matched sets, it is no longer possible to tabulate JLs and and a
little more arithmetic is req uired . When testing the hypothesis H o : T = TO under the model of an additive treatment effect, rTsi = r c si + T , one
computes adjusted responses, Rsi - TOZsi , which equal rca under the null hypot hesis, and then aligns t hese adjusted responses. A numerical example is given by Gastwirth, Kr ieger , and Rosenb aum (2000) .

140 4. Sensitivity to Hidd en Bias
4.6 Sensitivity Analysis for Comparing Two Unmatched Groups

4.6.1 ~Vhy Is There a Difference Between Sum Statistics and Sign-Score Statistics ?

Thi s sect ion discusses the sensit ivity analysis for stat ist ics T , such as the
rank sum statistic, Gehan's stat ist ic, or the log-rank st atistic , used to com-
pare unmatched treated and cont rol groups. Here, there is a single stratum,
S = 1, so the subscript s is omitted , and m = L Z i. As defined in Chapter
2, a sum st a t ist ic has th e form

n
T= LZiqi ,
i =1

(4.26)

where the qi are functions of the responses and so are fixed under the null hypothesis of no treatment effect. For instance, in Wilcoxon's rank sum st at ist ic, the qi are the ranks of the responses Ti , and T is the sum of the ranks in the treated group.
The sensitivity analysis for sign-score statistics in §4.2 and 4.3 and for sum statistics in the current section are similar in cert ain ways and different in others. They are identical in interpretation and similar in their broad outlines, but they differ in an important detail of implementation. In Proposition 14, the distribution of the test st at ist ic T is bounded at all points "a" by the distributions of two other random variables, T + and T- , which are obtained from the distribution (4.6) at two points u " and u " . In cont ras t , with sum st atisti cs, there is a point u+ E U that provides an
upp er bound on the probability prob(T 2: aim); however, the point u"
changes as "a" changes. This distinction has a noticeable effect on calculations , but no effect on the interpretation of the sens it ivity analysis.

4.6. 2 Sensitivity Analysis for Sum Statistics: The General Method
L This section obtains bounds on the behavior of a sum statistic T = Ziq i
under the null hypothesis of no treatment effect. Specifically, bounds are
obtained for the tail area or significance level prob(T 2: aim) and for the
expectation E(T) . These are the basis for the sensitivity analysis for significan ce levels, confidence intervals, and point estimates. For this purpose, in §4.6.2, assume that the null hypothesis of no treatment effect holds, and
that I' 2: 1. Renumber the n subjects so that ql 2: q2 2: ... 2: qn' Since
no quantity depends on the numbering of the n subjects, this is just a notational convenience.
The maximum value of prob(T 2: aim) from model (4.6) with u E U
is found at point u of the form Ul = = 1, U 2 1, ... , U k = 1, Uk+l =

4.6 Sensitivity An alysis for Comparing Two Unmat ched Gr oups 141

0, Uk+2 = 0, . .. , un = 0, that is, at a point whose coordinates consist of k
ones followed by n - k zeros for some number k. Let U+ be the set of all such u , for k = 0,1 , . .. , n . Similarly, the minimum value of prob(T ~ aim) is found at a point whose coordinates are k zeros followed by n - k ones
for some k. Write U- for the set of all such points. The value of k may change as "a" is changed. The maximum and minimum values of E(T) are also found at points of, respectively, U+ and U - . These facts are proved
in the appendix to this chapter, specifically in §4.7.3.
For a given u , let JLu and au be the expectation and standard deviation of T . Exact expressions and easily calculated approximations to J.Lu and a u ar e discussed shortly. The bounds on E (T) are then

min
uEU-

J.Lu

~

E ( T lm)

~

max
u EU+

J.L

u

·

(4.27)

Large sample approximations to the bounds on prob(T ~ aim) are obtained by referring the standardized deviates ,

max a-J.Lu

and

m. ma--J.-L-u ,

uEu- au

uEu+ au

(4.28)

to tables of the standard normal distribution. The effort required to compute the maximum and minimum in (4.28) is of the same order of magnitude as computing the rank sum statistic 2n tim es, an easy task with a computer.

4.6.3 Expectation and Variance of T
To use (4.27) and (4.28) for inference, one needs the moments J.Lu and au of T when u has k coordinates equal to 1 and n - k coordinates equal to O. The current section discusses exact moments and the next section discusses large sample approximations. As is often true with continuous approximations to discrete distributions, the exact calculations use only elementary probability theory and somewhat more arithmetic, while the approximations use asymptotic theory and less arithmetic. The exact calculations are easily programmed in, say, S+, while the approximations involve solving a quadratic equation and can be done in a spreadsheet. Although the approximations perform well and are sometimes convenient, the formulas provide no insight, so the sections describing the approximations are marked with an asterisk indicating these sections may be skipped.
Fix a u with k coordinates equal to 1 and n - k coordinates equal to O. For this u, write

and

142 4. Sensitivity to Hidden Bias
Notice carefully that (}ii = (}i' In words, given that m subjects were treated, the chance that subject i was treated is (}i and the chance that both subject i and subject j were treated is {!ij' Expressions for {!i and {!ij
are given soon . Now J.Lu = E (L Ziqi) = L «e.. Also,
so

In other words , the needed moments are simple functions of the probabili-

ties, (}i and {!ij '
To find {!i = prob (Zi = 11m), the probability (4.6) with S = 1 must be

summed over all zEn such that Zi = 1. Remember that Ui = 1 for k

subjects and Ui = 0 for the remaining n - k subjects. Write

(k) ( k) min(m,k)

(n,m,k) = Lexp(,zTu) =

L

a :~a r-

zEn

a=max(O ,m+k-n)

and define «n, m , k) = 0 if either m < 0 or k < O. Now (n, m , k) is the denominator of (4.6) with S = 1. Moreover,

exp (-yUi ) ( (n - I,m -1, k - Ui)

(},o =

(n,m ,k)

.

In parallel, {!ij = prob (Zi = 1, Zj = 11m) is the sum of the probability (4.6)
with S = lover all zEn such that Zi = 1 and Zj = 1. If i = i, then
{!ii = (!i' and if i =I- j then

o.0
~ 'J

=

-e-x-'p'--{-)'-'-('-u-i-'+ ---u..:j:)...}.:.(..n.::.-....2.:,..m..-'--:--2--,-k---'--U--i------U''-j')-

(n ,m,k)

.

Because each Ui is either 0 or 1, there are only two values of {!i to be computed, and only three values of (!ij to be computed.

4.6.4 *Large Sample Approximations to the Expectation and
Variance of T

Large sample approximations to J.Lu and au are now given when u has k coordinates equal to 1 and n - k coordinates equal to zero. The approxima-
tions are developed in the appendix, §4.7.4; they involve approximations E and if to the expectation and variance of ZT u, where ZT u is the number
of treated subjects with U = 1. As in §4.4.6, the calculation involves solving
the quadratic equation

E2 (r -1) - E{(r - l)(m + k) + n} + rkm = 0

(4.29)

4.6 Sensitivity Analysis for Comparing Two Unmatched Groups 143

for the root £ with max(O, k + m - n) ~ £ ~ min(k, m) . If k = 0, then £ = 0, but if k = n , then £ = m , and in either case let V = 0; otherwise,
let

V= (: +~+_1__ + 1 _)-1

(4.30)

E k-E m -E n-k-m+E

Then calculate the mean and variance of the scores qi separately for
subjects with Ui = 1 and Ui = 0,

Wo = n _ 1k -1 "~ (qi - _qo)2 ,
i :Ui=O

where we define (h = 0 if k = 0, qo = 0 if k = n, WI = 0 if k ~ 1, and
Wo = 0 if k ~ n - 1. Finally, if k =f. 0 and k =f. n , then approximate J-Lu by

Eql + (m - £)qo

(4.31)

and au by

(T (WI - wo)£ - (£2 + V) + n~k) + m(n-k~:':2E)Wo + V(llI - ilO) 2;
(4 .32)
otherwise, if k = 0 or k = n,

L J-Lu = mn qi and au =

L mn((nn--1m)) "~(qi - q-)2 ,where q- = -n1 qi.
(4.33)

In these calculations, £ and V approximate the expectation and variance
of ZTu , that is, of the number of treated subjects with U i = 1. If the
exact expectation E and variance V of ZTu were used in place of £ and V,
then (4.31) and (4.32) would give the exact moments of T . While the exact
moments E and V can be used, their computation involves somewhat more
effort; moreover, the approximations £ and V perform well and are widely
used in other contexts. Exact and approximate moments are compared in
an example in §4.6.5 and they are discussed in detail in §4.7.3.

144 4. Sensitivity to Hidden Bias

4.6.5 *Simplified Formulas for the Rank Sum Test Hlhen There Are No Ties

In the absence of ties among the responses, Wilcoxon's (1945) rank sum
statistic T involves ranking all n responses from 1 to n and summing the ranks in the treated group. With the n subjects arranged as in §4.6.2, the
rank sum is T = L.: Z iqi with ql = n, q2 = n - 1, . . . ,qn = 1. This leads
to simplifications of the formulas in §4.6.5. In particular, using familiar
arguments about sums of integers and sums of squares of integers (Lehmann 1975, p. 329), it follows that for u E U+ having k ones followed by n - k zeros

n-k+l

(n - k)(n - k + 1)

go = 2

Wo =

12

'

gl =

k+l -2-

+

n

-

k,

k(k + 1)
WI = 12

Substituting this in (4.31) gives

En + m( n - k + 1)
2

(4.34)

as the approximation to J-Lu' and similarly (4.32) gives

+ + {(n+l)(2k-n)+2m(n-k+l)}E-(n+2)E2 m(n-k-m)(n-k+ l) V(n-l)(n+~)

12

12

4

(4.35)

as the approximation to O"u. The same formulas may by used for an element, say u" , of U- , by
proceeding as follows . To approximate J-Lu. and O"u. for u" E U-, determine
u = 1 - u", so u E U+ , replace I' by Iff, and apply formulas (4.34) and
(4.35). This works because the distribution (4.6) with (f, u") is the same as with (Iff, u); see Appendix §4.7.4, for detailed discussion.

4.6.6 An Example: Chromosome Damage from Contaminated Fish
Skerfving, Hansson, Mangs , Lindsten, and Ryman (1974) st udied 23 subjects who had eaten large quantities of fish contaminated with methylmercury . Each of the 23 exposed subjects had eaten at least three meals a week of contaminated fish for more than three years. The control group consisted of 16 subjects who did not regularly consume contaminated fish and who ate far less fish of all kinds . Table 4.15 gives their data on two outcome measures, the amount of mercury found in the subject's blood,

4.6 Sensitivity Analysis for Comparing Two Unmatched Groups 145

recorded in ng/g, and the percent of cells exhibiting a particular chromosome abnormality called Cu cells , specifically, asymmetrical or incomplete symmetrical chromosome aberrations as recorded in cells cultured between 48 and 120 hours. Although the original study examined several types of chromosome abnormalities, the discussion here considers only this specific type of abnormality.
The table shows that subjects who ate contaminated fish had much higher levels of mercury in their blood and somewhat higher frequencies of chromosome aberrations. The data contain some extreme observations, for instance, subject 26 with a mercury level of 1100 ng/g and subject 24 with 9.5% of cells exhibiting chromosome aberrations. There are ties among the responses, particularly the subjects with 0% chromosome aberrations.
Consider first the level of mercury found in the blood. There are four pairs of tied observations. For instance, subjects #18 and #29 both had mercury levels of 70 tsg]g, so instead of giving ranks 23 and 24 to these observations, they are both given the average rank of 23.5 in Wilcoxon's rank sum statistic, T. The sum of the ranks in the exposed group for level of
mercury is T = 642. In the absence of hidden bias, that is, with r = 1, the
calculations in §4.6.2 yield an approximate expectation and variance for T of 460 and 1202.92 under the null hypothesis of no tr eatment effect, so the
deviate is (642 - 460)/ J1202 .92 = 5.25, with significance level < 0.0001. If
there were no hidden bias , there would be strong evidence that eating fish contaminated with methylmercury causes an increase in mercury levels in the blood.
Now, suppose I' = 2, so that one subject may be twice as likely as another to eat contaminated fish because they differ with respec t to an unobserved covariate for which adjustments are required. The largest significance level for all u E U is approximated using the deviate

min T - J-Lu uEU+ au

(4.36)

which equals 4.40 if the approximate expectation and variance in §4.6.2
are used. This says that a hidden bias of magnitude I' = 2 could not
begin to explain the higher levels of mercury found in the blood of subjects
who ate contaminated fish; no covariate that doubled the odds of eating
contaminated fish could reasonably be expected to produce the observed results.
The minimum in (4.36) is calculated directly, evaluating (T - J-Lu) / a u for
k = 0,1 , . .. , 39 and taking the minimum. In this case, the minimum occurs
at k = 21, that is, at au = (1,1, . .. , 1, 0, 0, . . . , 0) containing k = 21 ones
followed by n- k = 39- 21 = 18 zeros. The neighborhood of the minimum is
quite flat . For k = 20, 21, and 22, the deviates (T -J.Lu)/au are , respectively, 4.4035 , 4.3985 , and 4.3987. If exact expectations and variances are used in
place of the approximations, the minimum still occur s at k = 21 and the
deviate is 4.33. There is no need to calculate the maximum deviate in (4.28),

146 4. Sensitivity to Hidden Bias

TABLE 4.15. Methymercury in Fish and Human Chromosom e Dam age.

Id.

%Cu cells Mercury in blood

1 Control

2.7

2 Control

0.5

3 Control

0

4 Control

0

5 Control

5

6 Control

0

7 Control

0

8 Control

1.3

9 Control

0

10 Control

1.8

11 Control

0

12 Control

0

13 Control

1

14 Control

1.8

15 Control

0

16 Control

3.1

17 Exposed 0.7

18 Exposed 4.6

19 Exposed

0

20 Exposed

1.7

21 Exposed 5.2

22 Exposed

0

23 Exposed

5

24 Exposed

9.5

25 Exposed

2

26 Exposed

3

27 Exposed

1

28 Exposed

3.5

29 Exposed

2

30 Exposed

5

31 Exposed

5.5

32 Exposed

2

33 Exposed

3

34 Exposed

4

35 Exposed

0

36 Exposed

2

37 Exposed

2.2

38 Exposed

0

39 Exposed

2

5.3 15
11
5.8 17 7 8.5 9.4 7.8 12 8.7 4 3 12.2 6.1 10.2 100 70 196 69 370 270 150 60 330 1,100 40 100 70 150 200 304 236 178 41 120 330 62 12.8

4.6 Sensitivity Analysis for Comparing Two Unmatched Groups 147
since we know from the case of r = 1 that the minimum significance level
will be less than 0.0001.
For r = 5,20, and 35, the minimum deviates are 3.48, 2.43, and 2.10, re-
spectively, with approximate significance levels 0.0003, 0.0075, and 0.0179 . Even if one subject were 35 times more likely than another to eat contaminated fish-an extreme departure from randomization-this would not explain the high levels of mercury in the exposed group. This is a high level of insensitivity to hidden bias, a higher level than encountered in previous examples.
More important than the level of mercury is the possible damage to chromosomes. The rank sum for the percentage of abnormal cells is 551.5, with deviate 2.65 and significance level 0.004 in the absence of hidden bias ,
that is, with r = 1. A difference of this magnitude would provide strong evidence of an effect in a randomized experiment. For r = 2 and 3, the
deviates are 1.78 and 1.28, respectively, with upper bounds on the significance levels 0.0375 and 0.10. An unobserved covariate that tripled the odds of eating contaminated fish could explain the difference in the frequency of chromosome damage in exposed and control groups. For chromosome aberrations, the study is insensitive to small biases, but sensitive to biases of moderate size.
The percentages of abnormal cells have many ties. Twelve subjects have no abnormal cells , so all twelve are given the average rank of 6.5. There are many other ties as well. If average ranks are used in computing the rank sum statistic T but are ignored in computing the expectation and variance, that is, if the simpler formulas (4.34) and (4.35) are used, the minimum
deviates for r = 2 and 3 are 1.75 and 1.26 instead of the 1.78 and 1.28 given
above. Even with many ties, the moment formulas that ignored ties gave similar results. If instead the exact expectation and variance of T are used,
then the deviates for r = 2 and 3 are 1.74 and 1.23, a negligible change .
4.6.7 Hodges-Lehmann Point Estimates of an Additive Effect
This section conducts a sensitivity analysis for a Hodges-Lehmann (1963) estimate of an additive effect obtained from the rank sum test. The approach is similar to the sensitivity analysis in §4.3.5 for matched pairs. The model of an additive treatment effect makes little sense for coarse data with many ties, so in building point and interval estimates for an additive effect, it is assumed that there are no ties, and the moment formulas in §4.6.5 are used.
If the treatment has an additive effect T, then the adjusted responses RTZ satisfy the null hypothesis of no effect. The Hodges-Lehmann estimate of T is the value f such that R - fZ appears to precisely satisfy the null hypothesis of no effect, in the sense that the rank sum statistic T = t(Z, R-
fZ) computed from R - fZ equals its null expectation, say f. As with the signed rank statistic in §4.3.5; the rank sum statistic t(Z, R - TZ) declines

148 4. Sensit ivity to Hidd en Bias

t in discrete ste ps as T increases, so an equat ion of the form t(Z , R - f Z) =
may not have an exact solut ion. As a result, f is defined as t he average of
the smallest value that is too large and the largest valu e that is too small,
that is, f is defined by f = SOLVEft = t(Z , R - f ZH in (4.12).
Wh en r =1= 1, the null expectat ion f of the rank sum statist ic is J.Lu which
is not known becau se u is not known. However , bounds on f are available
from (4.27),

i-. tmin

=

min
uE U -

J.L u

:S

max
u EU+

J.L u

=

t max ,

for

all u

E U.

(4.37)

Since t(Z , R - r Z) declines as T increas es, the maximum f is found as the

solut ion §OLVE{fmin = t (Z, R - fZ)} while the minimum f is found as

SOLVE{fmax = t(Z , R - fZ)}.

_

_

The procedure is as follows. For each fixed r, compute fmax and fmin

using (4.34) in §4.6.5. With_these fixed valu es, compute SOLVE{ tmax =

t(Z , R - f Z)} and SOLVE{fmin = t(Z, R - fZ)} which give the range of

possible Hodges-Lehmann est imates given uncertainty about the value of

the unobserved covariat e u.

4.6.8 An Example: Point Estimates of the Increase in Chromosome Abnormalities
Continuing the example from §4.6.6, this section examines point est imat es of the increase in chromosome abnormalities. If there is no hidden bias,
t hat is, if r = 1 then t he null exp ectation of t he rank sum st atistic is f = 460 = m(n + 1)/2 = 23(39 + 1)/2. In fact , the rank sum st at ist ic T for
the proportion of cells with abnormalities is far higher, namely, T = 551.5. The Hodges-Lehmann estimat e is the value f which, when subtracte d from the responses for the 23 exposed subjects, gives a rank sum as close as possible to 460. Now, if 1.7 is subt racted from t he 23 exposed prop orti ons in Table 4.15 before the rank sum is comput ed , then T = 464.5 which is just slightl y too high , but if 1.70001 is subtracted, then T = 458 which is
just slightl y too low; so the Hodges-Lehmann estimate is f = 1.7. Were this
a randomized experiment, eating cont aminat ed fish would be est imated to increase the percentage of abnormalities by the additive effect 1.7%.
If there were a hidden bias of magnitude r = 2, then one subject might
be twice as likely as another to eat contaminated fish because they have
differing values of the unobserved covariate. In this case, the expectation
of the rank sum statistic in the absence of a treatment effect , namely f , is not known because it dep ends on u. Still, for u E U , the exp ect at ion
I is at most t max = 491.57 and at least t m in = 428.43. The maximum
fmax is found at u = (1,1 , . .. , l L0,0, . . . , 0) with k = 20 ones followed by n- k = 39-20 = 19 zeros, while fmin found at u* = (0, 0, . . . , 0, 1, 1, .. . ,1) with k = 19 zeros followed by n - k = 39 -19 = 20 ones. These bounds on
f are calculat ed using (4.37) and (4.34), together with the observation in

4.6 Sensitivity Analysis for Comparing T wo Unmatched Gr oups 149

TA BLE 4.16. Sensitivity Analysis for Methylmercury Dat a.

r Range of estimates

Range of

of effect

significance levels

1

1.7

0.004

2

1.0 to 2.0

0.0001 to 0.0375

3

0.7 to 2.2

< 0.0001 to 0.1

§4.6.5 about t he relat ionship between t he max over U+ and the min over

U- .

T he next step is to calc ulate SOLVE{tmax = t( Z , R - f Z)} wit h t max =
491.57. Now t (Z , R- 0.9999Z ) = 497 which is a lit tle too large, but t( Z, RlZ) = 490.5 which is a little too small; hence 1.0 = SOLVE{491.57 =

T(Z , R - f Z)}. In words , if 1% is subtrac ted from t he percentages of ab-

normalities in t he exposed group, t hen th e rank sum just about equa ls t he
maximum poss ible expectation for r = 2. In t he same way, SOLVE{tmin = t( Z , R-fZ)} = SOLVE{428.43 = t( Z, R -fZ)} = 2.0. Because we do not

know u , we cannot calc ulate a single Hodges-Lehmann estimate; however ,
if r = 2, the largest possible estimate is 2% and the smallest is 1%, all of

these values being significantly different from 0% as seen in §4.6.6.
Repeating t his for r = 3 gives t max = 509.28, SOLVE{509.28 = t( Z , Rf Z)} = 0.7, tmin = 410.72, and SOLVE{410.72 = t( Z , R - f Z)} = 2.2.
So the range of Hodges- Lehmann estimates for r = 3 is from 0.7 to 2.2%.

However , from §4.6.6, not all of these estimates differ significantly from 0%.

Table 4.16 summarizes these ca lculations.

Although t he null hypothesis of no treatment effect begins to be pla usib le
at about r = 3, the estimated effect is still at least 0.7%, which is not a

small number given the levels of abnormalities found in the control group.

Going beyond the table, the smallest est imated effect equals zero when
r = 8.9.

The model of an additive effect is not fully consist ent with the data

in Table 4.15, because the exposed group has percentages of abnormali-

t ies that are not only higher but also more variab le. An alternative to an

-m: analysis of t he percentages Rsi is an analysis of tra nsformed percentages,

say 10g(1 + R si ) or

since t hese transformations tend to red uce the

dispersion of larger values . An alternative approach is discussed in §5.3.

4.6.9 Confidence Intervals f or an Additive Effect
Confidence intervals for T ar e obtained by inverting the rank sum test.
Fix r ~ 1. With r fixed, for each u E U , the distribution (4.6) yields
a confidence interval for T . Since u is unknown , the sensitivity interval is defined to be the union of these confidence intervals, the union taken

150 4. Sensitivity to Hidden Bias

over all u E U. A value T is in the sensitivity interval if T is plausible for some u E U, and T is not in the sensitivity interval if it is rejected for every
u E U . If r = 1, then the sensitivity interval is the single confidence interval commonly obtained from the randomization distribution. As r increases,
the confidence interval becomes longer reflecting the possible impact of the unknown u .
Let T be the rank sum statistic under the null hypothesis of no treatment effect. From Proposition 19 in the appendix, §4.7.3 , prob{T ;::: adm} is maximized at some u E U+ and prob{T S; aolm} is maximized at some u E U-. Suppose that there are numbers ao and al so that prob{T ;::: allm} ::; 0:/2 for all u E U+ with equality for some u E U+ and prob{T S; aolm} S; 0:/2 for all u E U- with equality for some u E U- . In other words, if T S; ao or T ;::: al, then the null hypothesis of no effect is rejected at level 0: for all u E U .
In large samples, in a one-sided 0.025 level test, a value T is rejected as too small for all for all u E U if

ml.n t(Z,R- ZT) - fJ-u >_ 1.96,

uEU+

au

(4.38)

and T is rejected as too large for u E U if

max t(Z, R - ZT) - fJ-u S; -1.96,

uEU-

au

(4.39)

where fJ-u and au are approximated by (4.34) and (4.35). Since t( ·,·) is effect increasing, t(Z,R-TR) declines as T increases, and the set of points
T satisfying neither (4.38) nor (4.39) is therefore an interval.

4.6.10 An Example: Sensitivity Interval for the Increase in Chromosome Aberrations
In the example of §4.6.6 the Hodges-Lehmann point estimate of the increase
in chromosome aberrations was f = 1.7% in the absence of hidden bias, r = 1, and the point estimates ranged from 0.7 to 2.2% for r = 3. Consider
now the 95% confidence interval for T .
In the absence of hidden bias, r = 1, the largest value of T that is rejected
as too small is 0.2% and the smallest value that is rejected as too large is 2.8%, so the 95% confidence interval is [0.2, 2.8]. In other words, if 0.2 were subtracted from the responses of each subject who ate contaminated fish, and the rank sum test were applied to the resulting adjusted responses, the standardized deviate would just equal 1.96, whereas if 2.8 were subtracted instead, the deviate would just pass -1.96. Notice that, even in the absence of hidden bias , the confidence interval [0.2, 2.8] is fairly long.
If there were hidden bias of magnitude r = 2, the largest value T barely
rejected as too small in (4.38) is 0.0 and the smallest value T rejected as

4.7 Appendix: Technical Results and Proofs 151
too large in (4.39) is 3.5%, so the 95% sensitivity interval is [0.0, 3.5]. Keep in mind that this is a two-sided interval, while the test in §4.6.6 was a one- sided test. The sensitivity interval is the union of all the confidence intervals that might have been calculated had the unobserved covariate u been observed. For I' = 3, t he 95% sensitivity interval is [- 0.4, 4.0].

4.7 Appendix: Technical Results and Proofs
4.7.1 Outline and Summary
This appendix contains proofs and general results. Section 4.7.2 proves Proposition 14 concerning the values u" and u " providing the bounds for sign-score statistics. Section 4.7 .3 discusses sensitivity analysis for arrangement increasing statistics. Exact and approximate moment formulas for sum statistics are derived in §4.7.4. Finally, §4.7.5 discusses the effect of certain transformations of u , most importantly, the equivalence of (I' , u) and (l/f, 1 - u) .

4.7.2 Bounds for Sign-Score Statistics
The proof of Proposition 14 in §4.4.1 is now given.

Proof. The proof uses Holley's inequality, Theorem 9 in the appendix to
Chapter 2. Fix a u E U . Set v = u" - u. Renumber units in each subclass
so Cs l :::: Cs2 :::: . .. :::: cs ,ns and Vsl :::: Vs 2 :::: . .. :::: vs,n. , which is possible by t he definition of u " and t he fact that u E U. With this ord ering of the units, t (z , r ) is an isot onic function of zEn in the sense of §2.1O.4,
since interchanging Zsi = 0 a nd Zs,i+ l = 1 leaves l:i CsiZsi unchanged if
Csi = Cs ,i+ l or increases l:i CsiZsi by one if 1 = Csi > Cs ,i+ l = O. To prove
the first inequality in Propositi on 14, it therefore suffices to show that the premise of Holley's inequality holds , that is, to show

exp { , (z V z*)T u+} exp { , (z 1\ z*)T u} l:bEO exp (rbTu+) . l:bEO exp (rbTu)

exp{,(z*)T u+}
>

exp(,zTu)

l:bEO (rbTu+) l:bEO exp (rbTu )

for all z , z* E n . To show this, it suffices to show that
(z V z*{ u+ + (z 1\ z* )T u :::: zTu + (z*) T u+ for all z , z* En. (4.40)

Notice how convenient Holley 's inequality is: To prove that one random vari abl e is stochastically larger th an another, all that needs to be shown is th at a cert ain linear inequality (4.40) holds.

152 4. Sensitivity to Hidden Bias

First add and subt rac t (z V z*)T u on the left-hand side of (4.40) , and th en apply Lemma 2.9 to get

(z V z*)T u+ + (z 1\ z*)T U
= {(z V z*) + (z 1\ z*)}T u + (z V z*f (u+ - u)
(z + z*)T U + (z V z*f (u+ - 'u ) .

(4.41 ) (4.42)

Writ e the right-hand side of (4.40) as (z + z*)T U + (z*)T (u" - u) and
compare this with (4.42). From this comparison, to prove (4.40) it suffices to show that (z V z*f (u" - u) ~ (z*f (u" - u) , or equivalently that vT(z Vz*) ~ vTz*; however, this follows from Vs ! ~ Vs2 ~ ' " ~ vs,ns ' since the Is in z V z* are to th e left of the Is in z*. This proves the first
inequality in th e proposition. The second inequality is pr oved in the same
way aft er repl acing u" by u and u by u " , so v becomes u - u " . ·

4.7.3 Some Properties of Arrangement-Increasing Statistics
Let v be a fixed N-tuple, and let h( ·, ·) be an arrangement-increasing function as defined in §2.4.4. This section discusses properties of the expectation of h(Z , v) under th e model (4.6) , that is, properties of

= " ( w(v , u) = E{h(Z , v)}

LZE!1 h(z, v) exphzT u)

whE!1 exp

b 'Y

T

u

)

.

(4.43)

These properties justify the sensit ivity analysis for sum st atistics in §4.7,
but they also have other uses later.
Before discussing the properties of w(v , u) , consider a few cases. Let
T = ZT q be a sum st atistic and set v = q . If h(Z , q) = ZT q, then h( ·, .)
is ar rangement- increas ing, and u.!(q , u) is the expectation of ZT q . Alt erna-
tively, if h(Z , q) = 1 if ZT q ~ a and h(Z , q) = 0 otherwise, then w(q, u) is
the probability th at ZT q ~ a, that is, the tail probability used to determine
a significance level. Similar considerations apply with v = r if T = t(Z , r)
is any arrangement-increasing st at isti c.
The following proposition is an immediate cons equence of the composi-
tion theorem for arrangement-increasing functions. The composition theo-
rem is due to Hollander , Proschan, and Sethuraman (1977); see also Mar-
shall and Olkin (1979, §6.F .12) or Eaton (1987, §3.4). The composition theorem concerns expressions such as LZE!1 h(z, v) exphzT u) in (4.43) ; it
asserts that this expression is an arrangement-increasing function of v and u because h(z, v) and exphzT u) are each arrangement-increasing functions
and n is a symmetrical set . The following proposition says that w(v, u)
increases-or more precisely, w(v , u) doe s not decrease-as the coordinates
of u are permuted within strata into the same order as the coordinates of v .
In particular, the expectat ion w(v, u) is largest when u and v are ordered

4.7 App endix: Techni cal Resul t s and Proofs 153

in the sa me way within each stratum and w(v, u ) is smallest when u and v ar e orde red in opposite ways.

Proposition 17 w(v , u) is arrangem ent-increasing.

Pick any coordinate (s , i) and let Csi be the N -tuple with a one in

coordinate (s , i) and zeros in the other N - 1 coordinates. The following
proposition from Rosenbaum and Krieg er (1990) says that w(v, u + 8csi)

is monotone in 8 for eac h fixed u and v. Not e carefully t hat while this

is true for each fixed u and v and for each (s,i), the direction of the

monotonicity-incre asing or decreasing-may change as u , v , and (s, i)

ar e vari ed.

.

Proposition 18 For each fix ed u , v , and (s , i ), the expectation w(v , u +
8c si) is monotone in 8.

Proof. Let 0 0 = {z EO: zsi = O} and 0 1 = {z En: zsi = I} so
no o = 0 0 U 0 1 , and a sum over 0 may be broken up into a sum over plus
a sum over 0 1 . Write

w(v, u + 8c si)

L:zEflo h(z , v ) exp (,zTu ) + exp (,8) L:zEfl 1 h(z , v ) exp(, zTu )

L:bE fl o exphbTu) + exp(8) L:bEfl 1 exphbTu)

=

Ao + exp(8)A1
Do + exp(8)D1 '

say ,

where A o, A}, Do , a nd D 1 are constants not varying with 8; moreover, Do and D 1 are strictly positive. Differentiating with respect to 8 gives

ow(v, u + 8c si)
08

(D oA 1 - A oD 1hexp(8)
F {Do + D 1 exp (T8)

(4.44)

so the sign of this derivative do es not cha nge as 8 changes; hence w(v, u +
8c si) is monotone in 8. · Let if be the N-tuple v after its coordinates have been arranged in
decreasing order within each stratum, Vsi 2: Vs,i+! for i = 1, .. . , n s - 1,
and s = 1, . .. ,S. Let U+ be the set of all N-tuples b of zeros and ones such
s: that bsi 2: bs,i+ 1, i = 1, . . . ,ns -1, and s = 1, . . . , S, and let U- be the set
of all N-tuples b of zeros and ones such that bsi bs ,i + 1, i = 1, . . . , n s -1 , and s = 1, . . . , S .
The following proposition bounds the unknownw(v , u) by two quantities
that can be directly calculated. The bounds ar e sharp in that they are
attained for some u E U. For instance, if h(Z , q) = 1 if ZTq 2: a and
h(Z, q) = 0 otherwise, then Proposition 19 gives bounds on the one-sided
significance level obtained using the sum statistic ZTq.

154 4. Sensitivity to Hidden Bias

Proposition 19 For all U E U,

min w(v, b) ::; w(v, u) ::; max w(v, b) .

bEU-

bEU+

(4.45)

Proof. Suppose that, contrary to the upper bound in (4.45), there is a U E U such that

w(v , u) > max w(v, b) .
bEU+

A sequence Uo , uj , . .. , UJ , will be constructed such that U = Uo, UJ E U+, and w(v, Uj) ::; w(v, Uj+ 1), thereby establishing a contradiction. The construction is as follows. Suppose Uj has at least one coordinate that is not equal to zero or one. Then form Uj+l from Uj by picking anyone such coordinate of Uj, and setting it to either zero or one so that w(v, Uj) ::; w(v, Uj+l) j this is possible by Proposition 18. If every coordinate of Uj is
either zero or one, then set J = j + 1 and let UJ be obtained by sorting the
coordinates of Uj into decreasing order within each stratum. By Proposition 17, w(v, Uj) ::; w(v, uj ). Also, UJ E U+, so there is a contradiction, and the upper bound in (4.45) is proved. The lower bound is proved similarly.
·

4.7.4 Moments of Sum Statistics at Extreme Values of u
This section determines a simplified expression for the expectation and variance of a sum statistic ZT q under the model (4.6) when U has binary coordinates, U si = 0 or Us i = 1 for each (8,i). Also, large sample approximations to the expectation and variance are given . These results were used in §4.4.6 and 4.4.7 for the 2 x 2 x S contingency table and in §4.6 for the rank sum statistic.
Under mod el (1.6) , a sum statistic is the sum of S independent contributions, one from each stratum. The expectation and variance of a sum statistic is, therefore, the sum of the S separate expectations and variances of the contributions from each of the S strata. As a result, it suffices to consider the case of a single stratum, S = 1, so in this section the subscript
8 is omitted. Let Ui = 1 or U i = 0 for i = 1, . . . ,nj let k = L Ui, so U has
k coordinates equal to 1 and n - k equal to zero .
An important role is played by the random variable C = ZT u , which is the number of treated units for which Ui = 1. The variable C has the
extended hypergeometric distribution, which arises in other contexts as the conditional distribution of one binomial random variable given the sum of this variable and a second independent binomial variable. For detailed discussion of the extended hypergeometric distribution, see Johnson, Kotz, and Kemp (1992, §6.11) or Plackett (1981, §4.2) . Write the expectation and variance of Cas E = E(C) and V = var(C) . The expectation and variance
of ZTq have easily computed formulas defined in terms of E and if . (For

4.7 Appendix: Technical Result s and Proofs 155
reasons that are apparent shortly, t he symbols E and V used here are the sa me as the symbols used in §4.4.6.)
F ind t he mean and var iance of the qi separately for units with Ui = 1
and U i = 0, as follows:

Proposition 20 Und er model (4.6) in which u has binary coordinates, the expectation and vari an ce of Z T q are

E(ZTq)

EiiI + (m - E)ilo,

var( ZT q)

=

(WI-

wo)E -

2 (E

+

V)

(:1

+

n~k )

(4.46)

+

m

(

n-

k-m +2 n- k

E)wo

+

V( ql

-

- )2
qo .

(4.47)

Proof. Notice t hat in (4.6) , C = ZT U is the sufficient statistic, so the

condit ional dist ribution of Z given C = ZT u does not depend on / . More

e) (::;=.:) than this, prob(Z = zlC = c) is uniform on t he subset of n such t hat

z T u = C , that is, uniform on the set containing the

vectors wit h

c coordinates equal to 1 among t he k coordinates with Ui = 1, m - c coor-

dinates equal to 1 among the n - k coordinates with Ui = 0, and all ot her

coord inates equal to O. In other words, t he distribution prob( Z = zlC = c)
picks at random c of t he k coordinates wit h Ui = 1 and independently

picks at random m - c of t he n - k coord inates wit h Ui = O. It follows

that pro b(Z Tql C = c) is the dist ribution of t he sum of c scores selected at

ran dom from among t he k scores q i such that Ui = 1 plus t he sum of m - c

scores independently selected at random from am ong t he n - k scores qi

such t hat U i = O. Therefore,

E( ZT q) = E {E (Z T q lC )} = E{Cill + (m - C)ilo} = Eill + (m - E)ilo,

pr oving the first part of (4.46). Similarly,

var( ZT q) = E {var( ZTq lC)} + var{E( ZT q lC)}

= E { C (k - C)W I + (m - C)(n - k - m + C)wo }

k

n- k

+ var{ce, + (m - C)ilo}

(WI =

E { (W I - Wo )C - C2

k

+

wo n- k

)

+ men -

k - m + 2C)WO }
n- k

+var{C(ill - qo)}

WI - (WI (

Wo )-E - (E2 + V)

- + - w-o ) + -m'-(-n------k---,:m---+-'-2-E-)..w:.o.

k n -k

n-k

+V(ill - ilO) 2

156 4. Sensitivity to Hidden Bias

e) (:-=-:) proving the second part of (4.46).·

There are

elements of n such that zT u = c for each integer

c, max(O, m + k - n) ::; c::; min(m, k) . Using (4.6) gives:

E

=

",miu(ut,k) L..c=max(O ,m+k-n)

(k) Cc

( n-k) m-c

exp ('Y)C

",min(m,k) L..c=max(O,m+k- n)

(k) (n-k) c m-c

exp ('Y)C

(4.48)

and

V=

" , m i n ( m ,k) L . . c = m ax(O, m + k - n )

2 (k) Cc

(n-k) m-c

exp('Y)C

_

E2

",min(m,k) L.. c=max(O ,m+k-n)

(k)
c

( n-k) m-c

exp ('Y)C

.

(4.49)

An equivalent but simpler expression for V is given by Johnson, Kotz, and Kemp (1992, p. 280, expression (6.160)) ; namely,

V = fmk - {n - (m + k)(I- f)}E _ E2

(1 - I")

,

(4.50)

where I' = exp(v).

When m, k, n - m , n - k are large, E and V can be cumbersome to com-

pute, but in this case a large sample approximation is available. The ap-
proximations to E and V are E and "Ii where E is the root of the quadratic

equation

° E2(f - 1) - E{(f - l)(m + k) + n} + fkm =

(4.51)

with max(O, k + m - n) ::; E ::; min(k, m) , and

V- = ( -1=+1--_+-1 -_+

1 ) -_ 1

E k-E m-E n-k-m+E

(4.52)

These expressions are due to Stevens (1951) . Hannan and Harkness (1963)
give mild conditions such that C has a limiting normal distribution with
expectation E and variance V. If instead, m is fixed as n -+ 00 and k -+ 00
with kin -+ (, then Harkness (1965) shows that C has a limiting binomial
distribution with sample size m and probability (fI {(I - () + (f} .
These facts about the moments of ZT q were used several times in this
chapter. Consider the upper bound for the significance level in a 2 x 2
contingency table in §4.4.6 and 4.4.7 . Here, ri is binary, qi = r, and Ui = ri ,
so k = r+, iiI = 1, iio = 0, W1 = Wo = 0; therefore, from (4.46) , E(ZTq) = E
and var(ZT q) = V . The Normal approximation was used in §4.4.6 and the
binomial approximation in §4.4.7.
Now consider the upper bound for the sum statistic in §4.6. Here , the qi
are sorted into decreasing order, and U1 = 1, U2 = 1, . . . , Uk = 1, Uk+1 = 0, . . . ,Un = 0 for some k and (4.46) is used with the approximations in
place of the exact moments.

4.7 Appendix: Technical Results and P roofs 157
Under mild conditions on the behavior of t he scores qsi , the limiting Normal distribution for ZTq under model (4.6) as min n s -> 00 follows from , for example, Theorem 2.1 of Bickel and van Zwet (1978) . T hey also provide an asymptotic exp ansion of the tail area and a uniform bound on the error.

4.7.5 The Effects of Certain Transformations of u
It is useful to obse rve that , in the mode l (4.6) , certain transformations of u have simple consequences. For inst ance, consider the linear transformation
u * = (l/,6)(u - cd) for ,6 > O. Write v" = ,6,. T hen

prob(Z = zlm)

LbE!1 expbbT u) expb* zT u*)

exphzT(o l + ,Bu * )} LbE!1 h bT (o l + ,6u*)}

where the las t equality follows from the observation that bT l = L ms for
all b E n . In ot her words, a change in t he locat ion of u does not change the model, while a change in t he scale of u cha nges the sensitivity parameter , by a corresponding mu ltiple. The practical consequence is t hat t here is no need to consider other locations and scales for u , since they are implicitly covered by (4.6) .
A more import ant transformation is u ** = 1 - u. Now, u E [O , l ]N if and onl y if u ** E [0, l ]N. Then
prob( Z = z jm )

whe re t he last equality again follows from bTl = L m s for all b En. In
ot her words, replacing u by 1- u has t he effect of changing t he sign of" or equivalently ofreplacing I' by l/f . This has several practical consequences.
First, it suffices to consider , :2: 0, since any distribution wit h , < 0 at a po int u is t he same distribution as one with , > 0 at 1 - u. Second,
in sensit ivity analyses for sum statistics, the sets U+ and U- appear; see
§4.6.2, and P roposit ion 19 in §4.7.3. Now, u E U - if and only if 1 - u is
in U+ . It follows that t he min imum of a quantity, say J.Lu . in (4.27), as u
ra nges over U- with , > 0 equals a minimum of the same quantity as u
ranges over U+ with , replaced by - ,.

158 4. Sensitivit y to Hidden Bias
4.8 Bibliographic Not es
Cornfield , Haenszel, Hamm ond , Lilienfeld , Shimkin, and Wynder (1959) proposed a sensit ivity ana lysis for risk ratios; see also Greenhouse (1982) and Gastwirth, Kri eger , and Rosenbaum (1998a). Indep end entl y, Bross (1966, 1967) proposed a sensiti vity analysis for 2 x 2 ta bles. Gastwirth (1988, 1992a ,b) extended t he method of Cornfield et al. (1959) in several dir ections. Related methods are discussed by Schlesselm ann (1978) a nd Greenl and (1996). Rosenbaum and Rubin (1983) discu ssed sensit ivity a nalysis for a point est ima te of a differ ence in pr op ortions in a 2 x 2 x 8 table using 38 sensitivity par am et ers. The methods discussed in this chapter are lar gely taken from Rosenbaum (1987, 1988, 1991a, 1993, 1995, 1999a,b , 2001), Rosenb aum and Krieger (1990) , and Gastwirth, Kri eger , and Rosenbaum (2000) . For several applicat ions , see Normand, Landrum, Guadagnoli, et al. (2001), Aakvik (2001) , and Davanzo, Thomas, a nd Yue , et al. (2001). Gastwirth, Kri eger and Rosenbaum (1998b) propose a method of sensiti vity an alysis for permutation t ests with two sensit ivity parameters, one linking treatment assignment with u and the ot her linking response with u. Several methods of sensit ivity analysis for various types of regression mod els ar e discussed by Rosenbaum (1986), Cop as and Li (1997), Mar cus (1997), and Lin, Psaty, a nd Kr onmal (1998). Man ski (1990 , 1995) proposes "worst-case bounds" which are somew hat analogous to letting
r -+ 00 in a sensit ivity ana lysis; see also Balke and Pearl (1997) and Pearl
(2000, §8.2) .
4.9 Problems
1. McNemar's test . Start ing wit h 10,872 dea th cert ificat es with the diagnosis of sporadi c motor neuron disease (MND ), Grah am, Macdonald , and Hawkes (1997, Tabl e 3) examined their birth certificates and found that 70 of these cases with MND had a livin g twin free of MND . These 70 twin pairs formed the basis for a case-referent study. Because little is known about the causes of MND, they examined "many vari ables " as potential causes in their explorat ory study. Indeed, many case-r eferent st udies are exploratory: they run a substantial risk of false positives by performing many significance tests on many potential causes. Nonetheless , exploratory st udies have played an important role as the first of a series of increasingly focused studies to determine the ca uses of a disease. The st rongest associat ion Graham, Macdonald , and Hawkes found was with "car rying out car or vehicle maintenance." There were 16 twin pairs discordant for this variable, and 14/16 had an exposed case, while 2/16 had a n exposed referent, yielding an est ima te d odds ratio of 14/2 = 7 in the absence

4.9 Problems 159

of hidden bias. Do a sensitivity analysis for th e significan ce level from McNemar's test.

2. Wilcoxon's signed rank test . Many drugs used to treat cancer are quite harsh, and there is the possibility that these drugs can harm hospital workers who are exposed by accident. Kevekord es, Gebel, Hellwig, Dames, Dunkelberg (1998) studied this possibility when a "malfunction of a safety hood result[ed] in air flowing from the hood along the arms of the person preparing infusions of antineoplastic drugs" (p. 145) . They studied 10 nurses who may have experienced subst ant ial exposures , matching each nurse to a cont rol based on gender, age, and int ensity of smo king . They measured genetic damage using t he cytokinesis block micronucleus test , repo rting mean micronuclei/ Iff binucleate lymphocyt es (mm/l03 ) , as follows:

Pair Ages Smoking Exposed Cont rol

1 37/37

ns

20

11

2 24/25

s

10

9

3 33/32

s

22

19

4 29/30

ns

13

9

5 23/23

ns

13

7

6 28/29

ns

14

11

7 25/24

ns

12

6

8 38/40

s

21

23

9 32/32

ns

9

4

10 33/34

s

21

14

Kevekordes et. al. used Wilcoxon's signed rank test . Do a sensitivity analysis for t his t est, the Hodges-Lehmann point estimat e and the 95% confidence interval. Compare t he sensit ivity in this example to the examples in the chapter. Do you notice any interesting relationships involving the matched covariates, age and smoking?
3. Sensitivity to finite biases despite an infinite odds ratio. Using data from the Los Ange les County Cancer Surveillance P rogram, Peters, P rest on- Mar t in and Yu (1981) matched 92 cases of brain t umors in child re n less t han lO-years old to referent children wit hou t brai n tumors. They used friends or neighbo rs as referent s, matching for age, race, an d yea r of birth. Attention focused on occupational exposures of parents, including specific industries and chemical exposures. Several of many comparisons gave significant result s by McNemar's test. In particular, there were 10 pai rs discordant for whether the father worked in the aircraft industry, and in all 10 pairs, it was the case whose father was so employed. The point estimate of the odds ratio in the absence of bias is, therefore, infinite: 10/0 = 00. Do a sensitivity analysis for the significance level from McNemar's test.

160 4. Sensitivity to Hidd en Bias
4. Mantel-Haenszel test. In a case-referent study of eosinophilia-myalgia syndrome, Eidson , Philen, Sewell, Voorhees and Kilbourne (1990) matched 11 cases each to 2 noncases or referents, matching for residence, age, and gender. In all 11 matched triples, the case had consumed L-tryptophan, which is an amino acid health food supplement. Reported reasons for taking the supplement included insomnia, stress, and premenstrual syndrome. In 2 matched triples, one referent had used L-tryptophan. In 9 matched triples, neither referent had used Ltryptophan. Perform a sensitivity analysis with the Mantel-Haenszel test .
5. A simple derivation. Consider the bounding probabilities (4.17) for sign-score statistics in matching with multiple controls. These were justified by reference to the general Proposition 3, but a much simpler proof is possible in this special case . Give a brief, direct derivation of (4.17) from (4.15). In this special case , how many treatment as-
signments Z s are in ns in (4.6)? (Rosenbaum 1988)
6. A simple derivation. Obtain the bounds (4.19) for a case-referent
study by evaluating the model (4.6) at u = u" and u = u " . (Hint:
Corollary 15 may be helpful.)
7. A simple derivation. In the absence of ties and zero differences, obtain the simple formulas (4.11) for the expectation and variance of the upper bounding distribution T+ for Wilcoxon's signed rank test.
(Hints: First show that 2::7=1 i = 8(8/1) and 2::7=1 i 2 = 8(8+1~(28+1)
or see Lehmann 1975 who derives these expressions.)
8. A simple derivation. Derive (4.6) from (4.2) . If the general case (4.6) appears difficult, first try the simple special case of matched pairs (4.7), then the slightly more general ease of matching with multiple controls (4.15), and finally return to the general case (4.6).
9. Unbounded covariates. Consider S matched pairs, but replace the assumption that 1 2: Usi 2: 0 by the weaker assumption that 1 2: IUs l - us21 for at least S* < S pairs. In other words , a few pairs, specifically S - S* pairs, may have very large differences in Usi . For Wilcoxon's signed rank statistic T, find two new random vari ables replacing T+ and T- in Proposition 13 that bound the distribution of T. (See Rosenbaum 1987.)
10. Quade's test in matching with multiple controls . With continuous responses and matching with multiple controls in §4.5, Quade's test is an alternative to the stratified rank sum test which gives more weight to matched sets with more dispersion in their responses. However, like the stratified rank sum test , and unlike the aligned rank test, it is possible to tabulate the extreme moments for Quade's test in a

4.9 Problems 161
sensit ivity analysis , so only simple arit hmetic is required. For each matched set s, find the range of responses, max i R si - mini Rsi , and let ds be the rank of the range for set s when the S ran ges are ranked from 1 to S with average ranks for ties. If qsi is the rank of Rsi when t he resp onses in matched set s are ranked within set s from 1
to ns , then Qu ad e's test st at ist ic is I: ;=1 d; I:~~ 1 Z siqsi ' The ranks
of t rea te d subjects within mat ched sets are weighted by the ranks of the dispersions within sets. With matched pair s, n s = 2, ms = 1, the st rat ified rank sum t est reduces to th e sign test , but Quade's test reduces to t he signed rank test . Show that the tabl e of exact moment s in §4.5.3 for t he st rat ified rank sum test may be adapte d for use with
Quade's test. (Hints: Write qsi = d sqsi ' How is the maximum ex-
pectation of d s I: ~1 Z siqsi related to the maximum expectat ion of I:~~1 Z siqsi ?) Developing an idea of Tukey (1957) , Quade (1979) proposed this test for unreplicat ed, randomized complete blocks. Tardif (1987) discussed Qu ad e's t est with replicated treatment s, so Tardif's discussion includes the form of the test describ ed in this problem.
11. Lower bounds in matching with multiple controls. In the discussion of mat ching with multiple controls with continuous responses, the minimum expec tat ion of I:~1 Z siqsi and the maximum variance at this minimum expectat ion are needed to obtain the approxima te upp er bound on t he lower tail probability, prob (T :::; t im ). Show that the expectat ion and variance of I: ~~1 Z siqsi when Us l = 1, . . . , Usa = 1,
= = Us,a+l 0, . . . , us ,n s 0 are:

and

-2

+ I' ",a

2 ",n s

2

0 i=1 qsi 0 i= a+l q s i -2

I/sa =

f a + (n s _ a)

- fLsa '

With qs ,n s 2: .. . 2: qsl , use Proposition 19 to show that the minimum
possible expec tat ion of I:~~1 Z siqsi is mino<a<ns fLsa ' In providing an upper bound on prob (T :::; tim) , why is the minimum expect at ion
used with the maximum vari an ce?

12. Full matching. In a full mat ching , each matched set contains either one treated subjec t and at least one control, or one control and at least one treat ed subject, so min {m s , (n s - m s )} = 1 for each s. Full matching is the optimal form of stratifi cation: it makes subjects in the sa me strat um as comparable as possible; see Rosenbaum (1991c) for proofs and Gu and Rosenb aum (1993) for simulat ion results. Are new method s of sensit ivity ana lysis needed for full ma tching? Or , alte rnat ively, ca n t he methods in §4.5 for matchin g with multiple

162 4. Sensit ivity to Hidd en Bias
controls be easily adapted for use in full matching? (Hint: Consider a matched set with one cont rol and several treated subjects, so m.; =
ns -1. In this set , expr ess 2:7':'1 Z siqsi in terms of Z si = 1- Z si and qsi = (2:7':1 qSj) - qsd
13. Write S-Plu s code to perform a sensitivity analysis for the significance level from Wilcoxon 's signed rank stat istic using (4.9). Hint:
> signedrank
function(dif, gamma)
{
# Performs a sensitivity analysis for the significance # level for Wilcoxon's signed rank statistic. # Uses the large sample Normal approximation with # expectation and variance formulas that allow for # ties and zero differences .
#
# dif i s a vector of matched pair, # treated-minus-control, differences
#
# gamma is Upper Case Gamma , the sensitivity parameter .
#
# Output is the minimum and maximum significance level for a # one-sided, upper tailed test .
#
rk <- rank(abs(dif))
sl <- 1 * (daf > 0) s2 <- 1 * (dif < 0) W <- sumf s l * rk) Eplus <- sum«51 + 52) * r k * gamma)/(l + gamma) Eminus <- sum«sl + s2) * rk)/(l + gamma) V <- sum«sl + s2) * rk * rk * gamma)/«l + gamma)~2) Dplus <- (W - Eplus)/sqrt(V) Dminus <- (W - Eminus)/sqrt(V)
c(l - pnorm(Dminus), 1 - pnorm(Dplus))
}
For th e lead data in Table 3.1, t he differences are:
> lead
[1] 22 5 23 -6 18 25 13 47 15 16 6 1 2 7 0 4 -9 -3 36 25 1 16 42 30 25 23 32 17 9 -3 60 14 14
For r = 3 and r = 4 in Table 4.2, t he bounds for the significance level
are:
> s ignedrank(lead ,3)
[1] 6.661338e-016 1.361531e-002
> signedrank(lead,4)

[1] 0.00000000 0.03878978

4.10 References 163

4.10 References
Aakvik, A. (2001) Bounding a matching estimator: The case of a Norwegian training program. Oxford Bulletin of Economics and Statistics, 63, 115-143.
Aiken, L. H., Smith, H. L., and Lake, E. T. (1994) Lower Medicare mortality among a set of hospitals known for good nursing care. Medical Care, 32, 771-787.
Armitage, P. (1977) Statistical Methods in Medical Research (fourth printing), Oxford, UK: Blackwell.
Balke, A. and Pearl, J . (1997) Bounds on treatment effects from studies with imperfect compliance. Journal of the American Statistical Association, 92 , 1172-1176.
Bickel, P. and van Zwet, (1978) Asymptotic expansions for the power of distribution free tests in the two-sample problem. Annals of Statistics, 6, 937-1004.
Boston Collaborative Drug Project (1972) Excess of ampicillin rashes associated with allopurinol or hyperuricemia. New England Journal of Medicine, 286, 505-507.
Breslow, N. and Day, N. (1980) Statistical Methods in Cancer Research, I : The Analysis of Case-Control Studies. Lyon, France: International Agency for Research on Cancer.
Bross, I. D. J. (1966) Spurious effects from an extraneous variable . Journal of Chronic Diseases, 19, 637-647.
Bross, I. D. J . (1967) Pertinency of an extraneous variable. Journal of Chronic Diseases, 20, 487-495.
Cameron, E. and Pauling, L. (1976) Supplemental ascorbate in the supportive treatment of cancer: Prolongation of survival times in terminal human cancer. Proceedings of the National Academy of Sciences (USA), 73, 3685-3689.
Copas, J. B . and Li, H. G. (1997) Inference for non-random samples (with discussion) . Journal of the Royal Statistical Society, B, 59 , 55-96 .

164 4. Sensitivity to Hidden Bias
Corn field , J ., Haenszel, W ., Hammond , E. , Lilienfeld , A., Shimkin, M., and Wynder, E . (1959). Smoking and lun g cancer: Recent evide nce and a discussion of some questions. Journal of the Nat ional Cancer Institute, 22, 173-203.
Davanzo, P ., Thomas, M. A., Yue, K ., Oshiro, T., Belin, T. , Strober, M., and McCr acken, J. (2001) Decreased anterior cingulate myoinositol/ creat ine spectoscopy resonance with lithium tr eatment in children with bip olar disorder . Neuropsychopharmacology, 24, 359369.
Eat on, M. (1987) Lectures on Topics in Probability In equalities. Amsterdam: Centrum voor Wiskunde en Informatica .
Eidson, M., Philen , R. M., Sewell, C. M., Voorh ees, R. , and Kilbourne, E. M. (1990) L-tryptophan and eosinophilia-myalgia syndrome in New Mexico. Lancet, 335, 645-648.
Fisher , R.A . (1958) Lung cancer and cigar et tes? Natu re, 182, July 12, 108.
Freidlin , B. and Gastwirth, J . L. (2000) Should the median t est be retired from gener al use? American Statistician, 54 , 161-164.
Gastwirth, J. L. (1988) Stat istical Reasoning in Law and Public Policy. New York: Academic.
Gastwirth, J. L. (1992a) Employment discrimination: A statistician's look at analysis of disparate impact claims. Law and Inequality, 11, 151179.
Gastwirth, J. L. (1992b) Methods for assessing th e sensit ivity of statistical comparisons II Sp.o in 'T'itle VTT cases to omitted vari abl es. Ju rimetrics Journal , 19-34 .
Gastwirth, J. L. and Greenhouse, S. (1987) Estimating a common relative risk: Application in equal employment. Journal of the American Stat istical Association, 82 , 38- 45.
Gastwirth, J . L., Krieger , A. M. and Rosenbaum, P. R. (1998a) Cornfield's inequality. In: Encyclopedia of Biostatistics, P. Armitage and T . Colton, eds., New York: Wiley, pp. 952-955.
Gastwirth, J. L. , Krieger, A. M., and Rosenbaum, P. R. (1998b) Dual and simult aneous sensit ivity analysis for matched pairs. Biometrika , 85, 907-920.
Gastwirth, J. L., Krieger , A. M., and Rosenbaum, P. R. (2000) Asymptotic separability in sensit ivity analysis. Journal of the Royal Statistical Society, Series B, 62 , 545-555 .

4.10 References 165
Gibbons, J . D. (1982) Brown-Mood median test. In: Encyclopedia of Statistical Sciences , Volume 1, S. Kotz and N. Johnson, eds., New York: Wiley, pp. 322-324.
Graham, A. J ., Macdonald, A. M., and Hawkes, C. H. (1997) British motor neuron disease twin study. Journal of Neurology, Neurosurgery and Psychiatry, 6, 562=569.
Greenhouse, S. (1982) Jerome Cornfield's contributions to epidemiology. Biometrics, 388, 33-46.
Greenland, S. (1996) Basic methods of sensitivity analysis of biases . International Journal of Epidemiology, 25, 1107-1116.
Gu , X. S. and Rosenbaum, P. R. (1993) Comparison of multivariate matching methods: Structures, distances and algorithms. Journal of Computational and Grapical Statistics, 2, 405-420.
Hajek, J ., Sidak, Z. and Sen, P. K. (1999) Theory of Rank Tests (Second Edition) . New York: Academic.
Hakulinen, T. (1981) A Mantel-Haenszel statistic for testing the association between a polychotomous exposure and a rare outcome. American Journal of Epidemiology, 113,192-197.
Hammond, E. C. (1964) Smoking in relation to mortality and morbidity: Findings in first thirty-four months of follow-up in a prospective study started in 1959. Journal of the National Cancer Institute, 32 , 11611188.
Hannan, J . and Harkness, W . (1963) Normal approximation to the distribution of two independent binomials, conditional on a fixed sum . Annals of Mathematical Statistics, 34, 1593-1595.
Harkness, W . (1965) Properties of the extended hypergeometric distribution. Annals of Mathematical Statistics, 36 , 938-945 .
Herbst, A., Ulfelder, H., and Poskanzer, D. (1971) Adenocarcinoma of the vagina: Association of maternal stilbestrol therapy with tumor appearance in young women. New England Journal of Medicine, 284, 878-881.
Hettmansperger, T . (1984) Statistical Inference Based on Ranks. New York: Wiley.
Hodges, J . and Lehmann, E. (1962) Rank methods for combination of individual experiments in the analysis of variance. Annals of Mathematical Statistics, 33, 482-497.

166 4. Sensit ivit y to Hidd en Bias
Hodges, J . and Lehm ann, E. (1963) Estimat es of location based on rank t ests. Annals of Mathematical Statistics , 34, 598- 611.
Hollan der , M., Proschan , F. , and Sethuram an, J. (1977) Functions decreasing in transposition and their applications in ranking problems. Annals of Statis tics, 5 , 722-733.
Hollander , M. and Wolfe, D. (1973, 1999) Nonpammetric Stat istical Methods. New York: Wiley.
Holley, R. (1974) Remark s on the FKG inequ alities. Communications in Math ematical Physics, 36 , 227-231.
Jick, H. , Miettinen, 0. , Neff, R., et al. (1973) Coffee and myocardial infarction. New England Journal of Medicin e, 289, 63- 77.
Johnson, N., Kotz , S., and Kemp , A. (1992) Univariate Discrete Distributions. New York: Wiley.
Kelsey, J. and Hardy, R. (1975) Driving of mot or vehicles as a risk factor for acute herni at ed lumbar intervertebral disc. American Journal of Epidemiology, 102,63-73.
Kevekord es, S., Gebel, T . W., Hellwig , M., Dames, W ., and Dunkelb erg , H. (1998) Hum an effect monitoring in cases of occ upat ional exposure to antineoplast ic drugs: a method compari son. Occupational and Environm ental Medicine, 55 , 145-149.
Kr ieger , A. M. and Rosenbaum, P. R. (1994) A stochastic compar ison for arr angement increasing functions. Combinatorics, Probability and Computing, 3 , 345-348.
Lehmann, E. (1975) Nonpam m etrics: St atistical Methods Based on Ranks. San Francisco: Holden-Day.
Lin, D. Y , Psaty, B. M., and Kronmal, R. A. (1998) Assessing the sensit ivity of regression results to unmeasured confounde rs in observational studies. Biometrics, 54, 948-963.
Mack, T ., Pike , M., Henderson, B., Pfeffer, R., Gerkins, V., Arthur, B., and Brown, S. (1976) Estrogens and endometrial cancer in a retirement community. New England Journal of Medicin e, 294, 1262-1267.
Mann, H. and Whitney, D. (1947) On a test of whether one of two random variables is stochastically larger than the other. A nnals of Mathematical Stat istics, 18 , 50-60.
Manski, C. (1990) Nonp arametric bounds on treatment effects . American Economic Review, 319-323 .

4.10 References 167
Manski, C. (1995) Identification Problems in the Social Sciences. Cambridge, MA: Harvard University Press.
Mantel, N. and Haenszel, W. (1959) Statistical aspects of retrospective studies of disease. Journal of the National Cancer Institute , 22, 719748.
Marcus, S. (1997) Using omitted variable bias to assess uncertainty in the estimation of an AIDS education treatment effect. Journal of Educational and Behavioral Statistics, 22, 193-202.
Marshall, A. and Olkin, 1. (1979) Inequaliti es: Theory of Majorization and Its Applications. New York: Academic.
McNemar, Q. (1947) Note on the sampling error of the differences between correlated proportions or percentages. Psy chometrika, 12, 153-157.
Miettinen, O. (1969) Individual matching with multiple controls in the case of all or none responses. Biometrics, 22 , 339-355.
Ming, K. and Rosenbaum , P. R (2000) Substantial gains in bias reduction from matching with a variable number of controls. Biometrics, 56, 118-124.
Moertel, C., Fleming, T. , Creagan, E., Rubin, J., O'Connell, M., and Ames, M. (1985) High-dose vitamin C vs placebo in the treatment of patients with advanced cancer who have had no prior chemotherapy : A randomized double-blind comparison. New England Journal of Medicine, 312, 137-141.
Morton, D., Saah, A., Silberg, S., Owens, W., Roberts, M., and Saah , M. (1982) Lead absorption in children of employees in a lead related industry. American Journal of Epid emiology, 115, 549-555.
Mosteller, F . and Tukey, J. (1977) Data Analysis and Regression. Reading, MA: Addison-Wesley.
Nicholson, W ., Selikoff, 1., Seidman, H., Lilis, R , and Formby, P. (1979) Long-term mortality experience of chrysotile miners and millers in Thetford Mines, Quebec. Annals of the New York Academy of Sciences, 330, 11-21.
Normand, S. T ., Landrum, M. B., Guadagnoli, E., Ayanian, J. Z., Ryan , T . J ., Cleary, P. D., and McNeil, B. J . (2001) Validating recommendations for coronary angiography following acute myocardial infarction in the elderly: A matched analysis using propensity scores. Journal of Clini cal Epidemiology, 54, 387-398.

168 4. Sensitivity to Hidden Bias
O'Brien, P. C. and Fleming, T. R. (1987) A paired Prentice-Wilcoxon test for censored paired data. Biometrics, 43, 169-180.
Pearl , J. (2000) Causality. New York: Cambridge University Press.
Peters, J . M., Preston-Martin, S., and Yu, M. C. (1981) Brain tumors in children and occupational exposure of parents. Science , 213, 235-236.
Plackett, R. L. (1981) The Analysis of Categorical Data (second edition). New York: Macmillan.
Psaty, B. M., Koepsell, T . D., Lin, D., Weiss, N., Siscovick, D . S., Rosendaal, F. R, Pahor, M., and Furberg, C. D. (1999) Assessment and control for confounding by indication in observational studies. Journal of the American Geriatrics Society, 47, 749-754.
Quade, D. (1979) Using weighted rankings in the analysis of complete blocks with additive block effects. Journal of the American Statistical Association, 74 , 680-683 .
Rosenbaum, P. R (1986) Dropping out of high school in the United States: An observational study. Journal of Educational Statistics, 11, 207224.
Rosenbaum, P. R. (1987) Sensitivity analysis for certain permutation inferences in matched observational studies. Biometrika, 74 , 13-26.
Rosenbaum, P. R. (1988) Sensitivity analysis for matching with multiple controls. Biometrika, 75 , 577-581.
Rosenbaum, P. R (1989) On permutation tests for hidden biases in observational studies: An application of Holley's inequality to the Savage lattice. Annals of Statistics, 17, 643-653.
Rosenbaum, P. R (1991a) Sensitivity analysis for matched case-control studies. Biometrics, 47, 87-100.
Rosenbaum, P. R (1991b) Discussing hidden bias in observational studies. Annals of Internal Medicine, 115, 901-905.
Rosenbaum, P. R (1991c) A characterization of optimal designs for observational studies. Journal of the Royal Statisti cal Society, Series B , 53, 597-610.
Rosenbaum, P. R (1993) Hodges-Lehmann point estimates of treatment effect in observational studies. Journal of the American Statistical Association, 88 , 1250-1253.

4.10 References 169
Rosenbaum, P. R. (1995) Quantiles in nonrandom samples and observational studies. Journal of the American Statistical Asso ciation, 90 , 11424-1431.
Rosenbaum, P. R. (1999a) Using combined quantile averages in matched observational studies. Applied Statistics, 48, 63-78.
Rosenbaum, P. R. (1999b) Reduced sensitivity to hidden bias at upper quantiles in observational studies with dilated effects. Biometrics, 55 , 560-564.
Rosenbaum , P. R. (1999) Holley 's inequality. In: Encyclopedia of Statistical Sciences, Update Volume 3, S. Kotz , C. B. Read, and D. L. Banks, eds ., New York: Wiley, pp. 329-331.
Rosenbaum, P. R. (2001) Effects attributable to treatment: Inference in experiments and observational studies with a discrete pivot. Biometrika, 88, 219-232.
Rosenbaum, P. R. and Krieger , A. M. (1990) Sensitivity analysis for twosample permutation inferences in observational studies. Journal of the American Statistical Association , 85 , 493-498.
Rosenbaum, P. R. and Rubin, D. B. (1983) Assessing sensitivity to an unobserved binary covariate in an observational study with binary outcome. Journal of the Royal Statistical Society, Series B, 45 , 212218.
Rubin, D. B. (1978) Bayesian inference for causal effects : The role of randomization. Annals of Statistics, 6 , 34-58.
Savage, I. R. (1964) Contributions to the theory of rank order statistics: Applications of lattice theory. Review of the Int ernational Statistical Institute, 32, 52-63.
Schlesselmann, J . J . (1978) Assessing the effects of confounding variables. American Journal of Epidemiology, 108, 3-8.
Skerfving, S., Hansson, K., Mangs, C., Lindsten, J. , and Ryman, N. (1974) Methylmercury-induced chromosome damage in man. Environmental Research, 7, 83-98.
Smith, H. L. (1997) Matching with multiple controls to estimate treatment effects in observational studies. Sociological Methodology, 27, 325353.
St evens , W. L. (1951) Mean and variance of an ent ry in a contingency table. B iometrika, 38, 468-470.

170 4. Sens itivity to Hidden Bias
Tardif, S. (1987) Efficiency and optimality results for tests based on weighted rankings. Journal of the American Statistical Association, 82, 637-644.
Tukey, J . W. (1957) Sums of random part it ions of ranks. Annals of Mathem atical Statistics, 28, 987-992.
Wilcoxon, F . (1945) Individual com parisons by ranking methods. B iom etrics, 1, 80-83.

5
Models for Treatment Effects
5.1 Effects That Vary from Person to Person
The effect of a treatment may vary from one person to the next. One person may benefit or suffer greatly from treatment, while another person may experience little or no effect. In other words, the effect of the treatment on the i t h person in stratum s, namely rr « - TC si, may not be constant, but may change with i and s.
With only brief exceptions, in Chapters 2 to 4, the focus has been on testing the null hypothesis of no tre atment effect, H o : rr« = rca for
i = 1, . .. ,ns , s = 1, . .. , S, and on inference about an additive treatment effect, TTsi = rc« +7 for i = 1, . . . ,ns , S = 1, ... ,S. In applications, these
are two common tasks. Moreover, these two tasks serve to illustrate the conceptual differences between inference in a randomized experiment, in an observational study free of hidden bias, and in an observational study that addresses hidden bias using sensitivity analysis. Nonetheless, treatment effects that vary from person to person are quite common, and associated methods of inference are needed.
In this chapter, several situations are discussed . 1. Binary responses . When the responses under treatment and under
control, rr« and TCsi' are each binary, 1 or 0, say dead or alive, it is often useful to test the null hypothesis of no treatment effect, but the model of an additive treatment effect is not useful. With binary
responses, if rr« = TCsi + 7, i = 1, .. . ,n., s = 1, . . . ,S, then 7
must be 1, 0, or -1, and if 7 = 1, then everyone of the N subjects

172 5. Models for Treatment Effects
must die under treatment and survive under control. A treatment may possibly have no effect on a binary response, but if it has some effect, then it is very likely to affect some individuals and not others. Methods for binary responses are discussed in §5.5.
2. Continuous responses that are not shift ed. In a large randomized experiment, the model of an additive effect has clear implications for the distribution of observed responses in treated and control groups. Examination of the data from such an experiment may clearly indicate that the effect is not additive. Consider as a simple example the case of a randomized experiment that is balanced in the specific sense that the number m s of treated subjects and the number of controls n s - m s do not vary from one stratum s to another. For instance, a
completely randomized experiment, S = 1, and a matched pairs randomized experiment, m s = ns - m s = 1 for all s, are both balanced
in the sense that the term is used here . In such balanced randomized experiments, with a large sample size N, the model of an additive
effect, rt:« = rCsi + T, i = 1, . . . , n s , s = 1, . . . , S , for individu-
als implies that the distribution of observed responses, Rsi , among treated subjects, Zsi = 1, has the same shape and dispersion as the distribution of observed responses, R si, among controls, Z si = 0, but the treated distribution is shifted by T. For example, boxplots or histograms of the distributions of responses in treated and control groups would look the same, except one would be shifted upwards by T . If, in a large, balanced, randomized experiment, the distributions of observed responses are clearly not shifted, then the model of an additive effect is not applicable, and other methods are needed. In this case , several of the models in this chapter may be used instead.
3. Active ingredients and instrumental variables. In some contexts, the treatment may contain an active ingredient, and it is only the active ingredient that has an effect. Assignment to treatment is associated with a higher level of the active ingredient, but doses of this ingredient vary. In this case, it may be natural to think that the treatment effect rt:« - rc« varies with the level of the active ingredient, and is not constant for all subjects who received the treatment. The assigned treatment is an instrument for manipulating the active ingredient; see §5.4.
The material in this chapter is of practical importance for inference in experiments and observational studies, but it does not add new concepts beyond those in Chapters 2 to 4 and the material in this chapter is not used extensively in later chapters. Moreover, after §5.2, the remaining sections may be read in any order, except that §5.5 should be read before §5.6.

5.2 Order Statistics

5.2 Or der Statistics 173

Non addit ive models are often described using order statistics. The N subjects pr esent N pot ent ial resp onses to the control , t c si , i = 1, . . . , ns ,
S = 1, .. . , S. Sort t hese N values into order and label them r C(N ) :2: r C(N -I ) :2: . . . :2: r C (1 ); these are t he N order statistics of t he potent ial
responses to control. In randomization inference, t he pot ential responses,
r C si , are fixed features of the finite populat ion of N subjects ; hence, the order statistics of po tential resp onses to cont rol, r C(k) ' are also fixed . Not ice carefully t hat we obse rve t he response to contro l, rc « , from each sub-
ject who received the control, Z si = 0, bu t we do not observe r c « for treated subjec ts , Z si = 1, so we do not observe any of the order stat ist ics
r C (k ). Nonetheless, it is possible to use the observed dat a to dr aw inferences abo ut r C (k ) . Similar considerat ions apply to the N order stat ist ics
r T( N) :2: rT(N-I) :2: . . . :2: rT( I) formed by sorting the N pot ential responses to t reatment rt: « , i = 1, . .. , ns , S = 1, . . . , S. If the treatment effect were
addit ive, r Ts i = + rCsi T , i = 1, . . . , ns , S = 1, . .. 1 S, then the effect on the
order statistics would also be addit ive, rT(k) = + r C(k ) T , for k = 1, . . . , N .
The N observe d resp onses, R si = + Z si rTsi (1 - Z si ) rc « , may also
be sorted into order, yieldi ng the N observed order statist ics, R (N ) :2: R (N- I ) :2: . . . :2: R (1). T hese differ in two imp ortant ways from the or-
der statistics of the pot ent ial responses. First , th e R (k ) are observed while
the r e te, and rT (k ) are not. Second, since the observed responses R si vary wit h t he t reatment assig nme nt , Z si , t heir order statistics R (k ) are random
var iab les, whe reas t he r C (k ) an d rT(k) are fixed.

5.3 Dilated Effects
5.3.1 Definition of Dilated Effects
In a lar ge balanced randomized experiment , the mod el of an addit ive treatment effect ca nnot pr oduce treat ed responses that are bo t h higher an d more disp er sed than cont rol resp onses, alt hough thi s pattern is not un common in applications. In cont rast , t he model of dilat ed treatment effects can produce this pattern.
In a dil ated effect, the effect is larger when the response under cont rol
is lar ger. The treatment has a dilated effect if rr« = + r Csi b. (rc si) ,
> i = 1, . . . ,ns , S = 1, . . . , S, for some nonn egative, nondecreasing function,
b. (.), so b. (r ) :2: 0 for all rand b. (r ) :2: b. (r * ) for all r r* . Not ice that , with a dilate d effect , the effect of the treatment , rr« - rc a , is nonn egative a nd is lar ger , or at leas t no smaller, when th e response t hat would have been observe d under cont rol, r C si , is higher .
Consider several examples of dilated effects. The null hyp othesis of no t reatment effect , rr « = rc a , i = 1, . . . , n s , S = 1, .. . , S, an d th e model of

174 5. Models for Treatment Effects
an additive treatment effect, rr« = rc« + T, i = 1, .. . ,ns , S = 1, . . . , S, are both trivial examples of dilated effects. A multiplicative effect, rr« = {3rcsi with {3 ~ 1 is a dilated effect with ~ (rcsi) = ({3 - 1) rc« - A linear
a effect, rr« = 0' + ,Br c si with 0' ~ and (3 ~ 1, is a dilated effect with a ~ (rcsi) = 0'+({3 - 1) rca - As a final example, suppose ~ (r) = for r ~ r and ~ (r) > a for r > r with ~ (.) nondecreasing; then individuals who
would exhibit low responses under control, r ~ rCsi , are not susceptible to
the treatment, but the treatment does affect other individuals with rCsi >
r. Because larger control responses t'cs: entail larger treated responses
rr« = rc« + ~ (rc«) when the effect is dilated , it follows that the rTsi's
and rcsi's are ordered in the same way, so the person with the kth largest rt:« also has the kth largest rca - It follows that rT(k) = rC(k) + ~ {rC(k)}' for k = 1, .. . ,N.
When the effect is dilated, the potential responses under treatment are not only higher than the potential responses under control, but also more dispersed. A common way to measure dispersion is by the difference in two order statistics, such as the range, which is the difference between the maximum and the minimum, or the interquartile range, which is the difference between the upper and lower quartiles. When the effect is dilated, the order statistics of potential responses to treatment are farther apart than the order statistics of potential responses to control; that is, for every
k > j,
+ + rT(k) - rT(j) = [rC(k) ~ {rC(k)}] - [rc(j) ~ {rc(j)}] ~ rC(k) - rC(j) ,
because ~ {rC(k)} ~ ~ {rc(j)} ' Bickel and Lehmann (1976) and Shaked (1982) discuss this sort of dispersive ordering of distributions.
Fix a k and let p = rC(k) be the kfN quantile of the potential responses
to control, and consider drawing inferences about the effect of the treatment at this quantile, ~ (p). For instance, if N were odd and k = (N + 1) /2,
then 'p = rC(k) is the median response that would have been observed had
all Nsubjects received control, and ~ (p) is the effect of the treatment at this dtedian response . In this case, because ~ (.) is nondecreasing, ~ (p) is also the median of the N treatment effects, rt:« - T'Csi-
5.3.2 Example: Kidney Function in Cadmium Workers
Thun et al. (1989) compared cadmium workers to controls in an effort to estimate the effects of cadmium exposure on kidney function; see also Thun (1993). Specifically, they compared male workers at a cadmium recovery plant in Colorado to unexposed male workers at a Colorado hospital, after "frequency matching" for an important covariate, age . Kidney dysfunction was measured by {3-2-microglobulin in J-lg/g of creatinine. In Table 5.1, frequency matching is replaced by pair matching for age, yielding 23 pairs,

5.3 Dilated Effects 175

Pair

Cadmium Worker

Hospital Worker

1

107,143

311

2

33,679

338

3

18,836

159

4

173

110

5

389

226

6

1,144

305

7

513

222

8

211

242

9

24,288

250

10

67,632

256

11

488

135

12

700

96

13

328

142

14

98

120

15

122

376

16

2,302

173

17

10,208

178

18

892

213

19

2,803

257

20

201

81

21

148

199

22

522

114

23

941

247

one cadmium worker, one hospital control; see Rosenbaum (1996a, §4.3) for details. For some cadmium workers, the ,B-2-microglobulin levels are much higher and much more dispersed than among hospital controls, and the model of an additive effect is not appropriat.e. This pattern is not uncommon in studies of the effects of occupational hazards, where many exposed subjects appear comparatively normal, while many others have extreme values of a measure of biological impact.
The model of a dilated treatment effect can generate the pattern in Table 5.1. There are 46 = 2 x 23 potential response pairs, (rTsi, rCsi) ' Con-
sider first p = rC(23) and ~ (p), essentially the median potential response
to control and the median treatment effect.

5.3.3 Adjusted Responses with Dilated Effects
The logic of inference about an additive effect requires some changes before it can be applied to a dilated effect. When the treatment has an additive
effect rr« = rca + T for i = 1, .. . , ns , S = 1, .. . ,5, the observed response

176 5. Models for Tr eatm ent Effects
Rs; = Zs;rT si + (1 - Zs;) rc« is simply R s; = rca + Z s;T, and t his fact
permits inference about T to be derived from a test of the null hypothesis
of no treatment effect. For inst an ce, the hypothesis Hi, : T = TO is tested
by calculat ing adjusted responses, Rs; - 7,siTO , which equal rc « if t he null hypothesis is true, and then testing whether the adjusted responses ar e consistent with the null hypothesis of no treatment effect . This logic was appli ed many times in earlier cha pte rs, but it do es not quite work with
dilat ed effects , rr« = rc « + ~ (rc sd . The reason is that , under the model
of a dilate d effect, the adjusted response, R si-Zs;6. (p), do es not equal r c a , does not sa t isfy the null hypo thesis of no treatment effect, and cont inues to
depend on the treatm ent assignment Z si through Rs; - Zsi~ (p) = rc« +
Zs;{~ (rc s;) - ~ (p)) . The following prop ositi on says that alt hough t he magnitudes of the ad -
justed responses ar e not equal to the magnitudes of the resp onses under control, there is a sense in which they have the correct sign. Mor e pr ecisely, th e adjusted response, Rs; - Zs;~ (p) is abov e p just when rc « is above p. Thi s will provide a basis for exact randomization inference and sensitivity
analysis for ~ (p). Write sign(a ) = 1 if a > 0, sign (a ) = 0 if a = 0, and sign (a ) = -1 if a < O.
Proposition 21 If the treatm ent has a dilated effect, for i 1, . . . , ns ,
s = 1, ... , S,
sign {Rs; - Zsi~ (p) - p} = sign (rCsi - p) .
Proof. Recall that ~ (.) is nonnegative and nondecreasing. It follows
that if rc « > p then rt:« = rCsi + 6. (rc s;) > p + 6. (p) , so that R si -
Zsi~ (p) > p. Similarly, if rCsi < P then rr« = rc « +6. (rc si ) < p+ 6. (p) , so that Rsi-Zs;~ (p ) < p. Finally, if ra a = P then rTsi = rCsi+6. (rCsd =
p + ~ (p), so th at Rs; - Zs;~ (p) = p. ·
5.3.4 Testing Hypoth eses About ~ (p)
Und er the model of a dilated effect, for fixed k , consider testing the null
hypothesis Ho : ~ (p) = ~o . Calculate the adjust ed responses, A si =
Rsi - Z si6. 0 , and let A(N) ~ A(N-l ) ~ . .. ~ A(l) be their order statistics. If the null hypothesis is true, then the proposition implies p = A (k )' Let qsi = 1 if A si ~ A (k ) and qsi = 0 if A si < A (k )' Again, by the proposition,
if the null hypothesis is true, qsi = 1 if rc a ~ P a nd qsi = 0 if rc « < p, so
t he test st at istic, T = 2:;=1 2:~::1 Zsiqsi is the number of treated subjects
whose responses under control, rc« , would have exceeded p = rC(k)' A moment's thought reveals that the distribution of T under the null hy-
pothesis has already been determined in earlier chapters. Since the events
rc« ~ P and rc« < P involve only fixed quantities - that is, they do
not involve the treatment assignment Z si - it follows that the scores qsi

5.3 Dila ted Effects 177

TABLE 5.2. Testing Ho : L\ (rC(23») = 100 in the Cadmium Data.

Cadmium Worker

Hospital Control

A si > 247 A si < 247

A..i
Asi

;::: <

247 247

1

~

~L

are fixed when the null hypothesis is true, and T is the sum of fixed bi-
nary scores for the treated subjects. From Chapters 2 and 3 it follows that , in a uniform randomized experiment or an observational study free of hidden bias , the distribution of T under the null hypothesis is simply the
sum of ind ependent hypergeometric random variables . Under the sensitivity analysis model of Chapter 4, the distribution of T is bounded by two
known distributions for each fixed I' ;::: 1, namely two sums of independent
extended hypergeometric random variables ; see Corollary 16.
In the cadmium data in Table 5.1, consider testing the hypothesis that
the effect at the medi an p = rC(23) is Ho : ~ (p) = 100 p,g/g. To do this,
first subtract 100 from the response of each cadmium worker, yielding 46
adjusted responses, A si . Sort the 46 adjusted responses into order, and
find that A(23) = 247. If the hypothesis Ho : ~ (p) = 100 were true, then p = rC(23) = A(23) = 247. Then determine which adjusted responses A si
a are greater than or equal to 247, set t ing qsi = 1 if A si ;::: 247 and qsi = if
Asi < 247. Then summarize the results in Table 5.2. Becaus e the cadmium data are matched pairs, if (qsl,qs2) = (1,1) then 1 = L7~1 Z siqsi, and if
a (qsl, qs2) = (0, 0) then = L7~1 Z siqsi , so under the null hypothesis, T
receives a stochastic contribution from pair s only if the pair is discordant,
qsl + qs2 = 1. In a study free of hidden bias , the hypothesis H o : ~ {rC(2 3)} = 100
would be tested by comparing the 9 + 1 = 10 discordant pairs in Table
5.2 to a binomial distribution with 10 trials and probability of success 1/2. This is analogous to McNemar's test for paired binary data. The chance of
9 or more heads in 10 independent trials with probability of success 1/2 is
0.011, and this is the one-sided significance level. If there were no hidden bias, the data would strongly suggest the effect at the median response under control is greater than 100.
The sensitivity analysis for f ;::: 1 uses Table 5.2 and parallels the sen-
sitivity analysis for McNemar's test in Chapter 4. Specifically, the upper bound on the one-sided significance level is obtained by comparing 9 heads
in 10 trials to a binomial with 10 trials and probability of success I'/ (1 + f) .
For I' = 1, 1.5, and 2, these upper bounds are, respectively, 0.011, 0.046,
and 0.104, so an unobserved covariate that doubled the odds of exposure
to cadmium within pairs matched for age could render plausible the hypothesis H o : ~ (rC(23 )) = 100.

178 5. Models for Treatment Effects
5.3.5 Confidence Intervals for L\ (p)
Confidence intervals are obtained by inverting the test, that is, by testing
each hypothesis H o : ~ (p) = ~o and retaining in the interval the values
not rejected. For instance, in the ab sen ce of hidden bias , the one-sided 95% confidence interval for ~ {rC(23)} in the cadmium data is ~ ~ 147, because the hypothesis Ho : ~ {rC(23)} = 147 yields 9 successes in 11 discordant pairs with binomial tail probability 0.033, while H o : ~ {rC(23)} = 147.0001 yields 8 successes in 10 discordant pairs with binomial tail probability 0.055. If th ere were no hidden bias , we would be 95% confident that the effect at the median was at least 147 /19/9 ,
The sensitivity analysis finds the minimum endpoint of the 95% confi-
dence interval for several r . For r = 1, 1~, and 2, the 95% intervals are, respectively, ~ ~ 147, ~ ~ 81, and ~ ~ -39. A bias of magnitude r = 2
could explain away the ostensible effect of the treatment , ~ {rC(23)} ' at the median response under control, rC(23)'
5.3.6 Point Estimates of L\ (p)
Each hypothesis Ho : ~ (p) = ~o yields a value of the test statistic
T = L;=l L7';:1 Zsiqsi which, in the absence of hidden bias, r = 1, has expectation L;=l (rn, qs+) Ins, where m s = L7';:1 Zsi , qs+ = L7';:1 qsi, and qsi varies with ~o . Using SOLVE(·), find .6. by equating T to its
expectation. In the absence of hidden bias in the cadmium data, both T and its
expectation equal 12 for all ~o on the open interval (309,501) , so SOLVE(·)
returns the point estimate .6. = (309 + 501) /2 = 405.
The sensitivity analysis finds the maximum expectation ofT as L;=l E s, where E; is given by the extended hypergeometric distribution,
and the minimum point estimate is obtained by equating T to its expec-
tation and solving for .6.min using SOLVE(·). The minimum expectation and maximum point estimate are obtained in the same way, but with l/r in place of r.
In the cadmium data, for I' = 1, 2, and 3, the minimum point estimates
of ~ {rC(23)} are, respectively, .6.min = 405, .6.m in = 291, and .6.m in = 262. For instance, with r = 2, the hypothesis H o : ~ {rC(23)} = 291 yields A(23) = 222 and the counts in Table 5.3. Here, T = 8 + 6 = 14; that is,
in 14/23 pairs, including 8 concordant pairs, the cadmium worker had an adjusted response of 222 or more. In the 8 concordant pairs with qs+ = 2, the expected contribution to T is E; = 1, while in the 6 concordant pairs

5.3 Dilated Effect s 179

TA BLE 5.3. Test ing Ho : ~ {TC (23 )} = 291 in the Cadmium Data .

Hospital Control

Cadmium Worker

3l Asi > 222 Asi < 222

Asi Asi

~ <

2221
222 -

-

-

-86

-

-

-

-

-6

with qs+ = 0, the expected contribution to T is Es = O. In t he 9 = 6 + 3
discordant p air s with qs+ = 1, t he maximum expected contr ibut ion to T is
r / (T + 1) and the minimum contribut ion is 1/ (T + 1). It follows that , under the hypothesis H o : ~ {rC (23)} = 291, the expectation of T is bounded
by 8 + 9r / (I' + 1) a nd 8 + 9/ (I' + 1). For r = 2, th e maximum expect at ion
is 8 + (9 x 2) / (2 + 1) = 8 + 18/3 = 14 which equals T . Moreover , for the
hyp othesis H o : ~ {rC (23)} = 291.0001, the st at ist ic is T = 13 with null
expec tat ion 13 ~ , but for the hyp othesis Hi, : ~ {rC(23) } = 290.9999, the
statist ic is T = 14 with null expec tation 13~; therefore, S OLV E (.) returns
'& min = 291.

5.3.7 R educed S ensitivity at Upper QuantiZes
With a dil ated treat ment effect, the effect is lar ger when responses und er
cont ro l are high er . Lar ger effects are ofte n less sensit ive to hidden bias
t ha n smaller effects . On e reason dilated effects are impo rtant is t hat there
may be less sensit ivity to hidden bias for upper quantile effects than for lower quantile effects .
Consid er again t he cadmium workers in Table 5.1. As 32/43 = .744, t he upper quartile of t he 43 potential responses to control may be taken to be rC(32) and t he effect at t he upper qua rt ile is ~ { r C (32) }' Consider testing t wo hyp otheses, namely t he hypothesis of no effect at t he median , H o : ~ { r C (23)} = 0, and t he hyp othesis of no effect at t he upper qu ar t ile, H o : ~ { r C (32)} = O. Under the model of an add it ive treatment effect, these two hyp otheses woul d impl y each other, but under t he model of a dilated effect, ~ { r C (32)} may be lar ger than ~ { rC(23) } ' Table 5.4 compares t he sens it ivity of these two tests, reporting upper bo unds on one-sided sig-
nificance levels. Notice that the test of no effect at the medi an becomes
sensit ive to hidden bias a t r = 2, whereas the test of no effect at the upper qu ar til e becomes sensitive at r = 5. A mod erat e hidd en bias could explain
the so mewhat poorer typ ical kidney function found among cadmium workers, but onl y a ver y lar ge hidden bias could explain the extremely poor kidn ey fun cti on of some cadmium workers.
The concl usion is similar if significance tes ts are repl aced by confidence intervals. For instance , for r = 2, t he minimum one-sided 95% confidence intervals are ~{ rC ( 23 )} ~ - 39 and ~ { rC (32 )} ~ 211. With a moderate
bias of r = 2, no effect at the med ian is plausi ble, but t he smallest plausible
effect at t he upper quart ile is subs tant ial.

180 5. Models for Treatment Effects

TABLE 5.4. Sensitivity of Two Hypoth esis Tests in th e Cadmium Data.
= r Ho: ~ {TC (23)} = 0 Ho: ~ { TC(32 ) } 0

1

.0032

.000031

2

.051

.0023

3

.16

.013

4

.27

.035

5

.38

.065

5.4 Instrumental Variables
5.4.1 The Effects of an Active Ingredient: Efficacy and Effectiven ess
Some treatments work becaus e of an act ive ingredi ent, and som etimes the effects of the ingredient are mor e int eresting than the effects of the treatment. Mor e preci sely, a treatment may conta in a single active ingredient, and may have no effect but through this on e active ingredient. In this cas e, t he effect of the treatment may var y from one person to the next because the dose of t he act ive ingredient var ies. For inst ance, in a randomi zed clinical trial comparing a drug to no treatment, some patients may not consume the full dose of their assigned drug, with t he possible result that a negligible dose of a potent drug had negligible effects. When subject s are randomly assigned to treatment or control, but the doses are set by a process that is outside experiment al control, one may want to use the randomization as the basis for inference, and yet model the effect in terms of the act ual dose of the active ingredient that was received. This is possible, and it is the simplest example of an instrumental varia ble: randomization acts as an instrument for the dose. The approach t aken in this sect ion builds up OIl t he work of Angrist , Imbens and Rubin (1996) along the spec ific HIles developed in Rosenbaum (1996b, 1999b ).
Suppose that the ith subject in strat um s receives the trea tment at
dose d T si if assigned to treatment, Z si = 1, and receives the treatment at
dose dc« if assigned to control, Z si = 0, so the dose actuall y received by
this subject is D si = Z sidTsi + (1 - Z si) dc «- If the treatment effect were
= TTsi -TC si (3 (dT si - d c si), then the treatment effect would dep end solely
on the doses. For inst ance, if controls ar e assign ed to zero do se, dc « = 0, and treated subjec ts are assigned to a 10 mg dose, but the it h subject in stratum s takes non e of her assigned drug, then d T si = 0, and the effect of
the t reat ment for her is TTsi - rc« = (3 (dTsi - dc u ) = 0. In cont ras t, a
patient who would take the full dose would have effect (3 x 10, a nd a pa ti ent who would take half of th e assigned dose would have effect (3 x 5.
Sommer and Zeger (1991) distinguish the "biologic effica cy" of a treatment from its "progr ammat ic effectiveness." The efficacy is, esse nt ially, the effect the drug would have if used in the way it was intended t o be used,

5.4 Instrumental Variables 181
wher eas the programmatic effectiveness reflects also the way the drug is
actually used. In the model rr« - r c « = {3 (dT si - de e) , a 10 mg dose
has efficacy {3 x 10, but if the it h patient in stratum s refuses to take the 10 mg dose and takes 5 mg instead , the effectiveness for this patient is {3 x 5. The effectiveness for this patient is only half the biologic efficacy of the 10 mg dose because the patient took only half the dose. Efficacy and effectiveness are both of interest, but different methods of inference are required.
If the model rTsi - TC si = {3 (dT si - d c si) were true, then one might be interested in estimating {3, rather than estimating a constant or average treatment effect. Notice, however , that rr« - t c« = {3 (dT si - d C si) is a model, and it can be false. For instance, some treatments have programmatic effectiveness but no biologic efficacy-for instance, this is true of placebos. The effect of a placebo is: (i) fully realized by assigning a patient
to the treatment , Z si = 1, and convincing him that he received it, (ii) the
effect is absent if assigned to control, Zsi = 0; and (iii) the magnitude of the effect rr« - rc« is undiminished by covertly setting the dose to zero ,
dTsi = dc« = O. The model that says treatment effect is proportional to
do se increase, rr« - r c « = {3 (dT si - dc u) , is false for placebos .
5.4.2 Exclusion Restriction
The model that says treatment effect is proportional to dose, rr« - rc« =
{3 (dT si - dc u) , satisfies what is known as an exclusion restriction. Informally, the exclusion restriction says that treatment assignment, Z si , is
related to observed response, R si = Z sirTsi + (1 - Z si ) r c e , only through
the realized dose , D si = Z sidTsi + (1 - Z si ) dc «. To see this, notice that if = = = r Tsi - rCsi {3 (dT si - d c si ) , then TTsi- {3dT si r C si- {3d c si Rsi - {3D si ,
z.; so that R s i - {3D si is a const ant, not varying with the treatment assignment
5.4.3 A Numerical Illustration: Noncompliance in a Randomized Trial
Instrumental variable methods are illustrated using a contr ived, artificial example in this section, and using a practical example in §5.4.6. The artificial example is simple and clear because, unlike a practical example, the corr ect answer is known and the responses und er both treatment and cont rol are available. As a numerical illustration, consider the simple, artificial data in Table 5.5 concerning a randomized trial of encouragement to exercise for patients with chronic obstructive pulmonary disease. The trial
is not stratified, S = 1, so the s subscript is dropped. The treatment, Z i , is encour agement to exer cise, Z, = 1 signifying encouragement, Z, = 0 signi-
fying no encour ageme nt. The encouraged exercises ar e walking, jogging, or

182 5. Models for Treatment Effects

TABLE 5.5. Noncompliance wit h E nco uragme nt (Zd to Exercise (D d· dT i de, rr, r c, Zi Di ~
1 1 1 71 71 1 1 71 2 1 1 68 68 0 1 68 3 1 0 64 59 1 1 64 4 1 0 62 57 0 0 57 5 1 0 59 54 0 0 54 6 1 0 58 53 1 1 58 7 1 0 56 51 1 1 56 8 1 0 56 51 0 0 51 9 0 0 42 42 0 0 42 10 0 0 39 39 1 0 39

cycling. There are n = 10 patients, i = 1, .. . , 10, of whom m = 5 = L Z,
were randomly select ed to be encouraged to exercise, the remainder being
controls. For exa mple, i = 1 was encouraged but i = 2 was not. The pair
(dTi , dc i) ind icates whether person i would exercise, with or without en-
couragement, where 1 signifies exercise and 0 indi cates no exercise. For ex-
ample, i = 1 would exercise whether encour aged or not, (dT i , dc i) = (1,1) ,
whereas i = 10 would not exercise in eit her case, (dT i , dc i) = (0,0) , but
i = 3 exercises only if encour aged, (dT i , d c i) = (1,0). The response, (rTi , r ei) is a measure of lung fun ction, FEV or forced
expira t ory volume, on a convenient scale, with high er numbers signifying
better lung function. = Noti ce that r Tsi - rCsi (3 (dT si - dc u) with (3 = 5,
so switching from no exercise to exercise, d T si - d C si = 1, raises lun g function by 5, but encour agement that is ignored, d T si - dc « = 0, does
nothing. For inst ance, encouragement did nothing for subject i = 1, whose response was unchang ed, rr« - rc « = 71 - 71 = 0, because this subject
would have exercised anyway, (3 (dr .·i - d C si) = 5 (1 - 1) = O. However ,
i = 3 exercises only if encouraged , dTsi - dc « = 1, so would improve with
encouragement, rr« - rc« = 64 - 59 = 5 = 5 (1 - 0) . Not ice who responds to encour agement . Subject s i = 1 and i = 2 would
have the best lung function without encouragement, and they will exercise
with or without encouragement. Subjects i = 9 and i = 10 would have the
poorest lung function without encour agement, and they will not exercise
even if encouraged. Subj ects i = 3,4, .. . , 8 have intermediate lung func-
tion without exercise, and the y will exercise only if encouraged . Although
encouragement, Zi , is randomized, compliance with assigned treatment,
(dT i , des), is strongly confounded with the health of the patient. In this context, how can we estimate the efficacy (3?
The two obvious estimates are obviously wrong. The difference between
the mean respons e of patients who exercised and those who did not is

71 + 68 + 64 + 58 + 56 _ 57 + 54 + 51 + 42 + 39 = 14 8

5

5

.,

5.4 Instrumental Variables 183

which is nearly three times f3 = 5. The problem with this estimate is
that the people who exercised were in better health than the people who did not exercise; that is the main reason the people who exercised had better lung function . Similarly, the mean difference between those who were encouraged and those who were not is:

71 + 64 + 58 + 56 + 39 _ 68 + 57 + 54 + 51 + 42 = 3.2,

5

5

which is much less than f3 = 5. The estimate, 3.2, is called the intent-to-

treat estimate, and it is a useful estimate of "program effectiveness" but

not of "efficacy" . Exercise is more effective, in this artificial example, than

a program to encourage exercise , because some patients exercise without

encouragement and others will not exercise even if encouraged. In practice,

one must ask, with different answers in different contexts, whether one is

interested in the effects of encouragement or of exercise, of effectiveness or

of efficacy, and choose an estimator accordingly.
How can we estimate the efficacy f3?

5.4.4 Exact Randomization Inference in Randomized Trials
with Noncompliance
Exact randomization inference about f3 is straightforward and involves no
new principles. Under the model that says response is proportional to
dose , rr« - rca = f3 (dT si - dcsi), consider first testing the null hypoth-
esis H o : f3 = f30 · First, compute the adjusted responses, Rsi - f30D si,
which equal the constant rr« - f3dTsi = rc« - f3dcsi = asi, say, when the
null hypothesis is true. For testing the true hypothesis, H o : f3 = 5, the
adjusted responses are given in column five of Table 5.6. Now perform a randomization test of the null hypothesis of no effect of encouragement on the adjusted responses. For instance, the Wilcoxon rank sum test might be used , ranking the adjusted responses, as in the last column of Table 5.6, and
summing the ranks for encouraged patients, T = 10+8+5+3.5+1 = 27.5.
C5 In this randomized experiment, there are 0) = 252 ways to pick m = 5
of n = 10 subjects at random to receive encouragement, and each assignment has probability 1/252. A random choice of 5 of the 10 slightly tied ranks in Table 5.6 produces a rank sum of 35.5 or more with probability greater than 0.05, so T = 27.5 does not lead to rejection of the hypothesis
H o : f3 = 5. Notice carefully that both actual exercise, Di, and encouragement, Zi,
play a role in this test. The effect of the treatment is expressed in terms of actual exercise, Di , whereas the test relies on the random assignment of encouragement, Zi. Actual exercise, Di, is strongly confounded with initial health; it cannot be the basis for a randomization test. Encouragement, Zi, has an effect only if exercise behavior changes; encouragement alone does not describe the effect of exercise.

184 5. Models for Treatment Effects

TABLE 5.6. Testing Ho : {3 = 5 Using the Rank Sum Statistic.

FEV Exercise Encouragement

~

o,

z,

Rank

1 71

1

1

66

10

2 68

1

0

63

9

3 64

1

1

59

8

4 57

0

0

57

7

5 54

0

0

54

6

6 58

1

1

53

5

7 56

1

1

51

3.5

8 51

0

0

51

3.5

9 42

0

0

42

2

10 39

0

1

39

1

The test just described is an exact test about efficacy derived from
the random assignment of encouragement, Z si, and the model which as-
serts that programmatic effectiveness is proportional to the change in ex-
ercise, rr« - rc« = (3 (dTsi - dcs;), and it is valid in giving correct significance levels. Specifically, if the null hypothesis H o : (3 = (30 is true, then the adjusted responses Rs i - (3oDsi equal rr« - (3dTsi = rCsi (3dc si = a si , which satisfy the null hypothesis of no treatment effect, and
t (Z, R - (3oD) = t (Z, a) has its usual null randomization distribution,
where D = (D ll,D12, . .. , D S,ns )T and a = (aU,a12, ' " ,as,ns)T .
When does this test have power? Suppose that we test H o : (3 = (30 when
in fact (3 i- (30' This test will have no power - more precisely, it will have
power equal to the level of the test - if no one responds to encouragement
by starting to exercise, that is, if dT si = dc« for all s, i . To see this, notice
that if dT si = dcu then rr« - rc« = (3(dT si - dCsi) = 0, and therefore
rT si - (3odTsi = rca - /30 dc si and Rsi - ,BoD si is constant, not varying with Zsi, for every for every (30 ' Encouragement must produce some increase
in exercise - that is, (dTsi, dCsi) = (1,0) must occur frequently - if this test is to have much power.
Notice that the randomization test of no efficacy, H o : (3 = 0, is identical to the randomization test of no treatment effect , H o : rr« = rC si, for all s, i in Chapter 2. The two tests give identical significance levels in every application. The test of Ho : (3 = 0 can discover efficacy only if the treatment has some effectiveness , as judged by the randomization test for
the intent-to-treat analysis that ignores the dose received, Ds i . As discussed in Chapter 2, a Hodge-Lehmann estimate equates a statistic
to its null expectation and solves approximately for the parameter using
SOLV E (.). In a randomized experiment with S = 1, the rank sum statistic
has null expectation m (n + 1) /2. To estimate (3, compute the rank sum
statistic from the adjusted responses, R, -(3oDi , and use SOLVE (.) to find
the ~ that gives approximately m (n + 1) /2 as the value of the statistic.

5.4 Instrument al Vari abl es 185
In the example, m (n + 1) /2 = 5 (10 + 1) /2 = 27.5, and the rank sums compute d with /30 = 4.9999, 5, and 5.0001 are, respectively, T = 28, 27.5, and 27, so the estimate, 7J = 5, is exactly the correct value, /3 = 5, in this
artificial exa mple.
A 100 (1 - a) % confidence set for /3 is obtained by testing each hypo thesis H o : /3 = /30 at level a and ret aining the values of /30 not reject ed by
the test. The confidence set need not be an int erval, bu t if an int erval is
desired , the confide nce int erval may be defined as t he shortes t closed inte rval t hat contain s the confid ence set-adding point s to a confidence set
cannot decrease its chance of covering the true /3.
The confidence set beh aves in a manner that is both sens ible and un-
usu al. If the model rr« - Te si = /3 (dT si - desi) is severely wrong , the test may reject every value of /3, returning an empty confidence set. This might
happen , for example, with a treatment whose effect s are dramatic in size
but are essent ially placeb o effects. In this case, the assigned treatment, Z si , may st rongly pr edict the response R si, but the dose D si may not . If the model is clearly wrong, then it is reasonable for a confidence interval to reject the model. If the non compliance with encourageme nt is very exte n-
sive, so what people ar e enco uraged to do, Z si , is weakl y relat ed to what t hey actually do , D si , then Z si is said to be a "weak instrument" for D si ,
a nd in this case, the data may contain little inform ation abo ut /3. A weak
instrument will be correctly reflect ed in the confidence int erval, which may
maintain its 100 (1 - a) % exact coverage by becoming longer , perhaps in-
finite in length. Of cour se, when the data contain little informa t ion, a confide nce interval should say so.
The example above illustrates t his. With n = 10, m = 5, t he null distributi on of t he rank sum stat istic has Pr (T 2 36) = .048 and Pr (T 2 30) =
.345. In t esting H o : /3 = /30' no matter how small /30 is set , it is not
possible in the example to pr oduce a rank sum of T = 36, so t he one-sided
95% confidence interval is /3 2 - 00. However , t he rank sum is T = 30 for Ho : /3 = 1.9999 and T = 29 for Ho : /3 = 2.0001, so the (2/3) - con fi dence interval is /3 2 2. Du e t o noncompliance and a small sa mple size, there is not much information abo ut /3 in these data, but there is a little. (T he
minimum wage example in §5.4.6 is larger, with a stronger instrument, and it produces informative 95% confidence intervals.)
Traditional discussions of instrumental variables distinguish between the
ass umpt ions that make the problem eit her "identified" or "unidentified." Rou ghly sp eaking, if the problem is identified, then the confidence interval
for /3 gr adually shrinks t o t he single point /3 as th e sample size increases.
The idea of identification draws a bright red line between two types of prob-
lems. Is this red line useful ? In some problems that are form ally identified, the instrument is very weak, and with pr actical sample sizes, there is little
informa tion about /3. In principle, in a problem t hat is formally not identified , there may be quite a bit of information abo ut /3, perh aps enough

186 5. Models for Treatment Effects
for some particular practical decision; see Rosenbaum (1997) for discussion. Arguably, a bright red line relating assumptions to asymptotics is less interesting than an exact confidence interval describing what has been learner! from the evir!ence actually at hand .
5.4.5 Sensitivity Analysis in Observational Studies with Instrumental Variables
Instrumental variables are used in observational studies as well as experiments, but in an observational study, the treatment or instrument, Z si, is not randomly assigned . This section describes sensitivity analysis with an instrumental variable in parallel with the randomization inference with instrumental variables in the previous section. The analysis makes two assumptions: first, treatments, Zsi, are governed by the model used in Chapter 4; second, that effects are proportional to dose, rr« - rc« = 13 (dTsi - dcu) .
Consider testing the hypothesis H o : f3 = f30 using one of the test statistics T = t (".) discussed in Chapter 4, perhaps the signed rank statistic with matched pairs. If the null hypothesis were true, then the adjusted responses, Rsi - f3oDsi' would equal rr« - f3dTsi = rCsi - f3dcsi = asi, which are constant, not varying with the treatment assignment, Z si, so the asi would satisfy the null hypothesis of no treatment effect . In other words, if Ho : f3 = f30 is true, the adjusted responses Rsi - f30 D si satisfy the null hypothesis of no treatment effect, and t (Z, R - f3oD) = t (Z , a) has the null distribution described in Chapter 4. This leads to tests, confidence intervals by inverting tests, and Hodges-Lehmann point estimates. In other words, sensitivity analysis with an instrumental variable entails a different
model for treatment effect, namely rrc - rCi = f3 (dTi - dc i), and hence a
different definition of adjusted responses R si - f3oDsi' but beyond this no new principles or techniques are involved. An example is given in the next section.
5.4.6 Example: Minimum Wages and Employment
In an interesting, thoughtful, careful, but nonetheless controversial study, Card and Krueger (1994, 1995, 1998,2000) examined the possible effects of increases in the minimum wage on employment. Economic theory is usually understood as predicting that a forced increase in the price of labor will reduce demand for it , that is, put people out of work. Economists are often critical of the minimum wage arguing that it tends to hurt the very people it is intended to help. Card and Krueger compared New Jersey to adjacent eastern Pennsylvania before and after New Jersey increased its minimum wage from $4.25 to $5.05 per hour, or about 19%, on 1 April 1992. They looked at changes in employment in the fast-food industry, specifically

5.4 Instrumental Variables 187
Burger King, Kentucky Fried Chicken , Wendy's, and Roy Rogers . Here, their data will be used to illustrate sensitivity analysis with an instrumental variable. Card and Krueger have made their data publicly available using FTP; see Card and Krueger (1995, p18) for specifics. Card and Krueger found "no evidence that the rise in New Jersey 's minimum wage reduced employment at fast-food restaurants in the state."
The appendix, §5.10, contains a portion of Card and Krueger's data, intended solely to illustrate methodology. The data describe New Jersey and Pennsylvania, before and after New Jersey's wage increase, for 66 matched pairs of restaurants. Two variables are described: full-time equivalent (FTE) employment, and starting wages. For example, the New Jersey restaurant in pair #5 reported 23 full-time equivalent employees before the increase and 19 afterward, while its paired Pennsylvania restaurant reported 22.75 FTEs before and 21 afterwards. In this same pair, the starting wage rose from $4.25 to $5.05 in the New Jersey restaurant , but stayed steady at $4.25 in the Pennsylvania restaurant. Pair #5 exhibits the pattern anticipated by economic theory: wages rose in New Jersey from the old minimum to the new one , and employment declined , whereas the Pennsylvania restaurant changed little. Obviously, different patterns are seen in different restaurants. The restaurants were paired for chain and for starting wages before the increase. P airs 1 through 30 are Burger Kings , pairs 31 through 40 are Kentucky Fried Chicken restaurants, pairs 41 through 55 are Roy Rogers, and pairs 56 through 66 are Wendy's. A few of the employment numbers indicate that the interviewers and respondents may now and then have misunderstood one another, as happens in most if not all surveys. (For instance, in pair #29, the Pennsylvania Burger King reported a decline from 70.5 FTE before to 29 after.)
Notice that some New Jersey restaurants were paying close to or more than $5.05 as a starting wage before the increase in the minimum wage, and many of these restaurants did not substantially increase their starting wages. For example, in pair #29, the New Jersey Burger King was paying $5.12 before the increase and $5.05 afterwards. One might reasonably expect that changes in minimum wage laws will have effects only to the extent that they change wages, so that the New Jersey Burger King in pair #29 should experience little or no effect.
Let the response be the increase in the log of employment, so R ll = log (26.50) -log(15.50) , and let the dose be the increase in the log of start-
ing wages, so D ll = log (5.05) - log (4.25). The model rr« - rcu = 13 (dT si - dCsi) predicts a larger effect of the minimum wage, rr« -rCsi , on
a restaurant that was forced to make a larger change in wages, dTsi - dc«-
Because of the log scale , the parameter {3 is the elasticity. Notice that 13 re-
lates wage changes in either state to employment, as distinct from relating a change in the minimum wage law to employment.
The hypothesis H o : 13 = 130 is tested by computing the adjusted responses, Rsi - 13oD si , and applying Wilcoxon 's signed rank test to them,

188 5. Models for Treatment Effects
as in §4.3.3. Indeed, the test of H o : (3 = 0 is identical to the test in
§4.3.3. Even in the absence of hidden bias , r = 1, the null hypothesis
Ho : (3 = 0 is plausible when tested against the predicted decline in employment, Hi, : (3 < 0, with approximate one-sided significance level from the randomization distribution of the signed rank test of 0.87. In the absence of bias, the one-sided , approximate 95% confidence interval is (3 ~ -0.29. For a restaurant that increased its starting wage from the old minimum to the new minimum, D si = log (5.05) - log (4.25) = 0.172, a (3 = -0.29
yields -0.29 x 0.172 = -0.050 or about a 5% decline in employment . In
other words , in the absence of hidd en bias , the confidence interval rejects hypotheses that say the decline in employment is more than 5% for restaurants that faced the full impact of the wage increase. In the absence of hidden bias , the Hodges-Lehmann point estimate of (3 is actually positive, specifically 0.64, suggesting an increase rather than a decrease in employment.
Although the data give no sign of a decline in employment associated with wage increases, the results are sensitive to moderate biases. For example, the hypothesis Ho : (3 = -1 entails roughly a 17.2% = -1 x 0.172 decline in employment for a restaurant raising wages from the old minimum of $4.25 to the new minimum of $5.05, a substantial decline in employment.
In the absence of hidden bias, r = 1, the hypothesis H o : (3 = -1 is clearly
rejected with one-sided significance level of 0.004, but the hypothesis be-
comes barely plausible when r = 1.34, with upper bound on the significance level of 0.0506, and plausible when r = 1.5 with upper bound on the signif-
icance level of 0.10. The minimum Hodges-Lehmann point estimate equals
-1 at about r = 2.2. The 66 matched pairs provide no sign of a decline in
employment with wage increases, and they are consistent with increases in employment, but they are also sensitive to moderate biases, so a substantial decline in employment could be hidden by biases of moderate size.
5.5 Attributable Effects: Binary Responses
5.5.1 What Are Attributable Effects'?
The attributable effect is the effect of the treatment on the treated subjects. Attributable effects permit randomization inferences in contexts where the treatment effect cannot be additive.
In this section, there is a single stratum, S = 1, so the s subscript is dropped, and the responses, rr, and rei, are binary, 1 or 0, with a nonnegative effect, rr, ~ rei- Then the effect of the treatment on subject i is Oi = rrc - ret , where Oi = 0 or Oi = 1. Notice that Oi = 1 if (rTi, rCi) = (1,0) so that exposure to the treatment causes a response in subject i who would not have responded in the absence of treatment. Also, Oi = 0 if either (rTi>ci) = (0,0) or (rTi , rc.) = (1,1) so exposure to the

5.5 Attributable Effects: Binary Responses 189

TABLE 5.7. The Observed 2 x 2 Contingency Table.

Response

Treated

Control

1

2::= z, rr ,

2::=(1 - Zi) rc.

o

2::= z, (1 - rTJ 2::=(1 - Zi) (1 - rCi)

Total

m

n- m

treatment does not alter the response of subject i, but that response may
be 1 or O. Write 8 = (81) ' ' ' ,8 n )T, which is an n-dimensional parameter with binary coordinates. Hamilton (1979) uses 8 to express the common
measures of association in a 2 x 2 contingency table.
The attributable effect is A = 2::=7=1 Z, (rTi - rCi) = 2::=7=1 Zi8i ; it is the
number of treated responses actually caused by exposure to the treatment.
If there are m = 5 treated subjects, and 2 = 2::=7=1 ZirTi exhibit responses,
but exactly one of these, for subject j with Zj = 1, would have occurred
anyway under control, rr, = rCj = 1, then the attributable effect is A = 1
response caused by exposure to treatment. Under the null hypothesis of no
treatment effect, Ho : rr, = rCi , i = 1, . .. , n , the attributable effect A is
O. The attributable effect A depends not only on the parameter 8, but also
on who received treatment, Z. In a randomized experiment, A would vary
with the random assignment of treatments Z. That is, the attributable
effect A is an unobserved random variable, not a fixed parameter. Can
one draw inferences about the value of A?

5.5.2 2 X 2 Tables and Attributable Effects
Table 5.7 is the observed 2 x 2 contingency table. Notice carefully that in this table, treated subjects reveal their response to treatment, rrc, and control subjects reveal their response to control, rCi .
In contrast, Table 5.8 is the 2 x 2 contingency table that would have been observed had all subjects received the control , so this table involves only potential responses to control, rei- Notice that the marginal row and column totals in Table 5.8 are fixed, not varying with the treatment assignment Z, but the row totals of Table 5.7 change as Z changes when the treatment has an effect. Under the null hypothesis of no treatment effect,
Ho : rTi = "c« , i = 1, .. . , n , Tables 5.7 and 5.8 are equal. In a randomized
experiment, the upper corner cell, 2::= Z, rCi, in Table 5.8 has the hypergeometric distribution, and this is the basis for Fisher's exact test of the hypothesis of no effect. As noted in Chapter 4, for this test of the hypothesis of no effect, the sensitivity to hidden bias in an observational study is examined by comparing the observed Table 5.7 to two extended hypergeometric distributions; see Corollary 15. The question at hand is whether we can use similar reasoning to draw inferences about the attributable effect A when the null hypothesis of no effect does not hold.

190 5. Models for Treatment Effects

TABLE 5.8. Responses Had Everyone Received Control.

Response

Tre a t e d

Control

Total

1

~Zirci

~(1- Zdrci

~rci

n

z, ~ (1 - res) ~(1 - 7,i) (1 - rCi) ~(1 - rCi)

Total

m

n- m

n

TABLE 5.9. The Observed Table Adjusted for the Attributable Effect .

Response

Treated

Control

1

~ZirTi - ~Zi8i

~(1- Z i)rc i

o

{~Zi (1 - rTi)} + ~ Zi s, ~(1 - Z i) (1 - rCi )

ThW

m

n-m

In Table 5.9, the observed Table 5.7 is adjusted by subtracting the at-
tributable effect A = ~ Z; 8i from the upper left corner cell and adding it
to the lower left corner cell. Inference about A is based on the observation
that Table 5.9 equals Table 5.8. Informally, one asks: After what adjustments A = ~ Z, 8i does Table 5.9 app ea r to satisfy the null hypothesis of no treatment effect?

5.5.3 Testing Hypotheses About is
Consider testing the hypothesis Ho : 0 = 00 where 00 is an n-dimensional vector with 1 or 0 coordinates. For some hypotheses 00, inspection of the
data immediately shows the hypothesis is false. Since the treatment has a
nonnegative effect , rrc ~ rei - a treated subject without a response, Z, = 1
and R; = 0, must have 8i = 0, and a control subject with a response, Z, = 0 and R; = 1, must have 8i = O. Call the hypothesis Ho : 0 = 00
compatible if it satisfies these conditions and incompatible otherwise. The
one true hypothesis is compatible for every Z.
If the hypothesis Ho : 0 = 00 is incompatible , reject it with certainty,
that is, with type 1 error rate of zero. Otherwise, if the hypothesis is compat ible, compute A o = ~ Z, 80i . If the hypothesis H o : 0 = 00 is true,
then Ao = ~ Z; 80i = A = ~ Zi 8i , so Table 5.9 may be computed, and it
equals Table 5.8. In a randomized experiment, the hypothesis H o : 0 = 00 is tested by comparing this table to the hypergeometric distribution , whereas
in an observational study, the sensitivity analysis compares the table to
two extended hypergeometric distributions to bound the significance level.

5.5.4 Confidence Sets for is and Inference About A
oA confidence set for 0 may be obtained by t esting every hypothesis H o : = 00 and retaining the compatible hypotheses not reje cted by the test. For instance, if the test in the previous section rejects at the 0.05 level

5.5 Attributable Effects: Binary Responses 191

TABLE 5.10 . Station Design and Mortality.

No Pit Pit

Dead

16 14

Alive

5 18

hypotheses H o : f5 = f50 if Ao < a and accepts if Ao 2: a, then a one-sided
confidence set for f5 is the set of all compatible f50 with Ao = L Z, 00i 2: a.
The confidence set for f5 is awkward to examine because it is a set of n-
dimensional vectors with binary coordinates. However, it is easy to describe
the confidence set in a useful manner. Consider, for instance, the one-sided
confidence set for f5 consisting of all compatible f50 with Ao = L Z, OOi 2: a.
It is the set of all treatment effects f5 with at least a responses among treated
subjects actually caused by the treatment, that is, with at least a responses
attributable to treatment. An n-dimensional confidence set for f5 becomes
a one-dimensional set of plausible values for A.

5.5.5 Example: Death in the London Underground
In the London Underground, some train stations have a drainage pit below the tracks. The pit is about a meter in depth and runs the length of the station platform. When a passenger falls or jumps or is pushed from the station platform under a train - an "incident" in the language of the British Railway Regulations Act of 1893-such a pit is a place to escape contact with the wheels of the train. Using legally required records of 53 such incidents, Coats and Walter (1999) compared mortality in stations with and without such a pit. Their data are in Table 5.10. In stations without a pit, 16 of 21 incidents resulted in death, whereas in stations with a pit, 14 of 32 incidents resulted in death.
If Fisher's exact randomization test for a 2 x 2 table is applied , the one-
sided significance level is 0.0193, so if there were no hidden bias, r = 1, then
it would not be plausible that A = 0 deaths were caused by the absence of
a pit. In the absence of hidden bias, r = 1, all hypothesis H o : f5 = f50 with
L A o = Z; OOi = 1 are rejected with one-sided significance level 0.0439,
so neither zero nor one attributable death is plausible. However, in the
absence of hidden bias, r = 1, all hypotheses Ho : f5 = f50 with Ao = L Z, OOi = 2 attributable deaths are accepted with one-sided significance
level 0.0875 , so with 95% confidence, at least 6.7% = 2/30 of the deaths following incidents would be attributable to the absence of a pit. The test for A = 1 is performed by applying Fisher's exact test to Table 5.10 after
subtracting A = 1 from 16 and adding it to 5, altering the row totals.
In conducting an analysis of sensitivity to hidden bias, as discussed in Chapter 4, exact, sharp bounds on the significance levels from Fisher's exact test are obtained by comparing a 2 x 2 table to two extended hypergeometric
distributions, one with parameter r and the other with parameter l/r.

192 5. Models for Treatment Effects
This comparison is made after adjusting the table for the hypothesized
value of A. For instance, with r = 1.5, the upper bound on the one sided significance level with A = 0 is 0.0885 and for A = 1 it is 0.1634, so the
study is sensitive to biases of moderate size.
5.6 Attributable Effects: Displacements
5.6.1 What Are Displacements?
When a treatment has a nonnegative effect, displacements are a fairly general way of measuring the magnitude of the treatment effect . Displacements compare the observed treated responses to the unobserved distribution of responses that would have been seen had all subjects received the control.
This section considers a study without strata, in which the treatment has a nonnegative effect, rTi ~ rei- Recall that the n subjects offer n
potential responses to treatment and control, (rTi' rCi) , i = 1, ,n, and
these give rise to two sets of order statistics, rT(n) ~ rT(n-l) ~ ~ rT(l) and rC(n) ~ rC(n-l) ~ . . . ~ rC(l) ' Since some subjects receive treatment and others receive control, these order statistics are not observed. The
n observed responses, R, = ZirTi + (1 - Zd ret , yield n observed order
statistics, R(n) ~ R(n-l) ~ . .. ~ R(1). Fix an integer k so that the kin quantile of potential responses to control
is rC(k). Assume that rC(k+l) > rC(k), and let (J be any value strictly between rC(k) and rC(k+l) , so rC(k+l) > (J > rC(k) ' For instance, if n
is even and k = n/2, then (J is between the two middle order statistics of responses to control, and is a median. As seen below, the observed data may reveal that no such (J exists under certain hypotheses, so such hypotheses about (J may be rejected with certainty.
The ith subject has a displacement around () if rr, > () > ret- In
words, the ith subject has a displacement if the subject would have a response below (J under control, but would have a response above (J under treatment. For instance, if n is even and k = n/2, then the ith subject has a displacement if the response under control is below the unobserved median of the n potential responses under control, but the response under treatment is above the control median. If kin = 95%, then a displacement signifies a fairly typical response rCi under control together with a response rr« under treatment that would be unusually high under control.
Write S, = 1 if subject i has a displacement , that is, if rrc > () > rCi '
The number of treated subjects who experienced displacements because
they were exposed to treatment is A = L Zi8i.
Write rTi = 1 if rr: > (J, and rTi = 0 otherwise. In parallel, write
= = = rCi 1 if res > (J, and rCi 0 otherwise. Then 8i rTi - rCi' If (J
were known, then inference about A could be based on the method in the previous section for inference about binary responses. However , (J is not

5.6 Attributable Effects: Displacements 193
known, because it depends on the n unobserved order statistics of responses to control, TC(n) :2: TCCn-l) :2: . . . :2: TC(l) ' Given that () is not known, how can inferences be drawn?

5.6.2 Inference About Displacements

Inference about displacements is based on the following proposition from Rosenbaum (2001) . Although () is not known, the proposition says that
the observed order statistics, RCn) :2: RCn-l) :2: ... :2: RCI ), together with
a hypothesis about A = I:: ZiDi pin down () narrowly enough to permit
inferences.

I::i Proposition 22 If a = ZiDi , then R Ck+ l - a) > () > R Ck- a) '

Proof. By assumption TC(k+l) > TeCk), so there are exactly n - k sub-

jects with TCi > (), and since TTi :2: TCi it follows that these n - k subjects
all have R; > (). Since a = I::i ZiDi there are exactly a other subjects, not

included among the n - k subjects, with R; = TTi > () > TC i . For the

remaining k - a subjects, () >~. So there are exactly n - k + a subjects

with R; > () and exactly k - a subjects with () >~. This means that
o R Cn) :2: R Cn- l ) :2: . . . :2: R Ck H- a) > > R Ck- a) :2: .. . :2: R CI )' ·
I::i Notice carefully that if R Ck+ l - a) = R (k-a ) then there is no () such that
a = ZiDi displacements around () have occurred among treated subjects.

Inference proceeds as follows. To test a hypothesis, Ho : 8 = 80 with

= I:: = Ao

Zi DOi' find R(k+l-Ao) and RCk-Ao)' If R(k+l-Ao) RCk-Ao),

reject the hypothesis with certainty, that is, with type one error rate of

zero. Otherwise, if RCk+I-Ao) > R(k-Ao), then under the null hypothesis,

a treated subject, Z, = 1, has rTi = 1 if R: > R Ck- Ao) and rTi = 0 otherwise, while a control subject, Z, = 0, has rCi = 1 if ~ > R Ck-Ao) and rCi = 0 otherwise. The hypothesis H o : 8 = 80 may now be tested using

the methods in the previous section for attributable effects with binary

responses.

5.6.3 Example: Cytogenetic Effects of Benzene Among Shoe Workers
In Bursa, Turkey, Tunca and Egeli (1996) identified m = 58 shoe workers who used glues containing substantial quantities of benzene. The workers were exposed for periods ranging from 5 to 50 years , in conditions with insufficient ventilation, and with benzene exposure levels 10 to 30 times the maximum allowable concentration. In an effort to estimate the cytogenetic changes caused by long-term occupational exposure to benzene, Tunca and
Egeli compared the shoe workers to n - m = 20 controls who were also
residents of Bursa, Turkey, but who were believed to not have exposures to benzene.

194 5. Models for Tre atment Effects
For each of the n = 78 subjects, roughly 20 metaphases were analyzed for chromosomal aberrations, but the number of metaphases analyzed varied from person to person. Here, attention focuses on the percentage of gaps found for each subject. The data are fairly coarse exhibiting ties . Sorted into order, the percentages of gaps for the 58 shoe workers are 0.00, 0.00, 5.55, 6.66, 7.69, 8.33, 8.33, 8.69, 9.09, 9.09, 9.52, 10.00, 10.00, 10.00, 10.00, 10.52, 11.11, 11.11, 11.76, 11.76, 11.76, 11.76, 11.76, 12.00, 12.50, 13.04, 13.33, 13.33, 13.33, 13.33, 13.51, 14.28, 15.38, 15.38, 15.38, 16.66, 17.64, 17.64, 18.18, 18.60, 19.04, 19.23, 19.23, 20.00, 20.00, 20.00, 20.00, 20.00, 20.00, 21.05, 23.07, 23.80, 24.13, 25.00, 27.27, 29.41, 30.00, and 33.33. For the 20 controls, the sorted percentages of gaps are: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 5, 5, 5, 5, 5, 8, and 10. Many of the shoe workers had many more gaps than did most of the controls.
The unobserved median of n = 78 potential responses to control is the
average of the 39th and + 40th order statistics, {rC(39) rC(40)} /2. There-
fore, let k = 39, so that subject i is defined to have a displacement above the control median if there is a () such that rC(40) > () > rC(39) and rr, > () > rCi. Roughly speaking, subject i has a displacement above
the median if he would have had fewer than the median number of gaps that would have been seen had all n = 78 subjects escaped exposure to benzene, but instead would have had strictly more than that median had he been exposed to benzene.
In Table 5.11, three groups of hypotheses are tested assuming no hidden
bias , r = 1, namely each compatible hypothesis H o : d = do with A o = 1,
with Ao = 19, and with Ao = 25. Since R(39) = 11.76 > 11.11 = R(38), if A = 1, then () is between 11.11 and 11.76. Since none of the observed
responses for controls is above 11.11, the first 2 x 2 table in Table 5.11
is obtained, with significance level P < 0.00001, so it is not plausible that only A = 1 treated subject experienced a displacement from 11.11 or below
to 11.76 or above. This significance level is based on the hypergeometric distribution. Similarly, it is not plausible that only A = 19 treated subjects
had displacements from R(20) = 5 or below to R(21) = 5.55 or above. Now, R(15) = . . . = R(20) = 5. It is plausible that A = 25 or fewer treated
subjects had displacements from R(14) = 4 or below to R(15) = 5 or above. The sensitivity analysis for r 2 1 is similar except that the resulting
2 x 2 tables in Table 5.11 are compared to extended hypergeometric distributions to obtain bounds on the significance level. For instance, for testing
hypotheses Ho : d = do yielding Ao = 19 displacements attributable to treatment, the upper bounds on the significance level for r = 1,2,3, and 4
are 0.000025, 0.0027, 0.020, and 0.058. For Ao = 19 to be even marginally plausible, failure to control for an unobserved covariate would need to alter
the odds of treatment by at least a factor of r = 4.

5.7 Inference About a Quantile 195

TABLE 5.11. Testing Three Hypotheses in the Benzene Data.

A = 1, R (39-1 ) = lLll , P < 0.00001

Treated Control Total

TC i > 11.11

39

11.11 2:: TCi

19

0

39

20

39

Total

58

20

78

A = 19, R{39-19) = 5, P < 0.000025

Treated Control Tot al

TCi > 5

37

2

39

5 2:: TC i

21

18

39

Total

58

20

78

= A = 25, R(39-25) 4, P = 0.219

Treated Control Total

TCi > 4

31

8

39

4 2:: TC i

27

12

39

Total

58

20

78

5.7 Inference About a Quantile
5.7.1 A Method Based on the Extended Hypergeometric Distribution
An alternative to modeling the effect of the treatment is to draw nonparametric inferences about the distributions of responses that would be seen
under treatment or control. Consider the case of a single stratum, S = 1, and drop the s subscript . Then the order statistics of the n potential responses to treatment are TT (n ) 2:: TT(n - l) 2:: . . . 2:: TT(I ) , and these are
not observed because only m subjects received treatment. This sect ion discusses inference about the kin quantile, TT (k ). For instance, if n is odd
and k = (n + 1) 12 , then TT(k) is the median response that would have
been observed had all n subjects been exposed to treatment. A confidence interval for TT (k ) and its sensitivity analysis will be constructed.
It is convenient to assume, at first , that there are no ties , so that
TT (n ) > TT(n-l ) > ... > TT(I )· It is not difficult to show that the method to
be described works with ties, and that ties simply increase the probability that the confidence interval covers t he parameter, so a 95% confidence interval ~as covera~e slightly greate:. than 95%; see Rosenbaum (1995, §2.2).
Write RT(m ) > RT(m-l ) > . . . > RT(I ) for the m observed order st at ist ics
from the m treated subjects. The confidence interval for TT(k ) is formed us-

196 5. Models for Tr ea tm ent Effect s

ing two of the observed order stat ist ics, [RT(a) , RT(b)] with a < b. Specif-
ically, the argument that follows uses Corollary 15 to show that , under
th e sensiti vity analysis model, t he confidence interval [RT (a) , RT(b)] covers
TT(k) with probability at least Y (n , m , k, a , 1/r) - Y (n, m , k - 1, b, I' ).
Let Ci = 1 if TTi :5 TT(k) and c; = 0 otherwise. Then k = L ~=l ci = C+
from the definition of TT(k)' Notice that L~=l Z i Ci ~ a if and only if R T( a) :5 TT(k)' As not ed in Corollary 15, under the sen sitivity analysis mod el, the sign score stat ist ic L~=l Z i Ci has a distribution bounded by two extended hypergeometric distributions with parameters I' ~ 1 and 1/r. It follows that the one-sided confidence interval TT(k) ~ RT(a) has coverage probability that is sharp ly bounded by:
Y(n,m,k,a,r) > pr(tzici~a)

~ ~ ~ Pr {TT(k) RT(a )} Y (n , m, k, a , ) ,

In parallel, replacing k by k - 1, yields:
I (n, m , k - 1, b, I') > Pr {TT (k-l ) ~ RT(b)}
~ > Y ( n , m , k - 1, b, ) ,

but Pr {RT(b) ~ TT(k)} = 1- Pr {TT(k-l ) ~ RT(b)} , so the one-sided con-
fidence interval RT(b) ~ TT(k) has cover age probability that is sharply bounded by:

~) ~ 1 - I ( n , m , k - 1, b,

> Pr {RT(b) TT (k ) }

> 1- Y (n,m,k -l,b,r) .
l Finally consider the two-sided interval RT(a) , RT(b)] , where a < b. This in-
terval covers TT(k) if the event TT(k ) ~ RT(a) occurs but the event TT (k-l) ~
RT(b) does not occur, so [RT(a) ,RT(b)] covers TT(k) with probability

~ ~ Pr {TT(k ) RT(a)} - Pr {TT(k-l) RT(b)} ,

which is at least I (n , m , k, a , 1/r) - I (n , m , k - 1, b, I'}, In parallel, confidence intervals for TC(k) are constructed using the n - m
observed order statistics R C(n- m) > RC(n-m-l ) > ... > R C(l ) from the
n-m controls. Of course, one must replace m by n-m, so that, for example,
[Rc (a), R C(b)] covers TC(k) with probability at least Y (n , n - m , k , a , 1/r)-
I (n , n - m , k - 1, b, I' ].

5.7 Inference About a Qu antile 197

TABLE 5.12. Sensitivity of Confidence Intervals for th e Median Mercury Level.

r

rT(20) rC(20)

1 [100,196] [6,11]

2 [70,236] [6,12]

5 [69,270] [4,15]

5.7.2 Example: Methylmercury in Fish, Continued
In the study by Skerfving, Hansson, Mangs, Lindsten, and Ryman (1974) , discussed in Chapter 4, m = 23 subjects who ate large quantities of fish
contaminated with methylmercury were compared to n - m = 16 controls
who ate little or no contaminated fish. There are n = 39 subjects in total,
so the median for these n = 39 subjects is the (39 + 1) 12 = 20t h order
statistic. Consider, here, the level of mercury found in the blood as the
response. Had all n = 39 subjects eaten contaminated fish, the median
response would have been rT(20 ) , whereas had all n = 39 subjects avoided contaminated fish, the median would have been r C(20), but neither quantity is observed, because m = 23 ate contaminated fish and n - m = 16 did not.
The m = 23 treated subjects yield m = 23 observed order statis= = = tics, RT(I ) 12.8, R T(2 ) 40, . .. , R T(23) 1100. The chance that
the random interval [RT(a ) ,l'lT(b)] covers the fixed parameter rT(20) is
at least Y (39 , 23, 20, a, 11r) - Y (39,23,20 - 1, b, I'). For a 95% interval one selects a and b so that Y (39,23,20, a, 11r) - Y (39, 23, 20 - 1, b,r) ~ 0.95, perhaps by insisting that Y (39, 23, 20, a, 11r) ~ 0.975 and 0.25 ~ Y (39,23,20 - 1, b, I'}. Similarly, the n - m = 16 controls yield n - m = 16
= = = order statistics, R C(1 ) 3, R C (2 ) 4, .. . , R C (16) 17. Then [Rc (a) ,RC (b)]
covers r C (20) with probability at least
Y (39, 16,20, a, 11r) - Y (39, 16,20 - 1, b, I') .
Table 5.12 gives the sensitivity analysis for the 95% confidence intervals for the two median mercury levels, rT(20) and rC(20)' The coverage is actually somewhat greater than 95% both because of ties and because of the discreteness of the extended hypergeometric distribution, which does not
always p ermit exact equality, Y (n , m , k , a, ~ ) - Y (n , m , k - 1, b, I') = 0.95.
As alway s, the confidence intervals become somewhat longer as I' increases. However , even if subst ant ial biases are present, I' = 5, it would be clear that eating contaminated fish caused a substantial increase in typical blood mercury levels . Even with I' = 5, the median under control, r C (20) , is much lower and more pr ecisely determined than the median under treatment,
rT(20 )'

198 5. Models for Treatment Effects
5.8 Bibliographic Notes
Doksum (1974), Doksum and Sievers (1976), Lehmann (1975) , and Switzer (1976) express treatment effects in terms of a function ~ (.) such that
rr« = rc « + ~ (TC si), and dilated effects, with ~ (.) required to be non-
negative and nondecreasing, are discussed in Rosenbaum (1999a) . The fine paper by Angrist, Imbens, and Rubin (1996) shaped my presentation of randomization as an instrumental variable for studying the effects of an active ingredient; see also Angrist and Imbens (1994) and Angrist (1998) . Instrumental variables have long been a standard topic in the fitting of econometric models, and links to randomized experiments have been discussed by Holland (1988) and Sommer and Zeger (1991), among others. Rosenbaum (1996b, 1999b) discusses exact randomization inference and sensitivity analysis with an instrumental variable, as presented in this chapter.
Attributable effects are related to attributable risks, as discussed by MacMahon and Pugh (1970), Walter (1975), and Hamilton (1979). Displacement effects are related to the control median test, as discussed by Gart (1963) and Gastwirth (1968) , quantile comparison functions, as discussed by Li, Tiwari, and Wells (1996) , and nonparametric inference based on placements, as discussed by Orban and Wolfe (1982) . The discussion of attributable effects is based on Rosenbaum (2001) .
The confidence interval for a finite population quantile in §5.7 is discussed by Wilks (1962, §11.4) and by Sedransk and Meyer (1978) when
there is no hidden bias , r = 1, and Rosenbaum (1995) discusses sensitivity analysis for r ~ 1.
5.9 Problems
1. Quantiles in large finite populations. Suppose the treated group is a small fraction of the n subjects in the study. Specifically, in §5.7, suppose the number m of treated subjects is fixed , and the number
of controls increases, so n -> 00, with kin -> 0 where 0 < 0 < 1.
Show how to use the binomial distribution with sample size m and
success probability orI (or + 1 - 0) in place of the extended hyper-
geometric distribution to approximate the confidence interval. (Hint: The paper by Harkness (1965) discusses the limiting behavior of the extended hypergeometric distribution and might be helpful.) Notice that the limiting binomial distribution does not require knowledge of n , so it may be used to compare a treated group with a population distribution. (Solution: See Rosenbaum (1995 , §2.3).)
2. Worst case bounds. Some authors , such as Manski (1990 , 1995) , do
not introduce a sensitivity parameter, r , and instead report a worst

5.10 Appendix: Minimum Wage Data 199
case bound. What happens to th e confidence inte rva l in §5.7 for a
qu antile, TT (k ) , when r --> oo? W hat information is t here abo ut TT (k )
when the bias may be infinitely lar ge? Consider a simple case, wit h n
is odd, k = (n + 1) /2 so TT(k ) is the median , and set m = (n + 1) / 2,
so just slightly more than half of th e subjec ts received tr eatment. (Solution: See Rosenbaum (1995, §2.4).)
3. Dilated effects without strata. The meth od for dilated effects in §5.3 was illustrated with paired dat a , ns = 2, m s = 1, for each s. Apply the met hod to t he shoe worker data in §5.6 where there is a sin-
gle strat um S = 1. (Rose nbaum (1999a) discusses an unstra tified
e x am p le .)
4. Confidence intervals for an additive effect using differences of order statist ics. Withou t st rata, assume t he treatment has an add itive effect,
+ TTi = TCi T. Obtain sensit ivity bounds for
Pr { 7 2: RT(a ) - R C (k - a+ l ) } ,
in t he notat ion of §5.7. (Solut ion: Rosenbaum (1995, §4.2).)

5.10 Appendix: Minimum Wage Data

This appe ndix contains 66 matched pairs of rest aur ants from Ca rd and

Krueger 's (1994, 1995) data; see also Rosenbaum (1999b) . Two vari ables

are describe d: full-t ime equivalent (FT E) employment, and starti ng wages.

The rest auran ts were paired for chain and for start ing wages before the

increase. Pair s 1 t hrough 30 are Bur ger Kings, pairs 31 through 40 are

Kentucky Fried Chicken rest auran ts, pair s 41 t hro ugh 55 are Roy Rogers,

and pairs 56 through 66 are Wendy's. See §5.4.6 for detailed discussion.

Matched Pairs of Restaurants ,

Before and After the Minimum Wage Increase

FTE Employment

Starting Wages

New Jersey Pennsylvania New Jersey Pennsylvania

# Before After Before After Before After Before After

1 15.50 26.50 15.50 14 .00 4 .25 5.05 4.25 4 .40

2 18.00 32 .00 18 .00 19.00 4 .25 5 .05 4 .25 4.25

3 19.00 20.00 19.00 25 .00 4 .25 5.25 4.25 4.38

4 19 .50 47 .50 19 .50 27.00 4 .25 5.05 4 .25 4 .25

5 23 .00 19.00 22.75 21.00 4.25 5 .05 4 .25 4 .25

6 24 .00 26.50 24 .00 23 .00 4 .25 5 .05 4 .25 4.75

7 24 .00 25 .50 24.50 43.50 4 .25 5.05 4.25 4.75

8 26.00 25.00 26.00 20.00 4 .25 5.05 4.25 6.25

9 27.00 35 .00 27.00 25 .50 4 .25 5 .05 4.25 4 .25

200 5. Models for Tr eatm ent Effects
10 30 .00 26.00 32 .50 25.50 4 .25 5 .05 4 . 25 4 . 25 11 33.00 29 . 00 36.50 27.00 4 . 25 5.05 4 . 25 4 .25 12 38 .00 24 .50 39 .00 26.50 4.25 5.05 4 .25 4 .25 13 41. 00 22.50 41.50 23 .50 4 .25 5 .05 4. 25 4. 90 14 41.50 21.50 45 . 00 37 .50 4.25 5 .05 4 . 25 4 .25 15 13 .00 19.00 21.00 17 .50 4 .37 5.05 4 . 35 4.25 16 24.00 32 .00 24.00 16.00 4 .50 5.05 4 . 50 4 .25 17 30 .50 22.50 32 .00 21.00 4 .50 5.05 4.50 4 .50 18 50 .00 30.00 48 .50 27 .00 4 .50 5 .05 4 .50 4.35 19 18 .50 24 .75 52 .50 34.00 4.55 5 .05 4 .50 5 .05 20 16 .00 15.50 15 .50 34 .50 4 .75 5 .25 4 .75 4.75 21 17.00 21.50 18 . 50 41.25 4.75 5.05 4.75 4 .50 22 20 .50 39 .00 21.00 24.50 4 .75 5.05 4.75 4.50 23 22.50 44 .00 22.50 35.50 4 .75 5 .25 4.75 4.50 24 18 .50 13 .00 15 .50 27.50 4 .87 5 .05 4 .87 5 .00 25 16 .00 24 .50 13 .50 18.00 5 .00 5 .50 5.00 4.50 26 23.00 23 .25 23.50 36.50 5.00 5 .05 5.00 5 .00 27 27.50 27 .00 26 .50 30.50 5 .00 5 .25 5 .00 4 .50 28 35 .00 10.50 58.00 29 .00 5.00 5 .05 5.00 5 .00 29 46 .50 23 .75 70 .50 29 .00 5 .12 5 .05 5 .00 4 .75 30 20 .00 20 .50 28 .50 26.00 5 .50 5 .05 5 .50 4 .75 31 8 .00 8 .50 7 .50 9.50 4 . 25 5.05 4 .25 4 .25 32 10.50 14.00 10 . 50 16.50 4.25 5 .05 4 .25 4.25 33 9 .50 8 .00 8.50 14 .00 4. 50 5 .05 4 . 50 5 .00 34 8 .50 9 .00 8 .50 13.00 4 .50 5.05 4 .50 4 .50 35 14. 00 16 .50 14. 00 17.00 4. 50 5.25 4 .50 4 .75 36 11 . 50 14 . 00 11.00 11.00 4.75 5.05 4. 75 4.25 37 9.00 14.00 9.00 8 .50 5.00 5 .05 5 .00 5 .00 38 10.00 7 .50 9.50 13.50 5 .00 5 .05 5.00 4 .75 39 15 .00 18 . 50 11. 00 11 . 00 5.25 5 .05 5.25 5 .00 40 9 .50 9 .50 16.75 20.00 5 .50 5 .05 5 .25 5 .00 41 18 .75 24 .00 18 .00 15.00 4 .25 5 .05 4 .25 4 .35 42 13 .50 14.50 13 .00 13 .50 4 .50 5 .05 4.50 4.50 43 15.50 11 .50 18 . 00 34 .00 4.50 5 .05 4 .50 4.25 44 15.00 19.00 15 . 00 12 .50 4 .75 5.05 4 .75 4.75 45 19.50 28 .50 20 .25 10 .00 4.75 5 .05 4 . 75 4 .91 46 5 .00 8 .00 14.00 13.50 5 .00 5 .05 5 .00 4 .25 47 15.50 17 .50 15.00 19 .00 4.95 5.05 5.00 4.75 48 21.00 18 .00 15 .50 17.50 5 .00 5 .05 5 .00 4 .75 49 21.00 14 .00 18.50 14. 50 5.00 5 .05 5.00 4 .25 50 23 .00 15 .50 19 .00 17.50 5.00 5 .05 5 .00 4 .75 51 24 .00 21.00 20 .25 14 .00 5 .00 5 .05 5 .00 5. 00 52 24.50 36 .00 20.50 18.00 5.00 5 .05 5 .00 4 .75 53 26.00 16 .50 21.00 21.00 5 .00 5.05 5.00 5.00 54 30.00 26 .00 29 .50 15 .50 5 .00 5 .05 5 .00 4.75

5. 11 References 201
55 35.00 37.00 36 .00 19.00 5 .00 5.05 5.00 4.90 56 13.00 15.00 10.50 12 .00 4 .25 5 .30 4.25 4.25 57 18.00 23.50 17 .50 19 .00 4 .25 5.05 4.25 4.35 58 18.00 17 .50 25 .00 25.00 4.25 5.05 4 .25 4 .25 59 24.00 24 .00 25 .00 31 .50 4.50 5.05 4 .25 4 .50 60 36.50 60 .50 38 .00 18 .00 4 .25 5.05 4 .25 4.25 61 53.00 19 .00 38.00 20 .00 4.62 5 .05 4 .67 4.50 62 22 .00 23 .00 23 .50 18. 00 4.75 5.05 4 .75 4 .50 63 29.00 21.50 28.00 26.75 4.75 5 .05 4.75 5 .00 64 18.25 33.00 19.00 20 .50 5.00 5 .05 5 .00 5.00 65 33 .50 32 .00 34 .00 20.00 5 .00 5 .50 5.00 5.25 66 18 .00 33.50 24.00 35 .50 5.50 5.05 5 .50 4 . 75
5.11 References
Ang rist , J. D . (1998) Est imati ng the labor mar ket impact of voluntary military service using social secur ity data on military applicants. Econometrica, 66 , 249-288.
Angrist , J . D. and Imbens, G. W . (1994) Identificati on and estimation of local average t reatment effects. Econometrica, 62 , 467-475.
Angrist , J . D., Imbens, G. W ., and Ru bin, D. B. (1996) Identificat ion of causal effects using instrumental variables (wit h discussion) . Journal of the American Stat istical Association, 91 , 444- 455.
Bickel, P. and Lehmann, E. (1976) Descript ive statist ics for nonparametric pr oblems, IV: Spread. In Contributions to Statistics, J . J uneckova, ed., Dordrecht , Holland: Reidel, pp. 33- 40.
Card, D. and Kru eger , A. (1994) Minimum wages and employment: A case st udy of the fast- food industry in New Jersey and Pennsylvania. American Economic Review, 84, 772- 793.
Card , D. and Krueger , A. (1995) Myth and Measurement: The New Economics of the Minimum Wage. Princet on, NJ: Princeton University Press.
Card, D. and Krueger , A. (1998) A rean alysis of t he effect of t he New J ersey minimum wage increas e on the fast- food industr y wit h represent ati ve pay roll data . National Bureau of Economic Research, Working P ap er 6386.
Card , D. and Krueger, A. (2000) Minimum wages and employment: A case st udy of t he fast-food industry in New Jersey and Penn sylvania: Reply. American Economic Review, 90, 1397-1420.

202 5. Models for Treatment Effects
Coats, T . J. and Walter , D. P. (1999) Effect of st at ion design on death in the London Underground : Observational study. Brit ish Medical Journal , 319, 957.
Doksum, K. (1974) Empirical probability plots and statistical inference for nonlinear mod els in t he two-sample case. Annals of Statistics, 2, 267-277.
Doksum, K. and Sievers, G. (1976) Plotting with confidence: Graphical comparisons of two populations. Biom etrika , 63 , 421-434.
Gart, J . J. (1963) A median t est with sequential application. Biometrika, 50,55-62.
Gastwirth, J . 1. (1968) The first-median test: A two-sided version of the control median test. Journal of the American Statisti cal Association, 63, 692-706.
Hamilton, M. A. (1979). Choosing the parameter for 2 x 2 and 2 x 2 x 2 table analysis. American Journal of Epidemiology, 109, 362-375.
Harkness, W . (1965) Properties of the extended hypergeom etric distribution. Annals of Mathematical Statistics, 36, 938-945.
Holland, P. W. (1988) Causal inference , path analysis , and recursive structural equation mod els (wit h discussion) . Sociological Methodology, 449-476.
Lehmann, E . (1975) Nonparametrics: Statistical Methods Based on Ranks. San Francisco: Holden-Day.
Li, G. , Tiwari, R. C., and Wells, M. T . (1996) Quantile comparison functions in two-sample problems, with application to comparisons of diagnostic markers. Journal of the American Statistical A ssociation, 91, 689-698.
MacMahon, B. and Pugh, T . F. (1970) Epid emiology: Principles and Methods. Boston: Little, Brown.
Orban, J . and Wolfe, D. A. (1982) A class of distribution-free two-sample tests based on placements. Journal of the American Statistical Association, 77, 666-672 .
Manski , C. (1990) Nonparametric bounds on treatment effects. American Economic Review, 319-323.
Manski, C. (1995) Ident ification Problems in the Social Sciences. Cambridge, MA: Harvard Univer sity Press.

5.11 References 203
Rosenbaum, P. R. (1995) Quantiles in nonrandom samples and observational studies. Journal of the American Stat ist ical Association, 90 , 1424-1431.
Rosenbaum, P. R. (1996a) Observational studies and nonrandomized experiments. In : Handbook of Statistics, Volume 13, Design of Experiments, Chapter 6, S. Gho sh and C. R. Rao , eds., New York: Elsevier , pp. 181-197.
Rosenbaum, P. R. (1996b) Comm ent on "Ident ificat ion of causal effects using instrumental variables" by Angrist, Imbens, and Rubin. Journal of the American Statistical Association, 91 , 465-468.
Rosenbaum, P. R. (1997) Discussion of a paper by Copas and Li. Journal of the Royal Statistical Society , Series B , 59 , 90.
Rosenbaum, P. R. (1999a) Reduced sensitivity to hidden bias at upper quantiles in observational studies with dilated effects. Biometrics, 55, 560-564.
Rosenbaum, P. R. (1999b) Using combined quantile averag es in matched observational st udies. Applied Statistics , 48 , 63-78.
Rosenbaum, P. (2001) Effects attributable to tr eatment: Inference in experiments and observational studies with a discret e pivot. Biometrika , 88, 219--232.
Rubin, D. B. (1974) Estimating t he causal effects of treatments in randomized and nonrandomized stu dies. Journal of Edu cation al Psychology, 66, 688-701.
Shaked , M. (1982) Disp ersive ordering of distributions. Journal of Applied Probability, 19, 310-320.
Sedransk, J. and Meyer, J. (1978) Confidence int ervals for the quantiles of finite populations: simple random and stratified random sampling. Journal of the Royal Statisti cal Society , Series B, 40, 239--252.
Sheiner, L. B. and Rubin, D. B. (1995) Intention-to-treat analysis and the goals of clinical trials. Clini cal Pharmacology and Th erapeutics, 57, 6-15.
Skerfving, S., Hansson , K. , Mangs, C., Lindsten, J. , and Ryman, N. (1974) Methylmercury-induced chromosome damage in man. En vironmental Research, 7 , 83-98.
Sommer , A. and Zeger , S. L. (1991) On estimat ing efficacy from clinical trials. Statistics in Medicine, 10, 45-52.

204 5. Models for Treatment Effects
Switzer, P. (1976) Confidence procedures for two-sample problems. Biom etrika, 63 , 13- 25.
T hun , M. (1993) Kidney dysfunction in cadmium workers. In: Case Studies in Occupational Epidemiulugy, K . Steenland, ed ., New Yurk: Oxfurd Unive rsity P ress, pp. 105-126 .
Thun, M., Osorio, A., Schober, S., et al. (1989) Nephropathy in cadmium workers: Assessment of risk from airborne occupational exposure to cadmium. British Journal of Industrial Medicine, 46, 689-697.
Tunca, B. T. and Egeli, U. (1996) Cytogenetic findings on shoe workers exposed long-ter m to benzene. Environmental Health Perspectives, 104, sup plement 6, 1313-1 317.
Walter, S. D. (1975) T he distribution of Levin 's measur e of attributable risk. B iometrika, 62 , 371-375.
Wilks, S. (1962) Mathematical Statistics. New York: W iley.

6
Known Effects
6.1 Detecting Hidden Bias Using Known Effects
6.1.1 Sensitivity Analysis and Detecting Hidden Bias: Their Complementary Roles
As seen in Chapter 4, observational studies vary considerably in their sensitivity to hidden bias. The study of coffee and myocardial infarction in §4.4.5 is sensitive to small biases while the studies of smoking and lung cancer in §4.3.3 or DES and vaginal cancer in §4.4.5 are sensitive only to biases that are many times larger. If sensitive to small biases, a study is especially open to the criticism that a particular unrecorded covariate was not controlled because, in this case , small differences in an important covariate can readily explain the difference in outcomes in treated and control groups. Still, all observational studies are sensitive to sufficiently large biases, and large biases have occurred on occasion; see §4.4.3. A sensitivity analysis shows how biases of various magnitudes might alter conclusions, but it does not indicate whether biases are present or what magnitudes are plausible.
Efforts to detect hidden bias involve collecting data that have a reasonable prospect of revealing a hidden bias if it is present. If treatments are not assigned to subjects as if at random, if the distribution of Z is not
uniform on n, if instead the distribution is tilted, favoring certain assign-
ments Z over others, then this tilting or bias might leave visible traces in data we have or could obtain. Efforts to detect hidden bias use additional

206 6. Known Effects
information beyond the treated and control groups, their covariates and outcomes of primary interest. Recall from §1.2 Sir Ronald Fisher's advice, "Make your theories elaborate." This additional information may consist of several control groups, or several referent groups in a case-referent study, or it may consist of additional outcomes for which the magnitude or direction of the treatment effect is known. A systematic difference between the outcomes in several control groups cannot be an effect of the treatment and must be a hidden bias. A systematic difference between treated and control groups in an outcome the treatment does not affect must be a hidden bias . Detecting hidden bias entails checking that treatment effects appear where they should, and not elsewhere.
Efforts to detect bias and sensitivity analysis complement one another in their strengths and limitations. It is difficult if not impossible to detect small hidden biases, but a sensitivity analysis might indicate that small biases would not materially alter the study's conclusions. All studies are sensitive to sufficiently dramatic biases, but dramatic biases are the ones most likely to be detected.
Statistical theory contributes in two ways to efforts to detect bias. First, it provides qualitative advice about what these efforts can and cannot do, and about the types of data and study designs that have a reasonable prospect of detecting hidden bias . Second, theory provides a quantitative link between detection and sensitivity analysis. When does failure to detect hidden bias provide evidence that biases are absent or small? Does failure to detect hidden bias make a study less sensitive to bias?
Chapters 6, through 8 discuss three methods of detecting hidden biases, namely, known effects, multiple referent groups in a case-referent study, and multiple control groups. The three methods are ordered in this way because the technical development in Chapter 6 is most similar to Chapter 4, Chapter 7 is a step away, and Chapter 8 is a larger step away. The remainder of §6.1 discusses examples of known effects and concludes by asking when an effect is known .
6.1.2 An Example: Nuclear Weapons Testing and Leukemia
Can hidden biases be detected? Is there any real hope of detecting a departure from a random assignment of treatments within strata that are homogeneous in observed covariates? Is the task ahead an impossible task? The first example is of interest because it affords several opportunities to detect hidden bias and, in each case, bias is detected. Also , there is a bit of late news produced four years after the publication of the original study.
Lyon, Klauber, Gardner, and Udall (1979) studied the possible effects of fallout from nuclear weapons testing in Nevada on the risk of childhood leukemia and other cancers in Utah. The study grouped counties in Utah into high or low exposure based on proximity to nuclear testing in Nevada. In addition, the counties were studied in three time periods, 1944 to 1950

6.1 Detecting Hidden Bias Using Known Effects 207

TABLE 6.1. Leukemia Mortality Per 100,000 Person Years in Utah, Before, During and After Above Ground Nuclear Testing.

Cohort

Person- Years Deaths Rate

Low Exposure Counties Before: 1944-1950

1,095,997

44 4.0

High Exposure Counties Before: 1944-1950

330,177

7 2.1

Low Exposure Counties During: 1951-1958

3,898,901

152 3.9

High Exposure Counties During: 1951-1958

724,531

32 4.4

Low Exposure Counties After: 1959-1975
High Exposure Counties After: 1959-1975

3,153,008 451,408

112 3.6 10 2.2

prior to nuclear testing in Nevada, 1951 to 1958 during above-ground testing , and 1959 to 1975 during underground testing. As will be seen, this is an attractive and careful study design in that it provides several checks for hidden bias. Frequencies of childhood leukemia and other cancer were obtained from the Utah State Bureau of Vital Statistics, and person-years at risk were determined from the US Census and the Utah State Bureau of Vital Statistics; see Lyon et al. (1979) for details. This study was discussed by Land (1979), Beck and Krey (1983), Rosenbaum (1984a), and Gastwirth (1988, pp. 870-878). In particular, Gastwirth discusses the outcome of related litigation.
If above-ground nuclear testing has an effect, then how should that effect appear? Radiation could reasonably cause leukemias and other childhood cancers, but it should not prevent them, and more radiation should yield more cancers. If above-ground testing has an effect, and if there is no hidden bias, one expects the highest levels of leukemia and other cancers in the high-exposure counties during the period of above-ground testing, followed by lower but possibly still elevated levels in the low-exposure counties during the same time period, with still lower and similar levels in the highand low-exposure counties before and after above-ground nuclear testing. This is what one would expect to see if, contrary to fact, children had been assigned at random to one of the six cohorts of children. This is an elaborate theory in Fisher's sense, one that includes several effects of known direction and several control groups.
Table 6.1 shows the leukemia mortality rates from Lyon et al. (1979) for children under the age of 15. These are mortality rates per 100,000 person-years.
Table 6.1 conforms to the anticipated effect in one respect but not in another. As anticipated, in the high-exposure counties, the leukemia mor-

208 6. Known Effects

TABLE 6.2. Other Childhood Cancer Mortality Per 100,000 Person Years in

Utah, Before, During and After Above Ground Nuclear Testing.

Coho rt

Person-Years Deaths Rate

Low Exposure Count ies Before: 1944-1950

1,095,997

50 4.6

High Exposur e Counties Before: 1944-1950

330,1 77

21 6.4

Low Exposur e Counties During: 1951-1958

3 ,898 ,90 1

165 4.2

High Exposure Cou nties Durin g: 1951-1958

724 ,53 1

21 2.9

Low Exposure Cou nties After: 1959-1975

3,153,008

106 3.4

High Exposure Counties After : 1959-1975

45 1,408

15 3.3

tality rises from 2.1 leukemias per 100,000 be fore testing to 4.4 during above-ground testing, an d t hen returns to 2.2 during t he period of underground testing. T he low-exposure counties show a slight decline. On the other ha nd , the low-exposure counties had almost twice the leukemia of the high-exp osur e counties before nuclear testing (4.0 versus 2.1) and more t han 50% more after nuclear testing went un derground (3.6 versus 2.2). Indeed , t he rise in leukemias in t he high- exp osure count ies dur ing aboveground test ing brought t he level to just slightly more than t hat found in the low-exposure count ies at the sa me time (4.4 versus 3.9). It appea rs that t he high- and low-exposur e counties are not comparable in ways that matter for the leukemia rate.
Table 6.2 shows the correspond ing rates for other childhood ca ncers . Here, the anticipated effect is Hut seen. For t he high-exposure cou nties, the rate of other cancers declined during t he period of above-ground testing, just as t he leukemia rate was rising. This decli ne is not plau sibly a n effect of nuclear testing, an d it strongly suggests t hat the two per iods were not comparable in ways t hat matter for ca ncers ot her t han leukemias. The lowexposure counties show a slight decl ine. For cancers ot her t han leukem ia , before nuclear t est ing, t he high-exposure counties had high er rates than the low-exposure counties, but that reversed during above-ground t est ing. It appears t hat t he high- and low-exposure counties are not comparable in ways t hat matter for cancers other t han leukemi as . If t he differences t hat should not be present are sub jected to a for mal hypothesis test, t hen the differences are found to be statistically significant and not readily attributed to chance; see Rosenbaum (1984a).
In short , t he mortality rates vary in ways not readily attributed to chance or to effects of above-ground nuclear testing. More than t his, the variation in mor t ali ty rates that is inconsistent wit h an effect of nucl ear test ing is as

6.1 Det ecting Hidd en Bias Using Kn own Effects 209

large as the variation that is consistent with an effect . This does not neces-

sar ily mean that the int er esting rise in leukemia in high- exposure counties

is not an effect of nucl ear testing, but it is reason for extreme caution about

any such claim.

.

The st udy by Lyon et al. (1979) is an excellent st udy, even though there

is st rong evidence of hidden bias . Indeed, it is an excellent st udy because

ther e is st rong evidence of hidden bias. A poor study might have looked only

at leukem ia and onl y in high-exp osur e counties, and it would have found no

evide nce of hidden bias-becau se it did not look- and therefore it would

have left its audience with a n incorr ect impression. The editorial policies

of major journals sha pe scienc e. The N ew Engla nd Jo urnal of Medicine

wisely published the st udy by Lyon et al. (1979) along with a cautious

editor ial by Land (1979) , despite the evidence of hidden bias, and one

hop es it would have wisely declined to publish the imagined study which

considered only leukemia in high-exposure counties, despite its absence of

evide nce of hidden bias.

Four years later, Beck and Kr ey (1983) published a st udy that attempted

t o estimate the doses of radiation received between 1951 and 1958 in dif-

ferent parts of Utah. They took soil samples in the high- and low-expo sure

count ies described by Lyon et al. (1979) and measured cesium-137 and plu-

tonium. They concluded : "Alt hough the highest expos ures were found in

the extre me southwest part of Ut ah , as expected, the resid ents of the pop-

ulous northern valleys ar ound Provo, Salt Lake City, and Ogden received

high er mean dose and a significantly greater population dose (perso n-rads)

t han did t he resid ents of most counties closer to the test site [p. 181." In

ot her words, their sa mpling suggest s t hat t he "low"-exp osure count ies may

have received higher exposures than the "high"-exp osure count ies. Beck

and Kr ey also compar ed the radi ati on they found with background radi-

ation and global fallout and expressed their view that ".. . bone doses to

the population of sout hern Utah were far too low to account for the excess

childhood leukemia mortali ty reported by Lyon et al. (1979)."

For us, the important point is that care ful study design can help to

detect hidden biases.

6.1.3 Specificity of Associations and Known Effects
In ep idemiology, it is oft en said that a "specific" association between an exposure and a disease pr ovid es great er evidence that the exposure causes the diseas e than do es a "nonspecific" associat ion. For instance, Yerushalmy and P alm er (1959) write:
The demonstration of high relative frequencies in the st udy group is thus only a first ste p in the pr ocess of searc hing for et iologic factors. The investigation must pro ceed to the second and mor e crucial consid eration (which, for want of a better

210 6. Known Effects
term, is denoted here as that of specificity of effect) , Le., to the demonstration the difference in relative frequencies reflects a specific and meaningful relationship between the characteristic under suspicion and the disease under consideration . . . [p. 36].
. . . If the characteristic can be shown to be related only or mostly to the disease under study and not to many other disease entities, then our confidence that it is a cause-carrying vector for that disease is greatly increased.
If, on the other hand, it is found that the characteristic is also related to numerous other diseases, including those without obvious physiologic or pathologic connection with the characteristic in question, the relationship must be assumed-until further proof-to be nonspecific [p, 37].
In a comment, Lilienfeld (1959) adds several points. He suggests that specificity does not refer to the presence or absence of an association, but to its strength or degree . He argues that the association between smoking and lung diseases is specific because these associations are strong, though there are weak associations with many diseases. Moreover, he writes:
It is needless to point out that our interpretation of any relationship is limited by our biologic knowledge, and it may well be that an association which at present does not appear to be biologically plausible will turn out to be so when our knowledge has been extended. In fact , the finding of a biologically implausible association may be the first lead to this extension of knowledge.
A similar point is made by Sartwell (1960) , though with a more critical tone. Still more critical is Rothman (1986, p. 18), who says that ". . . everyd ay experienc e teaches us repeatedly that single events may have many effects" and that the criterion of specificity "seems useless and misleading. " Sir Austin Bradford Hill (1965, p. 297) regards specificity more favorably, but lists these and other difficulties.
If one agrees that the number of associations is not a particularly useful number, and instead emphasizes whether there are associations that are not plausibly effects of the treatment or exposure under study, then there is a strong link between specificity in this narrow sense and detecting hidden bias through known effects. If an observational study includes several outcomes, some of which may plausibly be affected by the treatment and others for which an actual effect is implausible, then the association between treatment and outcomes is specific in the narrow sense if strong associations are confined to outcomes for which effects are plausible. In this instance, the treatment is known to have no effect on certain outcomes.
Thomas Cook (1991) discusses specificity clearly in somewhat different terminology:

6.1 Detecting Hidden Bias Using Known Effects 211
' Nonequivalent dependent variable' designs .. . depend on some of the indicators being theoretically responsive to a treatment but all of them being responsive to the known plausible
alternative explanations. [p. 119] . . . [If a] prediction is about a
specific and complex pattern of relationships [ .. . then . . . ] no uncertainty is reduced if a theory makes a highly specific numerical prediction that other theories also make. Specificity (or multivariate complexity) only facilitates causal inference when no other theory makes the same prediction. The more specific or complex the causal implications are, the less likely it is presumed to be that alternative theories can be found that make the same prediction [p. 121].
See also Cook, Campbell, and Peracchio (1990, pp . 546-7 and pp . 561564) for discussion of nonequivalent dependent variables, see Campbell (1966) for discussion of the principle of pattern-matching in inference, and see Ross, Campbell, and Glass (1970) for an interesting example.
6.1.4 Example of Specificity: Acute Stress as a Cause of Sudden Death from Coronary Disease and Cancer
Is the risk of rapid death from coronary disease increased by acute stress? Trichopoulos et al. (1983) compared coronary mortality in Athens in the period immediately following the 1981 earthquake to time periods immediately before the earthquake and to corresponding time periods in 1980 and 1982. After the earthquake, they claim that "t he psychological stress was unquestionable, intense, and general" (p. 442) . They found higher rates of coronary mortality immediately following the earthquake than in the comparison time periods.
It is plausible that acute stress acutely increases the risk of death from coronary disease, but it is not particularly plausible that acute stress quickly causes many deaths from cancer. Trichopoulos et al. conducted a parallel analysis of cancer mortality following the earthquake, finding no increase in risk. So the association of mortality with stress appears where an effect caused by acute stress is plausible, but not where a causal effect is much less plausible.
6.1.5 Example of Specificity: Supply and Demand for Cholecystectomy
If the cost of performing a medical procedure fell dramatically, would the expenditure per person in a general population fall as well? With consumer products, a drop in price may stimulate increased demand, so expenditure per person may rise or fall. Can the same thing happen with medical procedures?

212 6. Known Effects
Using data from US Healthcare's HMO PA in southeastern Pennsylvania, Legorreta, Silber, Costantino, Kobylinski, and Zatz (1993) asked this question of laparoscopic cholecystectomy, which was essent ially unused in 1987 and comprised more than 80% of cholecystectomies in 1992. Laparoscopic or closed cholecystectomy costs less than traditional open cholecystectomy, is safer, less invasive, and requires a shorter hospital stay. They found that between 1988 and 1992, the cost per cholecystectomy fell by about 25%, but the number of cholecystectomies per 1000 enrollees nearly doubled, and total expenditures on gallbladder disease rose .
Was the increase in the number of cholecystectomies a consequence of the introduction of laparoscopic techniques? Or might it reflect some change in the patient population or in general medical practice from 1988 to 1992? In an effort to examine this question, Legorreta et al. (1993) did parallel analyses of two other surgical procedures that should not be affected by the introduction of laparoscopic cholecystectomy. One of these other procedures was appendectomy, which is not an elective procedure, and the other was inguinal herniorrhaphy, which has "a discretionary component similar to cholecystectomy" (p. 1431). The rates of appendectomy and inguinal herniorrhaphy did not increase significantly during this time period, nor did associated expenditures per 1000 enrollees. The change in the frequency and cost of cholecystectomies is specific to this procedure, and is not found in rates for two other procedures that should not be affected by the introduction of laparoscopic cholecystectomy.
6.1.6 Example of Specificity: Anger and Curiosity as Causes of Myocardial Infarction
Do brief bouts of anger increase the risk of myocardial infarction (MI) ? In a case-crossover study, Mittleman et al. (1995) compared anger in the two hours before an MI to the same two hours on the previous day. In part of their study, for 881 cases of acute MI, they measured anger using the State-Trait Personality Inventory in each of the two time periods. Using Wilcoxon's signed rank test , they found anger was more often reported in the two hours before an MI than in the corresponding two hours on the previous day, the difference being highly significant, P = 0.001.
However, Mittleman et al. were concerned that their measures of anger were based on recall, and a patient's recall may itself be affected by the occurrence of an MI. Perhaps the events leading up to an MI appear to a patient to-be more important than the events of the less dramatic, perhaps uneventful, previous day. As a partial check on this possibility, Mittleman et al. also obtained measures of curiosity from the State-Trait Personality Inventory in both time periods. Of course, they strongly doubted that curiosity causes MI. They found no sign of differences in curiosity in the two time periods using the signed rank test, P = 0.20. So the level of

6.1 Det ecting Hidden Bias Using Known Effects 213
anger is associated with the timing of the MI, but the level of curiosity is not. They wrote (p. 1724): ". . . the specificity observed for anger . . . as opposed to curiosity on the STPI subscales ... argue against recall bias."
6.1.7 Unaffected Subgroups: Abortion and Crime
Theorizing that unwanted children, perhaps children of unwed teenage mothers, might possibly be more likely to commit crimes as teens or adults, Donohue and Levitt (2001) investigated the sharp decline in crime rates in the 1990s and their relationship to the legalization of abortion in 1973 by the Supreme Court Decision in Roe v. Wade. Among many analyses, their study includes a test for hidden bias using a known effect.
If legalized abort ion reduced crime simply by eliminating future criminals, then the effect of legalization should be confined to certain age cohorts. The availability of legal abort ion in 1973 should not affect the cohort born in 1971, but might affect the cohort born in, say 1975. In one of many analyses, Donohue and Levitt relate abortion rates by state to two outcomes, namely (i) arrest rates by state for age cohorts that might be affected and (ii) arrest rates for cohorts that cannot be affected . Whether or not adjustments are made for covar iates, they find that arrest rates for cohorts that cannot be affected are unrelated to abortion rate s, whereas arrest rates for cohorts that can be affected are negatively associated with abortion rates. They writ e: "In high abortion states, only arrests of those born after abortion legalization fall relative to low abortion states."
6.1.8 When Is an Effect Known'?
When is an effect known? Might we be in error in asserting that an effect is known? In discussing "specificity," Sartwell (1960) recalls the ridicule that was once attached to the idea that tiny, invisible living organisms were a cause of disease. Would anyone claim that our current knowledge is free of substant ial error? There are two points.
First, as suggested at the end of §6.1.2, known effects and other attempts to detect hidden biases are not the basis for suppressing data or studiesquite the contrary. The study by Lyon et al. (1979) is a superior study because its report includes information about internal inconsistencies. If we misinterpret those inconsistencies because of some error in our current knowledge, then we are far more likely to correct the error if the report includes the inconsistencies than if they are excluded . If we at tempt to detect hidden bias , we report more data, not less.
Second, there is an entirely practical, albeit circular, definition of a known effect. An effect is known if, were the st udy to contradict it , we would have grave doubts about the study and few doubts about the effect. It is conceivable, in principle, that our understanding of time and radiation is subst ant ially in error, as our understanding of bacterial disease was once

214 6. Known Effect s
subst ant ially in error, so th at radiation released in the 1950s had biological effect s in the 1940s; however , before ent ertaining thi s possibility, we would think that perhaps the record s of the Census Bureau or the Utah registry contained errors, or that some other environment al hazard was the cause .
6.2 An Outcome Known to Be Unaffected by the Treatment
6.2.1 An Additional Outcome Intended to Detect Hidden Bias
In addition to the response R of primary interest, the study includes another outcome, say Y , in an effort to detect hidden bias. In other words, Y was recorded in the hop e of testing whether the treatment assignments
Z given m are uniformly or randomly distributed over n, or alternatively
whether there is a hidden bias. This chapter considers two senses in which the effect of the treatment on
Y might be known . In §6.2, Y is known to be unaffected by the treatment. For instance, in §6.1.3 the concern was with diseases that the treatment could not plausibly cause ; see also Problem 1. In §6.3, Y is known eit her to be unaffected or to be positively affected; that is, Y may be affected by the treatment, but the dir ection of the effect is known. In §6.5, the direction of the effect on the primary outcome, R , is known, and there is no secondary outcome, Y. In §6.2, because Y is unaffected by the treatment , write y in place of Y . To say y is unaffected by treatment is to say y does not vary with Z and so is constant.
In an observational st udy, suppose a test statistic T = t(Z , R) is com-
puted from the responses R of primary interest, and then T is compared
n to the uniform or random distribution of Z on under the null hypothesis
that R = r is unaffected by the treatment; that is, the significance level (2.5) is calculated. Recall from §3.2.2 that this significance level is the basis for testing the null hypothesis of no treatment effect if the study is free of hidden bias , but the test is not generally correct if hidden bias is present. If this significance level is small, it may be evidence that the null hypothesis is untrue and the treatment does affect R , or it may be evide nce that there is a hidden bias and the distribution of treatment assignments Z is not random.
The situation with y is different, because y is known to be unaffected by the treatment. From the unaffected outcome y , calculate a statistic
T* = t*(Z, y) and its significance level I{z En: t*(z , y) ;::: T * } I/K. If this
significance level is small, then there is evidence of hidden bias, that is,
evidence that Z is not uniformly or randomly distributed on n.

6.2 An Outcome Known to Be Unaffected by the Treatment 215
6.2.2 An Example: Unrelated Health Conditions in the Study of Methylmercury in Fish
Recall from §4.6.6 the study by Skerfving, Hansson , Mangs, Lindsten, and Ryman (1974) of possible chromosome damage caused by eating fish contaminated with methylmercury. The outcomes of interest were the level of mercury in the blood and the percentage of cells exhibiting chromosome damage. In addition to these outcomes, Table 1 of their st udy described other health conditions of these 39 subjects, including other diseases such as hypertension and asthma, drugs taken regularly, diagnostic X-rays over the previous three years, and viral diseases such as influenza. These are outcomes since they describe the period when the exposed subjects were consuming contaminated fish. However, it is difficult to imagine that eating fish contaminated with methylmercury causes influenza or asthma, or prompts X-rays of the hip or lumbar spine . For illustration, Table 6.3 records the number of unrelated health conditions for each of the 39 subjects or y which will be assumed to be unaffected by eating contaminated fish.
If the rank sum statistic is calculated from y, the sum of the ranks for exposed subjects is 483.5, with average ranks used for the many ties . The null hypothesis states that the study is free of hidden bias , so the distribu-
tion of treatment assignments Z given m is random or uniform on n. Under
the null hypothesis, the rank sum has expectation 460 and variance 932.4 allowing for the many ties. The deviate is (483.5 - 460)/J932.4 = 0.77 which is far from significance at the 0.05 level. In words, in terms of health conditions methylmercury could not reasonably cause , the treated and control subjects differ no more than we would have expected had treatments been assigned at random. The hypothesis that the study is free of hidden bias is not rejected.
Several questions arise. When does such a test have a reasonable prospect of detecting hidden bias? If no evidence of hidden bias is found, does this imply reduced sensitivity to bias in the comparisons involving the outcomes of primary interest? If evidence of bias is found, what can be said about its magnitude and its impact on the primary comparisons?

6.2.3 The Power of the Test for Hidden Bias

For a particular unobserved covariate u, what unaffected outcome y would be useful in detecting hidden bias from u ? Put another way, for a given unaffected outcome y, what unobserved covariate u can y hope to detect?
The power of the test for hidden bias based on T* = t* (Z, y) will now be studied in qualitative terms that indicate the relationship between u and y that leads to high power. Let "a" be a number such that

_
Q: -

1 K

"r*( ) LJ t z,Y

~

] a

_I{ZEn -

:t*(z,y)~a}1 K

'

zEfl

216 6. Kn own Effects

TAB LE 6.3. Unre late d Health Condit ions and Exposure t o Cont aminat ed Fish .

Id.

Unr elated conditions

1 Control

a

2 Control

a

3 Control

o

4 Control

o

5 Control

o

6 Cont rol

o

7 Control

a

8 Cont rol

o

9 Control

2

10 Control

o

11 Control

o

12 Control

o

13 Control

2

14 Control

1

15 Control

4

16 Control

1

17 Exposed

o

18 Exposed

o

19 Exposed

2

20 Exposed

o

21 Exposed

o

22 Exposed

2

23 Exposed

o

24 Exposed

o

25 Exposed

1

26 Exp osed

9

27 Exposed

o

29 Expo sed

1

30 Exposed

o

31 Exposed

o

32 Exposed

2

33 Exposed

o

34 Exposed

o

35 Exposed

2

36 Expo sed

o

37 Exposed

6

38 Expo sed

1

39 Expo sed

1

6.2 An Outcome Kn own t o Be Unaffected by t he Treatm ent 217

where K = Inl and [even t ] = 1 if event occurs and [event] = 0 ot herwise,
so a t est for hidden bias that reject s when t*(Z , y ) 2: a has level Q . Under
the model (4.6) , t he power of t his test is

r j3(y , u ) =

~*
L)t (z, y )
zEn

2:

a]

L

beExnpe(x-ypz(tT-yub)T

u

(6.1)

All of the statistics t *(z ,y) in §2.4.3 ar e arrangement-increasin g, meaning t hat the st atistics are monotone incr easing as the coordinates of z a nd y ar e gradually permuted into the same order within each st ratum or matched set . In other words, if in strat um s , subject i received t he treat-
ment, Zsi = 1, subject j received the control Zsj = 0, but subject j had the
higher value of y, that is, Y sj 2: Ysi , then interchanging these two subjects,
placing j in the treated group and i in the control group would increase-or at least not decrease-the value of the statistic t*(z ,y) .
The following proposition says that the power j3(y, u) of this test increases steadily as the coordinates of y and u ar e permuted into the same order within each st rat um or matched set. The power is great er when y and u are strongly related .
Proposition 23 If th e tes t sta tis tic t*(z ,y) is arrangem ent -increasing, then th e power j3(y, u ) is arrangem ent -in creasing.
The proof follows from Proposition 17 in §4.7.3 which in t urn is a conseq uence of the compos it ion theorem for arrangement-increasing functions (Hollander , Proschan , a nd Sethuraman 1977). D'Ab adie and Proschan (1984, §6) describe a tes t with a n arrangement-i ncreasing power function as having isot onic power, meaning the power increases as t he depa rt ure from the null hypothesis becomes more pr onounced in t he direction indicated by an order. Under slight ly different assumptions, it is also p ossible to show t hat a test based on an ar rangement- increasing stat istic T * = t*(Z ,y) is unbiased against alte rnat ives in which y and u are pos iti vely related ; see Rosenbaum (1989a) .
In short, the power j3(y, u ) of a test based on T * = t*(Z ,y ) increases
with the strength of the relationship between y and u. This yields two qualit at ive conclusions. First, if concerne d about a particular unobserved covariate u , one should searc h for an unaffected out com e y that is strongly related to u . Second, if an un affect ed outcome y is available, a test based on y provides information about unobserved covariates u with which y is st rongly rel ated.
Consider the use of these conclusions in a particular case. Sackett (1979) cat aloged a nd illustrated with exa mples numerous sources of bias in observationa l st udies. Included were sit uations in which the search for disease or t he inclination to recall or record disease was more intense among subjects exposed to a hazardous agent than among subject s not exposed . The danger , of cours e, is t hat more disease will be found among exposed subjects

218 6. Known Effects
not because the hazardous agent caused the disease, but rather because the agent stimulated intensive search for disease or distorted recall of disease. If u were an unobserved covariate measuring the inclination to search for or recall disease , then a test for bias due to u would have highest power if it were based on an unaffected outcome y strongly related to u. In other words, a good test would be based on records of diseases that could not reasonably be caused by the agent under study but which would likely be detected in diagnostic activities or recalled by subjects. Exposed and control groups should differ with respect to such a y if there are substantial distortions due to differing diagnostic efforts or recall in exposed and control groups.
As a second illustration, consider again the study of legalized abortion and crime by Donohue and Levitt (2001) . In their study, the unaffected outcome y is the arrest rate by state for cohorts that are too old to have been affected by the Roe v. Wade decision in 1973. Of course, arrest rates vary by state for many reasons, some of which were not observed. If u is an unobserved variable describing the states, then the power of the test for hidden bias using y is greatest when u and y are strongly associated. If arrest rates for older cohorts yare related to an unobserved u in much the same way that arrest rates for younger cohorts are related to u, then a test for hidden bias based on y will have high power to detect bias from a variable u that is related to the outcome of interest.
6.2.4 Did the Test for Bias Reduce Sensitivity to Bias?
In §6.2.2, the difference between treated and control groups in unrelated health conditions appeared reasonably consistent with the absence of hidden bias. The question remains whether these same findings are consistent with hidden biases that would alter the conclusion that methylmercury causes chromosome damage.
In §4.6.6, the effect of mercury on chromosome aberrations was sensitive to hidden bias when I' = 3 for a particular value of u, say u". This u? contained Is and Os and was strongly related to the outcome r of primary interest, namely, chromosome aberrations. In other words , if treatment assignments were governed by the model (4.6) with (T', u) = (3, UO), then there would not be strong evidence that eating contaminated fish causes
chromosome damage. For I' = 3, this UO maximized over u E [O ,I]N the
significance level of the test for an effect on chromosome aberrations. With a different choice of u , a larger value of I' would be required to change the conclusion about .chromosome aberrations. The distinction between I' = 1 and (I', u) = (3, UO) is important because the main conclusions would be different in these two cases.
Are the observed data about unrelated health conditions y consistent
with (I' , u) = (3, UO)? The unaffected outcome y can test the hypothesis
that (I', u) = (3, UO) in much the same way that it tested the hypothesis

6.2 An Ou tcom e Kn own to Be Unaffected by t he Tr eatment 219
t hat I' = 1. If (T', u ) = (3, UO) is not reject ed , th en y has done nothing to
reduce our concern abo ut a bias of th e form (f , u ) = (3, UO). If (I' , u ) = (3, UO) is rejected, a point of greates t sensit ivity to bias has been reject ed as implausible. Rej ection is likely if t he model with (f , u ) = (3, UO) tend s to produce large differen ces in valu es of Ysi , in trea ted and control groups, but these large differences are not seen in the data. In short , the question is: Did the test for bias using y reduce sensit ivity to bias?
In §6.2.3, the obs erved valu e T * = t * (Z , y) of the test st atisti c was compared with its distribution when there is no hidden bias , that is, the model
prob(Z = zjm) = IIK for each zEn, leading to the exact significance
r level I{z E n : (z, y) 2: T*} II K . In fact , any specified valu e of (f , UO) may
be tested using T * = t* (Z, y) in much the same way, yielding the one-sided significance level
(6.2)
where , as always, I' = exp f-v). Expression (6.2) is th e probability that the t est st at ist ic would exceed its observed value T * if
(6.3)
For the test statistics in §2.4.3, the exact significan ce level (6.3) may be approximat ed in large samples using the exp ectation I-l~o a nd variance a~o of T* under the model (6.3) , and referring the deviat e (T* -1-l~o)la~o to the standard normal distribution. The calculations of the moments of T* are essent ially the same as for T in Chapter 4, except that a different UO is of interest. An example is given in §6.2.5.
If the test (6.2) rejects (I' , UO) , then the test for bias based on the unaffected outcome y has rejected as implausible the point (f, UO) which did most to perturb the infer ence about the outcome R of primary interest, so the sensitivity of the primary comparison is reduced. On the other hand, if (I", UO) is not rejected, then (T', UO) remains plausible in light of the test based on y , so the sensitivity of the primary comparison for R is unchanged.
As the sample size increases, the test for hidden bias will tend to reject any value (T", UO) for which the expectation I-l~o of T* differs from the expectation I-l~ of T * at the true (I' , u) . Somewhat more precisely, as N .......
00, if a~. I VN tends to a constant, as is true of the st at ist ics in §2.4.3
under mild conditions that forbid degeneracy, and if (I-l~o -1-l~)IN tends to a nonz ero constant, then the power of the test for bias based on T* tends to one . For details, see Rosenbaum (1992).

220 6. Known Effects
6.2.5 An Example: Did the Test Using Unrelated Health Conditions Reduce Sensitivity?
In §4.6.6, the association between chromosome damage and eating contam-
inated fish became sensitive to hidden bias when I' = 3 for a U O containing
21 ones and 18 zeros , where U O was ordered in the same way as the percent ages of Cu cells in Tabl e 4.15. Is this pattern and magnitude of hidden bias, (T' , u) = (3, U O) , plausible in light of the test for hidden bias in §6.2.3?
The unrelated health conditions in Table 6.3 were found to be consistent with the abs ence of bias, I' = 1; specifically, the rank sum was 483.5 with expect ation 460, varianc e 932.4 , and st andardized deviate (483.5 460)/J932.4 = 0.77. If instead (T, u) = (3, U O) , then the rank sum statistic for unrelated health conditions is still 483.5 , but its expec t at ion is now 457.5, and its variance is 874.3, yielding a deviate of 0.88 = (483.5457.5)/ J874 .3. In other words , the observed data on unrelated health conditions are consistent with the absence of hidden bias, I' = 1, but they are
also quite consistent with a hidden bias (I', u) = (3, U O) that would alter
the study's conclusion about the effects of methylmercury on chromosome damage. Though the test found no evidence of hidden bias, it did not reduce the sensitivity to bias of the primary comparison; that is, it did not reject the point [I' , u) = (3, U O) of maximum sensitivity.
As noted in §6.2.4, the test for hidden bias based on the unaffected outcome y has greatest power against an unobserved covariate u strongly related to y . On the other hand, as seen in Chapter 4, the test of the null hypothesis of no treatment effect on the response r is most sensitive to bias from an unobserved covariate u strongly related to r. If y has only a weak relationship with r, as is true of the relationship between unrelated health conditions and the percentage of Cu cells , then the t est for bias based on y will have little power against values of u that matter most for r. For reducing sensitivity to hidden bias, the ideal y would be unaffected by the tre atment but otherwise would be st rongly related to the response r . This ideal y bears some resemblance to a useful type of covar iate, namely, a "baseline measure" or "pretest score," which is a measure of outcome of interest recorded prior to treatment , so a "baseline measure" is unaffected by the treatment but is often highly correlated with the outcome.
6.2.6 Should Adjustments Be Made for Unaffected Outcomes?
Should an unaffected outcome be viewed as another covariate? Should adjustments be made for unaffected outcomes in just the same way that adjustments are made for covariates?
The goal is compare subjects who were comparable prior to treatment. An outcome is, by definition, measured after treatment. Adjustments for unaffected outcomes render peopl e comparable prior to treatment only under special and restrictive circumstances, that is, under assumptions that

6.3 An Outcome With Known Direction of Effect 221
may be wrong and are often difficult to justify. This is discussed formally and in detail in Rosenbaum (1984b) .
A bias visible in an unaffected outcome may only be the faint trace of a much larger imbalance in an unobserved covariate. Indeed, there is a sense in which, if an imbalance in an unaffected outcome is produced by an imbalance in an unobserved covariate, then the covariate imbalance is always at least as large as the outcome imbalance. See Rosenbaum (1989b, §4.3) for formal discussion. Removing the outcome imbalance may do little to remove the imbalance in the unobserved covariate.
6.3 An Outcome With Known Direction of Effect
6.3.1 Using a Nonnegative Effect to Test for Hidden Bias
In many cases, a treatment can have no effect or can have the effect of increasing a particular outcome Y, but it cannot plausibly decrease it . In §6.1.2, radiation from nuclear fallout might have no effect on the frequency of childhood cancers other than leukemia, or it might increase them, but it is hard to imagine that fallout is preventing cancers. In Problem 2, occupational exposures to benzene might have no effect on total mortality or might increase mortality, but it is hard to imagine that benzene exposures prevent death.
In the terminology of §2.5, if the treatment has an effect on Y , then Y
takes the value yz if Z = z where each yz is fixed. There is no interference
between units if Yzsi = YTsi whenever Zsi = 1, and Yz si = uc« whenever
Zsi = 0, and there is a nonnegative effect if YTsi 2: YCsi for all (8, i). Let T* = t* (Z , Y) be an effect increasing statistic, for instance, any of the
statistics in §2.4.3. If the treatment has a nonnegative effect on Y, then the statistic T* will
tend to be larger than if the treatment had no effect on Y . Compare T* to its distribution in the absence of hidden bias under the null hypothesis of no effect on Y ; that is, proceed exactly as in §6.2.1. If T* is large, falling in the extreme upper tail of this distribution, then two explanations are possible, namely, a positive effect on Y or hidden bias. However, if T* is small, falling in the extreme lower tail of this distribution, then this cannot be due to a nonnegative effect on Y, so there is evidence of hidden bias. More precisely, if T* is small, calculate the tail probability of a value as smaller or smaller than the observed T* assuming the absence of hidden bias and no effect of the treatment on Y . Report this tail probability as the significance level for testing the hypothesis that hidden biases are absent. These highly intuitive ideas are discussed formally in §6.4.
This logic was used in §6. 1.2 in connection with childhood cancers other than leukemia in high- and low-exposure counties in Utah. Under the premise that higher levels of radiation from fallout might cause but would

222 6. Known Effects
not prevent cancers , the finding that high-exposure counties had lower frequencies of other childhood cancers was taken to indicate the presence of hidden bias .
6.3.2 Did the Test Reduce Sensitivity to Bias?
In §6.3.1, an outcome Y with a nonnegative effect was used to test the hypothesis that there is no hidden bias; that is, I' = 1. To use Y to test the hypothesis Ho : (I", u) = (T" , UO) with (T", UO) specified, proceed exactly as in §6.2.4, comparing T* to its distribution determined from (6.2) under the hypothesis of no effect on Y. As in §6.3.1, if T* is large compared to this distribution, there are two explanations: a positive effect on Y or an incorrect value of (T", UO) . However, if T* is small compared to this distribution, it cannot be due to a nonnegative effect on Y, so there is evidence against the hypothesized value (T" , UO). These considerations are stated formally in §6.4.
As in §6.2.4, the typic al use of this procedure is to test whether T* has rendered implausible the point of greatest sensitivity (F" , UO) for the outcome R of primary interest.

6.4 *The Behavior of T* with Nonnegative Effects

In §6.3, the significance level for the simple hypothesis of no effect on Y was used to test the composite hypothesis of a nonnegative effect. This section looks at the relevant technical details. Let T* = t*(Z, Y). Under
the model (4.6), the chance that T* 2: c is

~. * ( . _ . exp(rzT u)

etc = L..,lt
zEf!

z,Yz)

~

cj"
L..bEf!

exp

(b 'Y

T

).
u

(6.4)

Let a be anyone fixed treatment assignment, a E n. Suppose we ob-
served Z = a and, consequently, Y = Ya and T* = t* (a, Ya) . The hypothesis that the treatment had no effect on Y would say that Y = Ya , no matter how treatments Z were assigned. The significance level, say etc,a, for testing this hypothesis would be

(6.5)

The following proposition says that when the treatment has a nonnegative effect, the statistic T* is stochastically larger than all of its permutation distributions under the null hypothesis of no effect . In particular, when the treatment has a nonnegative effect, there is at most a 5% chance that T*

6.5 Bias of Known Direction 223

will fall in the lower 5% tail of its permutation distribution under the hypothesis of no effect . The proof is the same as the proof of Proposition 4 in §2.9.

Proposition 24 If t*(', .) is effect increasing and the treatment has a nonnegative effect on Y , then O:c 2: O:c,a for all c and all a En.

If "y = 0, then

I{z En: t*(z,yz) 2: e}1

O:c =

K

'

O:c,a

=

I{z En:

t*(z ,Ya) K

2:

e}1 '

(6.6)

and O:c,a is the usual significance level for a randomization test.

6.5 Bias of Known Direction
6.5.1 Does Disability Insurance Discourage Work?
The Social Security Disability Program provides financial support to disabled workers and their families. Concern is often expressed that disability insurance could provide a disincentive to work. For example, Parsons (1980, p. 130) wrote:
The recent increase in nonparticipation in the labor force of prime-aged male s can apparently be largely explained by the increased generosity of social welfare transfers, particularly Social Security disability payments.
Would most recipients of Social Security Disability Insurance (DI) work if they did not receive benefits? In a methodologically interesting study, Bound (1989) examined this question using a severely biased comparison in which the direction of the bias was clear; see also Parsons (1991) and Bound (1991). Specifically, Bound compared recipients of DI, say Z si = 0, to individuals who had applied for but were denied benefits, say Z si = 1. The treatment is the denial of benefits to an applicant. In 1978, for noninstitutionalized men aged 45 to 64, these two groups were similar in terms of several demographic characteristics (Bound 1989, Table 2), including me-
dian age of 55.6 for Z si = 1 versus 58·.3 for Z si = 0, years of education of
9.2 versus 9.1, percentage nonwhite of 13.2% versus 12.4%, and percentage married of 74.3% versus 79.9%. Nonetheless, the compar ison is biased because benefits tend to be granted to individuals who are more seriously ill and who are less able to work , and Bound (1989, p. 484) documents that the "rejected applicants are healthier and more capable of work than those who were accepted." So when rejected applicants are compared to applicants who received benefits, one expects to see greater participation in the workforce by rejected applicants for two reasons: they are more fit for

221\ 6. Kn own Effects
work , and they lack t he disincentiv e effect of t he be nefit. In ot her words, Bound is arguing t ha t t he direct ion of bias is known for the outcome R of pr imar y interest , nam ely, workforce par ti cipation . Is knowing t he dir ection of th e bias helpful?
Bound looked at a var iety of measures of workforce participat ion, but for cur rent purposes, it suffices to consider t he p ercentage employed a mong workers who applied for disability insuran ce. For noninsti tut ion alized men aged 45 t o 64 in 1978, Boun d (1989, Tabl e 2) found tha t 28.7% ofrejected
ap plicants (Zsi = 1) and 2.3% of recipi ents of DI were employed . Bound's
argument is essentially t he following. The differ en ce, 28.7 - 2.3, might reflect a disincenti ve effect of DI , or it might reflect the supe rior health of reject ed applicants, or it might reflect both t o some degree. In other word s, the difference 28.7 - 2.3 might overestimate t he effect t hat denying benefits would have had on workers who act ua lly received benefit s, but it seems unlikely to und erest imate the effect. If one accepte d this argument, one would conclude that most recipi ents of DI would not work if benefits were denied; after all, when benefits were denied to a healthier group of workers, most of them did not return to work .
Noti ce that knowing the dir ection of bias is helpful in some conte xts but not in other s. Bound (1989) found est ima tes of the disin centive effect that were much smaller than ot her studies had found . It was therefore relevant that the small size of these estimated effect s could not be at t ribute d to bias. Had Bound found larger est imates than others had found, knowing that t he bias te nded t o make the est imates larger would have weakened rather t han strengthened the case for his est imates when compared to t hose obtained by ot hers .
Bound's (1989) paper pr omp ted a comment by P ar sons (1991) with a reply by Bound (1991). Briefly, the discussion concerned whet her or not t here were addit iona l hidd en biases , beyond the bias of known directi on caused by denying benefits to healthier indiv idua ls.
6.5.2 *Bias of Known Direction: Formal Statement
Thi s sect ion provides one simple, form al st ate ment of the ar gument used in §6.5.1, so that a bias of known direction implies a n infer enc e that is biased in a known dir ecti on. The inference is based on a stat ist ic, t ( ', .) , which is both arrangement-increasing and effect increasing, two properties share d by most statistics discussed in this bo ok. Also, the distribution of treatment assignm ent s is governed by (4.6) with 'Y 2: O. For brevity and simplicity of discussion , assume the treatment has an addit ive effect ,
R = r c + TZ , so interest focuses on T ; however , this is by no means a
crit ical assumption. The discussion her e builds upon §6.4.
Consider t esting the hypothesis H o : T = T O by comput ing T = t (Z , R-
TO Z) from the adjusted responses, R - TOZ , and comparing T to it s null distribution under (4.6). In gener al , t he adjusted resp onse is R - T OZ =

6.5 Bias of Kn own Direction 225
r C + (T - T O) Z, SO for each z E 11 writ e Y« = r C+(T - T O) Z for the adju sted response that would have been observed under treatment assignment z. If
th e hypothesized effect is too small, t hat is, if T > T O, th en for every
zEn, the statisti c computed from th e adjust ed resp onses is too large,
t hat is, t (z,yz ) 2: t (z ,rc ), because t( ·, ·) is effect increasin g, and (Y zsi -
= = = rCsi )( 2zsi - 1) Zsi (T - T O) ( 2zSi - 1) 2: 0 for both Zsi 0 and Zsi 1.
It follows that if T > T O, then

2:

"L".)t(z , r c) zEfl

2:

L ( k]

ex p h z T bEflexp I

ub)T

u

)

=

((rc, u)

, say.

Here, ((rc ,u) is the chance that·t(z,rc) 2: k due to bias alone. Several

technical conclusions follow from this. After st ating the technical con-

clusions, they are then int erpreted in terms of the bias of the inference.

First, t (Z , R - TOZ) 2: t (Z, r c), so t (Z , R - TOZ) is stochastically larger

than t (Z , r c) whenever T > TO' Moreover, by Proposition 17, ((rc , u) is

arrangement- increasing. Finally, if Usi had a condi tional probability distri-

bu tion given r c a so that Usi and r C si were positively related (forma lly, if

11;=1 Pr(ulrc) =

11 ~":1 Pr(usilrc si ), where Pr(usilrc si) is TP2 ) , then the

chance that t (Z , r c) 2: k is greater than or equal to the chance under a

uniform randomized experiment ; see Rosenb aum (1989a) for details, and

Kri eger and Rosenbaum (1994) for a generalization.

If the hypothesis H o : T = T O is tested using a rank test such as
Wilcoxon's rank sum or signed rank test whose randomization distribution

rejects at level a when T 2: k, then the following several int erpretations

follow when TO is too small, that is, when T > TO. First, no matter what

pattern of biases u are pr esent, the value TO that is too small is more likely

to be rejected than the true value T . Second , if Usi and r o se are positively

related , then the chance of rejecting both TO and T is at least Ct. Third,

the stronger the positive relationship between r c and u, the more likely

rejection becomes.

In Bound's (1989) st udy, one continuous measure of workforce partici-

pation was the change in earnings, that is, earnings in the year after ap-

plication for DI benefits minus average earnings in the two years before

application. Notice that this is the change in earnings, so most changes

are negative, and the more negative the change , the greater th e decline in

earnings. In this case , r C si is the change in earnings if DI benefits are
granted, rr« = rca + T is the change in earnings if benefits are denied ,

and T is the disincentive effect , which is pre sumably nonnegative. Also,

U si measures fitness for work , larger values indicating greater fitness. Pre-

sumably, I 2: 0, so that greater fitness for work, Usi , is associated with a

226 6. Known Effects
greater chance that benefits will be denied , Zsi = 1. Presumably, greater
fitness for work, Usi, is nonnegatively associated with a larger, that is, less negative, decline in earnings, rc«. Suppose that we test the hypothesis
that the disincentive effect is Hi, : T = TO , versus H A : T > TO when in fact the true disincentive effect is larger, T > TO, and the test refers a conven-
tional rank test to its randomization distribution, rejecting at level Q when the randomization distribution is correct. If bias due to u would have led us to reject the true T, then it would also lead us to reject TO'S that are too small , and the probability that this will happen is at least Q and it increases as the strength of association between u and rc increases. If a small disincentive effect TO looks plausible-if the conventional test fails to reject it-then this failure to reject cannot be attributed to hidden bias due to u. Of course, similar considerations apply to confidence intervals and Hodges-Lehmann point estimates derived from the test. Bound's estimates of the disincentive effect are smaller than those found by others, but the small size of these estimates cannot be due to hidden biases of the type just described, because they push the estimate in the opposite direction.
6.6 Bibliographic Notes
Campbell (1969) and Campbell and Stanley (1963) discuss the strengths and weaknesses of various study designs, including the design in §6.1.2. Cook, Campbell, and Peracchio (1990, pp. 546-7 and pp . 561-564), Cook (1991), Shadish and Cook (1999, Table 1) and Shadish, Cook and Campbell (2002) refer to unaffected outcomes as "nonequivalent dependent variables." Disease specificity in §6.1.3 has been widely discussed; see, for example, Yerushalmy and Palmer (1959), Lilienfeld (1959) , Sartwell (1960), Hill (1965) , Susser (1973), and Rothman (1986) to sample a range of opinion. The use of known effects to test for hidden bias is discussed in Rosenbaum (1984a, 1989a,b). The link in §6.2.5 between a test for bias using one outcome and a sensitivity analysis for another is discussed in Rosenbaum (1992).
6.7 Problems
1. Petitti, Perlman, and Sidney (1986) commented on the contradictory results of several studies concerning the relationship between postmenopausal estrogen use and heart disease. After adjusting for several covariates, they found that the risk of death from cardiovascular disease for users of estrogen was half the risk of nonusers; however , they found the same difference for deaths from accidents, homicides, and suicide. They write:

6.8 References 227
There is no biologically plausible reason for a protective effect of postmenopausal estrogen use on mortality from accidents, homicide, and suicide. We believe that our results are best explained by the assumption that postmenopausal estrogen users in this cohort are healthier than those who had no postmenopausal estrogen use, in ways that have not been quantified and cannot be adjusted for. The selection of healthier women for estrogen use in this population is not necessarily a characteristic shared by other populations.
Do you agree? Consider also Kreiger, Kelsey, Holford , and O'Connor (1982).
2. Infante, Rinsky, Wagoner, and Young (1977) found a statistically significant excess of leukemia deaths among benzene workers when compared to the general population, but a statistically significant deficit of deaths overall. If one were willing to assume that working with benzene might cause disease or death but would not prevent them, then what would you conclude about the general health of benzene workers compared to the population as a whole? Could this explain the excess of leukemia deaths? Why or why not ?
3. What is the smallest value of r such that the expected value of T* in
§6.2.2 would equal the observed value of 483.5 for some u E U? (Hint:
Use the methods of Chapter 4. Answer: I' = 1.73 and u contains 15
ones and 24 zeros ordered in the same way as y in Table 6.3, that is,
U i ,= 0 when Yi = 0 and Ui = 1 when Y i > 0.)
4. How is the calculation in Problem 3 above related to the range of Hodges-Lehmann estimates of effect that one could calculate for y
using the procedure in §4.6.8? (Hint: What is the smallest r such
that the interval of Hodges-Lehmann estimates includes zero?)
5. Why is there no largest value of r such that the expected value of T*
in §6.2.2 equals the observed value of 483.5 for some u E U? (Hint: Review §4.7.5.)
6.8 References
Beck , H. L. and Krey, P. W . (1983) Radiation exposures in Utah from Nevada nuclear tests. Science, 220, 18-24.
Bound, J . (1989) The health and earnings of rejected disability insurance applicants. American Economic Review, 79 , 482-503.

228 6. Known Effects
Bound, .1. (1991) The health and earnings of rejected disability insurance applicants: Reply. American Economic Review, 81 , 1427-1434.
Campbell, D. T. (1966) Pattern matching as an essential in distal knowing. In : The Psychology of Egon Brunswik, Kenneth Hammond, ed ., New York: Holt, Rinehart and Winston, pp . 81-106.
Campbell, D. T . (1969) Reforms as experiments. American Psychologist, 24, 409-429.
Campbell, D. T . and Stanley, J . (1963) Experimental and Quasi Experimental Designs for Research. Chicago: Rand McNally.
Cook , T. D. (1991) Clarifying the warrant for generalized causal inferences in quasi-experimentation. In : Evaluation and Education at Quarter Century , M. W . McLaughlin and D. Phillips, eds. , NSSE 1991 Yearbook , pp. 115-144.
Cook, T . D., Campbell, D. T. and Peracchio, L. (1990) Quasi Experimentation. In: Handbook of Industrial and Organizational Psychology, M. Dunnette and L. Hough, eds ., Palo Alto, CA : Consulting Psychologists Press, Chapter 9, pp . 491-576.
D'Abadie, C. and Proschan, F . (1984) Stochastic versions of rearrangement inequalities. In Inequalities in Statistics and Probability, Y. L. Tong, ed., Hayward, CA: Institute of Mathematical Statistics, pp . 4-12.
Donohue, J. .1 . and Levitt, S. D. (2001) Legalized abortion and crime. Quarterly Journal of Economics, 116, 379-420.
Gastwirth, J. (1988) Statistical Reasoning in Law and Public Policy. New York: Academic.
Hill, A. B. (1965) The environment and disease: Association or causation? Proceedings of the Royal Society of Medicine, 58, 295-300.
Hollander, M., Proschan, F ., and Sethuraman, J. (1977) Functions decreasing in transposition and their applications in ranking problems. Annals of Statistics, 5, 722-733.
Infante, P., Rinsky, R., Wagoner, .1., and Young , R. (1977) Leukemia in benzene workers. Lancet, July 9, 76-78.
Kreiger , N., Kelsey, .1., Holford , T ., and O'Connor, T. (1982) An epidemiologic study of hip fracture in postmenopausal women. American Journal of Epidemiology, 116, 141-148.

6.8 References 229
Krieger, A. M. and Rosenbaum, P. R (1994) A stochastic comparison for arrangement increasing functions. Combinatorics, Probability and Computing, 3 , 345-348.
Land, C. E . (1979) The hazards of fallout or of epidemiologic research . N ew England Journal of Medicin e, 300, 431-432.
Legorreta, A. P. , Silber , J . H., Costantino, G. N., Kobylinski , R W. , and Zatz, S. L. (1993) Increased cholecystectomy rate aft er the introduction of laparoscopic cholecystectomy. Journal of the American M edical Association , 270, 1429-1432.
Lilienfeld, A. (1959) On the methodology of investigations of etiologic factors in chronic diseases-Some comments. Journal of Chronic Diseases, 10,41-46.
Lyon, J . L., Klauber, M. R, Gardner, J . W ., and Udall , K. S. (1979) Childhood leukemias associated with fallout from nuclear testing. New England Journal of Medicine, 300, 397-402.
Mittleman, M. A., Maclure, M., Sherwood, J. B., Mulry, R. P. , Tofter, G. H. , Jacobs, S. C., Friedman, R , Benson, H. , and Muller, J . E. (1995) Triggering of acute myocardial infaction onset by episodes of anger . Circulation , 92, 1720-1725.
Parsons, D. O. (1980) The decline of male labor force participation. Journal of Political Economy, 88, 117-134.
Parsons , D. O. (1991) The health and earnings ofreject ed disability insurance applicants: Comment. American Economic Review, 81 , 14191426.
Petitti, D. , Perlman, J. , and Sidney, S. (1986) Postmenopausal estrogen use and heart disease. New England Journal of Medicin e, 315, 131132.
Rosenbaum, P. R. (1984a) From association to causation in observational studies. Journal of the American Statistical Association, 79, 41-48.
Rosenbaum, P. R. (1984b) The consequences of adjustment for a concomitant variable that has been affected by the treatment. Journal of the Royal Statistical Society, Series A , 147, 656-666.
Rosenbaum, P. R. (1989a) On permutation tests for hidden biases in observational studies: An application of Holley's inequalit y to th e Savage lattice. Annals of Statistics, 17, 643-653.
Rosenbaum, P. R (1989b) The role of known effects in observational st udies. B iometrics, 45, 557-569.

230 6. Known Effects
Rosenbaum , P. R (1992) Detecting bias with confidence in observational studies. Biometrika, 79 , 367-374.
Ross , H. L., Campbell, D. T ., and Glass , G. V. (1970) Determining the social effects of a legal reform: The British "Breathalyser" crackdown of 1967. American Behavioral Scientist, 13, 493-509 .
Rothman, K. (1986) Modern Epidemiology. Boston: Little, Brown.
Sackett, D. (1979) Bias in analytic research. Journal of Chronic Diseases, 32 , 51-68.
Sartwell, P. (1960) On the methodology of investigations of etiologic factors in chronic diseases: Further comments. Journal of Chronic Diseases, 11,61-63.
Shadish, W. R and Cook, T. D. (1999) Design rules: More steps toward a complete theory of quasi-experimentation. Statistical Science, 14, 294-300.
Shadish, W . R, Cook, T . D., and Campbell, D. T . (2002) Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Boston: Houghton-Mifflin.
Skerfving, S., Hansson, K., Mangs, C., Lindsten, J., and Ryman, N. (1974) Methylmercury-induced chromosome damage in man. Environmental Research, 7 , 83-98.
Susser, M. (1973) Causal Thinking in the Health Sciences: Concepts and Strategies in Epidemiology. New York: Oxford University Press.
Trichopoulos, D., Katsouyanni, K ., Zavitsanos, X., Tzonou, A., and DallaVorgia, P. (1983) Psychological stress and fatal heart attack: The Athens 1981 earthquake natural experiment. Lancet, 26 February, 441-444.
Yerushalmy, J . and Palmer, C. (1959) On the methodology of investigations of etiologic factors in chronic diseases. Journal of Chronic Diseases, 10, 27-40.

7
Multiple Reference Groups in Case-Referent Studies
7.1 Multiple Reference Groups
7.1.1 What Are Multiple Reference Groups?
A case-referent study compares the frequency or intensity of exposure to the treatment among cases and among referents or noncases who are free of the disease; see §3.3. If referents or noncases are selected from several different sources, then the study has several distinct referent groups.
Case-referent studies with several referent groups are common . A few examples follow. Notice, in particular, the types of referent groups used. Gutensohn, Li, Johnson, and Cole (1975) compared the frequency of tonsillectomy among cases of Hodgkin's disease to two groups of referents, namely, spouses of cases and siblings of cases. The Collaborative Group for the Study of Stroke in Young Women (1973) compared the use of oral contraceptives by cases of stroke among young women aged 15 to 44 with the use of oral contraceptives among two referent groups matched for age and race, namely, women disch arged from the same hospital for some other disease and women who were neighbors of the cases. In a study of subacute sclerosing panencephalitis in young children, Halsey, Modlin , Jabbour, Dubey, Eddins, and Ludwig (1980) used playmates of cases as one referent group and children admitted to the same hospital as another. Kreiger, Kelsey, Holford, and O'Connor (1982) compared estrogen use among female cases of hip fracture with estrogen use in two referent groups, namely, trauma and nontrauma referents, that is, other women from the same hospitals who were admitted for traumas such as fractures or sprains other

232 7. Multiple Reference Groups in Case-Referent Studies
than hip fractures and women who were admitted for disorders that did not involve a physical trauma.
The use of multiple referent groups in case-referent studies is different from the use of multiple control groups. The case group and several referent groups are each exposed to the treatment and each exposed to the control in varying degrees. In contrast, a study with multiple control groups has several groups of subjects who did not receive the treatment. A case-referent study may have a single referent group and several control groups, and one will be discussed in §8.1.4. In principle, a case-referent study could have both multiple referent groups and multiple control groups. Notice that the term "control group" is sometimes used loosely to describe any group used for comparison, but in this book a control group refers specifically to subjects who did not receive the treatment.
7.1.2 An Example: A Study of Reye's Syndrome with Four Referent Groups
Aspirin bottles contain the following warning: "Children and teenagers should not use this medicine for chicken pox or flu symptoms before a doctor is consulted about Reye syndrome, a rare but serious illness reported to be associated with aspirin." Reye 's syndrome typically occurs in children under the age of 15 following an upper respiratory tract infection, and it often leads to death from cerebral damage. Hurwitz (1989) surveys the evidence linking Reye's syndrome and aspirin.
Hurwitz, Barrett, Bregman et al. (1985) compared the use of aspirin by cases of Reye's syndrome with its use in four referent groups, namely, referents from the case's emergency room, school, community, and inpatients at the case's hospital. This study was not the first to link aspirin with Reyc's syndrome, but from a strict ly methodological view , it is the most interesting. Earlier studies had convinced the US Surgeon General and the American Academy of Pediatrics to advise against giving children aspirin for chicken pox or flu, and that appears to have been very good advice, supported by the new US Public Health Service study by Hurwitz et al. (1985), which attempted to address criticisms of earlier studies. Observational studies are often subject to criticism, at times warranted criticism, and some caution in asserting conclusions may be appropriate. However, caution and uncertainty do not, by themselves, favor the null hypothesis of no treatment effect over other hypotheses; rather, caution in the face of uncertainty may sometimes merit strong action to warn of a possible hazard.
In their study, all subjects, both cases and referents, had to have had a "respiratory, gastrointestinal, or chicken pox antecedent illness within 3 weeks before hospitalization." In other words, the population being described consists of children who have had one of these illness within 3

7.1 Multiple Reference Groups 233

TABLE 7.1. Counts of Asp irin Use by Cases and Referents.
Aspirin No Aspirin % Using Aspirin

Cases

28

2

93%

Em ergency room

7

18

28%

Inpatient

5

17

23%

School

24

17

59%

Community

30

27

53%

TABLE 7.2. Od ds Rati os for Aspir in Use .

Cases School Community Emergency room

School 9.9

Community
12.6 1.3

Emergency Room
36.0 3.6 2.9

Inpatient
47.6 4.8 3.8 1.3

weeks. The st udy matched cases to referent s on th e basis of age, race, date of illness, and the spec ific typ e of antecedent illness. In addition, indi vidu al referent groups were matched in ot her ways; specifically, emergency room and inpatient referents came from the sa me hospital as the case, school referents came from t he sa me school or day care cente r, and community referents were selected by ran dom digit teleph one dialing from the same .community as t he case . Ta ble 1 in t heir art icle shows that cases and referents wer e similar in terms of age, race, gend er , and antecedent illness. (T he comparisons t hat follow are based on the published data and ignor e the matching, but for comparisons done both ways, t he matched and unmatched analyses agree wit h each ot her; compa re Tabl es 7.2 and 7.3 and t he results report ed in t he first par agraph of page 852 in Hurwi tz et al. 1985 .)
Tabl e 7.1 gives the frequ encies of aspirin use by case and referent groups in Hurwitz et al. (1985). Of the 30 cases, 28 had used aspirin. In each referent group, the relative frequency of aspirin use was much lower.
Tabl es 7.2 and 7.3 ar e calculate d from Table 7.1. Table 7.2 gives the odds ratio comparing aspirin use in each pair of groups. For instance, the odds of using aspirin were 9.92 times higher in the case group than in the school contro l group. Tabl e 7.3 gives the usual chi-square stat ist ic with cont inuity correction for a 2 x 2 t abl e for each pair of groups. Each chi-square has one degree of freedom, and is significant at th e 0.05 level or 0.01 level if great er than 3.84 or 6.63, resp ecti vely.
Two patterns ar e appare nt in Tables 7.2 and 7.3. F irst, cases used aspir in substantially a nd significantly more than did all four referent groups. If the st udy were free of biases, Cornfield 's (1951) result in §3.3.2 would

234 7. Multiple Reference Groups in Case-Referent Studies

TABLE 7.3. Chi-Squares for Aspirin Use.

Cases School Community Emergency room

School 9.0

Community
12.9 0.1

Emergency Room
22.4 4.6 3.3

Inpatient
24.3 6.0 4.6 0.0

suggest that aspirin use increases the risk of Reye's syndrome by 9.9 to 47.6 times. The second pattern concerns differences between the referent groups. School and community referents have similar frequencies of aspirin use, the odds ratio being 1.3. Emergency room and inpatient referents have similar frequencies of aspirin use, again with an odds ratio of 1.3. However, school and community referents are three to five times more likely to use aspirin than emergency room or inpatient referents, and three of these four comparisons are significant at the 0.05 level.
The differences in aspirin use among the referent groups are inconsistent with a study that is free of selection and hidden biases. If there were no bias , the frequency of aspirin use in each referent group should differ only by chance from the frequency of aspirin use among all children without Reye's syndrome in the relevant population of children having recently had one of the antecedent illnesses. However, in contrast with the study of nuclear fallout and childhood leukemia in §6.1.2, the differences among the referent groups, while statistically significant, are much smaller than each of the four differences between the cases and each referent group. There is evidence of hidden bias , but the biases appear to be much smaller than the ostensible treatment effect.
7.1.3 Selection Bias and Hidden Bias in Case-Referent Studies
Recall from §3.3 that a synthetic case-referent study begins with the population of M subjects in §3.2.1 and then draws a random sample without replacement of subjects who are cases and a random sample of subjects who are not cases, possibly after stratification on the observed covariates x . In some studies, the sample of cases includes all of the cases in the population; this is a trivial sort of random sampling, but it is random sampling nonetheless. In such a synthetic case-referent study, the reference group is the sample of subjects who are not cases . Synthetic case-referent studies are sometimes conducted and they form a simple model for the situation in which the process of selecting cases and referents neither introduces additional biases nor reduces bias . In a synthetic case-referent study free of hidden bias , §3.3 showed that the odds ratio estimates the population

7.1 Multiple Reference Groups 235
odds ratio and the usual Mantel-Haenszel test appropriately tests the null hypothesis of no effect of the treatment or exposure. Section §4.4 considered the test of no effect and its sensitivity to hidden bias in a synthetic case-referent study in which there is no selection bias .
Most case-referent studies are not synthetic case-referent studies. In particular, a study with several different referent groups is, by definition, not a synthetic case-referent study, since the several reference groups are, by definition, not random samples from the relevant population of subjects who are not cases. The purpose of this section is to discuss case-referent studies in which the reference group is not a random sample or stratified random sample of subjects who are not cases. This section summarizes findings based on the considerations in the appendix, §7.3, which should be consulted for formal proof.
Hidden bias may be introduced when treatments or exposures are assigned to the M subjects in the population. Selection bias may be introduced when cases and referents are selected into the study from the cases and referents in the population. The relationship between selection and hidden bias can be subtle. A careful choice of referent group may remove a hidden bias that would have been present had the entire population been available for study. A poor choice of referent group may introduce a selection bias into a study that was free of hidden bias, that is, a bias that would not have been present in the entire population.
In the discussion that follows, the model for hidden bias, (4.1), (4.2), or (4.6), is assumed to hold in the population of M subjects before cases and referents are selected. The intent is to test the null hypothesis of no treatment effect, so the null hypothesis is tentatively assumed to hold for the purpose of testing it. The null hypothesis of no treatment effect says that whether or not a subject is a case is unaffected by the treatment or exposure. More precisely, r is the N -dimension vector with rsi = 1 if the
ith subject in stratum s is a case and rsi = 0 if this subject is not a case,
and the null hypothesis H o says that r would be unaltered if the pattern of exposures Z were changed.
The null hypothesis H o refers to r, that is, to whether or not a subject is a case. In §7.1.2, r distinguishes cases of Reye's syndrome from children without Reye's syndrome. In many case-referent studies, other variables besides r are used in selecting referents, and some of these may be outcomes in the sense that they describe subjects after exposure to the treatment. This turns out to be an important consideration in distinguishing hidden bias and selection bias. As has been true throughout Chapters 4 and 6, the term hidden bias refers to an unobserved covariate u, that is, a variable describing subjects prior to treatment so that U is unaffected by the treatment.
Under H o, if subjects are selected based on quantities that are unaffected by the treatment, such as the response r , the observed covariate x , the unobserved covariate u, or some other unaffected outcome y, then the form

236 7. Multiple Reference Groups in Case-Referent Studies
of the model (4.6) and the value of I are unchanged. In this situation, if
there is no hidden bias in the sense that I = 0, then conventional methods such as the Mantel-Haenszel test may be used to test H a, and if hidden bias
is possible in the sense that I might not equal zero , then the methods in Chapter 4 may be used to appraise sensitivity to bias. In this specific sense, if cases and referents are selected based on quantities that are unaffected by the treatment, there is no selection bias.
Consider instead an outcome that is affected by the treatment, say y = Yz, where as in §6.3 the value of this outcome changes if the treatment assignment Z changes . For example, see Problem 1. If subjects are selected using the affected outcome Y = Yz, then the selection may introduce a bias where none existed previously, and it may distort the distribution of Z, so the model (4.6) can no longer be used to study sensitivity to hid-
den bias . For instance, if the treatment had a positive effect on Y = Yz,
then selecting referents with high values of Y would produce a referent group in which too many referents had been exposed to the treatment. Under H a, membership in the referent group should not change with the treatment or exposure. In the hypothetical study in §3.3.3 of smoking and lung cancer, a referent group of cardiac patients would lead to selection bias because smoking causes cardiac disease. Selecting cardiac patients as referents means selecting subjects who have higher frequencies of smoking, more exposure to the treatment, because exposure to the treatment caused some of their cardiac disease .
Although selecting subjects based on quantities unaffected by the treatment does not introduce selection bias in the test of H a, it may alter the quantity or pattern of hidden bias. That is, even if selection is based on fixed quantities unaffected by the treatment, the selected subjects may differ systematically from the unselected subjects in their values of the unobserved covariate Usi. Indeed, an investigator who uses siblings or neighbors as referents is, presumably, trying to reduce hidden bias without introducing selection bias, that is, to produce matched sets that are more homogeneous than the population in terms of certain covariates U that are not explicitly measured, without distorting the frequency of exposure to the treatment. Though often a sensible strategy, an attempt to reduce hidden bias by the choice of referent can at times backfire, increasing rather than reducing the amount of hidden bias , and perhaps this happened with the inpatient referents in §7.1.2. Let U be a binary variable indicating whether or not the adult caring for a child is aware of the advice against aspirin use by the Surgeon General and the American Academy of Pediatrics. It is conceivable that a case tends to differ more from an inpatient referent in terms of U than a case would typically differ from a referent selected at random from children who are not cases.
To summarize: Selecting referents based on characteristics unaffected by the treatment does not introduce selection bias in the test of H a, but it may decrease or increase the quantity of hidden bias. Selecting referents

7.2 Matched Studies with Two Referent Groups 237
based on characteristics affected by the treatment can introduce selection biases that distort the distribution of treatments or exposures Z, thereby invalidating both:
(i) tests that would have been appropriate in the absence of hidden bias; and
(ii) sensitivity analyses that would have been appropriate in the presence of hidden bias .
Again, formal proofs are given in the appendix, §7.3.
7.2 Matched Studies with Two Referent Groups
7.2.1 An Example: Breast Cancer and Age at First Birth
Table 7.4 describes data collected by Lilienfeld, Chang, Thomas and Levin (1976) and reported by Liang and Stewart (1987). The cases in this study were women in Baltimore who were diagnosed with primary malignant breast cancer. Each case was matched to one or two female referents on the basis of age and race . A hospital referent had been admitted to the same hospital as the case. A neighbor referent came from the same neighborhood as the case . There were 409 cases, of whom 195 were matched with both a hospital and a neighbor referent, 164 were matched only to a hospital referent, and 50 were matched only to a neighbor referent. The exposure of
interest here is the age of first birth, :s; 24 or :2: 25, where women who had never given birth were classified as :2: 25.
Each count in Table 7.4 is a matched set , the total count being 409
matched sets, rather than (3 x 195)+ (2 x 164)+ (2 x 50) = 1013 women. For
instance, there are 47 matched sets in which the case and both referents
first gave birth at an age :s; 24. This format is the correct format for
presenting matched comparisons because it indicates who is matched to whom, information that is necessary for an appropriate analysis.
For a moment, ignore the distinction between hospital and neighbor referents and compare the age at first birth of cases and referents using
the Mantel-Haenszel statistic. There are S = 409 strata defined by the
matched pairs and matched triples. There are a total of 209 cases who first gave birth at an age of 25 or greater, where 172.3 were expected in the
absence of hidden bias, leading to a significance level < 0.0001. If there is
no hidden bias, there is strong evidence of a higher risk of breast cancer among women 25 or older at first birth.
A first step is to test for hidden bias by comparing the frequency of older first births in the two referent groups. McNemar's test is used to compare the age at first birth in the two referent groups for the 195 matched triples. In the absence of hidden bias , matched hospital and neighbor referents

238 7. Multiple Reference Groups in Case-Referent Studies

Hospital R e fer e n t
:::; 24 :::; 24 ~ 25 ~ 25 :::; 24 ~ 25 None None

Case

< 24

:::; 24

47

32

~ 25

17

31

:::; 24

18

21

~ 25

8

21

None

58

53

None

24

29

:::; 24

17

12

> 25

11

10

should have similar frequ encies of first births at :::; 24 years of age . There
are 87 = 17 + 31 + 1~ + 21 discordant pairs, that is, hospital/neighbor
pairs in which one woman first gave birth at an age :::; 24 and the other
at an age ~ 25. In 48 = 17 + 31 of these discordant pairs, the hospital
referent first gave birth at an age:::; 24 and in the remaining 39 pairs the
neighbor referent first gave birth at an age :::; 24. McNemar 's test compares
this 48 versus 39 split of the 87 pairs with a binomial distribution with 87 ind ependent trials each having probability 0.5 of success, finding little or
no evidence that the frequency of first births at ages:::; 24 differs in the two referent groups.
In parallel with the discussion in §6.2.3, it may b e shown that the above
test comparing the two refer ent groups has the following properties. First,
in testing for hidden bias , the test has the correct level; that is, if I = 0,
then 5% of the time the test will falsely reject the hypothesis that I = 0 with a significance level of 0.05 or less. Second, for I > 0, the power of
the test increases ste ad ily as the values of u are rearranged to make the two referent groups more dissimilar; that is, the power function of the
appropriate one-sided test is arrangem ent-increasing in the pair of vectors containing the u's and t he binary indicators distinguishing hospital and
neighbor referents. The test can hope to distinguish I = 0 from I > 0 if
the referent groups are quite different in their typical values of u .

7.2.2 Partial Comparability of Cases and Multiple Referent Groups
All of the case-referent studies discussed in this chapter have the following features in common. A new (or incident) case of dis ease is made available to the investigator. This case is then matched to one or more referents who are similar in certain ways , for instance, a new patient at the sa me hospital of the same age and race. Then the case is matched to one or more additional refer ents who are similar to the case in different ways , for instance, a neighbor of the same age and race. This str ategy will be called

7.2 Matched Studies with Two Referent Groups 239

TABLE 75 Notation for a Matched Set with Two Referent Groups

Case Referent Group 1

Referent Group 2

Size

1

Is

Js

Subscripts (8,1) ( 8,2), .. . ,(8,Is + 1) (s, I s + 2) , . . . , (s, ns )

partial comparability. Each referent group is comparable to the case in some
ways but not in others. In Gutensohn, Li, Johnson, and Cole (1975), the .cases and their spouses have similar home environments and diets as adults,
while cases and siblings have similar childhood environments and diets and have some genetic similarities.
Consider testing the null hypothesis of no treatment or exposure effect, H o, by comparing cases with two referent groups, the situation with more than two groups being similar. Matched set 8 contains n s ~ 2 subjects, the
° first subject is the case , so rsl = 1, the next Is ~ subjects are referents ° from the first group, and the last Js ~ subjects are referents from the
second group , so n s = 1 + I s + Js and r si = 0 for i = 2, . .. ,ns . This
is summarized in Table 7.5 for matched set s. In the example in §7.2.1,
n s = 3, Is = 1, Js = 1, for 195 matched sets 8; ns = 2, I s = 1, Js = 0, for 164 more matched sets, and n s = 2, I s = 0, J, = 1, for 50 matched sets .
Under H o and in the absence of selection bias, a subject does not change from one referent group to another based on exposure to the treatment Z si, nor does exposure to the treatment cause cases of disease, so rsi and the
order of subjects is fixed under H o not varying with Z. To express partial comparability, write the unobserved covariate Usi as
a weighted sum of three unobserved covariates

(7.1)

where

°: :; Vk si :::; 1 for all k, 8 , i.

The first thing to notice about (7.1) is that it is not a new assumption, but
rather a reexpression of the old assumption in §4.2 that u E U. Any u E U
may be written as u = 'l/Jo Vo + 'l/J I VI + 'l/J2 V2 for some Vk E U for k = 1,2,3, and some 'l/Jk ~ 0, 1 = ~ 'l/Jk, and any u written in this way is an element
of U, so (7.1) is the same as the assumption that u E U . So far, (7.1) is
nothing new .
To express partial comparability, require

= Vi si VI s I for i = 2, . . . . L; + 1,

and

= V2si V2s I for i = I s + 2, .. . , n, ,

(7.2)

240 7. Multiple Reference Groups in Case-Referent Studies
which says that the referents in group 1 have the same value of VIsi as the case and the referents in group 2 have the same value of V2 si as the case, though VOsi may differ for cases and referents. The first thing to note is that, taken together, (7.1) and (7.2) are not a new assumption, just a reexpression of the assumption that u E U . Once again, any u E U may be
written to satisfy (7.1) and (7.2) by taking 'l/Jo = 1, 'l/JI = 0, 'l/J2 = 0, and
Vo = u , and any u that satisfies (7.1) and (7.2) is an element of U. So far, nothing new has been assumed.
The sensitivity analysis considers a range of values of the parameter
Cr,'l/JO , 'l/JI ,'l/J2) under the model (4.6). Taking Cr , 'l/JO, 'l/JI, 'l/J2) = Cr,I ,O,O)
gives exactly the sensitivity analysis in Chapter 4, because in this case
(7.2) does not restrict u in any way and Usi = VOsi' In other words,
Cr, 'l/Jo, 'l/JI ,'l/J2) = Cr, 1,0,0) signifies that partial comparability did nothing
to make either typ e of referent similar to the case in terms of the unob-
served covariate u. If instead Cr, 'l/Jo,'l/JI,'l/J2) = Cr, 0, 1, 0) then Usi = VIsi
and , using (7.2), the case and the first referent group have identical values of u, so there is no hidden bias using the first reference group. In the example of §7.2.1, this would mean that cases and matched hospital referents are comparable in terms of u. In the same way, Cr ,'l/JO,'l/JI ,'l/J2) = Cr,O,O, 1) signifies that cases and the second referent group have identical values of u; for instance, that cases and neighbors have identical values of u.
If Cr, 'l/Jo, 'l/JI,'l/J2) = Cr, 1/3, 1/3, 1/3) then the bias is split equally be-
tween the uncontrolled Vo and the partially controlled VI and V2 so partial comparability has reduced but not eliminated hidden bias for both groups.
In other words, the sensitivity considers several possibilities, including the possibility that partial comparability did nothing to reduce hidden bias, that it eliminated bias for one referent group but did nothing for the other, or that it reduced but did not eliminate bias for one or both groups.

7.2.3 *Sensitivity Analysis with Two Matched Referent Groups

The procedure for sensitivity analysis with two reference groups is similar

to that in §4.4.4 and 4.4.5 for case-referent studies; however, the sensitiv-

ity bounds now reflect the partial comparability of the referent groups.

Since the first subject in each matched set is the case, so rsl = 1 and

° rsi = for i = 2, . " ,ns, it follows that a sign-score statistic has the form

«z.; T = L s ds Li rsiZsi = L s

Most often, T is the Mantel-Haenszel

statistic with ds = 1 for each sand T = L Zsl is the number of exposed

cases, but the statistic could give different weights ds to different cases as

in §4.4.5.

In the notation of §4.4, B s = Zsl and Ps = Prob(Zsl = 11m). To conduct

the sensitivity analysis , bounds are needed on Ps under (7.1) and (7.2) , say

7.2 Matched St udies with Two Referent Groups 241

Ps- ~ Ps ~ P;- . For the Mantel-Haenszel stat istic, the bounds are used in

(4.20) for a large sa mple approxima t ion; alt ernatively, a formula ana logous

t o (4.10) is used for exact ca lculations . If there ar e var yin g weights ds , t hen

(4.21) is used.

.

The bounds require some preliminar y notation. Let 71;- be t he vector of dimension n s - 1 = I s + Js whose first Is coordinat es equa l exp (')''1/11) and whose last Js coordinates equal exp (')''1/12 )' In par allel , let 71; be the vector of dimension n s - 1 = Is + Js whose first Is coordina tes equal exp (')''1/10 + ,'1/12) and whose last Js coordinates equal exp (')''1/10 + ,'1/11)·
The mth element ary sy mmetric fun ction of an n-dimensional argument

a , with n positive coordinates, is the sum of all product s of m coordinates

of a , that is,

L II SYM m(a) =

a~j ,

bEW m j

C;J where Wm is the set containing the vectors b with 1 or 0 coordinates
such that L7=1 bj = m . This function is defined for m = 0,1 , .. . ,n. For inst ance, SYMo(a) = 1, SYM1(a) = a l + + an , SYM 2(a) = ala2 + a l a3 + ... + an-Ian , and SYM n(a) = ala2 an' For m = 1, . .. ,n, write 9m(a) = SYM m{a} / SYM m_ d a} , and notice th at 9m(a) is defined for
vect ors a with strictly po sitive coordinates.
The bounds, P; ~ Ps ~ P;- , on Ps = prob(Zsl = 11m) are Ps- = Ps+ = 1 if m s = n s, Ps- = Ps+ = 0 if m s = 0, and ot herwise if 0 < m s < ns,

p+ =

exp (')')

1

s

exp (')') + 9ms (711") '

Ps- = 1 + 9m (71;)" s

(7.3)

These expressions are derived in the appe ndix, §7.4.
To illustrate, con sider t he example in §7.2.1. Consider one of t he 195
matched sets with both a hospital and a patient referent , so n s = 3, Is = 1, Js = 1. In this matched set, the number of women who gave birth at age 25
or above could be m s = 0, 1,2, or 3. We want bounds, Ps- and P;- , on the
prob ability Ps = Prob(Zsl = 11m) that the case in this matched set was
among the women who gave birth at age 25 or abo ve. Given m s = 0, the case cer tainly did not give birth at age 25 or above, so in this case Ps- =
Ps+ = O. Similarly, if all of the women in this matched set gave birth at 25
or above, so m s = 3, then Ps- = P;- = 1. The two cases just considered, m s = 0 or m s = n s, conce rn concordant matched sets that contribute only
a const ant to the test stat istic and so do not affect the inference. Now
71;- = [exp(')'I/11) , exp(')' '¢2)] a nd 71; = [exp{r('¢o + '¢2)}' exp{r('¢o + '¢l )}]' If m s = 1, then onl y one of t he t hree women gave birth at 25 or abo ve, so SYM 1(71;-) = exp(,),'¢l) + exp(')''I/12)' SYMo(71;-) = 1, and

p+ =

ex p( , )

s exp(')') + exp(')''¢d + exp(')''¢2) '

242 7. Multiple Reference Groups in Case-Referent Studies and similarly

If, = 0, so there is no hidden bias, then Ps- = Ps+ = 1/3 in the two
expressions just given. If partial comparability did nothing to reduce bias,
so, =j:. 0, 'l/Jo = 1, and 'l/J1 = 'l/J2 = 0, then Ps+ = expCr)/{expCr) + 2}
and Ps- = 1/{I + 2 expCr)} in the expressions just given, and these are the bounds from §4.4.4.
In the same way, if two of the three women gave birth at 25 or above,
ms = 2, SYM 2(1J; ) = exp{r('l/Jl + 'l/J2)}' so

p+ =

exp(,)

s exp t-r) + _ex--=p--={c...:..'.c....':l(/-J,1:_+_ 'l,-/J-,2::.:)...:}:...-_ expCr'l/Jl) + expCr 'l/J2)

and similarly

v, If, = 0, then Ps- = Ps+ = 2/3 in the two expressions just given. If, =j:. 0,
'l/Jo = 1, and = 'l/J2 = 0, then Ps+ = 2· expCr)/{2 . exp(rr) + I} and
Ps- = 2· expCr)/{2 . expf-r) + exp(2,)}, as in §4.4.4.
° ° The pairs in §7.2.1 with a single referent have n s = 2. For these pairs,
Ps- = Ps+ = if ms = and Ps- = Pi = 1 if ms = 2. For ns = 2, ms = 1
with just a hospital referent,

r P_ = expCr'l/Jl)
S exp( TtPl) + expCr

p+ =

expCr)

;

s expf-y) + expCr'l/Jl)

(7.4)

r; see Problem 3. In these expressions, notice that = Ps+ = 1/2 if'l/Jl = l.
In other words , if there is substantial hidden bias in the sense that , is
large, but if all of that bias is in the variable Vlsi for which cases and hospital referents are comparable, then there is no bias in pairs containing a case and a hospital referent. Similarly, with just a neighbor referent,

P_ _

expCr'l/J2)

s - expCr'l/J2) + expCr) ,

p+ =

exp(,)

s expf-r) + expCr'l/J2)

7.2.4 Example: Sensitivity Analysis for Breast Cancer and Age at First Birth
Table 7.6 gives the results of the sensitivity analysis for the study in §7.2.1 which compared cases of breast cancer to hospital and neighbor referents.

7.2 Matched Studies with Two Referent Groups 243
TABLE 7.6. Sensitivity Analysis for Significance Levels (P) for Breast Cancer and Age at First Birth.

Interpretation

r '1/;0 '1/;1 '1/;2 P

A No hidden bias

1 1 0 o 0.0001

B No reduction in bias

1.5 1 0 o 0.0197

C No reduction in bias

2 1 0 o 0.48

D Hospital referents free of bias 2 0 1 o 0.0007

E Neighbor referents free of bias 2 0 0 1 0.025

F Bias partly removed

2 1/3 1/3 1/3 0.0485

G Hospital referents free of bias 3 0 1 o 0.0113

H Neighbor referents free of bias 3 0 0 1 0.36

The sensitivity analysis considers a range of assumptions about the hidden biases affecting each of the referent groups. Among other possibilities, the table considers the situations in which both groups are affected by the same biases, the hospital referents are free of bias but the neighbors are not, or neighbors are free of bias but the hospital referents are not.
The table gives the sensitivity parameters (T', '1/;0' '1/;1' '1/;2)' where r =
exp(-y), together with the upper bound on the significance level for the Mantel-Haenszel test comparing the age at first birth for cases and referents. The lower bound on the significance level is less than 0.0001 in each situation and so is not included in the table. The parameter I' measures the total quantity of hidden bias, so in this regard, situations C through F are similar, and situations G and H are similar. The parameters
('1/;0' '1/;1' '1/;2), where 1 = '1/;0 + '1/;1 + '1/;2' indicate the degree to which hidden
bias is controlled by using referents from the same hospital or neighborhood. With ('1/;0 ,'1/;1,'1/;2) = (1,0,0), the use of hospital and neighbor referents did nothing to make the cases and referents comparable in terms of the unobserved covariate usi-this gives the sensitivity analysis discussed in Chapter 4. With ('1/;0,'1/;1,'1/;2) = (0,1 ,0) , the hospital referents are free of hidden bias, because cases and hospital referents have the same value of
Usi ' With ('1/;0,'1/;1,'1/;2) = (0,0,1), the neighbor referents are free of hidden bias. With ('1/;0,'1/;1,'1/;2) = (1/3,1/3,1/3), the bias is partially reduced in both referent groups.
Of the 409 cases of breast cancer, 209 first gave birth at age 25 or older. In the absence of hidden bias, situation A in Table 7.6, there is a single
significance level < 0.0001 from the usual Mantel-Haenszel test, indicating
increased risk of breast cancer. This comparison is insensitive to all patterns
of hidden bias of magnitude r = 1.5, situation B, but it becomes sensitive for r = 2, situation C . An unobserved covariate associated with twice the
odds of an older first birth could explain the apparently higher risk of

244 7. Multiple Referenc e Groups in Case-Referent Studies
breast cancer among such women. However, a bias of magnitude r = 2 or I' = 3 could not explain the apparently higher risk if the bias affected only
the neighbors and not the hospital referents, situations D and G. A bias
of magnitude r = 2 could not explain the increased risk if it affected only hospital referents and not neighbors, situation E, but a larger bias r = 3
with the same pattern could explain the increased risk, situation H. In short, an unobserved covariate that doubled the odds of a late first
birth could explain the observed increase in risk of breast cancer if it affected both referent groups equally. A bias of this magnitude affecting only one referent group could not explain the increased risk . In this sense, partial comparability may reduce sensitivity to hidden bias.
7.2.5 Computations Illustrated
Table 7.7 shows some of the computations leading to situation D in Table
7.6; that is, (r, 'l/Jo,'l/J l' 'l/J2) = (2,0,1,0) . This is the situation in which there is hidden bias of magnitude r = 2, but it does not affect hospital referents. Rows 1 to 4 in Table 7.7 describe the 195 = 47 + 67 + 60 + 21 matched
triples, rows 5 to 7 describe the 164 = 58+77+29 pairs with only a hospital referent , and rows 8-10 describe the 50 = 17 + 23 + 10 pairs with only a neighbor referent. Rows 1,4, 5, 7, 8, and 10 describe concordant matched
sets in which either all ns women gave birth at an age :S 24 or all gave birth
at an age ~ 25. While these sets may be included in the computations, they contribute only a constant to the test statistic and therefore do not affect the results. Row 2 describes the 67 matched triples in which two women
had first births at ages :S 24 and one had a first birth at an age ~ 25. In 32
of these matched sets, the case of breast cancer was the one woman whose first birth occurred at an age ~ 25. In these 67 matched sets, depending on the value of the unobserved covariate u, the probability that the case will have age ~ 25 at first birth could be as low as Ps- = 0.25 or as high as Ps+ = 0.40. These probabilities are based on the formula (7.3) in §7.2.3. Summing from s = 1 to s = 409 in formula (4.20) gives the deviate used to obtain the significance level in Table 7.6.
Row 6 of Table 7.7 concerns the 77 discordant matched pairs in which there is a hospital referent but no neighbor referent. Note that Ps- = PI = 1/2 in these pairs, because the hospital referents are assumed free of bias in this calculation.
7.3 *Appendix: Selection and Hidden Bias
This appendix discusses the impact of certain types of nonrandom selection of subjects for comparison. The section serves two purposes. First, it provides the basis for the assertions in §7.1.3 concerning the relationship

7.3 *Appendix: Selection and Hidden Bias 245

TABLE 7.7. Computations Illustrated.

ns I s Js ms
311 a

#Matched Sets
47

#Sets With
Case> 25
a

p- p+

s

s

0.00 0.00

311 1

67

32

0.25 0.40

31 1 2

60

52

0.60 0.75

311 3

21

·2 1 a a

58

21a 1

77

21a 2

29

2a1 a

17

2a1 1

23

2a1 2

10

21

1.00 1.00

a

0.00 0.00

53

0.50 0.50

29

1.00 1.00

a

0.00 0.00

12

0.33 0.67

10

1.00 1.00

between selection bias and hidden bias in case- referent st udies. Second,
many obse rvational studies entail several comparisons wit h subsets of the
subjects selected in various ways, and the appe ndix cons iders the relation-
ship among t hese different comparisons.
Assume t hat hidden bias is expressed by t he model (4.1), (4.2), or (4.6). Also, to test t he null hypothesis of no treatment effect, H o, assume t hat the treatment does not affect the fixed responses r .
Divide t he un its in subclass s into two mutually exclusive and exhaustive
groups, C I. and C E., based on any fixed feature of the units, so C I. U
C E· = {I, .. . ,ns } and CI.· nCE. = 0. The division may be based on the
unobserved covariate u or on an unaffected outcome y , or under H o, on the unaffected responses r themselves, or on a combination of all three,
possib ly with t he aid of a table of random numbers. Suppose that the units
in C I . are included in a comparison but t he units in C E . are excluded.
Wr ite Z for the coordinates of Z in C I.. , s = 1, . .. , S, and write Z for
the coordinates in C E ., S = 1, . .. , S , wit h a similar not at ion for ot her
quantities. For instance, write

L ms =

Z si and

iEGl.

n so ms of t he s subjects included in C I ., from st ratum s received t he treat-
n ment. Also, contains all vectors with binary coordinates of dimension
IV = nI + ... + ii; with ms ones amo ng t he ii; coord inates for stratum s.
Starting from (4. 1) or (4.2), in parallel wit h §4.2.3,

(7.5)

246 7. Multiple Reference Groups in Case-Referent Studies

The same distribution (7.5) can be obtained beginning with (4.6) instead
of beginning with (4.1) or (4.2) by conditioning on m and Z. Note that m and Z determine m . Using the definition of conditional probability applied
to (4.6) and simplifying using zTu = ZT u + zTii gives

pr (Z' -- z. Im. , Z") -_ LexepxCp!CzT!b.iIT)iI) ,

(7.6)

i>Ef'!

In other words, the distribution in (7.5) and (7.6) arises either by starting with (4.2) and ignoring the excluded units, or by starting with (4.6) and "set ting aside" the excluded units by conditioning on their treatment
assignments, Z, so they no longer enter the permutation distribution.
The models in (7.5) and (4.6) have the same form and the same value of the parameter T' but selection of subjects changes u to u . If there is no hidden bias to start with, that is, if T = 0, then there is no hidden
n,bias after selection, and the treatments Z are uniformly distributed on so the methods in Chapter 3 may be used . If there is hidden bias to
start with, that is, if T '" 0, then after selection the methods in Chapter 4 may be used to appraise sensitivity to bias. However, as selection changes u to u, the quantity and pattern of hidden bias may be different after selection. For instance, if only siblings of cases are used as referents, and if the unobserved covariate describes childhood diet , then iI may be more nearly constant within matched sets than u is.
The situation is entirely different if subjects are selected based on a
quantity affected by the treatment, say Y = yz . This may distort the distribution of treatments or exposures Z, so model (7.5) does not hold and the methods of Chapter 4 cannot be used . Even if there is no hidden
n, bias in the sense that T = 0, after selection based on Yz , the distribution
of Z will not generally be uniform on so there will be selection bias in
testing Ho though there is no hidden bias.

7.4 *Appendix: Derivation of Bounds for
Sensitivity Analysis
:s This appendix derives the bounds Ps- Ps :S Ps+ on P s = prob(Zsl = 11m)
in §7.2.3 assuming partial comparability expressed by (7.1) and (7.2) and T ~ 0. The process is slightly different from that in Chapter 4 because
the Vksi are subject to the constraint (7.2) . Write ( si = expC!usi) = exp{r('lfJoVosi + 'lfJIVI si + 'lfJ2V2s i )}. Recall the notation in Table 7.5. Write
,(s,1..+2' . . . , (s, n.,] 'V i,

7.4 *Appendix: Derivation of Bounds for Sensitivity Analysis 247
for the n s - 1 dimensional vector describing the n s - 1 referents in matched set s. To calculate prob(Zsl = 11m), take term s in the product in (4.6), and sum over all z , E O s such that Zsl = 1, which is a sum over (;:,:-=,~) terms. Then

where 9m(a) = SYMm{a}jSYMm- 1{a} and 9m(a) is defined for vectors a with strictly positive coordinates.
In obtaining bounds on prob(Zsl = 11m) in (7.7), the following fact about ratios of symmetric functions is useful. See Mitrinovic (1970, §2.15.3, Theorem 1, p. 102) for a proof of the first part of Lemma 25.

Lemma 25 The ratio 9m(a) is monoione-increasinq in each coordinate of
a. Hence, prob(Zsl = 11m) is increasing in CsI and decreasing in (si for
i ;:: 2.

Because of the constraints (7.2), the (si are linked and cannot be changed arbitrarily. In particular, changing either VIsI or V2 s1 affects several (si ' As a result, the monotonicity in Lemma 25 is not sufficient to determine the bounds Ps- :::; Ps :::; PI· As will be seen in the proof of Proposition 27 below , Lemma 26 is needed to determine the extreme values of VIsI or
V2 sl'
Define f(o: , ,B) as the n s - 1 dimensional vector

f(o: , ,B) = ~ ~.

Is

s.

Lemma 26 The function

Vo:,B

Vo:,B + gm{f(o:,,B)}

(7.8)

is monotone-increasing in 0: and in ,B for 0: > 0, ,B > 0, for every fixed v> 0.

Proof. It will be shown that (7.8) is monotone-increasing in 0:, the proof
for ,B being similar. Proving that (7.8) is monotone-increasing in 0: is the
same as proving that 9m{f( 0:,,B)} j 0: is monotone-decreasing in 0:. Using the definition of SYM m, it follows that if () > 0, then 9m(()a) = ()gm(a). Let 0::::; 0:* so the task is to show 9m{f(0:,,B)}jo: ~ gm{f(o:*, ,B)}jo:* . Let
o= 0:* j 0: ;:: 1. Then, as required,

9m{f(0:,,B)}

()gm{f(o:, ,B)}

=

9m{f(()0:,(),B)}
"--..::........;-,-----~

()o:

()o:

>

9m{f(()0:, ,B)} ()o:

9m{f(0:*, ,B)} 0:*

248 7. Multipl e Reference Gro up s in Case-Refere nt St udies where th e inequality follows from th e mon otonicity of 9m(a). ·
Proposition 27 Under partial com pambility expressed by ( 7.1) and (7.2),

<

exph')

- expl-r) + 9m[f{exp h''lbl), exph''lb2)}] ·

Proof. Under th e const ra int (7.2) ,

(7.9)

exp{-'y('lbl Vlsl + 'lb2V2s1)} < ( sl ::;exp{-'y('lbO+ 'lb lvlsl + 'lb2v2sd}

exph''lblvlsd < ( si::; exp{-'y('lbo + 'lb l Vls l + 'lb2)}

for i = 2, . . . . L; + 1,

(7.10)

exph''lb2v2sd < ( si ::; exp{-'y('lbo + 'lbl + 'lb2v2sd } for i = Is + 2, . . . , ns.

Using Lemma 25, prob (Zsl = 11m) is increased by rai sing C l to its upper bound and reducing ( si for i ~ 2 to its lower bound in (7.10). If C l is at its upp er bound and ( si for i ~ 2 is at its lower bound in (7.10), then

Vo.{3
prob(Zsl = 11m) = vo.{3 + 9m{f(o., (3)}

(7.11)

with v = exph''lbo ), a. = exp h''lb l vl sd , and (3 = exp h''lb2v2s1) ; henc e, using Lemma 26, (7.11) is maximized when VIs1 = V2 s1 = 1, giving the
v, upp er bound in (7.9) upon using 1 = 'lbo + + 'lb2. If C l is at its lower
bound and C i for i ~ 2 is at its upper bound in (7.10), then (7.11) holds
with v = exp{- )'( 2'lbo + 'lb1 + 'lb2)} , a. = exp{-'y('lbo + 'lb lVls l + 'lb2)} ' and
{3 = exp{-'y ('lbO+ 'lb l +'lb2v2sd }, so the minimum valu e of (7.11) occurs with
Vlsl = V2s1 = o. ·

7.5 Bibliographic Notes
There are two books about case-referent studies by Breslow and Day (1980) and Schlesselman (1982) and, in addit ion, most epidemiology t exts discuss case-referent st udies and selection bias in detail; see Kelsey, Thompson, and Evans (1986) , Kleinbaum, Kupper , and Morgenstern (1982) , Lilienfeld and Lilienfeld (1980), MacMahon and Pugh (1970), Miettinen (1985a) , Rothman (1986), Rothman and Greenland (1998), and also the art icles by Cornfield (1951), Holland and Rubin (1988), Mantel (1973) , Mantel and Haenszel (1959), and Prenti ce and Breslow (1978) . Gastwirth (1988) discusses the st udies of Reye's syndrome. The use of mor e than one reference

7.6 P roblems 249
group is briefly discussed in most text s and is discussed in greater detail by Cole (1979), Fairweather (1987), Kelsey, Thomp son, and Evans (1986, pp . 160-163) , Liang and St ewart (1987), and Rosenbaum (1987). The technical material in §7.2 through §7.4 is largely based on Rosenb aum (1991).
7.6 Problems
1. A subject's knowledge of the investigator's hypothesis. Weiss (1994) discusses whether it is appropriate to exclude from a case referent study those subjects who were aware of the st udy 's hyp othesis. He writ es:
It is likely that for many persons who develop an illness, knowledge of a hyp othesis concerning its etiolo gy is obtained after the diagnosis .. . . In some instances, knowledge of the hypothesis could occur mor e commonly among exposed than nonexposed cases: inquiries by medical personnel into th e history of exposure to a possible etiologic factor may be of relativ ely greater salience to exposed persons . . . .
[ . . . excluding knowled geable subject s] will creat e bias if the acquisit ion of knowl edge of the etiologic hypothesis by cases is related to their exp osure stat us.
Express Weiss 's correct argument in the terminology of §7.1.3, that is, in t erms of an affect ed out come Y = yz used in selecting subjects .
2. Bad tequila in Acapulco. In 1985, the Journal of Chronic Diseases published an exchange led by OBi Miettinen (1985b) with dissent a nd discussion by J ames Schlesselman, Alvan Feinst ein, and Olav Axel son . Miettinen writes:
As an illustration, consider the hypothetical example of t esting the hypothesis that a caus e of traveller's diarrhea is the consumption of t equila (a Mexican drink) , with cases derived from a hospital in Acapulco , Mexico, over a defined p eriod of time. What might be the proper [referent] group?
Answer Miettinen's question. What is the treatment? What is the outcome? What is 1I'U]? Consider the binary variable indic ating whether a subject was in Acapulco during the defined period of time. Is this binary variable a covariate? How would 1I'1j] vary with thi s binary variable? What would be the consequence of matching on this variable? Would this automatically preclude certain referent groups? Read the published discussion a nd compare your answer to the answers given th ere.
3. A derivation. Obtain (7.4) from (7.3) using the observation that 'l/J1 = 1 - 'l/Jo - 'l/J2 from (7.1).

250 7. Multiple Reference Groups in Case-Referent Studies
7.7 References
Breslow, N. and Day, N. (1980) The Analysis of Case-Control Studies. Volume 1 of Statistical Methods in Cancer Research. Lyon, France: International Agency for Research on Cancer of the World Health Organization.
Cole, P. (1979) The evolving case-control study. Journal of Chronic Diseases, 32, 15-27.
Collaborative Group for the Study of Stroke in Young Women (1973) Oral contraception and increased risk of cerebral ischemia or thrombosis. New England Journal of Medicine, 288, 871-878.
Cornfield, J . (1951) A method of estimating comparative rates from clinical data: Applications to cancer of the lung, breast and cervix. Journal of the National Cancer Institute, 11, 1269-1275.
Fairweather, W. (1987) Comparing proportion exposed in case-control studies using several control groups. American Journal of Epidemiology, 126, 170-178 .
Gastwirth, J. (1988) Statistical Reasoning in Law and Public Policy. New York: Academic .
Gutensohn, N., Li, F., Johnson, R ., and Cole, P. (1975) Hodgkin's disease, tonsillectomy and family size. New England Journal of Medicine , 292, 22-25.
Halsey, N., Modlin, J ., Jabbour, J ., Dubey, L., Eddins, D., and Ludwig, D. (1980) Risk factors in subacute sclerosing panencephalitis: A casecontrol study. American Journal of Epidemiology, 111, 415-424.
Herbst, A., Ulfelder, H., and Poskanzer, D. (1971) Adenocarcinoma of the vagina : Association of maternal stilbestrol therapy with tumor appearance in young women. New England Journal of Medicine, 284, 878-881.
Holland, P. and Rubin, D. (1988) Causal inference in retrospective studies. Evaluation Review, 12, 203-231.
Hurwitz, E. (1989) Reye's syndrome. Epidemiologic Reviews, 11, 249-253.
Hurwitz, E. S., Barrett, M. J ., Bregman, D., Gunn, W . J., Pinsky, P., Schonberger, L. B., Drage, J. S., Kaslow, R. A., Burlington, D. B., and Quirman, G. V. (1985) Public health service study on Reye's syndrome and medications. New England Journal of Medicine, 313, 14, 849-857.

7.7 References 251
Kelsey, J. , Thompson , W. , and Evans, A. (1986) Methods in Observational Epidem iology. New York: Oxford University Pr ess.
Kleinb aum, D., Kupper , L., and Morgenst ern, H. (1982) Epidemiologic Research. Belmont , CA: Wadsworth.
Kr eiger , N., Kelsey, J ., Holford, T ., and O'Connor , T. (1982) An epidemiologic st udy of hip fracture in postmenopausal women. American Jo urn al of Epidem iology, 116, 141-148.
Liang, K. and Stewart, W . (1987) Polychotomous logistic regression met hod s for matched case-cont rol st udies with multiple case or control groups. American Journal of Epidemiology, 125, 720-730 .
Lilienfeld , A., Ch an g, L., Thomas, D., and Levin, M. (1976) Rauwolfia derivatives and br east cancer. Johns Hopkins Medical Journal, 139, 4 1 -50 .
Lilienfeld , A. and Lilienfeld , D. (1980) Foundat ions of Epidemiology (second edit ion). New York : Oxford University Press.
MacMahon, B. and Pugh , T. (1970) Epidemiology: Principles and Methods. Boston: Little, Brown .
Mantel, N. (1973) Synthet ic retrospecti ve st udies and relat ed topics. Biom etri cs, 29 , 479- 486.
Ma ntel, N. and Haenszel, W . (1959) Statistical aspects of retrosp ective studies of disease. Journ al of the Nat ional Cancer Institute, 22 , 719748.
Miet t inen, O. (1985a) Th eoretical Epidemiology. New York : Wiley.
Miet ti nen, O. (1985b) The "case-cont rol" st udy: Valid selection of subjects (wit h discussion ) Journ al of Chronic Diseases, 38, 543-548.
Mitrinovic, D. S. (1970) Analytic Inequalities. Berlin : Springer-Verlag.
Prenti ce, R. and Br eslow, N. (1978) Retrospective st udies and failur e time mod els. Biometrika , 65 , 153-158.
Rosenbaum , P. R. (1987) The role of a second control group in an observational study (with Discussion). Statistical Science, 2, 292-316.
Rosenb aum, P . R. (1991) Sensit ivity analysis for mat ched case-cont rol st udies . Biom etrics, 47, 87-100.
Rothman, K. (1986) Modern Epidemiology. Bost on: Little, Brown.
Rothman , K. and Gr eenl and, S. (1998) Modern Epidemiology. Philadelph ia: Lippi ncot t-Raven.

252 7. Multiple Reference Groups in Case-Referent Studies
Schlesselman, J. (1982) Case-Control Studies. New York: Oxford University Press.
Weiss, N. (1994) Should we consider a subject's knowledge of the etiologic hypothesis in the analysis of case-control studies? American Journal of Epidemiology, 139, 247-249.

8
Multiple Control Groups
8.1 The Role of a Second Control Group
8.1.1 Observational Studies with More than One Control Group
An observat ional study has multiple cont rol group s if it has severa l dist inct groups of subjects who did not receive the treatm ent. In a ra ndomized expe rime nt, every cont rol is denied the treatment for t he sa me reason , namely, the toss of a coin. In an observa tional st udy, ther e may be several distinct ways that the treatment is denied to a subject . If these several cont rol groups have outcomes that differ subst antially a nd significantly, then this cannot reflect an effect of the treatment, since no control subject received the treatment. It must reflect , instead, some form of bias .
Multiple control groups arise in several ways. In some contexts, a subject may become a cont rol eit her because the treatment was not offered or because, though offered, it was declined . Some years ago, the Educational Testing Service sou ght to evaluate the impact of the College Board's Advanced Placement (AP) Program which offers high-school st udent s the opportunity to earn college credit for advanced courses t aken in high school. In such a st udy, a student may become a control in either of two ways: the st udent may decline to participate in the AP Program , or the student may at te nd a school that do es not offer the AP Program. What hidd en biases might be pr esent with these two sour ces of controls? Schools offering the AP Program may have great er resources or have more college-bound stu-

254 8. Multiple Cont rol Groups
dents than other schools, and these charact erist ics are often found in school districts with higher family incom es. Possibly, students in school s offering the AP Program would have better out comes even if the AP Program itself had no effect. On the other hand, if the AP Program is available in a school , students who decline to participate may be less motivated for academic work than tho se who do participate. Here, too, if the AP Program had no effect, greater motivation among AP participants might possibly lead to better outcomes. The use of both control groups provides little pr ot ection in thi s st udy becau se t he most plausibl e hidden biases lead to patterns of responses that resembl e treatment effects. In the end , a singl e control group was used , namely, matched students in the same school who declined to participat e.
A related but different sit ua t ion arises with compensatory programs, that is, programs such as Head Start that ar e int ended to assist disadvantaged st udent s. Campbell and Boruch (1975) discuss biases that may affect studies of compensatory programs. As with the AP Program, if a compensatory program is offered , students who decline to participate might be less motivated. In contrast with the AP Program, admission to a compensatory program often dep end s on need , the program being offered to students with the greatest need. Aft er matching or adjustment for observed covariates, such as test scores and grades prior to admission into the program, if the comp ensatory pro gram had no effect, one might expect t hat program participants, being better motivated, would outperform st udents who decline to participate, but would not perform as well as st udent s who were not offered the program because of less need.
Generally, the goal is to select control groups so that, in the observed data, an actual treatment effect would have an appearance that differed from the most plausible hidden bias. Arguably, this is true in the case of the compensatory program but not in the case of the AP Program.
Multiple control groups also a rise when controls are selecte d from several exist ing groups of subjects who did not receive the treatment. Seltser and Sartwell (1965) st udied the possibility that X-ray exposure was causing deaths among radiologists. They compare d members of the Radiological Society of North America, a professional association of radiologists, to four other specialty societies. In two of these four societ ies, the American Academy of Ophthalmology and Otolaryngology and the American Association of Pathologists and Bacteriologists, most society members would normally use X-rays vastly less often than radiologists do . For the period 1945 to 1954, Seltser and Sartwell (1965, Table 7) calculated age-adjusted mortality rates per 1000 person-years of 16.4 for the radiologists, 12.5 for the pathologists and bacteriologist s, and 11.9 for the ophthalmologists and otolaryngologists. In other words , in these two control groups the mortality rates are similar, as they should be in the ab sence of hidden bias. Both groups had substantially lower mortality than among the radiologists, consistent with a possible effect of radiation exposure.

8.1 Th e Role of a Second Con trol Group 255

TABLE 8.1. Road Workers Compar ed to Two Control Groups, Office and Quarry

Work ers .

Renal Fun ction Road Office Quarry

Abnormal

24

4

2

Normal

68 39

36

Total

92

43

38

Multiple control groups are sometimes formed from several groups th at received different treatments that were believed to be the same in ways th at matter for the outcome under study. When formed in this way, differences among the control groups may reflect eit her hidd en bias or unanticipated differences in the effects of the control treatments. The problems in §8.5 discuss the possibility that contraception using the intrauterin e device causes ectopic pregn ancy. There ar e five comparison groups defined by other forms of contraception.
If subjects who receive negligible doses of a treatment are distinguished from those who actively avoid or abstain from the treatment, then two control groups are produced. In §8.l. 4, an example is discussed that distinguishes abstention from alcohol and ext remely low consumption of alcohol.
As noted in Chapter 7, a case-referent study may have one or more referent groups and one or more control groups. A referent is not a case. A control did not receive the treatment. A case-referent study of alcohol consumption might have two referent group s, say neighbors and siblings of cases , and two control groups, say abstainers and those who are not abstainers but who report virtually no alcohol consumption. Such a design would offer sever al opportunities to look for select ion and hidden biases.

8.1.2 An Example: Occupational Exposure to Hydrocarbons and Kidney Disease
To investigate whether occupational exposures to hydrocarbons cause renal disorders, Douglas and Carney (1998) compared 92 road workers exposed to asphalt or bitumen fumes to two control groups, namely, "38 hard rock quarry workers not occupationally exposed to hydrocarbons, and 43 office workers also not exposed to hydrocarbons." They identified renal function abnormalities using blood and urine tests, with results given in Table 8.l. In fact, 3 of the 24 road workers with abnormal kidney function had multiple abnormalities, whereas none of the controls had multiple abnormalities.
Using Fisher's exa ct test for a 2 x 2 table without hidden bias , the slightly higher rate of renal abnormalities among office workers when compared to quarry workers is not significant in either a one-sided (P = .40) or two-sided
(P = 2 x .40 = .80) test, so the control groups do not differ significantly.
However, the rate of renal abnormalities is significantly higher among road workers than among office workers (P = 0.018) and higher than among

256 8. Multiple Control Groups

TABLE 8.2. Cytogenetic Damage in Pb-Zn Miners and Two Control Groups.

Miners Housewives Distant

SCE 2: 9

22

0

0

SCE < 9

95

57

61

Total

117

57

61

quarry workers (P = 0.004) in one-sided tests, and of course it is also
higher than the combined control group (P = .0009).
The comparison of road workers with the combined control group is in-
sensitive to a bias of r = 1.8 with upper bound on the significance level of P = .044, but becomes sensitive at r = 2 with upper bound P = .072.
These exact calculations use the extended hypergeometric distribution, as
in §4.4.1, Corollary 15.

8.1.3 An Example: Cytogenetic Damage in Miners
Miners are often exposed to a variety of potentially hazardous substances, including radon gas. Marjan Bilban (1998), a researcher in Slovenia, compared cytogenetic damage of male miners at a lead and zinc mine to two control groups. Because virtually all males in the vicinity of the mine had worked with lead or zinc in some capacity, one control group consisted of housewives from the vicinity of the mine who had no occupational exposure to the mine or its products. The other control group, 86% male, came from the general population farther from the mine; it is labeled "distant controls." So the first control group lived in the same vicinity as the miners, but differed in gender, while the second control group was more similar in terms of gender, but lived elsewhere.
Several measures of cytogenetic damage were obtained from blood lymphocytes, including the average number of sister chromatid exchanges (SCE) . The frequencies of SCE of 9 or more are given in Table 8.2. Notice that
SCE 2: 9 was not uncommon among miners, but was never seen in either
control group. Fisher's exact test for a 2 x 2 table will be used to compare the miners to each control group and to the combined control group with 118 subjects. The sensitivity analysis is given Table 8.3, which reports upper bounds on the one-sided significance levels from Fisher's exact test, obtained using the extended hypergeometric distribution, as discussed in §4.4.1, Corollary 15. Comparing the miners to the combined group, the
upper bounds on the significance levels for r = 6 and 7 are, respectively,
0.045 and 0.068. Neither control group is ideal. Although one would not anticipate a
strong relationship between gender and SCE, some differences are certainly possible. Environmental hazards vary from place to place, and the distant controls may have been exposed to a different pattern of environmental hazards besides lead and zinc from the mine. Nonetheless, similar results

8.1 The Role of a Second Control Group 257

TABLE 8.3. Sensitivity Analysis for Significance Levels Comparing Pb-Zn Miners

to Controls.

r Housewives Distant Combined

1 .00059

.00039 .0000025

2 .014

.011

.00041

3 .051

.042

.0036

TABLE 8.4. Alcohol and Mortality.

Group Dead Alive

Control groups {Abstain 7

6

None

27 71

Treated groups { Lowest 14 38 Middle 13 20

Highest 21 20

were obtained for local housewives and distant controls, and the comparison is insensitive to small and moderate biases. To explain the higher level of SCE among miners as a bias, one would need to postulate substantial biases affecting both control groups in a similar manner.
8.1.4 An Example: Are Small Doses of Alcohol Beneficial?
Petersson, Trell , and Kristenson (1982) reviewed six studies suggesting that moderate consumption of alcohol may have beneficial effects in preventing some cardiac disease, and then they conducted a similar study with the additional feature that there were two control or "no alcohol" groups. Alcohol use was graded based on the response to ten questions. Nine of the questions described situations and asked about drinking in relation to those situations. One question asked about alcohol abstention. One control group consisted of men who described themselves as abstaining from all consumption of alcohol. The other control group consisted of men who did not say they abstained from alcohol, but who answered "no" to all nine questions about drinking behavior.
Between 1974 and 1979, the study obtained questionnaire responses from 7725 male residents of Malmo, Sweden. By 1980, there had been 127 deaths among these 7725 men. Each death was matched with two referents who were alive in 1980, the referents being matched to the death based on age and date of entry into the study. In principle, the analysis should make use of the matching, but this is not possible from the published data, so for this example, the matching is ignored . This study is, almost, a synthetic case-referent study in the sense of §3.3.2; see also §7.1.3. Petersson, Trell, and Kristenson (1982)'s data are given in Table 8.4. (In this table, their 0

258 8. Multiple Control Groups

TABLE 8.5. Odds Ratios for Alcohol and Mortality.

Abstain None Low Middle

None

0.33

Low

0.32 0.9i

Middle 0.56 1.71 1.76

High

0.90 2.76 2.85 1.62

TABLE 8.6. Chi-Squares for Alcohol and Mortality.

Abstain None Low Middle

None

2.6

Low

2.3

0.0

Middle 0.31 1.1 0.9

High

0.02 6.1 4.8 0.6

is called "None," their 1 is called "Lowest ," their 2 is called "Middle" and their ~ 3 is called "Highest ." )
Table 8.5 contains odds ratios comparing the groups in Table 8.4. In this table, the odds for the row are divided by the odds for the column, so for None/Abstain the odds ratio is (27/71)/(7/6) = 0.33. Table 8.6 gives the chi-square statistics for a 2 x 2 table, with the continuity correction; they have one degree of freedom and are significant at 0.05 or 0.025 if greater than 3.84 or 5.02, respectively. For instance, 2.60 is the chi-square for the 2 x 2 table Abstain/None x Dead/Alive.
When High alcohol consumption is compared to None or Low, the odds ratios are ab ove two and significant at 0.05, consistent with greater mortality among those who consume larger quantities of alcohol. However, the High group does not differ significantly from the Abstain group, and the odds ratio is actually slightly less than one. In fact, the odds ratios suggest the greatest mortality is found among abstainers, though the differences are not quite statistically significant. In particular, comparing the two control groups, the odds of death are slightly more than three times greater in the Abstain group than in the None group, though again this difference is not significant at 0.05. Notice that there are only 13 men in the Abstain group.
Of the abstainers, Petersson, Trell , and Kristenson write: "Most of these men, however, had chronic disease as the reason for their abstention, or even a past history of alcoholism. Increased mortality in nondrinkers may create a false impression of a preventive effect of any versu s no daily drinking in relation to general and cardiovascular health." In other words, though earlier studies had claimed a beneficial effect of moderate alcohol consumption, Petersson, Trell, and Kristenson are raising doubts about whether that is

8.1 The Role of a Second Control Group 259
an actual effect of alcohol, because moderate consumption appears better than abstention but no better and perhaps worse than negligible doses.
8.1.5 An Example: Availability and Refusal of Treatment ; Addressing Self Selection
A treatment may be available to some people and not to others, and may be refused by some people when available. For inst ance , many treatments are available in some places or organizations-cities, states, corporations, health plans-and not in other, ostensibly similar, places or organizations. In many contexts, people have the right to refuse treatment, and they often do. Several problems are evident. First, different places or organizations may actually be different in ways we neither anticipate nor measure, and this may create a hidden bias. Second, individuals who refuse treatment may differ from those who accept it, and this may create a hidden bias. Moreover, because one does not refuse a treatment that is not offered, the people from the place where the treatment is not available do not divide themselves into those who accept and those who reject treatment; the self select ion operates in one place, not in the other.
If people were randomly assigned to place s or organizations, th e sit uation would resemble the randomized design proposed by Zelen (1979). In that design, patients are divided at random into two groups, and the experimental treatment is offered to patients in the first group, some of whom refuse it . Zelen (1979) proposed comparing the two random groups, keeping the randomization intact by looking not at the effect of the treatment, but rather at the effect of the offer of the treatment. An alternative analysis that also keeps the randomization intact is the instrumental variable analysis in §5.4. If one believed the assignment to place or organization was free of hidden bias, and if one believed the exclusion restriction, then similar analyses, but with adjustments for observed covariates, might be performed in an observational study.
In observational studies, there is random assignment neither in the assignment to places or organizations nor in the decision to accept or refuse treatment. If the only reason outcomes differ in the three groups is the actual effect of the treatment, then the treated group is expected to differ from the two comparison groups which are expected not to differ from each other. If the only reason the three groups differ is a bias introduced by the decision to accept or refuse treatment, then the people from the second place should "fall between" - t hat is, be a statistical mixture of-the treated subjects and those who refused treatment. If the only reason the three groups differ is that people from the second place are not comparable to the others, then one expects them to differ from the other two groups that are expected not to differ from each other. Obviously, th e situation could be more complicated, with groups differing for mor e than one rea-

260 8. Multiple Control Groups

TABLE 8.7. Cognitive Therapy for Early Psychosis. COPE Refused Unavailable

Before Treatment SANS 17.3

17.7

20.8

After Treatment SANS

12.9

16.6

23.1

Before Treatment BDI

8.5

5.2

5.4

After Treatment BDI

7.5

2.7

4.2

son. Because these three simple explanations predict different patterns of outcomes, one analysis-perhaps one of several-will compare the groups to see how they differ.
An example occurs in a study by Jackson, McGorry, Edwards, et al. (1998) of cognitive therapy (COPE) given to 40 patients for early psychosis. Their program was available only in Victoria, Australia, so one comparison group (Unavailable) consisted of 14 ostensibly similar patients from other areas . The other comparison group (Refused) consisted of 20 patients who refused the program of cognitive therapy. For two outcomes, the Scale for the Assessment of Negative Symptoms (SANS) and the Beck Depression Inventory (BDI) , before and after treatment, the means for their data are displayed in Table 8.7. For both outcomes, lower scores signify less severe symptoms. Before treatment, the differences among the groups were not significant at the 0.05 level. After treatment, the COPE group was significantly better on SANS than the Unavailable group. After treatment, the COPE group was significantly worse on the BDI than the Refused group. The published data do not permit a more detailed analysis, and the sample sizes are small, so the means are unstable and the absence of significance has limited meaning . In particular, one is hesitant to make much of the interesting pattern in which the Refused group had better final outcomes than the Unavailable group. In larger samples, the design used by Jackson et al. (1998) would have provided more insight into possible biases than a study with either comparison group alone .

8.1.6 An Example: What Does It Mean to Not Receive Treatment?
Zabin, Hirsch , and Emerson (1989) studied the effects of having an abortion on the education, psychological status, and subsequent pregnancies of black teenage women in Baltimore. So the treatment is having an abortion, but what is the control? A woman will have an abortion only if she is pregnant and does not want the child; without the abortion but with good health, she will have a child. So one might compare a teen having an abortion to a teen having a child. Of course, one teen has a child and the other does not . Is this the correct comparison? Perhaps abortions do great psychological damage, but not as much damage as being the teenage mother of an unwanted child. Moreover, it is sometimes asserted, correctly or oth-

8.1 Th e Role of a Second Control Group 261
erwise, that if abortions were illegal , young women would be more careful about avoiding unwanted pregnancies. If one believed both that making abortions illegal prevented abortions, and also that removing abortion as a legal option prevented most unwanted pregnancies, then one might think it is more appropriate to compare a teen who had an abortion to a teen who was not pregnant. Perhaps th ere is a little merit in each of these two arguments. From a scientific perspective, however, the preference is clear: A scientist would like to know about all three teens , the one who had an abortion, the one who had a child, and the one who was not pregnant.
Notice that powerful self selection effect s ar e at work, and hidden bias es are likely. The decision by a young pregnant woman to have an abortion or have a child may reflect many characteristics that are incompletely measured, such as the degree to which she is determined to complete high school. Sexually active teenagers who do not use adequate birth control may tend to differ in many ways from those who do not become pregnant.
Zabin, Hirsch, and Emerson (1989) derived two control groups from 360 young black women who came for pregnancy tests at two clinics in Baltimore. The "t reate d" group consisted of women who were pregnant and had an abortion. Women who were pregnant and had a child formed the first control group. Women whose pregnancy test revealed they were not pregnant form ed the second control group. Because the second control group consisted of women who suspected they might be pregnant, it is likely to be less biased than a control group of women who simply were not pregnant. The second control group did not have to decide whether to have an abortion or a child, so it is not subject to the self selection effect that formed the treated group and the first control group. The purposeful decision to have an abortion or a child creates a self selection effect. If that selection effect were the only force producing differences among the three groups, then the negative pregnancy test group, being a mixture unaffected by the selection, should be found "between" the treated group and the first control group. If the only force producing differences among the groups were the psychological effects of having an abortion, then the two control groups should have similar outcomes. If the only force producing differences among the groups is the presence of the newborn child, then the abortion and negative pregnancy test groups should have similar outcomes. Three very simple theories should produce three recognizably different outcomes. Obviously, several forces may be at work simultaneously to produce other patterns of outcomes.
Zabin, Hirsch, and Emerson studied many outcomes with varied results. As one illustration, consider "negat ive educational change" two years after the pregnancy test. In the abortion group, 17.8% had a negative educational change, whereas in the child-bearing group it was 37.3% and in the negative pregnancy test group it was 37.4%. Despite the ambiguities in this study, it would be hard to argue that this pattern of results supports a claim that abortions cause negative educational change at two years.

262 8. Multiple Control Groups
The two control groups together provide more information about hidden biases than either group provides alone, in part because the control groups systematically vary certain important unobserved differences.
8.1.7 An Example: Using a Second Control Group as Partial Replication of an Unanticipated Finding
A second control group is sometimes the basis for internal replication of part of a study. One might do this, for example, if treated subjects are hard to find, but potential controls are plentiful and inexpensive. A second control group, not used in the initial stages of data analysis, provides a few of the many benefits of a replication, including an increase in sample size, and some data that are unaffected by what was learned from initial analyses using the first control group.
For instance, Kim, McConnell, and Greenwood (1977) used a second control group in this way. They were interested in the effects of a particular financial maneuver-the formation of a captive finance subsidiary-on the value of a company's bonds. This maneuver ". .. creates a new class of security holders with claims that are superior to those of the old bondholders," (p. 797), so it might be expected to depress the value of the bonds. Kim, McConnell, and Greenwood confined attention to firms with longterm debt whose stock traded on the New York Stock Exchange (NYSE). Twenty-four such firms formed a captive finance subsidiary between 1940 and 1971, so treated firms are in extremely limited supply. Each of these firms might have one or several actively traded bonds. Each bond of each treated firm was matched to a control bond of another NYSE firm on the basis of Moody 's bond rating, term-to-maturity, coupon interest rate, and coupon interest payment dates. Many control bonds were available. They found a substantial decline in value of the bonds of treated firms when compared to control bonds, a decline that began about seven months before the formation of the subsidiary and that ended about two months after, because (pp. 804-805): "Apparently, information about the impending formation of the finance subsidiary began to reach the market (and stockholders and bondholders began to react to the information) about seven months prior to the actual incorporation."
One might worry, of course, that while a decline in bond values was anticipated, the specific timing of the decline was not. Many different patterns of changes in bond values might, after the fact, be explained as consistent with the theory that the formation of the subsidiary caused a substantial decline in bond values. For instance, if the decline had taken place entirely after the formation of the subsidiary, then this too would have seemed consistent with the theory. A theory that is consistent with many different patterns of data is only weakly corroborated when one of those patterns is seen; however, if that one pattern reappeared upon replication,

8.2 Selecting Control Groups: Systematic Variation and Bracketing 263
then the corroboration would be much stronger. A replication with entirely new data was not feasible since no additional treated firms were available. Unable to replicate the treated group, but in an effort to address the issue as well as the available data would allow, Kim, McConnell, and Greenwood (1977) formed a second control group of matched bonds, finding that "the two control groups yielded approximately equal monthly returns over the period .. .."
In a sense, the second control group addresses half the problem . To be fully convincing, one would want to independently replicate a pattern first suggested by the comparison of the treated group and the first control group. The second control group provides the opportunity to independently replicate half of the pattern, but provides no replication of the pattern in the treated group. In short, when treated units are extremely scarce, a second control group may provide an incomplete replication of patterns suggested by the data.
8.2 Selecting Control Groups: Systematic Variation and Bracketing
The goal in selecting control groups is to distinguish treatment effects from the most plausible systematic biases. If this is to be done successfully, the pattern of outcomes anticipated if the treatment has an effect must differ from the pattern anticipated from a hidden bias. The principles of "systematic variation" and "bracketing" are intended to ensure that this is so.
In a thoughtful discussion of control groups in behavioral research, Campbell (1969) quotes Bitterman's (1965) discussion of control by systematic variation. Bitterman's work is in a challenging field, comparative psychology, which seeks to "st udy the role of the brain in learning [by comparing] the learning of animals with different brains" [Bitterman (1965, p. 396)]. Bitterman (1965, pp. 399-400) writes:
Another possibility to be considered is that the difference between the fish and rat which is reflected in these curves is not a difference in learning at all, but a difference in some confounded variable-sensory, motor, or motivational. Who can say, for example, whether the sensory and motor demands made upon the two animals in these experiments were exactly the same? Who can say whether the fish were just as hungry as the rats? . ..
I do not, of course, know how to arrange a set of conditions for the fish which will make sensory and motor demands exactly equal to those which are made upon the rat in some given ex-

264 8. Multiple Control Groups
perimental sit ua t ion. Nor do I know how to equate dri ve level or reward value in the two animals. Fortunately, however , meaningful comparisons are st ill possible , because for control by equation we may subst itute what I call control by system atic variation. Consider, for exa mple, the hypothesis that the difference between the curves . . . is due to a difference, not in learning, but in degree of hunger. The hypothesis implies t hat there is a level of hunger at which t he fish will show progressive improvem ent , and, put in this way, the hyp othesis becom es easy t o test . If, despite the widest possible variation in hunger , progressive improvement fails to appear in the fish , we may reject the hunger hypothesis.
In the terminology of this book, Bitterman's "cont rol by equat ion" is ana logous to controlling confounding due to an observed covariate x by matching subjects with the same or similar values of x as in Chapters 3 and 10; then differences in outcomes ca nnot be due to differ ences in x. "Cont rol by syste mat ic variation" concerns a variable u which is not recorded. If, however , two control groups can be formed so that u is much higher in one group than in the other , and if the groups do not differ materially in their outcomes, then this is consistent with the claim that differ en ces in u are not responsible for differences in outcomes obser ved be tween treated and control groups. The principle of sys temat ic vari ation leads to the following advice. When designing an observational study, identify the most plausible hidden biases and find control groups that sharply var y their levels.
For instance, if one were concern ed that physical exercise might be relat ed to kidney abnormalities, t he n in the st udy by Douglas and Carney (1998), the use of both quarry a nd office workers as cont rols is likely to systemat ically vary the amount of physical exercise that occurs on the job. P resumably, quarry workers are closer to t hf' t reated group, the road wor kers, in that both jobs ent ail physical exercise. Since the road worker s had more kidney abnormaliti es than bo th cont rol groups, with quarry workers having the fewest abnorm alities, differ ences in exercise on the job are not a plausible explanation of the pattern of kidney abnormalit ies.
A st ep beyond systematic variation of u is "bracket ing," as discussed by Campbell (1969). Bracketing seeks two control groups such that , in the first group, u tends to be higher than in the treated group and, in the second, u tends to be lower than in the treated group. The goal is two control groups that are farther ap art from each other in t erms of u than they are from the treated group. Possibly this is true of the example in §7.1.1 of a compe nsat ory educ ational program. In the absence of a program effect, mat ched controls who decline to participate might be expec te d to underperform the program group, while matched controls who are not eligible because of less need might be exp ected to outperform the program group. On t he other hand, with a large positive treatment effect a nd no hidden

8.3 Comparing Outcomes in Two Control Groups 265
bias, the program group would tend to outperform both matched control groups. Bracketing yields a study design in which treatment effects and plausible biases are likely to have different appearances in observable data.

8.3 Comparing Outcomes in Two Control Groups

8.3.1 A Model for Assignment to One of Several Groups

In earlier chapters, the notation and model described two groups, a treated and a control group. This section discusses a model for assignment to one of two or more groups. As will be seen, it is closely connected both to the model discussed in earlier chapters and to randomized experiments with two or more groups. Specifically, the model generalizes (4.2) to permit more th an two groups. Also, when there is no hidden bias, the model includes the distribution of treatment assignments in completely randomized
experiments and randomized block experiments. As always, there are n s subjects in stratum s defined by the observed
covariate x, , with N = nl + ... + ns , and the it h of these n s subjects has
an unobserved covariate Usi , with 0 ~ Usi ~ 1. If each subject falls in one of K groups, K 2 2, rather than a single treated group or a single control group, write G si k = 1 if the ith subject in stratum s is in group k, and
write G sik = 0 otherwise, with 1 = L~=l G sik for each (s, i). With fixed
covariates x , and Usi , consider the following multinomiallogit model (Cox, 1970, §7.5) for(Gsib . .. . Gsoc ):

pro

b

(

Gs

.
i k:

-
-

1) _
-

exp{~k(Xs) + 8kUsi}
K

L d + exp{~j(xs) 8j us
j=l

(8.1)

where the N vectors (Gsil, . . . , Gsi K ) are mutually independent.
Suppose that we wish to compare two specific groups, j and k, j =I- k,
and so select all subjects with (Gsij + G sik) = 1, that is, all subjects who
belong to one of these two groups. Then

prob(Gsij = 11Gsij + Gsik = 1)

where

=

exp{li(xs) + ')'usd 1 + exp{li(xs) + ')'usd'

(8.2)

and 0 ~ Usi ~ 1,

266 8. Multiple Control Groups
which is identical in form to (4.2). In other words, if the model (8.1) describes assignment to all K groups, then when comparing any two fixed groups, say j and k , the model and methods of earlier chapters may be used directly, recognizing only that the x(x,) and the 1 appropriate for comparing two groups j and k will be different from the K: (x s ) and the 1 for comparing two other groups j' and k'. In particular, if there are only K = 2 groups, then model s (8.1) and (4.2) are essentially the same.
Write m sk = E~~1 G sik for the number of subjects assigned to group k in strat um s. Also write b = (81, 00 , ,8 K )T, so there is no hidden bias if b = 0.

8.3.2 *The Model and Randomized Block Experiments with Several Groups

This section, which may be skipped , describes the relationship between the
model (8.1) and a randomized block experiment. The conclusion is that if
there is no hidden bias in the sense that b = 0 , then the distribution of as-
signments G sik under (8.1) is the same as in a randomized block experiment if one conditions on a sufficient statistic for the k(Xs ) . This is analogous to the conclusion in §3.2 for two groups. The notation introduced and results
in this section are not used in later sections. The section is intended solely
as further motivation for the model (8.1) . Write G for the N x K matrix containing the G sik , and write M for the
S x K matrix containing the m sk = E~s G sik' Conditioning on M fixes the number of subjects in group k in stratum s . Then

prob(G

=

gjM)

=

e "'*
L..

xepx(pu(Tu Tg bg~)*u)

'

(8.3)

where E* is a sum is over all TI ( ns ) possibl e g* such that: m sl · · .m ,«
(i) g;ik = 0 or g;ik = 1;
(ii) 1 = Ek g;ik; and
(iii) m sk = E~1 g;ik for each s , k.
If there is no hidden bias in the sense that b = 0, then (8.3) is constant
or uniform, assigning the same probability to each possible g . If there is just one stratum, S = 1, then this uniform distribution of treatment assignments is the same as th e distribution used to derive the Kruskal-Wallis
(1952) test. If there are several strata, S :::: 2, but each m sk = 1, so one
subject gets each treatment in each strat um, then this uniform distribution is the same as th e distribution used to derive Friedman's (1937) test. These two standard tests are discussed in many texts, for instance, Hollander and Wolfe (1973) or Lehmann (1975) .

8.3 Comparing Outcomes in Two Control Groups 267
In short, the model (8.1) is familiar in two senses. First, as shown in §8.3.1, in comparing groups two at a time, the model leads back to the methods used to compare treated and control groups in earlier chapters. Second, when all groups are considered together, if there is no hidden bias, the model leads back to familiar randomization tests comparing several groups.
8.3.3 Power of the Test Comparing Outcomes in Two Control Groups
Consider a study in which group k = 1 is the treated group and groups
k = 2, . . . ,K are the K - 1 control groups, with K > 2. What does it mean
to say that group 1 is a treatment group and groups k = 2, . .. , K are control groups? The answer defines multiple control groups, distinguishing a study with multiple control groups from a study that simply has several different treatments. Consider the response Rsi of the ith subject in stratum s under the K possible group assignments for this subject. To say that groups k = 2, . . . ,K are control groups is to say that the response of this subject, Rsi , would be the same no matter which control group received this subject, though Rsi might be higher or lower if the subject received the treatment by being assigned to group 1. Notice carefully that this is a statement about the responses of individual subjects under different treatments, not a statement about the observed responses in the several groups . This is, again, the definition of multiple control groups. If the response of an individual would change depending upon the control group to which that subject was assigned, then the differences between the control groups affect the response, so they are not really control groups but rather active treatments with varied effects.
Pick two control groups, j 2 2 and k 2 2, j =I- k. Suppose that G sik + G sij = 1 so the ith subject in stratum s is in one of these two control
groups. Then the response R si of this subject is the same if G si k = 1 or if G sij = 1; that is, conditionally given that G sik+Gsij = 1, the response R si
is fixed. Also, prob(Gsik = 11Gsij + G sik = 1) is given by (8.2), which has
the form used in Chapter 4 to compare two stratified or matched groups. Focus attention on the subjects in these two groups , setting aside subjects
in other groups. Write ii and r for the vectors of dimension Ls (msj +;::sk)
containing the Usi and R si for subjects in groups j and k , and write Z for the vector of the same dimension, where Zsi = 1 if G si j = 1 and Z si = 0 if
G si k = 1. Note that r is fixed as Zvaries since grou~s j and k lE'e control
groups. Also, let n be the set of possible values of Z, so each ZEn has
m sj ones and m sk zeros among its m sj + m sk coordinates for stratum s.
Contrast the responses of the subjects in groups j and k using an arrangement-increasing statistic T = t(Z ,F), for instance, any of the statis-
tics in §2.4.3. For example, if m sj + m sk = 1 for each s then T might be

268 8. Multiple Control Groups
the signed rank or McNemar st atistic comparing the pairs of subjects from groups j and k . Let

and

{3(-r , uii) = '~"_ [t (z-,-r ) 2: a] L~..eJxepx(p')('z')Tb' iiT)u- ) '

ien

be ~

where ')' = OJ - Ok as in (8.2). Using ar guments exact ly parallel to those in §6.2.3, the following points are established. All statements about probabil-
ities refer to conditional probabilities given the Gsik + Gsij '
· The comparison of responses in two control groups tests the null hypothesis that there is no hidden bias. A te st that rejects the hypothesis
of no hidden bias-that is, the hypothesis that ~ = o--when T 2: a
has level 0: . For instance, the rank sum test or the signed rank test would have their usual null distribution discussed in Chapter 2. This is true because ~ = 0 implies ')' = O.
· The test can have power only if there is sys tematic variation of the unobserved covariate. The power of the test is {3(r, ii) , which can differ
from 0: only if ')' = OJ - Ok =I- O. If OJ > Ok then group j will tend to have higher values of u than group k, and similarly if OJ < Ok then
group j will tend to have lower values of u, but if OJ = Ok they will tend to have the same distribution of u . In the terminology of §8.2, a comparison of cont rol groups j and k can hope to detect a hidden bias only if t hese two grou ps exhibit syste mat ic variati on of u .
· The power of this test for hidden bias is greatest if the unobserved covariate u and the responses of controls are strongly related. This is highly desirable, since an unob served covariate st ro ngly related to the response is one that does the most to distort inferences about treatment effects. More precisely, the power fun ction {3(r, ii) is arrangementincreasing. This is analogous to Proposition 23 in §6.2.3.
· Brack eting. There is bracketing in the sense of §8.2 if OJ > 01 > Ok
for in this case the distribution of u in the treated group tends to fall below the distribution in group j but above that in group k,
· Unbiased tests. If the unobserved covariate and the response under the controls are positively related, then the test is an unbiased test
of Ho : OJ = Ok against H A : OJ > Ok ; for specifics , see Rosenbaum
(1989a , §6).

8.4 Bibliographic Notes 269
In short, the behavior of the power function (3(r, ii) provides some formal justification for the principles of systematic variation and bracketing. See also the Problems in §8.5 for the relationship between the power (3(r, ii) and the sensitivity of tests for treatment effects.
8.4 Bibliographic Notes
The general use of multiple control groups to detect hidden biases in observational studies is discussed in detail by Campbell (1969), Rosenbaum (1984, 1987) and Shadish, Cook and Campbell (2002). The use of two control groups is common; it may be the most commonly used device to detect hidden biases. A few additional examples follow. Roghmann and Sodeur (1972) studied the effects of military service on authoritarian attitudes, comparing the West German Army to two control groups, namely, members of a German Catholic fraternity and West German students. In a study of the effects of constant noise on hearing, Taylor, Pearson and Mair (1965) compared jute weavers to two control groups: workers in the jute industry not exposed to noise and school teachers. In a study of the effects of the sequential use of obstetric forceps and vacuum extractors in vaginal deliveries, Ezenagu, Kakaria, and Bofill (1999) compared such deliveries to two groups, one using just forceps, the other using just a vacuum extractor. In a study of the psychological symptoms of women requesting removal of breast implants, Wells et al. (1997) compared such patients to two control groups, namely breast cancer patients and healthy controls. A study of 17 individuals with a rare genetic resistance to parvovirus B19 by Brown et al. (1994) had two treated and two control groups, using data from blood banks and current blood samples. Weston and Mansinghka (1971) compared the financial performance of 63 large conglomerate firms to two control groups, one comprised of industrial firms, the other comprised of a mixture of firms of different types. Another use of multiple control groups is to examine the impact of measurement procedures separated from effects of the treatment; see Solomon (1949) and Payne (1951) for general discussion, and see Berk, Lenihan, and Rossi (1980) for some discussion of an example. The power and unbiasedness of tests for hidden bias in §8.3.3 are discussed in Rosenbaum (1989a). The Advanced Placement Program example in §8.1 is discussed in Rosenbaum (1987). See also the Bibliographic Note, §7.5, concerning multiple referent groups in case-referent studies. An alternative strategy uses pretreatment or baseline measures of the response as one "control," and both pretreatment and posttreatment measures of response for untreated controls as another; see Rosenbaum (2001) for detailed discussion.

270 8. Multiple Control Groups
8.5 Problems
1. IUD and ectopic pregnancy: What does it mean to not receive treatment? Rossing, Daling, Voigt, Stergachis, and Weiss (1993) conducted a case-referent study of the possible increase in the risk of tubal or ectopic pregnancy caused by use of an intrauterine devise as a contraceptive. Can you spot an important issue that will arise in such a study? (Hint : An increased risk compared to what?)
2. IUD and ectopic pregnancy: Compared to what? Rossing et al. (1993, p. 252) write:
There is considerable evidence to indicate that, among women who conceive a pregnancy, users of an intrauterine device (IUD) are more likely than nonusers to have implantation occur outside the uterus . . . [In studies of] nonpregnant , sexually active women .. . both increased and decreased risks have been reported. In the two studies in which the comparison group was restricted to noncontracepting, nonpregnant women, however, current IUD users were observed to be at a reduced risk of ectopic pregnancy.
Why do the studies disagree with each other?
3. IUD and ectopic pregnancy: Several comparisons. Rossing et al. (1993, p. 252) collected data on female members of the Group Health Cooperative of Puget Sound who developed an ectopic pregnancy between 1981 and 1986; these were the cases. Referents were females from the same cooperative, selected using age and county of residence, with certain exclusions . Table 8.8 gives their data comparing cases and referents for IUD users and five other contraceptive groups. What conclusion do you draw?
4. IUD and ectopic pregnancy: Are comparison groups always control groups? Table 8.8 compares IUD users to five comparison groups. Are these control groups in the sense defined in §8.3.3? Why or why not?
5. Dose and response: The pattern of point estimates. The example in §8.1.4 had two control groups and it also had three treated groups at three doses or levels of alcohol consumption. Lilienfeld and Lilienfeld (1980, p. 309) write:
If a factor is of causal importance in a disease, then the risk of developing the disease should be related to the degree of exposure to the factor; that is, a dose-response relationship should exist.

8.5 Problems 271

TABLE 8.8. Thbal Pregnan cy and IUD.

Contraceptive method

Cases Referents

IUD

18

60

Ora l

13

202

Barrier

19

263

Sterilization

31

153

Rhythm, wit hd rawal, ot her 11

33

No ne

157

120

Ignoring the Abstain group, does t here appear to be increasing risk of death with increasing alco hol consumption in Table 8.5?
6. Dose and response: Could the pattern , or lack of pattern , be due to chance? Excluding the Abs tain group, some of the odds ratios in Table 8.5 differ significantly and ot hers do not; see Table 8.6. Given t his, what would you say about the pr esence or absence of a dose response relation ship. Compare your thoughts wit h t he sensible recomme ndat ions of Maclure and Greenl and (1992, p . 103) .
7. Dose and response: Can hidden bias produce a pattern of increasing response with increasing dose? Concerning dose and response, Weiss (198 1, p. 488) writes:
. . . one or more confounding factors can be rela ted closely enough to both exposure and disease to give rise to [a dose resp onse rela t ionship] in the absence of cause and effect .
Suggest a simple linear regression model with a continuous dose Z , a continuous res ponse R , a nd an unobser ved covariate u such that a dose response relati onshi p is produced in the absence of a treatment effect. That is, build a simple model illustrating Weiss's point .
8. Dose and response: Sens itivity analysis with continuous or discrete doses of treatment. Find an expo nent ial family model relati ng discret e or cont inuous doses Z to an un observed covariate u t hat red uces to t he logit model (4.2) when there are just two doses. Use t his model t o develop a me t ho d of sensitivity analysis sim ilar to t hat in Cha pte r 4 wh en treatmen ts come in dose levels. (Solution: Rosenbaum (1989b) , Gastwirth, Krieger , and Rosenbau m (1998) .)
9. Power to detect bias and sens itivity: Power against the worst u . Suppose the t reatment has no effect , and that t here are two control gro ups and a bi nary resp onse r . Suppose further that the one-sided MantelHae nszel statistic is used twice. F irst , in a test for hidden bias , the two control groups are compared to each other . Second, in a test for

272 8. Multiple Control Groups
a treatment effect, the treated group is compared to the two control groups, ignoring the distinction between the two control groups. Define the notation so each test rejects when its test statistic is large in the positive direction . What value u EO U of the unobserved covariate leads to greatest sensitivity in the test for a treatment effect in §4.4.6? What value ii of the unobserved covariate leads to greatest conditional power (3(r, ii) in the test for hidden bias in §8.3.3? What is the relationship between u and u ? Why is this highly desirable?
10. Did the test for hidden bias reduce sensitivity to hidden bias? The
bracketed case. Suppose there is a treated group, k = 1, and two
control groups , k = 2 and k = 3, such that the two control groups are
known to bracket the treated group, in the sense of §8.3.3, so that
82 > 81 > 83 , Continuing Question 9: How would you investigate
whether the test for bias has reduced sensitivity to bias? That is: How would you conduct an analysis similar to that in §6.2.4? What value UO would be tested? How is UO related to the value u that maximizes the power (3(r,ii)? Why is this, too, highly desirable?
11. Did the test for hidden bias reduce sensitivity to hidden bias? The unbracketed case. Why is bracketing important in Problem 1O? What
can happen without bracketing? (Hint: Consider the case of 81 > 82 = 83 , )
8.6 References
Berk, R. A., Lenihan, K. J ., and Rossi, P. H. (1980) Crime and poverty: Some experimental evidence from ex-offenders. American Journal of Sociology, 45 , iGG-i8G.
Bilban, M. (1998) Influence of the work environment in a Pb-Zn mine on the incidence of cytogenetic damage in miners. American Journal of Industrial Medicine, 34, 455-463.
Bitterman, M. (1965) Phyletic differences in learning. American Psychologist, 20 , 396-410.
Brown , K. E ., Hibbs , J . R., Gallinella, G., Anderson, S. M., Lehman, E . D., McCarthy, P., and Young , N. S. (1994) Resistance to parvovirus B19 infection due to lack of virus receptor (erythrocyte P antigen) . New England Journal of Medicine, 330, 1192-1196.
Campbell, D. (1969) Prospective: Artifact and Control. In Artifact in Behavioral Research, R. Rosenthal and R. Rosnow, eds ., New York: Academic, pp . 351-382.

8.6 References 273
Campbell, D. and Boruc h, R. (1975) Making th e case for randomized ass ignment to treatments by considering t he alte rnatives: Six ways in which qu asi-exp eriment al evaluations in compensatory educat ion tend t o underestimat e effects. In: Evaluation and Experiment, C. Bennet t and A. Lumsdaine, eds ., New York: Academic, pp. 195-296.
Ca mpbe ll, D. and Stanley, J. (1963) Experim ent al and Quasi-Experim ental Designs fo r Research. Chicago : Rand McNally.
Cox, D. R (1970) Th e A nalysis of Binary Data. Lond on: Methuen.
Dou glas , D. and Carney, G. (1998) Exp osur e to aspha lt or bit umen fume and renal disease. Occupational and En vironm ental Medicine, 55 , 645-646.
Ezenagu, L. C., Kakaria, R , Bofill, J . A. (1999) Sequ enti al use of instruments at operative vaginal delivery : Is it safe? American Journal of Obsetrics and Gyn ecology, 180, 1446-1449.
Friedman , M. (1937) The use of ranks to avoid the assumption of normality implicit in the analysis of variance. Journal of the American Statistical A ssociat ion , 32, 675-701.
Gastwirth, J. L., Kri eger , A. M., and Rosenbaum, P. R (1998) Dual and simult aneous sensit ivity ana lysis for matched pairs. Biom etrika, 85 , 907-920.
Hollander , M. and Wolfe, D. (1973) Nonparametri c Statistical Methods. New York : Wiley.
J ackson , H., McGorry, P. , Ed ward s, J. , Hulb ert, C. , Henry, L., Francey, S., Maude, D., Cocks, J ., Power , P., Harrigan, S., and Dudgeon, P. (1998) Cognitively-oriented psychotherapy for early psychosis (COPE): Preliminary results. British Journal of Psychiatry , 172, 93-100.
Kim , E . H., McConnell, J. J ., and Greenwood, P. R (1977) Capital st ructure rearrangements and me-first rules in an efficient capital market. Journal of Finance, 32 , 789-810.
Kruskal, W. and Wallis, W . (1952) Use of ranks in one-criterion variance analysis. Journal of the American Statistical Association, 47, 583621.
Lehmann, E . L. (1975) Nonparam etri cs: Stat istical Methods Bas ed on Ranks. San Francisco: Holden-Day.
Lilienfeld , A. , Chang, L., Thomas, D., and Levin, M. (1976) Rauwolfia derivatives and breast can cer. Johns Hopkins Medical Journal , 139, 41-50.

274 8. Multipl e Con trol Groups
Lilienfeld, A. and Lilienfeld , D. (1980) Foundations of Epidemiology (second edition) . New York: Oxford University Press.
Mac1ure, M. and Greenland , S. (1992) Tests for trend and dose-response: Misinterpret ations and alte rnatives. American Journal of Epidemiology, 135, 96-104.
Payne, S. L. (1951) The ideal mod el for controlled exp eriments. Public Opinion Quarterly, 15 , 557-562.
Petersson , B., Trell, E., Krist enson , H. (1982) Alcohol abstention and premature mortality in middl e aged men . British Medical Journal , 285, 1457-1459.
Roghmann, K. and Sodeur, W . (1972) The impact of militar y service on aut horit arian attitudes: Evidence from West Germany. American Journal of Sociology, 78 , 418-433.
Rosenbaum , P. R (1984) From associat ion t o causation in observational st udies. Journal of the Am erican Stat istical A ssociation, 79,41-48.
Rosenb aum, P. R (1987) The role of a second control group in an observational study (wit h Discussion). Statistical Science, 2, 292-316.
Rosenbaum, P. R (1989a) On permutation tests for hidden bias es in observational studies: An application of Holley's inequality to the Savage lattice. Annals of St atistics, 17, 643-653.
Rosenbaum , P. R (1989b) Sensitivity an alysis for matched observational studies with many ordered treatments. Scandinavian Journal of Statistics, 16, 227-236.
Rosenbaum, P. R (2001) St ability in the absence of treatment. Journal of the Amencan Stat istical Associatio n, 96, 210-219.
Rossing , M., Daling , J. , Voigt, L., Stergachis, A., and Weiss , N. (1993) Current use of an intrauterine device and risk of tubal pregnancy. Epidemiology, 4, 252-258.
Seltser, R and Sartwell, P. (1965) The influence of occupational exposure to radi ation on the mortality of American radiologists and other medical specialists. American Journal of Epidemiology, 81, 2-22.
Shadish, W. R and Cook , T . D. (1999) Design rule s: More steps toward a complete theory of quasi-experimentation. Statistical Science, 14 , 294-300.
Shadish, W. R , Cook , T. D., and Campbell, D. T . (2002) Experimental and Quasi-Experimental Designs for Generalized Causal Infe rence. Boston: Houghton-Mifflin.

8.6 References 275
Solomon, R. (1949) An extension of control group design . Psychological Bulletin, 137-150 .
Taylor, W ., Pearson, J ., and Mair, A. (1965) Study of noise and hearing in jute weaving. Journal of the Acoustical Society of America, 38, 113-120.
Weiss, N. (1981) Inferring causal relationships: Elaboration of the criterion of "dose-response." American Journal of Epidemiology, 113,487-490.
Wells, K. E., Roberts, C., Daniels, S. M., Hann, D., Clement, V., Reintgen , D., and Cox, C. E. (1997) Comparison of psychological symptoms of woman requesting removal of breast implants with those of breast cancer patients and healthy controls. Plastic and Reconstructive Surgery, 99, 680-685.
Weston, J . F. and Mansinghka, S. K. (1971) Tests of the efficiency performance of conglomerate firms. Journal of Finance, 26 , 919-936.
Zabin, L. S., Hirsch, M. B., and Emerson, M. R. (1989) When urban adolescents choose abortion: Effects on education, psychological status, and subsequent pregnancy. Family Planning Perspectives , 21 , 248-255.
Zelen, M. (1979) A new design for randomized clinical trials. New England Journal of Medicine, 300, 1242-1245.

9
Coherence and Focused Hypotheses
9.1 Coherent Associations
9.1.1 What Is Coherence?
The 1964 US Sur geon Gener al 's report , Smoking and Health (Bayne-Jones et al. 1964, p. 20), list s five criteria for judgment abo ut ca usa lity, the fifth bei ng "t he coher enc e of t he associat ion." A single sent ence defines coherence (Bayne-J ones et al. 1964, p. 185): "A final criterion for t he appraisal of causal significance of a n assoc iation is its coherence with known fact s in the natural history and biology of the disease." There follows a long discussion of the many ways in which the associat ion between smoking and lung ca ncer is coherent. P er ca pita consumpt ion of cigar ettes had , at that time, been increasing, and the incidence of lung cancer was also increasing. Men, at that time, smoked much more than women and had a much high er incidence of lung cance r. And so on. To this, Sir Austin Bradford Hill (1965 , p. 10) adds: ". . . I regard as greatly contributing to coherence the hist op athological evidence from the bronchial epithelium of smokers and the isolation from cigarette smoke of factors car cinogenic for the skin of laboratory animals." The pattern of associations in §1.2 between smoking and cardiovascular disease would also be described as cohere nt . Coherence is discussed by Susser (1973, pp. 154-162) and more crit ically by Rothman (1986, p. 19). MacMahon a nd Pugh (1970, p. 21) use the phrase "consonan ce with existing knowledge" in place of coherence. Coherence is related to Fisher 's "elab ora te theor y," as discussed in §1.2.

278 9. Coherence and Focused Hypotheses
Typically, coherence is defined briefly, if at all, and then illustrated with examples, often compelling examples. This chapter offers a definition of coherence. The definition is reasonably close to traditional usage of the term, and it has consequences for design and inference. The purpose is to distinguish coherence from efforts to detect hidden biases, as described in Chapters 6 through 8. Though both are useful, coherence and detection differ in their logic and their evidence.
In detecting hidden biases, the goal is to collect data so that an actual treatment effect would be visibly different from the most plausible hidden biases. Control groups, referent groups, or outcomes with known effects are selected with this goal in mind ; see, in particular, §§6.2.3, 7.2.2, 8.1, and 8.3.3. The many tables in Campbell and Stanley (1963) concern the ability of various research designs to distinguish treatment effects from biases of various kinds. Detection concerns distinguishing biases and effects.
Coherence is different . There is no reference to particular biases, no assurance that certain specific biases would be visibly different from treatment effects. A coherent pattern of associations is one that is, at each of many points, in harmony with existing knowledge of how the treatment should behave if it has an effect. In a coherent association, an elaborate theory describing the treatment and its effects closely fits equally elaborate data. What does such a close fit say about hidden biases?
9.1.2 Focused Hypotheses About Treatment Effects
Sir Karl Popper writes:
It is easy to obtain confirmations, or verifications, for nearly every theory-if we look for confirmations. . . . Confirmations should count only if they are the result of risky predictions ; that is to say, if, unenlightened by the theory in question, we should have expected an event that was incompatible with the theory-an event that would have refuted the theory [Popper 1965, p. 36] as scientists we do not seek highly probable theories but powerful and improbable theories [Popper 1965, p.58] .
A theory will be said to be better corroborated the more severe the [evaluations] it has passed.... [An evaluation is] more severe the greater the probability of failing it (the absolute or prior probability as well as the probability in the light of what I call our 'background knowledge' , that is to say, knowledge which, by common agreement, is not questioned while [evaluating] the theory under investigation) [Popper 1983, p. 244].

9.2 Signed Rank Statistics for Coherent Predictions 279
In §1.1, Fisher's elaborate theories are risky predictions because the form of the anticipated treatment effect is tightly and narrowly specified. If such an elaborate theory is confirmed at each of many opportunities, then one senses there is more dramatic evidence against the null hypothesis of no treatment effect and in favor of the elaborate theory of an effect. Indeed, statistical theory supports this view in the sense that hypothesis tests against ordered alternatives often provide more dramatic evidence against a null hypothesis; see, for instance, Jonckheere (1954), Page (1963), Barlow, Bartholomew, Bremner, and Brunk (1972), and Robertson, Wright, and Dykstra (1988) . In Chapter 4, dramatic evidence was typically less sensitive to hidden bias. Perhaps a coherent association, an association that matches an elaborate theory, is less sensitive to hidden bias.
9.2 Signed Rank Statistics for Coherent Predictions
9.2.1 Predictions About Multivariate Outcomes in Matched Pairs
There are 25 subjects in 5 matched pairs and the ith subject in pair s exhibits a K-dimensional response, R si' S = 1, ... , 5 , i = 1,2 . The coherent hypothesis makes predictions about the direction of the effect of the treatment on each of the K responses . Instead of testing each of the K responses separately, a single test will be performed that is particularly effective when the coherent predictions are correct. If complex, ornate data closely match an equally complex, ornate theory, then the results should be less sensitive to hidden bias-at least , that is the hope and the motivation.
This hope is realized in an example later in §9.3. In that example, the treatment is exposure of operating room personnel to anesthetic gases, and the response R si consists of K = 2 measures of mutagenicity, specifically, the number of sister chromatid exchanges and the number of micronuclei. The coherent theory predicts that anesthetic gases cause mutations, and that different measures of mutagenicity will all point in this same direction. The example serves to illustrate both the strengths and limitations of coherence.
In this section, it is assumed that the response has been recorded or rearranged in such a way that the coherent hypothesis predicts higher responses for treated subjects. More complex predictions can also be tested using partial orders of the type discussed in §2.8.
The model for sensitivity analysis is the same as in §4.3.1. One person in each pair received the treatment, signified by Zsi = 1, and the other
received the control, signified by Zsi = 0, so Z sl + Zs2 = 1 for each s ,
and the distribution of treatment assignments is given by (4.7) . Although

280 9. Coherence and Focused Hypotheses
(4.7) refers to conditional probabilities given m = (m l, . . . , ms) , because
m s = + Z sl Zs2 = 1 for every s , t he conditioning on m is suppress ed in t he
not at ion in t his section .

9.2.2 The Sum of Several Signed Rank Statistics
The test statistic is the sum of the K Wilcoxon signe d rank statistics for
t he K coordinates, R sik , k = 1, .. . , K of R si ' Recall that the responses
have been reorganized so that higher responses on each coo rd inate are anticipated under t reatment, so t he sum of K signed rank statistics will be large if this anticipation is confirmed .
For eac h k, rank the abso lute differences IRs 1k - R s2k l from 1 to S wit h average ranks for ties , writ ing qsk for t he rank. Also, write Cs l k = 1 if
= = R s 1k > R s 2k' and Cslk 0 ot herwise, a nd Cs2k 1 if R s 2k > R s 1k ' and
Cs2k = 0 ot herwise, so t hat a t ied pair, wit h R s 1k = R s 2k' has Cslk = Cs2 k =
O. Then t he signed rank statistic for R si k is Tk = L:;=l q s k L:7=1Csik Z si , and the sum of t hese K signed rank statistics is T = L: Tk.

9.2.3 Coherent Tests in the A bsence of Hidden Bias
This section discusses testi ng the null hyp othesis of no effect in t he absence
of hidden bias , that is, wit h r = 1, so t hat P r ( Z sl = 1) = 1/2. In §9.2.4, a sens itivity analysis is developed to address hidden bias , t hat is, r ~ 1 wit h P r ( Zs l = 1) unknown. In §9.2.5, hyp otheses ot her t han no effect are
discussed . It is convenient to exp ress T as a constant plus the su m of S independent
ran dom var iables , each random variable taking j ust two values . Sp ecifica lly, because Z s2 = 1 - Z s l ,

S { K K } e..{; T = ~

+ Cslk q sk (1 - Z s l ) { ; Cs 2k q sk

S

K

SK

L L L L = z., + (Cs lk - Cs2k) qsk

Cs2k q s k

s=l k= l

s=l k=l

S
= L ZS1 ui; + L,
s= l

(9.1)

K

SK

L L L where W s =

(Cs 1k - Cs2k) qsk and L =

Cs2k q sk ·

k=l

s= l k= l

9.2 Signed Rank Statistics for Coherent Predictions 281
In the absence of hidden bias, under the model (4.7) with r = 1, the S distinct Z s1'S are mutually independent with Pr (Zs1 = 1) = Pr (Zs1 = 0) =
1/2. Under the null hypothesis of no treatment effect, the responses R si are fixed, not varying with the Zsi's, so the Csik and qsk are also fixed. It
follows from (9.1) that, when r = 1, the null expectation of Tis E (T) =
w w;. ~ (L;=1 s) + L and the null variance of T is var (T) = ~ L ;=1 An
approximate one-sided significance level is obtained by comparing
T - E(T)
Jvar(T)
to the standard Normal distribution.

9.2.4 Sensitivity Analysis for a Coherent Test

The sensitivity analysis for r 2: 1 uses bounds on Pr (Zs1 = 1). Write

Ps = r / (1 + r) if ui; 2: 0 and Ps = 1/ (1 + r) if W s < O. Similarly, write

Ps = 1/ (1 + r) if W s 2: 0 and Ps = r / (1 + r) if W s < O. Notice that

Ps maximizes the chance of
chance of negative contribut

positive contributions to
ions, while Ps minimizes

T th

and minimizes the e chance of ~sitive

contributions and maximizes the chance of negative ones. Let T be a

random variable that is the sum of S independent terms taking value W s
with probability Ps and value 0 with probability 1- Ps. Define T similarly
but with Ps in place ofps ' As a special case of Proposition 13, the following
proposition provides sensitivity bounds for the coherent signed rank test

under the model (4.7).

Proposition 28 If the treatment has no effect on R s i , then for each fixed
r 2: 1,
(r prob 2: a) 2: prob (T 2: a) 2: prob (T 2: a) for all a and all U E U .

Under the null hypothesis of no treatment effect, T has expectation and
variance:

s

s

E(r) = LPsws+L, var (r) = LPs(1 - Ps) w;,

s=1

s=1

with analogous formulas for T but with Ps in place of Ps' As S -+ 00, the
(r upper bound on the tail probability, prob 2: a) , is approximated by:

{a- E(r )}]

[ (r) 1 - <I>

Jvar

,

282 9. Coherence and Focused Hy pot heses
where <I> (.) is th e standa rd Norm al cumulative di stribution . The sensit ivity analysis is illustrated in §9.3.
9.2.5 Coherent Equivalence Tests
Write r C .·i for the K - dimensional response that the it h subject in pair s
would exhibit und er control,'s = 1, . .. , S, i = 1,2. Then the treatment has
an additive effect on each coordinate if ther e is a K -dimensional T such
that t he observed resp onse is R s i = + r C si T Z si , S = 1, .. . , S, i = 1,2.
Point estimates and confidence interva ls for each coordinate of T may be obt ain ed by th e methods of Ch ap ter s 3 and 4. How ca n the cohere nt signed rank st at istic T be used to say something ab out t he ent ire vect or T ? A confidence "interval" for the K - dimensional T based on the scalar T is not possible, but a simple form of equivalence test is po ssibl e. If the null hypothesis that the treatment is highly effect ive is clearly rejected in favor of smaller effects, is this findin g sensit ive t o hidden biases? Although two-sided equivalence test s are most relevant to bioequivalen ce t esting in pharmaceutical experiments , one-sided equivalence t est s are most relevant to sensitivity anal ysis in observati on al st udies.
The hypothesis H o : T = T O may be te st ed by calc ulat ing the adj uste d response, R si - T OZsi , which equ als the fixed qu an ti ty r C si when the hypothesis is true. Then the coherent signed rank test is applied t o the adjust ed responses, R si - T oZsi , t esting t he hypothesis of no effect on these adjusted responses.
If the hypothesis Ho : T = TO , with each Tk > 0, asserts that the treat-
ment is quite effective, this hypothesis may be t ested against the alte rn at ive of smaller effects by rejecting H o when T is small. Rejection of H o in favor of smaller effect s provides strong evidence that the t reat me nt is n ot quite effect ive. The sensit ivity ana lysis is performed as in §9.2.4. In som e contexts, the conclusion that t he t reat me nt is not quite effect ive may be quite insensitive to hidden bias: very lar ge biases migh t be needed to mask a highly effect ive treatment. An example involvin g a surgical int ervention in urology is given by Li, Prop ert , and Rosenbaum (2001).
9.3 Example: Do Anesthetic Gases Cause Mutations?
9.3.1 Reduced Sensitivity to Hidden Bias from a Coherent Prediction
Wh en an esthetic gases are used in op er at ing ro oms, there is some leakage, so oper ating room personn el may be exposed rep eatedly. In an effort to determine whether such exposures were mutagenic , Hoer auf, Lierz , Wiesner ,

9.3 Example: Do Anesthetic Gases Cause Mutations? 283

TABLE 9.1. Mutagenicity of Anesthetic Gases in Exposed Veterinary Surgeons

(E) and Controls (C).

Pair Ages (E/C) Gender E-SCE E-MN C-SCE C-MN

1 52/51

M

8.59 10.75 6.37 6.25

2 26/25

F

9.12 13.00 8.35 6.00

3 31/30

M

12.99 6.75 5.35 7.75

4 27/27

F

7.87 7.50 12.03 6.50

5 26/27

M

8.15 9.75 5.88 3.00

6 31/30

F

13.40 5.50 6.39 5.75

7 35/38

M

9.58 4.00 9.74 3.50

8 33/33

F

10.29 9.75 6.62 9.25

9 40/41

F

10.08 12.50 4.30 9.75

10 27/27

F

11.72 7.50 9.28 10.25

Schroegendorfer, Lierz, Spacek, Brunnberg, and Nusse (1999) matched 10 veterinary surgeons to 10 unexposed veterinary physicians, matching for age and gender. They obtained two measures of mutagenicity, namely, the mean number of sister chromatid exchanges per metaphase (SCE) in cultured lymphocytes, and the number of micronuclei (MN) recorded as micronuclei per 500 binucleated cells. Their data are in Table 9.1.
If the Wilcoxon signed rank test is used assuming no hidden bias , then one obtains standardized deviates of 1.99 and 1.58 for SCE and MN, respectively, with approximate one-sided significance levels 0.023 and 0.057.
These two separate tests are sensitive to moderate biases: for r = 1.5, the
minimum deviates become 1.46 and 1.04 with maximum approximate onesided significance levels 0.073 and 0.149. Of course, the pattern for both SCE and MN is in the predicted direction. The coherent signed rank test has a deviate of 2.44 in the absence of hidden bias, with approximate onesided significance level 0.0073. The coherent test is less sensitive to hidden
bias: for r = 1.5 and r = 2, respectively, the minimum standardized devi-
ates are 1.94 and 1.63, with approximate maximum one-sided significance levels 0.026 and 0.052. Use of a coherent alternative has reduced sensitivity to hidden bias.

9.3.2 Details of the Calculations
The calculations leading to the coherent test are shown in Table 9.2. As in Wilcoxon's signed rank test, matched pair differences are calculated for each variable, SCE and MN, separately, the absolute differences are ranked with average ranks for ties, and the signs of the differences are noted. The signs and ranks are combined into a coherent score; for instance, for pair
#1, the score is 3 x (+ 1) + 8 x (+1) = 11. Notice that pair #3 has a slightly
negative difference for MN, but the largest positive difference for SCE, so the overall score of 5.5 is somewhat positive .

284 9. Coherence and Focused Hypotheses

TABLE 9.2. Calcul ation of the Coherent Sign ed-Rank St atistic from Matched

Pair Differ enc es (d) , Ranks (r) , and Signs (s) .

Pair dSCE dMN rSCE rMN sSCE sMN Score

1 2.22 4.50

3 8.0 +1 +1 11.0

2 0.77 7.00

2 10.0 +1 +1 12.0

3 7.64 -1.00

10 4.5 +1 -1 5.5

4 -4.16 1.00

7 4.5 -1 +1 -2.5

5 2.27 6.75

4 9.0 +1 +1 13.0

6 7.01 -0.25

9 1.0 +1 -1 8.0

7 -0.16 0.50

1 2.5 -1 +1 1.5

8 3.67 0.50

6 2.5 +1 +1 8.5

9 5.78 2.75

8 6.5 +1 +1 14.5

10 2.44 -2.75

5 6.5 +1 -1 -1.5

Wilcoxon 's signed rank statistic for SCE is 3+2+ 10+4+9+6+8+5 = 47
and for MN is 8 + 10 + 4.5 + 9 + 2.5 + 2.5 + 6.5 = 43, so the coherent
signed rank statistic is 47 + 43 = 90. This equals the sum of the scores,
11 + 12 + 5.5 + -2.5 + 13 + 8 + 1.5 + 8.5 + 14.5 + -1.5 = 70 plus the
const ant , L = 7 + 1 + 4.5 + 1.0 + 6.5 = 20 which adds back the five ranks with negative signs. In the absence of hidden bias, r = 1, the individual
signed rank st ati stics each have expectation 10(10 + 1)/4 = 27.5 while the
coherent statistic has expectation equal to twice this, namely 55, which
equals half the sum of the scores plus L or 70/2 + 20 = 55. In the absence
of hidden bias, r = 1, the variance of the coherent statistic is one fourth
of the sum of the squares of the scores, or ~ (112 + . . . + -1.52) = 205.375
and the deviate is (90 - 55) /)205.375 = 2.44.
The sensitivity analysis for r > 1 is similar, but it is important to keep
in mind that Ps = r / (1 + I") if the score is positive and Ps = 1/ (1 + f)
if the score is negative, thereby increasing the cha nce of a positive score
and decreasing the chance of a negative one. For instance, with r = 2, the
first pair has PI = 2/3 but the fourth pair has P4 = 1/3. With r = 2, the
maximum expectation for the coherent signed rank st atistic is the weighted
sum of scores plus L = 20, namely ~ x 11 + . . . + ~ x - 1.5 + 20 = 68 and the associated variance is r / (1 + r)2 = ~ times the sum of the squares
of the scores , 112 + . .. + -1.52 , or 182.56, so the minimum deviate is
(90 - 68) / J182 .56 = 1.63. The constant L does not affect the deviate or the significance level, sin ce
it is added to both the statistic and its exp ect ation. However, without L,
the coherent statistic cannot be described as the sum of the separate signed rank statistics. When computing the devi ate for the coherent st atist ic, L
may be dropped from both the statistic and its expectation .

9.4 *Proper ties of th e Coherent Signed Rank Test 285
9.4 *Properties of the Coherent Signed Rank Test
Properties of the coherent signed rank test are developed in Rosenbaum (1997) and are bri efly and informally outlined here. The coherent t est has good power when the treatment affects all of the outcomes to a similar degr ee, with outcomes that are weakly and symmetrically correlated. In this case, the gain in power and insensitivity to bias can be substantial. Of course, multiple outcomes that are perfectly correlated provide no incr ease in power. Obviously, the situation is less favorable when only some of the outcomes ar e affected by the treatment , but gains in power and insensitivity ar e non etheless possible when at least half the outcomes ar e affected and there are at least four outcomes. See Rosenbaum (1997, §4.3) for detailed dis cussion.
It is possible to compare the coherent test st atistic, T , to the individual statistics, Tk , by embedding them both in a family of test statistics . Fix a
set of weights, >"k 2: 0, 1 = L >"k, and consider the statistic, G = L >"k Tk. Then KG = T when >"1 = . .. = >"K = 1/K , and the two st atistics yield the
same deviate, {G - E(G)} /v!var(G). Also, G = Tk when >"1 = 0, ... , >"k-l = 0, >"k = 1, >"k+l = 0, . .. , >"K = O. The deviate for the coherent signed rank statistic discarding outcome K is obtained from G = L: >"k Tk with >"1 = . .. = >"K-l = 1/ (K - 1), >"K = 0, and so on. Consider the set of all possible >"k'S such that G > O. On this set of possible >"k'S, the
deviate has a special property, semistrict quasiconcavity, whose practical implications will now be described. See Rosenbaum (1997, Appendix) for formal definitions and proof. Suppose that we are unsure whether to use Tk based on the kth outcome or the coherent statistic without the kth outcome, T - Tc ; assuming both are positive. If their deviates are unequal, the special property implies that the deviate based on all of T is at least as large as the smaller of the two devi ates bas ed on Tk alone or on T - Tu, Informally, it may be better to know which outcomes are affected and which are not ; however, lacking that knowledge, the coherent test is always better than the poorer of two choices, namely using the kth outcome alone or discarding the kth outcome. As discussed in Rosenbaum (1997, Appendix) , the special property leads to many similar results of this kind : the combinat ion of two parts is always better than the weaker of the two parts, and may be better than eit her part, as in §9.3.
9.5 Some Other Forms of Coherence
In general, coherence specifies a detailed pattern of associations anticipated when the treatment is the cause of the associations. This chapter has emphasized on e type of coherence, namely, predictions about the direction

286 9. Coherence and Focused Hypotheses
of effect s for several out come variables. Ther e are , of cours e, many other patterns one might ant icipate.
In some st udies, it is possibl e to obtain measures of the response befor e and aft.er treatment. The imp ortance of baselin e measures of response is emphasized by Campbell and Stanley (1963), Cook, Campbell, and Peracchio (1990), Allison (1990), Cook and Shadish (1994) , and Shadish, Cook and Campbell (2002). For example, there are baseline measures of response in the minimum wage data in §5.1O, where employment data were obtained before and after the cha nge in New J ersey 's minimum wage. For ot her examples, see Grevert and Goldst ein (1977) and Allison and Long (1990) . Baseline measures of response are particularly useful when one ant icip ates that untreated subjects will remain relatively stable, without sys te mat ic increases or decreases in response. A st at ist ica l test designed to notice and record this particular coherent pattern can yield reduced sensit ivity to hidd en bias when the pattern occurs (Rosenbaum 2001) . Interestingly, in Grevert and Goldstein (1977), the control group was expected to change and the treate d group was expecte d to remain st a ble: the treatment, naloxone, was exp ecte d to block a decline in tension a nd a nxiety.
Yet another pattern is anticipated in an interesting examp le discussed by Salzberg (1999). Claiming that a fuel company had submitted fraudulent bills for fuel deliveri es t o certain City buildings, the City of New York sued. The City's evidence included fuel delivery records for these buildings before, during, and aft er the years of service by this company, together with parallel data for other buildings never served by this company. The coher ent prediction is a rise in fuel bills confin ed to buildings served by this company during the year s the company provided fuel.
Still another pattern was anticipated by Allison and Long (1990) in a careful st udy of the effects that academic departments have on the research productivity of their faculty. They looked at 179 job changes by chemist s, biologists, physicist s, and mathem aticians, and they measured productivity by publications and cit ations before and after the job change. They predicted and found increased productivity following moves to higher ranked departments, and decreased productivity following moves to lower ranked departments. See their discussion of the several mechanisms that might account for this pattern.
9.6 Strengths and Limitations of Coherence
As an argument, coherence has two strengths. First , a test against a coherent alternative penalizes a data set that exhibits nonsensical associat ions , making it more difficult to detect an effect in this case. Second, evidence of an effect may be dramatic in either of two ways : the effect may appear dramatic in size, or it may make numerous predictions each of which is

9.6 Strengths and Limitations of Coh erence 287
confirmed in data. A test aga inst a coherent alternative provides a basis for appraising the latter possibility.
The strengths may be expressed in another way. If the study were free of hidden bias, r = 1, then 5% of the treatment assignments zEn would lead to reje ction of the null hypothesis of no treatment effect at the 0.05 level. Which 5% of treatment assignments zEn should lead to rejection? The argument of coherence says this 5% should be chosen carefully. Specifically, one should reject for those zEn that appear most consistent with the pattern anticipated if the treatment actually caused the effect .
Coherence also has two significant limitations. First, a coherent pattern of associations may result from a coherent pattern of hidden biases . For instance, in §9.3, if vet erinary surgeons were exposed to some other mutagen besides anesthetic gases, the same coherent pattern of associations might be found. Similarly in §9.5, as discussed by Allison and Long (1990), their ant icipat ed coherent pattern of productivity changes following academic job changes could be produced by more than one mechanism. As discussed in §9.1.1, unlike efforts to detect hidden bias , coherence is concerned with the pattern of associations that is consistent with a treatment effect, but it does not take active steps to ensure that this pattern differs from what is expected from plausible hidden biases. Contrast coherence with "control by systematic variation" in §§8.2 and 8.3.3. If control groups are selected to systematically vary a relevant unobserved covariate then, as seen in §8.3.3, there are good prospects that any hidden bias that may be due to this covariate will be revealed when the control groups are compared. In contrast, the test against a coherent alternative comes with no promise that it can assist in distinguishing a treatment effect from any particular hidden bias.
The second limitation of coherence is that a summary statistic for several outcomes may be useful as a primary endpoint, but detailed results for each outcome are also important. A test against a coherent alternative concerns evidence against the null hypothesis of no effect and in the direction of a coherent pattern of associations. The evidence against the null hypothesis of no effect of any kind may be strong and insensitive to hidden bias , but the evidence about individual outcomes may be quite varied. Because outcomes differ in their consequences for policy, it is rarely sufficient to know that there is at least some effect on one of the outcomes. A sensitivity analysis against a coherent alternative should generally be accompanied by a sensitivity analysis for individual outcomes.
In short, a sensitivity analysis for a test against a coherent alternative helps to appraise evidence provided by the confirmation of numerous specific predictions. It is not , however , a substitute for sensitivity analyses for individual outcomes nor for active steps to detect hidden bias.

288 9. Coherence and Focused Hypotheses
9.7 *Appendix: Arrangement-Increasing Functions
of Matrices
In this section, the definition of arrangement-increasing functions is extended to certain partial orders and, in particular, the coherent signed rank statistic is seen to be arrangement-increasing with respect to a partial order. In addit ion, many other similar st atistics are arrangement-increasing with respect to a partial order and they play roles similar to that of the coherent signed rank statistic; see the Problems in §9.9. Among these statistics are: (i) sums of several rank sum statistics, (ii) sums of several align ed rank statistics, (iii) sums of several st at ist ics associated with Fisher 's exact test for a 2 x 2 table, and some st atistics of the type described in §2.8.4. Section 2.4.4 discussed arrangement-increasing functions f(a , b) of two stratified N-dimensional vectors a , b, that is, two vectors ind exed by
8 = 1, . . . ,S, i = 1, . . . ,ns , N = nl + . . . + ns . Such a function was defined
by two properties. First, it was permutation-invariant in the sense that interchanging two coordinat es from the same stratum in both vectors does not alt er the value of the function . Second, interchanging two coordinat es from the same stratum in one vector so their order disagrees with the order in the other vector decreases, or at least does not increase, the value of the function .
These two properties of arrangement-increasing functions may be stated formally using "interchange vectors" Lsij ' There is an interchange vector
for each 8 , 8 = 1, .. . ,S, and each i,j with 1 :::; i < j :::; n s and Lsij
is the N-dimensional column vector with a one in the ith coordinate for strat um 8, a negative one in th e jth coordinate for st rat um 8, and a zero in all other coordinat es. Let 1 denote the N x N identity matrix. When an N-dimensional vector b is multiplied by the matrix 1 - LSijL;;j the result (1 - 1.8 ijl.~j)h is h with its it h and jth coordinates of st ra t um s interchanged. Then f(· , ·) is permutation invariant if, for each a , and b in
the domain of f(· , .), for every interchang e vector Lsij, f(a , b) = f[(1 -
LSijL;;j)a, (I - LSijL;;j)bJ . A permutation invariant f (' ,') is arrangementincreasing if aT LsijL~jb :::: 0 implies f(a , b) :::: f[a , (I - LSijL;;j)b] .
In the same way, let A and B be two matrices each with N st ra t ified rows numbered 8 = 1, . . . ,S, i = 1, . . . , ns . Let f(A , B) be a realvalued function of th ese matrix arguments. Then f( ', .) is permutation invariant if simultaneously int erchanging two rows of A and the sam e two rows of B in the same subclass does not change f(A, B) ; that is, if for
every A and B in the domain of f (-, .), and for every interchange vector,
f(A , B) = f[(I-Ls ijL;;j)A, (I-LsijL;;j)BJ. Write C :::: 0 if Ckm :::: 0 for each k, m . A permutation-invariant function f(' , ') is arrangement -increasing if ATLSijL~jB :::: 0 implies f(A ,B) :::: j[A, (I - LSijL;;j)B) . In other words, if rows (8, i ) and (8,j) of A and B ar e ordered in the same way, then

9.8 Bibliographic Notes 289
int erchan gin g t hese two rows of B redu ces, or at least does not increase, j (A,B).
.s Let R be an N x K matrix of K-dimensional responses for N subjects,
with the usual partial order saying that subject (8, i) has a lower response than subject (8,j) if each of the K responses for subjec t (8, i) is less than or equal t o each of the K responses for subj ect (8,j ). This is the partial order used in §9.2 and the first partial ord er in §2.8.3. With thi s partial order, t he stat istic t (Z , R ) in (2.8) and t he coherent signed rank statist ic in §9.2 are both arrange ment-increasing.
Hollander , Proschan, and Sethuraman (1977) discuss properties of arrangement increasing functi ons of two vecto rs, and many of t hese extend to ar rangement-increasing fun cti ons of two matrices, sometimes with sma ll modificati ons; see Rosenbaum (1991, §2). For inst ance, using an exte nsion of their comp ositio n t heore m, Proposition 23 in §6.2.3 may be proved for poset stat ist ics. A different application arises when the coherent pattern of ass ociat ions is produced by an underlying and unobserved dose of treatment; see Rosenbaum (1991, §4) for a pr actic al example.
9.8 Bibliographic Notes
Coh erenc e is discu ssed wit h varying terminology and varying degrees of enthusiasm by Hill (1965), MacM ahon and Pugh (1970, p. 21), Susser (1973, pp . 154-162 , 1991) , a nd Rothman (1986, p. 19), among others. T he several references by Campbell, Cook, Sha dish, St anl ey, and Per acchio discuss coherence and detect ing bias , in different te rmi nology, an d they emp has ize t hat cohere nt patter ns may result from biases ra ther than treatment effect s. Coherence is also discussed more generally by Davidson (1986) and Thagard (2000) . There is a large lite rature on statistical met hods for orde r restrict ed inferen ce, t hough t he most widely used methods are for totally ordered outcomes rather t han par tially ordered outcomes; t ha t is, they conce rn dose-re sp onse relationships rather than cohere nce of mult iple outcomes . See Jonckheer e (1954) and Page (1963) for nonpar ametric methods for t ot ally ordered outc omes; these test s ar e also discussed in the textbook by Hollander and Wolfe (1973 ). For comprehensive sur veys of ord er rest ricted inferen ce with exte nsive bibliographies, see Barlow, Bar tholomew, Bremner, a nd Brunk (1972) and Robertson , Wright, and Dykstra (1988). Macl ure and Gr eenl an d (1992) are crit ical of potentia l misinterpretation of tests for t rend and sugges t careful terminology for discussing such tests. There is a large lit er at ur e on equ ivalence tests; see Schuirmann (1987) a nd Hsu, Hwan g, Liu , and Ruberg (1994), for example. This cha pte r is based upon Rosenb aum (1991, 1994, 1997) and Li, Prop ert , and Rosenbaum (200 1).

290 9. Coherence and Focused Hypotheses
9.9 Problems

1. Coherent rank sum statistics. Suppose that there is a single stratum, S = 1, so the s subscript is dropped , and a K -dimensional response, ~, where higher responses on each coordinate of R, are anticipated if the treatment has an effect . In this case , one might compute K separate Wilcoxon rank sum statistics, one for each coordinate of ~, and add them together to form a single test statistic. In a uniform
randomized experiment or in an observational study free of hidden
bias , r = 1, what are the null expectation and variance of this sum
of rank sum statistics? (Rosenbaum 1991)

2. Coherent rank sum statistics: Sensitivity analysis. How could you do a sensitivity analysis for the coherent rank sum statistic in the previous problem? (Hint: Write the statistic in the form (4.26) and apply the general method of §4.6.)

3. Coherent rank sum statistics: Arrangement increasing property. Show the coherent rank sum statistic is arrangement increasing in Z and the response matrix, using ideas from the appendix to this chapter. (Rosenbaum 1991)

4. Coherent Mann-Whitney statistics: Sensitivity analysis. How could you do a sensitivity analysis for the statistic in §2.8.4? (Hint: Write the statistic in the form (4.26) and apply the general method of §4.6.) (Rosenbaum 1994)

5. Coherent signed rank statistics with dose-response. Suppose that, in

pair s, the treatment is applied to the treated subject with fixed

dose ds , while the control remains untreated. Consider the statistic

D

=

K I:k=l

ds

I:SS=l

q sk

I:i2=l

Csi k

Z

si

whi· ch· gives

greater

we·ight

to

matched pairs in which the dose is higher. When the doses are all

the same, say d, = 1, the statistic D is essentially the same as the co-

herent signed rank test discussed in §9.2. Obtain the null expectation
and vari ance of D for r 2:: 1. (Rosenbaum 1997)

9.10 References
Allison , P. D. (1990) Change scores as dependent variables in regression analyses. In : Sociological Methodology, C. C . Clogg, ed ., Oxford: Basil Blackwell, pp . 93-114.
Allison, P. D. and Long , J. S. (1990) Departmental effects on scientific productivity. Ameri can Sociological R eview, 55, 469-478.

9.10 References 291
Barlow, R. , Bartholomew, D., Bremner , J ., and Brunk, H. (1972) Statistical Inferen ce Under Order Rest rictions. New York: Wiley.
Bayn e-Jones, S., Burdette, W ., Cochran, W. , Farb er, E ., Fieser, L., Furth, J. , Hickman, J ., LeMaistre, C., Schuman, L., and Seevers, M. (1964) Smoking and Health: R eport of the Advisory Com mittee to the Surgeon General of the Public Health Service. Washington, DC: US Department of Health, Education, and Welfare.
Campbell, D. and Stanley, J . (1963) Experim ental and Quasi Experimental Designs for R esearch. Chicago: Rand McNally.
Cook, T . D. (1991) Clarifying the warrant for generalized causal inferences in quasi-experimentation. In: Evaluation and Edu cation at Quarter Century, M. W. McLaughlin and D. Phillips, eds., NSSE 1991 Yearbook, pp. 115-144.
Cook, T . D. , Campbell, D. T . and Peracchio, L. (1990) Quasi Exp erimentation. In : Handbook of Industrial and Organizational Psychology, M. Dunnette and L. Hough, eds., Palo Alto , CA: Consulting Ps ychologists Press, Ch apter 9, pp. 491-576.
Cook, T. D. and Shadish , W. R. (1994) Social experiments: Some developments over the past fifteen years. Annual R eview of Psychology, 45, 545-580.
Davidson , D. (1986 ) A coherence theory of truth and knowledge. In: Truth and Interpretation , E. Lepore, ed., Oxford : Blackwell, pp. 307-319.
Gr evert, P. and Gold st ein , A. (1977) Effects of naloxone on experiment ally induced ischemic pain and on mood in human subjects. Proceedings of the National Acad emy of Sciences (Psychology), 74, 1291-1294.
Hill, A. B. (1965) The environment and disease: Association or causation? Proceedings of the Royal Society of Medicine, 58, 295-300.
Hoerauf, K., Lierz, M., Wiesner , G., Schroegendorfer, K., Lierz, P., Spacek, A., Brunnberg, L., Nusse, M. (1999) Genetic damage in operating room personnel exposed to isoflurane and nitrous oxide . Occupational and Environmental Health, 56, 433-437.
Hollander, M., Proschan, F. , and Sethuraman, J . (1977) Functions decreasing in transposition and their applications in ranking problems. Annals of Statistics, 5 , 722-733.
Hollander, M. and Wolfe, D. (1973) Nonparametric Statistical Methods. New York: Wil ey.

292 9. Coherence and Focused Hypotheses
Hsu, .J. C., Hwang , .J. T. G., Liu, H. K., and Ruberg, S..J. (1994) Confidence intervals associated with tests for bioequivalence. Biometrika, 81, 103-114.
Jonckheere, A. (1954) A distribution-free k-sample test against ordered alternatives. Biometrika, 41, 133-145.
Li, Y., Propert, K. J. and Rosenbaum, P. R. (2001) Balanced risk set matching. Journal of the American Statistical Association, 96, September, to appear.
Maclure, M. and Greenland, S. (1992) Tests for trend and dose-response: Misinterpretations and alternatives. American Journal of Epidemiology, 135,96-104.
MacMahon, B. and Pugh, T . (1970) Epidemiology: Principles and Methods. Boston: Little, Brown .
Mann, H. and Whitney, D. (1947) On a test of whether one of two random variables is stochastically larger than the other. Annals of Mathematical Statistics, 18 , 50-60.
Mantel, N. (1967) Ranking procedures for arbitrarily restricted observations. Biometrics, 23, 65-78.
Page, E . (1963) Ordered hypotheses for multiple treatments: A significance test for linear ranks. Journal of the American Statistical Association, 58, 216-230 .
Popper, K. (1965) Conjectures and Refutations. New York: Harper & Row .
Popper, K. (1983) Realism and the Aim of Science. Totowa, NJ: Rowman and Littlefield.
Robertson, T., Wright, F. T ., and Dykstra, R. L. (1988) Order Restricted Statistical Inference. New York: Wiley.
Rosenbaum, P. R. (1991) Some poset statistics. Annals of Statistics, 19, 1091-1097.
Rosenbaum, P. R. (1994) Coherence in observational studies. Biometrics, 50,368-374.
Rosenbaum, P. R. (1997) Signed rank statistics for coherent predictions. Biometrics, 53, 556-566.
Rosenbaum, P. R. (2001) Stability in the absence of treatment. Journal of the American Statistical Association, 96, 210-219.
Rothman, K. (1986) Modern Epidemiology. Boston: Little, Brown.

9.10 References 293
Salzberg, A. (1999) Removable selectio n bias in quas i-experiments. The American Statistician, 53, 103-107.
Schuirmann , D. J. (1987) A comparison of t he two one-sided test s procedure and t he p ower approach for assess ing the equ ivalence of average bioavail ability. Journ al of Pharm acokinetics and Biopharmaceutics, 15, 657-680.
Shadish, W. R., Coo k, T . D., and Campbell, D. T . (2002) Experim ental and Quasi-Experim ental Designs for Generalized Causal Inference. Bost on: Hou ghton-Mifflin.
Skerfving, S., Han sson, K., Ma ngs , C. , Lindsten, J ., and Ryman, N. (1974) Met hylmerc ury-induced chromosome damage in man . En vironmental R esearch, 7 , 83-98.
Susse r , M. (1973) Causal Th inking in the Health Sciences. New York: Oxford University P ress.
Susse r, M. (1991) W hat is a ca use and how do we know one? A grammar for prag matic ep ide miology. American Journal of Epid emiology, 133, 635-648.
Thagar d , P. (2000) Coherence in Thought and Action. Ca mbridge, MA : MIT Press.
Wi lcoxon , F . (1945) In dividual comparisons by ra nking methods. Biom etrics , 1, 80-83.

10
Constructing Matched Sets and Strata
10.1 Introduction: Propensity Scores, Structures, Algorithms
This chapter discusses the const ru ction of matched set s or strat a when there are several, p erhaps many, observed covariates x. There are three topics: the propensity score, t he form of an optimal stratification, and the construction of optimal matched sets. This introduction summarizes the main issues and findings.
As the number p of covariates increases, it becomes difficult to find matched pairs with the same or similar values of x . Even if each covariate is a binary variable, there will be 2P possible values of x , so with p = 20 covariates there are more than a million possible values of x. If there are hundreds or thousands of subjects and p = 20 covariates, it is likely that many subjects will have unique values of x . For this reason, it is sometimes said that matching is not useful when there are many covariates. Actually, the problem is not with matching as a technique but rather with the specific objective of obtaining matched pairs or sets that are homogeneous in x. If the objective is defined in other ways, then matching and stratification are not difficult with many covariates.
There are two objectives of matching and stratification besides matched set s that are homogeneous in x . First, if there is no hidden bias so that it suffices to adjust for x , then strata or matched sets are desired that permit use of the conventional methods in Chapter 2. Second, whether or not there is hidden bias, one would like to compare treated and control groups with

296 10. Constructing Matched Set s and Strata
similar distributions of x , even if matched individuals have differing values of x. The second object ive is called covariate balance.
The propensity score is a device for constructing matched set s or st rat a when x contains man y covariat es. If the true propensity score were known , both objectives in the pr evious par agraph would be at tained by matching or st rat ifying on t he propensity score, a single covari ate. That is, if st rat a or mat ched sets ar e formed that ar e homogeneous in the pr op ensity score, even if they are het erogeneous in x , then the methods of Ch apter 2 are appropriate in the absence of hidden bias, and the observed covariates x will tend to balance whether or not t here is hidden bias. In t he case of the first object ive, thi s was demonstrated in §3.2.5; see also §1O.2. 1 below. Covariate balan ce is demonstrat ed in §10.2.2. In practi ce, the propensity score is not known and must be est imat ed. One approach was discussed in §§3.4 and 3.5. For matching and st rat ificat ion, lise of est imate d propensity scores is illustrated in §1O.2.3 and simulation results are reviewed in §1O.4.7.
Section 10:3 discuss es optimal stratification. As it turns out, under quite general conditions, the form of an optimal stratification is always the same. This implies th at in sear ching for a good stratification , the searc h may be confined to strat ifications of this form because one is sure to be optimal. This op timal form is called a full matching. It is a matched sa mple in which each matched set cont ains eit her a treated subject and one or more cont rols or else a control subject and one or more treated subjects. P air matching is not opt imal, and neither is matching with a fixed number of controls. In the simulation results describ ed in §1O.4.7, full mat ching is found to be subs tant ially bet ter than matching with a fixed number of cont rols. It is easy to see why this happens. When the tre at ed a nd cont rol gro ups have different distributions of the observed covariates x , ther e ar e regions of x valu es with many treated subjects and few cont rols, and ot her regions with many controls and few treated subjec ts. Forcing every treate d subject to have thc sa me number of cont rols creates som e poor matched set s.
The const ruct ion of opt imal matched sa mples is discussed in §10.4. Various types of matching are illustrated and comp are d , including matching with a fixed numb er of controls, matching with a var iabl e number of controls, full matching, and balan ced matching. Network flow t echniques are used to obtain optimal matched samples, and optimal matching is contrasted with a commonly used alt ern at ive, greedy matching.
10.2 The Propensity Score
10.2.1 Definition of the Propensity Score
The prop ensity score is the condit iona l probability of receiving the treatment given the observed covariates x . Recall from §3.2 the mod el for treat-
ment assignment wit h 1r = prob (Z si = 1) and 0 < 1rsi < 1. For all n s

10.2 The Propensity Score 297
subjects in stratum s, define the propensity score to be
Since each 1rsi satisfies 0 < 1rsi < 1, it follows that 0 < A(Xs ) < 1 for each
s. The propensity score A(Xs ) has the following operational interpretation.
Pick a subject at random from stratum s , each subject having probability l/ns of being selected; then this random subject receives the treatment with probability A(Xs ) ' That is, pick subject (s, i) with probability l/ns , where (s,i) receives the treatment with probability 1rsi , so the marginal probability that a random subject will receive the treatment is
L ~';'l1rsdns = A(Xs ) .
The propensity score has two useful properties. The first, the more important of the two properties, was discussed in §3.2.5 and it applies when there is no hidden bias, that is, when 1r si = A(Xs ) for every s and i. If there is no hidden bias, then one need not form strata or matched sets that are homogeneous in X s ; it suffices to obtain strata or matched sets that are homogeneous in A(Xs ) ' If there is no hidden bias , if the strata are homogeneous in A(Xs ), then the conditional distribution of treatment assignments is uniform, and the statistical methods in Chapter 2 for a randomized experiment may be used ; see §3.2.5 for details. Since x , may be of high dimension, but A(Xs ) is a number, it is often much easier to find subjects with similar values of A(Xs ) than with similar values of XS ' When there is no hidden bias, when there is only overt bias due to X S , it suffices to adjust for the propensity score A(Xs ) .
The second property applies whether or not there is hidden bias ; that is, it applies even if 1r si =1= A(Xs ) . Strata or matched sets that are homogeneous in A(Xs ) tend to balance x, in the sense that treated and control subjects in the same stratum or matched set tend to have the same distribution of X S ' In an experiment, randomization tends to balance all covariates, observed and unobserved, in the sense that treated and control groups tend to have the same distribution of covariate values. In an observational study, strata or matched sets that are homogeneous in the propensity score A(Xs ) tend to balance the observed covariates X S , though there may be imbalances in unobserved covariates. The balancing property is demonstrated in the next section.
10.2.2 Balancing Properties of the Propensity Score
Pick a value of the propensity score , say A, such th at there is at least one s
with A(Xs ) = A. There may be several strata s with this same value of the propensity score, A(Xs ) = A, so write n/\ for the total number of subjects

298 10. Constructing Matched Sets and Strata

in these strata, that is,

L L nil =

n s = * n s·

. ,'\(x.)=11

where L:* denotes a sum over all 8 such that >.(xs ) = A. Pick a subject
at random from these strata; that is, pick a subject (8,i) from {(8,i) :
>.(xs ) = A} where each such subject has the same probability of being selected, namely, l/nll ' Write Z and X for the treatment assignment and
observed covariate for this random subject; that is, if the subject selected
is (8, i) then Z = Zsi and X = X s' What is the probability that Z = I? To emphasize that the probability
refers to a subject randomly selected from the nil subjects with >.(xs) = A,
write the probability as prob{Z = 1 I >'(X) = A}. If >.(xs ) = A, then the
random subject comes from stratum 8 with probability n s/nll , so

where again L:* denotes a sum over all 8 such that >.(xs ) = A. This same conclusion, prob{ Z = 1 I >'(X) = A} = A, may be expressed
in a slightly different way. If >.(xs ) = A, then subject (8, i) is selected with probability l/nll, and receives the treatment with probability lI'si; so

prob{ Z = 1 I >'(X) = A} = - 1 "Z:,:* ~ ~ 11'si = "~,* ns>'(xs) = A.

nil i=l

nil

Proposition 29 below describes the balancing property of the propensity score. It says that a treated and a control subject with the same value of the propensity score have the same distribution of the observed covariate X. This means that in a stratum or matched set that is homogeneous in the propensity score, treated and control subjects may have differing values X , but the differences will be chance differences rather than systematic differences. Again, this balancing concerns observed covariates, but unlike a randomized experiment, the propensity score does not typically balance unobserved covariates. More precisely, Proposition 29 says the following. Pick a value of the propensity score A and pick one subject at random from among the nil subjects with this value of the propensity score ; then for this subject, treatment assignment Z is independent of the value of the covariate X given the value of the propensity score >'(X) = A. The proposition is due to Rosenbaum and Rubin (1983).

Proposition 29 If >.(xs ) = A, then
prob{X = x, I >'(X) = A, Z = I} = prob{X = x, I >'(X) = A, Z = O} .

10.2 The Propensity Score 299
Proof. If 'x(xs ) = A, then by Bayes' theorem,
prob{X = x, I 'x(X) = A, Z = I} prob{Z = 11'x(X) = A,X = xs}prob{X = X s I 'x(X) = A} prob{Z = 1 I 'x(X) = A}
Now, prob{Z = 1 I 'x(X) = A,X = x,} = prob{Z 1 I X = x,} 'x(xs ) = A, and prob{Z = 1 I 'x(X) = A} = A, so
prob{X = x, I 'x(X) = A, Z = I} = prob{X = x ; I 'x(X) = A},
proving the result. ·
10.2.3 Matching or Stratifying on an Estimated Propensity Score: An Example
In practice, the propensity score 'x(x) is unknown. In this section, the propensity score 'x(x) is estimated using a logit model and the estimate is used in place of the true propensity score.
The example concerns a comparison of coronary bypass surgery and medical or drug therapy in the treatment of coronar y artery disease ; it
is from Rosenbaum and Rubin (1984). There were N = 1515 subjects, of
whom 590 were surgical patients and 925 were medical patients. The vector x contained 74 observed covariates describing hemodynamic, angiographic, laboratory, and exercise test results, together with information about patient histories. Each of these 74 covariates showed a statistically significant imbalance in treated and control groups; contrast this with the randomized experiment in §2.1.
These 74 covariates were controlled using five strata formed from an estimated propensity score. The propensity score was estimated using a linear logit model that predicted treatment assignment Z from the observed covariates x; see Cox (1970) for detailed discussion of logit models . The model included some interactions and quadratic terms selected by a sequential process described in Rosenbaum and Rubin (1984). The 1515 patients were divided into five strata, each containing 303 patients, based on the estimated propensity score. The stratum with the highest estimated probabilities of surgery contained 69 medical patients and 234 surgical patients, while the stratum with the lowest estimated probabilities of surgery contained 277 medical patients and 26 surgical patients. The theory in §1O.2.2 suggests that, had the true propensity scores been used in place of estimates, medical and surgical patients in the same stratum should ha.ve similar distributions of the 74 observed covariates.
Table 10.1 shows the imbalance in five of the 74 variables before and after stratification on the propensity score. The column labeled "Before" contains the square of the usual two-sample t-statistic, that is, the F-ratio,

300 10. Constructing Matched Sets and Strata

TABLE 10.1. Covariate Imbalance Before and After Stratification: F-Ratios.

Covariate

Before

After: Main Effect

After: Interaction

Abnormal LV Contraction 51.8

0.4

0.9

Progressing Chest Pain

43.6

0.1

1.4

Left Main Stenosis

22.1

0.3

0.2

Cardiomegaly

25.0

0.2

0.0

Current Nitrate Treatment 31.4

0.1

2.2

comparing the means of each variable among medical and surgical patients. The values in this column are large indicating the medical and surgical patients exhibit statistically significant differences on each of these variables, and in fact on each of the 74 covariates. The last two columns give F-ratios from a two-way 2 x 5 analysis of variance performed for each variable, the two factors being medical versus surgical and the five propensity score strata. The column labeled "After: Main Effect" is the F-ratio for the main effect of medical versus surgical. The column labeled "After: Interaction" is the F -ratio for the two-way interaction. None of the F-ratios in Table 10.1 is significant at the 0.05 level, and most of the F-ratios are less than one, so there is no indication of systematic imbalances in these covariates. For all 74 covariates, only one of the 2 x 74 = 148 F-ratios was significant at the 0.05 level. In a randomized experiment, 0.05 x 148 = 7.4 F-ratios significant at 0.05 would have been expected by chance alone. Evidently, these 74 observed covariates are more closely balanced within strata than would have been expected in a randomized experiment with five strata. However, randomization would balance both observed and unobserved covariates, while stratification on the propensity score cannot be expected to balance unobserved covariates.
In this case, a fairly coarse stratification on an estimate of the propensity score did tend to balance 74 observed covariates. Using these five strata, the medical and surgical patients were compared with respect to outcomes such as survival and pain relief. Adjusting for the five strata, there was little or no difference in survival. See Rosenbaum and Rubin (1984) for detailed results.

10.2.4 Propensity Scores with Doses of Treatment
Propensity scores have been described for the case of a treated group compared to a control group. When, instead, there are several doses of treatment, the propensity score may be generalized in either of two directions . Suppose in this section only that the treatment Z can take values 1,2, . . . , K . In the first generalization, the propensity score remains a scalar function of covariates, so that matching and stratification on the scalar propensity score proceed as for two treatment groups; see Joffe and

10.2 The Propen sity Score 301

Rosenb aum (1999). In the second approach, each of t he K levels of th e treatme nt Z requires it s own prop ensity score , and strata form ed from differ ent propensity scores are not compa rable; see Imb ens (2000) and Rosenbaum (1987). The first generalizat ion is somewhat easier to use, but t he second requires fewer ass umptions. A brief outline of t he two generalizat ions follows.
Suppose the levels of Z are ordered or ordinal, so Z = k + 1 is a higher
dose of t reat me nt than Z = k for each k. A common model for a condition al distribution of an ordina l vari able given a vector x of covariates is McCull agh's (1980) ordinal logit model, nam ely:

log

{

Pr Pr

(Z (Z

<2':

klx) klx)

}

=

Ok

+

T
{3

x

for k = 2,3, ... , K.

(10.1)

Notice that if Z were converted into a binary variable B indi cating whether
Z 2': k, recorded as B = 1, or Z < k, recorded as B = 0, then und er model
(10.1) , the binary variable would sat isfy a binary logit mod el,

log {

Pr (B Pr (B

==

11x) Olx)

}

= Ok

+

T
{3

x

,

a nd that as k changes, only the const ant t erm Ctk changes. See McCullagh (1980) for detailed discu ssion of th e attracti ve features of this model. When model (10.1 ) correctl y describ es Pr (Z lx) , the scalar {3Tx has essent ially the same properties as th e propensity score for two groups . In particular, matching or st rat ifying on {3Tx tends to balan ce x in the K dose groups. The import ant issue is that the ent ire distribution Pr (Zl x) is linked t o x only through a sca lar {3T x . Other models for Pr (Zl x) with thi s
prop erty behave similar ly; see Joffe and Rosenbaum (1999) for discussion. In pract ice, one estimates {3 by maximum likelihood , and mat ches on th e
~T
est imate d score, {3 x ; see Lu , Zanutto, Hornik and Rosenb aum (2002) for an exa mple.
The second generalization fits K separate propensity scores, Pr (Z = klx ), k = 1,2, . . . ,K. These K scores are used one at a time to adjust the responses of subjects who received dose Z = k to yield an estimate of the distribution of responses that would have been observed had all subjects received dose Z = k. These K adjusted distributions are then compared. See Imbens (2000) and Ros enbaum (1987) for two asp ects of this approach.
By est imat ing Pr (Z = klx) separately for each k, it is not necessary to as-
sume that Pr (Zlx) follows a particular model, such as (10.1) , so thi s second ap proach is somewhat more general. On the other hand, the K different propensity scores have little to do with one another. For instance, a person
having Pr (Z = I jx) = 1/4 has nothing in particular in common with a per-
son having Pr (Z = 31x) = 1/4, so there is no basis for matching these two
people together, or placing them together in the same st rat um. In other words, although the second approach is applicable in more circumstances, it preserves fewer of the convenient properties of the pr op ensity score.

302 10. Constructing Matched Sets and Strata
TABLE 10.2. Matching and Structure: Hypothetical Population with 2800 Subjects.
x=O x=1 x=2 Treated 100 200 100
Control 2000 300 100
10.3 Optimal Strata
10.3.1 The Importance of Structure: Intuition
The structure of a matched or stratified comparison refers to constraints imposed on the number of controls that are matched to a treated subject. Pair matching, where each treated subject has its own single control, is one structure. Matching each treated subject to two controls is an alternative structure. Matching each treated subject to at least one and at most four controls is yet another structure, called variable matching. Full matching is the structure in which each matched set contains either one treated subject and one or more controls, or else one control and one or more treated subjects. In an unconstrained stratification, each stratum may have any nonnegative number of treated and control subjects, perhaps zero.
Statistical theory, simulations, and case-studies demonstrate that structure strongly affects the ability of matching and stratification to remove biases due to observed covariates, that is, to compare people who look comparable. Before considering the subject in detail, §§1O.3.1 and 10.3.2 develop some intuition using hypothetical and actual examples.
Highly constrained forms of matching may fail to remove all of the bias due to observed covariates, whereas less constrained forms might succeed, and this remains true as the sample size increases. To see this, consider a simple hypothetical example. In the population before matching, there is one observed covariate at three levels, and its relationship to the treatment is given in the contingency Table 10.2. Notice that an exact pair matching of all 400 treated subjects is just barely possible here. However, if one matches each treated subject to two controls, obtaining 800 controls in
total, then there are not enough controls with x = 2 or x = 1 to go
around, and one might end up with 100 treated-control-control triples with covariate x triples (2,2,1), 200 triples with (1,1,0), and 100 triples with (0,0,0) . Many matched individuals have different values of the covariate x. Notice that the situation would not improve if all of the counts in Table 10.2 were doubled: a uniform increase in sample size does not make matching easier. On the other hand, if one matched each treated subject to at least one control and at most four controls, then one might have 100 treated-control pairs with covariate x pairs (2,2) , 100 pairs with (1,1), 100 treated-control-control triples with covariate x triples (1,1,1), and 100 matched sets of a treated subject and four controls with covariates x given by (0,0,0,0,0) , so each treated subject is compared to controls with the

10.3 Optimal Strata 303
TABLE 10.3. Matching and Structure: A Population in Which Even Pair Matching Is Not Possible .
x=O x=l x=2 Treated 100 200 100 Control 2000 300 50
same x , and there are still 800 controls in total. In this example, with a scalar x, the two matching procedures select the same controls but use them differently; however , with a vector x , this would no longer be true.
The situation in Table 10.3 is more difficult . There is no way to exactly
match the 100 treated subjects with x = 2 to 100 distinct controls; even pair
matching is not possible here . Although there is no exact pair matching of 400 treated subjects to 400 controls, a full matching of this size is possible . It might contain 50 treated-treated-control triples with covariate x triples (2,2,2), 150 treated-control pairs with (1,1), 100 pairs with (0,0), and 50 treated-control-control triples with (1,1,1).
In principle, when observations are available without cost , full matching can use all available observations. In Table 10.3, one might select 50 treated-treated-control triples with covariates x triples (2,2 ,2), 100 matched pairs with (1,1) , 100 matched treated-control-control triples with (1,1,1) , and 100 matched sets with one treated subject and 20 controls all having covariate values O. Because x takes just three values in Table 10.3, there would be no gain from subdividing the table into matched sets. However, in practical problems, x is a vector , often containing some continuous variables, and the matched sets would be more nearly homogeneous in x than a coarser stratification would allow; see §1O.3.6.
Unconstrained stratifications are sometimes useful, but special methods are needed when some cells have zero frequencies; see Rosenbaum (1987) for detailed discussion. In the discussion of constructing strata and matched samples in this chapter, zero frequencies are avoided.
10.3.2 The Importance of Structure: Death After Surgery
To illustrate the importance of structure in a practical example, several matched samples with different structures are compared using pilot data for a case-referent study of the causes of death after surgery in the Medicare population. This section is based on an example in Ming and Rosenbaum (2000) . The complete study examines more than 800 deaths randomly sampled from Medicare deaths following surgery at all Pennsylvania hospitals; see Silber, Rosenbaum, Trudeau, Even-Shoshan, Chen, Zhang, and Mosher (2001) and Rosenbaum and Silber (2001). The study attempts to compare patients who were in similar condition upon entering the hospital in the hope of learning about preventable causes of death during the hospital stay. Patients are matched on the basis of coarse computerized records

304 10. Constructing Matched Sets and Strata

TABLE 10.4. Optimal Matching with Three Controls: Risk Scores for the First

Five Matched Sets. Source : Ming and Rosenbaum (2000).

Set Death

Survivors

1 0.034 0.034, 0.034, 0.034

2 0.274 0.141, 0.114, 0.104

3 0.227 0.194,0.158,0.150

4 0.024 0.024, 0.024, 0.024

5 0.485 0.439, 0.198, 0.155

from Medicare. For matched patients, the hospital chart is abstracted in detail, an extremely expensive process.
Using data from one hospital, the pilot data describe 38 eligible patients who died following simple surgical procedures in 1993 and 1994, and 685 eligible patients who did not die. In the pilot, using data from earlier years, a baseline risk of death was estimated using a logit model, and the coefficients of this model were then used to score patient risk , and formed the basis for the matching. A score of 0.1 means that the logit model from earlier years estimated the risk of death upon admission to be 10%. The final matching uses this risk score in a more complicated matching algorithm described in Silber et al. (2001) . Before matching, the 38 deaths had a mean risk score of 0.152 and a standard deviation of 0.132 , and the 685 survivors had a mean risk score of 0.037 and a standard deviation of 0.050, so the patients who went on to die appeared at much greater risk at the time of admission.
Table 10.4 gives the risk scores for the first five of 38 matched sets when each death is matched to three referents who did not die, 3 x 38 referents in total. Although matched sets 1 and 4 are closely matched, many of the other matches are quite poor. For example, in matched set 5, the death was estimated to have a 0.485 chance of death upon admission, and one of the matched referents had only a 0.155 estimated chance of death. The poor matches are due to the unreasonable insistence that every death have three matched referents, even though there are not enough high risk survivors to go around.
Table 10.5 shows the same five deaths when each death is matched to at least one and at most four referents, with 3 x 38 referents in total. Here, matched patients have similar risk scores .
This example and associated theory are considered in detail in Ming and Rosenbaum (2000). In particular, they show that: (i) the pattern for the first five matched sets in Tables 10.4 and 10.5 applies generally to the 38 matched sets; (ii) that matching with between 1 and 4 referents removed 22% more bias than matching with three referents, and produced only a slight increase in the standard error; and (iii) that these patterns are consistent with general theory.

10.3 Optimal St rata 305

TABLE 10.5. Opt imal Matchi ng with One to Four Controls: Risk Scores for t he

F irst Five Matched Sets. Source: Ming and Rosenbaum (2000) .

Set Death

Surv ivors

1 .034 .034, .034, .034, .034

2 .274

.216

3 .227

.218

4 .024 .024, .024, .024, .024

5 .485

.439

The matchings described in t his section are optimal in t he sense described later in §1O.4. T his means: t hey minimi zed t he to tal absolute differ ence in risk scores over all matchings with the given size and st ruc t ure . The opt imal mat ching was perform ed in SAS; see Ming and Rosenbaum (2001) a nd §10.6.

10.3.3 Evaluating Stratifications Based on the Average Remaining Distance
Sect ion 10.3.6 characte rizes t he form of an optimal st ratificatio n. Optimality is defined in t erms of a dist ance between each trea ted subject and each control, and the goal is a stratificat ion that minimi zes a weighte d average of t he dist an ces wit hin each strat um. Und er mild conditions, t he optima l st ratification has a simple form developed in §10.3.6.
Init ially, t here are two sets of subjects: t he t reated subjects are in a set
A a nd t he controls are in a set B , wit h A n B = 0. The init ial number
of t reated subjects is IA I and the number of cont rols is IBI, where I . I
denotes t he number of eleme nts of a set . For each a E A and each b E B , ther e is a distance , Dab wit h 0 ~ Dab ~ 00. The distance measures the di fference between a a nd b in te rms of their observed covariates, say x ., and Xb; however , it need not be a distance in t he sense used to define a metric space, an d it is not requir ed to have any pr oper ties bes ides being
nonnegative. An infinite distance, Dab = 00 , indicates t hat X a and X b ar e
so different that it is forbidden to place a and b in the sa me strat um. The nature of the distan ce Dab is not important in characterizing the form
of an optimal stratification . Many dist ances have been proposed . Cochran and Rubin (1973) cons ider the following dist ances:
(i) the cate gorical dist anc e, if X a = Xb , then Dab = 0, ot herwise Dab = 00;
(ii) calipe r distance, if IXaj - XbjI ~ Cj for each coordinate j of x , then Dab = 0, otherw ise Dab = 00, where t he Cj are given constants;
(iii) qu adratic dist an ces, Dab = ( x a - X b )TD(xa - X b ) for some matrix D ,
including the Ma ha lanob is dist ance in which D is the inverse of a samp le var iance-covariance matrix of the x 's; an d

306 10. Constructing Matched Sets and Strat a
(iv) th e squared difference along a linear discriminant.
See also Carpenter (1977) and Rubin (1980) for discu ssion of the Mahalanobis distance. Smith, Kark, Cassel, and Spears (1977) st andardized the coordinates of x and t ake Dab equal to the squared length of the standardiz ed difference x, - X b; th is is a quadratic distance with D equal to a diagonal matrix of reciprocals of sample variances. Simil ar measures have been defined with th e coordinates of x replaced by their ranks. Rosenbaum and Rubin (1985) define three dist ances that use th e propensity score and ot her coordinates of x . Again , th e nature of the distance is not important in §§10.3 and 10.4.
A stratification (A I, . . . , A s ;BI, .. . , Bs) with 5 st rata consist s of 5 nonempty, disjoint subset s of A and 5 nonempty, disjoint subsets of B , so IAsl ~ 1, IBsl ~ 1, A s n A s, = 0 for s =I- s', B, nBs' = 0 for s =I- s' ,
At U .. . U As ~ A , and B t U .. . U B s ~ B. For s = 1, . . . ,5, stratum
s consists of the treated units from A s, and the controls from Bi, Notice that a stratification may discard some units; that is, it may happen that
IAi U· · · U Asl < IAI or IBt U··· U Bsl < IB I. Write 0: = IAt U·· · U Asl
and {3 = IBt U . .. U B sl , so the stratification includes 0: treated units and {3 controls, and call (0:, {3) th e size of the stratification.
A pair matching is a stratification (At , . . . , A s ; B t , .. . , B s) in which
IAsl = IBs l = 1 for each s. A matching with multiple controls is a st rat ifica-
tion (AI, .. . , As ; BI, , B s) in which IA sl = 1 for each s. A full matching
is a st ra t ificat ion (A I, , A s; B I, . .. , Bs) in which min( IAs l, IBs D = 1 for
each s , so a stratum consists of a single treated subject and one or more controls or else a single control and one or mor e treated subjects.
10.3.4 A Small Example: Nuclear Power Plants at New and Existing Sit es
As an illustration, Table 10.6 describes 26 light water nucl ear power plants built in the United States. The data are due to W. E. Mooz and are reported by Cox and Snell (1981). Seven of these plants were built on the site of an existing nuclear plant; they are plants A = {3, 5, 9,18,20,22, 24} and they form the columns of the t able. The other nineteen plants were built at a new site; they are
B = {1,2,4,6,7,8, 10, 11, 12, 13, 14, 15, 16,17, 19,21 ,23,25,26}
and they form the rows of the table. The numerical labels in A and B correspond to those used by Cox and Snell (1981). Excluded are six "par t ial turnkey" plants whose costs may contain hidden subsidies. The comparison of interest is the cost of plants built at new or existing sites, adjusting for covariates related to the cost. The example is intended solely as a small illustration of matching and st rat ificat ion.

10.3 Optimal Strata 307

TABLE 10.6. Covariate Distances Between Plants Built at a New Site (Rows)

and Plants Built at an Existing Site (Columns) . An Asterisk (*) Signifies a Plant

Built in the Northeastern U. S.

ID#

3 *5 9 18

*22 24

*1 28 24 10 7 2 ~18 28
*4 ~14 24

20 14 31 32 28 29

*6 22 22 18 8

7 14 [JQJ 4 14

8

30 27~

35 30 20 18 29 24

*10

17 14~

22 17

11 28 26 11 6

20 16

*12 26 24 9 12

14 9

13 28 24 10 0

26 22

14 20 16 14 '--=-24":;"'+----::--' 12 12

15 16

22 19 12 22

9 10

IT! 23 20

4 20 22 17

*17

26 23 14 24 6~ 6

19 21 18 22 32 7 15 16
21 Q!] 16 10 20 4 12 14

23 34 31 16 18 14 9 4

25 40 37 22 16 20 11 8

26 28 25 28 38 14 12 17

308 10. Constructing Matched Sets and Strata
The covariate x is two-dimensional and gives the year the construction permit was issued and the capacity of the power plant. The values in the table are distances Oab between power plants with a E A and b E B . The distance is formed as follows. The two covariates in x were ranked separately from 1 to 26 with average ranks used for ties . Then Oab is the sum of the absolute values of the two differences in ranks for x., and xs . For instance, 03,2 = 0 because plants 3 and 2 were started in the same year and had the same capacity, so their year covariates and their capacity covariates were each assigned the same tied rank, and the sum of the absolute differences in their tied ranks was zero.
The boxed distances describe a matching that is optimal among all matchings in which each plant in A is matched to two plants in B . For instance, plant 3 is matched to plant 2 and plant 21. Notice that plant 4 is better than plant 21 as a match for plant 3, but if plant 4 were matched to plant 3, then plant 5 would not receive its best match. The match described by the boxes is optimal in that it minimizes the total distance within pairs among all matchings with two controls. The construction of an optimal matching is discussed in §10.4.
To illustrate the notation in §10.3.3, the optimal match in Table 10.6 is the stratification of size (0:, f3) = (7,14) with S = 7 strata (AI , . . . , A7 ; Bi , . . . ,B7 ) =({3},{5}, . . . ,{24} ; {2,21},{4,7} , .. . ,{23,25}) ,sothefirst stratum consists of Al = {3} together with B l = {2, 21}. The goal in §1O.3 is to characterize optimal stratifications, and in §10.4 to construct them.
10.3.5 Evaluating Stratifications Based on the Average Distance Within Strata
A good stratification would place similar subjects in the same stratum. The distances between treated and control subjects in the same stratum would be small. Let o(As, Bs ) be the average of the IAsl x IBsl distances
Oab with a E As and b E Bs. For instance, in Table 10.6, o(AI, B l ) = 0({3}, {2,21}) = (03 ,2 +03,21)/2 = (0+ 18)/2 = 9. If IA.. I = 2 and IBsl = 5
then o(As , Bs ) would be an average of 10 distances. To find an optimal stratification, a numerical criterion is needed that
evaluates a stratification (AI, . . . , As ; BI, .. . , Bs), combining the S dis-
tances o(As , Bs ) , s = 1, ... , S into a single number. For this purpose, in-
troduce a weight function, w(·, .). The distances within the S strata will be combined with weights w(IA sl, IBsl), so the weights are a function of the sizes of the treated and control groups within each stratum. The weight function w(· , ·) is assumed to be strictly positive and finit e, and it is defined for strictly positive integer arguments. Define the distance ~ for a

10.3 Optimal Strata 309
stratification (AI, .. . , As; Bs ., » , ,Bs) to be
Ls
~ = w(IA sl, IBsl) 8(As, Bs)'
s=l
There are several natural choices of weight function. Let the stratification (AI, .. . , As; B l , . . . ,Bs) be of size (0:, {3) . One weight function is w(IA sl, IB sl) = IAsl/o:; that is, the weight is the proportion of the 0: treated subjects who fall in stratum s . In this case, ~ has a simple interpretation. From the stratification, pick one of the 0: treated subjects at random, and pick a control at random from the stratum containing the selected treated subject; then ~ is the expected distance between these two subjects. An-
other weight function is w(IA sl, IBsl) = IBsI/{3 with a similar interpretation. Still another weight function is w(IA sl, IBsl) = (IA sl + IBsl)/(o: + {3) . With this weight function, pick one of the 0: + {3 subjects at random and
pick a comparison subject at random in the same stratum but from the other treatment group; then ~ is the expected distance between these
subjects. For these three weight functions, 1 = L w(IAsl , IBsl), so ~ is
truly a weighted average of the 8(As , Bs ) ' A different weight function is
w(IAsl,IBsl) = IAsl x IBsl; then ~ is the total of all distances within
strata. Distinguish three types of weight function. They are defined in terms
of the impact of removing a pair of subjects from one stratum to form a new stratum comprised of just that pair. Does the total weight increase, decrease, or stay the same when a pair is separated? A weight function
favors large strata if w(p, q) < w(p - 1, q - 1) + w(l, 1) for all integers
p 2: 2, q 2: 2, it favors small strata if w(p, q) > w(p-1 , q -1) +w(l , 1), and
it is neutral if w(p , q) = w(p - 1, q - 1) + w(l , 1). A weight function that
favors large strata increases the total weight when a pair is separated, so there is a penalty for increasing the number of strata, increasing ~ even if the distances are not changed. Similarly, a weight function that favors small strata creates a reward for increasing the number of strata. A neutral weight function neither rewards nor penalizes the creation of additional strata.
The three weight functions IAsl/o:, IBsI/{3, and (IAsl + IBsl)/(o: + {3) are
all neutral, while the weight function IAsl x IBsl favors small strata.
Notice that ~ = 00 if there is a stratum s and a pair of subjects a E As
and b E B; with 8ab = 00. In words , if a comparison of a and b is forbidden, then placing a and b in the same stratum yields a stratification with an infinite distance ~. If ~ = 00 call the stratification unacceptable, but if ~ < 00 call it acceptable.
10.3.6 The Structure of Optimal Strata
Consider a fixed data set, a fixed size (0:, {3) for the stratification, and a fixed weight function w( ·, .). A stratification of size (0:,{3) and distance ~

310 10. Constructing Matched Sets and Strata
is optimal if there is no other stratification of size (0:, (3) with a strictly
smaller distance. It may happen that tJ. = 00 for an optimal stratification,
but in this case there is no acceptable stratification. A refinement of a stratification (AI , . . . , As ; B ll . .. ,Bs) is another
stratification (AI, . . . ,As; s., ... ,Sf;) of the same size with 5 ~ S such
that for each S, S = 1, .. . ,5, there exists an s such that As ~ A s and Sa~ B s . In other words, a refinement subdivides strata.
The following proposition says that if there is no penalty for creating additional strata, then any stratification can be refined into a full matching which is as good or better. Recall that all of the weight functions discussed in §1O.3.5 were either neutral or favored small strata. Proposition 30 is proved in the Problems in §1O.7 and in Rosenbaum (1991).
Proposition 30 Consider a weight function w( ·, .) that is either neutral or favors small strata. lfthe stratification (AI , ... , As; B ll . . . , Bs ) has distance tJ.o and is not a full matching, then it has a refinement which is a full matching and has distance no greater than tJ.o.
For weight functions that are neutral or favor small strata, Proposition 30 has several consequences. First, if there is an acceptable stratification of size (0:, (3), then there is an acceptable full matching of size (0:, (3) . Second, for each fixed size (0:,(3), there is a full matching that is an optimal stratification . In searching for an optimal stratification, it suffices to confine the search to full matchings because one of them is sure to be optimal. As will be seen in §10.3.7, neither statement is true for pair matching or for matching with multiple controls.
Under the conditions of Proposition 30, it can happen that the refinement is only as good as the original stratification, but no better. For this to happen, the distances {jab must satisfy a large number of linear equations. This will often happen when there are many distances {jab that are equal to zero. However, it may be shown that if the covariates x came from a multivariate normal distribution and the distance is the Mahalanobis distance, then with probability one the equations will not be satisfied, and the full matching will be strictly better than the original stratification. In other words, in the multivariate norm al case, with probability one , a stratification that is not a full matching is not optimal. For proof, see Rosenbaum (1991, §4).
10.3.7 Pair Matching Is Not Optimal
Unlike an optimal full matching, an optimal pair matching is not generally an optimal stratification. The distance matrix in Table 10.7 demonstrates
this. There are IAI = 3 treated subjects, A = {a ,b ,c}, IBI = 3 controls,
B = {I, 2, 3}, and the distances take two values , W > E.

10.4 Optimal Matching 311
TABLE 10.7. Hypothetical Distance Matrix.
A abc 1e eW B 2wW  3wW e
For the neutral weight function w(IAsl, lB..!) = (IAsl + IBs!)/(a: + {3),
the optimal stratification and optimal full matching is (AI , A2 ; B I, B2 ) =
({a,b} ,{c}; {1},{2,3}) with distance ~ = (3+3)/6 = . The optimal
pair matching is (AI,A2 ,A3 ; B I,B2,B3 ) = ({a}, {b},{c} ; {1},{2} ,{3}) with distance (2 + 2w + 2)/6 > e. By letting w increase, the difference
between optimal full matching and optimal pair matching may be made arbitrarily large.
In the same way, the optimal matching with multiple controls is not generally an optimal stratification.
10.4 Optimal Matching
10.4.1 Greedy Matching Versus Optimal Matching
In §lO.4, the task is to build a matched sample from a' matrix of distances 8ab between treated subjects a E A and controls b E B. Various types of matching are considered, including pair matching, matching with multiple controls, balanced matching, and full matching. Here, optimal refers to minimizing the total distance within matched sets .
The first impulse is to use what is known as a greedy algorithm. A greedy algorithm divides a large decision problem into a series of simpler decisions each of which is handled optimally, and makes those decisions one at a time without reconsidering early decisions as later ones are made . One greedy algorithm for matching finds the smallest distance 8ab, for a E A and b E B , calls this (a, b) the first matched pair, removes a from A and b from B , and repeats the process to find the next pair . Greedy algorithms do solve a small class of problems optimally, but the matching problem is not a member of that class.
In principle, greedy can perform very poorly as a matching algorithm. To see this, consider the distance matrix in Table 10.8 with two treated
subjects and two controls, where e is finite. Greedy pairs a with 1 at a cost
of 0 and then is forced to pair b with 2 at a cost of 00. The optimal match pairs a with 2 and b with 1 for a cost of 2. In principle, greedy can be arbitrarily poor compared to optimal matching.
The situation in Table 10.8 is not far-fetched when some pairings are forbidden through the use of infinite distances, as is true with category

312 10. Constructing Matched Sets and Strata

TABLE 10.8. A Small Distan ce Matrix. A

a

b

10

B

- - -2 -E- - - -

matching and caliper matching. Suppose one were matching on age , requiring matched pairs to have ages that differ by less than five years. As with the caliper distance in §10.3.3, there is an infinite distance 8 for any pair whose ages differ by more than five years; however , if the age difference is less than or equal to five years, the distance is the absolute difference in ages. If 1 and a are both 50 years old , 2 is 47 years old, and b is 53 years old , then Table 10.8 results with E = 3. Greedy would pair the 50-year olds, and then it would have no acceptable match for the 53-year old . There are also theoretical results suggesting greedy can be very poor in large problems. See, for instance, Walkup (1979) and Snyder and Steele (1990) . In §1O.4.7, greedy and optimal matching are compared by simul ation when covariates are multivariate normal.
If greedy were used to match each treated plant to two controls in Table 10.6, it would begin by pairing plant 3 to plant 2 at a cost of 83,2 = 0 units
of distance, then plant 5 to 4 at a cost of 85 ,4 = 0, and so on . Table 10.9
compares greedy and optimal matching step by step. In Table 10.9, greedy does well at the beginning wh en there is little
competition for controls. In selecting the first 11 pairs, greedy and optimal matching have selected the same pairs and produced the same tot al distance. At Step 12, greedy misses a small opportunity because it never reconsiders previous decisions. Greedy adds the pair (22,26) at a cost of 822,26 = 12 units of distance. Instead, at Step 12, optimal matching deleted pair (20,15) and added pairs (20,21) and (22,15) at a cost of
-820,15 + 820,21 + 822,15 = -2 + 4 + 9 = 11. As the final matched pairs
are selected and the competition for controls intensifies, greedy misses additional opportunities. In the end, the greedy match gives a total distance
(79 - 71)/71 = 11% higher than necessary.
This figure, 11%, refers to this one example, and should not be antici-
pated in general. Greedy performs poorly when there is intense competition for controls and it performs well when there is little competition. There is, however, no reason to use a greedy algorithm. Fast optimal algorithms are widely available ; see §1O.6.

10.4 Optimal Matching 313

TABLE 10.9. Step-By-Step Comparison of Greedy and Optimal Matching.

Gr eed y

Optimal

St ep

Add Dist an ce

Delet e

Add Dist an ce

1 (3,2)

0

(3,2)

0

2 (5,4)

0

(5 ,4)

0

3 (18 ,13)

0

(18 ,13)

0

4 (20,14)

0

5 (18,8)

2

(20,14) (18 ,8)

°2

6 (20,15)

4

(20,15)

4

7 (9,7)

8

(9 ,7)

8

8 (24,23)

12

(24,23)

12

9 (22,17)

17

(22,17)

17

10 (9,10)

22

(9 ,10)

22

11 (24,25)

30

(24,25)

30

12 (22,26)

42

(20,15) (20,21)

41

(22 ,15)

13 (5,21)

58

(9,7) (9,16)

52

(5 ,7)

14 (3,19)

79

(22,15) (22,26)

71

(20,21) (20,15)

(3 ,21 )

10.4.2 Optimal Matching and Minimum Cost Flow in a N etwork
Optimal matching is known to be equivalent to finding a minimum cost flow in a certain network, a problem that has been exte nsively st udied a nd for which good algorit hms exist . The curre nt sect ion sketches a few of the general ideas about network flow. These ideas are applied to matching problems in subsequ ent sect ions. One can , of course, use optimal matching without understanding network optimization, just as one can fit a logit model without understanding nonlinear optimization. An at t rac t ive, detailed, modern discussion of this subject is given by Bertsekas (1991) ; he also provides computer code in an App endix and the code may be downloaded from a website. See also Ahuja, Magn anti, and Orlin (1993), P apadimitriou and St eiglitz (1982) , Tarjan (1983) , and Rockafellar (1984).
A network is a directed graph, that is, a set V of vertices and a set E of dir ected edges consisting of ord ered pairs of elements of V . Lat er the vertices in the set V will include subjects available for matching, that is, V will contain Au B , and the set E of edges will include an edge (a, b) with
a E A and b E B if a may be matched to b, that is, if {jab < 00 . However,
at times it will be convenient to include in V and E certain other vertices and edges, so for the moment V is any set of vertices and E is any set of ordered pairs of element s of V . A network (V, E) is depicted by dr awing

314 10. Constructing Matched Sets and Strata

a dot for each vertex v E V, and for each edge e = (VI , V2) E E an arrow from vertex VI to vertex V2.
As an illustration, Figure 10.1 is a network for the matching problem in Table 10.8, The four vertices are V = {a, b, 1, 2} and the three edges are E = {(a, 1), (a,2),(b, I)}. There is no edge (b,2) because Db2 = 00, so b cannot be matched to 2.
b -+ 1
/
a -+ 2

Vertices V = {a, b, 1, 2} Edges E = {(a, 1), (a, 2), (b, I)}

FIGURE 10.1. Matching network for table 10.8.

Network flow theory was originally concerned with the movement of material from one vertex to another along the edges. One might think of a railroad network or a telephone network: A flow in a network assigns a number FLOW(i,j) to each edge (i ,j) E E signifying that FLOW(i,j) units of material are to flow from vertex i to vertex j directly across edge (i,j). Network flow optimization finds the best flow for all (i,j) E E subject to various requirements. Each edge (i, j) must carry at least MIN (i, j) units of flow and at most MAX(i,j) units of flow, that is, MIN(i ,j) ::; FLOW(i,j) ::; MAX(i,j) for all (i,j) E E, where MIN(i,j) and MAX(i,j) are given numbers for each (i ,j) E E . For each vertex i E V , the divergence is the total flow out from i minus the total flow into i j that is,

L L DIV(i) =

FLOW(i,j) -

FLOW(k, i).

j :(i,j)EE

k :(k,i)EE

If there were a warehouse at vertex i , then DIV(i) > 0 would signify that the stock in the warehouse is being depleted, DIV(i) < 0 would signify that
stock is building up , and DIV(i) = 0 would signify that stock is arriving and leaving at the same rate. There are specified limits on the divergence at each vertex, DMIN(i) ::; DIV(i) ::; DMAX(i).
Shipping a unit of flow from i to j along (i ,j) costs COST(i ,j) . The total cost of a flow is I:(i,j)EEFLOW(i,j) COST(i ,j) . The minimum cost
flow problem is to find a flow, FLOW(i,j) for (i ,j) E E, which minimizes the total cost subject to the constraints, that is,

L minimize

FLOW(i,j) COST(i,j),

(i,j)EE

(10.2)

subject to

MIN(i ,j) ::; FLOW(i,j) < MAX(i,j) for all (i ,j) E E ,

IDA Optimal Matching 315
and
s DMIN(i) ~ DIV(i) DMAX(i) for i E V.
See Bertsekas (1991, Exercise 1.6, p. 19) for discussion of the relationship between this definition of the minimum cost flow problem and other equivalent definitions.
An integer flow is a flow in which FLOW(i,j) is an integer for each (i ,j) E E . Integer flows arise naturally when it is impossible to divide a unit in half for shipping. Also, in matching problems, only integer flows make sense because whole units must be matched. If all of the capacity constraints, MIN(i,j) , MAX( i,j), DMIN(i), and DMAX(j) , are integers, then whenever there is a minimum cost flow there is also an integer minimum cost flow (e.g., Tarjan (1983, p. 110)). Notice that the costs COST(i,j) need not be integers. Throughout this chapter, MIN(i,j) , MAX(i ,j), DMIN(i), and DMAX(j) are integers, and the solution to the minimum cost flow problem is assumed to be one of the integer solutions. This happens automatically with commonly used algorithms.
Good algorithms exist for solving the minimum cost flow problem . In particular, there is an algorithm for optimal matching which requires computational effect that grows no faster than the cube of the number of subjects to be matched; see Papadimitriou and Steiglitz (1982, Theorem 11.1, p. 250) or Tarjan (1983, Theorem 8.13, p. 110). For comparison, the conventional way of multiplying two square matrices with one row per subject requires effort that grows as the cube of the number of subjects. In other words, the rate of growth in the difficulty of these two problems is similar . Bertsekas (1991, §5) compares the performance of several algorithms on a Macintosh Plus computer. In particular, with his favored algorithm for pair matching, he reports solving in less than six seconds optimal pair matching problems with 5000 treated subjects, 5000 controls, and 25,000 permitted
matched pairs (i.e., IAI = 5000, IBI = 5000, lEI = IHa,b) : a E A, b E B,
bab < 00}1 = 25,000) .
The remainder of §1O.4 indicates how to set up various matching problems as minimum cost flow problems. Once cast as minimum cost flow problems, available algorithms provide optimal solutions.
10.4.3 Matching with a Fixed Number of Controls
In matching with a fixed number of controls, each of the treated subjects in A is to be matched with a fixed number, say k ;::: 1, of controls from B to
minimize the total of the klAI distances between treated subjects and their
matched controls. This becomes a minimum cost flow problem with the following identifications. An alternative approach is discussed in Problem 9.
The vertices are the subjects, V = A U B . The edges link treated subjects to controls for which the distance is finite, E = {(a,b) : a E

316 10. Constructing Matched Sets and Strata
A ,b E B,{jab < oo}. See Figure 10.1. The cost is simply the distance, COST(a, b) = {jab for all (a, b) E E . The bounds on the flow are MIN(a, b) =
o and MAX( a, b) = 1 for all (a, b) E E . The bounds on the divergences
are DMIN(a) = DMAX(a) = k for all a E A, and DMIN(b) = -1,
DMAX(b) = 0 for all b E B. Suppose that there is an integer flow FLOW(a , b) that satisfies the
constraints in (10.2). Since MIN(a, b) = 0 and MAX(a, b) = 1 and the
FLOW(a, b) is an integer, it follows that FLOW(a, b) = 0 or FLOW(a, b) =
1 for all (a,b) E E . Since DMIN(a) = DMAX(a) = k , it follows that for
each a E A, FLOW(a , b) = 1 for exactly k subjects b E B . Also , since
DMIN(b) = -1 and DMAX(b) = 0, for each b E B , there is at most one
a E A such that FLOW(a, b) = 1. In other words, a flow satisfies the
constraints if and only if {(a,b): FLOW(a,b) = I} is a matching of each treated subject to exactly k controls. A minimum cost flow is a matching that minimizes the total distance among all matchings that assign k controls to every treated unit. If no integer flow satisfies the constraints, then there is no acceptable matching with k controls, where an acceptable matching was defined in §1O.3.5.
The boxed power plants in Table 10.6 are an optimal match with k =
2 controls; see also Problem 11. Notice that there is competition among treated plants for the same control. For instance, control 7 was matched to treated plant 5 at a distance of {j5,7 = 10, though 7 is closer to plant 9, and so on. See also Table 10.9.
10.4.4 Matching with a Variable Number of Controls
An alternative to matching each treated subject a E A to k controls bE B is to require each treated subject to have at least km in controls and at most km ax controls, with a total of h controls in the matched sample. In this case, the optimization chooses the best number of controls for each treated subject. To produce a matching, the parameters km in , km ax , and h should
satisfy km in ~ 1 and km ax ~ IBI - IAI + 1, and IAlkm in ~ h ~ IAlkm ax .
Optimal matching of h controls with at least kmin controls and at most km ax controls becomes a minimum cost flow problem in the following way.
Add to the vertex set a new vertex called the SINK , so V = AUBU{SINK} .
Add an edge from each b E B to the sink, so E = {(a, b) : a E A, b E B,
{jab < oo} U {(b, SINK) : b E B}. See Figure 10.2 which adds a SINK to
Figure 10.1. The SINK is needed to ensure that optimal matching does not re-
duce the cost by matching fewer than h controls. Set DMIN(a) = kmin,
DMAX(a) = km ax for all a E A, DMIN(b) = DMAX(b) = 0 for all bE B, and DMIN(SINK) = DMAX(SINK) = -h. Set MIN(b,SINK) = 0, MAX(b,SINK) = 1, and COST(b,SINK) = 0 for all b E B . Define all other
quantities as in §10.4.3. In an integer FLOW, each of h controls must send one unit of flow to the SINK, and each of these controls must receive its

10.4 Optimal Matching 317

TABLE 10.10. Three Matched Samples with a Vari able Number of Controls.

Treated

km in = 1

kmin = 1

km in = 2

Unit

km ax = 13

= kmax 4

= kmax 3

3

2

2

2,6

5

4

4

4,7

9

7, 10, 12 1, 7, 10, 16 1, 10, 16

18 1, 6, 8, 11, 13, 16 6, 8, 11, 13 8, 11, 13

20

14, 15, 19, 21 14, 15, 19, 21 14, 19, 21

22

17,26

17,26 15,17,26

24

23, 25

12, 23, 25 12, 23, 25

Total Distance

87

91

118

unit of flow from a different treated unit. An integer FLOW satisfies the constraints in (10.2) if and only if {(a ,b) : a E A, bE B , FLOW(a ,b) = I}
is a matching with h controls in which each treated unit has at least kmin and at most kma x controls. A minimum cost flow is an optimal matching.
Table 10.10 gives optimal matched samples with a variable number of
controls for three choices of km in and kmax . The table identifies the controls matched to each treated plant. For instance, in the first match with km in = 1 and kmax = 13, treated unit 9 is matched to controls 7, 10, and 12. Every control is matched to some treated unit , so h = 19, unlike the match in
§1O.4.3 where some controls were discarded. The first match in Table 10.10
has km in = 1 and kmax = 13, so it requires only that every tre ated plant
have at least one control. This first match assigns one control to treated unit 3 and six controls to treated unit 18. The last match has kmin = 2
and kmax = 3. Remember that there are IBI = 19 controls and IAI = 7
treated units. Since 19/7 = 2.71, to match with kmin = 2 and kmax = 3 is to require the number of controls to be as nearly constant as possible.
Table 10.10 also gives the total distance within matched sets for each of
the three matched samples. The match with kmin = 1 and kmax = 4 has a total distance only slightly greater than the match with kmin = 1 and km a x = 13, and both are much better than the match with kmin = 2 and kma x = 3. A substantial price was paid in giving more than one control to treated units 3 and 5.

b --+ 1

"" a

/
--+

2

--+

SINK

Vertices V = {a, b, 1,2,51N K} Edges E = {(a, 1), (a, 2), (b, 1), (1, SINK), (2, SINK)}

FIGURE 10.2. A network with a sink.

318 10. Constructing Matched Sets and Strata
An alternative method for matching with variable controls is discussed in Problem 10 and in Ming and Rosenbaum (2001).
10.4.5 Optimal Full Matching
Recall that in a full matching, each matched set contains a treated unit and one or more controls or a control unit and one or more treated units. This section finds a full matching of all subjects that minimizes the total
distance. Assume at first that Dab > 0 for each a E A and b E B; this
assumption can be removed, as indicated at the end of this section. Optimal full matching uses the network in §1O.4.3 without a SINK but
with the following changes . Set DMIN(a) = 1 and DMAX(a) = IBI for each a E A and DMIN(b) = -IAI and DMAX(b) = -1 for each b E B . Define
other quantities as in §10.4.3. Then an integer FLOW that satisfies the constraints in (10.2) must have at least one unit of flow leaving each treated unit, since DMIN(a) = 1, and it must have at least one unit of flow entering each control, since DMAX(b) = -1, so every treated unit is connected to one or more controls and every control is connected to one or more treated
units. However, the set {(a,b) : a E A,b E B, FLOW(a,b) = I} may
not define a full matching because a treated unit a might be connected to several controls including b but b might be connected to several treated units. This is not a problem, however, if FLOW has minimum cost, as will now be demonstrated.
Find a minimum cost integer FLOW. It will now be shown that because FLOW has minimum cost, the set {(a, b): a E A,b E B, FLOW(a,b) = I} does define a full matching. Suppose not, so there are a, a* E A and b,
b* E B such that FLOW(a ,b) = 1, FLOW(a* , b) = 1, and FLOW(a\b*) =
1. Define a new flow called BETTER such that BETTER(a*, b) = 0 and BETTER(i,j) = FLOW(i,j) for all (i,j) =1= (a*,b) . Then BETTER satis-
fies the constraints and it has a cost that is lower by Da · ,b > 0, so FLOW is
not optimal, and there is a contradiction. Hence, a minimum cost integer FLOW is an optimal full matching.
It was assumed at the beginning of this section that Dab> 0 for all a E A
and b E B. This assumption will now be removed. Suppose that Dab = 0 for
d pairs (a, b) with a E A and b E B. Construct a new minimum cost flow problem identical to the original problem except that Dab = e > 0 for these d pairs. The minimum cost flow for the new problem is a full matching and the total cost is at most de higher than the minimum cost of the original problem. Since e was arbitrary, it follows that for sufficiently small e, the minimum cost flow for the new problem is also a minimum cost flow for the original problem.
As it turns out, the first match in Table 10.10 is an optimal full matching.

10.4 Optimal Matching 319
10.4.6 Optimal Balanced Matching
In the nuclear power plant example in Table 10.6, two of the treated plants were constructed in the northeastern United States, specifically plants 5 and 22, and six of the control plants were constructed in the northeast. Construction costs, the outcome, are generally high in the northeast, so it would be desirable to match on this covariate in addition to the date of construction and the capacity of the plant. In the minimum distance match with two controls, 2/7 = 29% of the treated plants were constructed in the
northeast, but only 3/14 = 21% of the controls were constructed there. The matched sample would be balanced if 4/14 = 29% of the controls
came from the northeast. This section finds the matched sample which has the minimum total distance among all balanced samples with two controls per treated unit.
In general, suppose that units are divided into C categories, c = 1, . .. ,C, that me treated subjects fall in category c, and that at least km.; controls are available from category c. The task is to match each treated unit with k controls so that a total of km; controls fall in category c, and the total distance is as small as possible.
The following network is used. Introduce C new vertices , SINKl , . . . ,
SINK c . The vertices are the subjects together with the sinks, V = Au
B U {SINK l, . . . , SINKc}. The edges E are of two types. There is an edge linking each treated subject a E A to each control b E B for which the
distance is finite, Dab < 00. These edges have COST(a , b) = Dab. There is
also an edge linking each control in category c to SINKe , so each control is linked to exactly one sink . These edges connecting b E B to a sink have COST equal to zero. The set E of edges is the union of these two sets
of edges . All edges (i,j) E E have MIN(i,j) = 0 and MAX(i,j) = 1.
The bounds on the divergences are DMIN(a) = DMAX(a) = k for all
a E A, DMIN(b) = DMAX(b) = 0 for all b E B , and DMIN(SINKe ) =
DMAX(SINKe ) = -kme for c = 1, . . . ,C. Suppose that there is an integer flow FLOW(a,b) that satisfies the con-
straints in (10.2). Then the set ((a,b) : a E A,b E B, FLOW(a,b) = I} defines a balanced matched sample with k controls for each treated subject. To see this, note the following. A total of k units of flow leave each treated
unit a E A because DMIN(a) = DMAX(a) = k, so each treated unit is
paired with k controls. No control b E B can be matched to more than one
treated unit because DMIN(b) = DMAX(b) = 0 and MAX(b,SINKe ) = 1
for exactly one c, so unit b must pass on all the flow it receives and can pass on at most one unit of flow. The sample is balanced because DMIN(SINKe ) = DMAX(SINKe ) = -kme , so there must be km; controls from category c. A minimum cost integer flow therefore defines a balanced matched sample of minimum total distance.
Table 10.11 compares optimal balanced matching with greedy matching and optimal matching for the example in Table 10.6. All three matched

320 10. Constructing Matched Sets and Strata

TABLE 10.11. Comparison of Greedy, Optimal and Balanced Matching.

Treated Unit Greedy Optimal

Optimal Balanced

3 2, HI

2,21

2, 10*

*5 4*,21

4*,7

4*,7

9 7,10* 10*, 16

12*, 16

18 8, 13

8, 13

8, 13

20 14, 15 14, 15

14,21

*22 17*,26 17*, 26

15, 17*

24 23, 25 23,25

23, 25

Total Distance

79

71

74.5

% Treated in Northeast

29

29

29

% Control in Northeast

21

21

29

samples have two controls for each treated plant. The greedy and optimal match are from §1O.4.3. The optimal balanced match forces 29% of the control plants to come from the northeast because 29% of the treated plants are from the northeast.
In Table 10.11, optimal balanced matching corrects the imbalance in plants from the northeast with a distance 5% = (74.5 - 71)/71 higher th an the unbalanced optimal match. The optimal balanced match is better than the greedy match both in being balanced and having a smaller total distance.
The method described in this section balanced a single categorical covariate and minimized distance among such balanced matched samples. It is possible to balance many variables at once , but this requires integer programming rather than network optimization. See Li, Propert, and Rosenbaum (2001) for discussion with an example.

10.4.1 Comparison of Matching Methods Using Simulation
In a simulation study, Gu and Rosenbaum (1993) compared the methods described in this chapter. This section outlines some of the findings, though the paper should be consulted for detailed discussion, num erical results, and specifics.
The simulation considered multivariate normal covariates x with common covariance matrix in the treated and control groups but different mean vectors. The number of covariates or dimension of x was 2, 5, or 20. In each
matched sample , there were IAI = 50 treated subjects. The number of controls available for matching was IBI = 50,100, 150, or 300. For each match-
ing situation considered , 50 different matched samples were constructed. Three distances {jab were used . The first was the absolute difference
in propensity scores estimated using a logit model. The second was the
Mahalanobis distance. The third method, M + P , used a caliper on the

10.4 Optimal Matching 321
propensity score , so Dab = 00 if a and b had propensity scores differing by more than 0.6 times the standard deviation of the propensity scores, and otherwise Dab was the Mahalanobis distance. This third distance was proposed by Rosenbaum and Rubin (1985).
Two types of measure were used to judge the quality of a matched sample. The first was the average distance within matched sets. The average distance is the total distance that was minimized by optimal matching divided by the number of distances summed to form the total. The second was the balance of the matched groups, that is, the difference in covariate mean vectors in treated and control groups after matching. When the matched sets have unequal sizes, as is true for some matching methods, balance is defined in terms of the average over matched sets of the average difference between treated and control subjects within matched sets. Different distances Dab may be compared in terms of balance but not in terms of total distance, since the difference in propensity scores is not commensurate with the Mahalanobis distance.
The main findings follow.
· When there were 20 covariates, matching on the propensity score produced greater covariate balance than matching using the Mahalanobis distance. When there were two covariates, the methods were
similar with no consistent winner. The combined distance, M + P,
often fell between the other methods but rarely performed poorly.
· When a fixed number klAI of controls were matched, full match-
ing was found to be much better than matching k controls to each treated subject. That is, the method of §1O.4.5 was much better than the method of §1O.4.3 when the same total number of controls was matched. This was true for both the average distance and covariate balance.
· Optimal matching was sometimes much better than greedy matching and sometimes only marginally better. Optimal matching was much better than greedy at minimizing the average Mahalanobis distance
when there were few controls to choose from, IBI = 50 or IBI = 100,
and the number of covariates was 2 or 5. Optimal matching was only slightly better than greedy at minimizing the propensity distance. Optimal matching was no better than greedy at producing covariate balance.
Some caveats are needed. The comparisons of different distances refer only to covariate balance, because the distances themselves are not commensurate. The comparison of full matching and matching with a fixed number of controls refers only to average distance and balance, measures of bias. An optimal full matching may contain matched sets of extremely unequal sizes, and these may be unattractive for reasons of precision or aesthetics. In pr actice, with a given data set , a full matching, a matching with

322 10. Constructing Matched Sets and Strata
a fixed number of controls, and several compromises may be compared, as in §10.4.4.
10.5 Bibliographic Notes
The discussion in §10.2 of the balancing property of the propensity score is based on Rosenbaum and Rubin (1983, 1984). Three empirical comparisons of analyses using propensity scores are Rosenbaum and Rubin (1985), Smith (1997), and Dehejia and Wahba (1999) . The discussion of optimal stratification in §10.3 is from Rosenbaum (1991), and the discussion in §10.3.2 is from Ming and Rosenbaum (2000). There is a vast literature on network optimization and its relationship to matching. A concise place to start is Bertsekas (2001). Some early references are Kuhn (1955) and Ford and Fulkerson (1962), and modern discussions are given by Papadimitriou and Steiglitz (1982), Tarjan (1983), Rockafellar (1984), Bertsekas (1991, 2001), and Ahuja, Magnanti, and Orlin (1993) . The material and examples in §10.4 are from Rosenbaum (1989), except for §10.4.5 which is from Rosenbaum (1991). Section 10.4.7 summarizes the simulation study in Gu and Rosenbaum (1993). Other simulations of greedy matching with a single control are given in Rubin (1973,1979,1980). Li, Propert, and Rosenbaum (2001) discuss matching on longitudinal covariate histories when treatment is delayed for varied periods of time. Joffe and Rosenbaum (1999) and Lu, Zanutto, Hornik and Rosenbaum (2002) discuss matching with doses of treatment; see also Imbens (2000) for an alternative approach. · Matching forms a useful link between quantitative and qualitative research; see Rosenbaum and Silber (2001).
The methods of this chapter are widely used, and a few selected illustrations follow. Propensity scores are used by: Lecher (2000), Normand, Landrum, Guadagnoli, et al. (2001), Petersen, Normand, Daley, and McNeil (2000), Phillips, Spry, Sloane, and Hawes (2000), Powers and Rock (1999), and Silber, Kennedy, Even-Shoshan, et al. (2000). Optimal matching is used by: Rephann and Isserman (1994), Nuako, Ahlquist, Sandborn, et al. (1998), Ghavamian, Bergstralh, Blute, et al. (1999), and Warner, Warner, Offord, et al. (1999).
10.6 Software
The availability of software changes rapidly. A brief discussion follows. Propensity scores may be estimated using a logit model available in most
statistical software packages. Propensity scores with several doses may be estimated using McCullagh's (1980) ordinal logit model, also available in

10.7 Problems 323
most st atistical softwar e packages. Stratification on an est imated prop ensity score is straightforward.
When properly coded, algorit hms for optimal mat ching are very fast , often fast er than cas ua lly coded greedy algorithms. A bri ef, element ary, clear exposit ion of one of the simplest and fast est algorit hms- t he auct ion algorit hm-for optimal pair matching is given by Bertsekas (2001). It is easy to translate Ber ts ekas ' exposit ion of the auction algorit hm into casua l, bri ef S-Plus code; see Problem 11. Such an implementation is of value for learning about the algorit hm in small problems , but a quick algorithm requires car eful programming and cannot loop within S-Plus.
An algorithm for optimal pair matching can be tricked into performing optimal matching with a fixed number of controls as in §1O.4.3 or with a variable number of controls as in §1O.4.4. The trick involves introducing duplicate copies of treated subjects and phantom controls so that an optimal pair matching with the duplicates and phantoms equals an optimal matching with multiple cont rols. The easy details, an example, and SAS code are given by Ming and Rosenbaum (2001) and are discussed in Problems 8 through 11.
The SAS System has several proc edures or PROCs th at are useful in optimal matching, PROC ASSIGN and PROC NETFLOW in SAS/OR. Sp ecifically, PROC ASSIGN impl ements th e assignment algorithm, or optimal pair matching: it starts with a distance matrix, such as Tabl e 10.6, and returns an optimal pair matching. Programming features in SAS may be used to con struct the distance matrix. As ju st noted, PROC ASSIGN can be tricked into performing optimal matching with multiple controls. More complex matching pr oblems , such as full mat ching, may be solved using PROC NETFLOWj here, however, t he user must pr ogram the const ru ct ion of a network. Bergstralh , Kosanke , and Jacobsen (1996) provide downloadable SAS ma cros t hat simplify optimal matching in SAS. In addition, the SAS Web site, http://www.sas.com. has a few basic technical reports on propensity scores and matching which may be locat ed using their search engine.
Bertsekas (1991) provides downloadable subrout ines for network optimization.
10.7 Problems
1. Refinement without improvement. Find a distance matrix bab and a stratification (AI , . .. , As ; B I, . .. , Bs ) such that the refinement in Proposition 30 is as good as but no better than the stratification.
2. Full matching and the support of the distribution of covariates. Let X l, ... , X n be ind ependent random variables with distribution F(·)
and let Xl, . . . , xn be independent random variables with distribution

324 10. Constructing Matched Sets and Strata
F(.), where the x 's are independent of the x 's. Suppose that we match x's to x 's to minimize the distance 8ab = IXa - xbl. Consider both a
pair matching of each x to a single x and a full matching. Within each
x matched set , calculate the average x and the average and difference
these two averages. Each matched set produces one such difference; average the differences across matched sets and call the result B. Then B is a measure of covariate balance. Note that B is computed from certain X a - Xb, not from IXa - xbl. Suppose that F( ·) and F(.) are two beta distributions on the interval [0, 1] with different means. How does B behave as n -+ 00 for pair matching and full matching? Suppose that F( ·) is uniform on [0,1] and F( .) is uniform on [1,2] . How does B behave as n -+ 00 for pair matching and full matching? (Hint : Does pair matching affect B ?) What does this suggest about what full matching can and cannot do?
3. Proof concerning full matching. Problems 3 through 7 prove Proposition 30, and the notation of that proposition is used . A proof of Proposition 30 along these lines is given in Rosenbaum (1991, §4).
Why can we assume, without loss of generality, that ~o < oo? Why
can we assume that there is some s such that IAsl ~ 2 and IBsl ~ 2?
Fix that s.
4. Proof concerning full matching, continued . Pick any two units a E A s and b E B i. Suppose that (a, b) are separated from stratum s to form
a new stratum S + 1 with AS+ 1 = {a} and BS+1 = {b}. Let O(a, b) be
the difference between the distance ~o for the original stratification and the distance for the new stratification in which (a, b) are in their
own strata. Express O(a, b) in terms of w(IAsl , IBsl) , w(IAsl-1, IBsl-
1), w(l, 1), 8(A s, Bs), 8(A s - {a}, B , - {b}) , and 8ab. Here , A s - {a} means the set As with a removed.
5. Proof concerning full matching, continued. What is the average of 8ab over all a E A s and b E B s? What is the average of 8(As - {a} , B ; -
s {b}) over a E A, and e B s ?
6. Proof concerning full matching, continued . Show that the average of O(a, b) over a E A s and b E B ; is nonnegative. (Hint: Use Problem 5 and th e assumption that the weight function is either neutral or favors small strata.)
7. Proof concerning full matching, continued . Conclude that there is some a E A s and b E B; such that O(a,b) ~ O. Separate this (a, b) to form a new st rat um. How does repeating the process prove Proposition 30?
8. Pair matching and the assignment algorithm. The assignment problem is optimal pair matching of m treated subjects to m controls, with an m x m distance matrix, a . Suppose you had an algorithm for

10.7 Problems 325
the assignment problem , but you had n tr eated subjects and m > n
cont rols, and you wanted an optimal pair mat ching. For inst ance, Table 10.6 is an m x n = 19 x 7 distance matrix. Pad t he m x n distan ce matrix with zeros to make it a square m x m matrix; t hat is, add m - n ph antom columns. Show th at an optimal assignment from the square m x m matrix yields an optimal pair mat ching of the n treated su bjects once the m - n ph antoms and their mat ched cont rols are discarded .
9. Matching with two cont rols and the assignment algorithm. Continuing Problem 8, suppose m ~ 2n, and that you want to use the assignment algorit hm to match each of the n t reated subject s to two cont rols. Duplicate the m x n dist an ce matrix, yielding an m x 2n matrix, and pad it with m - 2n columns of zeros to yield an m x m matrix. Show that an optimal assignment from th e square m x m matrix yields an optimal matching of the n treat ed subject s with two control s once the m - n phantoms and their mat ched controls are discard ed.
10. Matching with variable controls and the assignment algorithm. Continuing Problem 9, show how to use th e assignment algorit hm to mat ch with a vari able number of cont rols. (Ming and Rosenbaum 2001)
11. ToyAuction: Splus code for a toy version of the auct ion algorithm. Read Bertsekas (2001) and write up th e auction algorithm for the assignment problem in S-Plus code. (Hint:
> ToyAuction
function (a)
{
# a is a square matrix of nonnegative integer distances
#
# Note carefully: a is square! Pad a nonsquare matrix
# with zeros (phantoms) to make it square & discard them # later . See Ming & Rosenbaum (2001) J Comp Graph Stat
#
# b is a vector, where row i is matched to column b[i]
#
# Implements a simple version of the auction algorithm # for the ass ignment problem . The code closely follows # the description i n Bertsekas (2001) Auction Algorithms # in Encyclopedia of Optimization. The code is a toy - # to learn about small examples . No effort has been made # to make the code efficient . ToyAuction is slow, but # the auction algorithm can be fast .
#
a <- - a #change signs -- maximize negat ive distances

326 10. Constructing Matched Sets and Strata
quit <- 10000 #loop limit qcount <- 0 #loop counter n <- dim(a) [1] #remember a is square! eps <- 0.95/n #small eps is slow, but ensures optimal match p <- rep(O, n) #initial prices b <- l:n #initial match: row i matched to b[i] bid <- rep(O, n) happy <- 0 go <- T
while(go) {
for(i in 1.n) {
gain <- ajL, ] - p o <- order(gain) if(gain[b[i]] >= gain[o[n]] - eps) {
happy <- happy + 1
}
else {
bid[o[n]] <- 1 p[o[n]] <- p[o[n]] + gain[o[n]] + eps - gain[o[n -
1]] #Update price
k <- (l:n)[b == o[n]] #current owner of o[n] b[k] <- b[i] #give current owner i's object b[i] <- o[n] #give i best choice
}
}
qcount <- qcount + 1 if(happy == n) { go <- F
}
happy <- 0
if (sum(bid) n) {
go <- F
}
if(qcount > quit) { b <- "too many iterations" go <- F
}
}
b
}
The distance matrix in Table 10.6 is given in the matrix temp.
> temp
1 234 5 6 7
[1,] 28 24 10 7 17 20 14 [2,] 0 3 18 28 20 31 32

10.7 Problems 327
[3,] 3 0 14 24 16 28 29 [4,] 22 22 18 8 32 35 30 [5,] 14 10 4 14 18 20 18 [6,] 30 27 12 2 26 29 24 [7,] 17 14 ' 5 10 20 22 17 [8,] 28 26 11 6 18 20 16 [9,] 26 24 9 12 12 14 9 [10,] 28 24 10 0 24 26 22 [11,] 20 16 14 24 0 12 12 [12,] 22 19 12 22 2 9 10 [13,] 23 20 5 4 20 22 17 [14,] 26 23 14 24 6 5 6 [15,] 21 18 22 32 7 15 16 [16,] 18 16 10 20 4 12 14 [17,] 34 31 16 18 14 9 4 [18,] 40 37 22 16 20 11 8 [19,] 28 25 28 38 14 12 17 The next step takes temp and converts it into a square 19 x 19 matrix using the idea in Problem 9. Specifically, the seven columns are duplicated and padded with zeros. Columns 1 and 8 refer to power plant 3, columns 2 and 9 refer to power plant 5, and so on. Columns 15 through 19 are phantoms, to be discarded after matching.
> temp2<-cbind(temp,temp,matrix(0,19,5))
Applying ToyAuction to temp2 gives an optimal match with two controls.
> ToyAuction(temp2)
[1] 19 8 9 16 2 4 3 15 14 11 5 12 10 13 18 1 7 6 17 For example, the first control in row #1 is matched to column #19, which is a phantom, so the first control is not used . The second cont rol in row #2 is matched to column #8, which is the second copy of the first column; that is, the second control is matched to power plant 3 in t he first column of Table 10.6. The third control, power plant 4 in Table 10.6, is matched to column 9, which is the second copy of column 2 in Table 10.6, t hat is, power plant 5. The optimal match found by ToyAuction has the same distance as the optimal match in Table 10.6, but they are not quite identical. The match in Table 10.6 included the power plant pairs (25,24) with a distance of 8 and (26,22) with a distance of 12, for a total
of 8 + 12 = 20. The match using ToyAuction replaced these two pairs by
(12,24) , or row 9 with column 14, with a distanc e of 9, and (25,22 ), or row
18 with column 6, for a distance of 11, for a total of 9 + 11 = 20.)

328 10. Constructing Matched Sets and Strata
10.8 References
Ahuja, R. K., Magnanti, T . L., and Orlin, J. B. (1993) Network Flows: Theory, Algorithms, and Applications. New York: Prentice-Hall.
Bergstralh, E. J ., Kosanke, J. L., and Jacobsen, S. L. (1996) Software for optimal matching in observational studies. Epidemiology, 7, 331332. http://www.mayo.edu/hsr/sasmac.html.
Bertsekas, D. (1991) Linear Network Optimization: Algorithms and Codes. Cambridge, MA: MIT Press. http://www.mit.edu:8001//people/ dimitrib/home.html.
Bertsekas, D. (2001) Auction algorithms. Encyclopedia of Optimization, C. A. Foudas and P. M. Pardalos, eds. , Kluwer.
Carpenter, R. (1977) Matching when covariables are normally distributed. Biometrika, 64, 299-307.
Cochran, W. G. (1968) The effectiveness of adjustment by subclassification in removing bias in observational studies. Biometrics, 24, 205213.
Cochran, W . G. and Rubin, D. B. (1973) Controlling bias in observational studies: A review. Sankya , Series A, 35, 417-446.
Cox, D. R. (1970) The Analysis of Binary Data. London: Methuen.
Cox, D. R. and Snell, E. J . (1981) Applied Statistics: Principles and Examples. London: Chapman & Hall .
Dehejia, R. H. and Wahba, S. (1999) Causal effects in nonexperimental studies: Reevaluating the evaluation of training programs. Journal of the American Statistical Association, 94, 1053-1062.
Ford, L. and Fulkerson, D. (1962) Flows in Networks. Princeton, NJ : Princeton University Press.
Ghavamian, R., Bergstralh, E. J ., Elute, M. 1., Slezak, J., and Zincke, H. (1999) Radical retropubic prostatectomy plus orchectomy versus orchietomy for pTxN+ prostate cancer: A matched comparison. Journal of Urology, 161, 1223- 1227.
Gu, X. S. and Rosenbaum, P. R. (1993) Comparison of multivariate matching methods: Structures, distances and algorithms. Journal of Computational and Graphical Stat istics, 2 , 405-420.
Imbens, G. W. (2000) The role of the propensity score in estimating doseresponse functions . Biometrika, 87, 706- 710.

10.8 References 329
Joffe, M . M. and Rosenbaum, P. R (1999) Propensit y scores. American Journal of Epidem iology, 150, 327- 333.
K uhn , H. W . (1955) T he Hungar ian method for the assignment problem. Nava l Research Logistics Quart erly, 2 , 83-97 .
Lechner , M. (2000) An evaluation of public-sector-sponsored continuous vocational training programs in East Germany. Journal of Human Resources, 35, 347- 375.
Li, Y. , Propert , K. J . and Rosenbaum, P. R (2001) Balanced risk set matching. Journal of the American Stat istical Association, 96 , September , to appear .
Lu , B. , Zanutto, E. , Hornik, R , and Rosenbaum , P. R (2002) Matching with doses in an observational study of a media campaign agai nst drug abuse. Journal of the American Statistical Association, to appear.
McCullagh, P. (1980) Regression models for ordinal data. Journal of the Royal Statistical Society , B , 42, 109- 142.
Ming, K. and Rosenbaum , P. R (2000) Substantial gains in bias reduction from matching with a variable number of controls. Biometrics, 56 , 118- 124.
Ming , K. and Rosenbaum , P. R (2001) A not e on optimal matching wit h var iable controls usi ng the assignment algorithm. Journal of Computationa l and Graphical Stat istics, to appear.
Normand, S. T ., Landrum , M . B. , Guadagnoli, E., Ayanian, J . Z., Ryan , T . J. , Cleary, P. D ., and McNeil , B. J. (2001) Validating recommendations for coronary angiography following acute myocardial infarct ion in the elderly: A matched analysis using propensity scores . Journal of Clin ical Epidemiology, 54 , 387- 398.
Nuako, K. W ., Ah lquist, D. A., Sandborn, W. J., Mahoney, D. W., Siems, D . M., and Zinsmeist er , A. R (1998) P rimary sclerosi ng cholangit is and colorectal carcinoma in patients wit h chronic ulcerative colit is: A case-contro l study. Cancer, 82 , 822- 826.
P ap adimit riou, C. and Steiglitz, K. (1982) Combinatorial Optim ization. Englewood C liffs, NJ: P rent ice-Hall.
P etersen , L. A., Normand, S., Daley, J ., and McNeil , B. (2000) Outcome of myocardia l infarction in Veterans Health Administration patients as compared with medicare patients. New England Journal of Medicine , 343, December 28, 2000, 1934- 1941.

330 10. Constructing Mat ched Sets and Strata
Phillips C. D., Spry K. M., Sloane P. D., and Hawes, C. (2000) Use of physical restraints and psychotropic medications in Alzheimer special care units in nursing homes. American Journal of Public Health, 90, 92- 96.
Powers, D. E. and Rock, D. A. (1999) Effects of coaching on SAT I: Reasoning test scores. Journal of Educational Measurement, 36, 93118.
Rephann, T . and Isserman, A. (1994) New highways as economic development tools-An evaluation using quasi-experimental matching methods . Regional Science and Urban Economics, 24, 723- 75l.
Rockafellar, R. T . (1984) Network Flows and Monotropic Optimization. New York: Wiley.
Rosenbaum, P. R. (1984) Conditional permutation tests and the propensity score in observational studies. Journal of the American Statistical Association , 79, 565-574.
Rosenbaum, P. R. (1987) Model-based direct adjustment. Journal of the American Statistical Association, 82, 387-394.
Rosenbaum, P. R. (1989) Optimal matching for observational studies. Journal of the American Statistical Assoc iation, 84, 1024-1032.
Rosenbaum, P. R. (1991) A characterization of optimal designs for observational studies. Journal of the Royal Statistical Society , Series 13, 53, 597-610.
Rosenbaum, P. R. and Rubin, D. B. (1983) The central role of the propensity score in observational studies for causal effects. Biometrika, 70 , 41-55.
Rosenbaum, P. R. and Rubin, D. B. (1984) Reducing bias in observational studies using subclassification on the propensity score . Journal of the American Statistical Associat ion, 79, 516-524.
Rosenbaum, P. R. and Rubin, D. B. (1985) Constructing a control group using multivariate matched sampling methods that incorporate the propensity score. American Statistician, 39, 33-38.
Rosenbaum, P. R. and Silber , J. H. (2001) Matching and thick description in an observational study of mortality after surgery. Biostatistics, 2, 217- 232.
Rubin, D. B. (1973) The use of matched sampling and regression adjustment to remove bias in observational studies. Biometrics, 29, 185203.

10.8 References 331
Rubin, D. B. (1979) Using multivari ate matched sa mpling and regression adjust ment to control bias in observational st udies. Journal of the American Statist ical A ssociat ion, 74 , 318-32 8.
R ubin, D. B. (1980) Bias redu ction using Mahal anobis metr ic mat ching. Biometrics, 36, 293- 298.
Silber , J. H. , Kennedy, S. K. , Even-Shoshan, 0., Chen , W ., Koziol, L. F ., Showan, A. M., Longne cker, D. E. (2000) Anesth esiologist dir ect ion and patient outcomes. Anesthesiology, 93 , 152- 163.
Silber , J . H., Rosenbaum, P. R , Trudeau , M. E., Even-Shoshan , 0 ., Chen, W ., Zhang, X. , and Mosher , R E. (2001) Multivari at e matching and bias reduction in the surg ical outcomes study. Medical Care, to appear.
Smith, A., Kark, J. , Cassel , J. , and Spears, G. (1977) Analysis of prospective epidemiologic st udies by minimum distance case- control matching. American Journal of Epidemiology, 105, 567- 574.
Smith, H. (1997) Matching with multiple controls to est imate treatment effects in observational st udies. Sociological Methodology, 27 , 325353.
Snyder, T . L. and Steele, J . M. (1990) Worst case greedy mat ching in the unit d-cube. N etworks, 20 , 779- 800.
Tarjan, R. (1983) Data Stru ctures and Network Algorithms. Philadelphia: Society for Industrial and Appli ed Mathematics.
Walkup, D. (1979) On the expected value of a rand om assignment problem. SIAM Journal on Computing, 8 , 440-442.
Warner , D.O., Warner , M. A., Offord , K. P., Schroeder , D. R. , Maxson, P. , and Scanlon, P. D. (1999) Airway obstruction and periop erative complications in smokers undergoing abdominal sur gery. Anesthesioloau, 90, 372- 379.

11
Planning an Observational Study
11.1 Introduction and Some Ground Rules
11.1.1 Active Observation: Control and Choice
Many observational studies do not succeed in providing tangible, enduring , and convincing evidence about the effects caused by treatments, and those that do succeed often exhibit great care in their design. Particularly at the early stages of design, this care consists of choices that determine the circumstances of the study and the data to be collected. A convincing observational study is the result of active observation, an active search for those rare circumstances in which tangible evidence may be obtained to distinguish treatment effects from the most plausible biases. In an experiment, treatment effects are seen clearly because the environment is tightly controlled, whereas in a compelling observational study, control is, to a large extent, replaced by choice-the environment is carefully chosen.
Studies of samples that are representative of populations may be quite useful in describing those populations, but may be ill suited to inferences about treatment effects. For instance, describing early work in public program evaluation, Donald Campbell (1988, p. 324) wrote:
There was gross overvaluing of, and financial investment in, external validity, in the sense of representative samples at the nationwide level. In contrast, the physical sciences are so provincial that they have established major discoveries like the hydrolysis of water... by a single water sample ....

334 11. Planning an Observational Study
Passive observation of a natural population followed by regression analysis is often unsuccessful as an approach to inference about treatment effects; see, in particular, Box (1966) and Freedman (1997). A report of the National Academy of Sciences (Meyer and Fienberg 1992, p106) concerning evaluation studies of bilingual education makes a similar point:
In comparative studies, comparability of students in different programs is more important than having students who are representative of the nation as a whole . Elaborate analytic methods will not salvage poor design or implementation of a study.
Here, several principles are discussed which guide the choices made in the early planning and design of an observational study. The principles are illustrated using three observational studies that use choice effectively, one each from economics, clinical psychology and epidemiology. After discussing the quality of evidence, the examples are described, and then the subsequent discussion of principles makes reference to these examples.
11.1.2 The Quality of Evidence: Some Ground Rules
Most empirical disciplines make use of some form of mathematical reasoning. To discuss the quality of evidence provided by an empirical study one must first recognize that evidence is not proof, can never be proof, and is in no way inferior to proof. It is never reasonable to object that an empirical study has failed to prove its conclusions, though it may be reasonable, perhaps necessary, to raise doubts about the quality of its evidence. As expressed by Sir Karl Popper (1968, p. 50): "If you insist on strict proof (or strict disproof) in the empirical sciences, you will never benefit from experience ami never learn from it how wrong you are."
One expects that a proof will be correct and that evidence will be candidly presented, despite occasional disappointments. One is often concerned about the relevance of a proof and the quality of evidence. If it is proved that a certain bridge can withstand certain forces, and yet the bridge collapses, it not the correctness but the relevance of the proof that is likely to be called into question.
The distinction between the mathematical correctness and relevance of a proof is familiar in most empirical sciences that use mathematical methods, for instance, economics, where Samuelson in his 1947 technical treatise, The Foundations of Economic Analysis, wrote:
... our theory is meaningless in the operational sense unless it does imply some restrictions upon empirically observable quantities, by which it could conceivably be refuted (p. 7) ... By a meaningful theorem I mean simply a hypothesis about empir-

11.1 Introduction and Some Ground Rules 335
ical data which could be refuted, if only under ideal conditions. A meaningful theorem may be false. (p. 4)
Evidence may refute a theorem, not the theorem's logic, but its relevance. A related point is made by Quine (1951) .
Evidence, unlike proof, is both a matter of degree and multifaceted. Useful evidence may resolve or shed light on certain issues while leaving other equally important issues entirely unresolved. This is but one of many ways that evidence differs from proof.
Evidence, even extensive evidence, does not compel belief. Rather than being forced to a conclusion by evidence, a scientist is responsible and answerable for conclusions reached in light of evidence, responsible to his conscience and answerable to the community of scientists. Of this, Michael Polanyi (1964) writes:
...our decision what to accept as firmly established cannot be wholly derived from any explicit rules but must be taken in the light of our own personal judgment of the evidence.
Nor am I saying that there are no rules to guide verification, but only that there are none which can be relied on in the last resort ...
We may conclude that just as there is no proof of a proposition in natural science which cannot conceivably turn out to be incomplete, so also there is no refutation which cannot conceivably turn out to have been unfounded. There is a residue of personal judgment required in deciding-as the scientist eventually must-what weight to attachto any particular set of evidence in regard to the validity of a particular proposition. (pp. 30-31)
The scientist takes complete responsibility for everyone of these actions... (p. 40) ... for the process as a whole-he will assume full responsibility before his own conscience. (p. 46)
Evidence may be convincing beyond reasonable doubt, yet being convinced or remaining skeptical is a judgment for which a scientist is responsible. The desire to be compelled rather than convinced by evidence is the desire to evade responsibility for judging the evidence.
Aesthetics matter in proof, but also in evidence . A beautiful proof is simple, illuminating its conclusion and rendering it obvious. The same aesthetic applies to evidence. In both cases , the simple and the obvious are the product of care, effort, and skill.

~~6

11. Planning an Obs ervation al Study

11.2 Three Observational Studies

11.2.1 Examples of Careful Planning
Three examples are used to illustrate the choice of circumstances in which an observational study is conducted. The studies employ choice in their design in an instructive manner which meaningfully strengthens the evidence, but of course does not prove, th at the treatment caused its ostensible effects . Two of these studies, the lead exposure and minimum wage studies, were encounte red more briefly in §§3.2.4 , 4.3, and 5.4 .6.
To emphasize, th ese st udies are being used solely to illustrate careful planning and the use of choice in the design of observational st udies. The conclusions of the minimum wage and bereavement examples remain controversial, and it is not my purpose here to suggest the cont roversy is warranted or unwarranted. The purpose is to illustrate how careful planning can improve the quality of evidence.

11.2.2 The Effects of Increasing the Min imum Wage
The most familiar of all arguments of economic analysis are those of comparative stat ics, as discussed, for example, in the early chapt ers of Samuelson's (1947) Foundations of Economi c Analysis. Often motivated with the aid of diagrams in elementary economics courses, such an argument pictures the world as determined by an equilibrium of forces, and it describes how that equilibrium changes as the forces ar e chang ed . Arguments of this form (c.f. Samuelson's "Illustrat ive Market Case" on page 17) suggest that increasing the price of a commodity will decrease the demand for that commodity, oth er things "being equal" or ceteris paribus. Viewing labor as a commodity and applying such considerations leads many economists to expect th at au increase in the minimum wage will ca use a decline in employment among workers receiving the minimum wage. Developed in slightly different terms, such arguments sugg est t hat an increase in the minimum wage shifts production to use less labor and more capital equipment , or to substitute goods produced outside the reach of the minimum wage . For this reason , many economists argue that increasing the minimum wage hurts the very individuals it is intended to benefit. Insp ection of the details of such a theorem suggest that, as a theor etical argument remov ed from data, this expe ctation seems logical.
Writing in th e American Economic Review in 1994, David Card and Alan Krueger (CK) at te mpt ed to est imat e the effects of an increase in New Jersey's minimum wage that occurred on April 1, 1992. CK looked at employment in th e fast-food industry (Burger King , Kentucky Fried Chicken, Wendy 's , and Roy Rogers) in New Jersey before and after the increase in the minimum wage and compared this to a control group consisting of fast-food restaurants in adjacent eastern Pennsylvania. They found "no ev-

11.2 Three Obser vat ion al St udies 337
iden ce that the rise in New J ersey's minimum wage reduced employment at fas t-food restaurant s in the state." Methodological aspects of CK are nicely discussed by Meyer (1995) .
The CK st udy is highly controversial in its conclusions and somewhat unusual in it s design. To shed light on its design, it is useful to describe a related study conducte d in t he more traditional manner , which reached very different conclusions. The tradi t ional study used her e for compar ison act ually ca me in resp onse to Card and Krueger, and was conduct ed by Deere, Murphy, and Welch (1995), or DMW. The DMW st udy attempted to esti mate the effect s of t he increases in the Federal minimum wage that took place from $3.35 to $3.80 on April 1, 1990 and from $3.80 to $4.25 on April 1, 1991 by applying regression to nati onal monthly data from the Current Population Survey from 1985 to 1993. DMW conclude: "T he regression estimates have no sur prises. When the cost of employing lowwage laborers is increased , fewer low-wage laborers are employed ." Without taking sides on the substantive conclusion, §11.4 at several places compares the designs of these two studies.
Before leaving the st udies by CK and DMW, one should note that their conclusions do not, st rict ly spe aki ng, contradict each other . First , CK discuss a particular change in a state minimum wage while DMW discuss a partic ular change in the Fed eral minimum wage, and it is possible in principle that these different interventions had different effect s. Second , DMW examine changes in employm ent in cert ain demographic groups with varied percentages of minimum wage earners, while CK discuss employment in part icular fast-food rest aurant s. Not e, however, that the simple comparative statics argument above would suggest that these distincti ons should not matter and that the same general pattern of effects should be seen in both cases.
11.2. 3 Effects of Loss of a Spouse or Child in a Car Crash
Lehman, Wortman, and Williams (1987) (LWW) at te mpte d to est imate t he long-term psychological effects of a sudden and unexpected death of a spouse or a child in a motor vehicle crash. The study identified 39 individuals who had lost a spouse and 41 individuals who had lost a child in a motor vehicle crash four to seven years prior to the study. This group of exposed subjects was the result of a select ion process that applied various criteria and sampling to a record of motor vehicle fatalities in Michigan between 1976 and 1979, with some nonresponse that is discussed in the LWW paper.
Noting that "many previous st udies on the impact of bereavement have not included control or comparison groups...," so that these studies were "difficult to interpret," LWW constructed a control group in the following way. From a reservoir of 7581 individuals who came to renew their licenses , one control was matched to each exposed subject bas ed on gender , age,

338 11. Pl ann ing a n Observat ion al St udy
family income in 1976 (i.e., before the crash), educat ion level, number and ages of children. The outco mes included measures of depression a nd various psychiatric symptoms. Bereaved spouses and parents both were depressed subs t antially and significantly more than matched cont rols between four and seven years after the loss, and ber eaved spouses exhibite d higher rates of several other psychi atric sym ptoms . LWW conclude d:
The results presented here suggest that the curre nt theoretical approaches to bereaveme nt may need to be reexamined ... [T he discussion goes on to contrast the study 's results with the views of Bowlby and Freud, among others] (p . 228) From 4 to 7 years after the sudden loss of a spouse or child, bereaved respondent s showed significant ly greater distress than did matched controls, suggesting little evidence of timely resolution. Contrary to what some early writers have suggest ed about the duration of th e major symptoms of bereavem ent ... both spouses and parents in our study showed clear evidence of depression and lack of resolution at the time of the interview , which was 4 to 7 years after the loss occurred... The present study suggest s that exposure to stress can trigger endur ing changes in mental health and functioning (p. 229) .
11.2.4 Lead in Children of Workers Subject to Occupational Exposures to Lead
Morton, Saah , Silberg, Owens, Roberts and Saah (1982) (MSSORS) examined lead levels in the blood of children whose parents worked in a factory t hat used lead in the manufacture of batteries. They suspected that parents brought lead home in their clothes and hair, thereby exposing their children. Thirty-three children from different familie s with a parent at the battery factory were matched to thirty-three unexposed control children, the matching being based on age, neighborhood, and exposure to traffic.
They found that exposed children had substantially higher levels of lead in their blood than did matched control children. The exposed children were also classified in two ways, namely, parental exposure to lead on the job (low, medium, or high) , and parental hygiene upon leaving the factory (good, moderately good , poor). They found lower levels of lead in the blood of exposed children whose parents had lower exposures to lead on the job, and lower levels of lead among children whose parents had better hygiene. MSSORS (1982, p. 555) concluded: "...the data presented justify more stringent enforcement of lead containment practices..."

11.3 Choice of Research Hypothesis 339
11.3 Choice of Research Hypothesis
11.3.1 Narrow, Focused, Controlled Examination of a Broad Theory
Consider, first, a laboratory experiment in the physical or biochemical sciences. It begins with a broad theory that makes assertions about the effects of a treatment. Specifically, such a broad theory makes innumerable predictions about what would be observed in the innumerable circumstances in which the particular treatment might be applied, now and in the future, and in different locations. A laboratory experiment makes no effort to draw up a frame comprising all circumstances, locations, and times when the treatment might be applied and to draw a representative sample of such circumstances. Rather, the laboratory experiment examines the theory under highly unrepresentative circumstances, namely, circumstances in which sensitive, calibrated measuring instruments are used in an environment carefully freed of forces that might intrude on the experiment, in which the treatment is delivered at doses sufficient to produce dramatic effects if the theory is correct or to produce an equally dramatic absence of effect if the theory is incorrect. In a way, it is part of the essence of a laboratory experiment that its circumstances are unrepresentative. In a well-conducted laboratory experiment, one of the rarest of things happens: the effects caused by treatments are seen with clarity.
Observational studies of the effects of treatments on human populations lack this level of control, but the goal is the same. Broad theories are examined in narrow, focused , cont rolled circumstances.
Broad theories are desired because they predict more, and in consequence are both more useful and can be more thoroughly scrutinized. Quoting Popper (1968) again:
... those theories should be given preference which can be most severely tested (p . 121) ... if the class of potential falsifiers of one theory is 'larger' than that of another, there will be more opportunities for the first theory to be refuted by experience [...and...] the first theory says more about the world of experience than the second theory, for it rules out a larger class of basic statements.... Thus it can be said that the amount of empirical information conveyed by a theory, or its empirical content, increases with its degree of falsifiability (p. 112-113) [which] explains why simplicity is so highly desirable... [Simple theories] are to be prized more highly than less simple ones because they tell us more ; because their empirical content is greater; and bec ause they are better testable. (p. 142) Theories are not verifiable, but they can be 'corroborated' we should try to assess what tests, what trials, [the theory] has

340 11. Planning an Observational Study
withstood (p . 251) ... it is not so much the number of corroborating instances which determines the degree of corroboration as the severity of the various tests to which the hypothesis can he, ann has been , subjected, But the severity of the tests, in its turn, depends upon the degree of testability, and thus upon the simplicity of the hypothesis: the hypothesis which is falsifiable in a higher degree, or the simpler hypothesis, is also the one which is corroborable in a higher degree (p, 267).
Similar claims about simplicity, falsification and corroboration are made by Milton Friedman (1953, pp. 8-9) , who adds: "A hypothesis is important if it 'explains' much by little, that is, if it abstracts the common and crucial elements ... and permits valid predictions on the basis of them alone" (p . 14) and "...the only relevant test of the validity of a hypothesis is comparison of its predictions with experience" (p. 9) . As noted by Putnam (1995, p. 71), a similar point had been made earlier by Charles Sanders Peirce (1903, p. 418-419):
But if I had the choice between two hypotheses ... I should prefer ... [the one which] would predict more, and could be put more thoroughly to the test... It is a very grave mistake to attach much importance to the antecedent likelihood of hypotheses.... Every hypothesis should be put to the test by forcing it to make verifiable predictions.
The terms "falsify," "reject" or "refute," when applied to scientific theories, are not quite accurate. Lakatos (1981, p1l7) describes such a theory as "shelved," the implication being that the theory is stored along with the evidence against it . Under rare circumstances, a shelved theory might be reconsidered; see again the quote from Polanyi (1946, 1964) .
Broad theories permit close scrutiny in numerous particular cases, and a research hypothesis is intended to focus attention on one such case in which close scrutiny-a severe test-is possible. Passing such a severe test corroborates but does not prove the theory. Platt (1964), Meehl (1978), and Dawes (1996) make similar points.
11.3.2 Choice of Research Hypothesis in the Examples
In the economics example, broad arguments from comparative statics predict that increases in the cost of labor will diminish employment. If true, this theory operates in innumerable instances in the US economy on a daily basis; however, in almost all such instances, it operates amid numerous other forces that obscure its effects . For instance, if wages rise faster in one company than in a second company making a different brand of a similar product, then the theory may be true even though employment does

11.3 Choice of Resear ch Hyp othesis 341
not decline in the first company, precisely becau se increasin g demand for its br and of product may have led the first company to raise wages in an effort to increas e output by expanding its workforce. Even if the theory is correct, it rarely op erates in isolation. Car d an d Kru eger attempted to find one of t hose rare instan ces in which the t heory might be hoped to operate in relativ e isolation. Sp ecific as pects of t his isolation ar e discussed lat er , but t he point her e con cerns t heir choice of research hyp othesis. The effect of t he increase in the New J ersey minimum wage on fas t-fo od chains in 1992 is, in it self, at most a very minor footnot e to economic hist ory. However , as an opportunity to closely scrut inize and thereby possibly corroborate or refute the br oad theory t ha t forcible increases in the minimum wage cau se declines in employme nt, the 1992 increase in New Jersey's minimum wage becomes much more important. In observational st udies, one chooses a research hypothesis that permits a broad theory to operate dr am atically and in relative isolation.
Some account s in the popular press have emphas ized, perhaps even slight ly exaggerat ed, the breadth of the theory cha llenged by Card and Krueger 's results. Writing in Forbes, the Stanford economist Thomas Sowell (1995) sa id:
... if true, these results cha llenge the very foundations of economics. If rises in t he pri ce of labor do not reduce employment, why should we exp ect that a rise in t he pri ce of anyt hing else affect s t he qu an ti ty purchased? This is to economics wha t disproving t he law of gravi ty would be to physics.
Whether or not t his is what CK did, whether or not they were really ope rating on this sca le, nonetheless, the spirit of Sowell's remark is right: one seeks broad and consequent ial theories exposed to decisive cha llenges in focused , clear circumstances .
In the psychology example, th e belief that bereavement should have short- lived effects on mental functi oning ste ms from a much broader theory, the dominant but not universally accepted th eory in clinical psychology, which holds that the st ruc ture of mental functioning is largely shaped by a mixture of biology and experiences as a young child in relation to caret ake rs, usually parents. In particular, that theory suggests that bereavement should not greatl y alte r mental functioning over long periods of t ime . As in the economics example, if the broad theory is correct, then it is in const ant op er ation in innumerable lives, but in almost all cases its ope ration is obscured by limited knowledge of the biology of ment al functioning, by the difficulty in accurate ly measuring the expe riences of early childhood, and by t he difficulty in distinguishin g what is ca use and what is consequence in the mental life and experiences of an ad ult. Sudd en deaths from ca r crashes ar e a sit uat ion in which the broad theory operates or fails to ope rate with clarity.

342 11. Planning an Observational Study
Is it really true that a broad theory will be refuted or shelved based on a decisive challenge in a single, focused circumstance? Probably not. As argued by Lakatos (1970), a single , focused challenge may challenge a research program, may quicken interest in competing research programs, may stimulate further challenges in other focused circumstances, but it is unlikely to cause the immediate abandonment of a research program that has enjoyed some success. And this is for the best. Empirical studies, particularly observational studies, are attended by various uncertainties and ambiguities, some of which are difficult to quantify or even to identify, so consistent results in several studies are typically needed to force changes in the direction of a research program. Nonetheless, each such influential study is likely to examine the same broad theory in different focused circumstances, attended by different uncertainties.
In short, the choice of a research hypothesis focuses a broad theory on a narrow instance in which the theory's operation may be viewed clearly. Often, this setting permits the theory to operate in relative isolation from other forces, or to operate on a dramatic scale due to concentrated exposures, or else the treatment is imposed suddenly, at a discrete moment, in a manner not influenced by the individuals under study.
11.4 A Control Group
In design , one must choose a situation in which a control group can be constructed. A control group consists of subjects or units that did not receive the treatment. The control groups used in the three examples were described previously.
Some observational studies do not have a control group. For instance, in the st udy by DM\V, everyone covered by the Current Population Survey was in a region affected by the increase in the Federal minimum wage, so there is no control group-all subjects received the treatment. In contrast, the CK study of New Jersey's minimum wage had a control group consisting of branches of the same fast-food chains across the Delaware river in eastern Pennsylvania where the minimum wage had not been increased.
Lacking a control group, DMW estimate the effect of the increase in the Federal minimum wage using regression in the following way. The Federal minimum wage increases went into effect on April 1, 1990 and April 1, 1991, so DMW define years which begin on April 1 and end on March 31. They focus on two groups of individuals, namely, teenagers aged 15 to 19 and adult high school dropouts aged 20 to 54, reasoning that these groups contain a disproportionate number of individuals earning the minimum wage, so they should be most affected by changes in the minimum wage. These two groups are examined in parallel but separate analyses, but for brevity, only the analysis for teenagers is described here. Within

11.4 A Control Group 343
these groups, men, women, and blacks are examined in similar but not exactly parallel analyses; to permit a brief discussion here , the focus is on the analysis for male teenagers. For each year from 1985 to 1992, for each state, there is an outcome measure, namely the log of the fraction of male teenagers in the US who were employed, as estimated by the current population survey. DMW regress this outcome on the following predictors: (i) the log of the fraction of 15 to 64-year old men who were employed in the same state and year, (ii) state indicator variables, and (iii) indicator variables identifying the level of the Federal minimum wage. Concerning male teenagers, they write: "Compared to the employment level projected from the movement in aggregate employment with the $3.35 minimum wage, teenage employment was 4.8 percent ... lower in 1990 ... and 7.3 percent ... lower in 1991-1992." In other words , employment among male teenagers in 1990 and 1991-2 fell more sharply than employment among all 15 to 64-year old men in the same period, adjusting for state-to-state differences that are constant through time. Qualitatively similar though numerically different results were obtained for females, blacks, and adult high school dropouts. Their conclusion from these regressions was quoted earlier.
Conclusions reached in the absence of a control group are not necessarily wrong, but they are typically open to plausible objections and legitimate skepticism of types that are inapplicable with a control group. The assumption implicit in DMW's method of estimation is that changes in the log employment fraction for male teenagers would have been linearly related to changes in the log employment fraction among all 15 to 64-year old men if the minimum wage had not been increased, and any departure from such a linear change is an effect caused by the change in the minimum wage. Is this assumption self-evidently true? Might not employment among teenagers and high school dropouts fall disproportionately more than employment in the general workforce during times of generally declining employment even without an increase in the minimum wage? Alternatively, a rise in the minimum wage might increase employment in certain demographic groups and decrease it in others because employers find that they can pull into the workforce better educated or more-experienced workers who, at lower wages, would not work or who would work fewer hours. For instance, an anecdotal account in the popular press of changes in employment practices in response to the most recent increase in the Federal minimum wage describes an employer as introducing special hiring practices to avoid "wasting the extra 50 cents on unreliable help" (Duff 1996) . Even a bit of nonlinearity on the log scale might be mistaken for an effect of changing the minimum wage. Objections of this sort may well be incorrect and unfounded, but what is important here is that they can reasonably be raised for a study which lacks a control group.
If raising the minimum wage decreases employment then, DMW reasoned, the larger decreases should occur in groups with more minimum wage earners. Although DMW focused on comparisons involving teenagers

344 11. Planning an Observational Study
and adult dropouts, other groups with a disproportionate number of minimum wage earners were also examined briefly. For instance, low, medium and high wage states were compared, the first group being thought to be most affected by increases in the minimum wage . Men and women were compared, where women as a group receive lower wages . These comparisons pointed in the opposite direction from the comparisons discussed in earlier paragraphs; see DMW's Table 3. Employment in low wage states declined less than employment in high wage states and employment among women declined less than employment among men after increases in the minimum wage. Women in low wage states experienced no decline in employment. If increasing the minimum wage decreased employment, the reasoning DMW applied to teenagers and dropouts would have predicted larger employment declines in low wage states and among women. DMW (1995, p. 234) write: "T he latter fact is easily dismissed based on long-standing trends." Evidently, certain interactions do exist in which different demographic groups experience larger or smaller declines in employment, although DMW believe they can distinguish which effects are caused by the minimum wage and which are irrelevant demographic trends, and perhaps others will agree with them. Nonetheless, looking at the methodology, inconsistencies of this sort can arise in studies in which treated and control groups are replaced by groups with higher and lower exposure to the treatment.
An interesting paper by Holland and Rubin (1983) looks at various "par adoxes" that arise when there is no control group and a model or a calculation is used to estimate the treatment effect . They interpret the paradoxes as consequences of diverging, uncheckable, and unarticulated assumptions about what the control group would look like.
If a study lacks a control group, a minimal requirement is the articulation of the assumptions about what the control group would look like, together with a discussion of the tangible evidence in support of those assumptions and the sensitivity of conclusions t o violations of the assumptions. Articulation and evaluation of assumptions about the absent control group aid in judging the roles evidence and assumptions play in the study's conclusions.
In addition to a control group, baseline measures of the response are often useful. See §9.5, Cook, Campbell, and Peracchio (1990), Cook and Shadish (1994) , Allison (1990), and Rosenbaum (2001a) .
11.5 Defining Treated and Control Groups
11.5.1 Sharply Distinct Treatments That Could Happen to Anyone
In a randomized experiment, treated and control groups are defined by, first , defining the treatments themselves and, second, defining and implementing a mechanism for random assignment of treatments. Typically, in

11.5 Defining Treated and Control Groups

345

prolonged experiments with hum an populations, two or at most a few quite distinct treatments are compared (Peto, Pike, Armitage, Breslow, Cox, Howard, Mantel, McPherson, Peto, and Smith 1976).
The situation in observational studies is different . The investigator does not control the assignment of treatments to subjects, and so must define a treated and a control group using available subjects who have already received treatment or control. The goal in defining the treatment groups should be to produce a situation that resembles, to the extent possible , the situation in a randomized experiment: markedly distinct treatments that could happen to anyone. Consider the two parts separately.
In discussing the design of controlled trials, Peto, et al. (1976, p. 590) say :

A positive result is more likely, and a null result is more informative, if the main comparison is of only 2 treatments, these being as different as possible . ... it is the mark of good trial design that a null result, if it occurs, will be of interest.
Treatment groups that are distinct in concept but not in actual implementation may not differ in their outcomes even if the conceived but unimplemented distinction would have an important effect on outcomes. For instance, this was a concern in a National Academy of Sciences report on studies of bilingual education which found that: "... Immersion and Earlyexit Programs were in some instances indistinguishable from one another" (Meyer and Fienberg 1992, p. 102).
To say that the distinct treatments "could happen to anyone" is shorthand. One wishes to define the treated and control groups in such a way that the treatment could easily have happened to the controls, and the treated subjects could easily have been spared the treatment, the actual assignment of subjects to treatments being determined by haphazard or ostensibly irrelevant circumstances. Haphazard is not random, and haphazard treatment assignments can produce severe, consequential, and undetected biases that would not be present with random assignment of treatments. Still, haphazard or ostensibly irrelevant assignments are to be preferred to assignments which are known to be biased in ways that cannot be measured and removed analytically.

11.5.2 Examples of Defining Treated and Control Groups
An example of careful defining of treated and control groups comes from the study by LWW of the effects of a traumatic loss of a spouse or child. First, the treated and control conditions are markedly distinct. The loss is confined to a spouse or a child less than 18 years of age living at home, and the loss was produced suddenly by a car crash. One could study the effects of a loss of other relatives, such as an adult's parent or an adult's

346 11. Planning an Observational Study
adult sibling , or gradual losses due to chronic disease, but these might have smaller psychological effects. As in experiments, effects should be demonstrated for markedly distinct treatments before refined studies of smaller effects are undertaken.
Second, LWW took care to define the treated group so it "could happen to anyone" . In particular, they used published, relatively objective criteria to appraise probable responsibility or fault in the car crashes, and then insisted that the treated group consist of individuals from cars that were not at fault . For instance, if one car crossed a center dividing line and collided with an oncoming car , the occupants of the first car would be ineligible for the study while the occupants of the second car would be eligible . Their reasoning was that fault in car crashes is related to alcohol and drug use and to certain forms of psychopathology, all of which would be studied later as outcomes for survivors. In contrast, a car crash for which one is not responsible could happen to any driver. No matter what the particulars, car crashes are a far cry from random numbers, but car crashes for which one is not responsible are plausibly a limited but meaningful step closer to random.
In studying the effect of class size on academic achievement, Angrist and Lavy (1999) give another interesting example of sharply distinct treatments that could happen to anyone. In the US, a class of size 40 will often be located in a very different school district than a class of size 20, so it is difficult to distinguish the effects of class size from the other consequences of the differences between school districts. In contrast, Israeli public schools implement the following version of a rule due to Maimonides: when class size exceeds 40 students, the class must be divided. In this case , a class of size 41 becomes two much smaller classes. In that setting, one might compare certain classes of size near 40 to split classes of size near 20, knowing that these are very different class sizes, and yet the rather minor event of enrolling one or two more st udents determined this dramatic change in class size. Again, this is not a random assignment of class sizes to students, but it is a meaningful step closer to random. Angrist and Krueger (1999) discuss additional examples.
Still anot her example of sharply distinct treatments that could happen to anyone is found in Bronars and Grogger's (1994) study of the economic consequences of unwed motherhood. Here, too, as a group, women who bear children prior to marriage differ from unmarried women who do not bear children, and it is important to avoid mistaking these differences from economic effects of an additional unplanned child . Instead of comparing these two groups, Bronars and Grogger compared unwed mothers who had twins to unwed mothers who had singletons, reasoning that having twins rather than a single child is a comparatively haphazard event, one that could happen to anyone. See also Rosenzweig and Wolpin (1980, 2000).

11.6 Competing Theories, Not Null and Alternative Hypotheses 347
11.6 Competing Theories, Not Null and Alternative Hypotheses
In his essay, "How to be a good empiricist-a plea for tolerance in matters epistemological," Paul Feyerabend (1968) writes:
You can be a good empiricist only if you are prepared to work with many alternative theories rather than with a single point of view and 'experience' . This plurality of theories must not be regarded as a preliminary stage of knowledge which will at some time in the future be replaced by the One True Theory. Theoretical pluralism is assumed to be an essential feature of all knowledge that claims to be objective.... The function of such concrete alternatives is, however, this: They provide means of criticizing the accepted theory in a manner which goes beyond the criticism provided by a comparison of that theory 'wit h the facts' .... This, then, is the methodological justification of a plurality of theories: Such a plurality allows for a much sharper criticism of accepted ideas than does the comparison with a domain of 'facts' which are supposed to sit there independently of theoretical considerations. (p. 14-15)
Elsewhere, Feyerabend (1975) argues that alternative theories are needed to unearth new facts , advising one to:
...introduce and elaborate hypotheses which are inconsistent with well-established theories and/or well-established facts . ... [T]he evidence that might refute a theory can often be unearthed only with the help of an incompatible alternative (p. 29) ... [M]any facts become available only with the help of alternatives, [so] the refusal to consider [alternative theories] will result in the elimination of refuting facts as well (p. 42).
Popper (1965, p. 112) makes a closely related point:
A theory is tested not merely by applying it , or trying it out, but by applying it to very special cases-cases for which it yields results different from those we would have expected without that theory, or in the light of other theories. In other words we try to select for our tests those crucial cases in which we should expect the theory to fail if it is not true. Such cases are 'crucial' in Bacon's sense; they indicate the cross-roads between two (or more) theories.
Lakatos (1981, p. 114-5) distinguishes the "int ernal" testing of theories from the "ext ern al" competition between theories, suggesting the latter is an aid to the former:

348 11. Pl ann ing an Observational St udy
facts are only noticed if they conflict with some previous expectation. [This is a] cornerstone of Popper's psychology of discovery. Feyerabend developed another interesting psychological thesis of Popper's, namely, that proliferation of theories may-externally-speed up internal Popperian falsification (pp. 114-115).
In his paper of 1890, T . C. Chamberlin (1965, p756) argued for the "method of multiple working hypotheses":
The value of a working hypothesis lies largely in its suggestiveness of lines of inquiry that might otherwise be overlooked. Facts that are trivial in themselves are brought into significance by their bearings upon the hypothesis, and by their causal indications . .. In the use of the multiple method, the re-action of one hypothesis upon another tends to amplify the recognized scope of each, and their mutual conflicts whet the discriminative edge of each.
Endorsing Chamberlin's "method of multiple working hypotheses," John Platt (1964, p. 347) argued:
. .. rapidly moving fields are fields where a particular method of doing scientific research is schematically used and taught , an accumulative method of inductive inference that is so effective that I think it should be given the name of 'strong inference.' . .. Strong inference consists of applying the following steps to every problem in science, formally and explicitly and regularly:
1) Devising alternative hypotheses; 2) Devising a crucial experiment (or several of them), with alternative possible outcomes, each of which will, as nearly as possible, exclude one or more of the hypotheses; 3) Carrying out the experiment so as to get a clean result; 1*) Recycling the procedure . . . Any conclusion that is not an exclusion is insecure . . .
A scientific theory that has been fairly successful-a theory discussed in journals and textbooks, explained to undergraduates, offered to graduate students as an area for research, and so on-is likely to agree with empirical observations at many points and to seem helpful in interpreting those observations. Certainly, sufficiently large, externally imposed increases in the price of a commodity may cause demand to decrease, and both biology and the events of early childhood may have enduring effects on mental functioning. Both of these theories offer coherent interpretations of frequent observations. A successful theory is likely to work in many situations; this is an aspect of its success . Unaided by a competing theory, an empirical

11.6 Competing Theories, Not Null and Alt ern ative Hypotheses 349
investigation may do no more than rediscover why the successful theory achieved success in the first place . Such an investigation may not place the successful theory at much risk of refutation, and since it was never at much risk, failing to refute the theory provides little corroborating evidence in support of the successful theory.
A competing theory focuses attention on certain observable events about which the successful theory and its competitor make very different predictions. The competing theory directs attention to places where the successful theory might fail, placing the successful theory at severe risk of refutation. The competing theory anticipates a particular refutation of the successful theory, making refutation of the successful theory more likely and more decisive , and providing stronger corroborat ion of th e successful theory if its predictions turn out to be correct. Card and Krueger quote the following remark of Paul Samuelson : "In economics it takes a theory to kill a theory; facts can only dent a theorist 's hide" (Card and Krueger 1995, p . 355) .
The conventional argument anticipates that an increase in the minimum wage in New Jersey drives up the cost of some labor in New Jersey, with two consequences for employment: first , an increase in prices of final products resulting in reduced demand, and second a tendency to substitute capital equipment, whose cost has not increased , for labor, whose cost has increased. The increase in the minimum wage affects all New Jersey firms, so the price increases may have smaller effects on a single firm's business than would be the case if that one firm raised prices while other firms did not. Card and Krueger (1995, p. 359) express thi s same idea more formally as follows:
For purposes of modeling the effect of an industry-wide wage increase, however, the relevant product-demand elasticity is one that takes into consideration simultaneous price adjustments at all firms . This elasticity will tend to be smaller (in absolute value) than the elasticity of demand for a firm's output with respect to its own price. In the case of the restaurant industry, for example, any individual restaurant presumably faces a relatively elastic demand for its product, holding constant prices at nearby restaurants. When the minimum wage increases, however, prices will tend to rise at all restaurants, resulting in a smaller net reduction in demand at any particular firm.
In other words, if Roy Rogers alone raised the price of hamburgers, it might face a substantial decline in business as customers switched to Burger King , but if all restaurants raise prices at the same time, the decline in business might be much smaller. Notice that this is particularly true of the fast-food industry, because it is not practical for a New Jersey restaurant to import cooked food from , say, Hong Kong or Pennsylvania, to escape the

350 11. Pl anning an Observati on al Study
effect s of the minimum wage increase in New J ersey. If the conventional argument were incorrect, if increases in the minimum wage had onl y slight effect s when simult aneous price adjustments occur in all firms, then the fast -food industry, though unrepresentative of all industries, is one place to see this. Both theories accept that increases in the minimum wage might result in higher prices for fast-food, but only one theory predicts a dramatic decline in business and employment in the fast-food industry. In fact , Card and Krueger (1994, §§3E and 5) found no association between increases in th e minimum wage and (i) the number of hours a restaurant is open on a weekday, (ii) the number of cash registers, (iii) the number of cas h registers in operation at ll:OOam , but they did find some evidence of slightl y higher increases in prices in New Jersey than in Pennsylvania during this period. During the period of the minimum wage increases, CK (1984 , Table 2) found that the average price of a specifically defined "full meal" changed from $3.04 to $3.03 in the Pennsylvania restaurants and from $3.35 to $3.41 in the New Jersey restaurants. In other words, the st ru ct ure of a competing theory suggests where to look to test a standard theory, for instance, which industry to study and which outcome measures to examine.
Card and Krueger (1995) write: "We suspect that the st andard model ... does correctly predict the effect of the minimum wage on some firms ," (p. 355) but they say their results are "...inconsistent with the proposition that the standard mod el is always correct" (p. 383). Whether or not one agrees with CK about the minimum wage , the methodological issue is clear: A study of a narrow and unrepresentative corner of a population cannot, by itself, be the sole bas is for policy for the whole population, but it may provide a severe test of a theory that purports to apply throughout the population. Failing such a test raises doubts about using that theory as the sole basis for policy, whereas passing such a sever e test corroborates the theory, and tends to strengthen the case for using it as a basis for policy.
Similar, if more dir ect , considerat ions apply in the LWW st udy. A theory which suggests that mental functioning is largely shaped by biology and ear ly childhood experiences might reasonably be contrasted with a theory which holds that events lat er in life shape mental fun ctioning over long periods. Sudden deaths of close relatives in car crashes are instances in which these theories make markedly different predictions.
In short, scrutiny of a theory is aided by a competing theory. The competition between theories suggests circumstances in which the theories make sharply different predictions about particular observable quantities.

11.7 Internal Replication: Multiple Treatment Assignment Mechanisms 351
11.7 Internal Replication: Multiple Treatment Assignment Mechanisms
Replication is important in observational studies, as it is in experiments. Susser (1987) writes:
The epidemiologist's alternative to exact replication is the . consistency of a result in a variety of repeated tests... Consis-
tency is present if the result is not dislodged in the face of diversity in times, places, circumstances, and people, as well as of research design (p. 88).
In part, biases that are peculiar to the circumstances of one study may not replicate, whereas an effective treatment is expected to produce similar results in studies of varied circumstance and design.
Some observational studies incorporate a form of internal replication. These studies replicate the treatment assignment mechanism, so that essentially the same treatment is assigned to subjects by more than one process. As discussed in a moment, this is true of two of the examples. If two treatment assignment mechanisms produce a pattern of associations consistent with an actual treatment effect, then to explain the pattern as a hidden bias, one must attribute a bias to both assignment mechanisms, and moreover a bias yielding the pattern anticipated from an actual effect. In Popper's terms, each mechanism provides a check on the theory that the treatment is the cause of its ostensible effects, so if several assignment mechanisms produce compatible estimates of effect , then this theory receives greater corroboration.
In the MSSORS study, children were exposed to low levels of lead in three different ways. First, the parents of control children did not work in the battery factory. Second, among exposed children whose parents did work in the battery factory, some were believed to have received lower doses of lead because their parents worked in jobs in the factory that provided little exposure to lead. Third, some parents exposed to high levels of lead practiced good hygiene. In fact, no matter which device assigned a child to low exposures to lead, the results were similar: children with lower exposures tended to have less lead in their blood. This pattern could, conceivably, be the result of hidden bias, but it is somewhat more difficult, though of course not impossible, to imagine biases that would produce all three associations.
In the CK study of the increase in the New Jersey minimum wage, a fast-food restaurant could escape a legal requirement to increase wages in either of two ways . Restaurants in Pennsylvania were not required to increase wages. Restaurants in New Jersey whose lowest wage was above the new minimum wage were not required to increase wages. In connection with their Table 3, CK (1994 , p. 778) write: "Wit hin New Jersey, employment

352 11. Planning an Observational Study
expanded at the low-wage stores ... and contracted at the high-wage stores... Indeed, the average change in employment at the high-wage stores... is almost identical to the change among Pennsylvania stores..." In other words, restaurants placed under no new legal requirement by the minimum wage saw similar employment changes ; whether they were Pennsylvania restaurants or high-wage New Jersey restaurants.
In short, the central concern in an observational study is that treatments may be assigned to subjects in a biased manner. The choice of a setting in which essentially the same treatment is assigned to subjects by several very different processes provides a partial check of this central concern. More precisely, the theory that the treatment is the cause of its ostensible effects predicts similar effects no matter which mechanism delivered the treatment, and this prediction offers an opportunity to refute or corroborate the theory.
11.8 Nondose Nonresponse: An Absent Association
A causal theory not only predicts the presence of certain associations, but also the absence of certain others. In some studies, it is possible to determine the dose of treatment that a control would have received had this control received the treatment. Call this the potential dose. While it is often reasonable to expect higher responses from treated subjects who received higher doses (see §8.5), the same pattern is not expected among comparable controls: higher potential doses that were never received should not predict higher responses if higher responses are being caused by the treatment.
The minimum wage study contains an example. Card and Krueger (1994) define a measure, GAPi, of the impact of the minimum wage legislation on restaurant i , as the percentage increase in the starting wage in restaurant i needed to achieve the new New Jersey minimum wage. A restaurant that
already paid more that the new minimum would have GAPi = O. A restau-
rant that paid the old minimum wage would have GAPi = 18.8%. This variable GAPi resembles a dose of treatment in that the law has greater impact on the starting wage when GAPi is larger. A concern, however, is that GAPi is not only a dose of treatment, but also a variable describing local labor market conditions. Presumably, some restaurants must pay higher starting wages than others to attract employees, so GAPi is confounded with labor market conditions. For instance, the labor market in the poor city of Camden is different from the labor market in the relatively affluent suburb of Princeton. Still, it is not unreasonable to think that this confounding operates in a similar way in New Jersey and Pennsylvania. For the control restaurants in Pennsylvania, the undelivered potential dose of treatment is the percentage change in the starting wage needed to achieve New Jersey's new minimum wage. If these undelivered potential doses predicted employment changes in Pennsylvania, then that could not

11.9 Stability Analyses, and Minimizing the Need for Stability Analyses 353
be an effect of New Jersey's minimum wage legislation, and would strongly suggest confounding. Card and Krueger (1994, p. 784) write:
...we exclude stores in New Jersey and (incorrectly) define the variable for Pennsylvania stores as the proportional increase in wages necessary to raise the wage to $5.05 per hour. In principle the size of the wage gap for stores in Pennsylvania should have no systematic relation with employment growth. In practice, this is the case. There is no indication that the wage gap is spuriously related to employment growth.
In short, there is often the concern that not only the assignment to treatment or control but also the dose of treatment is confounded with unobserved covariates. When potential but undelivered doses are known for controls, the theory that the treatment is the cause of its ostensible effects predicts that delivered doses in the treated group should be related to the magnitudes of responses, but, at each fixed value x of observed covariates, undelivered doses in the control group should be unrelated to responses. This prediction provides an additional check of the theory that the treatment is the cause of its ostensible effects.
11.9 Stability Analyses, and Minimizing the Need for Stability Analyses
A complex analysis involves numerous implementation or analytical decisions. The audience for such an analysis typically wishes to be assured that conclusions are not artifacts of such decisions , but rather are stable over analyses that differ in apparently innocuous ways. All three examples include stability analyses for certain decisions, as described below.
A sensitivity analysis asks to what extent plausible changes in assumptions change conclusions. In contrast, a stability analysis asks how ostensibly innocuous changes in analytical decisions change conclusions. A sensitivity analysis typically examines a continuous family of departures from a critical assumption, in which the magnitude of the departure and the magnitude of the change in conclusions are the focus of attention. In contrast, a stability analysis typically examines a discrete decision, and the hope and expectation is that the conclusions are largely unaltered by changing this decision. Stability analyses are necessary in most complex analyses; however, the extent to which they are needed varies markedly from study to study.
As an example of a stability analysis, consider the MSSORS study of lead exposures, which needed to address the possibility that workers exposed to lead were more likely to have lead-related hobbies. MSSORS (1982, pp. 552-553) write:

354 11. Pl anning an Obse rvationa l St udy
...11 pairs were found in which t he st udy children had potential for lead expos ure ot her than that du e to the father 's occupat ion, while their matched cont rols had no such exposures . Exogenous sources of lead found in t he child re n 's environment were automobile bo dy painting, casting of lead and playin g wit h spe nt gun shell casings in t he home. Six children in the st udy group had fathers whose hob by was cas t ing lead into fish sinkers ; none of t he cont rol childre n's fathers did this. It was speculated t hat those who work with lead on t he job are more accusto med to handling lead , thereby promoting it s use in t he home environment .... [A]ny st udy/control mat ched pair in which one of th ese hobbies was pr esent for the st udy child and not pre sent for the cont rol was eliminat ed from the ana lysis. ... When these 11 children and their controls were eliminate d, and the rem aining 22 pairs were analyzed , the st udy and cont rol
groups cont inued to be stat ist ically differ ent (p < .001) .
MSSORS go on to show that the est imat es of lead levels do not change much when the 11 pairs are excluded . Notice that a discre te decisionwhether or not to include t he 11 pairs-is investigated by car ry ing out the ana lysis both ways and comparing the results, a process that is very different from sensit ivity ana lysis.
Similarl y, in the LWW study of the effects of t he death of a spouse or child in a car crash , there was concern that the death of a spo use might alte r famil y income an d, possibly, that it was t his sustained loss of income and not the death itself t ha t has psychologic al effects . This was invest igated by adjust ing for income by regression , concluding that most of t he findings rem ained stable (LWW 1987, p. 226). The minimum wage study included several st ability analyses, for inst anc e, various ways of handling temporarily closed restaurants; see CK (1984, Tabl e 5) .
The examples mentioned above have a common feature that ari ses frequently in observat ional studies. Because it is clear that one wishes to compare trea ted and control subje cts who were comparable prior to treatment, it is clear that visible pr etreatment differenc es need to be removed by adjustments of one kind or anot her. It may happen, however, that treated and control groups are not ed to differ after the start of treatment. In this case, the posttreatment difference may reflect unobserved pretreatment differences or effects caused by t he treatment or the effects of other treatments occurring at the same tim e. Lead hobbies are another treatment coexisting with occupat ional lead exposure. Income loss is an outcome affected by the loss of a spouse. The closing of rest aurants may be related to business condit ions, the level of the minimum wage being one such condition. Adjustments for posttreatment differences may remove part of the act ual treatment effect , and they may eit her remove bias or introduce bias into compar isons (Rosenbaum 1984). St ability analyses ar e common in this sett ing, and they

11.10 The Role of Time: Abrupt, Short-Lived Treatme nts 355
seek to dem onstrate t hat results are st able wheth er or not adj ust ments are mad e for a posttrea tment difference. An alte rnative approac h is to be explicit abo ut the effect of the treatment on t he posttreatment variable, replacing t he discrete choice of a stability analysis by the continuous variation in ass umptions of a sensitivity ana lysis; see Rosenbaum (1984, §§4.3, 4.4) for det ail ed discussion of this alte rnative.
As anot her example with a different result , t he minimum wage deb at e between Neumark a nd Wasch er (1992) and Card, Katz, and Krueger (1994) turns in part on a stability a na lysis. Neumark and Wascher (1994) had conducte d a panel study of cha nges in state minimum wages between 1973 and 1989 in relation to unemployment among teenagers and young adults, reaching the conclusion that increases in min imum wages depr ess employment. Card, Katz, and Krueger then commented that the results were unst able in the following sense. Newm ark and Wascher had mad e adjust ment s for the "proport ion of the age group enrolled in school". Card, Katz, and Krueger argued that , first , the conclusions about the minimum wage change dram atically if adjustments ar e not made for this variable and, second, that the definition of this variable is such that it is "mechanically" related to the response variable, nam ely employment, because anyone workin g even part-time was counte d as not enro lled in school. In their response, Neumark a nd Was cher disagreed.
The purpose here is to examine methodology and not the minimum wage deb ate. From a methodological view, the st udy by Newmar k and Was cher (1992) reli es heavily on analytical mod els in comparisons, whereas the st udy by Card and Krueger (1994) relies more on the design of t he st udy and t he choice of circumstances in which fairly compa rable uni ts are compare d, her e restaurants from the sa me chai ns in adjacent states . A st udy that relies heavily on an alytical mod els and adjustments will mak e many more implementation decisions in a na lysis, and so will need to conduct more extensive stability analyses to be convincing. This is an argument in favor of simple st udy designs that compar e ost ensibly comparable units under alternative treatments.
11.10 The Role of Time: Abrupt, Short-Lived Treatments
The concept that a treatment must precede its effects influences the design of an observational st udy in many ways. A tre atment may be delivered over a prolonged period of time, so the distinction between what precedes a t reat ment and what follows it may not be shar p. Subjects may swit ch from one treatment to another, possibly in part in response to an earlier failure of the first treatment. Other extraneous treatments may intervene, and these interventions may themselves be , in part, effects st imulated by

356 11. Planning an Observational Study
the treatments under study. Subj ects may know about the treatment before they receive it , and part of the ultimate effect of the treatment may begin to materialize before the treatment is delivered. For instance, t he increases in New Jersey 's minimum wage were public legislation well before the increases actually took place. For discussion of various asp ects of the role of time in intervention st udies, see Campbell and Stanley (1963 , p. 5-6), Diggle, Liang and Zeger (1994), Holland (1993) , Joffe et al. (1998), Li, Propert, and Rosenbaum (2001), Peto et al. (1976) , Robins (1989, 1992, 1998), Robins, Rotnitzky and Zhao (1995), Rosenbaum (1984, 2001a) , Rubin (1991, §5.2), Schafer (1996), Sobel (1995), and Susser (1987, p. 86) .
In research design , given th e choice, one would pr efer a single, abrupt, unexpected, short- lived treatment of dramatic proportions. With such a treatment, the line between what precedes treatment and what follows it is sharply drawn. This is true of only one of the three examples, namely the LWW study of th e psychological effects of the death of a spouse or a child in a car crash.
Abrupt, unexpected, short-lived treatments of dramatic proportions are sometimes informally associated with the term "exogenous" as it is used in econometrics. However, formal discussions of "exogeneity" actually define the matter rather differently (e.g., Engle, Hendry, and Richard 1983). In sociology, Giddens (1979, p. 127-128) makes a related point about the role of "crit ical situations":
We can learn a good deal about day-to-day life in routine settings from analysing circumstances in which those settings are radically disturbed. . . . By a critical situation I mean a set of circumstances which-for whatever reason-radically disrupts accustomed routines of daily life.
Another example of an abrupt, short-lived treatment is found in a study of the effects of immigration on labor markets. This is generally a difficult topic because immigration occurs gradually and immigrants may favor labor markets where jobs are available and attractive. It is usually difficult to disentangle the effects of immigration on labor markets from the effects of labor markets on immigration. Card (1990) exploited a rare exception, in which immigration was abrupt, short-lived, unexpected, and of dramatic proportions. In the Mariel Boatlift, about 125,000 Cubans immigrated to Miami between May and September, 1980, increasing Miami's labor force by seven percent. Card compared changes in Miami's labor market following the Mariel Boatlift to the concurrent changes in four unaffected cities, Atlanta, Houston, Los Angeles, and Tampa-St. Petersburg.
Many interesting treatments are not short-lived, but rather , by their nature, are prolonged or chronic. For such treatments, given the choice , one would prefer an abrupt , comparatively haphazard start of a chronic treatment that, once started, is inescapable. In discussing the effects of

11.11 Natural Blocks 357
prolonged or chronic stress as a cause of depression, Kessler (1997, p. 197) discusses this clearly:
. . . a major problem in interpret[at ion] ... is that both chronic role-related stresses and the chronic depression by definition have occured for so long that deciding unambiguously which came first is difficult .. . The researcher, however , may focus on stresses that can be assumed to have occurred randomly with respect to other risk factors of depression and to be inescapable, in which case matched comparison can be used to make causal inferences about long-term stress effects . A good example is the matched comparison of the parents of children having cancer, diabetes, or some other serious childhood physical disorder with the parents of healthy children. Disorders of this sort are quite common and occur, in most cases, for reasons that are unrelated to other risk factors for parental psychiatric disorder. The small amount of research shows that these childhood physical disorders have significant psychiatric effects on the family.
11.11 Natural Blocks
Another opportunity to use choice in place of control in the design of an observational study involves natural blocks. Whereas matching is used to pair unrelated individuals having similar values of measured covariates, natural blocks create pairs or groups of individuals who are related in ways judged to be important but difficult to measure explicitly. Twins, siblings, neighbors, and schools are familiar examples of natural blocks .
Twins, for example, resemble one another in terms of genetics and childhood environment in many ways that cannot practically be described in measured covariates. The LWW study of the psychological effects of the loss of a spouse or of a child could not adjust for genetic differences between exposed subjects and controls. In related work, Lichtenstein, Gatz, Pedersen, Berg, and McClearn (1996) examined the psychological effects of widowhood by comparing twins, one bereaved and one still married. In partial corroboration of the LWW study, they also found long term psychological effects of the loss of a spouse, suggesting that genetic differences are not a likely explanation of the psychological outcomes.
Behrman, Rosenzweig, and Taubman (1996) use twins in an economic observational study of the effect of college quality on subsequent earnings. Ashenfelter and Krueger (1994) make a similar use of twins, while Altonji and Dunn (1996) use siblings instead.
It is possible to combine matching for covariates and pairing using natural blocks. In the MSSORS study of lead exposure, exposed and control

358 11. Planning an Observational Study
children were compared to a neighbor's child of about the same age. Here, age is a covariate whereas neighborhood is a block. Similarly, in Rosenbaum (1986), high school dropouts were matched to students with similar grades, test scores , and behavior who remained in the same high school. Here , the high school is the block. In both cases, matching controlled for blocks and began the adjustment for covariates.
11.12 Refute Several Alternative Explanations
The common, perhaps inevitable, criticism of an observational st udy is that individuals who appeared comparable before treatment in terms of observed covariates were, in fact , not comparable, and that differing outcomes after treatment reflect this lack of comparability, not an effect caused by the treatment. In this context, Campbell (1957) insisted on a certain logic, a certain standard for criticism, namely that objections to an observational study be expressed as specific , credible threats to validity, or "grounds for doubt" in Wittgenstein's phrase (1972, p. 18); see also Bross (1960), Gastwirth, Krieger and Rosenbaum (1997), and Shadish and Cook (1999). Anticipating specific grounds for doubt, Campbell (1957) argued for improving the design to address these specific issues. Instead of assuming that hidden biases are absent, that what isn't visible is equal-the so-called ceteris paribus clause-one assumes specific biases may be present and investigates them. This is similar to advice offered by Lakatos (1970, p. 110):
How can one test a ceteris paribus clause severely? By assuming that there are other influencing factors , by specifying such factors, and by testing these specific assumptions. If many of them are refuted, the ceteris paribus clause will be regarded as well-corroborated.
Strengthen evidence by eliminating weaknesses, one weakness at a time.
11.13 Bibliographic Notes
This chapter is adapted from Rosenbaum (1999). The paper discusses several issues in greater depth, and is accompanied by interesting discussion by Manski (1999), Robins (1999), and Shadish and Cook (1999) , together with a rejoinder. Good , recent general discussions of the early planning of observational studies are given by Cook, Campbell, and Peracchio (1990) , Cook and Shadish (1994), Meyer (1995), Angrist and Krueger (1999) , Rosenzweig and Wolpin (2000), and Shadish, Cook and Campbell (2002) . The design of replications of observational studies is discussed in Rosenbaum (2001b) .

11.14 Problems

11.14 Problems 359

1. Environmental influences on eating and physical activity. Successful planning of an observational study requires a genuine puzzle in a context that is familiar. The context needs to be familiar so one can think concretely about plausible sources of bias, grounds for doubt, and what to do about them. In advanced scientific work, the context may be familiar only to the relatively few people who conduct studies in that area, but for a textbook problem, the context needs to be generally familiar. There is evidence that obesity is increasingly common in the United States; see Kuczmarski, Flegal, Campbell, and Johnson (1994) for evidence from the National Health and Nutrition Examination Survey. The question is: Why? Presumably it reflects changes in either eating patterns or physical activity or both, but the question is: What caused those changes? A thoughtful survey of possibilities is given by French, Story, and Jeffery (2001). They write : "Documenting the environmental influences on population physical activity and eating behaviors has posed an even greater challenge than documenting individual behaviors because such influences are difficult to define, measure, and study experimentally." Over roughly 25 years, they document: (i) dramatic increases in the consumption of cheese, up 146%, and soft drinks, up 131%, but a 3% increase in grams of fat consumed per day, (ii) dramatic increases in the number and use of restaurants, especially fast-food restaurants, and the commercial failure of several efforts by fast-food restaurants to market lower-fat options, and (iii) growing portion sizes, for instance, for soft drinks. They discuss convenience foods, pizza, "take-out ," women working outside the home, the large amounts spent on food and restaurant advertising, and the relative prices of different foods . Concerning physical activity, they discuss television , VCR's, computer games, and health clubs. Many possible hypotheses, and a context that is, well, familiar. As one specific suggestion: consider the hypothesis that food prepared by fast-food restaurants plays a large role, versus the alternative that its role is minor. Can you think of a control group, that is, a group that rarely or never eats in fast-food restaurants? Preferably, the control group would be formed not by food preferences, but rather by something ostensibly irrelevant. Can you think of more than one control group of this sort? Are these control groups representative of the US population? If not, can you find an exposed group or several exposed groups, perhaps also unrepresentative, but quite similar to the controls? Can you identify instrumental variables, that is, haphazard limitations on access to fast-food restaurants, limitations that can affect diet and physical activity only through limitations on access? What outcomes would you measure? What would constitute a coherent treatment effect?

360 11. Plan ning an Ob servational St udy
W ill you frame the hypothesis to have imp lications for meals eaten at home?
2. Read ethnographic accounts. The previous problem suggested t hat successful plan ning of an observational study req uires familiarity wit h t he context in which t he st udy will be conducted. Familiari ty with context is easily at tained for a few top ics, but for many others , familiarity is attained only t hro ugh yea rs of effort, perhap s acco mpanied by personal risk. For such difficult to pics, some familiarity ca n be at tained by reading a few et hnogra phic acco unts before planning an observatio na l st udy. The best way to cultivate t he habit of reading . et hnographic accounts before planning a n observational st udy is t o read one now. Some good choices ar e Becker (1972), Bosk (1981), Estroff (1985), and Anderson (2000).
11.15 References
Allison , P. D. (1990) Ch ange scores as dep endent variables in regression analyses. In : Sociological Methodology, C. C. Clogg, ed ., Oxford: Basil Blackwell, pp. 93-114.
Altonji, J. G. and Du nn, T . A. (1996) Using siblings to esti mate t he effect of school quality on wages. Review of Economics and St atistics, 77, 665-671.
Anderson, E. (2000) Code of the Streets: Decency, Violence and the Moral Life of the Inner City. New York: Norton.
Angrist, J . D. and Krueger, A. B. (1999) Empirical strategies in lab or economics. In: Handbook of Labor Economics, III, New York: Else vier , Ch apter 23.
Angrist , J. D. and Lavy, V. (1999) Using Maimonides' rul e t o est imate the effect of class size on scholas ti c achievement. Quart erly Journal of Economics, 533-575 .
Ashenfelt er , O. A. and Krueger , A. B. (1994) Estimates of the economic return to schooling from a new sa mple of twins. American Econom ic Review, 84, 1157-1173.
Becker , H. S. (1972) Outsiders: Studies in the Sociology of Deviance. New York : The Free Press.
Behrman , J. , Rosenzweig, M., a nd Taubman, P. (1996) Co llege choice and wages: Estimates using dat a on fem ale tw ins. The Review of Economics and St atistics, 672-685.

11.15 Refer ences 361
Bosk, C. L. (1981) Forgive and Remember: Managing Medical Failure. Chicago: University of Chicago Press.
Box, G. E. P. (1966) The use and abuse of regression. Technometrics, 8, 625- 6 2 9 .
Bronars, S. G. and Grogger, J . (1994) The economic consequences of unwed motherhood: Using twin births as a natural experiment. American Economic Review, 84 , 1141-1156.
Bross, 1. D. J. (1960). Statistical criticism. Cancer, 13 ,394-400. Reprinted in: The Quantitative Analysis of Social Problems, E. Tufte, ed., Reading, MA: Addison-Wesley, pp. 97-108.
Campbell, D. T. (1957) Factors relevant to the validity of experiments in social settings. Psychological Bulletin, 54, 297-312.
Campbell, D. T. (1984, 1988) Can we be scientific in applied social science? Evaluation Studies Revi ew Annual, 9, 26-48. Reprinted in: D. Campbell, Methodology and Epistemology for Social Science : Selected Papers. Chicago: University of Chicago Press, pp . 315-333 .
Campbell, D. and Stanley, R. (1963) Experimental and Quasi-Experimental Designs for Research. Chicago: Rand McNally.
Card, D. (1990) The impact of the Mariel Boatlift on the Miami labor market. Industrial and Labor Relations Review, 43, 245-257.
Card, D., Katz, L., and Krueger, A. (1994) Comment. Industrial and Labor Relations Review, 48, 487-496 .
Card, D. and Krueger, A. (1994) Minimum wages and employment: A case study of the fast-food industry in New Jersey and Pennsylvania. American Economic Review, 84, 772-793 .
Card, D. and Krueger, A. (1995) Myth and Measurement: The New Economics of the Minimum Wage. Princeton, NJ : Princeton University Press.
Card, D. and Krueger, A. (2000) Minimum wages and employment: A case study of the fast-food industry in New Jersey and Pennsylvania: Reply. American Economic Review, 90, 1397-1420.
Chamberlin, T. C. (1890,1965) The method of multiple working hypotheses. Originally in Science 1890, 15, 92. Reprinted in Science 1965, 148, 754-759.

362 11. Planning an Observational Study
Cook, T . D., Campbell, D. T. and Peracchio, L. (1990) Quasi-experimentation. In : Handbook of Industrial and Organizational Psy chology, M. Dunnette and L. Hough , Palo Alto, eds. , CA: Consulting Psychologists Press, Chapter 9, pp. 491-576.
Cook, T . D. and Shadish, W. R (1994) Social experiments: Some developments over the past fifteen years. Annual Review of Psychology, 45, 545-580.
Dawes, R (1996) The purpose of experiments: Ecological validity versus comparing hypotheses. Behavioral and Brain Sciences, 19, 20.
Deere, D., Murphy, K., and Welch, F . (1995) Employment and the 19901991 minimum-wage hike. American Economic Review, 85, 232-237.
Diggle, P. J. , Liang, K.Y., and Zeger, S. L. (1994) Analysis of Longitudinal Data. New York: Oxford University Press.
Duff, C. (1996) New minimum wage makes few waves: Employers offset 50-cent raise with minor shifts. Wall Street Journal, 20 November 1996, pp . 2-4.
Engle, R, Hendry, D., and Richard, J . (1983) Exogeneity. Econometrica, 51 , 277-304.
Estroff, S. E. (1985) Making It Crazy: An Ethnography of Psychiatric Clients in an American Community. Berkeley, CA : University of California Press.
Feyerabend, P. (1968) How to be a good empiricist-a plea for tolerance in matters epistemological. In : The Philosophy of Science (Oxford Readings in Philosophy), P. H. Nidditch, ed ., New York: Oxford University Press , pp. 12-39.
Feyerabend, P. (1975) Against Method. London: Verso.
Fisher, R. A. (1935) The Design of Experiments. Edinburgh: Oliver and Boyd.
Freedman, D. (1997) From association to causation via regression. Advances in Applied Mathematics, 18, 59-110.
French , S. A., Story, M., and Jeffery, R W. (2001) Environmental influences on eating and physical activity. Annual Review of Public Health, 22, 309--335.
Friedman, M. (1953) The methodology of positive economics. In : Essays in Positive Economics, Chicago: University of Chicago Press, pp . 343.

11.15 References 363
Gastwirth, J. L., Krieger, A. M., and Rosenbaum, P. R. (1997) Hypotheticals and hypotheses. American Statistician, 51, 120-121.
Giddens, A. (1979) Central Problems in Social Theory. Berkeley: University of California Press.
Holland, P. (1993) Which comes first , cause or effect? In : A Handbook for Data Analysis in the Behavioral Sciences: Methodological Issues, G. Keren and C. Lewis, eds., Hillsdale, NJ : Lawrence Erlbaum, pp . 273- 2 8 2 .
Holland, P. & Rubin, D. (1983) On Lord's paradox. In: Principles of Psychological Measurement: A Festschrift for Frederic Lord, H. Wainer and S. Messick, eds ., Hillsdale, NJ : Lawrence Erlbaum, pp . 3-25.
Joffe, M., Hoover , D., Jacobson, L., Kingsley, L., Chmiel, J., Visscher, B., and Robins, J. (1998) Estimating the effect of zidovudine on Kaposi's sarcoma from observational data using a rank preserving structural failure- time model. Statistics in Medicine, 17, 1073-1102.
Kessler, R. C. (1997) The effects of stressful life events on depression. Annual Review of Psychology, 48, 191-214.
Kuczmarski, R. J ., Flegal, K . M., Campbell, S. M., and Johnson, C. L. (1994) Increasing prevalence of overweight among US adults. The National Health and Nutrition Examination Surveys, 1960 to 1991. Journal of the American Medical Association, 272, 205-211
Lakatos, I. (1970) Falsification and the methodology of scientific research programs. In: Crit icism and the Growth of Knowledge, I. Lakatos and A. Musgrave, eds., New York: Cambridge University Press, pp. 91-196. Reprinted in: I. Lakatos (1978) Philosophical Papers, Volume 1, New York, Cambridge University Press, pp. 8-101.
Lakatos, I. (1981) History of science and its rational reconstructions. In: Scientific Revolutions, I. Hacking, ed., New York: Oxford University Press, pp . 107-127. Reprinted from Boston Studies in the Philosophy of Science, VIII, 1970.
Lehman, D., Wortman, C., and Williams, A. (1987) Long-term effects of losing a spouse or a child in a motor vehicle crash. Journal of Personality and Social Psychology, 52, 218-231.
Li, Y., Propert, K. J. , and Rosenbaum, P. R. (2001) Balanced risk set matching. Journal of the American Statistical Association, 96 , September, to appear..

364 11. Planning an Observational Study
Lichtenstein, P., Gatz, M., Pedersen, N., Berg , S., and McClearn, G. (1996) A co-twin-control study of response to widowhood. Journal of Gerontology: Psychological Sciences, 51B, 279-289.
Mauski, C. (1999) COlluuellt. Statisl'icul S cience, 14, 279-281.
Meehl, P. (1978) Theoretical risks and tabular asterisks: Sir Karl, Sir Ronald, and the slow progress of soft psychology. Journal of Consulting and Clinical Psychology, 46, 806-834. Reprinted in: P. Meehl, Selected Philosophical and Methodological Papers, Minneapolis: University of Minnesota Press, 1991, pp . 1-42.
Meyer, B. D. (1995) Natural and quasi-experiments in economics. Journal of Bus iness and Economic Statistics, 13, 151-161.
Meyer, M. and Fienberg, S, eds. (1992) Assessing Evaluation Studies: The Case of Bilingual Education Strat egies. Washington, DC : National Academy Press.
Morton, D., Saah, A., Silberg , S., Owens, W., Roberts, M., and Saah, M. (1982) Lead absorption in children of employees in a lead-related industry. American Journal of Epidemiology, 115, 549-555.
Neumark, D. and Wascher, W. (1992) Employment effects of minimum and subminimum wages: Panel data on state minimum wage laws. Industrial and Labor Relations Review, 46, 55-81.
Neumark, D. and Wascher , W. (1994) Reply. Industrial and Labor Relations Review, 48 , 497-512.
Peirce, C. S. (1903) On selecting hypotheses. In: Collected Papers of Charles Sanders Peirce, C. Hartshorne and P. Weiss, eds. , Volume 5, Cambridge, MA: Harvard University Press, 1960, pp . 413-422.
Peto, R., Pike, M., Armitage, P., Breslow, N., Cox, D., Howard, S., Mantel, N., McPherson, K, Peto, J. , and Smith, P. (1976) Design and analysis of randomized clinical trials requiring prolonged observation of each patient, I: Introduction and design. British Journal of Cancer, 34, 585-612.
Platt, J . (1964) Strong inference. Sci ence, 146,347-352.
Polanyi, M. (1946, 1964) Science, Faith and Society. New York: Oxford University Press. Reprinted, Chicago: University of Chicago Press.
Popper, K (1965) Conjectures and Refutations. New York: Harper and Row.
Popper, K (1968) The Logic of Scientific Discovery. New York: Harper and Row. (English translation of Popper's 1934 Logik der Forschung.)

11.15 References 365
Putnam , H. (1995) Pragmatism. Oxford : Blackwell.
Quine, W . (1951) Two dog mas of empiricism. Philosophical Review. Reprinted in: W. Quine (1980) From a Logical Point of View, Cambridge, MA: Harvard University Press, pp. 20-46.
Robins, J . (1989) The control of confounding by int ermediat e variab les. St atistics in Medicine, 8 , 679- 701.
Robins, J. (1992) Estimation of th e time-dependent accelera ted failur e time model in t he pr esence of confounding fact ors. Biom etrika, 79 , 321-334.
Robins, J. (1998) Correction for non-compli ance in equivalence trials. Statistics in Medicin e, 17, 269-302.
Robins, J. (1999) Comment. Stat istical Science, 14, 281-293.
Robins, J. , Rotnitzky, A. and Zhao , L. (1995) Analysis of semiparamet ric regression models for repeat ed outcomes in the pr esence of missing data. Journal of the American Statistical Association, 90 ,106-121.
Rosenbaum, P. R . (1984) The conseq uences of adjust ment for a concomit ant var iable t hat has been affected by th e tr eatment. Journal of the Ro yal Statistical Society, Series A , 147, 656-666.
Rosenbaum, P. R. (1986) Dr opp ing out of high school in t he United States : An obse rvat ional study. Journal of Educational Statistics, 11 , 207224.
Rosenbaum, P. R . (1999) Choice as alternat ive to cont rol in observational st udies (wit h discussion ). St atistical Science, 14, 259-304.
Rosenbaum, P. R. (2001a) Stability in th e absence of treatm ent . Journal of the American Statis tical A ssociation, 96 , 210-219.
Rosenbaum, P. R. (200lb) Replicating effects and biases. American Statistician , 55, 223-227.
Rosenzweig, M. and Wolpin, K. (1980) Testing th e quantity-quality fertility model: The use of twins as a natural experiment. Econometrica, 48, 227-240.
Rosenzweig , M. R. and Wolpin , K. I. (2000) Natural "natural experiments" in economics. Journal of Economic Literature, 38, 827-874.
Ru bin , D. B. (1991) Pract ical implicat ions of modes of statist ical inference for causal inference and t he crit ical role of the assignment mechanism. Biometrics, 47, 1213-1 234.

366 11. Planning an Ob serv ational Study
Samuelson, P. (1947, 1983) Foundat ions of Economic Analysis. Cambridge, MA: Harvard University Press.
Shadish, W . R. and Cook , T. D. (1999) Comment-Design rules: More steps toward a compl ete theory of quasi-experimentation. Statistical Science, 14 , 294-300.
Shadish, W . R., Cook , T . D., and Campbell, D. T. (2002) Experimental and Quasi-Experimental Designs for Gen eralized Causal Inference. Boston: Houghton-Mifflin.
Shafer , G. (1996) The Art of Causal Conjecture. Cambridge, MA : MIT Press.
Sobel, M. (1995) Causal inference in the social and behavioral sciences. In: Handbook of Stat istical Modelling for the Social and Behavioral Sciences, G. Arminger, C. Clogg, and M. Sobel, eds., New York: Plenum, pp. 1-38.
Sowell, T. (1995) Repealing the law of gravity. Forbes, 22 May, p. 82.
Susser , M. (1987) Falsification, verification and causal inference in epidemiology: Reconsideration in the light of Sir Karl Popper's philosophy. In: M. Susser , Epidemiology, Health and Society : Selected Papers, New York: Oxford , pp . 82-93.

12
Some Strategic Issues
12.1 What Are Strategic Issues?
By and large, the discipline of statistics is concerned with the development of correct and effective research designs and analytical methods, together with supporting theory. Here , correct and effective refer to formal properties of the designs and methods. The first eleven chapters discussed issues of this sort. In contrast, a strategic issue concerns the impact that an empiric investigation has on its intended audience. Often, the audience is not focused on statistical technique and theory, may have limited training in statistics, and may be comprised of laymen, that is, laymen with respect to their knowledge of statistics. When this is so, strategic issues may arise in which formal properties are weighed against impact on the intended audience.
Should strategic issues be considered at all? Why, after all, should laymen manage the conduct of science? Why should the decisions of laymen govern the interpretation of empiric research? Why should laymen sit as judge and jury on statistical analyses?
The answer, of course, is that public and corporate managers, governors, judges, and juries are, typically, not professional statisticians. The person responsible for a decision hopes and expects to find the evidence somewhat convincing, not merely to hear that an expert finds the evidence convincing . Often, these hopes and expectations are reasonable, and often they determine the impact of an empiric investigation.

368 12. Som e Strategic Issues
12.2 Some Specific Suggestions
This bri ef, final chapter discusses a few st rat egic issues in the design and conduct of obser vational st udies. Motivation and elabora t ion of these issues is found in t he chap ters or sect ions indicated within par entheses.
· Strategic issues arc more than com m unication and presentation. Strategic issues affect th e choice of research design and analytical methods.
· Design observational studies. A recent report of the National Academy of Science s (Meyer and Fienberg 1992 , p. 106) concludes : "Care in design and implementation will be rewarded with useful and clear study conclu sions. . . . Elaborate analytical method s will not salvage poor design or implementation of a study." Exert as much experimental control as is possible . Use the same measurement te chniques in treated and control groups (§1.2) . Carefully con sider the process that selects individuals into the st udy- select ion can introduce or eliminat e biases (§§7.1.3, 7.3). Anticipate hidden biases that pose the greatest threat to the st udy. Actively collect data that can reveal those biases if they ar e present (Chapters 6, through 8). Employ strategies that can reduce sensitivity to hidden bias (§5.3.7, Chapters 9 and 11) .
· Focus on simple comparisons. Tukey (1986) writes: "increase impact of results on consumers . .. by focusing on meaningful results (e.g., simple comparisons)." Cox (1958, p . 11) lists "sim plicity" as one of the five "requirements for a good experiment" and writes: "T his is a very important matter which must be constantly borne in mind . . . ." Peto, Pike, Armitage, Breslow, Cox , Howard, Mantel, McPherson, Peto, and Smith (1976, §4, p. 590) make a similar point. Simplicity is of greater importance in observat ional studies. Comparisons are often subject to genuine ambiguity or credible challenge. Issues of this kind are far more likely to be resolved if they ar e not compounded by unnecessary complications. A complex analysis can oft en be divided into several simple analyses, each of which can be challenged and debated separately. Writing within economics, Blaug (1992 , p. 245) offers good advice for all fields in saying that empirical work should be judged "on the basis of the likely validity of the results reported and not on the t echnical sophistication of the te chniques employed."
· Compare subjects who looked comparable prior to treatment. The most direct , most compelling way to address overt biases is to compare treated and control groups that looked comparable prior to treatment in terms of observed covariates. Susser (1973, §7) calls this "simplifying the condit ions of observation." The matching and stratification methods in Chapter 10 can often produce matched pairs or sets or strata that balance many observed covariates.

12.3 References 369
· Use sensitivity analys es to inform discussions of hidden biases due to unobserved covari ates. Even with t he greatest care, undetected hidden bias is a legit imat e concern in an observationa l study. However, claims about hidden biases do not become credible merely because the covariates involved were not observed . T he issue is exp lored through sens it ivity analyses (C hapter 4) . Sensitivity analyses for unobse rved covariates are likely to have greatest impact if they build upo n standard statistical techniques applied to simp le comparisons of treated and contro l gro ups t hat appear comparable in te rms of observed covariates.
12.3 References
Blau g, M. (1992) Th e Methodology of Economics (second editio n). New York: Cambridge Univers ity Press.
Cox, D. R. (1958) The Planning of Experim ents. New York: Wiley.
Meyer, M. and Fienberg, S. , eds . (1992) Assessing Evaluation Studies : The Case of Bilingual Education Strategies. Washington, DC : National Academy Press.
Peto , R. , P ike, M. , Armitage, P., Breslow, N., Cox, D. , Howar d, S., Mantel , N., McP herson, K. , Peto, J ., and Smith, P. (1976) Design and analysis of randomized clinical trials requiring prolonged observation of each patient, I: Int roduct ion and design. British Journal of Cancer, 34 , 585- 6 12 .
Susser, M. (1973) Causal Thinking in the Health Sciences. New York: Oxford University Press.
Tukey, J . (1986) Sunset sa lvo. The American Statistician, 40 , 72- 76.

Index

active ingredient, 172, 180 additive treatment effect, 42, 65,
92, 171, 199 adjusted responses , 43, 44, 176,
183 adjustment
by exact matching, 80, 295 by exact stratification, 79, 295 for a covariate. fi. 72 for an outcome, 74, 220 for many small categories, 75,
357 for overt bias, 72 for the propensity score, 81,
86,90 selecting covariates, 76 stratifying inexactly matched
pairs, 93 aligned rank test, 33, 139 arrangement increasing , 36, 152,
217, 224, 267, 288 attributable effect, 188 average treatment effect, 46

baseline measure of response, 64, 220, 269, 286
bracketing, 264
Campbell's threats to validity, 358 case-control study, 7 case-referent study
concept, 7, 83 multiple control groups, 255,
257 multiple referent groups, 231,
255 sensitivity analysis, 124, 130 synthetic, 84, 234 censored times, 51, 134 ceteris paribus, 336, 358 chi square test , 31 choice, in planning an observational
study abrupt, short-lived treatment,
356 alternative to control, 333 chronic but inescapable treat-
ment, 356 internal replication, 351

natural blocks, 357 of control group, 344 of research hypothesis , 339,
347 coherence; 277
baseline measures of response, 286
coherent Fisher's exact test, 288
coherent rank sum statistic, 288,290
coherent signed rank statistic, 280
contrasted with detecting bias , 278,287
reduced sensitivity to bias, 283 strengths and limitations, 286 compatible hypothesis, 190 completely randomized experiment,
25 concordant pair, 111 conditional permutation test
exact procedure, 87 large sample procedure, 90 constant treatment effect, 42, 65 control by systematic variation,
263 covariate
balance, 21, 296 definition, 20, 73 unobserved, 107 criticism of a study, 8 cross product ratio, 84
detecting hidden bias contrasted with coherence, 278, 287 known effects, 205 multiple control groups, 253 multiple referent groups, 231
dilated treatment effect , 173 direct adjustment, 47 direction of bias , 223 dispersive order, 174 displacements, 192

Index 371
distributive lattice, 59 dose
dose-response, 270, 290 negligible, 255, 257 nondose nonresponse, 352 of active ingredient, 172, 180 potential dose , 352 propensity score for dose, 300 sensitivity analysis, 271 unobserved , leading to coher-
ence , 289
effect increasing, 38, 54, 223, 224 efficacy and effectiveness, 180, 183,
184 Efron's biased coin experiment, 26 elaborate theory, 5, 206, 207, 277,
339 equivalence test , 282 ethnographic methods, 76, 360 exact matching, 80 exact stratification, 79 examples
abortion and crime , 213, 218 abortion and ectopic pregnancy,
127 abortion and education, 260 Advanced Placement Program,
253 allopurinol and rash, 130 anger and myocardial infarc-
tion, 212 Are small doses of alcohol ben-
eficial?, 257 asbestos and lung disease , 132 asphalt and kidney disease,
255,264 aspirin and Reye's syndrome,
232 benzene exposure among shoe
workers , 91, 193 bereavement in twin pairs, 357 billing fraud , 286 breast cancer and age at first
birth, 237, 242

372 Index
capt ive finan ce subsidiaries and bond values, 262
chemot herapy for lung cancer , 88
class size and Maimonides rul e, 346
coffee and hear t disease, 127 cognitive th erapy for early psy-
chosis, 260 contamina ted fish , 144, 148,
150, 197, 215, 220 coronary artery bypass surgery
versus drugs, 299 corona ry bypass sur gery
randomized trial , 19 departmental effect s on aca-
demic producti vity, 286 DES and cancer , 7, 125 Do anesthet ic gases cau se mu-
t ations?, 282 Does disability insur ance dis-
courage work?, 223 dropping out of high school,
358 dying afte r surge ry, 303 economic consequences of un-
wed motherhood, 346 estrogen use and canc er, 127 fallout from nuclear test s, 206 genetic damage among lead
and zinc min ers, 256 immigration and labor mar-
kets: the Mariel Boatlift , 356 "incidents" in the London Underground, 191 IUD and ectopic pr egnancy, 270 kidney functi on among cadmium workers , 174 L-tryptophan and eosinophiliamyalgia syndrome, 160 lead in children's blood, 81, 115, 117, 118, 338

minimum wage and employment, 186, 199, 336
mot or neuron disease in twins , 158
mu t ageni c effects of ant ineoplasti c drugs, 159
price and dem and for a medical procedure, 211
psycholo gical effects of bereavement, 337
public vers us Catholic high schoo ls, 8
smoking and heart disease, 5 smoking and lung ca ncer, 105,
112,277 st ress and coronary mortal-
ity, 211 t he Lad y t asting t ea , 21, 29 t ruc k dri vin g and back injury,
127 vasectomy and myocardial in-
farction , 92, 98 vitamin C and cancer , 2, 122 exclusion restriction, 181 exte nded hypergeometric distribu-
t ion , 120, 189, 194, 196, 256 exte rnal validity, 39, 46
Fi sher 's exact t est , 30, 189, 255, 256
FKG inequality, 61 free of hidden bias , 78, 214 full matching, 161, 296 , 303, 310,
318, 321
Gehan's test , 53, 140 greates t lower bound, 58 grounds for doubt , 10, 358
hidden bias , 106 Hodges-Lehmann est imate, 47, 81,
116, 147, 184 Holley's inequality, 61, 151 hypergeometric distribution , 31,
120, 189

identification, 185 incompatible hypothesis , 190 instrumental var iable, 172, 180 inte nt-to-treat estimat e, 183 int erference between units, 64 int ernal replication, 351 int ernal validity, 39, 46 invariant, 36 inverting a test , 45
known effects, 205
L-estimate, 63 larger treatment effect, 43, 54 lattice, 58 least upper bound, 58
M-estimate, 63 Mann-Whitney test, 32 Mantel ext ension test, 32 Mantel-Haenszel test , 31, 85, 122,
124, 130, 160, 240 matched sampling, 2 matching, 295
inexact, 93 on the propensity score, 81 on x , 80 using every control, 317, 318 variable controls, 304, 316 McNemar's test, 31, 93, 98, 112,
158 median test, 33, 123, 135, 177
no effect , 27, 38, 40 no interference between units, 41
odds ratio, 84, 106, 233, 258 optimal matching, 311
balanced, 319 full matching, 318 illustration, 306 network flow, 313 software, 323 variable controls, 316 versus greedy matching, 311,
320, 321

Ind ex 373
order st atist ics, 173, 192, 195 ordinallogit model, 301 out come
adjust ment for , 74, 220, 354 definition, 73 unaffect ed , 235 overt bias, 71
paired randomized experiment , 26 partial comparability, 239 partially ordered set , 50, 58, 288 pilot study, 76 poset, 50 positive tr eatment effect , 43, 54 power of tests for hidden bias, 215,
238, 268, 272 propensity score, 296
conditional permutation test , 87, 90
covariat e balance, 296, 297 doses of treatment , 300 example of st rat ificat ion, 299 in a st udy free of hidden bias ,
78, 297 in a st udy with hidden bias ,
297 simulation, 320 software, 322
Quade's test , 160 qualitative methods, 76, 322, 360 quality of evidence, 334
R-estimate, 63 random assignm ent, 24 random sample without replace-
ment , 35 randomization inference, 3, 22, 27 randomization tests, 30
aligned rank test , 33 coherent signed rank, 280 Fisher's exact t est , 30, 189,
255 Friedman's test , 266 Gehan's t est , 53

374 Index
int erference between units, 64 Kruskal-Wallis test , 266 longitudinal data, 64 Mantel extension t est , 32 Mantel-Haenszel test , 31, 85 McNemar's test , 31,93, 98 median test , 33 Quade's test , 160 sign test, 33 stratified rank sum t est , 33 t-test , 33, 65 Wilcoxon's rank sum test , 32 Wilcoxon's signed rank test ,
32 randomized block experiment, 25 randomized experiment, 3, 19 rank sum test, 32 reducing sensitivity to bias
dilated effects, 179 known effects, 219 multiple control groups, 272 partial comparability, 244 reducing sensitivity to hidd en bias coherence, 283 retrospective study, 7
Savage 's lattice, 59 selecting covariates, 76 selection bias, 86, 235 self select ion into treatment, 259,
261 sensit ivity analysis
aligned rank test, 139 case-referent study, 124, 130 coherent test, 281, 290 comparison with population
rates, 132 concept, 8, 11, 105 confidence interval, 117, 149,
178 contrasted with stability anal-
ysis ,353 Cornfield's method, 105 dilated effects, 177 doses of treatment, 271

Fisher 's exac t t est , 191, 256 full matchin g, 161 Gehan 's test , 140 Hodges-Lehmann est imate, 116,
147 insensitive but wrong anyway,
124 instrumental vari abl es, 186 Mantel-Haenszel test, 122, 124,
130,240 matched pairs, 110 matching with multiple con-
trols, 136 McNemar's test , 112 median test, 123 multiple cont rol groups, 256 partial comparability, 240 quantile, 195 rank sum test, 140, 145 reducing sensitivity, 179,219,
244, 272, 283 signed rank test , 114, 162 standardized mortality ratio,
133 stratified rank sum test , 138 2 x 2 x Stable, 130 2 x 2 table, 191 shift model, 42, 65 sign test , 33, 135 sign-score statist ic, 35, 110, 119,
151 signed rank test , 32, 187, 280 softwar e, 322
Fortran and C subroutines, 323
S-Plus, 162, 323, 325 SAS , 305, 323 StatXact, 132 specificity, 209 stability analysis, 353 standardized mortality ratio, 133 strata, 24 stratification, 295 distance, 308 notation, 306

of inexactly matched pairs, 93
on the propensity score , 81 on x, 79 optimal, 296, 302, 310 size, 306 stratified rank sum test, 33, 138 subclass, 24 sum statistic, 35, 140 SUTVA ,41 symbols
[event], 29 [j], 78
~( .), 173 r,107 ,,107 Y( ·,·, ·,·, ·),120 i, 24, 79 As, 79 M ,77 rn, , 24, 79 N, 23, 79 n s , 24, 79 n,25 n o,25
ns , 109
7I'"[j},78 q,33
Qs ,35 rc,42
TCsi,41
r, 28 R,41 Ts i , 28 rT,42 rr« , 41 r z , 40 5 ,24,79 S , 24, 79 t (., .), 28 T,42 u,107 n ,109
u,no
u", 218

Ind ex 375
x ,77 Y ,214 Z,24 Zs , 2 5
z.; 24, 79
t-test, 33 totally ordered, 50 ToyAuction, 325 treatment assignment probability,
78, 106 treatment effect, 40, 171
additive effect, 42 attributable effect, 188 dilated, 173 displacements, 192
unbiased test, 44 uniform randomized experiment,
25 unit, 23 unobserved covariate, 107
weak instrument, 185 Wilcoxon's rank sum test , 32, 140,
145 Wilcoxon's signed rank test , 32,
81, 114, 159, 187, 280

Springer Series in Statistics

(continued from p. ii )

Kotz/Johnson (Eds .): Breakthroughs in Statistics Volume I. Katz/Johnson (Eds.): Breakthroughs in Statistics Volume II. Kotz/Johnson (Eds.) : Breakthroughs in Statistics Volume III. Kuchler/Sorensen: Exponential Families of Stochastic Processes. Le Cam : Asymptotic Methods in Statistical Decision Theory. Le CamIYang: Asymptotics in Statistics : Some Basic Concepts, 2nd edition . Liu : Monte Carlo Strategies in Scientific Computing. Longford: Models for Uncertainty in Educational Testing . Mielk e, Jr./Berry: Permutation Methods : A Distance Function Approach. Miller, Jr.: Simultaneous Statistical Inference, 2nd edition. MostellerlWallace: Applied Bayesian and Classical Inference: The Case of the
Federalist Papers . Pan/Fang: Growth Curve Models and Statistical Diagnostics. Parzen/Tanabe/Kitagawa: Selected Papers of Hirotugu Akaike. Politis/RomanolWolj: Subsampling. Ramsay/Silverman: Functional Data Analysis. Rao/Toutenburg: Linear Models : Least Squares and Alternatives. Read/Cressie: Goodness-of-Fit Statistics for Discrete Mult ivariate Data. Reinsel: Elements of Multivariate Time Series Analysis , 2nd edition. Reiss: A Course on Point Processes. Reiss: Approximate Distributions of Order Statistics: With Applications
to Non-parametric Statistics . Rieder: Robust Asymptotic Statistics. Rosenbaum: Observational Studies, 2nd edition . Rosenblatt: Gaussian and Non-Gaussian Linear Time Series and Random Fields . SiimdallSwenssonIWretman: Model Assisted Survey Sampling. Schervish: Theory of Statistics . Shao/Tu: The Jackknife and Bootstrap . Siegmund: Sequential Analysis: Tests and Confidence Intervals . Simonoff: Smoothing Methods in Statistics . Singpurwalla and Wilson: Statistical Methods in Software Engineering:
Reliability and Risk. Small: The Statistical Theory of Shape. Sprott: Statistical Inference in Science . Stein : Interpolation of Spatial Data: Some Theory for Kriging . Taniguchi/Kakizawa : Asymptotic Theory of Statistical Inference for Time Series. Tanner: Tools for Statistical Inference: Methods for the Exploration of Posterior
Distributions and Likelihood Functions , 3rd edition . Tong : The Multivariate Normal Distribution. van der VaartIWellner: Weak Convergence and Empirical Processes: With
Applications to Statistics. Verbeke/Molenberghs: Linear Mixed Models for Longitudinal Data. Weerahandi: Exact Statistical Methods for Data Analysis . West/Harrison: Bayesian Forecasting and Dynamic Models, 2nd edit ion.

ALSO AVAILABLE FROM SPRINGERI

tati tical Con ulting

Paul w. ad . Ir n th J Be,..,..,.

JAVIER CABRERA and ANDREW MCDOUGALL
STATISTICAL CONSULTING
This book is primarily written for the student or statistician who is interested in becoming involved in consulting activities. Different types of statistical consulting environments are discussed, followed by a detailed description of the communication skills that a statistician needs to develop to be effective consultant. Part I of the book conclude s with a consultation project reproduced in its entirety. A wide range of case studies of varying complexity are presented in Part II. The appendices provide valuable information on resources and details on the SAS and S-PLUS software packages.
2001/400 PAGES/HARDCOVER/ ISBN 0-387-98863-7
NEIL H. T1MM
APPLIED MULTIVARIATE ANALYSIS
The presentation integrates both theory and practice including both the analysis of formal linear multivariate models and exploratory data analysis techniques. Each chapter contains the development of basic theoretical results with numerous applications illustrated using examples from the social and behavioral sciences, and other disciplines. All examples are analyzed using SAS. Top ics discussed include multivariate regression, multivariate analysis of variance for fixed and mixed models, seemingly unrelated regression models and repeated measurement models . The book also includes tests of multivariate normality with chi-square and beta plots, tests of multivariate nonadditivity, tests of covariance structure, tests of nonnested hypotheses, and the assessment of model assumptions.
2002/750 PAGES/HARDCOVER/ISBN 0-387-95347-7 SPRINGER TEXTS IN STATISTICS

PAUL W. MIELKE, JR. and KENNETH J. BERRY
PERMUTATION METHODS
A Distance Function Approach
Univariate and multivariate permutation methods are presented that provide exact probability values and approximate probability values based on resampling and moment techniques. Metr ic Euclidean distance functions are emphas ized, in contrast to the nonmetric squared Euclidean distance functions common to statistical tests that rely on the assumption of normality. Permutation methods based on Euclidean distance yield powerful robust statistics for the detection of phenomena such as cyclic, autoregressive, and overly regular patterns, multiple clumping , and directional shifts of correlat ed data.
The authors describe permutation methods associated with completely randomized and randomized block experimental designs .
2001/344 PAGES/HARDCOVER /ISBN 0-387-98882-3 SPRINGER SERIES IN STATISTICS
To Order or for Infonnation:
In North. Central and Soulh America:
CALL: 1-BOO-SPRINGER orFAX:(20t) 348-4505
WRI1t:Springer-Verlag New York. Inc .. Dept. 54115. PO 80x 2485. secaucus. NJ 07096-2485 VISIT: Your local technical bookstore [ -MAIL: ordersOspringer-ny.com · INSlllUCTORS:call or write for info on t ext book e..am copies
For all otner orders: CALL: +49 (0) 6221·34!>217/8 · FAX: +49 (0) 6221-
34!>229 ' WRI1t:Spnnger Customer servIce.
Haber str , 7. 69126 Heidelberg. Germany [-MAIL: ordersOspnnger.de or th rough your bool<seller
PROMOTION· S4115

