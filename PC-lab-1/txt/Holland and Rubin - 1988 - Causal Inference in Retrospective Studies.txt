Evaluation
Review
http://erx.sagepub.com/

Causal Inference in Retrospective Studies
Paul W. Holland and Donald B. Rubin
Eval Rev 1988 12: 203
DOI: 10.1177/0193841X8801200301
The online version of this article can be found at:
http://erx.sagepub.com/content/12/3/203

Published by:
http://www.sagepublications.com

Additional services and information for Evaluation Review can be found at:
Email Alerts: http://erx.sagepub.com/cgi/alerts
Subscriptions: http://erx.sagepub.com/subscriptions
Reprints: http://www.sagepub.com/journalsReprints.nav
Permissions: http://www.sagepub.com/journalsPermissions.nav
Citations: http://erx.sagepub.com/content/12/3/203.refs.html

>> Version of Record - Jun 1, 1988
What is This?

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

The problem of drawing causal inferences from retrospective case-control studies is
considered. A model for causal inference in prospective studies is reviewed and then
applied to retrospective studies. The limitations of case-control studies are formulated in
terms of the level of causally relevant parameters that can be estimated in such studies. An
example using data from a large retrospective study of coffee-drinking and myocardial
infarctions is used to illustrate the ideas of the article.

CAUSAL INFERENCE IN
RETROSPECTIVE STUDIES
PAUL W. HOLLAND
Research Statistics Group
Educational Testing Service
DONALD B. RUBIN
Harvard University

Yhilosophical

causality often emphasize the
are usually concerned with
understanding causal mechanisms. Purely statistical discussions of
causality are substantially more limited in scope, because the unique

~

discussions of

meaning of causation. Scientists

contribution of statistics is to measuring causal effects and not to the
understanding of causal mechanisms or to the meaning of causation.
This distinction is sometimes expressed as &dquo;statistics can establish
correlation, but not causation.&dquo; We feel our emphasis on measurement
is more appropriate, because it focuses on what statistical theory can
contribute to discussions of causality. Measuring causal effects accurately without any understanding whatsoever of the causal mechanisms
AUTHORSâ€™ NOTE: A version of this article titled &dquo;Causal Inference in Prospective and
Retrospective Studies&dquo; was delivered at the Jerome Cornfield Memorial Session of the
American Statistical Association, August 1980, in Houston. The topic of the article was
especially appropriate for that session since many important contributions to the study of
health effects from prospective and retrospective studies were made by Jerome Cornfield.
EVALUATION REVIEW, Vol. i2 No. 3, June 1988 203-2311
i988 Sage Publications, Inc.

o

203

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

204

involved

of the meaning of causation is not only possible but is, of
commonplace experience of everyday life; that is, people are
quite capable of using automobiles, ovens, calculators, and typewriters
safely and effectively without any knowledge of how these devices work.
course,

or

a

Of course, careful measurements of causal effects often lead to

a

better

understanding of the causal mechanisms involved.
In this article we first review a mathematical model for causal
inferences in prospective studies that is based on the work of Rubin
( 1974, 1977, 1978, 1980), and developed further in Holland and Rubin
(1983), Rosenbaum (1984a, 1984b, 1984c), Rosenbaum and Rubin

(1983a, 1983b, 1984a, 1984b, 1985a, 1985b), Holland (1986a, 1986b) and
Rubin (1986). We then apply this model to study causal inference in

retrospective case-control studies.
1. CAUSAL INFERENCE IN PROSPECTIVE STUDIES
The logic of measuring causal effects is clearest in prospective studies,
begin with that case. The essential elements of a prospective study
are the following:

so we

(1)
(2)
(3)

a

population of units, U

set, K, of well-defined causal agents (also called treatments or causes) to which
each unit u can be exposed. (For notational simplicity, we consider only two causal
agents, K = {t,c}.
a response Y that can be recorded for each unit after exposure to a causal agent
in K.
a

In a prospective study, a sample of units from U is obtained and each
unit is assigned to a treatment in K. The causal agents are then applied,
and later the response of each unit in the study is recorded. The intuitive
notion of causal effect that we wish to describe with our model is the
difference between the response measured on a unit that is exposed to
cause or treatment t and the response that would have been measured on
the same unit had it been exposed to treatment c. Thus our notion of the
causal effect of a causal agent will always be relative to another causal
agent, and is defined for each unit in U.
This meaning of causal effect is not foreign to statistical thinking, and
is evident in the writings of R. A. Fisher (1935), Kempthorne (1952),
Cochran (1965), and Cox (1958), for example (see Holland, 1986b).
Although this notion of a causal effect can be defined for each unit in U,

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

205

in general we are not able to directly measure a causal effect for a single
unit because having exposed a unit to t, we cannot return in time to
expose the same unit to c, instead. This is the Fundamental Problem of
Causal Inference, to which we shall return in the next section.
Before turning to the formal model we need to clarify the nature of
the response Y. For our discussion we will assume that Y is dichotomous,
taking on only the values 0 or 1. The extension to a general Y is
straightforward. We have chosen to restrict Y to be dichotomous
because it is the situation of common interest in retrospective studies.
1.1 THE FORMAL MODEL AND THE DEFINITION
OF UNIT-LEVEL CAUSAL EFFECTS

In the model, instead of a single dependent variable Y we have a
dependent variable, Yk, for each of the treatments to which the unit
could have been exposed. Thus if the unit is exposed to causal agent t we

will record the value of Yt for that unit. If that same unit had been
exposed to causal agent c instead of t, then we would record the value of
Yc for that unit and not the value of Yt. More formally, for two
treatments, we associate the following vector with each unit in U,

where

Yk(u) the response made by unit u if it is exposed to cause keK.
=

The novel feature of this model is the introduction of several versions of
the response variable Y. There is a version of Y for each of the causal
agents in K, because our definition of causal effect compares Yt (the
response made if exposed to t) to Yc (the response made if exposed to c).
Rubin (1980, 1986) refers to the assumption that the vector (1) fully
represents the possible values of Y under all pairings of kEK with uEU as
the &dquo;stable unit-treatment value assumption,&dquo; or the SUTVA.
The fact that each unit has a value for both Yt and Yc is very
important because it allows us to define causal effects at the level of
individual units. On unit u in U, the causal effect of t relative to c is a
comparison of Y~(u) and Yc(u), for example the difference Yt(u) - Yc(u).
A question that immediately arises is whether or not it is ever possible
to expose a unit to more than one treatment and thereby directly observe

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

206

than one component of the vector in (1). One can argue that this is
possible in principle, because once a unit has been exposed to a
treatment, the unit is different from what it was before. As mentioned
earlier, this is the Fundamental Problem of Causal Inference (Holland,
1986). However, the propriety of this extreme position depends on the
nature of the treatments and the units under study. We will not pursue
this issue further here, but will simply make the &dquo;worst-case&dquo; assumption
that a unit can be exposed to at most one treatment condition. For our
application to retrospective studies this assumption is adequate, since in
these studies units are exposed to only one of the causal agents.
In order to relate the vector in (1) to the data that are actually
observed, we introduce the variable S, where S = k if the unit is exposed
to cause k; S is the &dquo;causal indicator&dquo; variable that indicates to which
kEK each unit is exposed.
The observed data from a unit u is the vector
more

never

The notation Ys is used because it indicates that we can observe only
the response of a unit to the treatment to which it is exposed, that is,

The quantity Ys is the observed value of the response and is therefore
what is usually called the &dquo;dependent variable&dquo; in statistical discussions
(e.g., in an ANOVA of an experiment). We never can observe Yk if S ~ k.
Since we can observe only the value of Yt or Yc but not both, it is a
consequence of the model that causal effects for individual units are not

directly measurable.
In summary, our idealized model for a prospective causal
be viewed as based on the following sequence of steps:

study can

(1) determination of the population U under study
(2) determination of the set K composed of causal agents, treatments, or causes under
study
(3) determination of the response variable Y to be observed
(4) consequent definition of the vector (Yt, Yc) for every unit in U
(5) determination of the causal indicator S for every unit in the study
(6) consequent definition of the vector of observable data (Ys, S) for every unit in the
study
(7) observation of (Ys, S) for each unit in the study

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

207

1.2 THE THREE LEVELS OF CAUSAL INFERENCE

three levels or &dquo;strengths&dquo; of causal inferences that arise in
These
are: unit-level, subpopulation-level, and populationpractice.
level causal inferences. These levels are ordered by decreasing strength
in the sense that knowledge of all unit-level causal inferences implies
knowledge of all sub- and population-level causal inferences, and
knowledge of all subpopulation causal inferences for a partition of U
implies knowledge of population-level causal inferences, but not vice
versa. We briefly describe each of these levels. Due to the Fundamental
Problem of Causal Inference, all of these involve indirect estimation of
causal effects.
Unit-level causal inference: The definition of causal effects is at the
unit level and is the difference
There

are

homogeneous when Yk(Ul) Yk(U2) for every pair of
Homogeneous units may be encountered in laboratory
research in the physical sciences. When unit homogeneity can be
assumed, unit-level causal inferences are easy, since Yt(u) - Y~(u) Yt(ui)
Yc(U2) for every u, ui, and U2 c U. Hence unit-level causal inference only
requires the observation of Yt on Ul and Yc on U2 for one pair of units, ul,
U2. Such situations do not require statistical methods for the estimation

Units

are

units,

ui, U2.

called

=

=

-

of causal effects.

Population-level causal inference: The population distribution of Yt
over U are, in the dichotomous case, specified by P(Yt
1) and
P(Y~ 1). A population causal inference is a comparison of these two
probabilities-or, more generally, of the distributions of Yt and Yc over
U. A population causal inference is weaker than a unit-level causal
inference because it only describes how t or c affects the distribution of Y
over all of U rather than how it affects the value of Y on a given unit u in
U. There are many ways to compare distributions, and two important
ones for the dichotomous case are the difference
and Yc

=

=

and the odds-ratio,

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

208

and (5) are equally good ways of comparing dichotdistributions in general, they are quite different from a causal
point of view. The difference (4) may be interpreted in two ways, first as
a difference in probability, and second as an average causal effect, or

Although (4)

omous

ACE,

An ACE is the average of all the unit-level causal effects over U, and
sometimes, for example when Y is continuous, an ACE can be shown to
approximate all of the unit-level causal effects in U. This fortunate state
of affairs occurs when we have a case of constant effects, i.e.

This form of additivity does not often occur for dichotomous Yâ€™s except
under very special circumstances.
The odds ratio in (5), while a useful comparison of probabilities, does
not have an interpretation as an ACE, but we shall see that it arises
naturally in the study of retrospective research designs. The odds ratio
(5) is a comparison of the distribution of Yt over U with that of Yc, with
no concern with how Yt and Yc might be related for particular units in U.
Subpopulation-level causal inference: Subpopulations of U may be
defined in many ways, but we shall use only one method. It is to define
subpopulations by the values of covariates.
A covariate is a value of a variable that is defined on each unit u in U
but that is not affected by the exposure of units to causes in K. In our
model, the introduction of a variable, X, defined on the units of U,
requires the notation Xt(u) to indicate that, in general, X can depend
both on the unit u and on which cause, k, to which u is exposed. A
covariate is a special type of variable for which Xk(u) = X(u) for all kEK.
Variables that are measured prior to the exposure of units to causal
agents are always covariates, but sometimes variables measured after
exposure are also covariates-for example, a drug treatment is not
likely to change the value of variables such as an adultâ€™s height.
Subpopulations defined by a covariate, X, allow us to consider
probabilities of the form

Subpopulation-level causal inferences may be based on such probabilities. For example, we may consider the conditional difference
Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

209

or

the conditional odds ratio

Just as population-level causal inferences distinguish (4) from (5), so,
too, do subpopulation-level causal inferences distinguish (7) from (8) for
the same reasons. Similarly, the difference (7) also can be interpreted as
a conditional ACE, that is,

whereas the odds ratio

(8) has no such interpretation. Yet (8) is still
intermediate type of causal inference between the unit level
and population level because it can describe the way that the causal
agent t changes the distribution of Y-values relative to that of the causal
agent c for the subpopulation of U for which X(u) = x. If this is a
relatively homogeneous population, such information can be tantamount to a unit-level causal inference, and thus a conditional ACE.

useful as

an

1.3 THE ROLE OF RANDOMIZATION IN PROSPECTIVE STUDIES

It is well known that randomization aids one substantially in drawing
causal inferences, yet why is this so? The model developed above gives
an easy answer to this question.
When randomization is used to assign units to exposure to the causal
agents in K, the variable S is made statistically independent of all other
variables defined on U. Hence in particular,

for k

=

t or c

(or for

all choices of kEK when K has

more

than two

members).
Now let us consider the data that can be observed in a prospective
study, that is, (Ys(u), S(u)) for u in the study.
From a set of observations of (Ys, S) we can calculate the distribution
of Ys given the observed value of S. In particular we can estimate the
value of

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

210

The

mean

value in

(11) is also equal to

by the standard rules of conditional probability. Now suppose randomization is employed. Using (10), (11), and (12) we have this basic identity
(that holds only for randomized studies in general):

The difference

is called the prima facie ACE (or FACE) in
study the FACE equals the ACE, that is,

The FACE in

general.

In

a

randomized

(14) is a quantity that can be estimated from the data in

any prospective study. In a randomized prospective study the FACE has

causal relevance, since it

equals the ACE.

1.4 THE ROLE OF COVARIATES IN PROSPECTIVE STUDIES

When

a

unit in the

covariate is available in a study, the observed data for each
study is expanded from (Ys, S) to

where X is the covariate (possibly vector-valued). From observed values
of these data for the units in the study we can, in principle, estimate the
regression of Ys on S and X, that is,

The

quantity in (17), however, equals

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

211

from the standard rules of conditional probability. But (18), as it stands,
is much like (12) in not having any causal relevance. Rosenbaum and
Rubin (1983) define a special condition that generalizes randomization
and that gives (18) causal relevance when it holds. It is the condition of
strong ignorability. Treatment assignment (i.e., the distribution of S
given X and Yk) is strongly ignorable if (a) given X, S is independent of
Yk for key, and (b) P(S = k~ X) > 0 for all kEK. This is a stronger
condition than ignorability defined by Rubin (1978) for Bayesian
inference.
If strong ignorability holds, then (18) becomes

and the difference

which is the conditional FACE, equals the conditional ACE; that is, (20)

equals

Note that by averaging
the ACE in (15), that is,

over

the conditional ACE in

(21) we obtain

Hence the condition of strong ignorability is less restrictive than that of

randomization, but it still allows us to measure the average causal effect
in a prospective study using the data that are available. Of course, the
of the assumption of strong ignorability needs to be
considered carefully in any real application. For a more detailed
discussion of these issues see Rubin (1977), Holland and Rubin (1983),
and Rosenbaum (1984a).

plausibility

2. CAUSAL INFERENCE IN RETROSPECTIVE
CASE-CONTROL STUDIES
The structure of a retrospective case-control study is considerably
different from the general prospective study discussed in the preceding

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

212

section. In a case-control study, a population of units is divided into
those who have a particular symptom or disease of interest (i.e., the
&dquo;cases&dquo;) and those who do not have the symptom or disease (i.e., the
&dquo;controls&dquo;). Samples (random samples, in principle) of cases and
controls are selected from this population, and information about each
selected person is obtained to ascertain (a) the level of exposure to the
particular causal agents of interest and (b) other medically relevant
information that may be used to define subpopulations of units.
The response variable for a case-control study is the dichotomous
variable that indicates whether or not the unit is a &dquo;case&dquo; or a &dquo;control,&dquo;
that is,

Case-control studies are retrospective because they begin at the
endpoint of a prospective study (i.e., observations of the response
variable for each unit in the study) and then look back in time to
discover the causal agent to which each unit has been exposed (i.e., the
value of the causal indicator S). In retrospective studies, the basic
groups are cases (Ys = 1) and controls (Ys = 0) with S measured on each
sampled unit, whereas in prospective studies the basic groups are
exposed (S = t) and not exposed (S = c), with Ys measured on each
sampled unit. In addition to this fundamental difference between casecontrol and prospective studies, two other differences should be
mentioned. First, since the investigator can only collect data on prior
exposure to the causal agents of interest, it is impossible to use
randomization to assign units to the causal agents. Thus case-control
studies are never randomized. Prospective studies, on the other hand,
may or may not employ randomization depending on the amount of
control that is possible. Second, the populations studied in case-control
studies usually consist of survivors only, because it is often impossible to
obtain comparable data on individuals who are deceased. This limitation
may have consequences for the interpretability of the results of a casecontrol study. An excellent reference for case-control studies is Breslow
and Day (1980).
Although, in principle, it is almost always possible to design a
prospective version of a case-control study, it is often much more
expensive than the case-control study. There are several reasons for this:

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

213

(a) prospective studies require large sample sizes in which the &dquo;cases&dquo; are
rare (e.g., when Ys
represents a rare disease) and (b) prospective
studies may involve long time spans before relevant data become
available. Hence it is likely that case-control studies will always be an
attractive possibility for many types of scientific investigations, especially in the early stages of the research. It is therefore important to
know their limitations, to design them as well as possible and to analyze
the data collected in such studies correctly. Our goal in the present
article is to illuminate all of these points by applying the model for
=

causal inference outlined in Section 1 to case-control studies.

2.1 THE STANDARD TWO-WAY TABLE

In analyzing data from a case-control study it is customary to form
and draw conclusions from the two-way table of counts illustrated in
Table 1. We assume that this table is formed by randomly sampling mi+
&dquo;cases&dquo; (units with Ys = 1) from the subpopulation of cases, and
randomly sampling mo+ &dquo;controls&dquo; (units with Ys = 0) from the
subpopulation of controls.
J.
In Table 1, myk is the number of units in the study for which
and
S = k. For example, mic is the number of &dquo;cases&dquo; in the study that were
observed exposed to causal agent c. Before examining this table of
sample data, let us consider the population table that underlies it. Table
2 gives the population proportion of people with exposure to t or c
among all those who are cases or controls. These population values are
denoted by

Ys y

The

corresponding sample ratio

estimates ryk. We shall call the {ryk} the retrospective probabilities of the

study. They are &dquo;retrospective&dquo; because the conditioning is on an event
that occurs after the event whose probability is being assessed.
In this development we must emphasize the importance of representing the observed value of the response as Ys. For example, in (23) it

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

214

TABLE 1

The Standard Two-Way Table in Retrospective Studies
Showing the Sample Distribution of Cases and Controls
Observed for Each Causal Agent

TABLE 2

The

Population Table
ryk Related

to the

of Retrospective Probabilities
Sample Table in Table 1

would be incorrect to condition on Yk = y since Yk is the response made if
exposed to cause k, whereas Ys is the observed response. Because Ys is
being conditioned on in Table 2, it is sometimes said that in a casecontrol study exposure is the dependent variable and diagnosis (i.e., case
or control) is the independent variable. This description is neither
helpful nor of scientific interest, and we will not describe the situation in
these terms.
If we consider the weakest level of causal inference, that is, a
population-level causal inference, then the causal parameters are the
marginal probabilities P(Yt = 1) and P(Yc = 1). Thus the retrospective
probabilities in (23) are not in themselves of any causal interest, because,
at the very least, they do not address the correct events. However, by
applying the usual rules of probability, we may reverse the roles of S and
Ys in (23) and obtain more interesting probabilities. The result of this

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

215

accepted justification for looking
Cornfield, 1956).

reversal is the

at Table 1

(see

2.2 RELATING RETROSPECTIVE AND
PROSPECTIVE PROBABILITIES

To reverse the roles of S and Ys we make
obtain

use

of Bayesâ€™s theorem to

However,

so

it follows that

probability P(Yk = yl S k) is &dquo;prospective&dquo; because the
conditioning event occurs prior in time to the event whose probability is
being assessed. We denote these prospective probabilities by
The

Hence the

=

retrospective and prospective probabilities are related by

where

and

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

216

or

Hence the prospective probabilities pyk can be determined from the
retrospective probabilities ryk and the overall proportion of cases and
controls in the population, ay, via

We illustrate the array of &dquo;prospective&dquo; probabilities of (26) and (27)
in Table 3.
The cross-product ratio for Table 2 may be expressed as:

The

cross-product ratio for Table

3 may be

expressed

as:

Because Tables 2 and 3 are related via row and column multiplication,
equation (28), it is well known (e.g., Bishop et al., 1975) and easily
shown that the two cross-product ratios ant and apro are equal.
see

2.3 wHY THE STANDARD TWO-WAY TABLE IS MISLEADING

Even though the equality of ant and apro is the usual reason one ever
looks at the data in Table 1, the crucial question of how it relates to the
causal parameters of interest remains, that is, P(Yt = 1), P(Yc = 1) or the

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

217

TABLE 3

The Population Table of Prospective Probabilities

average causal effects in (6) or (9). The answer is that, without an
additional assumption, the cross-product ratio, apro, has no causal

relevance.
The crucial assumption is randomization, because then S is independent of Yx and

and hence

we

have

Hence randomization implies that apro equals a defined in (5), which is a
population-level causal parameter. However, as we stated earlier,
retrospective studies are never randomized, so that the assumption that
S is independent of Yk is dubious in most cases. Thus there is generally
no value to examining the data in Table 1 from the point of view of using

it to estimate causal parameters.
2.4 THE ROLE OF COVARIATES IN RETROSPECTIVE STUDIES

If there is a covariate X (possibly a vector) that is measured on each
unit in the study, then we may form a table like Table 1 for each value of
X. Let mykx be the number of units in the study for which Ys = y, S = k,

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

218

and X = x. These are arrayed in Table 4 for X = x. We suppose that at
each value of X, the data arise from a random sample of cases and a
random sample of controls, not necessarily with the same sampling
rates. This sampling scheme includes matched case-control pairs, where
the cases are randomly sampled from the population of cases, and for
each sampled case with X = x, a matching control with X = x is found.
The sample ratios

population retrospective probabilities

estimate the

We may again
in

(35)

as we

apply Bayesâ€™s theorem to reverse the roles of S
yields

and Yss

did in (25). This

However,

so

that

Again the probability P(Yk = yes k, X x) is &dquo;prospective,&dquo; and we
by
=

=

denote it

and,

before,
by

as

related

the

retrospective

and

prospective probabilities

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

are

219

TABLE 4

The Distribution of Cases and Controls in the
Observed for Each Causal Agent, at X
=

Sample
x

where

and

or

Again, pykx can be determined from rykx and Byx, the proportion of cases
and controls among those units with X

=

x, via

The odds ratio for the tables of retrospective probabilities underlying
the sample in Table 4 is

The

corresponding odds ratio for the prospective probabilities is

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

220

As

before, these two odds ratios are equal, that is,

Under strong ignorability we have

so

that

Hence, when strong ignorability holds, aP~o(x) equals a(x) as defined in
(8), which is a subpopulation causal parameter.
It may happen that a(x) as defined in (8) and (46) does not depend on
x-this is the case of no interaction of X with the effect of the causal
agents on the distribution of Y-values. In such a situation we will denote
this common value by ao. Note that apro(x) can be constant in x
regardless of the plausibility of strong ignorability-these are two, quite
different, assumptions. The constancy of cip.(x) is testable with the data
(Ys, S, X) whereas strong ignorability is not.
Unfortunately, there is no simple relation between the population
causal parameter

and ao even when strong ignorability and the assumption of no
interaction between X and the effect of t holds. Nevertheless, ao is a
causally interesting parameter itself: ao is the amount by which the odds
for Yt = 1 are increased over the odds that Yc =1in each X-stratum of U,
and, thus, ao is a causal parameter. Since ao is specific to each X-stratum

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

221

of U, it provides causal information about the effects oft relative to c in
U that is at a more detailed level than the overall population level.
However, in general it is not as strong a causal inference as a unit-level
causal inference.
Our conclusion is that in a case-control study the simple two-way
table (Table 1) generally holds no causal interest even for a matched
case-control study (i.e., M1+x = mo+x). It is crucial to stratify on
covariates and to estimate ant(x) = apm(x)-which is a causally relevant
parameter, a(x), under strong ignorability. If the stratified table exhibits
constant odds ratios, then, assuming strong ignorability, this parameter
equals ao and gives the amount that t increases the proportion of units in
each X-stratum that are &dquo;cases&dquo; relative to c. This &dquo;amount of increase&dquo;
is in terms of the odds corresponding to the proportions. Thus, for
example, for a given value of the proportion P(Yc = 1~ X = x), we may
calculate P(Yt = IIX = x) via the formula

Comparing this to the given value of P(Y~ = 11 X = x) leads to a causal
inference about the effect of the causal agent when X = x. In general,
however, the stratified table will not exhibit a constant odds ratio and
then the values of a(x) are the causally relevant parameters (under
strong ignorability), and can be used in place of aa in (48) to calculate
P(Yt = 11 X = x) from P(Yc = 1~ X = x).

AN EXAMPLE
THE DATA

The following data are taken from a case-control study of the
relationship between coffee drinking and the occurrence of myocardial
infarctions (MI) by Jick et al. (1973). We use these data for illustrative
purposes only. A total of 24,741 patients were classified as &dquo;cases&dquo; (had
an MI) or &dquo;controls&dquo; (did not have an MI). Table 5 shows the standard
two-way table that presents the cases and controls cross-classified by the
potential causal agents under study-self reported daily coffee con-

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

222

our previous notation has considered only two
causal agents, Table 5 presents four, a control (0 cups per day) and three
levels of the amount of coffee drinking; the extensions needed to handle
this extra complexity are simple. The odds ratios estimated in Table 5
are defined by

sumption. Although

â€™

/

.

for k = 2, 3, 4, that is, aBro is the odds ratio for level k of coffee drinking
relative to the control of no coffee drinking.
Table 5 suggests a modest increase in the risk of MI among persons
who drink coffee. The odds ratios range from 1.5 to 1.8. The odds ratios
exhibited in Table 5 are not monotone in the amount of self-reported
coffee drinking, and the effect seems to be almost as strong for persons
who drink 1-2 cups per day as for those drink 6 or more cups per day.
Table 5, however, does not take various background variables into
account and, as we have discussed earlier, is therefore likely to be
misleading because it is not reasonable to believe that the drinking of
coffee is randomly assigned and therefore independent of Yk, k = 1, 2,

3,4.
In addition to the variables

S

=

level of self-reported coffee intake

and
Y

=

case or

control,

following set of variables were also available on all patients in the
study.
the

A
G
C
O

=

Age: 6 levels: 20-29, 30-39,..., 70-79

=

Gender: 2 levels: male, female
Smoking: 3 levels: other, ex-smoker, current smoker
Other heart disease: 2 levels: yes, no

=
=

In addition, because the data were collected from 24 suburban
Boston hospitals, a fifth variable, H = hospital, was included in the

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

223

TABLE 5

Cross-Tabulation of Self-Reported Daily Coffee Intake
by Cases and Controls (Y) for 24,741 Patients

(S)

analysis (with 24 levels). This results in a covariate X, which takes on 6 X
2 X 3 X 2 X 24 = 1728 values, so that when Table 5 is stratified on X we
obtain a seven-way contingency table with 2 X 4 X 1728 = 13,824 cells.
With a total of 24,741 observations, this gives us about 1.9 observations
per cell-a very sparse table indeed! Many approaches to simplifying
this sort of situation are possible, for example, see Breslow and Day
(1980). We shall use log-linear contingency table models: (a) because of
their direct relationship to odds ratios, (b) because they allow us to
adjust for the effect of all of the covariates simultaneously, and (c)
because they allow us to smooth the sparse, seven-dimensional table.
3.2 LOG-LINEAR MODELS FOR THIS PROBLEM

Let X = (A, G, C, 0, H) denote our complete vector of covariates. The
logs of the retrospective probabilities rykx from (35) may be expressed as

are assumed to satisfy the usual ANOVA-like
identifying constraints, u,~+~ u2(+) 0, etc. (Bishop et al.,1975). We need

where the u-terms in (50)

=

to express the

=

odds ratios

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

224

in terms of the u-terms in
equation holds:

(50).

It is easy to show that the

following

where

(52) it follows that the hierarchical log-linear model specified
by setting all U123 = 0 corresponds to the assumption that
From

x. Thus we may investigate the question of whether or not the
odds ratio, a k mt(x), depends on x by testing for three-way interaction of
the various covariates in X and with Ys and S. Furthermore, if a model
where all u123 = 0 is acceptable, the estimated u12-terms may be used to
obtain estimates of ak ret. If we are willing to make the assumptions
necessary to ensure that akret is the causally relevant parameter discussed
in Section 3.4, that is, a o, then we may test a k ret = 1 (i.e., no effect of
different levels of the causal agent) by testing that U12 = 0. This test will
adjust for the distribution of the covariates in the several exposure
groups. In the remainder we assume strong ignorability and refer to a o
rather than 0;â€™~.

for all

3.3 SIMPLIFYING THE ANALYSIS

As described above it may seem as though we are considering the
whole 2 X 4 X 1728 table, but one important feature of the use of
log-linear models is that they do not force this when there are
insufficient data to do so. Instead we break up the joint distribution of X
=
(A, G, C, O, H) into various marginal distributions and expand the
model in (50) to make use of them. In the present example we expand the
table to the full seven dimensions, fit all u-terms involving Ys and/ or S
but not X, and only fit effects for the following pairs and triples of
variables involving X:

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

225

The u-terms in parentheses indicate which terms in
expanded in the seven-way table.

(50)

have been

3.4 RESULTS

If we fit the log-linear model indicated by the pairs and triples of
variables in (55) and then delete the YS terms and refit the model, we
obtain a likelihood-ratio test of a o= 1 for k = 2, 3, 4. The value of the
likelihood-ratio statistic is 12.3, which, under the null hypothesis, has
three degrees of freedom. Thus this analysis supports the conclusion
that at least one 0, kis not 1, and thus that there is a relationship between
coffee consumption and myocardial infarctions. The estimated values of

a oare

opposed to the raw odds ratios given in Table 5. These adjusted odds
ratios are monotonic in the amount of coffee consumed, with the major
effect for higher levels of coffee consumption. If we are willing to assume
strong ignorability of the distribution of coffee consumption and
diagnostic status (case or control) given the set of covariates in X, then
these estimated odds ratios are the subpopulation-level causal effects
as

described in Section 2.4.
To study the question of whether Qret(X) = apro(x) varies with x, we fit
five additional models, each of which supplements (55) with one of these
triples of variables: HSY, ASY, GSY, CSY, or OSY. The likelihoodratio statistics for these models, the degree of freedom, and attained
significance levels are given in Table 6.
None of these interactions are strong enough to be statistically
significant at conventional levels. This result contradicts previous
analysis of these data that found an interaction of the effect of coffee
drinking on diagnostic status with these variables, (Miettinen, 1976).

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

226

TABLE 6

Summary

of Study of Dependence of

aret(x)

on x

4. DISCUSSION AND SUMMARY

4.1 RISK FACTORS: CAUSAL AGENTS VERSUS ATTRIBUTES

In medical studies the term &dquo;risk factor&dquo; is used to lump &dquo;true&dquo; causal
agents such as smoking or coffee drinking, which can be altered, with
individual attributes such as age and sex, which cannot be altered. We
think it is wise to distinguish carefully between these two types of risk
factors and to reserve discussions of causation to include only the
former. The model used in this article presupposes a response value Yt if
the unit is exposed to t and a value Yt if it is exposed to c. When t or c is
construed to be an attribute of a unit (e.g., a personâ€™s sex) it is entirely
unclear how to define both Yt and Yc on each unit. In this sense it is
meaningless to speak of estimating the causal effects of attributes of
units. This does not mean that attributes have no predictive value, since
prediction is simply a consequence of association between variables,
which does not necessarily involve notions of cause. Our definition of a
causal agent is much stricter than some definitions used by economists,
for example, Granger Causality (Granger, 1969). Granger labels as a
cause any predictor of Y that adds independent information to the
prediction. We believe this is too generous a definition of causality, not
only misusing the language but possibly leading researchers away from
the study of the effects of manipulations that are possible-see Holland
(1986) and Rubin (1986).
4.2 RANDOMIZATION AND STRONG IGNORABILITY

One useful feature of the model developed for prospective studies in
Section 1 is that it clarifies the importance of randomization in causal

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

227

studies. The statistical independence of Yk and S that randomization
is very important but not always appreciated by writers on the
subject. For example, it is often asserted that there is some sort of
difficulty in resolving randomization of treatments to units with the
Bayesian/ likelihood/ modeling framework (Basu, 1980, Kempthorne,
1976, and Kruskal, 1980, but argued otherwise by Rubin, 1978, 1980).
One possible source of confusion is that the independence of S and (Yt,
Yt) does not imply that S is independent of the observed response Ys
except in very special circumstances, for example, when Yt = Yc for all
units. However, the equation
ensures

consequence of randomization, has an impact on both
and
Bayesians
frequentists alike. This is simply because it states that a
population parameter that can be estimated with observed data, that is,
the FACE, E(YsIS = t) - E(Ysl S = c), equals a population parameter that
has causal relevance, that is, the ACE, E(Yt - Yc).
The assumption of strong ignorability is a crucial one for causal
inferences in retrospective studies. Because such studies are never
randomized, strong ignorability appears to be one of the few constructs
available to us for using data from retrospective studies to draw the type
of conclusions we might try to make in a prospective study. There are
two reasons why we might be willing to assume strong ignorability even
when the stronger assumption of randomization is absurd. First of all, if
each X-stratum contains a very homogeneous set of units who tend to
respond very similarly to t or c then it can be shown that strong
ignorability will hold approximately. Second, we may be willing to
make the assumption of ignorability because there is nothing in the
observed data to contradict it. This is a subtle point and needs
elaboration. Suppose that we assumed that S is randomized and,
therefore, independent of Yk and all other variables, including X. Then
we could check this assumption by examining the observed distribution
of X given S. Under randomization X and S are independent, so

which is

a

Equation (58) can be checked with a simple chi-square test for
homogeneous proportions, and rejection indicates that S is not
independent of X and therefore not randomized. However, if we assume

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

228

that S is conditionally independent of Yr given X = x then we cannot use
the observed distribution of X given S = k to disprove this assumption.
Hence, strong ignorability is the strongest independence assumption
that we can make that is not contradictable by the data if we restrict
ourselves to (Ys, S, X).
One point that should be emphasized is that the causal parameters
that can be estimated in retrospective studies are more limited than
those that can be estimated in prospective studies, even when we are
willing to make the strong ignorability assumption in both cases. For
retrospective studies we can estimate

However in

prospective studies

we

may estimate

a(x) but also

or

and

Thus in comparing the results of prospective and retrospective
studies of the same causal agents it is important to be sure that estimates
of comparable parameters are being considered.
4.3 THE ROLE OF MATCHING IN PROSPECTIVE
AND RETROSPECTIVE STUDIES

We close with a comment on an alternative way to describe the
difference between prospective and retrospective studies from the point
of view of matching.

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

229

In prospective matching, units exposed to t and to

c are

matched

on

X, whereas in retrospective matching a unit that is a case is matched on
X with

unit that is a control. Suppose for simplicity that S is
of Yk given X so that at each level of X we have a
randomized experiment, that is, the experiment is a randomized block
design with the blocks defined by X. Prospective matching reconstructs
the randomized block experiment by creating matched pairs of units
exposed to t and to c. The average matched-pair difference is an
unbiased estimate of the treatment effect for the population defined by
the values of X in the matched pairs. Thus prospective matching on X
perfectly controls for X in this population whenever both members of
each matched pair have the same values of X.
In contrast, retrospective matching on X in general cannot perfectly
control for X because it does not reconstruct the randomized block
experiment. In each matched pair, one member is a case and one member
is a control; to reconstruct the randomized block experiment, one
member must be exposed and one unexposed, which generally does not
occur when one member is a case and the other a control. Thus
summaries from the case-control matched sample such as the odds ratio
do not represent an estimate of a causal effect for which X has been
controlled, even when all matched pairs are exactly matched with
respect to X. With retrospective matches, we really need to estimate the
odds ratio in each matched pair, and this requires building a model
relating Yi, Y2 to X and S such as we have illustrated in Section 3.
a

independent

REFERENCES
BASU, D. (1980) "Randomization analysis of experimental data: the Fisher Randomization Test." J. of the Amer. Stat. Assn. 75: 575-582.
S. E. FIENBERG, and P. W. HOLLAND (1975) Discrete Multivariate Analysis: Theory and Practice. Cambridge: MIT Press.
BRESLOW, N. E. and N. E. DAY (1980) Statistical Methods in Cancer Research, Vol. 1:
The Analysis of Case-Control Studies. Lyon, France: International Agency for
Research on Cancer.
COCHRAN, W. G. (1965) "Planning of observational studies of human populations." J.
of the Royal Stat. Society series A, 128, part 2: 234-255.
CORNFIELD, J. (1951) "A method of estimating comparative rates from clinical data,
application to cancer of the lung, breast and cervix."J. of the National Cancer Institute
11: 1269-1275.

BISHOP, Y.M.M.,

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

230

"A statistical problem arising from retrospective studies."
Proceedings of the Third Berkeley Symposium 4: 135-148.
COX, D. R. (1958) Planning of Experiments. New York: John Wiley.
FISHER, R. A. (1935) The Design of Experiments. Edinburgh: Oliver & Boyd.
GRANGER, C.W.J. (1969) "Investigating causal relations by econometric models and
cross-spectral methods." Econometrica 37: 424-438.
HOLLAND, P. W. (1986a) "Which comes first, cause or effect?" New York Statistician

CORNFIELD, J. (1956)

38: 1-6.

HOLLAND, P. W. (1986b) "Statistics and causal inference." J. of the Amer. Stat. Assn.
81: 945-970.

HOLLAND, P. W. and D. B. RUBIN (1983) "On Lordâ€™s Paradox," in Wainer and
Messick (eds.) Principles of Modern Psychological Measurement. Hillsdale, NJ:
Lawrence Erlbaum.

JICK, H. et al. (1973) "Coffee and mycardial infarction."New England J. of Medicine 289:
63-67.

KEMPTHORNE, O. (1952) The Design and Analysis of Experiments. New York: John
Wiley.
KEMPTHORNE, O. (1976) Discussion of "On rereading R. A. Fisher" by Leonard J.

Savage.

Annals of Statistics 4: 495-497.

KRUSKAL, W. (1980) "The significance of Fisher." J. of the Amer. Stat. Assn. 75:
1019-1030.

MIETTINEN, O. S. (1976) "Stratification by a multivariate confounder score." Amer. J.
of Epidemiology 104: 609-620.
P. R. (1984a) "From association to causation in observational studies:
the role of tests of strongly ignorable treatment assignment." J. of the Amer. Stat.
Assn. 79: 41-48.
ROSEMBAUM, P. R. (1984b) "The consequences of adjustment for a concomitant
variable that has been affected by the treatment. " J. of the Royal Stat. Society series A,
147: 656-666.
ROSENBAUM, P. R. (1984c) "Conditional permutation tests and the propensity score in
observational studies." J. of the Amer. Stat. Assn. 79: 565-574.
ROSENBAUM, P. R. and D. B. RUBIN (1983a) "The central role of the propensity score
in observational studies for causal effects." Biometrika 70: 41-55.
ROSEMBAUM, P. R. and D. B. RUBIN (1983b) "Assessing sensitivity to an unobserved
binary covariate in an observational study with binary outcome." J. of the Royal Stat.
Society series B, 45: 212-218.
ROSENBAUM, P. R. and D. B. RUBIN (1984a) Discussion of Pratt and Schlaifer "On
the nature and discovery of structure." J. of the Amer. Stat. Assn. 79: 26-28.
ROSENBAUM, P. R. and D. B. RUBIN (1984b) "Reducing bias in observational studies
using subclassification on the propensity score." J. of the Amer. Stat. Assn. 79:
516-524.
ROSENBAUM, P. R. and D. B. RUBIN (1985a) "Constructing a control group using
multivariate matched sampling methods that incorporate the propensity score." Amer.
Statistician 39: 33-38.
ROSENBAUM, P. R. and D. B. RUBIN (1985b) "The bias due to incomplete matching."
Biometrics 41: 103-116.
RUBIN, D. B. (1974) "Estimating causal effects of treatments in randomized and
nonrandomized studies." J. of Educ. Psychology 66: 688-701.

ROSENBAUM,

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

231

B. (1977) "Assignment of treatment group on the basis of a covariate." J. of
Educ. Statistics 2: 1-26.
RUBIN, D. B. (1978) "Bayesian inference for causal effects: the role of randomization."
Annals of Statistics 6: 34-58.
RUBIN, D. B. (1980) Discussion of "Randomization analysis of experimental data: the
Fisher Randomization Test," by D. Basu. J. of the Amer. Stat. Assn. 75: 591-593.
RUBIN, D. B. (1986) "Which ifs have causal answers." J. of the Amer. Stat. Assn. 81,
961-962.

RUBIN, D.

Paul W. Holland is Distinguished Research Scholar and Chairman of the Research
Statistics Group at Educational Testing Service, Princeton, New Jersey 08541. He has
contributed widely to the applications of statistics to the social sciences, including
categorical data analyses, social networks, robust regression, test equating, item bias, item
response theory, and causal inference in nonexperimental research. He is a fellow of the
American Statistical Association, the Institute of Mathematical Statistics, and the
American Association for the Advancement of Science.

Professor and Chairman of the Department of Statistics, Harvard
University, Cambridge, MA 02138. He has contributed to the theory and application of

Donald B. Rubin is

statistics to many areas,

including causal inference in randomized and nonrandomized

studies, methods such as matched sampling for controlling bias in observational studies,
techniques such as the EM algorithm and multiple imputation for dealing with missing
data, and the application of Bayesian and empirical Bayesian techniques to social science
data. He is a fellow of the American Statistical Association, the Institute of Mathematical
Statistics, the International Statistical Institute, the American Association for the
Advancement of science, the John Simon Guggenheim Foundation, and the Woodrow
Wilson Society.

Downloaded from erx.sagepub.com at Universitaetsbibliothek on November 19, 2012

