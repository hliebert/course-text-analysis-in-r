Adjusting for Nonignorable Drop-Out Using Semiparametric Nonresponse Models:
Comment
Author(s): Jianqing Fan and Chunming Zhang
Source: Journal of the American Statistical Association, Vol. 94, No. 448 (Dec., 1999), pp.
1122-1125
Published by: Taylor & Francis, Ltd. on behalf of the American Statistical Association
Stable URL: https://www.jstor.org/stable/2669925
Accessed: 21-10-2019 14:54 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

American Statistical Association, Taylor & Francis, Ltd. are collaborating with JSTOR to
digitize, preserve and extend access to Journal of the American Statistical Association

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:26 UTC
All use subject to https://about.jstor.org/terms

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:26 UTC
All use subject to https://about.jstor.org/terms

Fan

and

Zhang:

Comment

1123

mean CD4 counts can range from very small to very large.

lier time, such as week 20, 32, or 44. For the ACTG 175

This makes comparisons of several treatments very diffi-

data, there are on average about 15.6%, 21.0%, and 25.7%

cult. The authors compared two treatment arms for different

of drop-out. A low percentage of drop-out means that the

combinations of sensitivity parameters, based on the same

mean CD4 counts can be estimated more reliably even with-

family of models on the drop-out time (see the authors'

out adjustments (missing at random). Applying the same

Fig. 2). Although this method is very useful, it is conceiv-

sensitivity analysis techniques to the data collected at these

ably possible that the drop-out risk for one treatment group

earlier weeks, if a drop-out risk model is right and the range

follows a family of stochastic models but follows a com-

of sensitivity parameter is reasonable, then the estimated

pletely different one for the other treatment group. Thus as

population mean should be less sensitive than at week 56.

long as there are no data available for validation of model

Should the results contradict with this intuition, it would

assumptions, there are always uncertainties on an adjust-

be odd to accept the assumption that the drop-out risk is

ment method.

modeled correctly. This gives us an idea to verify whether

2. VALIDATION OF ASSUMPTIONS ON
DROP-OUT TIME

Validation of model assumptions on drop-out time is par-

ticularly important for adjusting for nonignorable drop-out.

the model is reasonable and the sensitivity parameter is in

a good range.

3. CHOICE OF SENSITIVITY PARAMETERS

It reduces the chance of making erroneous adjustments. It

We wholeheartedly endorse the notion that the sensitivity

is, however, hard to check all aspects of model assumptions.

parameter oz0 should be varied to see how sensitive conclu-

To attenuate the difficulty, the authors correctly pointed out

sions depend on this parameter. It appears unclear, however,

that one should consult with subjectmatter experts. One can

what the scale of oz0 is and what range of oz0 should be used.

also use other information collected during the course of a

An extreme value of o0 can not only make resulting esti-

study to validate certain aspects of model assumptions.

mates meaningless, but also cause some technical problems

There are several possible methods to accommodate side

and numerical instability.

information. Take clinical trial ACTG 175 AIDS, for in-

Different values of o0 entail different implied missing

stance. One can use available CD4 measurements at earlier

probabilities under a drop-out model. A possible choice of

weeks to predict missing measurements at week 56. The

the range of oz0 is to make the model-based missing probabilities consistent with empirical (observed) missing probability. An implied missing probability that is much too large
or too small provides evidence that the choice of oz0 does

results can then be used to calibrate the sensitivity analysis for the data at week 56. This will validate the extent to

which the two adjustment methods are consistent.

A second possibility is to compute implied (model-based)

not fit available data. See Section 2 of this discussion for

missing probability for different choices of the sensitivity

a simple method of calculating the model-based missing

parameter a0. Despite av0 unidentifiable, this checking ver-

probability.

ifies how well unknown parameters and functions were es-

Another possibility for choosing a range of a sensitivity

timated. Under model (1), the missing probability is given

parameter is to apply sensitivity analysis to the data collected at an earlier stage of a longitudinal study where the

by

percentage of drop-out is smaller. The sensitivity parameter

P(A = 0) E{1 - S(TIV(T), Y)},

can be chosen so that the resulting estimate is reasonably
close to the estimate deriving directly from the data col-

where S(tIV(T),Y) exp(-Ao(tIV(t))exp(cvoY)). As in

Section 3 of the article, if V(t) is a time-homogeneous discrete covariate, then the distribution of Y for each level

of V can be estimated. Hence an estimate of the implied

lected at that time point.
4. OTHER APPROACHES TO COMPARING
TWO TREATMENTS

missing probability can be obtained. If the situation is more

Population mean is known to be not robust. It is not sur-

complicated than the foregoing simple setting, then one can

prising that estimates of a population mean depend sensi-

use the crude estimate

tively on the assumptions of how data were missing. Given
the risks of model misspecification and the difficulty of

n

P(A = 0) - 1 Z,{1 - S(Ti Vi(T) Ii)},
i=l1

model validation, it seems preferable to using a more robust functional of an underlying distribution, such as median, trimmed mean, or the distribution function itself. As

where for missing cases, Vi(T) is Vi(Qi) and Yi is the

reported by the authors in Section 7.1, such robust func-

imputed response such as estimated population mean. The

tionals are less sensitive to underlying models on drop-out

time. Hence they are more objective and less disputable for
implied missing probability can be estimated more carefully
assessing the efficacy of treatments.
than what is outlined. An estimated missing probability unWhen two treatments are compared, we are interested
der model (1) that is excessively larger or smaller than the
sample proportion of missing data provides evidence that
the drop-out model is inadequate.

not only in whether two estimates of population means are
significantly different, but also in how different the treat-

A third possibility of model validation is to use the same

ment effects are. An illuminating method is to compare the

drop-out model to analyze the mean CD4 counts at an ear-

two distributions of the response variables. For estimation

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:26 UTC
All use subject to https://about.jstor.org/terms

1124

Journal

of

the

American

Statistical

of a cumulative distribution F(y) under the authors' frame-

work, one can solve an equation similar to (3) for each
given y. Namely, one could estimate F(y) by solving the
equation

Association.

December

1999

5. UNDERSTANDING ESTIMATING EQUATIONS

We now give a simple derivation for estimators given
in the article and relate them with the existing techniques in the censored regression literature. Assume that

b(V(T), t, ,) is independent of ,u. Then (3) gives the solu-

n

tion

Zh(Oi;F,Ao;b) = 0

n

i=l1

,i=n-l EYi*,

with
where

h(O; F, Ao; b) = (V(T) Y) [I(Y < y) -F- E{(1 -A)

y* 7(V(T),Y)-l[Y - E{(1 - A)b(V(Q),Q) V(T),Y)}]

x b(V(Q), Q; F) V(T), Y)} + (1- A)b(V(Q), Q; F).
The distributions can be informatively and visually compared by computing their corresponding kernel density es-

if not missing

b(V(Q), Q) if missing.

timates (see, e.g., Fan and Gijbels 1996; Silverman 1986).

This estimator looks complicated but can be simply de-

For a given bandwidth h and a kernel function K(.) (e.g., a

rived as follows. One naturally uses the available infor-

symmetric probability density function), the estimates can

mation (V(Q), Q) to impute missing data, resulting in ad-

be obtained via smoothing the estimated distribution func-

justment bo(V(Q), Q), for a given function bo. Correspondingly, one adjusts a nonmissing case by b1 (Y, V(T)), using
all collected information. Then the data after adjustments

tions as follows:

f (v) = ) I K (Y h t dF (t).

become

Y* = Ab, (Y, V(T)) + (1- A)bo (V(Q), Q).
Using the estimated densities, one can compare how the two

treatments differ from each other, not only in population
mean, but also in dispersion and other important functionals

For the sample average of the adjusted data to be unbiased,
it is required that

(see Fan and Gijbels 1996, p. 49).

EY EY*

As an illustration, we plot the estimated densities for
the four treatment arms, using a boundary corrected ker-

E[7rr(V(T), Y)bi (Y, V(T))

nel density estimator. Subjects are assumed to be missing

+ E{(1 - A)bo(V(Q), Q) V(T), Y}].

at random for simplicity of computation. Figure 1 indicates
that all four treatment arms have similar-shaped densities of
CD4 counts. But the treatment using AZT has lower CD4

counts, and the other three treatment arms perform very
similarly.

This equation is obviously satisfied if

Y = r(V(T), Y)bi (Y, V(T))

+ E{(1 - A)bo(V(Q), Q) V(T), Y},
X 10-3 Density estimates for CD4 counts

or, equivalently,

b1 (Y, V(T)) (V(T)I Y)

2-

Cll

/

x [Y - E{(1 - A)bo(V(Q)I Q) V(T), Y}].

ll

This yields exactly the same procedure as that of the au-

1.5

thors.

The idea of the foregoing derivation appeared already in
the censored regression literature (see, e.g., Fan and Gijbels
1994; Zheng 1987). To get the best estimator after adjust-

ments, Fan and Gijbels (1994) argued that the function bo
should be chosen such that var(Y*) is minimized, among
a class of possible adjustment functions under considera-

0.5-

tion. An intuitive and appealing transformation function is
to take
0

200

400

600

800

1000

1200

CD4 counts

or, eie nTY, z--,Q = Z-Y -W 7Q), =-O)

Figure 1. Kernel Density Estimates for CD4 Counts for Four Separate Treatment Arms, Assuming that Subjects Were Missing at Random.

,AZT; ---, AZT+ ddl;**, AZT+ ddC; -, ddl.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:26 UTC
All use subject to https://about.jstor.org/terms

van

der

Laan:

Comment

1125

This pair of adjustments of course satisfy the require-

With the estimated cumulative distribution function, all

ment EY = EY* and are the best restoration in the

other functionals can easily be estimated via a plug-in

sense that it is closest to the original data Y. This

method.

transformation is related to the Buckley-James (BuckADDITIONAL REFERENCES

ley and James 1979) method in the censored regression
setting.

Buckley, J., and James, I. R. (1979), "Linear Regression With Censored

The foregoing adjustment functions depend on unknown
parameters. To implement the idea in practice, one needs

to estimate these parameters using observable data. A
parametric model and a semiparametric model are proposed by Scharfstein, Rotnitzky, and Robins for the purpose of estimating these unknown parameters. The result-

ing estimator is the sample mean of the adjusted data.
The idea is also applicable to other linear functionals,

such as the cumulative distribution function at a point.

Data," Biometrika, 66, 429-436.
Fan, J., and Gijbels, I. (1994), "Censored Regression: Nonparametric Techniques and Their Applications," Journal of American Statistical Associ-

ation, 89, 560-570.

- (1996), Local Polynomial Modelling and Its Applications, London:
Chapman and Hall.
Silverman, B. W. (1986), Density Estimationz for Statistics and Data Analysis, London: Chapman and Hall.

Zheng, Z. (1988), "Strong Consistency of Nonparametric Regression Estimates With Censored Data," Journal of Mathematical Research and

Exposition, 3, 231-241.

Comment
Mark VAN DER LAAN

Let me first compliment the authors on their two very

censored-data structure handled by the authors is mono-

nice articles on sensitivity analysis. The article under dis-

tone. Thus to have CAR, one wants to collect over time

cussion applies a nonparametric sensitivity analysis toward

any variables that might be used in a "decision" to censor a

a particular type of censored-data model of practical inter-

subject. An estimator that is consistent under CAR will ex-

est. The methodology is completely general and thus can

trapolate a subject censored at time t by using uncensored

be applied to any censored-data structure of a full-data ran-

subjects who have the same observed history up until time

dom variable X; that is, when the observed data 0 can

t. If one feels that in a particular application uncensored

be defined as 0 = (X, C) for some given mapping @

and censored subjects at time t with the same observed his-

and censoring variable C. A model of such a censored-data

tory might not be exchangeable, then the CAR assumption

structure is typically built up by a model for the full-data

will need to be tested and/or a sensitivity analysis will be

random variable X and a model for the conditional distri-

appropriate.

bution C, given X, referred to as the censoring mechanism.

In nonparametric CAR censored-data models in which

To make estimation of the full-data distribution or parame-

the full-data distribution is unspecified and the censoring

ters thereof tractable, one often assumes that the censoring

mechanism is only known to satisfy CAR, one cannot test

mechanism satisfies coarsening at random (CAR) as orig-

whether the censoring mechanism satisfies coarsening at

inally formulated by Heitjan and Rubin (1991) and gener-

random, because the model is already nonparametric. How-

alized by Jacobsen and Keiding (1995) and then by Gill,

ever, to get a good sense about deviations from CAR, one

van der Laan, and Robins (1997). Under CAR, the likeli-

could assume a semiparametric CAR model for the cen-

hood factorizes into a likelihood for the full-data distribu-

soring mechanism and extend this with a one-dimensional

tion and a likelihood for the censoring mechanism, so that

parameter oa measuring a deviation from CAR. Now one

maximum likelihood estimation of the full-data distribution

could try to estimate all unknown parameters including oa,

can ignore the censoring likelihood. Intuitive understand-

which will then provide a test of CAR given the assumed

ing of the CAR assumption is in general very hard, but in

model. Under the latter extension of the CAR model, the

monotone-censored data structures (i.e., one observes an in-

likelihood will not factorize anymore. As a consequence,

creasing sigma field .t over time t up till the minimum of

maximum likelihood estimation is typically less attractive

C and the point at which the full data are completely ob-

and also an estimating equation approach is harder (see Rot-

served) it has a very appealing and easily understandable

nitzky, Robins, and Scharfstein 1998).

interpretation. In these monotone-censored data problems,

In a nonparametric CAR model, one can still extend

the censoring mechanism satisfies CAR if and only if the

the CAR model for the censoring mechanism with a one-

hazard of C at t, given the full data X, is only a function of

dimensional parameter a measuring the deviation from

the data 2t that one has available at time t. The particular
? 1999 American Statistical Association
Mark van der Laan is Associate Professor, Division of Biostatistics,
School of Public Health, University of California, Berkeley, CA 94720.

Journal of the American Statistical Association

December 1999, Vol. 94, No. 448, Theory and Methods

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:26 UTC
All use subject to https://about.jstor.org/terms

