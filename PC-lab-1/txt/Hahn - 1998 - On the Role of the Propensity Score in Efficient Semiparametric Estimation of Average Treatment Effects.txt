On the Role of the Propensity Score in Efficient Semiparametric Estimation of Average
Treatment Effects
Author(s): Jinyong Hahn
Source: Econometrica, Vol. 66, No. 2 (Mar., 1998), pp. 315-331
Published by: The Econometric Society
Stable URL: https://www.jstor.org/stable/2998560
Accessed: 05-03-2019 15:06 UTC
REFERENCES
Linked references are available on JSTOR for this article:
https://www.jstor.org/stable/2998560?seq=1&cid=pdf-reference#references_tab_contents
You may need to log in to JSTOR to access the linked references.
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

The Econometric Society is collaborating with JSTOR to digitize, preserve and extend access
to Econometrica

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

Econoroetiica, Vol. 66, No. 2 (March, 1998), 315-331

ON THE ROLE OF THE PROPENSITY SCORE IN EFFICIENT

SEMIPARAMETRIC ESTIMATION OF AVERAGE
TREATMENT EFFECTS

BY JINYONG HAHN'

In this paper, the role of the propensity score in the efficient estimation
treatment effects is examined. Under the assumption that the treatment is ignorable given

some observed characteristics, it is shown that the propensity score is ancillary for
estimation of the average treatment effects. The propensity score is not ancillary for
estimation of average treatment effects on the treated. It is suggested that the marginal

value of the propensity score lies entirely in the "dimension reduction." Efficient semiparametric estimators of average treatment effects and average treatment effects on the
treated are shown to take the form of relevant sample averages of the data completed by
the nonparametric imputation method. It is shown that the projection on the propensity
score is not necessar for efficient semiparametric estimation of average treatment effects

on the treated even if the propensity score is known. An application to the experimental
data reveals that conditioning on the propensity score may even result in a loss of
efficiency.

KEYWORDS: Treatment effect, propensity score, semiparametric efficiency hound.

1. INTRODUCTION

THE CENTRAL PROBLEM IN EVALUATION STUDIES is that any potential outcome
that program participants would have received in the absence of the program is

not observed. Let Di denote a dummy variable such that Di = 1 when treatment
is given to the ith individual, and Di = 0 otherwise. Let Yoi and Yli denote

potential outcomes when Di = 0 and Di = 1, respectively. We can then say that

the treatment causes the outcome variable of the ith individual to increase by

Yli - Yoi. Thus, Yli - Yoi can be called the treatment effect for the ith individual. Individual treatment effects cannot be observed, though, because we only

observe Di and Y mDitYi + (1 - D1)Y0i. Because of this missing data problem,

attention has been focused on some parameters which can summarize the
impact of the program in a meaningful way. Usually, the parameter of interest
formulated in terms of conditional means, presumably because the case for
social experimentation implicitly assumes that the mean gain from program
participation is the primary object of interest. See Heckman (1992), Clements,
1 Previous versions of this paper have been circulated under the title "Efficient Semiparametric
Estimation of the Average Treatment Effects from the Experimental Data." I appreciate helpful
comments from Joshua Angrist, Gary Chamberlain, Whitney Newey, James Powell, Petra Todd,
Fannie Tseng, Yoon Jae Whang, a co-editor, two anonymous referees, and seminar participants at
Lehigh University, Northwestern University, Penn State University, and the 1996 North American

Summer Meeting of the Econometric Society. Guido Imbens inspired this research and deserves a
lot more than a usual thank you. Financial support has been provided by the Institute for Economic
Research and the Research Foundation of the University of Pennsylvania.
315

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

316

JINYONG

HAHN

Heckman, and Smith (1993), and Heckman and Smith (1995) for related discus-

sion. Thus, the atverage treatnment effects

3 _E[Yli -Yoi
and the average treatnent effects on the treated

y-E[Yli -Yoi IDi = 1],
have received a lot of attention in the literature. For example, Heckman,

Ichimura, Smith, and Todd (1995) and Todd (1995) considered the mean impact
of job training (for the program participants) on earnings. Angrist (1995a)
considered the mean impact of military service (for veterans) on civilian earnings. In a related context, Imbens and Angrist (1994) reinterpreted the IV
estimator as the estimator of some local average treatment effects.

Problems of sample selection are common in evaluation studies. Traditionally,
two main approaches have been used in the literature to control for the bias:

regression-based "control function" methods, predominantly used in economet-

rics, and "matching" methods, mainly used in statistics. A common feature of
both approaches is that the conditional probability of program participation
given some observed characteristics, often called the propensity score, plays a
crucial role in controlling bias to obtain the estimator of the impact of the
program. Many estimators proposed in the econometric literature for evaluating
the impact of a social program rely on estimates of this propensity score to
control for systematic differences between treatment and comparison groups.
Examples include Heckman, Ichimura, Smith, and Todd (1995), Todd (1995),
and Angrist (1995a, b). The critical role played by the propensity score in the
literature is often motivated by Rosenbaum and Rubin's (1983, 1984) argument.

They showed that if (i) there exists a variable Xi (which is always observed) such
that Di is ignorable given Xi, i.e., Di and (Yoi,Y1I) are independent of each
other given Xi; and (ii) 0 < P[Di = 1 IXi] < 1 for all Xi; then Di and (Yoj, Y11)
are independent of each other given the propensity score

p(x) -P[Di = 1 Xi =x].
This in particular implies that E[jyi p(Xi)] = E[Y IDi = 1, p(Xi)] for j = 0,1,

hence,

/3 = E{E[Y IDi = 1, p(X)] -E[Y IDi = 0, p(X,)]1

rl^a Ara

Also observe that conditioning on Xi has the same effect:

3 = E{E[YJ IDi = 1, Xi] -E[Y IDi = 0, Xi].
These observations suggest that a consistent estimator of /3 may be constructed
as a sample average of

E[YiDi = 1,p(Xi)]-E[Y Di = O,p(Xi)] or

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

PROPENSITY

SCORE

317

where E[Y Di, p(Xi)] and E[Yi Di, Xi] denote some nonparametric estimators

of Yi given (Di, p(Xi)) and (Di, Xi), respectively. Similar observation suggests
that a consistent estimator of y may be constructed as a sample average of the

same object over the subsample where Di = 1. But because conditioning on the
unitzuariate propensity score fully controls for the bias, and because the estimation of conditional distribution is more difficult when the dimension of the
conditioning variable is large due to the curse of dimensionality, this "dimension

reduction" has led many to focus on more reliable estimation of the propensity
score.

The purpose of this paper is to consider the efficient estimation of /3 and -y
when the treatment is ignorable given observed characteristics, and to examine
the role of the propensity score from an efficiency point of view. This problem is

not a standard parametric problem because the distribution of (Yoi, Yli) is no
parametrically specified. The semiparametric efficiency bound, introduced by

Stein (1956), and developed by Begun, Hall, Huang, and Wellner (1983) and
Bickel, Klaassen, Ritov, and Wellner (1993), among others, provides the semiparametric analog of the Cramer-Rao lower bound. See Newey (1990), for
example, for a review on this subject. I calculate the semiparametric efficiency
bounds under various assumptions and develop estimates whose asymptotic

variances achieve these bounds. It turns out that the propensity score p(x) is
ancillci;y for the estimation of /3: the efficiency bound for /3 under the knowledge of the propensity score is the same as the one without knowledge of the
propensity score. The knowledge of the propensity score does decrease the

asymptotic variance bound for , though. I provide a heuristic argument that
this added information can be solely attributed to the "dimension reduction"
feature of the propensity score.

I show that conditioning on the propensity score is not necessai^y and may
even be harmful for the efficient estimation of /8 and y. For the case where the
propensity score is not known, I construct efficient estimators which take the

forms of some relevant sample averages of the data completed by the nonpara-

metric impittation] method based on the nonparametric regression Xi. Even
when the propensity score is known, in which case the asymptotic variance

bound for y is smaller when compared to the case where the propensity score is
not known, it is found that the projection on the propensity score is not
necessaiy to achieve the semiparametric efficiency bound. It is then found that

conditioning on the propensity score results in a loss of efficiency in the case of

experimnental datC.

2. EFFICIENCY BOUNDS

In this section, I calculate the semiparametric efficiency bounds of /3 and y
and examine the role of the propensity score in efficient estimation. Knowledge
of the propensity score is shown to add no additional information for estimation

of /3, and hence, the propensity score is ancillaiy for /3. For the estimation of -y,

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

318

JINYONG

HAHN

I argue that the marginal value of the propensity score is concentrated solely on
the dimension reduction feature.

Assume that the treatment is ignorable give some covariates Xi. Our data set

consists of (Di, Yi, Xi) i = 1,..., n, where YX-DiY1i + (1 - Di)Yoi. Notice that we
observe only one of Yoi and Y1i. Our objects of interest are the average
treatment effects /3 and the average treatment effects on the treated 'y. The
asymptotic variance bounds for /3 and y are calculated in the following theorem.
The semiparametric asymptotic variance bound provides the semiparametric
analog of the Cramer-Rao lower bound: no regular estimator sequence has a
smaller asymptotic variance.

THEOREM 1: Under the assumption that (Yoi, Y1i) I Di IXi, the asymptotic variance bounds for /3 and y are

E- 2r(Xi) cr 2(Xi)1
E I I~~~ 1 ,( l ,)
p(X) 1 -p(Xd) + iJ-zI)J]
and

p (X)(J2(Xi) +P (Xi)2o02(Xi) (p(Xi) - Y )2p(X
(1) El 1 1
[ P2 p 2(I_ -p(Xi)) p 2
respectively, where

PI(Xi) = E[YliiXi],
00(Xi) = E[ Yoi |Xi]

/3(Xd) = p 1(X1) - 0(Xi),
o-i2 (Xi) = var (Y, i Xi),
?o 2 (Xi) = var(Yo i lXi),

p = E[p(Xi)].
(Proof in Appendix.)
To examine the role of the propensity score in efficient estimation of /3 and

'y, consider the hypothetical situation where the propensity score p(-) is known

while maintaining the assumption that (Yoi, Y1-) I Di Xi. The reduction in the
asymptotic variance bounds due to this additional assumption would then
indicate the role of propensity score from the efficiency point of view.

THEOREM 2: Assume that (Yoi, Y1i) I Di Xi. Furthermore, assume that th

propensity score pQ ) is known. The asymptotic ivariance bounds for /3 and y are
then equal to

- 2 (Xi) - p X)(Xi)

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

PROPENSITY SCORE 319

and

Ep(Xi)l2(Xi) p(Xi) 2o02(Xi) ( /(Xi) -y)2p2(X.)
2 p2 p2(1 _p(Xi)) p2,
respectively.

(Proof in Appendix.)

A comparison of asymptotic variance bounds in Theorems 1 and 2 shows that

the propensity score does not play any role in the estimation of /3: the
knowledge of the propensity score does not decrease the asymptotic variance

bound. In this sense, the propensity score is ancillary for the estimation of /3.
On the other hand, knowledge of the propensity score clearly plays some role
for the estimation of y: it reduces the asymptotic variance bound by

(,3(Xi) -_y) p(Xi)( -P(Xi))
(2)
p
21
which can be interpreted as the marginal value of the propensity score. Because

the propensity score is not known in many realistic circumstances, this marginal
value can only tell us the hypothetical marginal benefit.

One might also ask the marginal value of the "dimension reduction" due to

the propensity score. To be more specific, suppose that Xi has a continuous
distribution, and the support r of Xi is a union of the equivalence classes ,,
such that the propensity score is equal to a on each r?. Suppose that we can
identify such equivalence classes, although we do not know the propensity score
itself. Observe that the knowledge of such equivalence classes amounts to the

"dimension reduction" often associated with Rosenbaum and Rubin (1983,

1984). What is the marginal value of such knowledge? It is clear that knowledge
of the equivalence classes should not add any information in estimation of /3:

the marginal value (in terms of asymptotic variance bound) of the propensity
score itself was zero. For the estimation of y, I do not yet know how to compute
the efficiency bound under this generality. Instead, I consider a simple case
which suggests that the marginal value of the propensity score entirely consists
of the "dimension reduction." I consider an extreme example where the propensity score is constant over Z This is the case of random treatment assignment.

Observe that / = y in this case.

THEOREM 3: Assume that (Yoi, Y1i) I Di iXi. Furthermore, assume that the

propensity score p0 ) is equal to some unknown constant p. The asymptotic variance
bound for /3 = y is equal to
4 + 1 _p +(2(Xi) -)j .

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

320

JINYONG

HAHN

(Proof in Appendix.)

Now, consider the variance bounds in Theorem 1 for the case where pQ) =p.
We can see that the bound for /3 equals

(3) E[ 0I( ,(' ( B(X) - )2]
and that for y equals

o- 12(Xi) fo 2 (Xi) (P(Xi) _ 0) 2

(4)

E+

p

I-p

+

p

1

These are the bounds if we do not know that the data are generated by the

random treatment assignment. A comparison of (3) with the bound in Theorem
3 suggests that the bound for /3 does not change even if we know that the data
are generated by random treatment assignment. This is hardly surprising when
viewed against Theorem 2: the marginal value of the propensity score, which in
this case is the knowledge that the data are generated by the random treatment
assignment and the knowledge of the probability of treatment, is zero for l3.
Thus, the marginal value of the former knowledge should also be zero. Now,

compare (4) with the bound in Theorem 3. The difference between them,

E [ P ( 8(Xi)- _') 2
indicates the marginal value (in the estimation of y) of the knowledge that the
data are generated by the random treatment assignment, or the marginal value

of the dimension reduction. It turns out that this marginal value equals (2) when
p) =p. In other words, the marginal value (in the estimation of y) of the
knowledge of the propensity score entirely consists of the marginal value of
dimension reduction.

3. EFFICIENT ESTIMATION

Having calculated efficiency bounds for /3 and y, it is of interest to develop
estimators which achieve these bounds. The estimators take the forms of some

relevant sample averages from the data completed by the nonparametric impu-

tation method based on the projection on Xi. I then consider estimation of 'y
when the propensity score is known, in which case the asymptotic variance

bound is decreased, and argue that conditioning on the propensity score is not
necessary for efficient estimation. Finally, I argue that conditioning on the
propensity score may even be harmful in efficient estimation by considering the
random treatment assignment where the propensity score is constant, under
which case projection on the propensity score is equivalent to taking the
marginal expectation.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

PROPENSITY

SCORE

321

Notice that the original data set contains some missing values because only

one of Y1i and Yoi are observed. If both were observed, then the sample average
of the difference Yli - Yoi would consistently estimate /3, and the sample
average of the difference Y1i -Yoi over a subsample where Di = 1 would
consistently estimate y.

The nonparametric imputation method imputes the missing values of Y1i an
Yoi using their conditional expectation given Xi. In general, these conditional

expectations are not identified. But the ignorability of Di given Xi helps us to
identify them. Because we have

E[DiYi IXiN] = E[DiY1i NX E[Di |Xi ]E[ Y1i NXi] = E[Di IXi] 31(Xi),

we can identify 831(Xi) by E[DiY jX1]/E[Di X1]. Similarly, we can ide

I30(Xi). Even though E[DjYiJXi], E[(1 -Dj)YiJXi], and E[DiJXi] are not exa

known in the sample, we can use various nonparametric regression techniques

to consistently estimate them. Let E[DDiYi Xi], E[(1 - Di)Yi IXi], and E[Di

denote the corresponding nonparametric regression estimators. We can then fill

in the missing values of Y1i and Yoi by

181(Xi)- ^1 ] and 830(Xi)-E[D IX1]
EDii II-E[Di iXJ
respectively. With this "nonparametric imputation," we have a "complete" data

set, where we "observe" Yli DiYi + (1 - Di),31(Xi) under "treatment," and
Yoi (1 - D)Y + D1 :30(Xi) under "control." Our "complete" data set thus
consists of (Y11, Yoi0 Di, Xi), i = 1,. . . ,n, and we can estimate /3 and y by

/3 1 E (Y -Yoi) and (1/n)jDi / - Oi)

n i ~~~~~(1/n)LjDi
Notice that we may consistently estimate /3 and y by the sample averages of

,31(Xi) -,30(Xi) over the entire sample and over the subsample where Di = 1,
respectively, if (,8j(X1),,30(X1)) were observed. Because they are not, we may
use

/3 n - ~ ( :1(Xi) - /30(Xi)) and

(1/n)LjDi ( /31(Xi) - /0(Xi))

(1/n)LjDi
instead. Because these estimators are based on the data set where the missing

values of /31(Xi) and 830(Xi) are imputed by the nonparametric regressio
method, they can also be interpreted as nonparametric imputation based estimators.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

322

JINYONG

HAHN

If the estimators are 4ni-consistent and asymptotically normal, we can use

Newey's (1994) argument to show that the asymptotic variances of nI( /- 3)

and Fn( /3-,l3) are equal to each other and equal to
E 2(x) X + (/(Xi) _ 8)2]

p (Xi) 1 - p(Xi)

Similarly, we can show that the asymptotic variances of H(jn - ry) and n? - ry)
are equal to each other and equal to

p(Xi)_2_(Xi) p(Xi) _ 2 +_ (2(X)- Xi)
E pi2p 2 (I-pj(Xi)) p2 2.
From Theorem 1, it follows that ,B and 13 are efficient for 13, and ry and r are
efficient for y.

PROPOSITION 4: Assume that (Yoi, Y1i) I D1 iXi. Then, 13 and 13 are efficie

semiparametric estimators for /3, and j' and r are efficient semiparametric estimators for y.
(Proof in Appendix.)

Proposition 4 does not provide any regularity conditions. Neither does it tell
us any specific nonparametric regression estimation to be used. In the case

where Xi has a finite support, it is trivial to fill the gap. Notice that, if
take

YLiDiY> I(Xi =x)

Ef DiYi IXi = x]= Li(XI - x)

E[( -Di)YXi Ixi XI E( l(XD X=X)
and

EtD 1 (X, =X)

E[Dj1Xi=x]= L1X=)
the usual argument will establish the asymptotic distribution.

THEOREM 5: Assume that (Yoi, Y1i) I Di [Xi. Furthermore, assume that Xi ha

known finite support. Then, ,B and /3 are efficient semiparametric estimators for /
and j' and r are efficient semiparametric estimators for y.
(Proof omitted.)

When Xi has a continuous distribution, we can choose a variety of nonparametric estimators. When these estimators are computed by the series estimation,
we can find some regularity conditions under which the nonparametric imputa-

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

PROPENSITY SCORE 323

tion based estimators are asymptotically normal.2 To obtain a series estimator of

E[LYIXi =x], for example, we take

p (X) = (PK(X), , PKK(X)) ,
y = (Y1, ... ,Y1d I

P K [ ppK(X1) ,-.p K(X )I] and
E [ Yi Xi = x] = p K r ( X) * (p P PK)- ,
Let

uii =DiYi -p(Xi)131(Xi),
U2i = (1 -Di)Yi - (1 -p(X1))j80(Xj),
U3i = Di -p(Xi)THEOREM 6: Assume that (Yoi, Yli) I Di iXi. Furthermore, assume that:
(i) E[ U2i [Xi] is bounded for k = 1, 2, 3;

(ii) the support of Xi is a Cartesian product of compact intervals H> x1,j, xl,j];

(iii) the density of Xi is bounded below by C Fl 1K(x -x j)(x,,j - X)]V for some

C > 0, and pkK(x) are the products of polynomials that are orthonormal with

respect to NJ= K[(x - x,j)(x,,j - x)]v;
(iv) p(x), j31(x), /30(x) are continuously differentiable of all orders;
(v) K=n? for some e >0, and K7+4'/n -> 0.
Then, /3 and /3 are efficient semiparametric estimators for /3, and j' and
efficient semiparamnetric estimators for y.
(Proof in Appendix.)
It seems that imputation is unavoidable even for the experimental data

case. Consider regressing Y - E[Yi IXi] on Di- E[Di IXi], where E[Y

E[Di jX] are some nonparametric estimators of E[YJ Xj] and E[

this estimator /3SL. The probability limit of /3SL equals

E[(Yj-EL Yi |Xi )(Di-EL Di|Xi ])] ,
E [(Di -E Ds i[Xi ])2]
This is an estimator due to Robinson (1988) for the partially linear semipara-

metric regression model. The asymptotic variance vara( /BSL) of /SL' comput
using Newey's (1994) machinery, equals

E[ -- ] +E[ I ( ] + ((l p -p) 3 wvar( /3(Xi)).

2 In practice, it can be extremely difficult to construct a series PK1(.).. * PKK() such th
Condition 3 in Theorem 6 is satisfied. This condition should thus be viewed as a "high level"
assumption. I thank an anonymous referee who pointed it out.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

324

JINYONG

HAHN

Because

vara(sL)-vara,(/i) = (P(1p) -4) var(/3(Xd))>O,
/3SL is not an efficient estimator.
It was seen that the propensity score is ancillaiy for estimation of /3. On the
other hand, the propensity score is not ancillary for y, but its value is solely
concentrated on the "dimension reduction" feature. Thus, it is of interest to ask

whether the projection on the propensity score instead of Xi is necessary to
attain the efficiency bound in the estimation of y. Although the propensity score
is unknown in many realistic situations, many estimators in the literature use the

nonparametric regression estimation of some conditional expectation on the
propensity score to exploit the "dimension reduction" feature of the propensity
score. I argue that an efficient estimator for y does not have to use the

projection on the propensity score even when the propensity score is known.
Because the sole value of the propensity score seems to be its "dimension
reduction" feature, it can be inferred that the "dimension reduction" does not

imply the necessity of the projection on the propensity score.

PROPOSITION 7: Assume that (Yoi, Yli) I Di Xi. Furthermore, assume that th
propensity score p0-) is known. Then, the estimator

1 (E[ DiYAXi] E[(1- Dd)1yXi \x 1
- P(Xd) I I - -p(Xd)

n k E 2Di xi] 1 -E[D1 Xi] , n
is efficient for the estimation of y.

(Proof in Appendix.)
I now argue that the projection on the propensity score may even be harmful
for the estimation of 3 = y by considering the experimental data case. As for
efficient estimation, we would want to use the estimator which is efficient when

the propensity score is known, because the marginal role of the propensity score

is purely contained in the "dimension reduction." Observe that /3, which is an
efficient estimator for ,3 with or without the knowledge of the propensity score,

is still efficient for /3. As for the estimation of y with the knowledge of the
propensity score, we observe that the estimator developed in Proposition 7
reduces to /3 when the propensity score is constant. Note that we would not
want to use j', because it is efficient only when the propensity score is unknown
and does not make use of the "dimension reduction."

Now, consider the projection on the propensity score. Because the propensity
score is a constant, the projection on the propensity is equivalent to the
marginal expectation. Thus, the idea of conditioning on the propensity score
leads us to consider the difference of the sample averages as our estimator. Call
such an estimator oLS. It can easily be shown that the asymptotic variance

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

PROPENSITY

vara(

OLS)

of

SCORE

POLs

325

equals

LT(Xi) ](Xi) + var+ (X)) var(/30(Xi))
Comparing this with the asymptotic variance of /3 or /3, we find that

var((/OLS)-var,,( i) =var( /1(X1)+ I I' ,(X))
> 0,
and thus OLS is not an efficient estimator.

Comparison of the asymptotic variance of /3 (or ,3) and ry (or ry) suggests that
knowledge of the propensity score can help in a subtler way than the mere

projection on the propensity score. Consider again the experimental data case
where /3 = y. We observe that /3 is efficient whereas ^ is not. This is due to the

fact that we essentially throw away observations with Di = 0 in the "complete"
data analysis. With the knowledge that /3 = y, we can avoid this loss of
information. It is natural to conjecture that this observation would generalize to
the situation where the propensity score is not necessarily constant. Suppose

that p(Xi) =po for Xi E% and p(Xi) =pI for Xi E.Z, where Po =PI and
%0 U 2j = 2. Suppose that we classify the observations according to the know
propensity score. On each subgroup where the propensity score is equal to p0,
say, we can efficiently estimate

E[Yli-Yoi IDi = 1, p(Xi) =po] = E[Yli -Yoi Jp(Xi) =Po]
by /3.

Dept. of Econioinics, Unitersity of Pennsylvania, 3718 Locuist Walk, Philadelphia,
PA 19104-6297, U.S.A.; hahn @econi.sas. ipen;z.edli
Manuiiscript receitved Febriiaiy, 1995; final rei'ision received April, 1997.

TECHNICAL APPENDIX

PROOF OF THEOREM 1
In calculating the variance bounds of 8 and -y, I follow the approach of Bickel, Klaassen, Ritov,

and Wellner (1993, Section 3.3). First, the tangent space is characterized. The density of (Y0, Y1, D, X)
(with respect to some u-finite measure) is given by

q7(yo, Y'1, d, x) =f (y,O, y I Ix)p(x) d( _p(X))1 - f(X),

where f(y0, y lx) and f(x) denote the conditional distribution of (Y0, Y1) given X, and the margin
distribution of X, respectively. The density of (Y, D, X) is then equal to

q(y,d,x) = [fl(ylx)p(x)Yt[f0(y Ix)(1 _p(X))], 1f(x),

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

326

JINYONG

where

(5)

[

HAHN

f1(.jx)

fi(y

=f(yO,

Ix,

*x)dyO,

O)p(X,

0)]

an

d[fo

which equals q(y, d, x) when 0 = 00. The corresponding score is given by

(6) s(d, y, x I 0) -_d sl(y ix, 0) + (1- d) so(y ix, 0)

+ d - p(x, 0) Px )+tx )

p(x, 0)(1 -p(x, 0))
where
d

s1(y x, 0) = -logdOfl(YJX, 0),
d

sO(Y x, 0) = -logdOfo(YjX, 0),
d

p(x, 0) = -p(x, 0),
dO

d

t(x, 0) = -logf(X, 0).
dO

From (6), we obtain

56= {d sl(y x) + (1 -d) so(y x) + a(x) (d-p(x)) +t(x)}
as the tangent space of this model, where fsj(y x)fj(y fx) dy = 0 Vx, j = 0,1, ft(x)f(x) dx 0, and
a(x) is any square-integrable measurable function of x.
Now, the average treatment effect is shown to be pathwise differentiable. For the parametric
submodel under consideration, we find that

/3(0) = ffyfl(y fx, 0)f(x, 0) dydx - ffyfo(y fx, 0)f(x, 0) dydx,
and

ffyp(x, 0)fl(y x, 0)f(x, 0) dydx - ffyp(x, 0)fO(y x, 0)f(x, 0) dydx
fp(x, 6)f(x, 0) dx
Thus,

o0 ffysl(y lx, 00)fl(y Ix)f(x) dydx + f,831(x)t(x, oo)f (x) dx
- ffyso(ylx, Oo)fo(yfx)f(x) dydx - f /0(x)t(x, oo)f(x) dx,
and

dy(00) ffyp(x)sl(y fx, OO)f1(y fx)f(x)dydx ffyp(x)so(y Ix, OO)fO(y Ix)f(x) dydx
do

p

p

f (8(x) - y)p(x, Oo)f(x)dx f13f(x) - y)p(x)t(x, OO)f(x) dx
p

p

Let
D

1-D

(Y, D,X)= p(X) (Y 31(X)) 1-p(X) ( (X)) + /3(X) - 3
D

1-D

p(X)

Fy (Y, D, X)- -*(Y - '81() - pY 1-p(X) (
p

p

p

-

p

X.

/3(X) - /3(X) -

+ ~~(D -p(X))? p()
p

p

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

PROPENSITY

SCORE

327

For the parametric submodel whose score is given by (6), we have

d,0 (00)

do= E[ Ft3 WI D, X) *s(D, Y, XI 00)],

dO E[ F,(Y, D? X) *s(D, Y, XI 00) ]
from which we conclude that ,3 and y are differentiable parameters.

The variance bounds are the expected squares of the projections of Ff and F, on 5?. Because

F,3,FF, c5-, the projections on Y are themselves, and the variance bounds are the expecte
of the projections of F,3 and F,.
PROOF OF THEOREM 2

Now the parametric submodel under consideration changes from (5) to

[fi(y |X, 0 )p(X)]d [fo(y |x, 0 )(1-_p(X))] -f(X, 0 )Because the score now equals

s(d,y,x 0) -d s1(y x, 0) + (1 -d) s0(y x, 0) + t(x, 0),
the tangent space changes to

?= {d * sl(y Ix) + (1 - d) * so(y {x) + t(x)}.
We find that
d,(3 ( o00

do0= E[F,f3(Y, D, X) s(D, Y, XI 0)],

d0
and

dry ( 00)

= E[F,(Y, D, X) s(D, Y, XI 0)],

for
D

1-D

FJ3WI D, X) = (Y- f31(X)) - (Y- p30(X)) + p3(X) -/,
p(X) 1-p(X)
X) D 1 - -D p(X) _______y

F ( Y, D,IX) = -- ( Y , 8( X )) - (,, ( Y-,SOfX )) + p( X) .
p

p

I

1-p(X)

0p

Because F13, F,, e5 again, the variance bounds are the expected squares of the projections of F and

Fy

PROOF OF THEOREM 3

The regular parametric submodel under consideration now changes to

q(y,d, x) =[,f(y Ix, 0)p(0)]d[fo(y x, 0)(1 _p(0))]l-df(x, 0).
The tangent space is thus equal to

Y= {d*s1(yix) + (1 - d) *so(ylx) + a * (d -p) + t(x)},
where a is real number. We find that

d,8(00)

do =0 [o,sWI D, X) -s (D,Y, XI 0A]

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

328

JINYONG

HAHN

for
D

1-D

FJ6(Y,D,X) - p(Y-/31(X))- *(Y-,/3(X)) + ,8(X)-,/.
p

i-p

Because

F,

E39,

we

obt

PROOF OF PROPOSITION 4

For the general case, we can use Newey's (1994) argument for a heuristic proof. I only consider
and y. The asymptotic variance of ,3 and y can be similarly obtained. First, consider ,3. This
estimator takes the form (1/In)inm(Zi, h1, h2, 173), where

ho](x) = E[ DiY, IX = x]1
10)2 (X) = E[(1- Di)Yi IXi = X]

h03(x) = E[Di IXi =X],
and h1, h2, h3 are their estimators. Zi denotes the observation for individual i. Let h (0), 112(0), h3(0)
denote the corresponding functions under some parametric submodel which equals the true model

at 0 = 00. Because m(Xi, hl, h,, h3) depends on h1l, h,, h3 only through their values
h (Xi), h(Xi), h3(Xi), it follows that

-^E[i?i(Xi,
h,(O),
h3(o))] = dE E ,hj(o) b6(Xj)]
890 h,(O),
do
k)OiAi)
for
C)

= in(x, hl(0), h9(0), h3(0)) I 0= ,
Notice that
1

8(x) -1-p()

2 l-p(X)'

:6() '1(X POWX

3(X) = p(X) (1 -p(X))
Newey's (1994) Proposition 4 then suggests that the above estimator has the
function equal to

Di(Yji -/31(X)) (1 - Di)(Yo0 i +0(Xi) ((Xj) )(x) ( 81
p(Xi) 1 -p(X,) +(3()-/0X)-(3

so that its asymptotic variance equals the efficiency bound. For ~

suggests that the numerator has the asymptotic influence function eq

DiYi-1(X)) - (1 - Di)(Y - /0(Xi)) + Di ( /1(Xi) - /0(X)) -py.
1 -p(X,)

Because the denominator has the asymptotic influence function equal to Di -p, the asymp
influence function of the ratio can be computed by the delta method as equal to

Di I 1-Di p(Xi)D
-(Yi-/1(X,)) - ( (Y0i - /0(Xi)) +-( ,1(Xj) -/0((Xi) -

p
and

p

the

1p

t(Xt

)

p

asymptotic

variance

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

of

PROPENSITY

SCORE

329

PROOF OF THEOREM 6

I only consider f3. The rest can be shown similarly. First, I introduce some notation. For a vecto
of function f(x), let

If(x)Id = maxiAI < dmaxXE IAf(x)I,
where r is the support of Xi. We also let

~d(K) = SUpIAI=d Xe I8dpK(x)I.
In what follows, C denotes a generic constant.

To show that the series estimation based imputation estimator is efficient, it suffices to show that

the following conditions taken from Newey (1994) are satisfied:

1. E[u'i Xi] is bounded for k = 1,2,3.
2. (i) The smallest eigenvalue of E[pK(Xi)pK(Xi)'] is bounded away from zero uniformly in K;
(ii) pK(x) is a subvector of PK+ I(X) for all K; (iii) for each K, there is some nonzero r such that
I pK(X) is a nonzero constant on the support of Xi.
3. For each nonnegative integer d, if Ig(x)Id is finite then there are constants C, ad > 0 such that

for all K there is ir with Ig(x) - pK(X)'.Id < CK-'d.
4. (i) There is a function D(z, h) linear in h such that for all h with Ih - h0j0 sufficiently small,

Im(z, h) - m(z, ho) - D(z, h - h0)In < b(z)Ih - ho 0;

(ii) E[b(Zi)] Vd(K)[(K/n)112 + K- ] - 0
and

E[b(Zo)]v4fd(K)2[K/n +K ] 2 0.
5. There is b(z), d > 0 such that E[b(Zi)2] < x, ID(z, g)Io < b(z)IgId, and

(EK 12 Kl)/ 2x[(K/n )1 + Ka ]O.
6. (i) There is 8(x) such that E[D(z, g)] = E[8(Xi)g(Xi)] for all g; (ii) for each K there are TK
such that

n.E[18(Xi) - Kp - TK (Xi)l1] -O,
O(K) Kln O> 0, 4o(K)2E[Ig(X) - 1rKpK(X )I] 0,

E[18(X,) - KP (X0)1] 0
Except for condition 4 (i), these conditions are equivalent to Newey's (1994) Assumptions 6.1-6.6.
Newey's Assumption 6.4 (i) is replaced by his Assumption 5.1 (i), because the former is stronger than
necessary for obtaining asymptotic normality: he makes the assumption to make the proof of the
consistency of the asymptotic variance estimator easier. Newey's (1994, Theorem 6.1) shows that the
semiparametric estimator is asymptotically normal under these conditions.

I will verify that these conditions are satisfied. Condition 1 is satisfied by hypothesis. By Lemma
A.15 of Newey (1995), condition 2 is satisfied by pkK(x) equal to the products of polynomials that

are orthonormal with respect to Hlj= 1[(x - x1j)(xj -x) v with ;d(K) < CKI + V+ 2d and IpkK(X)ld <
CK 5+ 2d. By Lemma. A.13 of Newey (1995), condition 3 is satisfied with ad equal to any positive

constant. Because p(x) is bounded away from 0 and 1, for h sufficiently close to ho, condition 4(i) is
satisfied with

D(z, h-h ) =h-hol h2 - _ hol + 1 h2 ](h -h )
03 03 0h3 (1 -h03) ]

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

330

JINYONG

HAHN

and

b(z) = C(1 + 13,8(x)l + 1,30(x)D.
Also observe that

[() 2 ] ? (( ) +K I+ d) a 0

nO(K) [- +K (a K =?( K +da2+2 -2a) ?
if we take av> 1 + v. For condition 5, note that

D(z, g)v ? C(1 + ,31(x)1 + K0(x)I)-gL, and

[( K7+1 1/1

For condition 6, note that

ED(Z, g)] = E[ 1(XI)g(Xx)] for

(p(x) 1 p()1 K(x) 1132))
Because 8(x) is continuously differentiable of all orders, by Lorentz (1986, Theorem 8), there exist

qrK and (K such that

E[l(XP)-( K (Xi)H - O(KK2 a 0 and
8WK --=
0~ n
ELHg(Xi)
7FKpK(Xi)lo]
- O(K 2& C) 0.
We have

So(K) EHgP(X) l = P(X)] O(K2?-2 ) 0

E E[D(XZ ) - g Kp) E [(Xi)-0] g gXi) for= O(nK4a) 0,

E[18 Xi) ~K p(Xi)12 ( n

if we take ai suf iciently large.

E'lg(i) - -p(XP)

PROOF OF PROPOSITION 7

Newey's (1994) Proposition 4 suggests that the numerator has the asymptotic influence function
equal to

- KXi1231(XK)) l -(1 -D)(Y - 30(X.))?P(X) ( (X)-o(X))-py

Because
denominator has the asymptotic influence
function equal to p(X,) -p, we can use the
Ththeweyasymptotic
variaceofithion4sugestimat
delta method to obtain the asymptotic influence function,

-( j3(XK)) (Xi) ( KY0 30(Xi)) + p 4( a(X) o (X) - y)
pto

pK

1f

-Xis

pstK

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

PROPENSITY

SCORE

331

REFERENCES
ANGRIST, J. (1995a): "Using Social Security Data on Military Applicants to Estimate the Effect of

Voluntary Military Service on Earnings," National Bureau of Economic Research, Working Paper
No. 5192.

(1995b): "Conditioning on the Probability of Selection to Control Selection Bias," forthcoming in Economics Letters.

BEGUN, J. M., W. J. HALL, W. M. HUANG, AND J. A. WELLNER (1983): 'Information and Asymptotic

Efficiency in Parametric-Nonparametric Models," Annals of Statistics, 11, 432-452.
BICKEL, P., C. A. J. KLAASSEN, Y. RITOV, AND J. A. WELLNER (1993): Efficienlt alnd Adaptive

Estimation for Seiniparanetric Models. Baltimore: Johns Hopkins University Press.
CLEMENTS, N., J. HECKMAN, AND J. SMITH (1993): "Making the Most out of Social Experiments:
Reducing the Intrinsic Uncertainty in Evidence from Randomized Trials with an Application to
the National JTPA Experiment," Unpublished manuscript, University of Chicago.
HECKMAN, J. (1992): "Randomization and Social Policy Evaluation," in ELialitatinig Welfarze and

Training Programs, ed. by C. Manski and I. Garfinkel. Cambridge: Harvard University Press.
HECKMAN, J., H. ICHIMURA, J. SMITH, AND P. TODD (1995): "Nonparametric Characterization of
Selection Bias Using Experimental Data: A Study of Adult Males in JTPA," Unpublished
manuscript, University of Chicago.

HECKMAN, J., AND J. SMITH (1995): "Assessing the Case for Randomized Social Experiments,"
Journical of Econzomic Perspectives, 9, 85-110.
IMBENS, G. W., AND J. D. ANGRIST (1994): "Identification and Estimation of Local Average

Treatment Effects," Econ1oinetrica, 62, 467-475.
LORENTZ, G. (1986): Approximationi of Funlctions. New York: Chelsea Publishing Company.
NEWEY, W. K. (1990): "Semiparametric Efficiency Bounds," Jown{al of Applied Econometrics, 5,
99-135.

(1994): "The Asymptotic Variance of Semiparametric Estimators," Ecozornetrica, 62,
1349-1382.

(1995): "Convergence Rates for Series Estimators," in Advances in EconoImietrics anld
Quantitative Economics: Essaiys in Honior of Professor C. R. Rao, ed. by G. Maddala, P. Phillips,
and T. Srinivasan. Cambridge: Basil Blackwell.

ROBINSON, P. (1988): "Root-N-Consistent Semiparametric Regression," Econom-iietrica, 56, 931-954.

ROSENBAUM, P., AND D. RUBIN (1983): "The Central Role of the Propensity Score in Observational

Studies for Causal Effects," Bio,netrika, 70, 41-55.
(1984): "Reducing Bias in Observational Studies Using Subclassification on the Propensity

Score," Journal of the American StatisticalAssociatiol, 79, 516-524.
STEIN, C. (1956): "Efficient Nonparametric Testing and Estimation," in Proceedinigs of tihe Third
Berkelev Symposium onz Mathiemnatical Statistics ancd Probability, 1. Berkeley: University of California
Press.

TODD, P. (1995): "Matching and Local Linear Regression Approaches to Solving the Evaluation
Problem with a Semiparametric Propensity Score," Unpublished manuscript, University of
Chicago.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:06:39 UTC
All use subject to https://about.jstor.org/terms

