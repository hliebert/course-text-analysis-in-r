American Economic Journal: Economic Policy 3 (May 2011): 41–65
http://www.aeaweb.org/articles.php?doi=10.1257/pol.3.2.41

Manipulation of Social Program Eligibility†
By Adriana Camacho and Emily Conover*
We document how manipulation of a targeting system for social welfare programs evolves over time. First, there was strategic behavior
of some local politicians in the timing of the household interviews
around local elections. Then, there was corrupt behavior with the
sudden emergence of a sharp discontinuity in the score density,
exactly at the eligibility threshold, which coincided with the release
of the score algorithm to local officials. The discontinuity at the
threshold is larger where mayoral elections are more competitive.
While cultural forces are surely relevant for corruption, our results
also highlight the importance of information and incentives. (JEL
D72, I32, I38, O15, O17).

D

ue to the high costs to society in terms of development and growth, addressing
corruption has become a priority of governments and international institutions.1
To effectively combat corruption it is necessary to understand its causes. Although
causes are debated, culture is often identified as a key factor.2 While cultural forces
are surely relevant for corruption, our findings suggest that policy makers should
also consider information, timing, and political incentives when designing instruments to allocate public subsidies.
Our paper documents the sudden emergence of a sharp discontinuity exactly at the
eligibility threshold of a targeting instrument used to identify potential beneficiaries
for a variety of social welfare programs in Colombia. The sudden emergence appears
to be a consequence of the diffusion of information about the mechanism for resource
allocation. In the four years following the introduction of the instrument, there was no
apparent manipulation but, rather, strategic behavior by some politicians who timed
* Camacho: Economics Department and CEDE, Universidad de Los Andes, Calle 19 A # 1Este-37, Bogotá,
Colombia (e-mail: adcamach@uniandes.edu.co); Conover: Economics Department, Hamilton College, 198
College Hill Road, Clinton, New York 13323 (e-mail: econover@hamilton.edu). We thank Departamento Nacional
de Planeación (DNP) for providing the Census of the Poor dataset, Andres Rosas and CEDE for municipality level
data and El Tiempo for the newspaper circulation data, and Registraduría for electoral data. Research assistance
from Alejandro Hoyos, Paula Mejía, and Roman A. Zárate is gratefully acknowledged. We are grateful to Anna
Aizer, Pranab Bardhan, Donald Conover, Ernesto Dal Bo, Pedro Dal Bo, Andrew Foster, Bryan Graham, Margaret
Grosh, Chang-Tai Hsieh, David Levine, Daniel Mejía, Edward Miguel, Enrico Moretti, Suresh Naidu, Paulina
Oliva, Cristine Pinto, Nora Rojas, Gérard Roland, Dean Scrimgeour, Ernesto Stein, and two anonymous referees for helpful comments and suggestions. Special thanks also to participants in the UC Berkeley Development
Seminar, NEUDC 2007 conference, Brown University micro lunch participants, Seminario CEDE Universidad de
Los Andes, European Econometric Society 2008, LACEA-PEG 2008 conference, and The World Bank Poverty
Reduction and Economic Management Network. All errors are ours.
†
To comment on this article in the online discussion forum, or to view additional materials, visit the article page
at http://www.aeaweb.org/articles.php?doi=10.1257/pol.3.2.41.
1
For related work on corruption and development see Paolo Mauro (1995) and Pranab Bardhan (1997).
2
See Mauro (2004), Johann Graf Lambsdorff (2006), Raymond Fisman and Edward Miguel (2007), and
Abigail Barr and Danila Serra (2010).
41

42

American Economic Journal: economic policy

May 2011

the surveys right before elections. After the information was released, corruption,
manifested by lowering poverty index scores, made some households eligible for subsidies. The cost of the corrupt behavior documented here is non-trivial, corresponding
roughly to 7 percent of the National Health and Social Security budget.
In the early 1990s, when the Colombian government initiated an unprecedented
proxy-means testing system, targeted social program spending became a priority.
To identify the poor population the government carried out its Census of the Poor
(known as the SISBEN I in Colombia).3 This census collects comprehensive information on dwelling characteristics, demographics, income, and employment at the
individual and household level and uses it to assign a poverty index score to each
family which goes from 0 (poorest) to 100 (least poor). This score was designed to
measure long term living conditions, not transitory income shocks, and thus to properly identify the population most in need of assistance. Eligibility rules for several
social welfare programs use specific thresholds from the poverty index score. The
most common threshold was a score of 47 for urban families.
The central government instructed municipal officials on how to target the population for the Census of the Poor with door-to-door interviews, but allowed municipalities discretion over the administration and timing of the interviews. Safeguards
built into the system included the creation and distribution by the central government of the questionnaire and the computer program that calculates the scores. In
this paper we use the dataset corresponding to the original urban Census of the Poor,
commonly known as the “old” or “first” SISBEN, implemented between 1994 and
2003. This dataset covers approximately 18 million individual observations in urban
areas, with the responses to all the questions in the census, as well as the poverty
index score recorded for each family.
Despite the safeguards in the system, we found unusual patterns in the data suggesting that not all the scores are accurate. In Figure 1, we document the sudden
emergence in 1998 of a sharp discontinuity of the score density, exactly at the eligibility threshold. In the spirit of studies that use statistics to uncover evidence of
cheating,4 we identified municipalities with relatively high proportions of families
that had almost identical answers in a given month. Using the answers to the questions and the score algorithm, we also found that most of the manipulation was not
due to overwriting the final score.
The Census of the Poor can be manipulated in several ways: the enumerators can
change the answers, a person in a position of power (e.g., a politician) can instruct
someone to change the score, or respondents can lie.5 One type of manipulation
does not exclude another. Although each type of manipulation can undermine the
system, in this paper we focus on political manipulation. Newspaper articles suggest
that manipulation took place at the local government level.6
3
See Tarsicio Castañeda (2005), and Carlos E. Vélez, Elkin Castaño, and Ruthanne Deutsch (1999) for a
detailed description of the SISBEN.
4
See Brian A. Jacob and Steven D. Levitt (2003), Justin Wolfers (2006).
5
There is anecdotal evidence of people moving or hiding their assets, or of borrowing and lending children.
6
For example, in the newspaper El País the title of an article dated October 13, 2000 translates to “Politicians
offer Census of the Poor interviews in exchange for votes.” Other references for press articles on electoral manipulation are available in the online Appendix C.

Camacho and Conover: Manipulation of Social Program Eligibility

Vol. 3 No. 2

1994

5

5

4

4

3
2
1
0

1995

6

Percent

Percent

6

3
2
1

0

0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

0

Poverty index score

4

Percent

Percent

5

4

2

1997

6

5

3

3
2
1

1
0

0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

0

Poverty index score

4

Percent

Percent

5

4

2

1999

6

5

3

3
2
1

1

0
0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

0

Poverty index score

4

Percent

Percent

5

4

2

2001

6

5

3

1

3
2
1

0

0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

0

Poverty index score

4

Percent

Percent

5

4

2

2003

6

5

3

7 14 21 28 35 42 49 56 63 70 77 84 91 98

Poverty index score

2002

6

3
2
1

1
0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

Poverty index score

2000

6

0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

Poverty index score

1998

6

0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

Poverty index score

1996

6

0

43

0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

Poverty index score

0
0

7 14 21 28 35 42 49 56 63 70 77 84 91 98

Poverty index score

Figure 1. Poverty Index Score Distribution 1994–2003, Algorithm Disclosed in 1997
Notes: Each figure corresponds to the interviews conducted in a given year, restricting the sample to urban households living in strata levels below four. The vertical line indicates the eligibility threshold of 47 for many social
programs.

44

American Economic Journal: economic policy

May 2011

The algorithm for the score was made available to municipal administrators
sometime after July 1997, in an instructional presentation that was also distributed
as a pamphlet.7 Before diffusion of the score algorithm, the benefits of surveying for
local politicians were high since people were confused about the eligibility criteria
for the programs. They thought that having an interview was a sufficient condition for eligibility (Misión Social, Departmento Nacional de Planeación Ministerio
de Salud, and Programa Naciones Unidas para el Desarrollo (UNDP) 2003, 153).
Although there is variation across municipalities, during this period many local politicians were conducting a relatively large number of surveys around election time.
This behavior is not necessarily corrupt, but it is strategic. Over time, however,
people became aware that instead of interviews, a score below a certain cutoff was
necessary for program eligibility. The timing of the release of the score algorithm to
local officials coincides almost exactly with the appearance, in 1998, of a sharp discontinuity of the score density at 47, the cutoff threshold. After the score algorithm
was released, we find that in municipalities with more competitive elections, and
thus with higher benefits to the incumbent for each additional vote, the discontinuity
at the poverty threshold is larger.
We assess whether alternative explanations could generate the observed patterns
in the score distribution. To ensure that the changes in the distribution are not due to
changes in macroeconomic conditions, we use other data where there is no incentive for manipulation, and find that the score distribution does not exhibit a clear
jump at the eligibility threshold. We rule out the possibility of municipal officials
getting better at targeting the poor by looking at the number of interviews conducted
within poorer and richer neighborhoods over time and find that it remains relatively
constant. We estimate a weighted average of a municipal level poverty index and
find that over time the proportion of poor, in the municipalities that conducted surveys, did not increase, indicating that the pattern is not driven by the composition
of municipalities.
Government social program spending in Colombia doubled from 1992 to 1996.8
Most of these social programs use the poverty index score from the Census of
the Poor to identify beneficiaries. There are few studies that quantify the costs of
corruption;9 we contribute to this literature by estimating the costs of corruption for
a nationwide intervention and observed that these costs are significant. We estimate
that approximately 3 million people (8 percent of the Colombian population at that
time) had their scores lowered.
Our findings also add to the growing literature explaining how politicians in developing countries use pre-electoral manipulation to influence electoral outcomes.10
Moreover, this paper is unique in relating pre-electoral manipulation with targeting
systems for social programs. From a methodological perspective, by providing a
real and wide-spread case we add to the literature that emphasizes the importance
of taking into account the possibility of sorting when evaluating programs that use
7
Colombia’s National Planning Agency (DNP), July 1997 “SISBEN: Una Herramienta Para la Equidad,”
PowerPoint presentation and pamphlet.
8
Data from Colombia’s National Administrative Department of Statistics (DANE) and DNP.
9
See for example, Benjamin A. Olken (2006); Ritva Reinikka and Jakob Svensson (2004).
10
Stuti Khemani (2004); Allan Drazen and Marcela Eslava (2010); Claudio Ferraz (2007).

Vol. 3 No. 2

Camacho and Conover: Manipulation of Social Program Eligibility

45

proxy-means tested targeting.11 Similarly to studies in the United States and the
United Kingdom that, although not about corruption, have shown bunching behavior due to kinked budget sets,12 evaluations of programs that use targeting tools
should consider behavioral responses from individuals and politicians.
The paper is structured as follows: in section I we describe the datasets used in
the study. In Section II we present evidence in support of the manipulation hypothesis. In Section III we use a political economy model to explain what could be
generating the poverty index score discontinuity and test some of the predictions
of the model with election data. In Section IV we present results showing that the
changes in the distribution are most likely not driven by alternative explanations. We
conclude in Section V.
I. Data

A. Census of the Poor Data
The original Census of the Poor was conducted by each municipality between
1994 and 2003. Including urban and rural households, the dataset contains 25.8
million individual records. In our sample we exclude the rural population because
its eligibility thresholds are different and approximately 70 percent of Colombia’s
population is urban.
Colombia’s neighborhoods are geographically stratified into six levels (strata),
with level 1 the poorest and level 6 the wealthiest. There is also an unofficial strata
level 0 which corresponds to neighborhoods without access to any type of utilities,
domestic workers or people who rent a room from another household. Since the
objective of the Census of the Poor is to identify the poor, municipal officials were
instructed to conduct door-to-door interviews in neighborhoods of strata below level
four, though people living in richer neighborhoods could request an interview. We
exclude from our sample people living in neighborhood strata level four or above.13
This leaves approximately 18 million individuals that represent roughly 40 percent
of the total Colombian population. Of 1,102 municipalities, 785 have Census of the
Poor records, and these municipalities account for 86.5 percent of the Colombian
population.
Using the Socio-Economic Characterization Survey, representative at the national
level, we estimate that the response rate for the Census of the Poor is approximately
between 77 percent and 89 percent. This high response rate is supported by the
way in which the surveys were conducted, which followed the same process as the
population Census. Each enumerator was assigned specified blocks, and they were
instructed to conduct the interviews in a clockwise fashion, house by house without
skipping any residence. Supervisors then randomly checked to ensure that the interviews were completed appropriately.
See Justin McCrary (2008) for a formal and general test of manipulation of the running variable density
function.
12
Leora Friedberg (2000); Richard Blundell and Hilary W. Hoynes (2004); Emmanuel Saez (2010).
13
Our main findings do not change when we include people in all strata levels.
11

46

American Economic Journal: economic policy

May 2011

Table 1—Summary Statistics: Census of the Poor and 1993 Population Census
Census of the Poor
Panel A
Individual characteristics
Age
Male
Not disabled

Highest schooling (age > 18)
None
Primary
Secondary
College
Post-college
Household characteristics
Household size**
Number of rooms in HH
Brick, rock or blocks walls
Dirt floors
Access to electricity*
Access to sewage
Trash disposal service

Panel B
Possessions
Own a TV
Own a refrigerator
Own a blender
Own a washer
Observations

Mean or percent

Obs.

Population Census
Mean or percent

Obs.

25.69
0.48
0.98

18,176,019
18,176,019
18,175,663

26.37
0.48
0.98

2,325,747
2,325,747
2,325,747

0.11
0.51
0.35
0.02
0.00

1,222,950
5,478,766
3,711,856
256,427
11,305

0.06
0.38
0.42
0.13
0.01

77,850
516,254
569,317
172,703
19,226

3.44
1.89
0.84
0.11
0.98
0.90
0.87

5,310,308
5,310,304
4,436,999
562,147
5,203,646
4,801,232
4,619,680

4.17
3.56
0.86
0.06
0.96
0.89
0.84

537,317
537,317
462,446
33,324
513,655
475,839
452,385

Census of the Poor
Percent of households
0.52
0.33
0.37
0.04
5,310,308

Notes: Panel A includes information available both in the Census of the Poor and the 1993 Population Census.
Panel B includes only information available in the Census of the Poor. 1993 Population Census is a 10 percent random sample from the Minnesota Population Center (Minessota Population Center 2007). We restrict both to urban
areas only. The 1993 Population Census includes all socio-economic strata levels, while the Census of the Poor
includes only levels below 4 (i.e., the left-side of the distribution according to socio-economic strata geographical
characterization).
** Different definitions.
* Different wording of question.

The Census of the Poor is not a panel dataset despite the fact that it spans a 10
year period. Generally, each household was interviewed only once. Implementation
dates varied by municipality, and most municipalities conducted more than one
round of interviews to cover the poor population.
Panel A in Table 1 shows summary statistics for the Census of the Poor and a
10 percent sample of the 1993 Population Census from the Minnesota Population
Center (Minnesota Population Center 2007). The 1993 Population Census includes
all urban socio-economic strata levels, while the Census of the Poor includes only
those below level 4 (i.e., the left-side of the distribution according to socio-economic
strata characterization).14 The table shows that, as expected, people in the Census of
the Poor are slightly younger, have smaller dwellings, and generally less education.

14

Information about the strata level is not available in the Population Census.

Vol. 3 No. 2

Camacho and Conover: Manipulation of Social Program Eligibility

47

The poverty index score is a weighted average of answers to the Census of the
Poor.15 The Census of the Poor has 62 questions, which took approximately 10–15
minutes to complete. The score is calculated at the family level. It uses information
about the unit of residence, the family, and individuals. The poverty index score has
four components: utilities, housing, demographics, and education. These components are divided into subcomponents that are added to calculate the overall score.
The algorithm used to calculate the score is complex, and many of the answers for
demographic and education questions do not enter directly into the calculation but
are derived (e.g., average education of household members older than 11 years old;
social security of the highest wage earner), making it very difficult for anyone to
predict whether a family would have a score below 47.
B. Socio-Economic Characterization and Quality of Life Surveys
We use alternative data sources to verify whether score discontinuities emerged
in these other data. Data for 1993 come from the Socio-Economic Characterization
Survey implemented by DNP, the same agency that designed the Census of the Poor.
This survey includes approximately 20,000 households in urban areas. Data for
1997 and 2003 come from the Quality of Life Surveys, collected by DANE.16 The
1997 and 2003 Quality of Life Surveys include approximately 9,000 and 18,500
urban households respectively. The surveys are representative at the national level.
In our analysis we restricted the sample to people living in urban areas and strata
levels below four to make it comparable with our working dataset of the Census of
the Poor.
C. Election Data
Data for mayoral elections were provided by Colombia’s Electoral Agency. For
the period we study, mayoral elections occurred in 1994, 1997, 2000, and 2003.
There is information for the number of votes every candidate in each municipality
received only after 1997, thus we are able to create a measure of political competition for 1997, 2000, and 2003. We define the intensity of political competition as:
(1)

(

)

votes(winner) − votes(runner up)
​     
   
​.
 ​
political competition ≡ 1 − ​ ___
Total votes

We define political competition this way so that higher values represent more
competitive elections. This variable takes values that could go from 0 to 1. The
closer to 1 the more competitive the election. Table 2 shows summary statistics for
the variables used in the empirical analysis. The mean value for the political competition variable is 0.829, which translates into a difference in the fraction of votes the
winner received relative to the runner-up of 0.171.
15

The algorithm for calculating the poverty index score is available in online Appendix D.
The 1993 survey is known in Colombia as the CASEN survey. The 1997 and 2003 surveys are known in
Colombia as Encuestas de Calidad de Vida (ECV).
16

48

American Economic Journal: economic policy

May 2011

Table 2—Summary Statistics: Election and Control Variables
Description
Political competition
Discontinuity+/− 3 points
Discontinuity+/− 5 points
Log population
Ratio of urban to total population
Proportion of poor (NBI)
Proportion of surveys
Number of community organizations
Newspaper circulation
Distance to largest city in state (km)
Surface area of municipality (km2)

Mean
0.829
0.022
0.026
10.517
0.534
0.304
0.511
56
434
101
796

SD
0.168
0.031
0.036
1.136
0.233
0.143
0.252
325
3,154
83
1,889

Min
0.109
−0.136
−0.076
8.771
0.188
0.005
0.000
2
1
0
15

Max
0.999
0.152
0.209
14.656
0.988
0.691
1.000
5,944
51,574
548
17,873

Notes: Discontinuity +/− x points is the difference in the fraction of interviews x = 3,5 points before the threshold relative to the same points after the threshold, using data for the 6 months prior to the election and accounting
for the fact that a continuous non-manipulated distribution would also yield a non-zero discontinuity as described
in Section IIIB. The closer to 0 the smaller the discontinuity at the threshold. Political competition is one plus
the negative of the difference in the fraction of votes the winner received relative to the runner-up in the previous election (see equation (1)). The closer to 1 the more competitive the election. NBI is a measure for the proportion of people in a municipality with unsatisfied basic needs constructed using information from the 1993 and
2005 Population Census. Community organizations are the number of neighborhood level civil institutions in each
municipality. Newspaper circulation corresponds to certified daily average circulation data by municipality for 2004
from Colombia’s main national newspaper, El Tiempo. A municipality in Colombia is the jurisdiction most similar
to a county in the United States.

II. Manipulation of Poverty Index Scores and Timing of Interviews

A. Patterns in the Data
The poverty index score could have been manipulated at different stages and by
different agents: during the interview by the respondent or the enumerator, at the data
entry point or later by someone with access to the data, such as a municipal official.
Although all types of manipulation could be detrimental to the system, we focus on
political manipulation because of its implications on undermining the political process
and weakening democratic institutions. Manipulation during or after the data entry
stages involves changes to the answers in the questionnaire, in a specific component,
or changing the final score. In this section we show information in support of the
claims that the Census of the Poor was manipulated, and in particular we find problems likely to come during or after the data entry stages, which is consistent with
manipulation occurring in a centralized way. In Section IV we explore whether alternative explanations could be generating the trends we observe in the data.
Some suspicious patterns in the data are shown in Figures 1 and 2. Figure 1 shows
that from 1998 to 2003 the score distribution exhibits an increasing discontinuity of
the density exactly at the eligibility threshold of 47, indicated by the vertical line
in the figure. Table 3 shows the estimate of the discontinuity at the threshold using
local linear regressions with a rule-of-thumb bandwidth suggested by J. Fan and I.
Gijbels (1996). The timing of the appearance of the poverty index score discontinuity in 1998 at the 47 threshold coincides almost exactly with the release of the score
algorithm to municipal administrators (sometime after July 1997). Before the score
algorithm was made available to municipal officials, some local politicians behaved

Camacho and Conover: Manipulation of Social Program Eligibility

Vol. 3 No. 2

49

Relative number of surveys

3000

2000

1000

0
1994

1995

1996

1997

1998

1999

2000

2001

2002

2003

Year
Figure 2. Number of Census of the Poor Interviews, Controlling for Municipality and Strata
Notes: Vertical lines indicate regional mayoral elections. Results from coefficients of a regression of number of
surveys per year-month, on an indicator for each year month, controlling for municipality and strata level. Base
month: January 1994.

strategically by timing the household interviews around local elections. This is illustrated in Figure 2 which shows that there are spikes in the number of interviews
conducted during periods of mayoral elections from 1994 to 1997. In particular, the
spike is more noticeable prior to the 1997 election. There are no obvious spikes in
the number of surveys conducted after 1998.
Figure 3 shows the Census of the Poor distribution from 1998 to 2003 and the 1993
Socio-Economic Characterization Survey data distribution, which is representative
at the national level. If the 1993 survey data distribution is a good approximation of
what the Census of the Poor distribution would look like without manipulation, then
this figure indicates that one way in which manipulation occurred was to have some
scores lowered. The differences between the distributions can guide as to where the
people who had their scores changed come from.
B. Evidence of Manipulation
We were able to identify, whether the given overall score, or a specific component, is different from what the algorithm should have generated by using the score
algorithm and the individual answers from the survey. Table 4 shows that the housing, utility and education components match almost perfectly. But approximately
11 percent of individuals do not match in the demographic component. Most of the
discrepancies come from the income subcomponent. This could happen because at
the data entry stage the program used to calculate the score required the data entry

50

American Economic Journal: economic policy

May 2011

Table 3—Size of the Discontinuity at the Eligibility Threshold
Year
1994
1995
1996
1997
1998
1999
2000
2001
2002
2003

Estimator
0.033
0.080
0.008
0.024
0.868***
1.209***
1.422***
1.683***
1.565***
1.547***

SE

[0.086]
[0.083]
[0.121]
[0.097]
[0.119]
[0.145]
[0.154]
[0.150]
[0.132]
[0.132]

Note: Estimation done using local linear regressions and an optimal bandwidth algorithm.
*** Significant at the 1 percent level.

Table 4—Reconstructed versus Recorded Poverty Index Score
Component
Housing
Utilities
Education
Demographic

Match
Yes
No
Yes
No
Yes
No
Yes
No

Individuals
18,107,888
60,165
18,068,140
99,915
17,721,184
446,871
16,052,471
2,115,583

Households
5,288,141
16,806
5,278,296
26,651
5,194,450
110,497
4,700,355
604,592

Percent of
households
99.68
0.32
99.50
0.50
97.92
2.08
88.60
11.40

Notes: The Census of the Poor includes individuals in urban areas and all socio-economic strata levels. “Match”
indicates all individuals and households where the reconstructed score (calculated using the score algorithm and
answers to each question) agrees with the score given in the database.

person to type a value for that year’s minimum wage. If someone in the municipality entered (by accident or on purpose) the wrong minimum wage, then the income
subcomponent generated by the algorithm would be different.
Figure 4 shows the overall results of the given poverty index score distribution and
the reconstructed score at the individual level for people living below strata level four.
The figure shows that, with some exceptions at the zero score, the reconstructed score
follows closely the given score distribution. Importantly, at the aggregate level, the
reconstructed score also changes discontinuously at the threshold, indicating that for
most of the municipalities the manipulation did not occur by overwriting the true score
with a new score, but it must have occurred at a different stage in the process.
In the data, we identify values of the score that cannot exist. Almost all of the
subcomponents of the poverty index score have four decimal digits. Across components, the score algorithm generates only two possible combinations that can take
whole number values, all other combinations have at least two decimal places. We
find that 4 municipalities within a departamento (state) have whole number values
which the score algorithm could not have generated. Moreover the average of these
scores is 20 and all of them are below the eligibility threshold. We also identified the
highly unlikely cases that all components sum to zero. We found that the majority of
these cases appear in 8 municipalities for 14,354 families and after 1998.

Camacho and Conover: Manipulation of Social Program Eligibility

Vol. 3 No. 2

51

6
Socio−Economic
Characterization Survey
Census of the Poor

Percent

4

2

0
0

7

14

21

28

35

42

49

56

63

70

77

84

91

98

Poverty index score
Figure 3. 1998–2003 Census of the Poor and 1993 Socio-Economic
Characterization Survey Score Distribution
Notes: The Census of the Poor and the Socio-Economic Characterization Survey use only urban households living in strata levels below four. The vertical line indicates the eligibility threshold of 47 for many social programs.

5
Poverty Index Score
Reconstructed Score

Percent

4

3

2

1

0
0

7

14

21

28

35

42

49

56

63

70

77

84

91

98

Poverty index score
Figure 4. Poverty Index Score and Reconstructed Score
Notes: Triangles indicate the reconstructed Poverty Index Score using the score algorithm. Bars indicate the Poverty
Index Score distribution as it appears in the Census of the Poor database. The vertical line indicates the eligibility
threshold of 47 for many social programs.

Another way to change the scores, besides hard coding different answers, would
be to learn a combination of answers that yields a score below the threshold and
use this combination repeatedly. To investigate this possibility, we follow two
approaches. We selected the families that have almost exactly the same answers as

52

American Economic Journal: economic policy

May 2011

at least one other family interviewed in a given municipality and month.17 In the first
approach, we counted the number of families with shared answers and divided that
by the total number of families interviewed in that municipality and month. This
gives us a ratio between 0 and 1. If, for example, everyone in that municipality and
month had the same answers, the ratio would be 1. Since we do not observe manipulation in the score distribution before 1998, we treat the pre-1998 data as a sample
from the true data generating process for repeated answers. Using the pre-1998 data,
we estimate local linear quantile regressions of the proportion of repeated answers
on the total number of interviews conducted in each municipality and month.18 We
use the predicted values from these regressions to flag those in the post-1998 period
above the ninetieth percentile.
In a second and more restrictive approach, we identified the number of families
with the most common repeated answers in each municipality and month. We divided
that number by the total number of families interviewed in that municipality and
month. This gives us a ratio between 0 and 1. If, for example, in a municipality there
were 1,000 households interviewed in a given month, and 10 had shared answers,
while another 500 households also had shared answers that yield a different score, we
identify only those 500 households and divide that number by 1,000. Then, using the
pre-1998 data, we estimate local linear quantile regressions of the proportion of the
most common repeated answers on the total number of interviews conducted in each
municipality and month. We use the predicted values from these regressions to flag as
suspicious those in the post-1998 period above the ninetieth percentile.
With these methodologies we were able to identify, for example, a municipality
that on a single day interviewed approximately 45,000 individuals from different
neighborhoods, but who each had a score of 31. These individuals had the same
answers for schooling, earnings and possessions, the same survey supervisor, coordinator and data entry person, and very little variation in dwelling characteristics.
Having the same supervisor and coordinator is consistent with centralized manipulation and not manipulation from individuals copying answers from their neighbors,
or enumerators “selling” answers to the households.19
Overall, using the first approach, we identified around 819,000 households
(approximately 2.8 million people) with highly suspicious similarities in their
answers. With the second approach, we identified around 50,000 households
(approximately 178,000 people) with highly suspicious similarities in their answers.
In Figure 5, we show how with the first approach 77 percent of the households
17
We write “almost exactly” because the condition we used is that the value for the four components of the score
(education, housing, demographics, and utilities) should be exactly the same.
18
We estimate local linear quantile regressions because both the mean, and the variance of the proportion of
repeated answers, changes with the total number of interviews. Thus, we need a flexible functional form to identify
the upper quantiles.
19
This is because the answers came from different neighborhoods, and the scores are exactly the same. To get
the same scores it is necessary that the demographics of the household including composition, and age structure
are (almost) the same, and the observable dwelling characteristics would also need to be (almost) identical. This
is highly unlikely and if respondents are dishonest enumerators can detect lies during the interview for observable
dwelling characteristics. Additionally because respondents needed to provide national ID cards, birth certificates or
other forms of documentation, demographic information is also corroborated. Supervisors, coordinators, data entry
people or someone higher up are likely to notice that 45,000 people are ending up with almost exactly the same
answers for a detailed questionnaire with 62 questions.

Camacho and Conover: Manipulation of Social Program Eligibility

Vol. 3 No. 2

100

Percent below threshold

53

95.3

Percent above threshold

Percent suspicious

80

76.7

60
48.6

51.4

40
23.3

20
4.7

0

1993 survey

Repeated

Max repeated

Figure 5. Percent of Suspicious Scores Below and Above the Threshold
Notes: Repeated answers corresponds to number of families with the exact same score for all four components
within a municipality and month. 1993 survey uses data from the 1993 Socio-Economic Characterization Survey
(SEC).

identified with unusual answers, fall below the 47 threshold. While with the second
approach 95 percent do. This is in contrast to only 48 percent of all respondents
falling below this threshold when using data from the 1993 nationally representative
household survey. Furthermore, in both approaches there is a high concentration of
people with scores between 35 and 47.
To summarize, in this section we showed patterns in the data that suggest there
was manipulation in the implementation of the Census of the Poor. We also found
some evidence of manipulation by identifying non-matching answers between the
score the algorithm would have generated and the given scores. The largest number
of suspicious scores comes from looking within municipalities and in each month,
where we found approximately 2.8 million people with repeated answers. We summarize our findings in Table 5.
III. Mechanisms for Manipulation of Poverty Index
Score and Timing of Interviews

A. Theoretical Framework
In this section we provide a brief theoretical framework to motivate our empirical
findings. We show two mechanisms through which politicians misused the program,
either by conducting a large number of surveys before elections or by changing
people’s scores. The instrument used to increase their electoral support depends on
the relative costs and benefits of each at a particular point in time.20
20
See James A. Robinson and Thierry Verdier (2002), Robinson (2005) and Frederic Charles Schaffer (2007)
for related literature on vote buying, patronage, and clientelism.

54

American Economic Journal: economic policy

May 2011

Table 5—Summary of Suspicious and Changed Poverty Index Scores
Due to:
Suspicious hard coding a different score from
what the algorithm would generate
Suspiciously repeated answers
in a municipality-month
Total cheating detected
Estimated undetected cheating

Number of
households

Percent of
households

22,532

0.42

819,384

15.43

841,916
35,277

15.85
0.66

Notes: Hard coding a different score includes: hard coding a component score that cannot
exist, hard coding the component scores as zeros, changing the final score to zero or another
score. Suspiciously repeated answers consists of finding combination of answers for households within a municipality and month that are repeated beyond what the ninetieth percentile
of the pre-1998 data would indicate. See Section IIB for details.

Using a probabilistic voting model framework,21 let the cumulative density of
the poverty index score s be given by F(s). Let the exogenous poverty index score
threshold for program eligibility be denoted ​s​0​, and 0 < F(​s​0​) < 1 so that some
people fall above and below the poverty index score threshold. Voters support the
incumbent, I, if the expected utility they get from him winning exceeds the expected
utility they would get from the challenger C:
(2)	​G​  C​ < ​G​  I​ + ​nI​​​b​​si​​ ​핀[​si​​ ≤ ​s0​​] + p​b​​si​​ ​핀[​si​​ > ​s0​​] + ​δi​​ + θ.
G represents a vector of public goods proposed by each candidate, assume it is
exogenous. ​n​I​is the number of surveys conducted before the election divided by the
total number of surveys conducted. b​ ​​si​​​ represents the benefit to the voter of being
surveyed. ​n​I​​b​s​i​​​  핀[​si​​ ≤ ​s0​​] represents the expected benefit to the voter if the incumbent
conducts a relatively large number of surveys before the election. From the voter’s
perspective, this term is only beneficial if his score is below the official threshold ​s​0​.
p is the proportion of people with scores above s​ ​0​threshold for whom the politician
chooses to lower the score to some score below s​ 0​​. We will call this “cheating.” b​ ​​si​​​
is the benefit to the individual from having his score lowered. Thus, p​b​s​i​​​  핀[​si​​ > ​s0​​]
represents the expected benefits to a voter with a score above the threshold of getting
a score below ​s0​​  . ​δ​i​and θ correspond to an individual specific measure of the voter’s
political bias toward the candidate and an aggregate shock to the population’s preferences respectively. Both are uniformly distributed and inversely related to ϕ and
ψ, which respectively indicate the relative dispersion of the individual and population’s preferences for the candidate.
The incumbent wants to maximize the probability of winning the next election.
Unlike the incumbent, the challenger cannot conduct surveys or cheat before the
election.22
See Assar Lindbeck and Jörgen W. Weibull (1987); and Torsten Persson and Guido Tabellini (2000).
Studies that have looked at whether it is possible to buy votes in a secret ballot system include Susan C. Stokes
(2005) who explains how clientelistic parties are able to circumvent the secret ballot through “deep insertion into
21
22

Vol. 3 No. 2

Camacho and Conover: Manipulation of Social Program Eligibility

55

Assuming increasing costs in the number of surveys conducted and in the amount
of cheating, c( p, ​nI​​  ) = (η/2)(​nI​​​  )2​​ + ​(c/2)​​p2​​, we can solve the incumbent’s problem for the fraction of people for whom the politician lowers the score p, and for the
fraction of surveys conducted before the election n​ I​​respectively:
(3)

ψϕ​b​s​i​​[​ 1 − F(​s0​​)]
__
p = ​ 
  
c ​

ψϕ​b​​si​​ ​F(​s0​​)
(4)	​n​I​ = ​ _
.
η ​
Some of the results we obtain from this set-up include: a direct relationship between
the level of political competition ψ, and the amount of cheating, ∂p/∂ψ > 0; an
inverse relationship between the costs and the amount of cheating, ∂p/∂c < 0; and
between the costs and the amount of surveys conducted ∂​n​I​/∂c < 0. In municipalities with a higher proportion of poor people we should see less cheating,
∂p/∂F(​s0​)​ < 0. These results will be tested in the empirical section and in the
online Appendix A.
These findings explain that the patterns observed in Figures 1 and 2 are consistent with a relative costs and benefit tradeoff between conducting surveys before an
election or cheating. People value surveys because to determine eligibility for many
social programs they first need to be surveyed. When the program started, there was
confusion among the population as to whether being surveyed was a sufficient condition for eligibility. This enabled politicians to use surveys as a way to influence
the electoral outcomes. At this point, the optimal strategy for the incumbent was to
almost exclusively conduct surveys since the costs of surveying relative to cheating
were low because the score algorithm was still secret. Although timing the surveys
around election periods is not in itself corrupt, it does correspond to strategic behavior. The release of the exact poverty index score formula greatly reduced the costs
of cheating after 1998. Over time people were also becoming increasingly aware
that in addition to being surveyed they needed a score below the threshold, ​s0​​. These
factors contributed to a change in the optimal strategy for the incumbent, which
became cheating after 1998.23

voters’ social networks” and repeated interactions between the parties and voters. In Colombia, a way in which the
contract can be enforced is by exploiting the timing of enrollment into social programs. Households first need to get
surveyed, then get an id card, and finally enroll. Another way is a system know as the “carousel” (see El Tiempo,
“How to Buy a Vote in Colombia,” June 20, 1998, http://www.eltiempo.com/archivo/documento/MAM-790679#).
Electoral officials at a voting table sign each ballot when the voter first comes to the table, or else the ballot is considered invalid. To get the carousel going, a voter needs to insert an unsigned ballot in the box and keep the signed
ballot. The vote-buyer-coordinator marks the signed ballot with his preferred candidate and asks the next voter to
deposit the ballot and return an unmarked signed ballot.
23
Mayors in Colombia cannot be re-elected for consecutive terms. However, mayoral electoral manipulation
was widely documented in the press during the period we study. In addition, Drazen and Eslava (2010, 46) explain
that even if incumbent mayors cannot be re-elected immediately he has incentives to manipulate because “his decisions affect his party’s re-election chances (or those of the incumbent’s preferred candidate),” and in the future he
may run for re-election to the same (or a different) office.

56

American Economic Journal: economic policy

May 2011

B. Empirical Results
Having provided a framework for the patterns documented in Figures 1 and 2, in
this section we test whether the extent of cheating in the data responds to incumbents’ costs and benefits. We exploit variation both within and across municipalities.
A challenge encountered by scholars studying corruption is how to measure it. We
develop a measure of manipulation at the municipal level which uses the size of the
discontinuity at the threshold.
The administration of the Census of the Poor is controlled by the executive branch
of local government, thus we use election data for mayors. We regress the discontinuity at the threshold for each municipality on competitiveness of the election. The
regression equation has the following form:
(5) discontinuit​yj​t​ = α + ​β1​​  political_competitio​nj​t−1​ + β​Xj​t​ + ​ηt​​ + ​γ​j​ + ​ϵ​jt​,
where the dependent variable discontinuity serves as a proxy for the amount of
cheating in a municipality j at time t. We construct this variable using data from
municipalities that conducted interviews 6 months before the election (May–
October) because in Colombia political campaigns can only be conducted during
the 6 months prior to the elections. This variable is defined as the difference in the
fraction of interviews 3 and 5 points below the threshold relative to the same number
of points above the threshold of 47, divided by the number of points (3 or 5).24 To
account for the fact that a continuous non-manipulated distribution would also yield
a non-zero discontinuity, we subtract the discontinuity of the distribution observed
in each municipality for the period without manipulation from 1994 to 1997. If
there were no surveys conducted in this range in a municipality in a given year then
the variable discontinuity has a missing value. discontinuity could go from −1 to 1,
but most of the values are positive. The closer this variable is to 0 the smaller the
discontinuity at the threshold.
We define political competition as specified in equation (1). This variable could
go from 0 to 1. The closer the value is to 1 the more competitive the election. Since
we only have information for all candidates starting in 1997, we estimate the results
for election years 1997, 2000, and 2003. Our regression results report standardized coefficients for all variables. Following the literature, we used lagged political
competition as a proxy for anticipated political competition because using the value
from the same year is likely to be endogenous since it is a function of anticipated
and manipulated political competition.25
The variable X includes population and the ratio of urban to total population
in each municipality for each year. η is a year effect, and γ the municipality fixed

24

We use 3 and 5 points from the threshold because we want values sufficiently closed to the threshold where
there is data for many municipalities.
25
In addition, there is a statistically significant and positive correlation (0.04) between contemporaneous and
lagged political competition.

Vol. 3 No. 2

Camacho and Conover: Manipulation of Social Program Eligibility

57

Table 6—Discontinuity at the Threshold and Political Competition

Dependent variable:
Political competition
Log population

Discontinuity +/− 3 points

(1)

0.174**
[0.074]

Ratio of urban to total
population
Year effects
Municipality effects
Observations
R2

Yes
Yes
112
0.18

(2)

0.176**
[0.080]
11.181***
[3.445]

Yes
Yes
112
0.29

(3)

Discontinuity +/− 5 points

(4)

(5)

(6)

0.177**
[0.080]
10.283***
[3.667]
−4.305
[8.149]

0.112*
[0.056]

0.113*
[0.062]
5.577**
[2.345]

0.114*
[0.062]
5.136*
[2.688]
−2.113
[5.268]

Yes
Yes
112
0.30

Yes
Yes
112
0.14

Yes
Yes
112
0.21

Yes
Yes
112
0.21

Notes: Robust standard errors in brackets. All regressions include an intercept term, and report standardized coefficients. The dependent variable is the difference in the fraction of interviews 3 and 5 points before the threshold relative to the same points after the threshold divided by the number of points, using data for the 6 months prior to the
election and accounting for the fact that a continuous non-manipulated distribution would also yield a non-zero discontinuity as described in Section IIIB. The closer to 0 the smaller the discontinuity at the threshold. Political competition is defined as one plus the negative of the difference in the fraction of votes the winner received relative to
the runner-up in the previous election (see equation (1)), thus scores closer to 1 denote more competitive elections.
*** Significant at the 1 percent level.
** Significant at the 5 percent level.
  * Significant at the 10 percent level.

effects. A positive coefficient on political competition indicates that more competitive elections are associated with more cheating by incumbents.
Results are displayed in Table 6. Consistent with the model the table shows that
when the benefits of an additional vote are higher, the discontinuity at the threshold
is larger. Columns 1 and 4 do not include additional controls to the municipality and
year effects, all other columns include population controls. Columns 1–3 of Table 6
use the fraction of surveys 3 points below and above the threshold, while columns
4–6 use the fraction of surveys 5 points below and above the threshold. A standard
deviation increase in the amount of political competition (s.d. = 0.168) increases
the percent of interviews three points below the threshold relative to three points
above the threshold by 0.17 of a standard deviation, and it increases the percent of
interviews five points below the threshold relative to three points above the threshold by 0.11 of a standard deviation. The magnitude of the effects remain constant
after including population controls.
If politicians are using the Census of the Poor to influence the election outcomes,
then we expect manipulation to be more prevalent just before the elections. As a
falsification exercise we explore whether the competitiveness of the election influences the size of the discontinuity on non-electoral periods. We construct the variable discontinuit​yj​t​ using data for: months 12–6 prior to the election (November of
the previous year to April of the election year), and using the same 6 months of the
year (May–October) but 1 year before the election. Results are reported in Table 7.
We find that, unlike the results reported in Table 6 which use data for 6 months prior
to the election, the political competition does not influence the size of the discontinuity at the threshold.

58

American Economic Journal: economic policy

May 2011

Table 7—Robustness: Discontinuity at the Threshold using Information months 12–6 prior to the
election and 1 Year Prior to Mayoral Election
Discontinuity +/− 3 points
Dependent variable:
Political competition, discontinuity
in months 12–6 prior to election
Observations
R2
Political competition, discontinuity
in 1 yr prior to election
Observations
R2
Year effects
Municipality effects
Log population
Ratio of urban to rural

(1)

(2)

(3)

Discontinuity +/− 5 points
(4)

(5)

(6)

−0.009
[0.031]
328
0.12
0.028
[0.040]
384
0.00

−0.009
[0.032]
328
0.13
0.028
[0.040]
384
0.00

−0.010
[0.032]
328
0.13
0.028
[0.040]
384
0.00

0.030
[0.036]
328
0.08
0.045
[0.041]
384
0.02

0.030
[0.036]
328
0.09
0.044
[0.040]
384
0.03

0.029
[0.036]
328
0.09
0.043
[0.040]
384
0.03

Yes
Yes

Yes
Yes
Yes

Yes
Yes
Yes
Yes

Yes
Yes

Yes
Yes
Yes

Yes
Yes
Yes
Yes

Notes: Robust standard errors in brackets. All regressions include an intercept term and report standardized coefficients. The dependent variable is the difference in the fraction of interviews 3 and 5 points before the threshold
relative to the same points after the threshold divided by the number of points and accounting for the fact that a continuous non-manipulated distribution would also yield a non-zero discontinuity as described in Section IIIB, using
data for (1) months 12–6 prior to the election (November of the previous year to April of the election year), and (2)
using the same six months of the year (May–October) but one year before the election. The closer to 0 the smaller
the discontinuity at the threshold. Political competition is defined as one plus the negative of the difference in the
fraction of votes the winner received relative to the runner-up in the previous election (see equation 1), thus scores
closer to 1 denote more competitive elections. Each cell and row represents results from a different regression.

In online Appendix A we exploit variation across municipalities. We use number
of community organizations and number of the main newspaper in circulation as
measures for the costs of manipulation in a given municipality. We estimate cross
section regressions because the available data that proxies for the cost of cheating
do not vary over time. We find that consistent with the model’s predictions, better
monitoring is associated with a lower fraction of surveys in the 6 months before the
election and less cheating in municipalities around election times.
IV. Alternative Explanations for Pattern in Score Distribution

We first rule out that the score algorithm is mechanically generating a higher
number of combinations for scores below the eligibility threshold by calculating the
number of possible combinations to generate each score. We plotted this simulated
distribution, available in online Appendix B Figure B1, and found that it does not
exhibit a discontinuity at the eligibility threshold or anywhere else.
Another explanation for what could be generating the pattern in the score distribution over time could be changes in general macroeconomic or labor market conditions. In fact, in 1999 Colombia experienced a recession. During that year, according
to figures from DANE, real GDP fell by 4.2 percent. The recession is likely to have
increased the proportion of poor in the population, and thus could have affected the
shape in the aggregate score distribution. To address this concern, we took data from
the Socio-Economic Characterization and Quality of Life Surveys for 1993, 1997,

Vol. 3 No. 2

Camacho and Conover: Manipulation of Social Program Eligibility

59

and 2003. If the unusual patterns in the poverty index score data are genuine, not due
to manipulation, we would expect to see them in an alternative dataset. Using these
surveys and the score algorithm, we constructed the poverty index score to see how the
distribution behaves over time.26
Even though we do not have Quality of Life Survey data for 1999, the year of the
recession, we expect that if the effects of the recession went beyond 1999 then the
2003 survey data distribution should also exhibit a discontinuity at the threshold,
such as the one observed in the Census of the Poor. The first graph in Figure 6 shows
that the 1993 Socio-Economic Characterization Survey distribution and the Census
of the Poor distribution for 1994 are centered around a similar point. The second and
third graphs in Figure 6 show the poverty index score distribution and the Quality
of Life Surveys for 1997 and 2003 respectively. In 1997, the Census of the Poor
distribution is centered to the left of the Quality of Life Survey distribution, but we
do not observe a discontinuity at the eligibility threshold. In 2003 however the two
distributions differ greatly. The mode of the distribution of the Census of the Poor
is to the left and there is a discontinuity at the eligibility threshold, which does not
appear in the Quality of Life Survey data distribution.
To summarize, from Figure 6 we can see that if a random sample of interviews
was drawn each year, then the distribution would not exhibit a discontinuity at the
eligibility threshold and, consistent with the overall growth in the Colombian economy during this 10 year period, the distribution would be moving to the right over
time. However, instead what we see is that the mode of the Census of the Poor distribution moves left over time, and that after 1997 the distribution shows a discontinuity at the eligibility threshold.
One objection to Figure 6 is that the Socio-Economic Characterization and
Quality of Life Survey data that we use is a representative sample of the population
at a given point in time. Comparisons with these data assume that a random sample
of neighborhoods was interviewed in a given year across and within municipalities. However, municipalities had discretion on the timing of the surveys, and not
all municipalities interviewed all people in strata level below four at once. Thus, it
could be possible that the pattern we see at the aggregate level is driven by selection.
Specifically, richer municipalities could have conducted interviews first, and within
a municipality richer neighborhoods could have been surveyed first. One explanation for the pattern in the score distribution could be that over time municipalities became better at identifying the poor neighborhoods, or that the municipalities
which conducted the interviews later were poorer and thus had a higher concentration to the left of the threshold.
To rule out the possibility that richer municipalities were conducting surveys earlier and poorer municipalities later, we check for the possibility that municipalities
conducting surveys are poorer over time. We do this by using a measure of poverty
at the municipal level called the Unsatisfied Basic Needs Index (NBI in Spanish).
This index is provided by DANE and takes a value between 0 and 100. The higher
26
Most of the questions necessary to construct the score algorithm are available in the Socio-Economic
Characterization and Quality of Life Surveys with a few exceptions like the income question, where the SocioEconomic Characterization Survey provides more detailed and extensive questions on income sources.

60

American Economic Journal: economic policy

May 2011

1993−1994
6
SEC survey 1993
Census of the Poor 1994

Percent

4

2

0
0

7

14

21

28

35

42

49

56

63

70

77

84

91

98

Poverty index score

1997
4

Quality of Life Survey 1997
Census of the Poor 1997

Percent

3

2

1

0
0

7

14

21

28

35

42

49

56

63

70

77

84

91

98

Poverty index score

2003
6
Quality of Life Survey 2003
Census of the Poor 2003

Percent

4

2

0
0

7

14

21

28

35

42

49

56

63

70

77

84

91

98

Poverty index score
Figure 6. Poverty Index and 1993 Socio-Economic Characterization (SEC) and 1997 and 2003 Quality of
Life Surveys Score Distributions
Notes: The Census of the Poor, the Socio-Economic Characterization, and Quality of Life Surveys use only urban
households living in strata levels below four. The vertical line indicates the eligibility threshold of 47 for many
social programs.

Camacho and Conover: Manipulation of Social Program Eligibility

Vol. 3 No. 2

61

Unsatisfied Basic Needs Index

50

40

30

20

10
1994

1995

1996

1997

1998

1999

2000

2001

2002

2003

2004

Month−year
Figure 7. Weighted Unsatisfied Basic Needs Index Over Time
Notes: Each dot depicts a monthly weighted value for the Unsatisfied Basic Needs Index. The index captures the
proportion of poor in a municipality, and it takes the values between 0 (richer) and 100 (poorer). The fitted line has
a negative and insignificant coefficient.

the value, the larger the fraction of poor in the municipality. We estimate a weighted
average of this index, by taking the proportion of surveys conducted in each municipality in a given month, and multiplying this value by the Unsatisfied Basic Needs
Index for that municipality and year. The results are presented in Figure 7. The
figure shows a declining proportion of poor over time, this relationship however
is not significant, indicating that the composition of the proportion of poor in the
municipalities conducting surveys did not increase over time.
Since implementation was done at the municipal level, and to the extent possible, our analysis is at this level, one way to check for selection is by comparing
the number of surveys conducted by stratum level over time within a municipality.27
We should be concerned about selection if, for instance, we see that within a municipality strata level 1 (poorer) interviews are increasing over time while in strata
level three (richer) interviews are decreasing. The equation that we use to calculate
the number of interviews within a municipality over time is:
(6)

surveys_stratum​xj​t​ = α + ​ηt​​ + ​γ​j​ + ​ϵ​jt​,

where surveys_stratumx corresponds to the number of surveys conducted in stratum
level x in municipality j at time t. In Figure 8, we plot the coefficients for η which
correspond to each year month combination from January 1994 to September 2003,
using January 1994 as the reference month. The figure shows that, excluding the
27
We did this because the central government instructed municipal officials to use strata levels in the surveying
process.

62

American Economic Journal: economic policy

May 2011

Relative number of surveys

10,000
0 (unofficial)
1 (poorer)
2
3 (richer)

5,000

0

−5,000
1994

1995

1996

1997

1998

1999

2000

2001

2002

2003

Year

Figure 8. Number of Census of the Poor Interviews by Strata Level, Controlling for Municipality
Notes: Vertical lines indicate regional mayoral elections. Results from coefficients of a regression of number of surveys in each strata per year month, on an indicator for each year month, controlling for municipality. Base month:
January 1994. See equation (6) in Section IV for details.

peaks in 1995 and 1997 which correspond to electoral periods previously discussed,
for strata one to three the number of interviews remains relatively constant over
time, and they have a slight upward trend after 2000 for strata 0.28
Overall the results presented in this section and in the online Appendix B indicate
that the score algorithm, changes in economic conditions or selection do not explain
why after 1998 we see a discontinuity exactly at the eligibility threshold. Although
alternative explanations not explored in this section due to space or data constraints
could be proposed for the pattern observed in the Poverty Index Score distribution, in order for these explanations to be relevant, they would need to address not
only the leftward shift in the distribution, but also the timing of the emergence of
the d­ iscontinuity after the release of the score algorithm, and the sharp drop in the
­density of the distribution exactly at the eligibility threshold.29
V. Summary and Discussion

In this paper, we documented patterns in the data that indicate strategic behavior and manipulation during the implementation of the first Census of the Poor
in Colombia. Not ruling out the possibility of individual manipulation, we identify mass manipulation following the data entry stages after the score algorithm
was made available to local officials. We motivate our empirical findings with a
28
See online Appendix B for additional information on alternative possible explanations for the patterns
observed in the score distribution.
29
Alternative explanations such as individuals misrepresenting themselves to reduce their score, enumerators
“helping” out, or changes in the minimum wage might explain a leftward shift in the score distribution, but do not
explain the timing of the emergence of the discontinuity at the threshold in 1998, and the discontinuity emerging
exactly at the threshold.

Vol. 3 No. 2

Camacho and Conover: Manipulation of Social Program Eligibility

63

theoretical framework that indicate how manipulation by politicians may have
occurred. We tested the predictions of this framework with electoral data and found
that the amount of manipulation in some municipalities is positively associated with
political competition.
By using administrative data we are able to identify manipulation of a large scale
targeting system that determines eligibility for social programs. In a “back of the
envelope” calculation we estimate that approximately three million people had their
scores changed, this corresponds to roughly 33 percent of what the Socio-Economic
Characterization Survey data indicates should be the actual number of beneficiaries.
Considering that during the period studied the total population of Colombia was
approximately 40 million, the misallocation of three million of the poorest segment
of the population is noteworthy. We link this manipulation to the political process
and show that it can take time for corruption to emerge. The sudden emergence of
the discontinuity argues against the idea that corrupt behavior is due solely to social
norms and culture, and that it is inherent in the system or the population. Instead it
supports the view that corruption can be enabled by a change in information, and
become more pronounced possibly due to political incentives.
Most of the paper has focused on documenting and explaining motivations for
manipulation, yet the findings presented here raise two important questions: First, was
the manipulation observed necessarily bad from a social welfare perspective? Factors
that should be considered when answering this include: if the proxy-means testing
instrument is properly identifying the population most in need, then the resources
used by people who had their scores lowered could have instead been used to provide
additional social programs for people truly below the poverty eligibility threshold. The
possibility of clientelism, in which resources are directed to those with political connections rather than real need, often involves socially wasteful rent-seeking.30
Second, is the design of the proxy-means testing instrument properly identifying
the population most in need? If the people who had their scores lowered were truly in
need, then this type of manipulation could be welfare enhancing, in which case, the
need for a mechanism that does not use a discontinuous rule to identify the poor arises.
For instance: a system that uses an observable and hard to manipulate characteristic
might not as carefully identify individuals, but would be less costly to administer and
present less opportunity for cheating; or redesigning the Poverty Index Score to reduce
the possibility of excluding some people who are truly in need.
Whether or not the manipulation documented here reduced welfare, the findings
in this paper highlight the importance of adopting changes to improve the system.
The Colombian government has already made important changes that help reduce
manipulation in the implementation of the second Census of the Poor which started
in 2003. The second census has a different questionnaire and a new score algorithm which has been kept secret. The government has also set guidelines that
limit conducting interviews or assigning social benefits in pre-electoral periods in

30
See Robinson (2005) for information on the historical presence of clientelistic relationships in Colombia.
Daron Acemoglu, Robinson, and Rafael J. Santos (2009) discuss elections, violence, and government policies in
Colombia.

64

American Economic Journal: economic policy

May 2011

certain municipalities.31 Further efforts and controls like increasing the penalties for
cheating, improving detection of cheaters, updating the information or introducing
changes to the system, and more forcefully restricting to non-electoral periods the
selection of the people eligible for the program should be considered as ways in
which future duplicity can be limited.
References
Acemoglu, Daron, James A. Robinson, and Rafael J. Santos. 2009. “The Monopoly of Violence: Evi-

dence from Colombia.” MIT Department of Economics Working Paper 09-30.

Bardhan, Pranab. 1997. “Corruption and Development: A Review of Issues.” Journal of Economic

Literature, 35(3): 1320–46.

Barr, Abigail, and Danila Serra. 2010. “Corruption and Culture: An Experimental Analysis.” Journal

of Public Economics, 94(11–12): 862–69.

Blundell, Richard, and Hilary W. Hoynes. 2004. “Has ‘In-Work’ Benefit Reform Helped the Labor

Market?” In Seeking a Premier Economy: The Economic Effects of British Economic Reforms,
1980–2000, ed. David Card, Richard Blundell, and Richard B. Freeman, 411–60. Chicago: University of Chicago Press.
Castañeda, Tarsicio. 2005. “Targeting Social Spending to the Poor with Proxy-Means Testing: Colombia’s SISBEN System.” World Bank Human Development Network Social Protection Unit Discussion Paper 0529.
Drazen, Allan, and Marcela Eslava. 2010. “Electoral Manipulation via Voter-Friendly Spending: Theory and Evidence.” Journal of Development Economics, 92(1): 39–52.
Fan, J., and I. Gijbels. 1996. Local Polynomial Modelling and Its Applications. London, UK: Chapman and Hall.
Ferraz, Claudio. 2007. “Electoral Politics and Bureaucratic Discretion: Evidence from Environmental
Licenses and Local Elections in Brazil.” Unpublished.
Fisman, Raymond, and Edward Miguel. 2007. “Corruption, Norms, and Legal Enforcement: Evidence
from Diplomatic Parking Tickets.” Journal of Political Economy, 115(6): 1020–48.
Friedberg, Leora. 2000. “The Labor Supply Effects of the Social Security Earnings Test.” Review of
Economics and Statistics, 82(1): 48–63.
Jacob, Brian A., and Steven D. Levitt. 2003. “Rotten Apples: An Investigation of the Prevalence and
Predictors of Teacher Cheating.” Quarterly Journal of Economics, 118(3): 843–77.
Khemani, Stuti. 2004. “Political Cycles in a Developing Economy: Effect of Elections in the Indian
States.” Journal of Development Economics, 73(1): 125–54.
Lambsdorff, Johann Graf. 2006. “Causes and Consequences of Corruption: What Do We Know from
a Cross-Section of Countries?” In International Handbook on the Economics of Corruption, ed.
Susan Rose-Ackerman, 3–51. Cheltenham, UK: Edward Elgar.
Lindbeck, Assar, and Jörgen W. Weibull. 1987. “Balanced-Budget Redistribution as the Outcome of
Political Competition.” Public Choice, 52(3): 273–97.
Mauro, Paolo. 1995. “Corruption and Growth.” Quarterly Journal of Economics, 110(3): 681–712.
Mauro, Paolo. 2004. “The Persistence of Corruption and Slow Economic Growth.” IMF Staff Papers,
51(1): 1–18.
McCrary, Justin. 2008. “Manipulation of the Running Variable in the Regression Discontinuity
Design: A Density Test.” Journal of Econometrics, 142(2): 698–714.
Minnesota Population Center. 2007. Integrated Public Use Microdata Series, International: Version
3.0. Machine-Readable Database. Minneapolis, MN: University of Minnesota.
Misión Social, Departmento Nacional de Planeación Ministerio de Salud, and Programa Naciones
Unidas para el Desarrollo (UNDP). 2003. ¿Quién se beneficia del SISBEN? Evaluación Integral.

Bogotá, Colombia: Departmento Nacional de Planeación.

Olken, Benjamin A. 2006. “Corruption and the Costs of Redistribution: Micro Evidence from Indone-

sia.” Journal of Public Economics, 90(4–5): 853–70.

Persson, Torsten, and Guido Tabellini. 2000. Political Economics: Explaining Economic Policy. Cam-

bridge, MA: MIT Press.

31

As reported in El Tiempo, September 2, 2003.

Vol. 3 No. 2

Camacho and Conover: Manipulation of Social Program Eligibility

65

Reinikka, Ritva, and Jakob Svensson. 2004. “Local Capture: Evidence from a Central Government

Transfer Program in Uganda.” Quarterly Journal of Economics, 119(2): 679–705.

Robinson, James A. 2005. “A Normal Latin American Country? A Perspective on Colombian Develop-

ment.” http://scholar.harvard.edu/jrobinson/files/jr_normalcountry.pdf.

Robinson, James A., and Thierry Verdier. 2002. “The Political Economy of Clientelism.” Centre for

Economic Policy Research (CEPR) Discussion Paper 3205.

Saez, Emmanuel. 2010. “Do Taxpayers Bunch at Kink Points?” American Economic Journal: Eco-

nomic Policy, 2(3): 180–212.

Schaffer, Frederic Charles. 2007. Elections for Sale: The Causes and Consequences of Vote Buying.

Boulder, CO: Lynne Rienner Publishers.

Stokes, Susan C. 2005. “Perverse Accountability: A Formal Model of Machine Politics with Evidence

from Argentina.” American Political Science Review, 99(3): 315–25.

Vélez, Carlos E., Elkin Castaño, and Ruthanne Deutsch. 1999. “An Economic Interpretation of Target-

ing Systems for Social Programs: The Case of Colombia’s SISBEN.” http://www.acoes.org.co/pdf/
Documentos%20HFTF/29.pdf.
Wolfers, Justin. 2006. “Point Shaving: Corruption in NCAA Basketball.” American Economic Review,
96(2): 279–83.

This article has been cited by:
1. Paul Niehaus,, Antonia Atanassova,, Marianne Bertrand,, Sendhil Mullainathan. 2013. Targeting
with Agents. American Economic Journal: Economic Policy 5:1, 206-238. [Abstract] [View PDF
article] [PDF with links]
2. Eric V. Edmonds,, Norbert Schady. 2012. Poverty Alleviation and Child Labor. American
Economic Journal: Economic Policy 4:4, 100-124. [Abstract] [View PDF article] [PDF with links]
3. Vivi Alatas,, Abhijit Banerjee,, Rema Hanna,, Benjamin A. Olken,, Julia Tobias. 2012. Targeting
the Poor: Evidence from a Field Experiment in Indonesia. American Economic Review 102:4,
1206-1240. [Abstract] [View PDF article] [PDF with links]

