Large Sample Properties of Generalized Method of Moments Estimators
Author(s): Lars Peter Hansen
Source: Econometrica, Vol. 50, No. 4 (Jul., 1982), pp. 1029-1054
Published by: The Econometric Society
Stable URL: https://www.jstor.org/stable/1912775
Accessed: 06-03-2019 15:51 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

The Econometric Society is collaborating with JSTOR to digitize, preserve and extend access
to Econometrica

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

Econometrica, Vol. 50, No. 4 (July, 1982)

LARGE SAMPLE PROPERTIES OF GENERALIZED METHOD OF
MOMENTS ESTIMATORS1
BY LARS PETER HANSEN
This paper studies estimators that make sample analogues of population orthogonality
conditions close to zero. Strong consistency and asymptotic normality of such estimators is
established under the assumption that the observable variables are stationary and ergodic.
Since many linear and nonlinear econometric estimators reside within the class of estimators studied in this paper, a convenient summary of the large sample properties of these
estimators, including some whose large sample properties have not heretofore been
discussed, is provided.

1. INTRODUCTION

IN THIS PAPER we study the large sample properties of a class of generalized
method of moments (GMM) estimators which subsumes many standard econometric estimators. To motivate this class, consider an econometric model whose
parameter vector we wish to estimate. The model implies a family of orthogonal-

ity conditions that embed any economic theoretical restrictions that we wish to
impose or test. For example, assumptions that certain equations define projec-

tions or that particular variables are predetermined give rise to orthogonality
conditions in which expected cross products of unobservable disturbances and
functions of observable variables are equated to zero. Heuristically, identification

requires at least as many orthogonality conditions as there are coordinates in the
parameter vector to be estimated. The unobservable disturbances in the orthogonality conditions can be replaced by an equivalent expression involving the true
parameter vector and the observed variables. Using the method of moments,
sample estimates of the expected cross products can be computed for any
element in an admissible parameter space. A GMM estimator of the true

parameter vector is obtained by finding the element of the parameter space that
sets linear combinations of the sample cross products as close to zero as possible.
In studying strong consistency of GMM estimators, we show how to construct
a class of criterion functions with minimizers that converge almost surely to the

true parameter vector. The resulting estimators have the interpretation of making
the sample versions of the population orthogonality conditions as close as

possible to zero according to some metric or measure of distance. We use the
metric to index the alternative estimators. This class of estimators includes the
nonlinear instrumental variables estimators considered by, among others,

Amemiya [1, 2], Jorgenson and Laffont [24], and Gallant [11].2 There the
'The author acknowledges helpful comments by Robert Avery, Robert Hodrick, V. Joseph Hotz,
Dan Peled, Thomas Sargent, Katherine Schipper, Kenneth Singleton, Kenneth Wallis, Halbert White,
and an anonymous referee. Special thanks are given to Christopher Sims who played a prominent

role in the formulation of this paper.
2We include versions of two- and three-stage least squares under the heading of instrumental
variables procedures.
1029

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1030

LARS

PETER

HANSEN

population orthogonality conditions equate expected cross products of instruments and serially independent disturbances to zero. In our treatment we work

directly with expressions for the population orthogonality conditions and implicitly permit the disturbance terms used in construction of the orthogonality
conditions to be both serially correlated and conditionally heteroskedastic.3 We
allow ourselves flexibility in choosing the distance measure because it permits
choosing measures that are computationally convenient and because the choice

of distance measure influences the asymptotic distribution of the resulting estimator.

In studying asymptotic normality, we view estimation in a different but closely
related fashion. We follow Sargan [29, 30] and consider estimators that have the
interpretation of setting linear combinations of the sample orthogonality conditions to zero, at least asymptotically, where the number of linear combinations

that are set to zero is equal to the number of coordinates in the parameter vector

to be estimated. We index alternative estimators by an associated weighting
matrix that selects the particular linear combinations of orthogonality conditions
that are used in estimation. Since alternative weighting matrices give rise to
estimators with alternative asymptotic covariance matrices, we describe how to
obtain an asymptotically optimal weighting matrix. The estimators considered in
our treatment of consistency are shown to reside in the class of estimators

considered in our treatment of asymptotic normality by examining the first-order
conditions of minimization problems used to construct the class of consistent

estimators. It turns out, however, that our discussion of asymptotic normality is
sufficiently general to include other consistent estimators that are obtained from
minimizing or maximizing other criterion functions which have first-order condi-

tions that satisfy the specification of our generic GMM estimator, e.g., least
squares or quasi-maximum likelihood estimators. Again our discussion of large
sample properties permits the disturbances implicitly used in the orthogonality
conditions to be both conditionally heteroskedastic and serially correlated.4
There are a variety of applications in which it is important to possess an

asymptotic theory which accommodates these features. In testing market efficiency and the rationality of observed forecasts using least squares procedures,
one oftentimes encounters situations in which the implied forecast interval

3Sargan [30] treats the case in which disturbances can follow a low-order autoregression and can
be filtered to remove serial correlation prior to the construction of the orthogonality conditions.

White [34] discusses linear instrumental variables estimation in which observation vectors are
independent but not necessarily identically distributed. White allows heteroskedasticity to exist both
conditionally and unconditionally, but places restrictions on higher moments of observable and
unobservable variables that are not needed in this paper. Here we think of heteroskedasticity
emerging because of some implicit conditioning, do not impose independence, but maintain a
stationarity assumption.

4Engle [9] allows for conditional heteroskedasticity in regression models with serially uncorrelated
disturbances. He proposes a maximum likelihood procedure for estimating such models when the
form of the heteroskedasticity is specified a priori. White [32, 33, 34] has studied the asymptotic
distribution of a variety of estimators for cross-sectional models which allow for both conditional and
unconditional forms of heteroskedasticity. See Footnote 3.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1031

exceeds the sampling interval giving rise to a serially correlated forecast error
[4, 14, 17]. Least squares procedures can be used since the hypothetical forecast
error should be orthogonal to the observed forecast and to any other variables in

the information set of economic agents when the forecast is made. On the other
hand, generalized least squares procedures can result in inconsistent parameter
estimators (see Sims [31] and Hansen and Hodrick [17]). Brown and Maital [4],
Hansen and Hodrick [17], and Hakkio [14] rely on the asymptotic distribution

theory in this paper to carry out least squares estimation and inference for such
models.
Hansen and Sargent [18, 19] have considered linear rational expectations
models in which economic agents are assumed to forecast infinite geometricallydeclining sums of forcing variables and the econometrician employs only a
subset of the variables in the information set of economic agents. The disturbance terms in these models are serially correlated but orthogonal to current and

past values of a subset of variables which are not strictly exogenous. Hansen and

Sargent [18, 19] discuss how to apply the techniques developed in this paper to
those rational expectations models. McCallum [28] has shown how other types of
linear rational expectations models with disturbance terms that have low-order
autoregressive representations lead to equations that can be estimated consistently using standard instrumental variables procedures. He notes, however, that

the associated asymptotic distribution of the estimations has to be modified in
the manner suggested in this paper to allow the disturbances to be serially
correlated. In considering models like those studied by McCallum [28], Cumby,
Huizinga, and Obstfeld [5] propose a two-step, two-stage least squares estimator

that resides within the class of estimators examined in this paper.5
Hansen and Singleton [20] have studied how to test restrictions and estimate

parameters in a class of nonlinear rational expectations models. They construct

generalized instrumental variables estimators from nonlinear stochastic Euler
equations and note that the implied disturbance terms in these models are
conditionally heteroskedastic and in many circumstances serially correlated.

Their estimators are special cases of the generic GMM estimator of this paper.
Finally, Avery, Hansen, and Hotz [3] describe how to use methods in this paper

to obtain computationally convenient procedures for estimating multiperiod
probit models. The vector disturbance term implicit in their orthogonality condi-

tions also is conditionally heteroskedastic.

In the examples described above, application of the techniques in this paper
will not result in asymptotically efficient estimators. However, in these and other

examples, a researcher may be willing to sacrifice asymptotic efficiency in

exchange for not having to specify completely the nature of the serial correlation

and/or heteroskedasticity or in exchange for computationally simpler estimation
strategies. As noted above, we do provide a more limited optimality discussion
5Cumby, Huizinga, and Obstfeld [5] proposed their estimator independently of this paper.
However, their discussion of its asymptotic distribution exploited results in a precursor to this paper
written by the author.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1032 LARS PETER HANSEN

that is patterned after an approach taken by Sargan [29, 30] and can be easily
exploited in practice.

The organization of the paper is as follows. The second section provides some
consistency results for the GMM estimator under various assumptions about the
form of the econometric model. The third section discusses the asymptotic
distribution of the GMM estimator and considers the construction of an asymptotically optimal estimator among the class of estimators that exploit the same
orthogonality conditions. The fourth section examines procedures for testing
overidentifying restrictions using GMM estimation. Finally, the fifth section
contains some concluding remarks.

2. CONSISTENCY OF THE GMM ESTIMATOR

In this section we specify our first form of the GMM estimator and provide
some sufficient conditions that insure its almost sure convergence to the parameter vector that is being estimated. Let Q denote the set of sample points in the
underlying probability space used in our estimation problem, and let E denote
the associated expectations operator. We will be working with a p component
stochastic process { x : n > 1 } defined on this probability space. A finite segment

of one realization of this process, i.e., {fx,(@w): 1 < n < N} for sample size N and

for some wo E S2, can be thought of as the observable data series that the

econometrician employs.

ASSUMPTION 2.1: {x,,: 1 < n} is stationary and ergodic.
We introduce a parameter space S that is a subset of Rq (or its compactifica-

tion) and let Po be the element of S that we wish to estimate.
ASSUMPTION 2.2: (S, a) is a separable metric space.

One possibility is to use the standard absolute value norm on R q to define a. It
is well known that since S is a subset of R q the resulting metric space is

separable. We do not restrict ourselves to this metric in order to allow for S to b
a subset of a compactification of R q.

We consider a function f: RP x S -- R r where R is the real line and r is greater
than or equal to q.

ASSUMPTION 2.3: f(., fi) is Borel measurable for each /8 in S and f(x, ) is
continuous on S for each x in RP.

The function f provides an expression for the r orthogonality conditions that
emerge from the econometric model in the sense indicated by Assumption 2.4.

ASSUMPTION 2.4: Ef(x1, /3) exists and is finite for all /B E S and Ef(xI, /80)
=0.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1033

A common way to obtain orthogonality conditions is to exploit the assumption
that disturbances in an econometric model are orthogonal to functions of a set of
variables that the econometrician observes. For example, suppose that the
econometric model is given by

un= F(Xn,io0)

(1)

n = G(xnq i30)
where

(2) E[un 0 zn]=O.

The vector functions F and G are specified a priori, un is an uno

of disturbance terms, zn is a vector of instrumental variable
the Kronecker product. The dependence of G on its second argument is oftentimes trivial. When (2) is satisfied, we can let the function f be given by

(3) f(xn, go) = F(Xnq /0) 0 G(Xn, o),
and it follows that

E[ f(xn 13o) 0.
We proceed to describe how to use orthogonality conditions to construct an

estimator of the unknown parameter vector go.
For our discussion of consistency, we introduce a sequence of random weight-

ing matrices { aN: N > 1 } that are dimensioned s by r where q < s < r. The
matrices are random in order to allow for their possible dependence on sample
information.

ASSUMPTION 2.5: The sequence of random matrices { aN: N > 1} converges
almost surely to a constant matrix ao.6
These weighting matrices are used in conjunction with a method of moments

estimator of E[fi(xn, ,B)] to obtain a sample objective function whose minimiz
is our estimator of flo. Let
fn (w ) =J[xn (W) f8@]I)
N

gN('9)N E fn (@ : )9
hN (o, /) = aN (i) gN ( A)'

BN(o) = { E S: IhN(o )12 = inf IhN (. f)I2}
6This matrix convergence is defined as element by element convergence using the absolute value
norm on R.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1034 LARS PETER HANSEN

The random function gN(/3) is just the method of moments estimator of
E [f(xn, /3)], IhN 2 is the sample criterion function to be used in estimation, and
BN is the (random) set of elements in the parameter space S that minimize IhN 2.
The weighting matrices { aN : N > 1 } can be thought of as defining the metric by
which the sample orthogonality conditions gN(bN) are made as close as possible
to zero.

To estimate g3o we choose an element out of BN. More precisely, we employ the
following definition.

DEFINITION 2.1: The GMM estimator {bN b N> 1 } is a sequence of random
vectors such that bN (O) E BN (O) for N > N*(co) where N*(co) is less than infinity

for almost all X in 0.7
The nonlinear instrumental variables estimators discussed by Amemiya [1],
Jorgenson and Laffont [24], and Gallant [11] are defined in this manner for
appropriate choices of aN. Their instrumental variables estimators assume that

the function f satisfies (1)-(3) and in addition that the disturbances are serially

independent. They use consistent estimators of E [u U4] and E [zzJ] to construct
an estimator of ao where

aoao= {E[ unun] E[Znzn] }1.8
In preparation for our first consistency theory, we introduce the notation

ho(3) = aoE[f1(W, 13)],

1 (W, /3,8) = sup(tfi(o, /3A)-fl(,a)t a E S,a(,a) < 86.
The following definition is needed for our consistency results.

DEFINITION 2.2: The random function f1 is kth moment continuous at /3 if

lim,50E [ k(C 8 6)] =0.9
Since { Xn: n > 1 } is stationary, it follows that if fi is kth moment continuous,
then fn is kth moment continuous for all n. Notice that kth moment continuity is

joint property of the function f and the stochastic process { Xn: n > 1). An
7In this definition we have imposed the requirement that the sequence of functions { bN: N > 1}
be measurable. Alternatively, we could follow a suggestion of Huber [23] and not necessarily require
that the functions be measurable and establish almost sure convergence in terms of outer probability.
8Amemiya [1], Jorgenson and Laffont [24], and Gallant [11] do not require that the instrumental
variables be stationary and ergodic but instead require that the appropriate moment matrices
converge. Stationarity and ergodicity coupled with finite expectations are sufficient conditions for
these moment matrices to converge almost surely. Amemiya [2] adopts a more general representation
of the orthogonality conditions than (3) to allow different disturbances to be paired with different sets
of instruments.

9The function E((*, k3, 8) is Borel measurable under Assumptions 2.2 and 2.3. In the case in which
k = 1, DeGroot [6] refers to first moment continuity as supercontinuity.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1035

alternative characterization of kth moment continuity is established in Lemma
2.1.

LEMMA 2.1: Under Assumption 2.3, if there exists a 8 > 0 such that E [E
3)] < + oo, then fi is kth moment continuous at /.
Using this lemma, it is apparent that kth moment continuity is implied if the
random function fi is dominated locally by a random variable with a finite kth
moment. DeGroot [6, p. 206] proved Lemma 2.1 for k and q equal to one, and

the extension to larger specifications of k and q is immediate.
One other lemma is of use in verifying first moment continuity in the case
where the function f satisfies relation (3).

LEMMA 2.2: Suppose (i) F1 and G1 are second moment continuous at ,l; (ii)

F1(, /l3) and G1(, /l3) have finite second moments. Then f1 = F1 0 G1 is first
moment continuous at /3.10
Lemma 2.2 may be useful in establishing that fi is first moment continuous at

/3 when the orthogonality conditions are of the form (3).
We now consider our first consistency theorem for the GMM estimator.

THEOREM 2.1: Suppose Assumptions 2.1-2.5 are satisfied. If (i) f1 is first moment

continuous for all ,l Ee S; (ii) S is compact; (iii) ho( ,l) has a unique zero at /0; then
a GMM estimator { bN: N > 1 } exists and converges almost surely to /l30.
Condition (iii) of this theorem is the parameter identification requirement that
the population orthogonality conditions used in estimation be satisfied only at

the true parameter vector. When ao is an r by r nonsingular matrix, ho will ha

unique zero at Po0 if, and only if, Ef(xI, *) has a unique zero at Pog. When a

fewer rows than columns (s < r), condition (iii) imposes the more stringent

requirement that s linear combinations of the population orthogonality condi-

tions are satisfied only at the true parameter vector. For this reason, it may be

judicious to choose ao to be an r by r nonsingular matrix.11
The compactness condition (ii) of Theorem 2.1 can be weakened if a special

structure is imposed on the function f. Consider the following assumption.

ASSUMPTION 2.6: f(xI, /3) = co(x1) + c1(x )X( P) where co(x1) is an r dimensional column vector, c1(x ) is an r by m matrix, and X(,8/) is an m dimensional
vector.

'0At the recommendation of the editor, detailed versions of proofs in this section are not included
in the paper but are available from the author on request.

" I Sargan [29] and Amemiya [2] note that from the standpoint of obtaining desirable small sam
properties, one should try to conserve on the number of orthogonal conditions used in the estimation.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1036

LARS

PETER

HANSEN

This assumption accommodates models that are linear in the variables but not

necessarily in the parameters. Our next theorem establishes consistency for
models with orthogonality conditions that satisfy Assumption 2.6.

THEOREM 2.2: Suppose Assumptions 2.1-2.6 are satisfied. If (i) (S, a) is locally

compact; (ii) X is continuous on S, and for any k > 0 there exists a p > 0 such that

X(a) - X( /)I < p, a(a, /3) < (; (iii) for any p > 0,

inf 1+I( j h (PA)l A E- S, JX(P - )-( go)j > P} > ?;
then the GMM estimator { bN: N > 1} exists and converges almost surely to /go.
In examining Theorem 2.2, let us first consider the case in which X(/) = /3.

Condition (i) is easily verified for (S, a) = (Rq, I 1). The function ho is given

h0(,B) = a0E[c0(x1)] + aoE[c1(x1)] P.

Suppose that ao and Ec,(x,) are both of full rank. Furthermore, we assume
flo is a zero of ho. This is sufficient to imply that for any p > 0

inf{ 1 I ho(13)J :f P Rq,I >p-}pol > 0,
and consequently condition (iii) is met. Thus, for models that are linear in
parameters, Theorem 2.2 requires no additional assumptions on the parameter
space in order to achieve consistency. Of course, this result could be demon-

strated easily by explicitly solving for the estimator. Nonetheless, a consistency
result for linear models in which the underlying stochastic process is stationary

and ergodic is embedded in Theorem 2.2.
The more interesting aspect of Theorem 2.2 is that it provides a consistency
result for models that are nonlinear in the parameters and does not explicitly

employ a compactness requirement. For this reason, we will examine conditions
(ii) and (iii) in more depth. Condition (ii) requires that the mapping defined by
the inverse of X be continuous at the true parameter vector. In interpreting
assumption (iii), it is fruitful to view R m as the unrestricted parameter space. The
function X is used to indicate the elements of that space which satisfy the

restrictions generated by the model. In particular, we let

P = ( 9 E Rm : X(/f) = O for some/3 E S },
i.e., P is the image of X over the set S, and the set S indexes elements of P that
satisfy the restrictions. We define another set Q as

Q = (9 E Rm: a0Ec0(xl) + a0Ecl(x1)9 = 0}.
The hyperplane Q consists of all the elements of Rm that satisfy the population
orthogonality conditions used in estimation. From conditions (ii) and (iii), we are

guaranteed that Q n P = {f 0} where 90 = X(fo)4
We now endeavor to construct sufficient conditions for condition (iii) to hold.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1037

We define a function t by

((p) = inf { - 71 E Q, (=- P, |w -Sol > P, 10-Sot > P}
The following lemma supplies some sufficient conditions for (iii) of Theorem 2.2
to hold.

LEMMA 2.3: Suppose Assumptions 2.4 and 2.5 are satisfied. If (i) for any p > 0,

t(p) > 0; (ii) limP-0inf t(p)/p > 0; then condition (iii) of Theorem 2.2 is satisfie
Condition (i) of Lemma 2.3 says that it is not possible for elements in P to get

arbitrarily close to elements in Q outside of the neighborhood of 00,. Conditi
(ii) of Lemma 2.3 says that the distance between P and Q outside a neighbor-

hood of radius p of 00 eventually grows at least proportionately wit

condition like (ii) is needed because although the set P is specified a priori, the set

Q is not known and ao, E[co(xl)], and E[c,(x,)] have to be estimated. Using
estimators of these matrices, define the random set

QN = E aN N c(x) + aN N C(Xn) = 0}Even very small errors in estimating ao, E [co(x1)], and E [c,(x,)]
terms of the distance between QN and 0 E Q as 0 becomes large in absolute
value. To insure that the GMM estimator is consistent, we have to rule out the

possibility that QN n P contains an element far away from 00 for sufficiently
large sample size N.

If S is compact and P n Q = { 00}, then assumptions (i) and (ii) of Lemm

are trivially met. However, Lemma 2.3 and Theorem 2.2 can be applied in

situations in which S is not compact. In fact, an important special case occurs

when Q = {S0}. This means that the unrestricted parameter vector QO is uniquely
determined by the population orthogonality conditions used in estimation. When

Q = { 0O} assumptions (i) and (ii) of Lemma 2.3 are easily verified.'3
The consistency Theorems 2.1 and 2.2 illustrate the potential tradeoff between
assumptions on the function f and assumptions on the parameter space S in

order to obtain strong consistency of the GMM estimator. Theorem 2.1 most
closely resembles other consistency theorems in the literature for nonlinear
instrumental variables, where the parameter space is assumed to be compact [1,

24]. In contrast to those theorems, Theorem 2.1 does not assume that disturbances are serially independent. Theorem 2.2 relaxes the compactness assumption at the cost of being more restrictive about the specification off.
12 A requirement equivalent to condition (ii) of Lemma 2.3 can be formulated in terms of
asymptotic cones. If we let As(P) and As( Q) denote the asymptotic cones of P and Q, respectively,
then condition (ii) is equivalent to requiring that As(P) n As( Q) = {O}.
13In the example considered in Hansen and Sargent [18, pp. 33-36], Q O {90}. Malinvaud [27, p.
350] has proved a theorem for minimum distance estimators similar to Theorem 2.2 in cases in which

Q = {f 0}. Huber [23] has a general treatment of consistency in cases in which the observation vect

is independent and identically distributed.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1038 LARS PETER HANSEN

Before concluding this discussion on consistency, one additional theorem is
considered. Suppose elements in Rq are partitioned into two subvectors, i.e.,

la' = (3 j', 13). Furthermore, suppose the metric a is

ao(8, y) = max(o1(,y1, I),o2(/32v72)}
where a1 is a metric defined on

S1= (/ 3: (/,/3 5)' E S for some/32}
and 2 is a metric defined on

S2= 2 (12:(I, 13) E S for some l1}.
In some circumstances it may be computationally convenient to construct a

strongly consistent estimator {blN N ?>1 } of f3lo by using a subset of the

orthogonality conditions provided by the model. In particular, Theorems 3.1 or
3.2 could be used to establish this consistency. After obtaining this estimator of
1 0, we can construct an estimator of 1B2,0 by minimizing
|hN[w, bl, N (W)1 82 ]12

with respect to 8B2 such that ( 23j% 13)' E S, where I = blN(w). Theorem 2.3

establishes the consistency of this recursive estimator.

THEOREM 2.3: Suppose Assumptions 2.1-2.5 are satisfied. If (i) the conditions of
Theorem 3.1 are satisfied; (ii) { bl ,N: N > 1 } converges almost surely to 13a o; (iii)
for any sequence { yj:j2 1 } in S such that { y I : j]? 1 } converges to 81 o, there

exists a sequence { 82j:j2 1 } such that {(-Y 1j 382j): ] > 1} is a sequence in S

that converges to 180; then a GMM estimator {bN : N > 1 } exists and converges
almost surely to 10.14

A couple of comments are in order about Theorem 2.3. First, condition (iii)
imposes an extra requirement on the parameter space S. If a1 and 2 are defined
by the absolute value norm, then a sufficient condition for (iii) to hold is that S
be convex. However, condition (iii) can be satisfied in the absence of convexity.

Second, some of the coordinate functions of hN[w,bl N (w), ] may not actually
depend on J12. If this is the case, computation of the criterion function for the
second step of this recursive procedure can be simplifed by ignoring these
coordinate functions.

3. THE ASYMPTOTIC DISTRIBUTION OF THE GMM ESTIMATOR

In this section we establish the asymptotic normality of a generic GMM
estimator. Our discussion adopts a different but closely related formulation of
14A version of Theorem 2.3 also can be established using the assumptions of Theorem 2.2 and
conditions (ii) and (iii) of Theorem 2.3.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1039

GMM estimation to that in Section 2. The first-order conditions of the minimiza-

tion problem used to define a GMM estimator in Section 2 have the interpretation of setting q linear combinations of the r sample orthogonality conditions to
zero where q is the dimensionality of the parameter space. It turns out that

estimators obtained by minimizing or maximizing other criterion functions, e.g.,
quasi-maximum likelihood or least squares estimators, oftentimes can be interpreted in the same manner by examining the corresponding first-order condi-

tions. 15 Our approach in this section is to adopt a generic form of the first-or
conditions and to assume that consistency has already been established. For
estimators not included in the discussion of Section 2, consistency might be

established by appealing to other treatments of those estimators or by appropriately modifying the proof strategy employed in Section 2.
We begin our asymptotic distribution discussion by describing the underlying

assumptions which we make. We extend the index set of the stochastic process
containing the observable variables from the nonnegative integers to include all
of the integers. For studying probabilistic properties, Doob [7, p. 456] argues that
this extension is innocuous.

ASSUMPTION 3.1: {x,: - < n < + x } is stationary and ergodic.
We modify the specification and role of the set S in the analysis.

ASSUMPTION 3.2: S is an open subset of R q that contains IBo*
We use the metric implied by the absolute value norm to define our notion of
convergence on S. We place additional requirements on the function f and the

process {xn : - < n < + oo}.
ASSUMPTION 3.3: f(., /3) and af/a/,(., 8) are Borel measurable for each

B8 E S and af/af3(x, -) is continuous on S for each x E RP.

ASSUMPTION 3.4: afl/a, is first moment continuous at 8Bo and E[af/af

B8o)] exists, is finite, and has full rank.

We adopt the notation do = E[af/3af(xI, IB]O

Our first consistency theorem (Theorem 2.1) relies on the condition that fi is
first moment continuous. A link between this condition and Assumptions 3.3 and
3.4 is provided by Lemma 3.1.

15Hausman [21], among others, has provided an instrumental variables interpretation of maxim
likelihood estimators by examining the first-order conditions of the maximization problem solved in
obtaining the estimators. Avery, Hansen, and Holtz [3] illustrate how to apply results of this section to
consistent, quasi-maximum likelihood estimators of multiperiod probit models. Hansen and Hodrick
[17] apply results from this section to least squares estimators.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1040 LARS PETER HANSEN

LEMMA 3.1: Suppose Assumptions 3.3 and

and is finite, then fi is first moment contin
When f takes the special form given by Assumption 2.6, X is differentiable with

aX/af/ continuous on S, and c,(xl) has a finite expectation, then Assumptions
3.3 and 3.4 are satisfied as long as E[cj(xj)]aX/af8(j80) has full rank.
As in Section 2, we will think of the function f as defining the orthogonality

conditions that we consider using in estimation. Let

wn =(xn, I0) for -x < n < + x
and

vj E[wlw_ WoIw_j y-1, . . . ]E[wol W-j-l 1W-j-2 5
Assumptions 3.1 and 3.3 imply that {Wn: - < n < + oo} is stationary and
ergodic. An iterated expectations argument can be employed to establish that

{vj: j > O} is a martingale difference sequence.

ASSUMPTION 3.5: E[w0w'] exists and is finite, E[wj wo ,w w J 1, . . . ]
verges in mean square to zero, and 7 0E [Vj. j]1/2 is finite.
Among other things, Assumption 3.5 implies that

E[ f(xn, I30) ]=O for -oo < n < + oo,17
and provides sufficient conditions suggested by Hannan [16] for applying a
central limit theorem for stationary, ergodic processes proved by Gordin [13].

We could conceive of estimating 80 by selecting a value of ,B that satisfies the r

equations:

(5) gN (JA) = O.
This may not be possible since (5) involves only q unknowns and r can exceed q.
Instead, we follow Sargan [29, 30] and reduce the number of equations to q by

using linear combinations of the r equations. To accomplish this, we introduce a
sequence of q by r random matrices {a*: N > 1} and make the following
assumption:

ASSUMPTION 3.6: {a* : N > 1} converges in probability to a constant matrix
a* which has full rank.

16Abbreviated versions of the proofs of some of the results in this section and in Section 4

provided in the Appendix. More detailed versions of the proofs can be obtained from the author on
request.

'7This implication can be seen by employing an iterated expectations argument and noting that

E[wo] = E[f(xn, 0o)I-

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1041

We require that a GMM estimator {b*: N > 1 } asymptotically satisfy the set
equations

aO*Ef(x,, )= 0
in the sense of Definition 3.1.

DEFINITION 3.1: The GMM estimator {b: N > 1 } is a sequence of random

vectors that converges in probability to /0 for which { Na*gN(b): N > 1}
converges in probability to zero.
Before showing that this GMM estimator is asymptotically normal and displaying the dependence of its asymptotic covariance matrix on the limiting

weighting matrix a*, we discuss the link between this estimator and the GMM
estimator of Definition 2.1. Note that

IhN (1)12 = laNgN (1)1 = gN(8 )aNaNgN' ( )a
Assuming that the first-order conditions for the problem of minimizing IhNI2 are

satisfied by bN, then

(6) g (bN)'aNaNgN (bN)
Let aN be the q by r matrix

(7) a* = a,g (bN)'a aN.

Substituting (6) into (7), we obtain aNgN(bN) = 0 which trivially satisfies one
the key requirements of Definition 2.1. Once we establish the strong consistency
of the estimator of Definition 2.1, require that the first-order conditions (6) be

satisifed, and demonstrate that the sequence {a*: N > 1 } converges in probability to a constant matrix, then we obtain a GMM estimator of Definition 3.1.

Lemma 3.2 supplies sufficient conditions for {a*: N > 1} as defined by (7) to
converge in probability to a constant matrix.

LEMMA 3.2: Suppose Assumptions 3.1-3.4 are satisfied. If (i) {bN :N > 1}

converges in probability to I30; (ii) { aN: N > 1 } converges in probability to ao;

{(agN/a/3)(bN): N > 1} converges in probability to do and {a* : N > 1} giv
(7) converges in probability to a* = doa'ao.
While the above discussion shows how the estimators of Definition 2.1 can be

viewed as GMM estimators under Definition 3.1, our asymptotic distribution is
not limited to estimators of this form. Any consistent estimators which minimize

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1042

LARS

PETER

HANSEN

or maximize criterion functions with first-order conditions that can be represented as

aNgN(bN) + HN(b*) = 0
where {VNHN(b *) : N > 14 converges in probability to zero for an appropriate
choice of a*, f, and HN, can be viewed as special cases of the generic GMM
estimator of Definition 3.1.18 Thus, various forms of least squares and quasimaximum likelihood along with nonlinear instrumental variables estimators are
included in our asymptotic distribution discussion.

In preparation for our asymptotic distribution theorem, we let

Rw(j) = E[ wOw-].
Assumptions (3.1) and (3.5) insure that Rw(j) is finite and that the matrix
+ 00

SW = E RW(j)
j=-00

is well defined and finite.'9 Theorem 3.1 displays the asymptotic distribution of
the GMM estimator.

THEOREM 3.1: Suppose Assumptions 3.1-3.6 are satisfied. Then {VN(b* - 30)

N > 1) converges in distribution to a normallv distributed random vector with mea

zero and covariance matrix (ado)-la* SwaS*'(a*do) 1.2O

Since Sw plays a prominent role in the expression for the asymptotic covar
ance matrix, we shall examine Assumption (3.5) in conjunction with the compu-

tation of Sw. We focus on situations in which

(10) f(xn, i?) = Un (0 Zn
where we view zn as a vector of the instrumental variables and u, is a vector

the disturbance terms from the econometric model. Let

Ru(j) = E[ Un Un1]
and

RZ (j) = EL ZnZn ]
and assume that RJ(O) and RZ(O) exist and are finite. It is instructive for us to

examine five special cases.

18The minimax estimator of Sargan [30] can be interpreted as a GMM estimator with a nontrivial
HN-

19Under Assumptions 3.1 and 3.5 it can be shown that the elements in the autocovariance

function for { wn: - 0 < n < + oo } are absolutely summable.
201f S is singular, then it may be the case that the asymptotic covariance matrix for the GMM
estimator is singular. If this happens, the GMM estimator has a degenerate normal asymptotic
distribution.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1043

CASE (i):

E[un Zn1Un-=Zn-0,Un-2* =0?
E[unun |ZnsUn- Zn- 1 Un-2 ... **] = Ru(0).
This case includes as a special subcase models in which { un -X < n < + x }

is a sequence of independent, random vectors and un is independent of {zj: < j < n }. It is straightforward to verify that

E[wo wI ,w- _, .... 3=0 for 1 ?1,
VO = WO,

and

Vj =0 for j> 1.

This shows that Assumption 3.5 is satisfied. Also, it can be demonstrated that

R-(U)=0 for j# 0
and

Sw = Rw(O) = Ru(0) 0 R(0).

Thus, Sw can be computed from the second moments of Zn and un.
CASE (ii):

E[ un I Zn, Un- I,Zn- ,Un-21 .. O. =?
This case differs from Case (i) in that we no longer assume that the conditional

covariance matrix for un is independent of the conditioning set. This allows for a
particular form of heteroskedasticity. The stationarity assumption, however,

restricts us to circumstances in which the unconditional variances of {unu:
< n < + x } are constant. As in Case (i), it can be verified that Assumption 3.5
of Theorem 3.1 is met and that

RW(j)=0 for jp50.

In contrast with Case (i), we can no longer compute Rw(O), and co
from the second moments of un and Zn. More specifically, we hav
Sw = RW(0) = E[ unun 0 znzn,j-

This form of Sw arises in the multiperiod probit estimators prop
Hansen, and Hotz [3].
CASE (iii):

E[ un l Znl Un-k,Zn-1, Un-k- 1 ... .1=0

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1044

LARS

PETER

HANSEN

Models in which the disturbance term is orthogonal to an extensive informa-

tion set shifted back k time periods, such as the nonlinear rational expectations

models studied by Hansen and Singleton [20] and the linear (in the variables)
rational expectations models studied by Cumby, Huizinga, and Obstfeld [5] are
included in this case. It can be verified that

E[woIw_w__I.... ]=? for ?>k
and

vj=0 for j>k.
This means that Assumption 3.5 is satisfied. Also,

RW(j)=0 for j>k
and
k-I

SW= E R, (j).
j=k+ I

Computation of SW entails only the determination of a finite number of the
autocovariances of { wn -X < n < + }.
CASE (iv):

E[ Un I Zn, Un-k, Zn-1, Un-k- * ] =0
E[ unun-j l znf un-kl zn- l1 un-k- 11 ... ] = Ru (j) for 0 < j < k.
This case is embedded in Case (iii), and thus we know that assumptions (ii) and
(iii) of Theorem 3.1 are satisfied. Since the conditional autocovariances of

{Un -X < n < + x } are assumed constant, it follows that

Rw(j) = Ru(j) 0 Rz(j) for -k + 1 < j < k-1
and
k-I

SW= E Ru (j) DRz (j).
j=k+ I

Thus Sw can be computed from a finite number of the autocovariances of

{Zn: -X < n < +x}) and {un: -0 < n < +x}). Brown and Maital [4] and
Hansen and Hodrick [18] use these assumptions to study k-step ahead forecast-

ing equations. McCallum [28] employs these assumptions in proposing instrumental variables procedures for linear rational expectations models.

One set of sufficient conditions for the conditional autocovariances of { un
-00 < n < + so } to be constant is as follows. Suppose yn = (Un, Zn + k) and that
the conditional expectation

E[ n Yn . n 2. ...
This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1045

is equal to the corresponding best linear predictor. Also, let

Yn -E[yn Iyn-19 Yn-29* . . . Un
and suppose that
E[ un*un* I Yn- 1 Yn-2 9 **. ]

is constant and hence independent of elements in the conditioning set. These are
sufficient to imply that

E[UnUnf-j I Znf Un-k,Zn- 1l Un-k-, * . = RU(j).
CASE (v): Suppose that the {(u', z'): - < n < + xo } process is linearly
regular and has fourth order cumulants that are zero. For simplicity we assume
that

E[zn] = 0,

E[un] =0.
Let

R UZ(i

R 2 (j)
E[ UnZn_ jl ] u2z (j

Rj (j)
Ruz(j
where L is the number of elements in the disturbance vector and where R k (j) is
an M dimensional row vector with the same number of elements as are in the
instrument vector. Define

RR() (-j)'R ' (j) R 2(-j)'R]' (j) ... RL (-j)'R ' (j)

Rw j) = RU-j) R R2z(j) R 2( (-j)'R 2 ( j) ... RUL (-j)'R

Ru1z (-j)'RuLz( j) RU2Z(-j)'Ruz ( .j.**. Ruz (-j)'R
Then it can be shown that

(8)

RW(j) = RW(j) + RU(j) 0 RZ(j),
+ oo

SW = E [kw (j) + Ru (j) DRz (j)]
j= -00

An alternative representation for Sw can be obtained using spectral density

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1046

LARS

PETER

HANSEN

matrices. Let
+ o0

Su (co) = 2 e - iX8RU ( )
?=-00

i =-oo
+ oo

j= -00
+ o0

Su e
(j)kk
k()
E R
-iX8
j= -00

The following relationships hold:

E Ru (j) 0 Rz (j) = 2v '7 Su(@ 0 Sz -)dco,

)00
+ o0

j]- 00

R k(-j)R(i)= j 1 S 'z (S)' Slz (CO] dco.

Substituting relations (9) into (8) yields an equivalent representation for Sn,. As

noted above, Assumption 3.5 implies that Ruz(O) = 0. In the rational expectations
models studied by Hansen and Sargent [19], it is assumed that Ruz(j) = 0 for
j > 0. This additional assumption can be used to simplify the expressions
obtained in (8) and (9).

The five special cases discussed above illustrate how auxiliary assumptions
imply alternative formulas for calculating Sw. These auxiliary assumptions also
can be used to obtain formulas for models with orthogonality conditions that
have representations other than (10). Assumption 3.5, however, accommodates
models that do not necessarily satisfy the defining assumptions of any of the five
special cases discussed above. Some of the models examined by Hansen and
Sargent [19] are not included in these cases as well as models whose orthogonality conditions emerge because certain equations define best linear predictors but
not conditional expectations. Theorem 3.1 can be applied to these models as well.
In order to make asymptotically valid inferences and construct asymptotically

correct confidence regions, it is necessary to have consistent estimators of a*, do,

Sw. Since {a* : N ? 11 is assumed to converge in probability to ao, we can use a*
as our estimator of a*. A natural candidate for estimating do is dN = (1/N)
agN/a/3(bN). From Lemma 3.2 and Assumptions (3.1)-(3.4) of Theorem 3.1, dN
is consistent. Consistent estimation of Sw is a little more involved. Let

wN = f(Xn s b )g
N

Rw ( ) N wn wn _ j

Lemma 3.3 provides conditions that are sufficient to guaran
consistent estimator of RWO().

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1047

LEMMA 3.3: Suppose Assumptions 3.1-3.5 are satisfied. If f, is second moment

continuous at 80, then { RN(j): N > 1 } converges to R (j) in probability.
In situations where Sw depends on a finite number of autocovariances, i.e.,
k-I

Sw = I Rw (j),
j=-k+ I

we can use Lemma 3.2 to argue that:
k-I

=:
w
Sw=E
1=-k+ 1

R N (j)

is a consistent estimator of Sw. Furthermore, if the conditional covariance
assumptions of Case (i) or (iv) are met, the special structure of Sw can be
exploited even further. Lemma 3.3 can be used to establish consistency of the
sample autocovariances of the estimated disturbances and the instruments. In the

general case, Sw cannot necessarily be computed from a finite number of
autocovariances which complicates its consistent estimation. However, SW is the

spectral density matrix of { Wn: - Xc < n < + xc } at frequency zero, and a
consistent estimator of Sw can be obtained by using procedures appropriate for
estimating spectral density matrices.21
Up until now we have said relatively little about selection of the matrices

{ a : N > 1]. As is clear from the conclusion of Theorem 3.1, different choices of
these weighting matrices give rise to GMM estimators with different asymptotic

covariance matrices. In fact, Theorem 3.1 provides a convenient scheme for
comparing the asymptotic distributions of elements of a whole family of econo-

metric estimators formed by taking different weighted averages of the orthogonality conditions that emerge from the model. One could conceive of determining

an "optimal" estimator from this class, where an optimal estimator is one that
has an asymptotic covariance matrix at least as small as any other element in the

class. This approach can be viewed as an extension of Sargan's [29, 30] discussion
of how to obtain the optimal linear combinations of instruments to use in
estimation given a finite set of instruments are specified a priori. Given a finite

set of orthogonality conditions we show the optimal linear combinations (the aO*

matrix) to use in estimating f80. In describing the solution to this optimization
problem, it is convenient to introduce some definitions and notation.

For a given function f and a given stochastic process { xn: - Xc < n < + x}
we maintain Assumptions 3.1-3.5 and we assume that Sw is nonsingular. Asso-

ciated with f and {xn: -c < n < + x}, we consider a family A of GMM

21 See Hannan [15] for a discussion of alternative strategies for estimating spectral density matrices
In this paper we do not formally establish consistency of these spectral estimators of S. At the very

least, it appears we would want to make the additional assumption that afl/a,8 be second-moment
continuous at f30 in proving consistency. Hannan [16] provides some comments about consistent

estimation of spectral density matrices under Assumptions 3.1 and 3.5. An advantage of spectral

estimators of S., over truncated autocovariance estimators is that spectral estimators are constrained
to be positive semidefinite.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1048 LARS PETER HANSEN

estimators of 0. To each element of A, we assume there corresponds a sequence
of q by r weighting matrices that converge in probability to a constant matrix of
full rank such that the element of A satisfies Definition 3.1 of a GMM estimator
using this particular sequence of weighting matrices. Two elements of A are said
to be asymptotically equivalent if they have the same asymptotic covariance

matrix. Using Theorem 3.1, it is obvious that if two elements of A have the
same limiting weighting matrix, then they are asymptotically equivalent. We
now consider a theorem that provides us with characterization of an optimal estimator.

THEOREM 3.2: Suppose { bN: N > 1 } E A and that the limiting weighting matrix
associated with { bN: N > 1 } satisfies

(10) (a*do) - la*Swa*(a*do) - 1 = (doS7- 'do)
Then { b N > 1 } is optimal with asymptotic covariance matrix (doSw-'do)Furthermore, all optimal estimators in A will have a limiting weighting matrix that
satisfies (10), and

(1 1) a* = edo6Sw-1
for some q by q nonsingular matrix e.
In order to determine an optimal choice of a* of the form specified in (1 1), it is

necessary to have a consistent estimator of do and Sw. This can be accomplished

by initially employing a not necessarily optimal GMM estimator and using one

of the estimation strategies mentioned earlier for Sw and do.
In considering the GMM estimators of Section 2, we indicated that from the

standpoint of consistency it may be desirable to employ a square nonsingular

matrix ao as the limiting weighting matrix. If we choose ao such that a'a0
and aN is some consistent estimator of ao, then Lemma 3.2 informs us that the

corresponding a* is equal to doSw-7. Thus the resulting estimator is optimal.
Under the assumptions defining Case (i) above, the choice of a'a0 = Sw- 1 yields
the nonlinear instrumental variables estimators discussed by Amemiya [1], Jor-

genson and Laffont [24], and Gallant [11].
Our optimality result in Theorem 3.2 is limited in that it takes the specification

of the orthogonality conditions as given and does not discuss how to construct
optimally orthogonality conditions. Amemiya [2] describes how to accomplish
this latter task in environments with serially uncorrelated disturbances. A draw-

back of his approach is that in many circumstances his construction is not
possible to implement in practice. A related limitation of our optimality result is

that it only allows a finite number of orthogonality conditions to be considered.

Hayashi and Sims [22] and Hansen and Sargent [19] discuss optimality in linear
environments in circumstances where orthogonality conditions

E[ Un X Zn-ml = 0

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1049

for m > 0 can be used in estimation. Such a specification admits infinitely
many orthogonality conditions in constructing instrumental variables estimators.
These authors allow the disturbances to be serially correlated, but they rule out
conditional heteroskedasticity.
4. TESTING OVER-IDENTIFYING RESTRICTIONS

When the number of orthogonality conditions, r, exceeds the number of
parameters to be estimated, q, tests of the restrictions implied by the econometric
model are available. As was noted in Section 3, estimation of the model
parameters sets q linear combinations of the r sample orthogonality conditions
equal to zero, at least asymptotically. Thus, when the model is true, there are
r - q linearly independent combinations of the orthogonality conditions that

ought to be close to zero but are not actually set to zero. This provides us with a
scheme for testing the over-identifying restrictions of the model which is
elaborated upon below.

Using the results of Section 3, we can obtain the asymptotic distribution of

{ NgN(bk): N > 1}. Recall that gN(bk) is an expression for the sample orthogo-

nality conditions evaluated at the parameter estimator b*. Lemma 4.1 provides
the desired asymptotic result.

LEMMA 4.1: Suppose Assumptions 3.1-3.6 are satisfied. Then {f NgN(b): N
> 1} converges in distribution to a normal random vector with mean zero and

covariance matrix 0= [I - do(a do)- a *S [I - do(ado)- 'as]'.
Since we have assumed that { NagN(bN)] :N> 1] converges to zero in

probability, it is reasonable to suspect that the asymptotic covariance ma
given in Lemma 4.1 is singular. We can verify this singularity by premultiplying

t0 by a* and obtaining a matrix of zeroes. Although t0 is singular, if S", is
nonsingular and r exceeds q, then t0 is not zero. Hence there are linear
combinations of the sample orthogonality conditions that have a nondegenerate
asymptotic distribution. These linear combinations of sample orthogonality conditions can be used to obtain asymptotically valid test statistics of the model
restrictions.

We wish to examine a particularly convenient test statistic of this form. This

test can be viewed as an extension of a specification test proposed by Sargan [29,
30] and of the specification test associated with minimum chi-square estimators
(see Ferguson [10]). Let

TN = gN(bN) (SW) gN(bN),

where { S: : N > 1) is a consistent estimator of S,. Its asymptotic distri

given in Lemma 4.2 assuming { bN : N > 1 } is an optimal estimator as defined in
Section 3.

LEMMA 4.2: Suppose Assumptions 3.1-3.6 of Theorem 4.1 are satisfied and that

ao = edoSW-7 for some q by q nonsingular matrix e. Then NTN converges in

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1050

LARS

PETER

HANSEN

distribution to a chi-square distributed random variable with r - q degrees of
freedom.

Recall from Section 3 that choosing aN such that aNaN = (Sd)1 gives rise to a

GMM estimator that is optimal and has a nonsingular limiting weighting matrix.
Lemma 4.2 provides us with the asymptotic distribution of the minimized value

of the criterion function |aNgN ( )12. This can be used as a statistic to test t
over-identifying restrictions of the econometric model.22

5. CONCLUSION

This paper has provided a discussion of the large sample properties of a class

of econometric estimators that are defined in terms of orthogonality conditions.
Viewing estimation in this way is convenient for comparing estimators that

exploit, at least implicitly, the same set of orthogonality conditions and is
suggestive of computationally practical estimators in situations in which asymptotically efficient estimation is computationally burdensome. The contribution of
this paper is to provide a discussion of consistency and asymptotic normality of
estimators under conditions not previously examined by other researchers.
In our discussion we exploited the assumption that the underlying stochastic
process of observables is stationary and ergodic. Assumptions of this nature

oftentimes play a role in model specification. Lucas [25] and Lucas and Sargent
[26] have emphasized that in time series modeling based on dynamic theory, the

stochastic properties of the forcing variables play a critical role in model
specification. Characterizing the forcing variables as a stationary process is

clearly convenient in deriving the dynamic decision rules of economic agents
because stationary processes have time invariant probability laws. Furthermore,

the stationary assumption and the theorems in this paper accommodate potentially complicated conditional covariance structures for the disturbance terms
and the observable variables. On the other hand, there exist many situations in
which it would be useful to relax the stationarity assumption. It seems likely,
however, that such extensions will either employ more obscure regularity conditions, or will employ regularity conditions that are not uniformly weaker than

those used in this paper. Nonetheless, it would be a useful exercise to examine

the extent to which results like those obtained here remain intact or could easily
be modified when a subset of forcing variables are not stationary (even though
they may have a time invariant representation). Along this vein, extensions of the
cross-sectional results of White [32, 33, 34] and cross-sectional and time series

22This result can be viewed as an extension of Sargan's [29, 30] derivation of the asymptotic
distribution of what he refers to as the smallest characteristic root. Gallant and Jorgenson [12]
propose a test for restrictions that is the nonlinear three-stage least-squares analogue of the likelihood
ratio test. A derivation of the asymptotic distribution of their test statistic could be obtained in the
estimation environment considered here. Avery, Hansen, and Hotz [3] use Lemma 4.1 directly to
obtain some alternative specification tests.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1051

results of Eicker [8] to the class of time series estimators considered here would
be of interest.
Carnegie-Mellon University
Manuscript received March, 1979; final revision received July, 1981.

APPENDIX

In this Appendix we provide a brief sketch of some of the results in Sections 3 and 4. A more
detailed version of the proofs to all of the lemmas and theorems presented in this paper is available
from the author on request.

PROOF OF THEOREM 3.1: We write agN/a,l in terms of its r row functions:
ag'
a,8

agN
a,3
agN
a,

and we let

DgN( B I.. r)
ag(

Using Taylor's theorem and Assumptions 3.2-3.4, with probability arbitrarily close to one for
sufficiently large N we can write

(12) gN(bN) = gN(UO) + DgN(bN. . * )(b* -0)
where bA is between /lo and b* for i = 1, . . ., r. Premultiplying by a*, we obtain

aNgN(bN) = aNgN(/30) + aNDgN(bkN A * * * (b -80)
Since { bN N > 1 } converges in probability to lo, it follows that { bn : N > 1 } converges in probabil-

ity to flo for i =1, . . ., r. Thus Lemma 4.2 implies that { DgN(b . b1Q): N > 1) converges in

probability to do. Using Assumptions (3.4) and (3.6) we know that for sufficiently large N with
probability arbitrarily close to one we can write

(13) b* -/o= -[a* DgN (Nb . , )] aNgN(0)
+[aNDgN(6N. * )] aNgN(bN)-

Using Assumptions 3.1. 3.5, and Theorem 1 in Hannan [17], it can be shown that { N
> 1} converges in distribution to a normally distributed random vector with mean zero and

covariance matrix S,,.. We use Assumption (3.6) to conclude that { VN(b* - 13o): N > 1 } converg

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1052

LARS

PETER

HANSEN

distribution to a normally distributed random vector with mean zero and covariance matrix
(a*dO)- lao*Swa*'(a*do)

PROOF OF THEOREM 3.2: First, we factor Sw = CC' where C is r by r and nonsingula
let

D = (a*do) la*C - (doS, 'do) do6C
Third, we note that

DC-'do= O.
Fourth, we verify that

(a*d) lao* Sa*'(ao*do) I'DD' + (doS,,- 'do)
Thus, (doSW- 'do) is a lower bound for the asymptotic covariance matrix of elements in A. This
lower bound is attained if and only if D = 0.

We can premultiply D by aO*d0, postmultiply D by C -', and claim that if D = 0, then

O- ao*do(doS, 'do) do6Sw7 =0
or

a= ed6Sw7'
where

e = a*do(doS 'do)
On the other hand, if we let

a*= edo6Sw
for some q by q nonsingular matrix e, we can verify that D = 0.
PROOF OF LEMMA 4.1: We substitute (12) into (13) and obtain

VNgN(b) = [ I- DgN(b.N** ) {,aDgN () . * b)} aN]jVNgN (/30)
+DgN(bkN,...,/4Nr)[a*DgNQ(5.N' ** Nr)] a*gN(b*)Recall from the Proof of Theorem 3.1,

DgN (bN.

in probability and { VNgN ( go) :N > 1) converges to a normally distributed random v

zero and covariance matrix Sw. The conclusion of Lemma 4.1 follows immediately.

PROOF OF LEMMA 4.2: First, we factor S,$ = CNCN and adopt some normalization so that
CN -> C in probability

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

LARGE SAMPLE PROPERTIES 1053
where C is nonsingular. Second, we determine the asymptotic covariance matrix of

{VN(CN)-<gN(bN) N > 1). Using Lemma 4.1 and the fact that a* was chosen optimally

conclude that this covariance matrix is

I - C - 'd0(d6S, 'd0) Ido6C -

which is idempotent and has rank r - q. It follows that { NgN(b*)(SN) NgN(b,) N> 1 } is asymptot

ically chi-square distributed with r - q degrees of freedom.

REFERENCES

[1] AMEMIYA, T: "The Nonlinear Two-Stage Least-Squares Estimator," Journal of Econometrics,
2(1974), 105-110.

[2] "The Maximum Likelihood and Nonlinear Three-Stage Least Squares Estimator in the
General Nonlinear Simultaneous Equations Model," Econometrica, 45(1977), 955-968.
[3] AVERY, R. B., L. P. HANSEN, AND V. J. HOTZ: "Multiperiod Probit Models and Orthogonality
Condition Estimation," Carnegie-Mellon University, Pittsburgh, Pennsylvania, 1981.
[4] BROWN, B. W., AND S. MAITAL: "What Do Economists Know? An Empirical Study of Experts'
Expectations," Econometrica, 49(1981), 491-504.
[5] CUMBY, R., J. HUIZINGA, AND M. OBSTFELD: "Two-Step, Two-Stage Least Squares Estimation in
Models with Rational Expectations," National Bureau of Economic Research, Technical
Paper 11, 1981.

[6] DEGROOT, M. H.: Optimal Statistical Decisions. New York: McGraw-Hill, 1970.
[7] DOOB, J. L.: Stochastic Processes. New York: John Wiley and Sons, 1953.
[8] EICKER, F.: "Limit Theorems for Regressions with Unequal and Dependent Errors," in Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability I, ed. by L. M.
LeCam and J. Neyman. Berkeley: University of California Press, 1967.
[9] ENGLE, R. F.: "Autoregressive Conditional Heteroscedasticity with Estimates of the Variance of
Inflationary Expectations," University of California, San Diego, Department of Economics
Discussion Paper 79-39, 1979.
[10] FERGUSON, T. S.: "A Method of Generating Best Asymptotically Normal Estimates with
Application to the Estimation of Bacterial Densities," Annals of Mathematical Statistics,
29(1958), 1046-1062.
[11] GALLANT, A. R.: "Three-Stage Least-Squares Estimation for a System of Simultaneous, Nonlinear, Implicit Equations," Journal of Econometrics, 5(1977), 71-88.
[12] GALLANT, A. R. AND D. W. JORGENSON: "Statistical Inference for a System of Nonlinear,
Implicit Equations in the Context of Instrumental Variable Estimation," Journal of Econometrics, 11(1979), 275-302.
[13] GORDIN, M. I.: "The Central Limit Theorem for Stationary Processes," Soviet MathematicsDoklady, 10(1969), 1174-1176.
[14] HAKKIO, C. A.: "Expectations and the Forward Exchange Rate," National Bureau of Economic
Research Working Paper No. 439, 1980.
[15] HANNAN, E. J.: Multiple Time Series. New York: John Wiley and Sons, 1970.
[16] "Central Limit Theorems for Time Series Regression," Zeitschrift fur Wahrscheinlichkeitstheorie und verwandte Gebiete, 26(1973), 157-170.
[17] HANSEN, L. P., AND R. J. HODRICK: "Forward Exchange Rates as Optimal Predictors of Future
Spot Rates: An Econometric Analysis," Journal of Political Economy, 88(1980), 829-853.
[18] HANSEN, L. P., AND T. J. SARGENT: "Formulating and Estimating Dynamic Linear Rational
Expectations Models," Journal of Economic Dynamics and Control, 2(1980), 7-46.
[19] : "Instrumental Variables Procedures for Linear Rational Expectations Models," forthcoming in Journal of Monetary Economics.
[20] HANSEN, L. P., AND K. J. SINGLETON: "Generalized Instrumental Variables Estimation of
Nonlinear Rational Expectations Models," forthcoming in Econometrica.
[21] HAUSMAN, J. A.: "An Instrumental Variable Approach to Full Information Estimators for
Linear and Certain Nonlinear Econometric Models," Econometrica, 43(1975), 727-738.
[22] HAYASHI, F., AND C. A. SIMS: "Nearly Efficient Estimation of Time Series Models with
Predetermined, But Not Exogenous, Instruments," University of Minnesota, 1981.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

1054 LARS PETER HANSEN

[23] HUBER, P. J.: "The Behavior of Maximum Likelihood Estimates Under Nonstandard Conditions," in Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability I, ed. by L. M. LeCam and J. Neyman. Berkeley: University of California Press, 1967.
[24] JORGENSON, D. W., AND J. LAFFONT: "Efficient Estimation of Nonlinear Simultaneous Equations with Additive Disturbances," Annals of Economic and Social Measurement, 3(1974),
615-640.

[25] LUCAS, R. E., JR.: "Econometric Policy Evaluation: A Critique," in The Phillips Curve and Labor
Markets, Carnegie-Rochester Conferences on Public Policy, ed. by K. Brunner and A. H.
Meltzer. Amsterdam: North Holland, 1976.

[26] LUCAS, R. E., JR., AND T. J. SARGENT: "After Keynesian Macroeconomics," in After the Phill
Curve: Persistence of High Inflation and High Unemployment. Boston: Federal Reserve Bank of
Boston, 1978.

[27] MALINVAUD, E.: Statistical Method of Econometrics. Amsterdam: North Holland, 1970.
[28] MCCALLUM, B. T.: "Topics Concerning the Formulation, Estimation, and Use of Macroeconometric Models with Rational Expectations," American Statistical Association Proceedings
of the Business and Economic Statistics Section, (1979), 65-72.

[29] SARGAN, J. D.: "The Estimation of Economic Relationships Using Instrumental Variables,"
Econometrica, 26(1958), 393-415.

[30] "The Estimation of Relationships with Autocorrelated Residuals by the Use of Instrumental Variables," Journal of the Royal Statistical Society B, 21(1959), 91-105.
[31] SIMs, C. A.: "Are There Exogenous Variables in Short-Run Production Relationships?" Annals
of Economic and Social Measurement, 1(1972), 17-36.

[32] WHITE, H.: "Nonlinear Regression on Cross-Section Data," Econometrica, 48(1980), 721-746.
[33] : "Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for
Heteroskedasticity," Econometrica, 48(1980), 817-838.

[34] : "Instrumental Variables Regression on Cross-Section Data," San Diego: University of
California Press, Department of Economics Discussion Paper 80-7, 1980.

This content downloaded from 206.253.207.235 on Wed, 06 Mar 2019 15:51:01 UTC
All use subject to https://about.jstor.org/terms

