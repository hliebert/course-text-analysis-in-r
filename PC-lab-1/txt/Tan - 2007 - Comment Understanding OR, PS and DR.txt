Statistical Science
2007, Vol. 22, No. 4, 560–568
DOI: 10.1214/07-STS227A
Main article DOI: 10.1214/07-STS227
© Institute of Mathematical Statistics, 2007

Comment: Understanding OR, PS and DR
Zhiqiang Tan
and their difference, μ1 − μ0 , which gives the average causal effect (ACE). KS throughout focused on the
problem of estimating μ1 from the data (Xi , Ti , Ti Yi ),
i = 1, . . . , n, only, noting in Section 1.2 that estimation
of the ACE can be separated into independent estimation of the means μ1 and μ0 . We shall in Section 3 discuss subtle differences between causal inference and
solving two separate missing-data problems, but until
then we shall restrict our attention to estimation of μ1
from (Xi , Ti , Ti Yi ) only.
The model described at this stage is completely
nonparametric. No parametric modeling assumption
is made on either the regression function m1 (X) =
E(Y |T = 1, X) or the propensity score π(X) = P (T =
1|X). Robins and Rotnitzky (1995) and Hahn (1998)
established the following fundamental result for semiparametric (or more precisely, nonparametric) estimation of μ1 .

We congratulate Kang and Schafer (KS) on their excellent article comparing various estimators of a population mean in the presence of missing data, and thank
the Editor for organizing the discussion. In this communication, we systematically examine the propensity score (PS) and the outcome regression (OR) approaches and doubly robust (DR) estimation, which are
all discussed by KS. The aim is to clarify and better our
understanding of the three interrelated subjects.
Sections 1 and 2 contain the following main points,
respectively.
(a) OR and PS are two approaches with different
characteristics, and one does not necessarily dominate
the other. The OR approach suffers the problem of
implicitly making extrapolation. The PS-weighting approach tends to yield large weights, explicitly indicating uncertainty in the estimate.
(b) It seems more constructive to view DR estimation in the PS approach by incorporating an OR model
rather than in the OR approach by incorporating a PS
model. Tan’s (2006) DR estimator can be used to improve upon any initial PS-weighting estimator with
both variance and bias reduction.

P ROPOSITION 1. Under certain regularity conditions, there exists a unique influence function, which
hence must be the efficient influence function, given by




T
T
Y − μ1 −
− 1 m1 (X)
π(X)
π(X)

T 
Y − m1 (X) .
= m1 (X) − μ1 +
π(X)

τ1 =

Finally, Section 3 presents miscellaneous comments.
1. UNDERSTANDING OR AND PS

The semiparametric variance bound (i.e., the lowest
asymptotic variance any regular estimator of μ1 can
achieve) is n−1 E 2 (τ1 ).

For a population, let X be a vector of (pretreatment)
covariates, T be the treatment status, Y be the observed
outcome given by (1 − T )Y0 + T Y1 , where (Y0 , Y1 ) are
potential outcomes. The observed data consist of independent and identically distributed copies (Xi , Ti , Yi ),
i = 1, . . . , n. Assume that T and (Y0 , Y1 ) are conditionally independent given X. The objective is to estimate

The semiparametric variance bound depends on both
m1 (X) and π(X). The bound becomes large or even
infinite whenever π(X) ≈ 0 for some values of X. Intuitively, it becomes difficult to infer the overall mean
of Y1 in this case, because very few values of Y1 are
observed among subjects with π(X) ≈ 0. The difficulty holds whatever parametric approach, OR or PS,
is taken for inference, although the symptoms can be
different. This point is central to our subsequent discussion.
The problem of estimating μ1 is typically handled
by introducing parametric modeling assumptions on either m1 (X) or π(X). The OR approach is to specify an

μ1 = E(Y1 ),
μ0 = E(Y0 ),
Zhiqiang Tan is Assistant Professor, Department of
Biostatistics, Bloomberg School of Public Health, Johns
Hopkins University, 615 North Wolfe Street, Baltimore,
Maryland 21205, USA (e-mail: ztan@jhsph.edu).
560

COMMENT

OR model, say m1 (X; α), for m1 (X) and then estimate
μ1 by
μ̂OR =

n
1
m̂1 (Xi ),
n i=1

where m̂1 (X) is the fitted response. The PS approach is
to specify a PS model, say π(X; γ ), for π(X) and then
estimate μ1 by
μ̂IPW =

n
1
Ti Yi
n i=1 π̂ (Xi )

or

n
n

Ti Yi

π̂(Xi )
i=1

Ti
,
π̂
(X
)
i
i=1

where π̂(X) is the fitted propensity score. The idea
of inverse probability weighting (IPW) is to recover
the joint distribution of (X, Y1 ) by attaching weight
∝ π̂ −1 (Xi ) to each point in {(Xi , Yi ) : Ti = 1} (see Tan,
2006, for a likelihood formulation). More generally,
consider the following class of augmented IPW estimators μ̂AIPW = μ̂AIPW (h) depending on a known function h(X):


μ̂AIPW



n
n
1
Ti Yi
Ti
1
−
− 1 h(Xi ).
=
n i=1 π̂(Xi ) n i=1 π̂(Xi )

A theoretical comparison of the two approaches is
given by
P ROPOSITION 2. Assume that an OR model is correctly specified and m1 (X) is efficiently estimated with
adaptation to heteroscedastic var(Y1 |X), and that a PS
model is correctly specified and π(X) may or may not
be efficiently estimated. Then
asy.var (μ̂OR ) ≤ asy.var (μ̂AIPW ),
where asy.var. denotes asymptotic variance as n → ∞.
In fact, the asymptotic variance of μ̂OR , which is the
lowest under the parametric OR model, is no greater
than the semiparametric variance bound under the nonparametric model, whereas that of μ̂AIPW is no smaller
than n−1 E 2 (τ1 ) because τ1 has the smallest variance
among π −1 (X)T Y − (π −1 (X)T − 1)h(X) over all
functions h(X). In the degenerate case where m1 (X)
and π(X) are known, the comparison can be attributed
to Rao–Blackwellization because E[π −1 (X)T Y −
(π −1 (X)T − 1)h(X)|X] = m1 (X). This result has interesting implications for understanding the two approaches.

561

First, the result formalizes the often-heard statement
that the (A)IPW estimator is no more efficient than the
OR estimator. If a correct OR model and a correct PS
model were placed in two black boxes, respectively,
and if a statistician were asked to open one and only
one box, then the statistician should choose the box for
the OR model in terms of asymptotic efficiency (minus
the complication due to adaptation to heteroscedastic
variance of Y1 given X). However, one could immediately argue that this comparison is only of phantom
significance, because all models (by human efforts) are
wrong (in the presence of high-dimensional X) and
therefore the hypothetical situation never occurs. In
this sense, we emphasize that the result does not establish any absolute superiority of the OR approach over
the PS approach.
Second, even though not implying one approach is
better than the other, the result does shed light on
different characteristics of the two approaches as an
approximation to the ideal nonparametric estimation.
Typically, increasingly complicated but nested parametric models can be specified in either approach to
reduce the dependency on modeling assumptions. For
a sequence of OR models, the asymptotic variance
of μ̂OR is increasing to the semiparametric variance
bound, whereas for a sequence of PS models, the asymptotic variance of μ̂AIPW is decreasing to the semiparametric variance bound. For this difference, we suggest that the OR approach is aggressive and the PS
approach is conservative. Correctly specifying an OR
model ensures that μ̂OR is consistent and has asymptotic variance no greater, whereas correctly specifying
a PS model ensures that μ̂AIPW is consistent and has asymptotic variance no smaller, than otherwise would be
best attained without any modeling assumption. This
interpretation agrees with the finding of Tan (2006) that
the OR approach works directly with the usual likelihood, whereas the PS approach retains part of all information and therefore ignores other part on the joint
distributions of covariates and potential outcomes.
Now the real, hard questions facing a statistician
are:
(a) Which task is more likely to be accomplished, to
correctly specify an OR model or a PS model?
(b) Which mistake (even a mild one) can lead to
worse estimates, misspecification of an OR model or
a PS model?
First of all, it seems that no definite comparison is possible, because answers to both questions depend on unmeasurable factors such as the statistician’s effort and

562

Z. TAN

experience for question (a) and the degree and direction of model misspecification for question (b). Nevertheless, some informal comparisons are worth considering.
Regarding question (a), a first answer might be
“equally likely,” because both models involve the
same vector of explanatory variables X. However,
the two tasks have different forms of difficulties. The
OR-model building works on the “truncated” data
{(Xi , Yi ) : Ti = 1} within treated subjects. Therefore,
any OR model relies on extrapolation to predict m1 (X)
at values of X that are different from those for most
treated subjects [i.e., π(X) ≈ 0]. The usual model
checking is not capable of detecting OR-model misspecification, whether mild or gross, in this region
of X. (Note that finding high-leverage observations
can point to the existence of such a region of X, not
model misspecification.) This problem holds for lowor high-dimensional X, and is separate from the difficulty to capture m1 (X) within treated subjects when X
is high-dimensional [cf. KS’s discussion below display
(2)]. In contrast, the PS-model building works on the
“full” data {(Xi , Ti )} and does not suffer the presence
of data truncation, although suffering the same curse
of dimensionality. The exercise of model checking is
capable of detecting PS-model misspecification. The
matter of concern is that successful implementation is
difficult when X is high-dimensional.
Regarding question (b), KS (Section 2.1) suggested
that the (A)IPW estimator is sensitive to misspecification of the PS model when π(X) ≈ 0 for some values of X. For example, if π(X) = 0.01 is underestimated at 0.001, then, even though the absolute bias is
small (= 0.009), the weight π −1 (X) is overestimated
by 10 times higher. In this case, the estimator has inflated standard error, which can be much greater than
its bias. In contrast, if the OR model is misspecified,
then the bias of the OR estimator is the average of
those of m̂1 (X) across individual subjects in the original scale, and can be of similar magnitude to its standard deviation.
In summary, OR and PS are two approaches with
different characteristics. If an OR model is correctly
specified, then the OR estimator is consistent and has
asymptotic variance no greater than the semiparametric variance bound. Because of data truncation, any OR
model suffers the problem of implicitly making extrapolation at values of X with π(X) ≈ 0. Finding highleverage observations in model checking can point to
the existence of such values of X. In contrast, the PS
approach specifically examines π(X) and addresses

data truncation by weighting to recover the joint distribution of (X, Y1 ). The weights are necessarily large for
treated subjects with π(X) ≈ 0, in which case the standard error is large, explicitly indicating uncertainty in
the estimate. If a PS model is correctly specified, then
the (A)IPW estimator is consistent and has asymptotic
variance no smaller than the semiparametric variance
bound.
2. UNDERSTANDING DR

The OR or the (A)IPW estimator requires specification of an OR or a PS model, respectively. In contrast,
a DR estimator uses the two models in a manner such
that it remains consistent if either the OR or the PS
model is correctly specified. The prototypical DR estimator of Robins, Rotnitzky and Zhao (1994) is
μ̂AIPW,fix =

n
Ti Yi
1
n i=1 π̂(Xi )



−
=



n
1
Ti
− 1 m̂1 (Xi )
n i=1 π̂(Xi )

n
1
m̂1 (Xi )
n i=1
n

Ti 
1
+
Y − m̂1 (Xi ) .
n i=1 π̂ (Xi )

The two equivalent expressions [resp. (9) and (8) in
KS] correspond to those for the efficient influence
function τ1 in Proposition 1. Proposition 3 collects theoretical comparisons between the three estimators.
P ROPOSITION 3.

The following statements hold:

(i) μ̂AIPW,fix is doubly robust.
(ii) μ̂AIPW,fix is locally efficient: if a PS and an OR
model are correctly specified, then μ̂AIPW,fix achieves
the semiparametric variance bound and hence
asy.var (μ̂AIPW,fix ) ≤ asy.var (μ̂AIPW ).
(iii) If an OR model is correctly specified and m1 (X)
is efficiently estimated in μ̂OR , then
asy.var (μ̂AIPW,fix ) ≥ asy.var (μ̂OR ).
Compared with μ̂OR , μ̂AIPW,fix is more robust in
terms of bias if the OR model is misspecified but the
PS model is correctly specified, but is less efficient in
terms of variance if the OR model is correctly specified. The usual bias-variance trade-off takes effect.
Compared with μ̂AIPW , μ̂AIPW,fix is more robust in

563

COMMENT

terms of bias if the PS model is misspecified but the OR
model is correctly specified, and is more efficient in
terms of variance if both the PS and the OR models are
correctly specified. The usual bias-variance trade-off
seems not to exist. Intuitively, the difference can be attributed to the characteristics of OR (being aggressive)
and PS (being conservative) discussed in Section 1. It
is possible for the PS approach to reduce both bias and
variance by incorporating an OR model, but not so for
the OR approach by incorporating a PS model.
Local efficiency implies that if the PS model is correctly specified, then μ̂AIPW,fix gains efficiency over
μ̂AIPW for every function h(X) under the condition
that the OR model is also correctly specified. A more
desirable situation is to find an estimator that is not
only doubly robust and locally efficient but also, whenever the PS model is correctly specified, guaranteed to
gain efficiency over μ̂AIPW for any initial, fixed function h(X). For simplicity, consider μ̂IPW corresponding to h(X) = 0 as the initial estimator. In this case,
consider Tan’s (2006) regression (tilde) estimator
μ̃REG =

n
1
Ti Yi
n i=1 π̂(Xi )

− β̃

(1)





n
1
Ti
− 1 m̂1 (Xi ),
n i=1 π̂ (Xi )

where β̃ is the first element of β̃ = Ẽ −1 (ξ̂ ζ̂  )Ẽ(ξ̂ η̂),
Ẽ denotes sample average, and
(1)

η̂ =

TY
,
π̂ (X)




T
ξ̂ =
−1
π̂(X)

m̂1 (X),

∂ π̂
(X) 
∂γ 

1 − π̂(X)

,

∂ π̂

(X) 
T
∂γ 
ζ̂ =
m̂1 (X),
.
π̂ (X)
1 − π̂(X)

This estimator algebraically resembles Robins, Rotnitzky and Zhao’s (1995) regression (hat) estimator
μ̂REG =

n
Ti Yi
1
n i=1 π̂(Xi )

− β̂

(1)





n
1
Ti
− 1 m̂1 (Xi ),
n i=1 π̂ (Xi )

where β̂ is the first element of β̂ = Ẽ −1 (ξ̂ ξ̂  )Ẽ(ξ̂ η̂).
Compared with μ̂AIPW,fix , each estimator introduces an
estimated regression coefficient, β̃ or β̂, of η̂ against
control variates ξ̂ . Therefore, μ̃REG and μ̂REG share the
(1)

advantage of optimally using control variates ξ̂ [Proposition 4(ii)]. See Section 3 for a discussion about “control variates” and “regression estimators.” On the other
hand, β̂ is defined in the classical manner, whereas
β̃ is specially constructed by exploiting the structure
of control variates ξ̂ . This subtle difference underlies
Proposition 4(i).
P ROPOSITION 4.

The following statements hold:

(i) μ̃REG and μ̂REG are locally efficient, but μ̃REG
is doubly robust and μ̂REG is not.
(ii) If a PS model is correctly specified and π(X) is
efficiently estimated, then μ̃REG and μ̂REG achieve the
smallest asymptotic variance among




n
n

Ti Yi
Ti
1
(1) 1
−b
− 1 m̂1 (Xi ),
n i=1 π̂(Xi )
n i=1 π̂(Xi )

where b(1) is an arbitrary coefficient. The two estimators are asymptotically at least as efficient as μ̂IPW and
μ̂AIPW,fix , corresponding to b(1) = 0 and 1.
Compared with μ̂AIPW,fix , μ̃REG provides a more
concrete improvement upon μ̂IPW due to the possession of three properties: optimality in using control
variates, local efficiency and double robustness. Using μ̃REG achieves variance reduction if the PS model
is correctly specified (the effect of which is maximal
if the OR model is also correctly specified), and bias
reduction if the PS model is misspecified but the OR
model is correctly specified. On the other hand, comparison between μ̂OR and μ̃REG is similarly subject to
the usual bias-variance trade-off as that between μ̂OR
and μ̃AIPW,fix . That is, μ̃REG is more robust than μ̂OR
if the OR model is misspecified but the PS model is
correctly specified, but is less efficient if the OR model
is correctly specified.
The preceding comparisons between μ̂AIPW,fix , μ̃REG
and μ̂OR , μ̂IPW present useful facts for understanding
DR estimation. It seems more meaningful to consider
μ̂AIPW,fix or μ̃REG as an advance or improvement in the
PS approach by incorporating an OR model rather than
in the OR approach by incorporating a PS model. The
OR and PS models play different roles, even though
the models are equally referred to in the concept of DR
and μ̂AIPW,fix can be expressed as bias-corrected μ̂OR
or equivalently as bias-corrected μ̂IPW . This viewpoint
is also supported by the construction of μ̂AIPW,fix (in
the first expression by Robins, Rotnitzky and Zhao,
1994) and μ̃REG . Both of the estimators are derived
under the assumption that the PS model is correct, and
then examined in the situation where the OR model is

564

Z. TAN

also correct, or the PS model is misspecified but the
OR model correct (see Tan, 2006, Section 3.2).
The different characteristics discussed in Section 1
persist between the PS (even using μ̂AIPW,fix or μ̃REG
with the DR benefit) and OR approaches. The asymptotic variance of μ̂AIPW , μ̂AIPW,fix , or μ̃REG if μ̃REG the
PS model is correctly specified is no smaller, whereas
that of μ̂OR if the OR model is correctly specified is
no greater, than the semiparametric variance bound.
Moreover, if the OR model is correct, the asymptotic
variance of μ̂AIPW,fix or μ̃REG is still no smaller than
that of μ̂OR . Therefore:
P ROPOSITION 5. The asymptotic variance of
μ̂AIPW,fix or μ̃REG if either a PS or an OR model is
correctly specified is no smaller than that of μ̂OR if
the OR model is correctly specified and m1 (X) is efficiently estimated in μ̂OR .
Like Proposition 2, this result does not establish absolute superiority of the OR approach over the PS-DR
approach. Instead, it points to considering practical issues of model specification and consequences of model
misspecification. There seems to be no definite comparison, because various, unmeasurable factors are involved. Nevertheless, the points regarding questions
(a) and (b) in Section 1 remain relevant.
In summary, it seems more constructive to view DR
estimation in the PS approach by incorporating an OR
model rather than in the OR approach by incorporating
a PS model. The estimator μ̃REG provides a concrete
improvement upon μ̂IPW with both variance and bias
reduction in the sense that it gains efficiency whenever
the PS model is correctly specified (and maximally so
if the OR model is also correctly specified), and remains consistent if the PS model is misspecified but
the OR model is correctly specified. On the other hand,
comparison between μ̃REG and μ̂OR is complicated by
the usual bias-variance trade-off. Different characteristics are associated with the OR and the PS-DR approaches and should be carefully weighed in applications.

the fact that if the PS model is correct, then η̂ asymptotically has mean μ1 (to be estimated) and ξ̂ mean
0 (known). That is, ξ̂ serve as auxiliary variables (in
the terminology of survey sampling) or control variates
(in that of Monte Carlo integration). Variance reduction can be achieved by using Ẽ(η̂) − bẼ(ξ̂ ), instead
of μ̂IPW = Ẽ(η̂), with b an estimated regression coefficient of η̂ against ξ̂ .
The control variates for μ̃REG in Section 2 include
(π̂ −1 T − 1)m̂1 and (T − π̂)[π̂(1 − π̂)]−1 ∂ π̂/∂γ , the
second of which is the score function for the PS model
and is necessary for asymptotic optimality in Proposition 4(ii). If the PS model is correct, then μ̃REG is
always at least as efficient as μ̂IPW in the raw version,
that is, μ̂AIPW (0), but not always than μ̂IPW in the ratio version. However, the indefiniteness can be easily
resolved. If the control variate π̂ −1 T − 1 is added, or
(1, m̂1 ) substituted for m̂1 , then μ̃REG always gains
efficiency over both versions of μ̂IPW . Furthermore, if
(1, h, m̂1 ) is substituted for m̂1 , then μ̃REG always
gains efficiency also over the estimator μ̂AIPW (h).
Causal Inference

Causal inference involves estimation of both μ1 and
μ0 . Similar estimators of μ0 can be separately defined
by replacing T , π̂ and m̂1 with 1 − T , 1 − π̂ and
m̂0 , where m0 = E(Y |T = 0, X). The control variates
((1 − π̂ )−1 (1 − T ) − 1)(1, m̂0 ) for estimating μ0 differ from (π̂ −1 T − 1)(1, m̂1 ) for estimating μ1 . As
a consequence, even though μ̃1,REG or μ̃0,REG individually gains efficiency over μ̂1,IPW or μ̂0,IPW , the
difference μ̃1,REG − μ̃0,REG does not necessarily gain
efficiency over μ̂1,IPW − μ̂0,IPW . The problem can be
overcome by using a combined set of control variates,
say, [π̂ −1 T − (1 − π̂)−1 (1 − T )](π̂, 1 − π̂, π̂ m̂0 , (1 −
π̂)m̂1 ) . Then μ̃1,REG − μ̃0,REG maintains optimality in using control variates in the sense of Proposition 4(ii), in addition to local efficiency and double robustness. The mechanism of using a common set of
control variates for estimating both μ1 and μ0 is automatic in the likelihood PS approach of Tan (2006).
PS Stratification

3. OTHER COMMENTS
Control Variates and Regression Estimators

The name “regression estimator” is adopted from
the literatures of sampling survey (e.g., Cochran, 1977,
Chapter 7) and Monte Carlo integration (e.g., Hammersley and Handscomb, 1964), and should be distinguished from “regression estimation” described by
KS (Section 2.3). Specifically, the idea is to exploit

KS (Section 2.2) described the stratification estimator of Rosenbaum and Rubin (1983) as a way “to
coarsen the estimated propensity score into a few categories and compute weighted averages of the mean
response across categories.” It is helpful to rewrite the
estimator in their display (6) as
μ̂strat =

n
Ti Yi
1
,
n i=1 π̂strat (Xi )

565

COMMENT





n
n
where π̂strat (X) =
i=1 Ti 1{π̂ (Xi ) ∈ Sj }/ i=1
1{π̂(Xi ) ∈ Ŝj } if π̂ (X) ∈ Ŝj (the j th estimated PS stratum), j = 1, . . . , s. That is, μ̂strat is exactly an IPW
estimator based on the discretized π̂strat (X). Comparison between μ̂strat and μ̂IPW is subject to the usual
bias-variance trade-off. On one hand, μ̂strat often has
smaller variance than μ̂IPW . On the other hand, the asymptotic limit of μ̂strat can be shown to be
s E[π(X)m (X)|π ∗ (X) ∈ S ∗ ]



1
j
P π ∗ (X) ∈ Sj∗ ,
∗
∗

j =1

E[π(X)|π (X) ∈ Sj ]

where π ∗ (X) is the limit of π̂(X), which agrees with
the true π(X) if the PS model is correct, and Sj∗ is that
of Ŝj . The ratio inside the above sum is the withinstratum average of m1 (X) weighted proportionally to
π(X). Therefore, μ̂strat is inconsistent unless π(X) or
m1 (X) is constant within each stratum (cf. KS’s discussion about crude DR in Section 2.4). The asymptotic
bias depends on the joint behavior of m1 (X) and π(X),
and can be substantial if m1 (X) varies where π(X) ≈ 0
varies so that m1 (X) are weighted differentially, say,
by a factor of 10 at two X’s with π(X) = 0.01 and 0.1.
Simulations

KS designed a simulation setup with an OR and a
PS model appearing to be “nearly correct.” The response is generated as Y = 210 + 27.4Z1 + 13.7Z2 +
13.7Z3 + 13.7Z4 + , and the propensity score π =
expit(−Z1 + 0.5Z2 − 0.25Z3 − 0.1Z4 ), where and
(Z1 , Z2 , Z3 , Z4 ) are independent, standard normal.
The covariates seen by the statistician are X1 =
exp(Z1 /2), X2 = Z2 /(1 + exp(Z1 )) + 10, X3 =
(Z1 Z3 /25 + 0.6)3 and X4 = (Z2 + Z4 + 20)2 . The
OR model is the linear model of Y against X, and the
PS model is the logistic model of T against X.
In the course of replicating their simulations, we accidentally discovered that the following models also
appear to be “nearly correct.” The covariates seen by
the statistician are the same X1 , X2 , X3 , but X4 =
(Z3 + Z4 + 20)2 . The OR model is linear and the
PS model is logistic as KS models. For one simulated
dataset, Figures 1 and 2 present scatterplots and boxplots similar to Figures 2 and 3 in KS. For the OR
model, the regression coefficients are highly significant and R 2 = 0.97. The correlation between the fitted
values of Y under the correct and the misspecified OR
models is 0.99, and that between the linear predictors
under the correct and the misspecified PS models is
0.93. Tables 1 and 2 summarize our simulations for KS
models and for the alternative models described above.
The raw version of μ̂IPW is used. The estimators μ̃(m)
REG

(m)

and μ̂REG are defined as μ̃REG and μ̂REG except that the
score function for the PS model is dropped from ξ̂ . For
these four estimators, (1, m̂1 ) is substituted for m̂1 .
KS found that none of the DR estimators they tried
improved upon the performance of the OR estimator;
see also Table 1. This situation is consistent with the
discussion in Section 2. The theory of DR estimation
does not claim that a DR estimator is guaranteed to
perform better than the OR estimator when the OR and
the PS models are both misspecified, whether mildly or
grossly. Therefore, KS’s simulations serve as an example to remind us of this indefinite comparison.
On the other hand, neither is the OR estimator guaranteed to outperform DR estimators when the OR
model is misspecified or even “nearly correct.” As seen
from Table 2, μ̂OR yields greater RMSE values than the
DR estimators, μ̂WLS , μ̃REG and μ̃(m)
REG when the alternative, misspecified OR and PS models are both used.
For n = 200, the bias of μ̂OR is 2.5 and that of μ̃REG
is 0.44, which differ substantially from the corresponding biases −0.56 and −1.8 in Table 1 when KS models
are used.
The consequences of model misspecification are difficult to study, because the degree and direction of
model misspecification are subtle, even elusive. For the
dataset examined earlier, the absolute differences between the (highly correlated) fitted values of Y under
the correct and the alternative, misspecified OR models
present a more serious picture of model misspecification. In fact, the quartiles of these absolute differences
are 2.0, 3.2 and 5.1, and the maximum is 20.
For both Tables 1 and 2, the DR estimators μ̃REG
(m)
and μ̃REG perform overall better than the other DR estimators μ̂AIPW,fix and μ̂WLS . Compared with μ̂WLS ,
μ̃REG has MSE reduced by 15–20% (Table 1) or by
20–25% (Table 2) when the PS model is correct but
the OR model is misspecified, which agrees with the
optimality property of μ̃REG in Proposition 4(ii). Even
the simplified estimator μ̃(m)
REG gains similar efficiency,
although the gain is not guaranteed in theory. The non(m)
DR estimators μ̂REG and μ̂REG sometimes have sizeable biases even when the PS model is correct.
Summary

One of the main points of KS is that two (moderately) misspecified models are not necessarily better
than one. This point is valuable. But at the same time,
neither are two misspecified models necessarily worse
than one. Practitioners may choose to implement either of the OR and the PS-DR approaches, each with
its own characteristics. It is helpful for statisticians to

566

Z. TAN

F IG . 1.

F IG . 2.

Scatterplots of response versus covariates (alternative models).

Boxplots of covariates and propensity scores (alternative models).

567

COMMENT
TABLE 1
Numerical comparison of estimators of μ1 (KS models)
Method

Bias

n = 200

π -model
correct

π -model
incorrect

% Bias

RMSE

MAE

Bias

% Bias

RMSE

MAE

IPW
strat

0.080
−1.1

π -model correct
0.64
12.6
−37
3.20

6.11
2.04

16
−2.9

π -model incorrect
32
52.7
−93
4.28

8.99
3.11

OLS

−0.025

y-model correct
−0.99
2.47

1.68

−0.56

y-model incorrect
17
3.33

2.19

AIPWfix
WLS
REGtilde
REGhat

−0.024
−0.025
−0.025
−0.52

y-model correct
−0.96
2.47
−1.0
2.47
−1.0
2.47
−20
2.63

1.67
1.68
1.69
1.73

0.24
0.39
0.14
−0.52

y-model incorrect
6.9
3.44
13
2.99
5.2
2.73
−19
2.81

2.06
1.89
1.76
1.78

REGtilde

(m)

−0.024

2.47

1.68

0.24

(m)
REGhat
AIPWfix

WLS
REGtilde
REGhat

−0.21
−0.026
−0.026
−0.027
−0.45

−8.4
−1.0
−1.0
−1.1
−18

2.48
2.48
2.47
2.47
2.60

1.68
1.71
1.70
1.71
1.71

−0.026

−1.1

2.47

1.69

(m)

REGtilde

−0.98

8.9

2.74

1.79

−0.086
−5.1
−2.2
−1.8
−2.2

−3.2
−44
−69
−62
−76

2.65
12.6
3.91
3.47
3.68

1.74
3.75
2.77
2.41
2.53

−2.0

−68

3.56

2.47

(m)
REGhat

−0.13
−5.3
2.48
1.68
−2.2
−77
3.68
2.59
...............................................................................................................................
n = 1000
π -model correct
π -model incorrect
IPW
0.098
2.0
4.98
3.04
68
9.2
746
14.7
strat
−1.1
−86
1.71
1.24
−2.9
−214
3.22
2.94
−0.047

y-model correct
−4.0
1.15

AIPWfix
WLS
REGtilde
REGhat

−0.046
−0.046
−0.046
−0.13

y-model correct
−4.0
1.15
−4.0
1.15
−4.0
1.15
−11
1.16

REGtilde

(m)

−0.046

−4.0

REGhat
AIPWfix
WLS
REGtilde
REGhat

(m)

−0.083
−0.10
−0.048
−0.046
−0.045

−7.2
−6.5
−4.1
−4.0
−3.9

REGtilde

(m)

−0.046

REGhat

(m)

−0.058

OLS
π -model
correct

π -model
incorrect

−0.85

y-model incorrect
−56
1.75

1.15

0.766
0.769
0.773
0.796

0.043
0.12
0.048
−0.077

y-model incorrect
2.6
1.63
8.7
1.37
3.9
1.23
−6.3
1.23

1.11
0.943
0.809
0.812

1.15

0.770

0.092

7.3

1.26

0.870

1.15
1.61
1.15
1.15
1.16

0.768
0.769
0.764
0.764
0.786

0.024
−26
−3.0
−1.7
−1.7

1.9
−8.5
−203
−120
−122

1.24
308
3.38
2.21
2.24

0.857
5.56
3.05
1.73
1.75

−4.0

1.15

0.763

−2.1

−152

2.48

2.04

−5.0

1.16

0.771

−2.2

−158

2.57

2.15

promote a common, rigorous understanding of each approach and to investigate new ways for improvement.
We welcome KS’s article and the discussion as a step
forward in this direction.
ACKNOWLEDGMENTS

We thank Xiao-Li Meng and Dylan Small for helpful
comments.

0.770

REFERENCES
C OCHRAN , W. G. (1977). Sampling Techniques, 3rd ed. Wiley
New York. MR0474575
H AHN , J. (1998). On the role of the propensity score in efficient
semiparametric estimation of average treatment effects. Econometrica 66 315–331. MR1612242
H AMMERSLEY, J. M. and H ANDSCOMB , D. C. (1964). Monte
Carlo Methods. Methuen, London. MR0223065

568

Z. TAN
TABLE 2
Numerical comparison of estimators of μ1 (alternative models)
Method

Bias

n = 200

π -model
correct

π -model
incorrect

MAE

Bias

% Bias

RMSE

MAE

0.080
−1.1

π -model correct
0.64
12.6
−37
3.20

6.11
2.04

18
−1.1

π -model incorrect
34
55.7
−36
3.22

9.61
2.21

OLS

−0.025

y-model correct
−0.99
2.47

1.68

2.5

y-model incorrect
80
4.04

2.73

AIPWfix
WLS
REGtilde
REGhat

−0.024
−0.025
−0.025
−0.52

y-model correct
−0.96
2.47
−1.0
2.47
−1.0
2.47
−20
2.63

1.67
1.68
1.69
1.73

0.53
0.83
0.33
−0.34

y-model incorrect
14
3.82
28
3.09
13
2.63
−13
2.70

2.32
1.96
1.71
1.74

REGtilde

(m)

−0.024

−0.98

2.47

1.68

0.45

17

2.74

1.78

(m)
REGhat
AIPWfix

WLS
REGtilde
REGhat

−0.21
−0.024
−0.026
−0.025
−0.42

−8.4
−0.97
−0.10
−0.10
−17

2.48
2.48
2.47
2.47
2.56

1.68
1.71
1.70
1.71
1.71

0.09
−2.5
0.33
0.44
−0.026

3.6
−21
11
16
−0.95

2.63
12.2
3.11
2.74
2.74

1.74
2.72
2.05
1.80
1.78

11

2.83

1.80

2.76

1.77

(m)

−0.025

−1.0

2.47

1.69

0.31

(m)
REGhat

−0.22

−8.9

2.48

1.71

0.035

IPW
strat

0.098
−1.1

π -model correct
2.0
4.98
−86
1.71

3.04
1.24

80
−0.96

π -model incorrect
8.5
951
−72
1.65

16.8
1.17

OLS

−0.047

y-model correct
−4.0
1.15

0.770

2.2

y-model incorrect
152
2.67

2.21

AIPWfix
WLS
REGtilde
REGhat

−0.046
−0.046
−0.046
−0.13

y-model correct
−4.0
1.15
−4.0
1.15
−4.0
1.15
−11
1.16

0.766
0.769
0.773
0.796

0.061
0.22
0.12
−0.012

y-model incorrect
3.3
1.87
16
1.39
10
1.21
−0.97
1.19

1.17
0.957
0.818
0.801

REGtilde

(m)

−0.046

−4.0

1.15

0.770

0.14

12

1.25

0.849

(m)
REGhat
AIPWfix

WLS
REGtilde
REGhat

−0.083
−0.12
−0.048
−0.044
−0.099

−7.2
−6.3
−4.1
−3.9
−8.5

1.15
1.83
1.15
1.15
1.16

0.768
0.780
0.768
0.765
0.787

1.22
441
1.55
1.46
1.45

0.826
2.92
1.12
0.946
0.910

−0.045

−3.9

1.15

0.757

0.22

17

1.29

0.847

1.17

0.764

0.13

10

1.28

0.836

n = 1000

π -model
incorrect

RMSE

IPW
strat

REGtilde

π -model
correct

% Bias

(m)

REGtilde
(m)
REGhat

−0.16

−14

ROBINS , J. M. and ROTNITZKY, A. (1995). Semiparametric efficiency in multivariate regression models with missing data. J.
Amer. Statist. Assoc. 90 122–129. MR1325119
ROBINS , J. M., ROTNITZKY, A. and Z HAO , L. P. (1994). Estimation of regression coefficients when some regressors are
not always observed. J. Amer. Statist. Assoc. 89 846–866.
MR1294730
ROBINS , J. M., ROTNITZKY, A. and Z HAO , L. P. (1995). Analysis
of semiparametric regression models for repeated outcomes in

0.069
−31
−0.55
0.61
0.57

1.3

5.7
−6.9
−38
46
43

the presence of missing data. J. Amer. Statist. Assoc. 90 106–
121. MR1325118
ROSENBAUM , P. R. and RUBIN , D. B. (1983). The central role of
the propensity score in observational studies for causal effects.
Biometrika 70 41–55. MR0742974
TAN , Z. (2006). A distributional approach for causal inference using propensity scores. J. Amer. Statist. Assoc. 101 1619–1637.
MR2279484

