DOI 10.1515/jem-2013-0009

J. Econom. Meth. 2015; 4(1): 145–151

Practitioner’s Corner
Martin Ravallion*

On the Implications of Essential Heterogeneity
for Estimating Causal Impacts Using Social
Experiments
Abstract: The standard model of essential heterogeneity, whereby program take up depends on unobserved
costs and benefits of take up, is generalized to allow the source of latent heterogeneity to influence counterfactual outcomes. The standard instrumental variables (IV) estimator is shown to still be preferable to the
naïve, ordinary least squares (OLS), estimator for mean impact on the treated. However, under certain conditions, the IV estimate of the overall mean impact will be even more biased than OLS. Examples are given for
stylized training, insurance and microcredit schemes.
Keywords: essential heterogeneity; experiments; instrumental variables; randomization; selective
compliance.
JEL Codes: C93; H43.
*Corresponding author: Martin Ravallion, Department of Economics, Georgetown University, Washington DC, USA,
E-mail: mr1185@georgetown.edu

1 Introduction
Any imaginable policy intervention will have diverse impacts, possibly with losses as well as gains. To some
degree, such heterogeneity can be explained with the available data, and knowledge about the determinants
of impacts can enhance the precision of evaluations and their policy relevance. However, a degree of unobservable heterogeneity in impacts must be expected in practice. While this is ignorable for estimating the
aggregate benefits as long as the heterogeneity is orthogonal to the actual receipt of the intervention, that is
not a particularly plausible condition. Naturally, people make rational choices about whether to participate
in any offered treatment, and they almost certainly base their choices on things they know that are not available as data. Take up will depend on latent costs and benefits of take up. This gives rise to what Heckman,
Urzua, and Vytlacil (2006) term “essential heterogeneity” (also known as “correlated random coefficients”),
an idea going back over 25 years in the literature.1
There still appears to be some confusion amongst practitioners about the implications of essential heterogeneity for the inferences drawn from social experiments with selective take-up. The near universal estimator in practice uses the randomized assignment as the instrumental variable (IV) for treatment. I have
often heard the following statement (or something like it) at seminars or other presentations or discussions
on impact evaluations:
“Granted there is selective take-up of the treatment, but the randomized assignment is an ideal instrumental variable, since
it only influences outcomes via treatment.”

This claim is known to be wrong. The exclusion restriction required by the IV estimator does not hold under
essential heterogeneity; see Heckman, Urzua, and Vytlacil (2006). We can expect that, amongst those assigned
1 Early discussions include Heckman and Robb (1985), Björklund (1987) and Heckman (1992).

Brought to you by | Universität St. Gallen Bibliothek
Authenticated
Download Date | 9/17/18 3:41 PM

146

M. Ravallion: On the Implications of Essential Heterogeneity for Estimating Causal Impacts

to the treatment group, those units with higher expected gains will be more likely to accept the treatment.
However, the IV estimator still gives the mean impact on the treated and is open to other interpretations.2 It
may not be what some practitioners think they are getting, but it does provide a parameter of interest.
However, in the standard formulation of the problem of essential heterogeneity as a random coefficient
model, the IV is not in fact required for an unbiased estimate of mean impact on the treated in large samples.
Indeed, the naïve OLS estimator – obtained by ignoring the endogeneity of treatment and simply subtracting
the mean of the outcomes for the control group from that for the treatment group – also delivers a consistent
estimate of mean impact on the treated, as Section 2 shows.
The paper argues that the standard formulation of the essential heterogeneity problem in the literature
is unduly restrictive. Practitioners need a more general formulation, to allow for the fact that the same latent
factors generating diverse impacts from the treatment can also be expected to have bearing on outcomes
under the counterfactual. Section 3 examines the implications of this more general formulation of the essential heterogeneity problem.
For understanding the IV estimator in this more general setting, the OLS estimator is the obvious comparator. I expect most practitioners aware of the problem of essential heterogeneity would subscribe to a view
something like this (paraphrasing something I have heard at times):
“Granted a bias may remain due to essential heterogeneity, but at least the IV estimator does better than simply comparing
mean outcomes for those treated with those not.”

This too is wrong, as a generalization. Section 3 shows that, depending on how the heterogeneity alters counterfactual outcomes, OLS may be less biased for the mean impact than the IV estimator – indeed, there is even
a special case in which OLS is unbiased.
Whether the use of randomization as an IV is to be preferred for estimating mean impact can thus be
seen to depend on the behavioral assumptions made in modeling outcomes for the specific program being
evaluated. Section 3 describes stylized examples of the various cases, which point to important differences
between types of programs in the biases to be expected.

2 B
 iases in Standard Impact Estimators under Essential
Heterogeneity
Selective take-up is to be expected in most randomized experiments with human subjects. So we have a
potential source of bias, as is well-recognized in the literature. In practice, the near universal fix for this
problem is to use a dummy variable for the randomized assignment as the instrumental variable (IV) for
treatment status.3
The assignment to treatment will naturally be correlated with receiving the treatment. But can it be legitimately excluded from the main regression, as also required for a valid IV? At first glance it sounds very
reasonable to assume that being randomly assigned to some treatment only matters to its outcomes if one
actually receives that treatment. However, on closer inspection this assumption is far from reasonable. As
Heckman, Urzua, and Vytlacil (2006) point out, plausible behavioral responses to the option for treatment
2 Heckman and Vytlacil (2007, Section 9.2) show that the IV estimator under essential heterogeneity gives the mean impact for
those treated. Under certain conditions the IV estimator under essential heterogeneity gives another parameter of potential interest, namely the “local average treatment effect” (LATE) (Imbens and Angrist 1994), given by the mean impact for those units
induced to take up the treatment by a change in the IV. Imbens and Angrist identify conditions under which LATE can be identified by the standard IV estimator.
3 The theoretical conditions for this to work are laid out by Angrist, Imbens, and Rubin (1996). The IV estimator is identical to the
method of correcting for selective compliance proposed by Bloom (1984) in which the intent-to-treat estimate is deflated by the
proportion who take up the assigned option of treatment. This assumes no “crossovers” in that treatment is only possible for units
assigned to treatment. With crossovers, one obtains instead a local average treatment effect (Imbens and Angrist 1994).

Brought to you by | Universität St. Gallen Bibliothek
Authenticated
Download Date | 9/17/18 3:41 PM

M. Ravallion: On the Implications of Essential Heterogeneity for Estimating Causal Impacts

147

invalidate the exclusion restriction. This section elaborates on this point and explores further its implications
for impact evaluation.
The randomized assignment is denoted Zi (for unit i = 1, …, n), which takes the value 1 if unit i is assigned
to treatment and 0 otherwise. The actual treatment status is Di, taking the value 1 if treated and 0 otherwise.
At least some units take up treatment, but not all (0 < E(D) < 1). Treatment is only possible if one is assigned
to the treatment group, but take up is voluntary. The unit-specific impact of the treatment is βi, which is
the difference between the outcome under treatment and that when untreated. Since we cannot observe
someone in two states of nature at the same time, the βi’s are unobserved. The mean impact is β and ηi
represents the variation in impact around the mean, i.e., βi = β + ηi . The mean impact on those treated is
E ( β | D = 1) = β + E ( η| D = 1). Given that treatment (conditional on assignment) is a choice variable, a natural
assumption is that those who take up the treatment tend to be those with higher η’s, i.e., E(η|D = 1) > E(η|D = 0),
implying that E(η|D = 1) > 0, given that η has zero (unconditional) mean.
The standard regression specification in the literature for estimating the mean impact on outcome Y is a
random coefficient model:4
Yi = α + βi Di + εi = α + βDi + ( εi + ηi Di )

(1)



The heterogeneity in impact is swept into the error term, such that the coefficient on D gives the mean causal
effect. Now consider the standard IV estimator in which the randomized assignment is used as the IV for
treatment. This converges in large samples to:5
Plim ˆβ IV = β +

Cov( ηD, Z )
Cov( D, Z )

(2)



Here I use the fact that randomization implies that Cov(ε, Z) = 0. Randomization also implies that Cov(η, Z) = 0.
However, under essential heterogeneity, it does not imply that Cov(ηD, Z) = 0 since there will be sorting on the
η’s; amongst those assigned the program, those who choose to take it up will tend to have higher η’s. Thus
the randomized assignment is not a valid IV for identifying mean impact, as was pointed out by Heckman,
Urzua, and Vytlacil (2006).
But what does the IV estimator give us? We can write the bias term on the RHS of (2) as:
Cov( ηD, Z ) E ( ηDZ ) − E ( ηD ) E ( Z )
=
Cov( D, Z )
E ( DZ ) − E ( D ) E ( Z )



(3)

Evaluating these terms further by exploiting the fact that both D and Z are binary, with D = 1 implying Z = 1
(since assignment to treatment is necessary for receiving treatment), we have:6
E ( ηDZ ) = E ( ηD ) = E ( η | D = 1) E ( D )

(4.1)



E ( DZ ) = E ( D ) 

(4.2)

Substituting (4.1) and (4.2) into (3) and then (3) into (2) we have:
Plim ˆβ IV = β + E ( η | D = 1) = E ( β | D = 1)



(5)

Thus the IV estimator still gives the mean impact on the treated, but overestimates the overall mean impact
under essential heterogeneity.
4 As in (inter alia) Heckman and Robb (1985), Björklund (1987), Heckman (1992), Heckman, Urzua, and Vytlacil (2006).
5 I will drop the subscript i from now one for notational brevity.
6 Note that E(ηDZ) = E(ηDZ|D = 1)E(D)+E(ηDZ|D = 0)(1–E(D)) = E(η|D = 1)E(D) given that E(ηDZ|D = 0) = 0.

Brought to you by | Universität St. Gallen Bibliothek
Authenticated
Download Date | 9/17/18 3:41 PM

148

M. Ravallion: On the Implications of Essential Heterogeneity for Estimating Causal Impacts

The fact that the IV estimator still gives mean impact on the treated despite essential heterogeneity is
clearly a valuable property. Note, however, that if essential heterogeneity is the only source of bias – specifically, if Cov(D, ε) = 0 – then the “naïve” OLS estimator also gives mean impact on the treated. To see why, note
that for the OLS estimator (in obvious notation):
Plim ˆβOLS = β +

Cov( ηD, D )
Var( D )

(6)



The bias term is:7
Cov( ηD, D ) E ( ηD 2 ) − E ( ηD ) E ( D ) E ( ηD )
=
=
= E ( η | D = 1)
Var( D )
E ( D )( 1− E ( D ))
E( D )



(7)

Thus OLS also converges to E(β|D = 1). While the presence of essential heterogeneity naturally biases both estimators of overall mean impact, it turns out to be exactly the same bias. Of course, the reason is different. For
the IV method, the bias stems from the violation of the exclusion restriction, while for OLS, it stems directly
from the endogeneity of treatment.
Notice that if essential heterogeneity is the only concern then one does not need to know the randomized
assignment (as required by the IV estimator) to obtain a consistent estimate of the mean impact for those
treated; the data for OLS – outcomes and treatment status – are sufficient. Outcomes for those treated can
then be collected alongside the receipt of treatment. The control group need only represent those for whom
treatment is not an option.

3 A
 llowing Essential Heterogeneity to Alter Counterfactual
Outcomes
The above formulation has followed the literature on essential heterogeneity in postulating that it only
matters through the implied interaction effect between take-up and the gains from treatment. This is restrictive. More generally, one can allow the same latent factors causing variability in the gains from treatment to
have bearing on counterfactual outcomes. In other words, in the absence of the intervention, there are systematic differences in the outcome variable of interest between units that tend to have high returns from the
intervention and those with low returns. One can readily imagine real world settings in which this would be
expected; examples are given below. Thus it can be argued that this generalization of the standard model of
essential heterogeneity (as found in Heckman, Urzua, and Vytlacil 2006, for example) enhances its relevance.
To introduce this feature, let the error term in (1) now take the form:
ε = γη + υ 

(8)

We can identify “pure” essential heterogeneity as the special case γ = 0. More generally, latent characteristics
that enhance impact may be associated with higher (γ > 0) or lower (γ < 0) counterfactual outcomes. (In the
special case γ = –1 we have a constant impact amongst those treated.) To keep the focus on the implications
of essential heterogeneity, I assume that the new innovation error term (υ) in (8) is orthogonal to treatment
(Cov(D, υ) = 0). One can weaken this assumption to conditional exogeneity, by adding control variables to the
basic model in (1).
For interpreting the econometric model in (1) and (8), it is helpful to consider a more explicit model of
outcomes as returns to a primary individual characteristic χ, which is observed by each experimental unit but
not by the analyst, and where the return to higher χ can be systematically altered by the intervention. We can
write this model as:8
7 I use the fact that E(ηD2) = E(ηD) = E(η|D = 1)E(D).
8 Note that the error terms are the same in these equations given that (by assumption) Cov(D, υ) = 0.

Brought to you by | Universität St. Gallen Bibliothek
Authenticated
Download Date | 9/17/18 3:41 PM

M. Ravallion: On the Implications of Essential Heterogeneity for Estimating Causal Impacts

Y = a0 + b0 χ + υ if D = 0
Y = a1 + b1 χ + υ if D = 1

149

(9)



This is equivalent to the model in (1) and (8) where the correspondence is as follows:
α = a0 + b0 E ( χ )

β = a1 − a0 + ( b1 − b0 ) E ( χ )

(10)

η = ( b1 − b0 )( χ − E ( χ ))
γ = b0 /( b1 − b0 )



Rational take up requires that E(χ|D = 1) > E(χ|D = 0) if the gain ( β + η ) is increasing in χ (i.e. if b1 > b0), while
E(χ|D = 1) < E(χ|D = 0) if b1 < b0. Either way, E(η|D = 1) > 0.
There are three possible regimes for how heterogeneity alters counterfactual outcomes: γ > 0, –1 ≤ γ < 0 and
γ < –1. These relate to differences in the types of programs being evaluated, given likely behavior responses. I
provide stylized examples of each regime.
Regime 1: γ > 0. Consider the following training program. The source of latent heterogeneity is learning
ability, which is unobserved by the analyst but known individually. People choose whether to participate
in the (randomly assigned) program on the basis of their ability, as this determines their expected benefits.
(As usual, there is some cost of participation, including forgone income.) Labor market earnings are the outcomes of interest. The program imparts skills that are complementary to ability, so that the returns to ability
are greater under treatment (b1 > b0). (For example, an accountancy course enhances the returns to numeracy.)
Absent the program, higher ability yields higher income (b0 > 0). Thus γ > 0.
Regime 2: –1 ≤ γ < 0. Consider instead a public insurance scheme, providing support for those suffering
(say) ill-health or a crop failure. Participants are compensated for income losses stemming from some unobserved risky behavior on their part, denoted by χ. The program attracts those with high χ. Expected income
is the outcome variable. In the absence of the program, those who undertake the risky activity are assumed
to have higher expected utility but lower expected income (b0 < 0). However, with the program in place, the
risk-takers are largely compensated for any loss, leaving a net gain in expected income (b1 > 0). Thus: –1 ≤ γ < 0.
Regime 3: γ < –1. A variation on the example for Regime 1 is to suppose that the training program provides
skills that substitute for latent ability (rather than the two being complements). Thus the scheme dulls the
benefits from higher innate ability and is more attractive to those with lower ability. In this case, we have
b1 < b0 and γ < –1. To give another example of Regime 3 for a different type of program, consider a microcredit
scheme, which provides extra credit to some target group and χ denotes access to credit from other sources.
Take up is higher for those with lower χ; E(χ|D = 1) < E(χ|D = 0). (For example, self-targeting mechanisms in
the scheme’s design discourage participation for those with high χ.) Greater access to credit from alternative sources increases counterfactual incomes (b0 > 0) as well as participants’ incomes (b1 > 0). However, the
scheme attenuates the gain enjoyed by those with greater access to credit from alternative sources, i.e., b1 < b0.
So, again, γ < –1. And, given that take up is greater for those with lower χ, we have E(η|D = 1) > 0.9
What biases can be expected in standard estimates of the mean impact? For the OLS estimator we now
have:
Plim ˆβOLS = β +

Cov( ηD, D ) γ Cov( η, D )
+
Var( D )
Var( D )



(11)

Similarly to the derivation above for the bias in the IV estimator, we have:


γ
Plim ˆβOLS = β +  1+
 E ( η | D = 1)
 1− E ( D ) 


(12)

9 Notice that positive returns to the latent characteristic with or without treatment (b0 > 0 and b1 > 0) are consistent with both γ < 0
and E(η|D = 1) > 0 as long as the selection yields E(χ|D = 1) < E(χ), as is implied by the assumption that those with low access to credit
tend to take up the scheme.

Brought to you by | Universität St. Gallen Bibliothek
Authenticated
Download Date | 9/17/18 3:41 PM

150

M. Ravallion: On the Implications of Essential Heterogeneity for Estimating Causal Impacts

Plainly, the IV estimator dominates when the essential heterogeneity matters to counterfactual outcomes
(γ≠0) and the parameter of interest is the mean impact on the treated. Indeed, it can be argued that the role
of the IV estimator is not to remove the bias stemming from the interaction effect between treatment and
gains from treatment, but rather to remove any bias in how the same source of essential heterogeneity alters
counterfactual outcomes.
What about the overall mean impact, β ? The preferred estimator then depends on the regime. In Regime
1 (γ > 0), while both the OLS and IV estimators overestimate mean impact, the use of the randomized assignment as the IV reduces the bias in the OLS estimate.
In Regime 2 (–1 ≤ γ < 0), the outcome depends on the program participation rate. When the participation
rate is relatively low – specifically E(D) < 1+γ( ≥ 0) – OLS overestimates mean impact, but is less biased than
the IV estimator. With a sufficiently high participation rate, E(D) > 1+γ, OLS underestimates mean impact but
will have a lower (higher) absolute bias than the IV estimate if 2(E(D)–0.5) is less than (greater than) 1+γ. A
program participation rate < 0.5 (common in practice) is sufficient for OLS to have lower bias than the IV
estimator in Regime 2. OLS is unbiased when E(D) = 1+γ, implying that the odds of program take-up, E(D)/
(1–E(D)), equal the relative returns to the latent characteristic, b1/b0. This is clearly a knife-edge property.
In Regime 3 (γ < –1), OLS underestimates the true mean impact, while IV overestimates it. As in Regime
2, with E(D) > 1+γ, the (absolute) OLS bias will be less than (greater than) the IV bias if 2(E(D)–0.5 is less than
(greater than) 1+γ. (A necessary condition for the OLS estimate to be less biased is that E(D) < 0.5, but this is not
sufficient.) The weighted mean of the two estimates will be unbiased when the weight on the OLS estimate is
(1–E(D))/(–γ). The lower the treatment rate, the higher the weight on the OLS estimate. The greater the effect
of the impact heterogeneity on counterfactual outcomes the higher the weight on the IV estimate.

4 Conclusions
Essential heterogeneity is such an intuitively plausible idea that the onus on practitioners should be to establish a priori grounds why it does not exist. Short of such grounds, we can expect a bias in the estimate of
mean causal impact obtained by using the randomized assignment as the instrumental variable for treatment status. The bias stems from a failure of the exclusion restriction, even with a perfectly randomized
assignment.
But will the IV estimator still help in reducing the bias in the naïve OLS estimator? We have seen in this
paper that whether (to paraphrase Heckman and Vytlacil 2005, 671) “the IV cure is worse than the disease”
depends crucially on what impact parameter one is interested in, the type of program one is evaluating and
the behavioral responses to that program. If one is only interested in the mean impact for those actually
treated then the IV estimator is still unbiased, even though the randomized assignment is not a valid IV.
However, if the latent interaction effect between take up and the gains from take up is the only source of bias
then the OLS estimator also delivers the mean treatment effect on the treated. Under the standard characterization of essential heterogeneity in the literature, the IV and OLS estimates converge asymptotically to the
same value.
The two estimators only differ in large samples when there is some other source of bias, on top of that
from the interaction effect between the take up and the unobserved variation in the impact of the treatment.
A natural extension to the standard formulation of the essential heterogeneity problem is to allow the same
factors creating the heterogeneity in impact to also matter to counterfactual outcomes. If these work in the
same direction – such that higher counterfactual outcomes due to the latent factor come hand-in-hand with
higher returns to treatment – then the IV estimator can be trusted to reduce the OLS bias in mean impact. A
training program providing complementary skills to latent ability is probably a good example.
However, there is no a priori reason to expect the two sources of bias to work in the same direction. That
depends on the type of program and the behavioral responses to that program. If the latent factors leading to
higher returns to treatment are associated with lower counterfactual outcomes then the “IV cure” for endogenous treatment can indeed be worse than the disease. The paper has described examples, based on a stylized

Brought to you by | Universität St. Gallen Bibliothek
Authenticated
Download Date | 9/17/18 3:41 PM

M. Ravallion: On the Implications of Essential Heterogeneity for Estimating Causal Impacts

151

public insurance program and a microcredit scheme for fighting poverty. Indeed, the OLS estimator may even
be unbiased, despite the selective take-up. And even when it is not, averaging the IV and OLS estimates can
reduce the bias under certain conditions. Practitioners need to think carefully about the likely behavioral
responses in each application.
Acknowledgments: For helpful comments the author is grateful to Pedro Carneiro, Emanuela Galasso, James
Heckman, Aart Kraay, Michael Lokshin, David McKenzie and Berk Ozler.
Previously published online April 9, 2014

References
Angrist, Joshua, Guido Imbens, and Donald Rubin. 1996. “Identification of Causal Effects Using Instrumental Variables.” Journal
of the American Statistical Association XCI: 444–455.
Björklund, Anders. 1987. “What Experiments are Needed for Manpower Policy?” Journal of Human Resources 23 (2): 267–277.
Bloom, Howard S. 1984. “Accounting for No-shows in Experimental Evaluation Designs.” Evaluation Review 8: 225–246.
Heckman, James. 1992. “Randomization and Social Policy Evaluation.” In Evaluating Welfare and Training Programs, edited by
Charles F. Manski and Irwin Garfinkel, 201–230. Cambridge and London: Harvard University Press.
Heckman, James, and Richard Robb. 1985. “Alternative Methods for Evaluating the Impact of Interventions – An Overview.”
Journal of Econometrics 30: 239–267.
Heckman, James and Edward Vytlacil. 2005. “Structural Equations, Treatment Effects and Econometric Policy Evaluation.”
Econometrica 73 (3): 669–738.
Heckman, James, and Edward Vytlacil. 2007. “Econometric Evaluation of Social Programs, Part ii: Using the Marginal Treatment
Effect to Organize Alternative Econometric Estimators to Evaluate Social Programs, and to Forecast their Effects in New
Environments.” In Handbook of Econometrics, edited by James Heckman and Edward Leamer, vol. 6B, Amsterdam: North
Holland.
Heckman, James, Serio Urzua, and Edward Vytlacil. 2006. “Understanding Instrumental Variables in Models with Essential
Heterogeneity.” Review of Economics and Statistics 88 (3): 389–432.
Imbens, Guido, and Joshua Angrist. 1994. “Identification of Local Average Treatment Effects.” Econometrica 62 (2): 467–475.

Brought to you by | Universität St. Gallen Bibliothek
Authenticated
Download Date | 9/17/18 3:41 PM

