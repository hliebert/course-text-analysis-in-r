STATISTICS IN MEDICINE
Statist. Med. 2003; 22:1285–1303 (DOI: 10.1002/sim.1380)

Weighting in instrumental variables and G-estimation
Marshall M. Joe1; ∗; † and Colleen Brensinger 2
1 Department

of
Room 602
2 Department of
Room 618

Biostatistics and Epidemiology; University of Pennsylvania School
Blockley Hall; 423 Guardian Drive; Philadelphia; PA 19104-6021;
Biostatistics and Epidemiology; University of Pennsylvania School
Blockley Hall; 423 Guardian Drive; Philadelphia; PA 19104-6021;

of Medicine;
U.S.A.
of Medicine;
U.S.A.

SUMMARY
We propose here a simple scheme to use information on compliance and prerandomization covariates
to improve analysis of randomized trials with non-compliance. We use the data to determine the eect
of randomization on treatment received among various strata dened by pretreatment covariates. When
the eect of treatment received on the outcome of interest is the same across strata and pretreatment
covariates predict non-compliance, weighting the estimating functions by the eect of randomization
on treatment received can improve the precision of explanatory estimates of treatment eect and can
increase the power of intent-to-treat tests of the null hypothesis. Eciency gains under the weighting
scheme are a simple increasing function of the variability of these weights. Such weighting schemes
will often lead to improvements even when these conditions are not met. We use a randomized trial of
cholestyramine to illustrate these points. Copyright ? 2003 John Wiley & Sons, Ltd.
KEY WORDS:

causal inference; noncompliance; instrumental variables; randomized trials; weighting

1. INTRODUCTION
Non-compliance is a pervasive problem in randomized trials. Until recently, analysts have
chosen between two methods for analysing such data: the widely accepted and seemingly
conservative intent-to-treat (ITT) methods, and the widely and justly maligned ‘as treated’ or
‘per protocol’ analyses and their variants [1].
Recent years have seen the development of alternatives which seek to improve on these
familiar approaches; instrumental variables methods, long popular in econometrics, provide the
basis for several recent proposals [2–7]. These methods use information on treatment received,
but in a seemingly inecient way, by seeing whether a postulated eect of treatment among
the subjects receiving treatment can explain dierences between the randomized groups [8]. As
∗

Correspondence to: Marshall M. Joe, Department of Biostatistics and Epidemiology, University of Pennsylvania
School of Medicine, Room 602 Blockley Hall, 423 Guardian Drive, Philadelphia, PA 19104-6021, U.S.A.
† E-mail: mjoe@cceb.upenn.edu
Contract=grant sponsor: United States National Heart, Lung and Blood Institute; contract/grant number: R29
HL59184.

Copyright ? 2003 John Wiley & Sons, Ltd.

Received February 2001
Accepted July 2002

1286

M. M. JOFFE AND C. BRENSINGER

typically discussed and applied, compliant and non-compliant subjects are weighted equally
in the ‘adjusted’ comparisons of the randomized groups. It seems intuitively obvious that
compliant subjects provide more information about the eect of treatment than non-compliant
ones and so should receive more weight in the analysis.
This paper presents a simple weighting scheme for instrumental-variables type estimators
based on this notion and shows how it can be used to improve eciency. We extend the
scheme to estimators not considered previously [9–12] and consider when such schemes can
confer substantial benets. We illustrate some of these points with data from a randomized
trial of cholestyramine [13, 14].
2. CHARACTERIZING NON-COMPLIANCE AND ITS EFFECTS
To motivate our discussion, consider a study of the eect of cholestyramine (CLT) on blood
cholesterol levels measured at the end of a xed follow-up period. Choosing a continuous
outcome measured at the end of a xed follow-up period makes the ideas and calculations most
transparent; similar approaches can be taken with failure time and repeated measures outcomes.
Let R denote the intervention, assigned by randomization: R=1 for subjects randomized to
CLT, 0 for others. Let Y denote the outcome of interest (log serum cholesterol at the end of
follow-up), and let X represent covariates or attributes measured prior to randomization.
Sometimes compliance refers to a single act or event; other times, as in trials of ongoing
drug therapies, it refers to a series of events (for example, whether a subject takes a particular
drug on any given day). In the former case, compliance is naturally a scalar quantity. In the
latter case, it has often been treated as a scalar quantity not varying over time. For most of
our exposition, we will adopt this approach, as it simplies mathematics and understanding,
and yields a tractable analysis that can be performed with standard software. Let A denote the
level of consistency of one’s observed treatment/exposure pattern with the course of action
prescribed by the intervention; here, A=1 if a subject takes the level of CLT prescribed to
subjects randomized to receive it, and A=0 if the subject takes no CLT. More generally,
A can take any value between 0 and 1, expressing the overall level of compliance with the
regime (for example, proportion of prescribed doses taken for a medication). In order for this
representation to be adequate, we must either assume that compliance (for example, CLT use)
does not vary over time, or that treatment eects depend only on the average level it takes
over the interval.
Consider next dening and describing the eects of CLT use (or, loosely speaking, of
compliance). To x ideas, consider a strong-minded subject who is motivated to take all the
prescribed doses and wants to know what eect CLT use will have on his cholesterol level. In
other words, this individual wants to compare what would happen to his cholesterol level if he
used CLT with what would happen if he did not. This is a comparison of potential outcomes:
Y1 , the log serum cholesterol that would be observed at the end of one year were he to take
CLT as prescribed, and Y0 , the log cholesterol that would be observed if he does not take
CLT; we sometimes call Y0 the baseline potential outcome. More generally, Ya is the outcome
that would be seen if an individual received level a of CLT; denote the vector of potential
outcomes Ya by Y. At most one of these potential outcomes can be observed. Implicit in our
notation is the assumption that randomization has no eect on outcome except that mediated
by the dose of CLT received; that is, randomization has no direct eect. An investigator should
assess the validity or plausibility of this ‘exclusion restriction’ [2] in applications [15, 16].
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1287

WEIGHTING IN G-ESTIMATION

If all subjects complied with their assigned treatment (that is, all subjects assigned to
take CLT did so and no others did), a standard ITT analysis could help answer this person’s
question. A comparison of the mean responses in the randomized groups (that is, E(Y | R=1)−
E(Y | R=0)) equals in expectation a comparison of the potential outcomes E(Y1 ) − E(Y0 ).
Under the (non-identiable) assumption that the eect Y1 − Y0 is the same in each individual,
the ITT estimates from the randomized trial estimate what this motivated subject wants to
know.
ITT comparisons are standard even in the presence of non-compliance [1, 17], where they
are sometimes considered a pragmatic analysis or an analysis of the eectiveness of the
intervention [18]. The approach compares outcomes under two dierent plans: one which
encourages and provides CLT, and one which does not. This analysis only partially answers
the question of interest to this motivated subject; the study shows that CLT is likely to lower
serum cholesterol (further assumptions are required even to reach this conclusion [2, 19]), but
does not estimate how much.
Analyses which try to answer the question of interest to this subject and so estimate the
ecacy of CLT typically compare people based on the levels of treatment they receive, possibly adjusting for pretreatment covariates X . Two variants of this approach include: ignoring
randomization status and comparing subjects who received treatment with those who did not
(‘as treated’); comparing subjects who complied with their assigned regime (that is, subjects
assigned to CLT who used it with subjects assigned to placebo, ‘per protocol’) [1]. An assumption that would justify such analysis is ignorable non-compliance (see Rosenbaum and
Rubin [20]), expressed mathematically as f(A | R; X; Y)=f(A | R; X ); that is, any treatmentarm specic association between the level of treatment received and the potential outcomes
Y may be explained in terms of measured covariates X . Such assumptions make no use of
the fact of randomization, and analyses based on them justly provoke scepticism [1].

3. INSTRUMENTAL VARIABLES AS EXPLANATORY ANALYSIS
Instrumental variables analyses provide an alternative for answering the motivated subject’s
question but do not ignore the fact of randomization. This section outlines one such approach,
using G-estimation (an instrumental variables method) for estimating parameters in structural
nested distribution and structural nested mean models [6, 11, 19, 21], and shows how it often
can provide better-justied explanatory analyses than those sketched above.
Consider simple models for the eect of treatment received, that is, we are interested in
comparing observed outcomes Y to the outcome Y0 that would have been seen had treatment
not been provided. Let a (W ) ≡ E(Ya | W ) denote the mean of the potential outcome Ya in
the subset of the data dened by observable variables W . A structural mean model (SMM)
relates the observable mean outcome A (X; R; A) in the subset of the population dened by
treatment received A, covariates X , and randomization group R to the mean 0 (X; R; A) of the
baseline potential outcomes Y0 in the same subset. A simple, one-parameter SMM is
0 (X; R; A)=A (X; R; A) − 0 A

(1)

where 0 parameterizes the eect of treatment received. Under model (1), the realized eect
of treatment received is proportional to the amount of treatment received, that is, subjects
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1288

M. M. JOFFE AND C. BRENSINGER

who received half of their prescribed dose of CLT received half the cholesterol-lowering
eect (on the log scale) of subjects who received the full dose. We consider more exible,
multi-parameter SMMs in Section 5. Let X; R; A; a ≡ Ya − a (X; R; A) denote the residual from the
regression of the potential outcome Ya on its mean, and let UX; R; A ≡ {X; R; A; a } denote the set of
potential residuals. Structural distribution models (SDM) place restrictions on the distribution
of the potential residuals U. One possible restriction is that the residuals of the baseline and
observable outcomes X; R; A; 0 and X; R; A; A are identically distributed; that is, that
FX; R; A; 0 |X;R;A (e)=FX; R; A; A |X;R;A (e)

(2)

If the residuals X; R; A; 0 and X; R; A; A are identical, models (1)–(2) are deterministic or rankpreserving (RP). A more exible SDM may allow the distribution of the residuals to vary
with the treatment received A, as well as randomization group R and pretreatment
covariates X .
Randomization allows consistent estimation of 0 even when compliance is not ignorable. Let p ≡ pr (R=1) be the randomization probability, and let g(·) be a known function
of its arguments. Let  denote a guess or putative value for the causal parameter 0 , and
let U () ≡ Y − A. Informally, we call U () the putative potential outcome; under a RP
SDM, when =0 ; U ()=Y0 . For SDMs, randomization implies that the U (0 ) and pretreatment covariates X are jointly independent of the initial assignment R. Let g(u; x) be a
known, arbitrary function of its arguments. The joint independence implies that g{U (0 ); X }
is independent of R, and so that



(R − p)g{U (0 ); X } =0
(3)
E
i

For SMMs, U (0 ) is uncorrelated but not necessarily independent of R, thus (3) will hold if
g(u; x)=g0 (x) + g1 (x)u is a linear function of u. Replacing the true but unknown 0 in (3)
by a putative value  leads to estimating equations for 0 .
The structural model and the putative potential outcome U () both involve treatment received A, and so our estimation procedure (3) uses information on post-randomization treatment to estimate eects. This is acceptable in principle; heuristically, A is used with the
structural model (in SDMs) only to remove the eect of treatment and so recover a pretreatment variable U (0 ) uncorrelated with the randomization indicator.
These estimating equations generalize an instrumental variables estimator common in the
econometrics literature [2]. To see this, consider using the function g(u; x)=u in (3), which


ˆ ≡ {(R − p)Y }= { (R −
(R − p)Y = (R − p)A; solving for yields  yields 
leads to
p)A}, which is essentially the usual instrumental variables estimator.

4. GIVING MORE WEIGHT TO COMPLIERS
It seems intuitively obvious that compliant subjects should provide more information about
the eect of treatment than non-compliant ones. Although, even for binary compliance, we
often cannot denitively identify compliant individuals [2, 22], we can identify groups dened by prerandomization covariates X that are less compliant or more so; this identication
can improve eciency. Dene (X ) ≡ E(A | R=1; X ) − E(A | R=0; X ); (X ) is a measure of
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

WEIGHTING IN G-ESTIMATION

1289

the eect of randomization on treatment received and has been called the compliance score
[23, 24]. If treatment received is all or none (that is A=0 or 1) and there are no ‘deers’
(people who would take the experimental treatment if and only if assigned not to receive it
[2]), (X ) is the proportion of compliers among subjects with pretreatment covariates X . One
might be tempted to give more weight to strata X in which (X ) is large.
Formalizing the weighting scheme and its benets requires additional structure for the
estimating functions. Consider restrictions on the form of the function g(u; x) in (3). We can
decompose any arbitrary function g(u; x) into a product of a weight function w(x), dependent
only on pretreatment covariates x, and another function h(u; x), that is, g(u; x) ≡ w(x)h(u; x).
Dene X ; 0 () ≡ Y − A (X ) − A=U () − 0 (X ); for RP SDMs, X ; 0 (0 ) is the baseline
residual X ; 0 . One set of choices for h(u; x) is the set of functions q(·) of the residual u − 0 (x),
that is, h(u; x)=q{X ; 0 ()}.
The following theorems clarify the benets of a scheme that weights a function of the
residuals q{X ; 0 ()} by the eect of randomization on treatment received (x):
Theorem 1. Suppose that the semi-parametric SDM (1)–(2) holds, and that compliance
is ignorable. Consider estimating equations of form (3). Then
1. The optimal function g(u; x) is (x)q∗ (X ; 0 ), where q∗ () ≡ @ ln{f()}=@, and f() is
the density of the error function X ; 0 .
2. For any given function m() of the residual X ; 0 , the most ecient weighting scheme
is to choose weights w(x)=(x).
Part 1 of the theorem follows directly from Robins [21]. A sketch of the proof of part 2
appears in the Appendix. The theorem states that the most ecient estimating function w(x)
is obtained by combining an optimal function q∗ () of the residuals with compliance-based
weights (x). In addition, if one chooses a dierent function q() of the residuals, perhaps
to improve robustness and decrease sensitivity to large values of , compliance-based weights
will maximize eciency for that function q().
Theorem 2. Suppose that the semi-parametric SMM (1) holds, that compliance is ignorable, that subjects in the placebo group have no access to treatment, and that the
residual X ; 0 (0 ) is not associated with covariates X within a given treatment arm R
(that is, f{X; 0 (0 )|X; R} =f{X; 0 (0 )|R}). Consider estimating equations of form (3).
The optimal function g(u; x) for estimation in SMMs is (x)X ; 0 (0 ).
Theorem 2 follows directly from Robins [6]. Fischer-Lapp and Goetghebeur [11] also
consider the eciency benets of using residuals X ; 0 (0 ) in SMMs.
We consider next the eciency benets of using compliance-based weights. The simple unweighted estimator proposed elsewhere uses equal weights w(x)=1, so we compare
compliance-based weights to these. Let  and  denote the mean and standard deviation of
, the eect of randomization on treatment received, and let  = = be the coecient of
ˆ w; q an estimator of 0 using weights w(x) and transformation q(), and
variation. Denote by 
2
by w; q its asymptotic variance. Theorem 3, proven in the Appendix, quanties the benets
of compliance-based weights over unweighted estimation in SDMs.
Theorem 3. Under the conditions of theorem 1, the relative eciency of the weighted
ˆ ; q and 
ˆ 1; q is 1;2 q =2 =1 + 2 .
and unweighted estimators 
; q

Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1290

M. M. JOFFE AND C. BRENSINGER

Figure 1. The relative eciency of the unweighted G-estimator compared to the weighted G-estimator
as a function of  ≡ (X = 1)=(X = 0), the ratio of the eects of randomization on treatment received
in the better and worse complying strata, for dierent values of  ≡ pr (X = 1), the proportion of the
population in the better-complying stratum.

Fischer-Lapp and Goetghebeur [11] have the same ndings for the more restricted estimators
of SMMs. When the eect of randomization on treatment received (X ) is constrained to be
non-negative, as one would usually expect in randomized trials, the greatest values of  are
obtained when a large part of the population has small values of (X ) and a small part of
the population has relatively large values of (X ). Although most trials seek to maximize
compliance and so (X ), small values of (X ) may be common in trials which seek to
modify ingrained behaviours (for example, diet or smoking); the MRFIT study is one example.
Consider for illustration a binary covariate X ; let  ≡ pr (X =1) denote the proportion of the
population in the better-complying stratum, and let  ≡ (X =1)=(X =0) be the ratio of the
eects of randomization on treatment received in the better and worse complying strata. The
coecient of variation  is ( − 1){(1 − )}1=2 = {( − 1) + 1}. Figure 1 plots the relative
eciency against the proportion of subjects  in the better complying stratum for dierent
values of the compliance ratio .
In deriving suggestions for functions g(·) to use in G-estimation, we have assumed ignorable non-compliance, a common distribution of the errors X ; A at dierent values of X ,
and a correctly specied model for a measure of central tendency 0 (X ). The eciency, but
not the consistency, of the suggested estimators depends on these assumptions. Under these
assumptions (ignorable non-compliance in particular), standard regression estimators which
compare groups based on treatment received may be consistent and more ecient than the
G-estimators. The primary advantage of G-estimation and other instrumental variables estimators over standard regression methods is that they can provide valid estimates and tests of
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

WEIGHTING IN G-ESTIMATION

1291

treatment eects even when non-compliance is not ignorable. Thus, it is useful to examine the
eciency of the estimating functions discussed above in settings where the derivation does not
justify the eciency of these estimators in general, and under non-ignorable non-compliance
in particular.
We performed a simulation study to examine these issues, considering settings where individual compliance is all-or-none. We varied many components of the model used to generate
the data: for a scalar binary covariate X , the probability  that X =1; for a potential outcome
Y (0), we let 0 (X )=X and let X ; A =X ; 0 be either a standard normal or a standard t (with
5 degrees of freedom) random variable; we assumed that treatment received followed the
logistic model logit {pA=1 | X; R=1; Y (0)} = A + XA + X ; 0 A , and varied all three parameters in the regression; A =0 implies ignorable non-compliance. For these simulations, we
assumed that subjects not assigned to treatment could not obtain treatment outside the study,
so pr (A=1 | R=0)=0.
Table I provides some results of the simulations. Notably, the inuence of dierent weighting schemes depended on what function h(u; x) was used in the estimation. When h(u; x)=
w(x)m(X ; A ), the weighting by (estimates of) (X ) did not decrease and often improved
the eciency of estimators compared with equal weights (w(X )=1); this was true even for
non-optimal functions m() = q(), as, for example, when m()= but the error function 
followed a 5 degree-of-freedom t-distribution. However, for other choices of h(u; x) (here,
h(y0 ; x)=q(y0 )), weighting by (X ) sometimes reduced eciency. The eciency advantages
of weighting by (X ) appear to extend to settings where non-compliance is not random.
In practical data analysis, neither the appropriate weights (X ) nor residuals X ; 0 () will be
known; none the less, one can estimate them from the data. One can use estimates of expected
compliance Ê(A | R; X ) to estimate (X ) as Ê(A | R=1; X ) − Ê(A | R=0; X ). Similarly, one can
regress U () on X to obtain putative means 0 (X ) and residuals X ; 0 (). Results from
Robins [6] imply that estimation of these regressions from the data does not aect asymptotic
eciency.
To see the potential pitfalls with this in small samples, consider the limit where no two
subjects share the same values of covariates X . One might be tempted to replace (X ) with
ˆ )= p̂(A=1 | X; R=1) − p̂(A=1 | X; R=0)=A; in this limit, the
the non-parametric estimate (X
approach becomes a ‘per protocol’ analysis, which can be biased if compliance is not ignorable. Thus, it is important to examine the validity (that is, bias and coverage properties) of
the method (using more reasonable estimators of (X )) in studies with moderate sample sizes.
Similar issues arise in the estimation of 0 (X ); we estimate 0 (X ) from the data {X; Y (0; )}
for each hypothesized value  for 0 . Figure 2 presents simulation results. For the situations
considered, there was little indication of substantial bias or poor coverage. For the settings
considered, the mean squared error and the estimated variance increased faster with decreasing
sample size when the true (X ) was used instead of its estimate, and 95 per cent condence
intervals covered more than at their nominal rate in small samples, especially when the true
0 (X ) was employed instead of its estimate.
5. THE LRC-CPPT TRIAL
We applied the methods discussed above to the Lipid Research Clinics Coronary Primary Prevention Trial (LRC-CPPT), a randomized placebo-controlled double-blind trial of CLT, a drug
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

Copyright ? 2003 John Wiley & Sons, Ltd.

0:0

−1:5

3.0

1.5

0.0

3.0

1.5

0.0

Intercept Baseline
covariates

1

0

1

0

1

0

1

0

1

0

1

0

Potential
outcome
∞
5
∞
5
∞
5
∞
5
∞
5
∞
5
∞
5
∞
5
∞
5
∞
5
∞
5
∞
5

Logistic regression parameters
Error
for compliance in
function ; d.f. of t
experimental group
distribution

Data generation process characteristics

Least squares (with
covariate control)

0.270
0.338
0.179
0.220
0.183
0.223
0.133
0.164
0.134
0.169
0.116
0.144
0.098
0.121
0.090
0.113
0.081
0.104
0.082
0.098
0.077
0.100
0.074
0.098

0.269
0.337
0.185
0.221
0.181
0.214
0.133
0.158
0.119
0.143
0.108
0.130
0.098
0.121
0.094
0.115
0.086
0.105
0.085
0.100
0.081
0.101
0.075
0.099

0.241
0.315
0.165
0.205
0.169
0.211
0.120
0.155
0.123
0.161
0.105
0.135
0.090
0.113
0.081
0.106
0.074
0.098
0.074
0.092
0.070
0.093
0.069
0.092

0.239
0.314
0.158
0.196
0.151
0.186
0.104
0.137
0.096
0.121
0.084
0.111
0.090
0.113
0.080
0.104
0.073
0.095
0.071
0.090
0.068
0.088
0.065
0.088

0.290
0.321
0.248
0.287
0.203
0.224
0.172
0.208
0.160
0.174
0.146
0.158
0.104
0.113
0.102
0.115
0.086
0.100
0.092
0.097
0.084
0.095
0.082
0.095

0.249
0.282
0.177
0.196
0.158
0.168
0.107
0.126
0.100
0.108
0.087
0.099
0.095
0.101
0.082
0.093
0.076
0.085
0.073
0.078
0.069
0.076
0.067
0.077

0.817
0.819
0.727
0.719
0.723
0.720
0.635
0.634
0.630
0.627
0.577
0.573
0.504
0.499
0.444
0.449
0.408
0.407
0.388
0.389
0.365
0.368
0.361
0.366

0.075
0.103
0.701
0.987
0.068
0.090
0.579
0.824
0.059
0.080
0.456
0.685
0.054
0.067
0.499
0.692
0.049
0.064
0.414
0.592
0.051
0.063
0.373
0.532

Y (0; ) Y (0; ) Y (0; ) {Y (0; )
tanh
tanh{Y (0; ) Intent-to-treat As treated
ˆ ) −(X ) −(X )}(X
ˆ ) {Y (0; )} −(X )}(X
ˆ )
(X

G-estimators; functions g{Y (0; ); X }

Estimators

Table I. Root mean squared error of various G-estimators and least-squares estimators.

1292
M. M. JOFFE AND C. BRENSINGER

Statist. Med. 2003; 22:1285–1303

1293

WEIGHTING IN G-ESTIMATION

Figure 2. Empirical root-mean squared error and condence interval coverage from simulations. The left-hand panel plots the empirical root mean squared error (scaled by the
square root of the sample size) of dierent G- estimators of , and the right-hand panel
plots the coverage proportion of condence intervals from the same estimators, under two
sets of circumstances. In each case the estimators dier only in whether they use the true
or estimated values of the covariate X -specic eect (X ) of randomization on treatment
received and the conditional mean of U () (or Y (0)) given covariates X .

used to lower cholesterol levels and, thereby, the risk of coronary events and death [13, 14].
Efron and Feldman [25] used a subset of this study to examine the eect of compliance; we
apply dierent methods towards the same end.
In the LRC-CPPT, serum cholesterol was measured at several prerandomization and at
bimonthly postrandomization clinic visits for the duration of follow-up, which averaged 7.4
years. These clinic visits were also used to dispense packets of their assigned medication;
patients returned unused packets at each clinic visit. The proportion of packets used is a
measure of compliance.
As above, our endpoint is the serum cholesterol at the end of a xed follow-up period, here
one year (400 days). We use as a scalar measure of the treatment received over the year (A)
the proportion of the total potential number of packets (number of days × 6 packets= day) used;
for subjects who were prescribed reduced doses because they could not tolerate the drug, this
variable is not identical to per cent compliance, such as used by Efron and Feldman [25].
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1294

M. M. JOFFE AND C. BRENSINGER

Figure 3. A histogram of the distribution of the model-based values of the covariate-X specic eect
(X ) of randomization on treatment received from the LRC-CPPT.

We used the continuation ratio model [26] to model compliance with CLT (divided into
several ordered categories) in the treatment arm as a function of pretreatment covariates X ,
ˆ ), the
which included age, race, sex and centre. We used the model coecients to compute (X
stratum-specic eect of randomization on CLT received. Figure 3 illustrates the distribution
ˆ ) for all subjects in the study; although there is substantial variation, the coecient of
of (X
variation ˆ is only 9.5 per cent. We used standard regression methods to model U () as
a function of covariates; the strongest predictor of post-treatment cholesterol is pre-treatment
cholesterol, which is included in X .
Table II presents dierent G-estimates of 0 . Because of the large number of subjects in the
study, eciency is not an important concern here; none the less, the estimator using the natural
transformation m()=, compliance-based weighting, and, most importantly, residuals from the
regression of Y () on X has the smallest estimated variance. As would be expected when
ˆ ) improves eciency only slightly. Using the residuals from a
 is small, weighting by (X
ˆ on X (that is, using h(u; x)=m()w(x) instead of h(u; x)=m(u)w(x)) did
regression of U ()
improve eciency. Use of ‘robust’ estimators m()= tanh−1 (= ) did not change the point
estimates substantially but did increase the estimated variance.
ˆ against the proportion of the nominal dose of the asFigure 4 plots the residuals X ; 0 ()
signed treatment taken (in the treatment arm, this is A) in both arms and restricted quadratic
regression spline estimates of the mean residuals at dierent compliance levels. These plots
have implications both for G-estimation analysis using structural nested models and for standard regression approaches. The variability of the residuals is greater in the treatment than
the placebo arm, especially for subjects with more than the lowest level of compliance. Efron
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1295

WEIGHTING IN G-ESTIMATION

Table II. Various estimates of the eect of cholestyramine on log cholesterol, using LRC data.
Characteristics of estimator
Use residual from
regression

Robust transformation
m() = tanh−1 () used?

Estimates

If so,
divisor
coecient

Compliance
used to
weight

Point
estimate

Standard
error

No
Yes
No
Yes
No
Yes
Yes
Yes

−0:07866
−0:08019
−0:07994
−0:08010
−0:07994
−0:08010
−0:08016
−0:07778

0.00290
0:01068
0.00233
0.00232
0.00248
0.00232
0.00247
0.00314

−0:05763
−0:08763
−0:08889

0.00224
0.00256
0.00205

G-estimators
No

No

Yes

No
Yes

0.1
1
0.1
0.02

Least-squares estimators
Control for baseline cholesterol?
Intent to treat
As treated

No
No
Yes

and Feldman [25] noted the same phenomenon. These observations are not consistent with
(even a non-deterministic version of) SDM, (1)–(2) under which the variability in both arms
should be the same. This provides reason to prefer the weaker SMM and so G-estimators that
use linear functions m()=.
ˆ than poor
In both arms, subjects who comply well tend to have lower residuals X ; 0 ()
compliers. If the model for treatment eect is true (that is, in the placebo arm, compliance
has no eect), both arms provide some evidence against ignorable compliance. Thus, standard
regression analyses using treatment received as a regressor overestimate the benet of CLT
for lowering cholesterol (Table II).
There are also graphical checks of model assumptions. For example, Joe et al. show
elsewhere [24] that, under our simple SDM or SMM (1) E {Y | (X ); R=1}−E {Y | (X ); R=0}
=(X ). Thus, one could plot the dierence between smoothed estimates, E {Y | (X ); R=1}−
E {Y | (X ); R=0}, against the compliance score (X ). If the model is correct, the plot should
be a straight line through the origin with slope . Figure 5 provides such a plot; there is
slight evidence of deviation from linearity and of a non-zero origin. Alternatively, one could
ˆ |X; R=1}− E {U ()
ˆ |X; R=0} against a scalar component
plot the smoothed dierence E {U ()
ˆ | X }, or the compliance score. Under the
of X or some function of X ; for example, E {U ()
model (or any correctly specied SDM), the plot should be a horizontal line.
6. MODEL ELABORATION
This section considers various elaborations on our simple structural model (1). These more
elaborate models may be used to check the assumptions of the simpler model.
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1296

M. M. JOFFE AND C. BRENSINGER

Figure 4. Scatter plots of compliance with the prescribed regimen (per cent of prescribed doses
taken; this is A for subjects in the treatment arm) versus the residual from the regression of U ()
on covariates X . Point estimates and pointwise 95 per cent condence intervals from a regression
spline of the residual on compliance are overlaid. The end of the boxplot whiskers show the 5th
and 95th percentiles of the residual for subjects in each category of compliance (0–20 per cent,
20–40 per cent, 40–60 per cent, 60–80 per cent, 80–100 per cent).

In many settings, analysts may wish to allow treatment eects to vary with levels of other
baseline covariates. A generalization of the one parameter model (1) is
0 (X; R; A)=A (X; R; A) − 0 X ∗ A

(4)

where X ∗ is a vector function of pre-treatment covariates X (which can include a constant 1)
and 0 is a vector parameter. In this case, replace the scalar g(u; x) by a vector function g(u; x)
and sum in (3). One choice of functions is g(u; x)=w(x)q()x∗ ; again a product of a scalar
weight, a function of the residual, and the vector function x∗ of x. As previously, under the
same additional assumptions about the residual variance, the most ecient estimating function
is obtained by choosing compliance-based weights (X ) and optimal function q∗ ().
We chose to t model (4) to the LRC-CPPT data. In particular, we tested whether (centred)
baseline log cholesterol, the most potent baseline predictor of outcome Y , modied the eect
of treatment received and so included it in model (4); that is, X ∗ here is the two-vector
{1; cblogchl}. The point estimate (standard error) for the interaction term is 0.060 (0.056).
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1297

WEIGHTING IN G-ESTIMATION

Figure 5. Plots of the empirical ITT dierence between treatment and control groups within strata of
ˆ ). There are also two separate linear regression-based estimates; one
the estimated compliance score (X
constraining the line to go through the origin, one not.

In models (1) and (4), the eect of treatment received is proportional to the dose received.
To test this assumption, we can consider non-linear ‘dose–response’ relationships. Such a
two-parameter generalization of (1) is
0 (X; R; A)=A (X; R; A) − 0 A − 1 A2

(5)

The model can again be t by G-estimation. Consider again functions of the form g(u; x)=
w(x)q(); here, w(x) is now a vector. The optimal function w(x) is {(X ); (X )},
where (X ) ≡ E(A2 |X; R=1) − E(A2 |X; R=0).
In the LRC-CPPT, we tested whether the eect of treatment received is proportional to the
dose received; that is, if 1 =0. Using the optimal weights, we obtain point estimates (standard
errors) for 0 and 1 of −0:006 (0:085) and −0:100 (0:113); there is little evidence (p=0:37)
against the simpler model.

7. EXPLANATORY AND PRAGMATIC ESTIMATES
We have so far adopted an explanatory attitude towards G-estimation and structural nested
models, in which the analysis attempts to explain dierences between randomized groups in
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1298

M. M. JOFFE AND C. BRENSINGER

terms of the eects of treatment received [8]. When the goal is merely explanatory, it makes
little dierence whether changes from the nominally assigned dose should be classied as
non-compliance, or whether the eects in compliant and non-compliant individuals are the
same.
Randomized trials are usually run to provide guidance in how to treat patients. These
explanatory analyses do not directly answer the question of our motivated subject, or the
questions of the planner who would like to anticipate what would happen were the treatment to
be introduced into general practice. After a trial is completed the patterns of treatment received
among people assigned to it may dier from the patterns observed in the treatment arm in
the trial. For example, treatments to palliate unpleasant side-eects may become available,
making it feasible and possibly desirable for subjects to continue with the assigned treatment
[27]; further, compliance even in a similar population could be higher after a treatment is
accepted as ecacious or lower without the encouragement given in a randomized trial [28].
To anticipate what might happen in practice, one must compare a wider variety of potential
outcomes and consider more than the observed outcome Y (A) and baseline outcome Y (0). It
is thus tempting to extend the models for treatment eects to all potential outcomes Ya ; for,
example, (1) generalizes naturally to
a (X; R; A)=0 (X; R; A) + 0 a

(6)

Such models attempt to determine the potential eects of any arbitrary treatment regime on
outcome. Note that formulation (6), which is more ambitious, implies (1), but not vice versa.
Comparisons of E(Y1 ) and E(Y0 ), including average treatment eects E(Y1 −Y0 )=E(Y1 )−E(Y0 ),
are implied by (6) but not by (1). (6) makes the untestable (given the data as described)
assumption that the eects of additional increments of treatment are the same among people
whose observed treatment A=a and those whose observed treatment A¡a; that is, among
subjects with better and worse compliance.
Suppose that the reasons for non-compliance in the treatment group are associated with
side-eects, and that the level of side-eects is related to the anti-cholesterol eects at a
given dose (both might be inuenced by variability in metabolism of the drug). Then, one
might expect the magnitude of expected individual treatment eects E(Ya − Y0 | X; R; A) to be
decreasing (or at least non-increasing) in A, and ignorable compliance would fail to hold.
This does not necessarily invalidate structural model (1) (or more complicated functions like
(5)), whose applicability is subject to empirical investigation, as above. However, under this
scenario of non-ignorable non-compliance, (6) will not generally hold; Robins [19] terms this
phenomenon current treatment interaction.
Consider examining the sensitivity of pragmatic conclusions to the assumption. We generalize (6) to allow the eect that additional treatment (beyond A, what the subject has in fact
taken) to be a proportionally smaller than the realized eect of the treatment already taken.
One such model is
a (X; R; A) = 0 (X; R; A) + 0 a;

a6A

a (X; R; A) = 0 (X; R; A) + 0 (a − A); a¿A

(7)

where is the relative eect of additional treatment, compared to the realized eect of treatment received. The data provide no information about .
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1299

WEIGHTING IN G-ESTIMATION

Table III. Estimates of eect of encouragement to use CLT on log cholesterol, under dierent assumptions about eects of additional CLT, on how much compliance can be improved.
How much can
encouragement aect

Extra eect ( ) of additional compliance
for subjects with improvable compliance

compliance?
None (a = A)
30 per cent improvement (a = (A + 1)=2)
100 per cent improvement (a = 1)

0

36892

1

−0:058
−0:058
−0:058

−0:058
−0:061
−0:068

−0:058
−0:064
−0:079

In a pragmatic analysis, one might want to predict the mean outcome under dierent but
attainable compliance conditions than those observed in the study. This involves speculation
not only about the relative extra eect but also about what compliance levels are attainable.
We used model (7), together with dierent assumptions about the attainable improvement
in compliance, to predict the mean (log) cholesterol that would have been seen had subjects
complied dierently with their assigned treatments and so speculate what gains might be
attainable in practice. Table III shows the expected means under dierent assumptions about
these unknown quantities. If =0 or no improvement in compliance is possible, the intent-totreat eect is also the pragmatic eect. If =1 and full compliance is possible, the G-estimate
of 0 is also the pragmatic estimate. Intermediate values of the relative eect and of how
much compliance can be improved produce intermediate attainable gains due to CLT.

8. DISCUSSION
The increased eciency of weighted estimators is potentially useful for both explanatory
and pragmatic analysis. Better weights can result in more power against the null. It is often
claimed in trials with negative results that, had compliance been better, the experimental
treatment might have appeared more benecial than the analysis performed suggests. The
approach suggested here focuses attention on strata with better compliance, in which poor
compliance cannot easily explain the absence of dierences between randomized groups; thus,
the weighting approach suggested here can permit better assessment of the reasonableness of
such explanations of negative ndings.
Our approach is complementary to the more standard ITT approach. In fact, tests of the
null using both compliance-based weighting and the adjustments we have indicated for pretreatment covariates X as predictors of the potential outcome Y0 are still ITT tests of the
null hypothesis. The tests have the correct size under the null, since only their eciency,
but not their validity, depends on the distributions of compliance f(A | X; R) and the potential
outcome f(Y0 | X ). Thus, our approach will not be inconsistent with an appropriately powerful
ITT test of the null hypothesis, and will not nd a positive eect if an appropriate ITT test
does not.
Our approach may sometimes be inconsistent with non-parametric ITT estimates of eect
(that is, simple comparisons of the randomized groups). Our measures of treatment ecacy
will generally be farther from the null than simple ITT estimates of eectiveness. Because
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1300

M. M. JOFFE AND C. BRENSINGER

our estimates depend on modelling assumptions while the simpler ITT estimates do not, we
suggest that both be reported in the presence of non-compliance.
Other investigators have also proposed compliance-based weighting schemes [9–12]. Our
approach generalizes the work of Goetghebeur and Lapp [10] and Fischer-Lapp and Goetghebeuer [11], who consider only the identity transformation of the error function, m()=.
Their restriction of the functions m() is dictated by the use of a structural nested mean model
[6] rather than the stronger structural nested distribution model [19, 29]. Using non-identity
functions m() can increase eciency and reduce sensitivity to outliers in Y or  when the
stronger SDM holds.
Most of the methodologic ndings are consequences of the very general theory developed
by Robins. None the less, the application of this theory to specic situations has not been
worked out explicitly in many cases. In particular, formulae developed previously [11] do
not explicitly identify the compliance score and its role or importance in the broader array of
settings considered here (that is, in settings where robust estimators are used or placebo-group
subjects have access to the active treatment).
There are competing considerations in the choice of the function g(u; x) to include in
the estimating equations (3) and whether to use compliance-based weights. Analysts using
G-estimation for structural nested models may need to formulate and t several models: the
structural models themselves; the model for treatment assignment/randomization, the model
for compliance, and the model for the baseline outcome Y0 given baseline covariates. Each
model to be t takes the some of the investigator’s limited resources and complicates explanation of the procedures used. Thus, it is useful to know when the eort invested is likely
to yield substantial eciency benets. Our results help determine when the extra eort will
yield those substantial benets. However, even when compliance-based weights will not substantially improve eciency, understanding why subjects fail to comply may be of scientic
and practical interest.
It is worth comparing our assumptions to those of other methods proposed for dealing
with non-compliance. Efron and Feldman [25] proposed an approach not explicitly using the
potential outcomes approach for derivation. A primary assumption in their approach is that
someone in the jth percentile of the compliance distribution in the treatment arm would have
been in the jth percentile of compliance had he been in the placebo arm, and vice versa. Our
approach makes no corresponding assumption, which is hard to justify if side-eects of the
treatment are important determinants of non-compliance.
The approach of Angrist et al. [2] and Imbens and Rubin [22] is more similar. Their
approach assumes that compliance is all-or-none; this is a special case in our approach.
They sometimes further assume that there are no deers (that is, subjects who would receive
treatment if and only if randomized to placebo); our corresponding assumption is that the eect
in deers and compliers (subjects who would receive treatment if and only if randomized to
treatment) is the same. If, as in the LRC-CPPT, subjects randomized to placebo cannot receive
treatment, the assumption is not necessary. Under the assumption that there are no deers, their
estimator and our simple estimator (no weights or residuals) are asymptotically equivalent.
In most studies of pharmaceutical agents, compliance is not a one-time event but rather
may vary over time, even from day to day. The discussion above postulates that the average
level of compliance with the prescribed regimen, but no other aspect of treatment received,
determines response to treatment. This will often not be the case; in particular, when postrandomization clinical course inuences treatment received, there will likely be non-random
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1301

WEIGHTING IN G-ESTIMATION

uctuations in compliance level over time. In such settings, one might want to consider
explanatory alternatives to the simple model that allow the eects of treatment received at
dierent times to depend on the time of treatment (in relation to the end of the study); Robins
provides a class of such models, the structural nested models, and extends the estimation
procedures described here to those settings [30]. Again, it is possible to develop G-estimators
which provide more weight to compliant strata than non-compliant ones. Here, the form of
the optimal estimators will often be intractable; we would expect compliance-based estimators
to be both simple and often reasonably ecient.
Our use of the terms explanatory and pragmatic diers somewhat from previous uses in
the literature [18]. We do not identify ‘as treated’ as explanatory, because invalid estimates
of treatment eect explain nothing. Similarly, for the reasons noted above, intent-to-treat are
not necessarily pragmatic. The G-estimation=instrumental variables approach presented here
provides a unied approach to explaining associations observed in randomized trials and to
predicting the eects of a future intervention or treatment; the latter task is more ambitious
and requires additional assumptions or a sensitivity analysis.
For both goals, information on treatment received and on pre-treatment covariates is potentially useful. Information on treatment received allows for better-justied explanatory analysis
than ‘as treated’ analyses and its variants, permits more powerful ITT analyses, and provides
a basis for better justied and understood pragmatic analyses. The gain in power and precision
for the approach sketched here requires measurement of pre-treatment covariates X that predict
compliance; the gain will likely be most dramatic in studies with substantial non-compliance
and identiable strata with substantially better compliance.

APPENDIX: OUTLINE OF PROOFS OF THEOREMS
Theorem 1


Using a 
Taylor series expansion, rewrite the estimating
equations (3) as 0= {R − p}q{()}

w(X
 )= {R − p}q{(0 )}w(X ) + ( −0 ) {R − p}[@q{(0 )}=@0 ]w(X ). Let B(w) ≡
{R − p}q{(0 )}w(X ) and let C(w) ≡ {R − p}[@q{(0 )}=@0 ]w(X ). For a given choice
of weights, the variance V (w) of the resulting estimator is var{B(w)}=[E {(C(w))}]2 . Now
var{B(w)} =E[var{B(w) | X; }] + var [E {B(w) | X; }]=E[var{B(w) | X; }] (because randomization guarantees that E(B | X; )=0).
 Let Bi ≡ {R − p}q{(0 )}w(X ); because the subjects
are i.i.d., write var{B(w) | X; } = var (Bi | X; ). Now var (Bi | X; )=w(X )2 q()2 var (R − p | X )
=w(X )2 q()2 p(1 − p); then var (Bi | X )=E {var (Bi | X; )} =K1 w(X )2 p(1 − p), where K
1 ≡
E {q()2 }, a constant not dependent on X . Treating the X ’s as xed, we obtain var (B)=K1 w
(X )2 p(1 − p).

Let Ci ≡ {R − p}[@q{(0 )}=@0 ]w(X ); then E(C)= E(Ci ). Because @(0 )=@0 = − A,
E(Ci | R; X; )= {R − p}w(X )E([@q{(0 )}=@0 ] | R; X; )= −{R − p}w(X )q ()E[A |R; X; ]. Under random non-compliance, E(A | R; X; )=E(A | R; X ), so E(Condence interval | R; X; ) simplies to −{R − p}w(X )q ()E(A | R; X ). Let K2 ≡ − E {Q ()}, which is independent of
R and X under random non-compliance. Summing over the distributions of  and R successively, we obtain E(Ci | R; X )=K2 (R − p)w(X )E(A | R; X ) and E(Ci | X )=K2 w(X )E {(R −
p)E(A
| R; X )|X } =K2 w(X )p(1 − p)(X ). Treating the X ’s as xed leads to E(C)=K2

p(1 − p)w(X )(X ).
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

1302

M. M. JOFFE AND C. BRENSINGER

We now seek to nd the weights w which minimize the variance of var (B)= {E(C)}2 . Let
X0 denote an arbitrary reference stratum dened by covariates X . Without loss of generality, let w(X0 )=1. The variance is maximized when the derivatives @V (w)=@w(X )=0 for all
X =X0 , which in turn happens when [@ var{B(w)}=@w(X )]{E(C(w))}2 =2var{B(w)}E(C(w))
[@E {C(w)}=@w(X )]. which in turn implies [@ var{B(w)}=@w(X )]E {C(w)} =2var{B(w)}[@E {C
2K1 w(X )p(1 −
(w)}=@w(X
 )]. Substituting in the expressions forB(w) 2and C(w) leads to 
)(X
)=2K
p(1
−
p)(X
)K
w(X
)
p(1
−
p).
Let
K
≡
p(1−p)w(X )
p)K2 p(1−p)w(X
2
1
3

(X ) and K4 ≡ w(X )2 p(1−p). Further reorganization leads to w(X )=(X )(K4 =K3 ) ∝ (X ),
yielding a solution w(X )=(X )=(X0 ).
Although in practice neither the eect of randomization on treatment received (X ) nor
the residual 0 () will be known precisely, it follows from Robins et al. [31] that replacing
these quantities by consistent estimates thereof does not aect the asymptotic variance.
Theorem 3
ˆ w; q with weights w(X ) and a common distribution
From above, we have, for an estimator 


2
ˆ
of errors that var (w; q )=K1 w(X ) p(1 − p)= {K2 p(1 − p)w(X )(X )}2 . Because K1 and
K2 do not depend on the weighting scheme, and, in a randomized trial, there is a common
ˆ w; q ) ∝ E {w(X )2 }=[E {w(X )(X )}]2 ; the
value for p, we can write, taking expectations var (
ˆ ; q )=[E {(x)}]−2 =[E {(x)2 }]−1 =1 + 2 .
relative eciencies are then var (ˆ 1; q )= var (
(X )

ACKNOWLEDGEMENTS

The author thanks Drs Basil Rifkind, David Gordon and Michael Hartman for assistance in obtaining
data from the LRC-CPPT study, and Dr James Robins and a referee for useful comments. This work
was funded by a grant from the National Heart, Lung and Blood Institute (R29 HL59184).

REFERENCES
1. Lee YJ, Ellenberg JH, Hirtz DG, Nelson KB. Analysis of clinical trials by treatment actually received: is it
really an option? Statistics in Medicine 1991; 10:1595– 1605.
2. Angrist JD, Imbens GW, Rubin DB. Identication of causal eects using instrumental variables (with discussion).
Journal of the American Statistical Association 1996; 91:444 – 472.
3. Baker SG, Lindeman KS. The paired availability design: a proposal for evaluating epidural analgesia during
labor. Statistics in Medicine 1994; 13:2269 –2278.
4. Mark SD, Robins JM. A method for the analysis of randomized trials with compliance information: an application
to the multiple risk factor intervention trial. Controlled Clinical Trials 1993; 14:79 –97.
5. Robins JM, Tsiatis AA. Correcting for non-compliance in randomized trials using rank preserving structural
failure time models. Communications in Statistics – Theory and Methods 1991; 20:2609 –2631.
6. Robins JM. Correcting for non-compliance in randomized trials using structural nested mean models.
Communications in Statistics – Theory and Methods 1994; 23:2379 –2412.
7. Sommer A, Zeger SL. On estimating ecacy from clinical trials. Statistics in Medicine 1991; 10:45 –52.
8. White IR, Goetghebeur EJ. Clinical trials comparing two treatment policies: which aspects of the treatment
policies make a dierence. Statistics in Medicine 1998; 17:319 –339.
9. Cuzick J, Edwards R, Segnan N. Adjusting for non-compliance and contamination in randomized clinical trials.
Statistics in Medicine 1997; 16:1017 – 1029.
10. Goetghebeur E, Lapp K. The eect of treatment compliance in a placebo-controlled trial: regression with unpaired
data. Applied Statistics 1997; 46:351 –364.
11. Fischer-Lapp K, Goetghebeur E. Practical properties of some structural mean analyses of the eect of compliance
in randomized trials. Controlled Clinical Trials 1999; 20:531 – 546.
12. Zelen M. Randomized consent designs for clinical trials: an update. Statistics in Medicine 1990; 9:645 – 656.
Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

WEIGHTING IN G-ESTIMATION

1303

13. Lipid Research Clinic Program. The Lipid Research Clinics Coronary Primary Prevention Trial results. I.
Reduction in incidence of coronary heart disease. Journal of the American Medical Association 1984; 251:
351 –364.
14. Lipid Research Clinic Program. The Lipid Research Clinics Coronary Primary Prevention Trial results. II. The
relationship of reduction in incidence of coronary heart disease to cholesterol lowering. Journal of the American
Medical Association 1984; 251:365 –374.
15. Heckman J. Instrumental variables: a study of implicit behavioral assumptions used in making program
evaluations. Journal of Human Resources 1997; 32:441 – 462.
16. Philipson T, Desimone J. Experiments and subject sampling. Biometrika 1997; 84:619 – 630.
17. Friedman L, Furberg C, DeMets D. Fundamentals of Clinical Trials. 3rd edn. Springer-Verlag: New York 1998.
18. Newcombe RG. Explanatory and pragmatic estimates of the treatment eect when deviations from alloated
treatment occur. Statistics in Medicine 1988; 7:1179 – 1186.
19. Robins JM, Rotnitzky A, Scharfstein DO. Sensitivity analysis for selection bias and unmeasured confounding in
missing data and causal inference models. In Statistical Models in Epidemiology, Halloran E, Berry D (eds).
Springer-Verlag, New York 2000:1 –99.
20. Rosenbaum PR, Rubin DB. The central role of the propensity score in observational studies for causal eects.
Biometrika 1983; 70:41 –55.
21. Robins JM. Causal inference from complex longitudinal data. In Lecture Notes in Statistics-Latent Variable
Modeling with Applications to Causality, Berkane M (ed.). Springer-Verlag: New York, 1997;69 – 117.
22. Imbens GW, Rubin DB. Bayesian inference for causal eects in randomized experiments with noncompliance.
Annals of Statistics 1997; 25:305 –327.
23. Follmann DA. On the eect of treatment among would-be treatment compliers: an analysis of the multiple risk
factor intervention trial. Journal of the American Statistical Association 2000; 95:1101 – 1109.
24. Joe MM, Ten Have TR, Brensinger C. The compliance score as a regressor in randomized trials. Biostatistics
2003;(in press).
25. Efron B, Feldman D. Compliance as an explanatory variable in clinical trials (with discussion). Journal of the
American Statistical Association 1991; 86:9 –26.
26. Greenland S. Alternative models for ordinal logistic regression. Statistics in Medicine 1994; 13:1665 –1677.
27. Robins JM, Greenland S. Adjusting for dierential rates of prophylaxis therapy for PCP in high- versus lowdose AZT treatment arms in an AIDS randomized trial. Journal of the American Statistical Association 1994;
89:737 –749.
28. Robins JM. The analysis of randomized and non-randomized AIDS treatment trials using a new approach to
causal inference in longitudinal studies. In Health Service Research Methodology: A Focus on AIDS, Sechrest
LA (ed.). NCHSR, U.S. Public Health Service: 1989; 113 – 159.
29. Robins JM. Marginal structural models versus structural nested models as tools for causal inference. In:
Statistical Models in Epidemiology: The Environment and Clinical Trials. Halloran ME, Berry D (eds.).
Springer-Verlag: New York, 1999; 95–134.
30. Robins JM. Testing and estimation of direct eects by reparameterizing directed acyclic graphs with structural
nested models. In Computation, Causation, and Discovery, Glymour C, Cooper G (eds.). AAAI Press/The MIT
Press: Menlo Park, CA, 1999; 349 – 405.
31. Robins JM, Mark SD, Newey WK. Estimating exposure eects by modelling the expectation of exposure
conditional on confounders. Biometrics 1992; 48:479 – 495.

Copyright ? 2003 John Wiley & Sons, Ltd.

Statist. Med. 2003; 22:1285–1303

