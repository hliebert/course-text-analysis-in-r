Econometrica, Vol. 75, No. 2 (March, 2007), 537–551

NOTES AND COMMENTS
ESTIMATION OF AVERAGE TREATMENT EFFECTS
WITH MISCLASSIFICATION
BY ARTHUR LEWBEL1
This paper considers identification and estimation of the effect of a mismeasured
binary regressor in a nonparametric or semiparametric regression, or the conditional
average effect of a binary treatment or policy on some outcome where treatment may
be misclassified. Failure to account for misclassification is shown to result in attenuation bias in the estimated treatment effect. An identifying assumption that overcomes
this bias is the existence of an instrument for the binary regressor that is conditionally
independent of the treatment effect. A discrete instrument suffices for nonparametric
identification.
KEYWORDS: Binary regressor, program evaluation, treatment effects, misclassification, contamination bias, measurement error, binary choice, binomial response.

1. INTRODUCTION
THIS PAPER PROVIDES CONDITIONS for identification and estimation of the average effect, conditioned on covariates, of a binary treatment, program, or policy on a scalar outcome when treatment may be misclassified. More generally,
what is provided is an estimator of the effect of a binary regressor in a conditional mean regression (which may also include other regressors) when the
binary regressor is observed with error. This equals the conditional average
treatment effect given a weak unconfoundedness assumption.
Misclassification occurs when a binary variable (the treatment indicator) is
measured with error, that is, some units are reported to have received treatment when they actually have not, and vice versa. For example, in a returns to
schooling analysis the outcome could be wages, the binary variable could be
attaining a college degree, and misclassification could arise from school transcript reporting errors. See, e.g., Kane and Rouse (1995) and Kane, Rouse, and
Staiger (1999). Bollinger (1996) considers misclassification of union status in
wage equations. If treatment is a job training program, misclassification may
arise if individuals assigned to the program fail to attend or if those not assigned obtain training elsewhere. Similarly, for medical treatment, individuals
assigned a drug might fail to take it and those assigned a placebo might obtain
treatment from another source. More generally, misclassification describes any
binary variable that is sometimes mismeasured.
This paper first shows that misclassification causes attenuation bias in estimated treatment effects, analogous to the attenuation bias of classically mismeasured variables in linear regression models. Additional assumptions on
1
I wish to thank Todd Prono for excellent research assistance, Alberto Abadie, Jinyong Hahn,
Francesca Molinari, James Heckman, a co-editor, and anonymous referees for many helpful comments. Any errors are my own.

537

538

ARTHUR LEWBEL

the existence of an instrument are then provided that identify misclassification probabilities and the true probability of treatment (conditional on covariates), in addition to identifying the conditional average treatment effect.
Corresponding estimators are variants of Hansen’s (1982) generalized method
of moments (GMM).
Let Y be an outcome, let X be a vector of covariates, and let T ∗ be an unobserved true treatment indicator or, more generally, let T ∗ be any unobserved
binary variable that affects Y and can only equal zero or one. Define
(1)

h∗ (X T ∗ ) = E(Y |X T ∗ )

Hence h∗ (X T ∗ ) is the conditional mean outcome, given X and treatment T ∗ .
Since T ∗ is binary, we may without loss of generality rewrite the conditional
mean outcome as
(2)

h∗ (X T ∗ ) = h∗0 (X) + τ∗ (x)T ∗ 

where h∗0 (X) = h∗ (X 0) and
(3)

τ∗ (x) = h∗ (x 1) − h∗ (x 0)

Assume we observe draws of Y , X, and T but not of T ∗ . The binary variable T is a proxy for T ∗ that is subject to measurement error. Misclassification
occurs when T = T ∗ . If T ∗ were observed instead of T , then h∗ (X T ∗ ) and
hence τ∗ (x) would be identified and could be estimated by nonparametric regression.
Das (2004) identifies and estimates 
h(X T ) = 
h0 (X) + 
τ(x)T in the model

Y = h(X T ) + e, where E(e|X) = 0. Estimation is then based on E(Y |X) =

τ(x)E(T |X). The Das model allows T to be correlated with e. Similar
h0 (X) +
estimators of models with endogenous binary regressors include Newey and
Powell (2003) and Florens and Malavolti (2003). The Das estimator cannot be
applied in the present context, because here E(Y |X) = h∗0 (X)+τ∗ (x)E(T ∗ |X)
and, unlike the case with classically mismeasured variables (see, e.g., Aigner
(1973)), with a mismeasure T of a binary regressor T ∗ , E(T |X) = E(T ∗ |X).
Let X = (Z V ). Mahajan (2005) obtains identification of h∗ (x t) assuming that E(Y |Z V  T ∗ ) = E(Y |Z T ∗ ) and that E(T ∗ |Z V ) = E(T ∗ |Z), so V
is essentially an instrument that correlates with the true probability of treatment but is conditionally mean independent of the outcome. Hu (2005) obtains identification of h∗ (x t) under similar assumptions for multiple valued
discrete treatments t and weakens some of Mahajan’s side conditions.
The present paper focuses on identifying and estimating τ∗ (x), the effect
on Y of changing T ∗ . I will refer to τ∗ (x) as the conditional outcome treatment
effect, or just the treatment effect, although formally it is just the change in the
conditional mean of Y that results from changing the binary variable t ∗ from

TREATMENT EFFECTS

539

zero to one, holding x fixed, and only equals a true treatment effect when an
unconfoundedness condition holds, as discussed later.
Define the mismeasured (treatment) effect τ(x) = h(x 1) − h(x 0) where
h(X T ) = E(Y |X T ). Theorem 1 shows that under some general conditions
τ(x) = m(x)τ∗ (x), where 0 ≤ m(x) ≤ 1, so mismeasurement of the treatment
indicator results in attenuation bias, that is, the mismeasured estimate τ(x)
of the true treatment effect τ∗ (x) is biased toward zero. Related results include Klepper (1988), Manski (1990), Bollinger (1996), and Hotz, Mullin, and
Sanders (1997).
Theorem 2 then provides sufficient conditions for identifying and estimating the function m(x) and, hence, the true treatment effect τ∗ (x). As in
Mahajan (2005), again let X = (Z V ) and assume E(T ∗ |Z V ) = E(T ∗ |Z),
but replace Mahajan’s assumption that E(Y |Z V  T ∗ ) = E(Y |Z T ∗ ) with the
weaker assumption that E(Y |Z V  T ∗ = 1) − E(Y |Z V  T ∗ = 0) = E(Y |Z
T ∗ = 1) − E(Y |Z T ∗ = 0). Equivalently, rewriting equation (2) as h∗ (X T ∗ ) =
h∗0 (Z V ) + τ∗ (Z V )T ∗ , Mahajan assumes that both h∗0 (Z V ) and τ∗ (Z V ) do
not depend on V , whereas this paper assumes only that τ∗ (Z V ) does not depend on V . For example, a standard regression model where h∗ (x t) is linear
in its arguments with nonzero coefficients will satisfy this paper’s assumption
but violate Mahajan’s assumption. Another example is relating wages Y to
schooling T ∗ using a Card (1995, 1996) type distance to school instrument V .
The present paper would only require that V be conditionally independent
of the increase in wages associated with schooling, rather than conditionally
independent of the level of wages. The latter Mahajan requirement could be
violated if, e.g., access to schooling is correlated with access to higher paying
jobs on average (this example assumes other possible problems associated with
distance to schooling such as those described by Carneiro and Heckman (2002)
can be ignored).
Nonparametric identification will not require a continuous instrument, so
V can be discrete, but it will be required that V take on at least three values.
In contrast, Mahajan (2005) requires only a binary valued instrument. Some
intuition for this result is that V affects the true probability of treatment, and
under Mahajan’s assumptions, a change in V affects Y only through this effect
on T ∗ . In contrast, this paper allows V to affect Y both through T ∗ and through
h∗0 (Z V ), so two different changes in V must be observable to separate these
effects.
2. RELATING TRUE AND MISMEASURED EFFECTS OF TREATMENT
Let Y (t) denote the outcome from treatment T ∗ = t for t = 0 1. If
(4)

E[Y (t)|T ∗  X] = E[Y (t)|X]

then τ∗ (x) = E[Y (1) − Y (0)|X = x], which is the conditional average treatment effect. Equation (4) is a weak version of the Rubin (1978) or Rosenbaum

540

ARTHUR LEWBEL

and Rubin (1984) unconfoundedness assumption with respect to the true treatment T ∗ . See, e.g., Heckman, Ichimura, and Todd (1998) for a discussion of this
and similar results. In what follows, equation (4) is not imposed. If it does hold
where T ∗ is a treatment indicator, then τ∗ (x) is the conditional average treatment effect; otherwise, τ∗ (x) is just the effect on the mean of Y of changing a
binary T ∗ while holding X fixed.
If T ∗ were observed without error, then equations (1) and (3) would provide
an estimator for τ∗ (x) by replacing expectations with nonparametric regressions. Other existing estimators, e.g., those based on matching or conditional
propensity scores, could also be used in that case.
ASSUMPTION A1: There exists E(Y |X T ∗  T ) = E(Y |X T ∗ ).
Equivalently, Assumption A1 says that Y is mean independent of T − T ∗ ,
conditional on X T ∗ , so misclassification does not affect the true expected outcome. This is analogous to the classical assumption of independent measurement errors. This can be a substantive assumption if misclassification is due to
misperception or deceit on the part of the subject, for example, if T indicates
treatment that a respondent believes he or she has received, then Assumption A1 rules out placebo effects. This assumption could also be violated if an
individual’s propensity to lie about T ∗ is related to outcomes, e.g., individuals
who erroneously claim to have a college degree might also be more aggressive
job or wage seekers, in general.
Define r ∗ (x), b0 (x), b1 (x), and τ(x) as
r ∗ (x) = E(T ∗ |X = x) = Pr(T ∗ = 1|X = x)
bt (x) = Pr(T = 1 − t|X = x T ∗ = t)
τ(x) = h(x 1) − h(x 0)
The function r ∗ (x) is the conditional (on X = x) probability of receiving treatment, while b1 (x) and b0 (x) are the conditional probabilities of misclassifying
the treated and the untreated, respectively.
ASSUMPTION A2: There exist b0 (x) + b1 (x) < 1 and 0 < r ∗ (x) < 1 for all
x ∈ supp(X).
Assumption A2 says first that the sum of misclassification probabilities is
less than 1, meaning that, on average, observations of T are more accurate
than pure guesses (see, e.g., Bollinger (1996)). In a binomial response model
with misclassification, this assumption is what Hausman, Abrevaya, and ScottMorton (1998) call the monotonicity condition. Without an assumption like
this, by symmetry one could never tell if the roles of t = 0 and t = 1 were
reversed, and so, for example, one could not distinguish whether any estimate

TREATMENT EFFECTS

541

of τ∗ (x) corresponded to the effect of changing T ∗ from zero to one or the
negative of this effect. This assumption can be relaxed to b0 (x) + b1 (x) = 1 if
we only wish to identify the magnitude but not the sign of τ∗ (x), which may
be useful in applications where the sign of the effect is not in doubt and large
misclassification probabilities cannot be ruled out. See Hu (2005) for other
possible ways to relax this assumption.
Assumption A2 also requires that, for any value x that we may condition
on, there is a nonzero probability of treatment and a nonzero probability of
nontreatment, which is needed because a conditional treatment effect cannot
be identified if everyone is treated or if no one is treated. If this condition is
violated, then we will only obtain identification for values of x where r ∗ (x) is
not zero or one.
Define the functions
r(x) = E(T |X = x)
h(x t) = E(Y |X = x T = t)
τ(x) = h(x 1) − h(x 0)
Note that r(x) and τ(x) are the same as r ∗ (x) and τ∗ (x), except defined
in terms of the observed treatment mismeasure T instead of the true treatment T ∗ , so if treatment were observed without error, then r(x) would be the
conditional probability of treatment and τ(x) would equal the conditional average treatment effect.
THEOREM 1: If Assumption A1 is satisfied, then there exists a function m(x)
with |m(x)| ≤ 1 such that τ(x) = τ∗ (x)m(x). If, in addition, Assumption A2 is
satisfied, then m(x) > 0.
Proofs are provided in the Appendix. Three expressions for m(x) are provided there. First, m(x) = Pr(T ∗ = 1|X T = 1) − Pr(T ∗ = 1|X T = 0), which
shows that |m(x)| ≤ 1 because m is a difference of probabilities. Second,
[(1 − r(x)]r(x)m(x) = [1 − r ∗ (x)]r ∗ (x)[1 − b0 (x) − b1 (x)], which signs m, and
third, m(x) = M[b0 (x) b1 (x) r(x)], where M is defined by


1
(1 − b1 )b0 (1 − b0 )b1
1−
(5)
−

m = M(b0  b1  r) =
1 − b1 − b0
r
1−r
which is used later for point identification and estimation.
Theorem 1 shows that, given just Assumption A1, the magnitude of the mismeasured treatment effect τ(x) provides a lower bound on the true treatment
effect τ∗ (x), and with the addition of Assumption A2, the sign of the mismeasured effect τ(x) equals the sign of the true effect τ∗ (x). This is like the
attenuation bias property of a classically mismeasured regressor coefficient in

542

ARTHUR LEWBEL

a linear bivariate regression, even though here the measurement (misclassification) error is nonclassical and the model is not parameterized.
Theorem 1 also shows that if one is only interested in testing whether
τ∗ (x) = 0, then misclassification can be ignored, because given Assumptions
A1 and A2, τ∗ (x) = 0 if and only if τ(x) = 0.
3. IDENTIFICATION
ASSUMPTION A3: Assume r(x) and τ(x) are identified.
Assumption A3 holds given any data set that permits consistent estimation
of conditional expectations of observable data. Identification of the conditional outcome function h(x t) is not required, although an obvious estimator for τ(x) would be to difference estimates of h(x t). Identification of τ(x)
provides identification of a lower bound on τ∗ (x) by Theorem 1. Also, if the
misclassification probabilities b0 (x) and b1 (x) can be identified, then, given
Assumptions A1, A2, and A3, the true treatment effect τ∗ (x) can be identified
using τ∗ (x) = τ(x)/m(x) and equation (5). Additional assumptions will now
be made that suffice for this identification.
Partition X into two subvectors V and Z, so X = (V  Z).
ASSUMPTION A4: For some set Ω ⊂ supp(V ), for each z ∈ supp(Z), there exists a set Ωz ⊂ Ω such that for all v ∈ Ωz and v ∈ Ωz , we have bt (v z) = bt (v  z),
τ∗ (v z) = τ∗ (v  z), and for v = v , r ∗ (v z) = r ∗ (v  z).
In a small abuse of notation, let bt (z) and τ∗ (z) denote bt (v z) and τ∗ (v z),
respectively, for v ∈ Ωz . The distribution of V can be discrete, e.g., V could be a
scalar that only takes on a few different values. Assumption A4 says that there
exists a variable V that affects the true treatment probabilities r ∗ , but after
conditioning on other covariates does not affect the measurement errors bt
and does not affect τ∗ (at least for some values that V might take on). If T ∗ is
a treatment and unconfoundedness holds, then Assumption A4 says that after
conditioning on other covariates, V does not affect the conditional average
treatment effect, but is correlated with eligibility or selection for treatment.
Having a V that does not affect misclassification probabilities is sometimes
used for identification in binomial response models with misclassification. See,
e.g., Hausman, Abrevaya, and Scott-Morton (1998), Abrevaya and Hausman
(1999), and Lewbel (2000). A typical assumption in misclassified binomial response is that b0 and b1 are constants, which would imply that any elements
of X could serve as V for that part of Assumption A4.
Having V affect r ∗ but not τ∗ is a weaker version of the type of exclusion assumption that is commonly used in the identification of selection models. See,
e.g., Heckman (1990) for a discussion. Close variants of this assumption are
used by Manski (1990) to sharpen bounds on treatment effects and by Imbens

TREATMENT EFFECTS

543

and Angrist (1994) to identify local average treatment effects. The τ∗ condition
is satisfied if E(Y |Z = z V = v T ∗ = t) = s1 (z t) + s2 (z v) for some functions
s1 and s2 .
Assumptions A1, A2, A3, and A4 are all equivalent to (or are implied by)
assumptions made by Mahajan (2005), but as discussed in the Introduction,
Mahajan also requires that h∗ (v z t) = h∗ (v  z t) for v and v as defined in
Assumption A4. However, Mahajan only requires that Ω contain two elements,
so V can be binary, while the next assumption here requires that Ω contain at
least three elements.
ASSUMPTION A5: Each set Ωz ⊂ Ω contains three elements vk ∈ Ωz , k =
0 1 2, such that



τ(v0  z)
τ(v2  z)
τ(v0  z) τ(v1  z)
−
−
r(v1  z) r(v0  z)
1 − r(v2  z) 1 − r(v0  z)



τ(v0  z) τ(v2  z)
τ(v0  z)
τ(v1  z)
=
−
−

r(v2  z) r(v0  z)
1 − r(v1  z) 1 − r(v0  z)
The main content of Assumption A5 is that V can take on at least three
values. Assumption A5 is expressed in a form that can be empirically tested,
because the τ(v z) and r(v z) functions are conditional expectations of observable data, and so can be directly estimated (they are identified by Assumption A3). Assumption A5 can alternatively be written as requiring that
τ∗ (z) = 0, b0 (z) + b1 (z) = 1, and a certain inequality holds among just the
r and r ∗ functions (see the Appendix for details). Assumption A5 will therefore
fail to hold only if the true treatment effect τ∗ (z) is zero or if a complicated
nonlinear equality relationship holds among the true and mismeasured conditional treatment probabilities. This would require a perfect coincidence with
regard to the levels of these probabilities across all the values V can take on.
If Ω has more than three elements, then Assumption A5 will hold as long as,
for each value of z, there exists any one triplet v0  v1  v2 of V values in Ωz that
satisfy the necessary inequality. Note that the triplets v0  v1  v2 are permitted
to vary by (i.e., depend on) z.
THEOREM 2: Let Assumptions A1, A2, A3, A4, and A5 hold. Then the conditional misclassification probabilities b0 (x) and b1 (x), the conditional probability
of treatment r ∗ (x), and the effect τ∗ (x) are all identified. Also, if the condition
in Assumption A2 that b0 (x) + b1 (x) < 1 is replaced by b0 (x) + b1 (x) = 1, then
τ∗ (x) is identified up to sign.
A key component of Theorem 2 is that data on outcomes help to identify
misclassification probabilities. In particular, suppressing z for clarity, it follows
from Theorem 1 and Assumption A4 that
(6)

τ(vk )M[b0  b1  r(v0 )] = τ(v0 )M[b0  b1  r(vk )]

544

ARTHUR LEWBEL

Equation (6) depends only on the identified functions τ and r and on the unknowns b0 and b1 . For each z, evaluating this expression at k = 1 and k = 2
gives two equations in the two unknowns b0 and b1 . These equations are nonlinear, but the proof of Theorem 2 shows that these equations have a unique
solution and thereby identify b0 and b1 . Identification of the true treatment
effect τ∗ (x) then follows from equation (5).
Equation (6) also shows why identification requires V to take on three values. This equation depends on v0 and vk , so evaluating it at k = 1 and k = 2
requires existence of v0 , v1 , and v2 . Each additional value that V can take on
provides another equation that b0 and b1 must satisfy, so the larger is the set
of values Ωz , the greater will be the number of overidentifying restrictions that
determine b0 and b1 at that z.
A binary V would suffice for identification if we had some additional equality restriction on the misclassification probabilities b0 and b1 . For example, in
some applications it may be known that one or the other of these probabilities
is zero, such as when T ∗ is a job training program where we directly observe
everyone who takes the offered program, but we do not always observe when
someone who turns down the program gets alternative training elsewhere. An
example of a binary V might be a second mismeasured treatment indicator.
Theorem 2 could be applied without additional information if we observed
three mismeasured treatment indicators, by taking one of them as T and the
other two (which together can take on a total of four values) as V .
4. SEMIPARAMETRIC AND NONPARAMETRIC ESTIMATION
To construct estimators, the previous identification conditions will now be
expressed in the form of conditional moments. Assume the distribution of V
is discrete, define Ω = supp(V ) = {v0      vK }, for simplicity assume Ωz = Ω,
and let rk∗ (z) = r ∗ (vk  z). Let W = (Y T V ).
Define the vector valued function q0 (z) as the vector of K + 4 elements


(7)
q0 (z) = b0 (z) b1 (z) r0∗ (z)     rK∗ (z) τ∗ (z)
and define g as the vector valued function g[q0 (z) w] that consists of the
2K + 2 elements


b0 (z) + (1 − b0 (z) − b1 (z))rk∗ (z) − T I(V = vk )
(8)
(k = 0     K)
(9)

τ∗ (z)I(V = vk ) +
−

Y T − (1 − b1 (z))rk∗ (z)τ∗ (z)I(V = vk )
b0 (z) + (1 − b0 (z) − b1 (z))rk∗ (z)

Y (1 − T ) + (1 − b0 (z))(1 − rk∗ (z))τ∗ (z)I(V = vk )
1 − [b0 (z) + (1 − b0 (z) − b1 (z))rk∗ (z)]
(k = 0     K).

TREATMENT EFFECTS

545

COROLLARY 1: Define the function q0 by equation (7) and define the function g as the vector of functions (8) and (9). For any value of z in its support,
if Assumptions A1, A2, A3, A4, and A5 hold, then the only function q(z) that
satisfies E[g(q(Z) W )|(Z = z)] = 0 and has first two elements that are nonnegative and sum to less than 1, is q(z) = q0 (z).
The objects we wish to estimate are elements of q0 (z). Corollary 1 shows
that the identification based on Theorem 3 can be expressed as the statement
that the unknown functions q0 (z) are the solutions to the vector of conditional
moments E[g(q(Z) W )|Z = z] = 0.
Based on Corollary 1, the functions of interest q0 (z) can be nonparametrically estimated using nonparametric conditional moment GMM based estimators such as Carrasco and Florens (2000), Newey and Powell (2003), or Ai and
Chen (2003). In particular, estimation can take the form of parametric conditional moment GMM, replacing the unknown functions with sieve approximations. Empirical likelihood based conditional moment estimation such as
Otsu (2003) could also be used. Lewbel (2006a) provides a simple local GMM
estimator for this q0 (z).
To construct semiparametric estimators based on Corollary 1, assume we
can write q0 (z) = s(z β0 ), where s is a known function and β0 is a finite vector of unknown parameters. In this case, the conditional moments
E[g(q(Z) W )|(Z = z)] = 0 imply unconditional moments


E ηj (Z)g(s(Z β0 ) W ) = 0
(10)
(j = 1     J)
for bounded functions ηj (Z) chosen by the econometrician. Given the unconditional moments of equation (10) for j = 1     J, we may estimate β0 using
Hansen’s (1982) generalized method of moments. Asymptotic efficiency can
be obtained by using estimated optimal ηj (Z) functions as in Newey (1993),
Donald, Imbens, and Newey (2003), or Dominguez and Lobato (2004).
With this semiparametric estimator, only the dependence of probabilities
and treatment effects on z is parameterized. The dependence of probabilities
and treatment effects on v and on unobservables remains nonparametric. Identification of β0 will depend on the specification of the function s and on ηj (Z),
but as long as β0 is identified from q0 (z) = s(z β0 ), we can choose ηj (Z)
functions as previously to identify β0 . This identification requires that 2K + 2
(the dimension of s) times J be greater than or equal to the dimension of β0 .
If Z is discrete with a finite number of support points, then nonparametric
estimation of all the functions q0 (z) can be written as a special case of this
semiparametric estimator by defining β0 as the vector of elements βj0 = q0 (zj )
and letting ηj (Z) = I(Z = zj ), where j indexes every value of zj = z in the
support of Z.
It may be of interest to directly estimate the misclassified treatment effect
τk (z) = τ(vk  z) and the misclassified treatment parameters rk (z) = r(vk  z).

546

ARTHUR LEWBEL

By Theorem 1, τ∗ is zero if and only if τ is zero, so estimates of misclassified
treatment effects could be used to test if the true treatment effects are zero.
Estimates of τ and r could also be used in the bounds calculation of Theorem 1
when validity of V as an instrument is in doubt, and they can be used to test
Assumption A5. To express the misclassified functions as conditional moments,
define Q0 (z) as the 2K + 2 vector


(11)
Q0 (z) = r0 (z)     rK (z) τ0 (z)     τK (z)
and define G[Q0 (z) w] as the vector valued function that consists of the 2K +2
elements
(12)
(13)

[rk (z) − T ]I(V = vk )


Y (1 − T )
YT
−
− τk (z) I(V = vk )
rk (z)
1 − rk (z)

(k = 0     K)
(k = 0     K)

COROLLARY 2: Define the function Q0 by equation (11) and define the function G as the vector of functions (12) and (13). For any value of z in its support,
if Assumptions A1 and A2 hold, then the only function Q(z) that satisfies the
equations E[G(Q(Z) W )|(Z = z)] = 0 is Q(z) = Q0 (z).
Nonparametric or semiparametric estimation based on Corollary 2 proceeds
exactly like estimation based on Corollary 1 as previously described, replacing
q and g with Q and G.
5. CONCLUSIONS
This paper provides bounds and conditions for nonparametric point identification of the effect on an outcome of changing a possibly mismeasured
binary variable. Given a weak form of the unconfounding assumption, this
provides identification of conditional average treatment effects when the treatment indicator may be mismeasured. Estimators that employ these identification conditions are provided, based on direct estimation of relevant conditional
expectations.
Lewbel (2006a) and an addendum to this paper (Lewbel (2006b)) describe
both semiparametric and local GMM nonparametric estimation of a vector
of functions q(Z) based on moments of the form E[g(q(Z) W )|(Z = z)] = 0
(Corollaries 1 and 2 are examples of such functions and moments), and provide both a small Monte Carlo and an empirical application of Theorem 2 and
Corollaries 1 and 2, relating wages to attainment of an undergraduate degree,
allowing for misclassification errors in transcript reports.
It would useful to explore how other binary covariate effect estimators such
as matching and propensity score based methods might be adapted to the

TREATMENT EFFECTS

547

present application where the binary covariate such as treatment is mismeasured.
Dept. of Economics, Boston College, 140 Commonwealth Avenue, Chestnut
Hill, MA 02467, U.S.A.; lewbel@bc.edu, http://www2.bc.edu/~lewbel.
Manuscript received September, 2005; final revision received March, 2006.

APPENDIX
∗

Define pt (X) = E(T |X T = t) = Pr(T ∗ = 1|X T = t). Suppressing the
X argument for clarity, some relationships to be used later are, by Bayes theorem,
(14)

p0 =

b1 r ∗
1−r

and p1 =

(1 − b1 )r ∗

r

Also,
(15)

r = E(T ) = E(T |T ∗ = 1) Pr(T ∗ = 1) + E(T |T ∗ = 0) Pr(T ∗ = 0)
= (1 − b1 )r ∗ + b0 (1 − r ∗ )

which gives r = b0 when b0 + b1 = 1; otherwise
(16)

r∗ =

r − b0
1 − b0 − b1

and

1 − r∗ =

1 − b1 − r

1 − b0 − b1

PROOF OF THEOREM 1: Continuing to suppress the X argument, we have by
equations (1) and (2) and Assumption A1 that E(Y |T ∗  T ) = h∗0 + τ∗ T ∗ . By the
law of iterated expectations, this gives E(Y |T = t) = h∗0 + τ∗ pt . Then whereas
τ = E(Y |T = 1) − E(Y |T = 0), we obtain τ = (p1 − p0 )τ∗ , so m in Theorem 1
equals p1 −p0 and −1 ≤ m ≤ 1 follows from m equaling the difference between
two probabilities.
Using equation (14),
(17)

m = p1 − p0 =
=

(1 − b1 )r ∗
b1 r ∗
−
r
1−r

r∗
(1 − b1 − r)
(1 − r)r

and using equation (16) for 1 − r ∗ ,
(18)

(1 − r)rm = (1 − r ∗ )r ∗ (1 − b0 − b1 )

Because probabilities r and r ∗ lie between 0 and 1, this shows that m > 0 when
Assumption A2 holds, m = 0 when b0 + b1 = 1, and m < 0 when the sum of the

548

ARTHUR LEWBEL

misclassification probabilities b0 + b1 is greater than 1. Also, substituting equation (16) for r ∗ into equation (17) yields, after some algebraic simplification,
equation (5).
Q.E.D.
PROOF OF THEOREM 2: For clarity suppress z, and for the functions r and τ
denote rk = r(vk ) and τk = τ(vk ). For any given z, we have, for all v0 ∈ Ωz and
vk ∈ Ωz , that, by Theorem 1 and equation (5),

(19)

(20)

0 = M(b0  b1  rk )τ0 − M(b0  b1  r0 )τk 


(b1 − 1)b0 (b0 − 1)b1
0= 1+
+
τ0
rk
1 − rk


(b1 − 1)b0 (b0 − 1)b1
− 1+
+
τk 
r0
1 − r0




τk
τ0 τk
τ0
−
−
0 = (1 − b1 )b0
+ (1 − b0 )b1
+ τk − τ0 
rk
r0
1 − rk 1 − r0

Write this equation as
0 = B0 w0k + B1 w1k + w2k 
where Bt = (1 − b1−t )bt and each wjk is a function of r0 , rk , τ0 , and τk . Given
that Ωz ∈ Ω contains three elements v0 , v1 , and v2 , we have two equations
0 = B0 w0k + B1 w1k + w2k for k = 1 2 that are linear in the two unknowns B0
and B1 , and so can be uniquely solved as long as the matrix of elements wjk ,
j = 0 1, k = 1 2, is nonsingular. The determinant of this matrix is

 



τ2
τ1
τ0
τ0 τ2
τ0
τ0 τ1
−
−
−
−
(21)
−
r1
r0
1 − r2 1 − r0
r2
r0
1 − r1 1 − r0
and the inequality in Assumption A5 makes this determinant nonzero, as required.
Now let s = 1 − b1 − b0 . It follows from Bt = (1 − b1−t )bt that (s + b0 )b0 = B0
and 2b0 = B0 − B1 + 1 − s. Substituting the second of these equations into the
first and solving for s gives
1 − b1 − b0 = s = ±[(B0 − B1 + 1)2 − 4B0 ]1/2
if the assumption regarding s is s = 0. Then we have that s is identified up to
sign. By Theorem 1, τ∗ = τ(v)/M[b0  b1  r(v)] and


1
B0
B1
M[b0  b1  r(v)] =
1−
−

s
r(v) 1 − r(v)
so it follows that τ∗ is identified up to sign. Making the stronger assumption that s > 0, we have s is identified, so b0 and b1 are now identified by

549

TREATMENT EFFECTS

b0 = (B0 − B1 + 1 − s)/2 and b1 = −(B0 − B1 + 1 + s)/2. In addition by equations
(16) and (5), and Theorem 1, identification of these misclassification probabilities means that r ∗ and τ∗ are also identified.
Define Rk = [(1 − rk∗ )rk∗ ]/[(1 − rk )rk ]. Using τ = mτ∗ and equation (17), the
determinant (21) can be rewritten as


R0 R1
−
r1
r0



R2
R0
−
1 − r2 1 − r0





R0 R2
−
−
r2
r0



R1
R0
−
1 − r1 1 − r0



× (1 − b0 − b1 )τ∗ 
So the nonzero determinant condition can equivalently be written as requiring
that τ∗ = 0, b0 + b1 = 1, and the previously described function of rk∗ and rk for
k = 0 1 2 not equal to zero.
Q.E.D.
PROOF OF COROLLARY 1: To ease notation, drop the argument z everywhere and let all subsequent expectations be conditional on Z = z. Let
Ik = I(V = vk ). Having the mean of equation (8) equal zero makes b0 + (1 −
b0 − b1 )rk∗ = E(Ik T )/E(Ik ), which equals the true rk by definition of rk . Solving
the resulting equation b0 + (1 − b0 − b1 )rk∗ = rk for rk∗ and substituting the result
into equation (9) gives


YT
(1 − b1 )τ∗ rk − b0
−
rk
rk
1 − b0 − b1
−


Y (1 − T ) (1 − b0 )τ∗ 1 − b1 − rk
−
+ τ∗ Ik 
1 − rk
1 − rk 1 − b0 − b1

Setting the mean of this result to zero and dividing by E(Ik ) gives
E(Y T Ik ) (1 − b1 )τ∗ rk − b0
−
rk E(Ik )
rk
1 − b0 − b1
−

E[Y (1 − T )Ik ] (1 − b0 )τ∗ 1 − b1 − rk
+ τ∗ = 0
−
(1 − rk )E(Ik )
1 − rk 1 − b0 − b1

which, using rk = E(T Ik )/E(Ik ), simplifies to
E(Y T Ik ) (1 − b1 )τ∗ rk − b0
−
E(T Ik )
rk
1 − b0 − b1
−

E[Y (1 − T )Ik ] (1 − b0 )τ∗ 1 − b1 − rk
−
+ τ∗ = 0
E[(1 − T )Ik ]
1 − rk 1 − b0 − b1

which, after rearranging terms and using E(T Ik ) = prob(T = 1 V = vk ),

550

ARTHUR LEWBEL

gives
E(Y |T = 1 V = vk ) − E(Y |T = 0 V = vk )


1 − b0 1 − b1 − rk
1 − b1 rk − b0
+
− 1 τ∗ 
=
rk 1 − b0 − b1
1 − rk 1 − b0 − b1
which, by the definitions of the functions τ and m, reduces to τ(vk ) =
M(b0  b1  rk )τ∗ . It has now been shown that the conditional mean of g
equaling zero is equivalent to r(vk ) = b0 + (1 − b0 − b1 )rk∗ and τ(vk ) =
M[b0  b1  r(vk )]τ∗ with the true functions r(vk ) and τ(vk ), and, by Theorem 2, the only solutions to these equations for k = 0     K that also satisfy
b0 ≥ 0 b1 ≥ 0, and b0 + b1 < 1 are the true values of r0∗      rK∗  b0  b1  and
Q.E.D.
τ∗ .
PROOF OF COROLLARY 2: Setting the conditional mean of equation (12)
equal to zero and solving for rk (z) yields the definition of rk (z), and setting the
conditional mean of equation (13) equal to zero and solving for τk (z) yields
the definition of τk (z).
Q.E.D.
REFERENCES
ABREVAYA, J., AND J. A. HAUSMAN (1999): “Semiparametric Estimation with Mismeasured Dependent Variables: An Application to Duration Models for Unemployment Spells,” Annales
d’Economie et de Statistique, 55/56, 243–275. [542]
AI, C., AND X. CHEN (2003): “Efficient Estimation of Models with Conditional Moment Restrictions Containing Unknown Functions,” Econometrica, 71, 1795–1844. [545]
AIGNER, D. J. (1973): “Regression with a Binary Independent Variable Subject to Errors of Observation,” Journal of Econometrics, 1, 249–260. [538]
BOLLINGER, C. R. (1996): “Bounding Mean Regressions when a Binary Regressor Is Mismeasured,” Journal of Econometrics, 73, 387–399. [537,539,540]
CARD, D. (1995): “Using Geographic Variations in College Proximity to Estimate the Returns
to Schooling,” in Aspects of Labor Market Behavior: Essays in Honor of John Vanderkamp, ed.
by L. N. Christofides, E. K. Grand, and R. Swidinsky. Toronto: University of Toronto Press,
201–222. [539]
(1996): “The Effect of Unions on the Structure of Wages: A Longitudinal Analysis,”
Econometrica, 64, 957–979. [539]
CARNEIRO, P., AND J. HECKMAN (2002): “The Evidence on Credit Constraints in Post Secondary
Schooling,” Economic Journal, 112, 705–734. [539]
CARRASCO, M., AND J. P. FLORENS (2000): “Generalization of GMM to a Continuum of Moment
Conditions,” Econometric Theory, 16, 797–834. [545]
DAS, M. (2004): “Instrumental Variables Estimators of Nonparametric Models with Discrete Endogenous Regressors,” Journal of Econometrics, 124, 335–361. [538]
DOMINGUEZ, M., AND I. LOBATO (2004): “Consistent Estimation of Models Defined by Conditional Moment Restrictions,” Econometrica, 72, 1601–1615. [545]
DONALD, S. G., G. W. IMBENS, AND W. K. NEWEY (2003): “Empirical Likelihood Estimation and
Consistent Tests with Conditional Moment Restrictions,” Journal of Econometrics, 117, 55–93.
[545]
FLORENS, J.-P., AND L. MALAVOLTI (2003): “Instrumental Regression with Discrete Variables,”
Unpublished Manuscript, University of Toulouse. [538]

TREATMENT EFFECTS

551

HANSEN, L. (1982): “Large Sample Properties of Generalized Method of Moments Estimators,”
Econometrica, 50, 1029–1054. [538,545]
HAUSMAN, J. A., J. ABREVAYA, AND F. M. SCOTT-MORTON (1998): “Misclassification of the
Dependent Variable in a Discrete-Response Setting,” Journal of Econometrics, 87, 239–269.
[540,542]
HECKMAN, J. (1990): “Varieties of Selection Bias,” American Economic Review, Papers and Proceedings, 80, 313–338. [542]
HECKMAN, J., H. ICHIMURA, AND P. TODD (1998): “Matching as an Econometric Evaluations
Estimator,” Review of Economic Studies, 65, 261–294. [540]
HOTZ, V. J., C. MULLIN, AND S. SANDERS (1997): “Bounding Causal Effects Using Data from a
Contaminated Natural Experiment: Analyzing the Effects of Teenage Childbearing,” Review of
Economic Studies, 64, 575–603. [539]
HU, Y. (2005): “Identification and Estimation of Nonlinear Models with Misclassification Error
Using Instrumental Variables,” Unpublished Manuscript, University of Texas at Austin. [538,
541]
IMBENS, G. W., AND J. D. ANGRIST (1994): “Identification and Estimation of Local Average
Treatment Effects,” Econometrica, 62, 467–475. [543]
KANE, T. J., AND C. E. ROUSE (1995): “Labor Market Returns to Two- and Four-Year College,”
American Economic Review, 85, 600–614. [537]
KANE, T. J., C. E. ROUSE, AND D. STAIGER (1999): “Estimating Returns to Schooling when
Schooling Is Misreported,” Working Paper 7235, NBER. [537]
KLEPPER, S. (1988): “Bounding the Effects of Measurement Error in Regressions Involving Dichotomous Variables,” Journal of Econometrics, 37, 343–359. [539]
LEWBEL, A. (2000): “Identification of the Binary Choice Model with Misclassification,” Econometric Theory, 16, 603–609. [542]
(2006a): “A Local Generalized Method of Moments Estimator,” Unpublished Manuscript, Boston College. [545,546]
(2006b): “Estimation of Average Treatment Effects with Misclassification—
Addendum.” Available at http://www2.bc.edu/~lewbel/mistrea2addendum. [546]
MAHAJAN, A. (2005): “Identification and Estimation of Regression Models with Misclassification,” Unpublished Manuscript, Stanford University. [538,539,543]
MANSKI, C. F. (1990): “Nonparametric Bounds on Treatment Effects,” American Economic Review Papers and Proceedings, 80, 319–323. [539,542]
NEWEY, W. K. (1993): “Efficient Estimation of Models with Conditional Moment Restrictions,”
in Handbook of Statistics, Vol. 11, ed. by G. S. Maddala, C. R. Rao, and H. D. Vinod. Amsterdam: North-Holland, Chap. 16. [545]
NEWEY, W. K., AND J. L. POWELL (2003): “Instrumental Variable Estimation of Nonparametric
Models,” Econometrica, 71, 1565–1578. [538,545]
OTSU, T. (2003): “Penalized Empirical Likelihood Estimation of Conditional Moment Restriction Models with Unknown Functions,” Unpublished Manuscript, University of Wisconsin–
Madison. [545]
ROSENBAUM, P., AND D. RUBIN (1984): “Reducing Bias in Observational Studies Using Subclassification on the Propensity Score,” Journal of the American Statistical Association, 79, 516–524.
[540]
RUBIN, D. B. (1978): “Bayesian Inference for Causal Effects: The Role of Randomization,”
The Annals of Statistics, 6, 34–58. [539]

