Biomelrika (1990), 77, 3, pp. 521-8
Printed in Great Britain

Asymptotically optimal difference-based estimation of variance
in nonparametric regression

J. W. KAY AND D. M. TITTERINGTON
Department of Statistics, University of Glasgow, Glasgow G12 8QQ, Scotland, U.K.
SUMMARY

We define and compute asymptotically optimal difference sequences for estimating
error variance in homoscedastic nonparametric regression. Our optimal difference sequences do not depend on unknowns, such as the mean function, and provide substantial
improvements over the suboptimal sequences commonly used in practice. For example,
in the case of normal data the usual variance estimator based on symmetric second-order
differences is only 64% efficient relative to the estimator based on optimal second-order
differences. The efficiency of an optimal mth-order difference estimator relative to the
error sample variance is 2m/(2m + \). Again this is for normal data, and increases as
the tails of the error distribution become heavier.
Some key words: Difference order; Efficiency; Error variance; Nonparametric regression; Variate difference
method.

1. INTRODUCTION

In this paper we describe general difference-sequence methods for estimating variance
in homoscedastic nonparametric regression. We show that, asymptotically, estimators
based on symmetric differences, which are commonly used in practice, are strikingly
inefficient relative to optimal difference-based estimators. For example, symmetric secondorder differences are only 64% efficient relative to optimal second-order differences, when
the data have normal errors. Techniques based on optimal differences are no more difficult
to apply than methods which use nonoptimal differences, provided the optimal difference
sequence has been computed. We list optimal difference sequences of all orders up to
the 10th, and show how to compute optimal sequences of arbitrary order.
Our regression model is
Yj=f(xj) + ej 0 = 1 , . . . , n),
where / is an unknown function and the errors e, are independent and identically
distributed random variables with zero mean and variance a2. We assume that the x/s
have been ordered, so that x, =e... =s xn. A difference sequence {d}} is a sequence of real
numbers such that

1 4 = 0, Idj = l-

(11)

Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

BY PETER HALL
Department of Statistics, Australian National University, Canberra, ACT2601, Australia

522

PETER HALL, J. W. KAY AND D. M. TITTERINGTON

Assume that dj = O for j<-mt and j>m2, and d-midmi^0, where m,, m 2 >0. Then
m = mx + m2 is called the order of the sequence. It is usually convenient to take m, =0
and m2 = m. Our estimator of a2 based on this difference sequence is
fc-m,

(ldjYJ+kJ.

E{(a2- a2)2} = n~] var (e2) + e(n),
where e(n) is of smaller order than n~l and depends on a smoothing parameter involved
in the construction of &2. The necessity of choosing a smoothing parameter is a practical
drawback to the use of such estimators. By way of comparison, the difference-based
estimators considered in this paper do not require the selection of an extraneous parameter
other than the order of the difference sequence, and have the property
£{(c72-o-2)2}~"~lcvar(<?2),
where c> 1. We suggest using a low-order, optimal difference sequence, such as the
optimal second-order sequence (^(5*-HI), —{, —i(5* — 1)). If an optimal mth order
sequence is employed then the efficiency of er2 relative to &2, for normal errors, is
2m/(2m +1). This ratio exceeds 0-9 for ms*5 and equals 0-8 for m=2. The efficiency
is even greater when the error distribution has heavier tails than the normal.
It would be possible to treat m as a smoothing parameter, and choose m = m(n) to
diverge to infinity according to a formula which depends on properties of the unknown

Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

Estimators of this type have a long history in a time series context; see, for example,
Anderson (1971, p. 66). They werefirstconsidered in the case of nonparametric regression
by Rice (1984), Gasser, Sroka & Jennen-Steinmetz (1986), Miiller & Stadtmiiller
(1987,1989) and Miiller (1988, p. 99ff). If the function/is smooth and if adjacent-indexed
design points Xj get closer together as sample size increases, then the effect of/ on the
asymptotic mean squared error of <x2 is negligible. In finite-sample cases in which the
bias component is also important,/does have an effect, as described in as yet unpublished
work by A. M. Thompson, J. W. Kay and D. M. Titterington. The assumption that / has
a bounded derivative confers more than enough smoothness, and the condition that the
x/s are regularly spaced on an interval, or are drawn randomly from a population whose
density is bounded away from zero on an interval, is more than sufficient to guarantee
that the design points are sufficiently close. Under these conditions the asymptotic variance
of &2 depends only on the error distribution and on choice of {dj}. Judicious selection
of {dj} yields minimization of asymptotic variance. Miiller & Stadtmiiller (1987) have
taken a somewhat similar approach, although in the context of heteroscedastic regression.
There the asymptotic variance formula, and the recommendation for choice of {dj}, are
quite different from our own.
For first-order differences the only available choice of {do,dx) is (2~*, —2~*), or
the sign reversal of this vector. The most commonly used second-order difference
sequence is (d0, dx, d2) = (-6~ J , (f)1, -6" 1 ), although as we shall show the sequence
(i(5* + l), —5, —K51 —1)) performs substantially better. As m increases, the optimal
difference sequence becomes concentrated in a single spike. Curiously, the spike is at an
extremity of the sequence when m is odd, but in the centre when m is even.
Related work on variance estimation includes contributions by Buckley, Eagleson &
Silverman (1988), Eagleson (1990) and Hall & Marron (1990). This work focusses on
variance estimators a2 which have the property

Estimation of variance in nonparametric regression

523

function / However, there are obvious practical difficulties in specifying an appropriate
way for varying m. We should stress that allowing m to vary does not improve the
convergence rate of &2, only its efficiency; the convergence rate is n - i even for m = 1.
2. METHODOLOGY

r2 = var(e2) + 2cr4 £ fa djdj+k)

= <74{K + 2 £

fa djdj+X]

(2-1)

and K denotes the kurtosis of e/a. A formal theorem describing this property is stated
in Appendix 1. Recall the notation given just after (1-1), in particular that d_midm2=|=0
and that m = ml + m2 is the order of the difference sequence {dj}. Subject to condition
(1-1), first-order differences are unique. However, there is a wide latitude of choice for
higher-order differences.
Assume for simplicity that m, = 0 and m2=nu In view of (2-1) it is optimal to choose
d0,..., dm to minimize

l l j

J

)

(2-2)

subject to the constraint (1-1). Table 1 lists the optimal mth order difference sequences
for 1 =£ m =£ 10. These sequences are unique up to reversal of order and reversal of sign.
For the optimal mth order difference sequence, and with 5 denned by (2-2), we have
8 = (2m)"1 and

Therefore the minimum asymptotic variance using an mth order difference sequence is
n~lr\, where
T2 = var(e 2 ) + m - V .
(2-3)
Appendix 2 proves these results, and Appendix 3 discusses the computation of Table 1.
The trend in Table 1, as m increases, is for the difference sequence to converge to a
'spike' of unit mass at one of the entries, and to converge to zero everywhere else. To
Table 1. Optimal difference sequences for 1 as m «£ 10. Entries are rounded to four decimal
places
m

(d0,...,

1
2
3
4
5
6
7
8
9
10

(0-7071, -0-7071)
(0-8090, -0-5, -0-3090)
(01942, 0-2809, 0-3832, -0-8582)
(0-2708, -00142, 0-6909, -0-4858, -0-4617)
(0-9064, -0-2600, -0-2167, -01774, -01420, -01103)
(0-2400, 00300, -00342, 0-7738, -0-3587, -0-3038, -0-3472)
(0-9302, -01965, -01728, -01506, -01299, -01107, -00930, -00768)
(0-2171, 00467, -00046, -00348, 0-8207, -0-2860, -0-2453, -0-2260, -0-2879)
(0-9443, -01578, -01429, -01287, -01152, -01025, -00905, -00792, -0-0687, -00588)
(01995, 00539, 00104, -00140, -00325, 0-8510, -0-2384, -0-2079, -01882, -01830,
-0-2507)

dm)

Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

The asymptotic variance and mean squared error of the estimator a2 are both equal
to n~lr2, where

524

PETER HALL, J. W. KAY AND D. M. TITTERINGTON

(2-4)

d}=\
0

otherwise;

and, if m = 2v — \,

0

otherwise.

It may be proved after some tedious algebra that for this difference sequence, the value
of 5, defined at (2-2), is given by
~ !{6i'(2i'-l)2}"1(2Oi'2-18i'+l)

(m =

2f-l).

Note particularly that S->0 as m->oo, indeed 8 = O(m~l), just as in the case of the
optimal difference sequence. Therefore the spike sequence and the optimal sequence
have similar properties for large m. However, for small values of m the optimal sequence
performs substantially better than the spike sequence, as we shall shortly show.
One might be tempted to use the 'ordinary' difference sequence commonly employed
for numerical differentiation,
'
0

v

J

"
otherwise.

(2-6)

Here the square root factor serves to ensure that 1 d]- 1. Unfortunately, this sequence
performs very badly, particularly for large m. The reason is that it does not enjoy the
'spike' property. It is easily checked that the d/s defined by (2-6) converge uniformly to
zero, without any trace of a spike:
max |oU-*0
— 0O<_/<OO

as m-»oo. It may be proved that, for the ordinary difference sequence defined at (2-6),
c (2mY

Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

appreciate why, note that if we had the opportunity of observing the errors e , , . . . , en
then we would doubtlessly use al= n~l 1je] to estimate a2. This estimator has variance
n"Vo, where ro = var(e 2 ); compare this with (2-1) and (2-3). It has only eh and none
of the other errors, in the position of the jth summand. For large m, our optimal
difference-based estimator &2 is trying to emulate the performance of &%, and so each
summand is dominated by the contribution from just one data value. However, it is
curious that the value chosen for emphasis is in the middle of the moving average when
m is even, and at the very end of the sequence for odd m.
We might artificially construct an mth order 'spike' difference sequence by forcing a
dj towards the middle of the sequence to assume a value close to unity, and demanding
that all the others be close to zero. For example, if m = 2v then we might define

Estimation of variance in nonparametric regression

525

Table 2. Comparison of optimal, spike and
ordinary difference sequences
Type of difference

5

Eff. (%)

Optimal
Spike
Ordinary

i

67
67
67

Optimal
Spike
Ordinary
Optimal
Spike
Ordinary
Optimal
Spike
Ordinary

i

m

i
9

30313
TJS76

80
51
51
86
71
43
89
69
38
91
70
34

Spike differences defined by (2-4) and (2-5), ordinary
differences by (2-6). Fourth column lists efficiency of &2
for normally distributed errors.

Therefore, far from converging to zero as m -*• oo, S diverges to +oo. This means that, if
the ordinary difference sequence is used, asymptotic performance of the estimator becomes
increasingly poor as m increases, a most undesirable property.
Table 2 lists values of 8 for optimal, spike and ordinary difference sequences over the
range 1 =£ m =£ 5. It also gives the efficiency of a2 relative to a\ in the case of normally
distributed errors. This tabulation demonstrates the strikingly good performance of the
optimal difference sequence relative to both the others, for 2=s m =£ 5.
Note that in the case of normal data, and for an estimator computed using optimal
mth order differences, the efficiency of <r2 relative to a2, is
T2,
2

T

2
2+m~l

2m
2m + l '

using (2-3) and the fact that var (e2) = 2a4.
In conclusion we should note the role played by kurtosis K in formula (21). Of course
K = 0 in the case of normal errors, and K > 0 for error distributions which have heavier
tails than the normal. Since the efficiency of a2 relative to a\ is (K + 2)/(K + 2 + 25),
which is an increasing function of K, then the efficiency actually improves as the tails of
the error distribution become heavier. Thus, for practical purposes the ratio 2m/{2m +1)
may be regarded as a lower bound to the efficiency of the optimal mth-order difference
sequence.
ACKNOWLEDGEMENT

This research was supported by a Visiting Fellowship Research Grant for P. Hall from
the UK Science and Engineering Research Council and was conducted in the Department
of Statistics at the University of Glasgow.

Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

Optimal
Spike
Ordinary

526

PETER HALL, J. W. KAY AND D. M. TITTERINGTON
APPENDIX 1

Asymptotic formula for var(<?2)
Assume the conditions
E(e*)<°o,

E(e2) = cr2,

E(e) = 0,

(A-l)

and that, for some 0< e < f, C > 0 , and all x,y,
l+t

max \xi+,-x,\ = O(n- ).

(A-2)
(A-3)

l«J<n-l

Condition (A-2) is weaker than the assumption that/have a bounded derivative. Condition (A-3)
holds for each e > 0 if the design is regularly spaced, e.g. if x, = i/n for 1 =s i ^ n, or if the design
is random on an interval / and the design density is bounded away from zero on /. The following
theorem may be proved by routine methods.
THEOREM.

If (A-l)-(A-3) hold, and

T2

is given by (21), then

2

var(<r )~£(<x 2 -<r 2 ) 2 ~n-V
as n-* oo.
APPENDIX 2

Selection of optimal mth order difference sequence
We begin by considering the related problem of constructing a moving average process with
specified covariance structure. Assume that dl+... + d2m = 1. Consider the moving average process
X djej+k (-oo<fc<oo),
J-o
which has correlation function
Pk

= E(YQYk)(EY20)-l=

X djdJ+k.
j-o

It may be shown by techniques which are standard in time series analysis that the correlation
sequence defined by po=l, pk = - ( 2 m ) " ' for ls|fc|s£m, and pk = Q for |&|>m, is allowable in
the sense that there exists a sequence {dj} which produces these correlations. The argument uses
the fact that 2 pk eiM is real-valued and nonnegative, and the important details are given by
Anderson (1971, pp. 224-5).
Thus, we may produce a sequence d^,... ,dm such that d\+.. . + d2m = 1 and
j-o

These two conditions imply that 0 = ZJ'Lkdjdj+k = (Ljdj)2, that is do+.. . + dm = 0. Therefore our
sequence {dj} has, in addition to (A-4), the properties

1 4 = 0, Id]=l.
j-o

(A-5)

j-o

Put
Z

j j k ,

this time for a general sequence d0,..., dm. Condition (A-5) is equivalent to
Oo=l.

(A-6)

Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

\f(x)-f(y)\*C\x-y\*+',

Estimation of variance in nonparametric regression

527

An optimal mth order difference sequence minimizes
«=I

( l djdJ+k\ = 2 I a\

Jc+O \j-0

I

k-l

APPENDIX 3

Computation of optimal difference sequences
For general m, observe that

l

+ ... + dm_,dm)2.

(A-7)

Define
s, = -(do + dm),

s\=\-{dl+d2m),

tx = {\-\s\-\s22f.

Then do=-jsi + tl, dm = -2sl-t].
Using these formulae for d0 and dm, but taking 5,=
d, + . . . + dm_, and sl = d2 + .. . + d2m_lt and substituting for d0 and dm in (A-7), we obtain an
expression for D(d0,..., dm) as a function of du ..., dm_, alone. This formula incorporates the
constraints I d , = 0 and I d ^ = l , and may be minimized over d , , . . . , dm_, by using a standard
optimization routine. We used NAG routine ECU JAF.
When m = 2, the conditions I d , = 0 and 1 dj = 1 entail

The function (x2-j)2 + x* is minimized with x = ± | , and so we should take do+d2 = ±\. Thus,
d\ = -{do+d2) = zt\, and 1 = dl+d] + d\ = dl + \+(\^d0)2.
Solving this quadratic equation for
d0 we deduce that (d0, dlt d2) = (s(5i + l), -2, —^(5* — 1)), or one of the sign-changed and/or
order-reversed variants.
When m=3 it is convenient to make use of the identities 1 djdJ+k = -z ( K / c « 3 ) and
d20+d] + d\ + d\=\. The equation forfc= 3 implies that d3 = -(6doyl.
Substituting into the
equations for k = 1 and k = 2 we may now express d2 as a function of d, and d0 alone. Using
these formulae for d2 and d3 in either of the k = 1 and k = 2 equations, we produce a quadratic
in dx with coefficients depending only on d0. Solving for d,, we may now express dlt d2, d3 as
functions of d0 alone. The value of d0 may be obtained from d20 + d2 + d\ + d\= 1.

REFERENCES
ANDERSON, T. W. (1971). The Statistical Analysis of Time Series. New York: Wiley.
BUCKLEY, M. J., EAGLESON, G. K. & SILVERMAN, B. W. (1988). The estimation of residual

variance in
nonparametric regression. Biometrika 75, 189-99.
EAGLESON, G. K. (1990). Curve estimation—whatever happened to the variance? In Proc 47th Session of
the International Statistical Institute. To appear.

GASSER, T., SROKA, L. & JENNEN-STEINMETZ, C. (1986). Residual variance and residual pattern in

nonlinear regression. Biometrika 73, 625-33.
P. & MARRON, J. S. (1990). On variance estimation in nonparametric regression. Biometrika 77,415-9.
MULLER, H.-G. (1988). Nonparametric Regression Analysis of Longitudinal Data, Springer Lecture Notes
in Statistics 46. New York: Springer.
HALL,

Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

subject to (A-6). The minimum of 5 subject to (A-6) occurs when ak = -(2m)~x for l«Jt*£m,
and the minimum equals (2m)" 1 . We showed in the previous paragraph that there exists a difference
sequence {dj} with the property 2 y djdj+k = -(2m)" 1 , and (A-6), and so this sequence must produce
the minimum.

528

PETER HALL, J. W. KAY AND D. M. TITTERINGTON

H.-G. & STADTMULLER, U. (1987). Estimation of heteroscedasticity in regression analysis. Ann.
Statist. 15, 610-35.
MULLER, H.-G. & STADTMULLER, U. (1989). Detecting dependencies in smooth regression models.
Biometrika 75, 639-50.
RICE, J. (1984). Bandwidth choice for nonparametric kernel regression. Ann. Statist. 12, 1215-30.

MULLER,

[Received September 1989. Revised January 1990]
Downloaded from https://academic.oup.com/biomet/article-abstract/77/3/521/253632 by Universitat St Gallen user on 16 October 2018

