Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a
Population Mean from Incomplete Data
Author(s): Joseph D. Y. Kang and Joseph L. Schafer
Source: Statistical Science, Vol. 22, No. 4 (Nov., 2007), pp. 523-539
Published by: Institute of Mathematical Statistics
Stable URL: https://www.jstor.org/stable/27645858
Accessed: 05-03-2019 15:05 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve and
extend access to Statistical Science

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

Statistical Science
2007, Vol. 22, No. 4, 523-539

DOI: 10.1214/07-STS227

? Institute of Mathematical Statistics, 2007

Demystifying Double Robustness:
A Comparison of Alternative Strategies
Estimating a Population Mean from
Incomplete Data1
Joseph D. Y. Kang and Joseph L. Sch?fer

Abstract. When outcomes are missing for reasons beyond an investigator's
control, there are two different ways to adjust a parameter estimate for co
variates that may be related both to the outcome and to missingness. One
approach is to model the relationships between the covariates and the out
come and use those relationships to predict the missing values. Another is
to model the probabilities of missingness given the covariates and incorpo
rate them into a weighted or stratified estimate. Doubly robust (DR) proce
dures apply both types of model simultaneously and produce a consistent
estimate of the parameter if either of the two models has been correctly spec
ified. In this article, we show that DR estimates can be constructed in many
ways. We compare the performance of various DR and non-DR estimates of
a population mean in a simulated example where both models are incorrect
but neither is grossly misspecified. Methods that use inverse-probabilities as
weights, whether they are DR or not, are sensitive to misspecification of the

propensity model when some estimated propensities are small. Many DR
methods perform better than simple inverse-probability weighting. None of
the DR methods we tried, however, improved upon the performance of sim
ple regression-based prediction of the missing values. This study does not
represent every missing-data problem that will arise in practice. But it does
demonstrate that, in at least some settings, two wrong models are not better
than one.

Key words and phrases: Causal inference, missing data, propensity score,
model-assisted survey estimation, weighted estimating equations.

1. INTRODUCTION

1.1 Purpose
A new class of methods called doubly robust (DR)

Joseph D. Y. Rang is Research Associate, The Methodology

procedures was designed to mitigate selection bias aris
ing from uncontrolled nonresponse and attrition, non
random treatment assignment in observational stud

Center, 204 E. Colder Way, Suite 400, State College,

Pennsylvania 16801, USA (e-mail:
josephkang@stat.psu.edu). Joseph L. Sch?fer is Associate

ies and noncompliance in randomized experiments

Professor, The Methodology Center, 204 E. Colder Way,

(Robins and Rotnitzky, 2001 ; van der Laan and Robins,

Suite 400, State College, Pennsylvania 16801, USA (e-mail:

2003). DR methods require specification of two mod

jls @ stat.psu. edu).
discussed in 10.1214/07-STS227A, 10.1214/07-STS227B,

els: one that describes the population of responses, and
another that describes the process by which the data
are filtered or selected to produce the observed sam
ple. The distinguishing feature of DR estimates is that

10.1214/07-STS227C and 10.1214/07-STS227D; rejoinder at
10.1214/07-STS227REJ.

523
This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

524 J. D. Y. KANG AND J. L. SCH?FER
they remain asymptotically unbiased if one of the two
models is misspecified?that is, they consistently esti
mate their targets if either model is true (Robins and

X

(a)

x\

Rotnitzky, 1995).
DR methods are a refinement of a weighted esti
mating-equations approach to regression with incom
plete data proposed by Robins, Rotnitzky and Zhao
(1994, 1995) and Rotnitzky, Robins and Scharf stein
(1998). Further explanation and evaluation of DR es
timators has been given by Lunceford and Davidian
(2004), Carpenter, Kenward and Vansteelandt (2006),

(b)

T Y

x2

x3

l? Jo

y\i III

yi

^3

^21 pi

y3] ?ill

Davidian, Tsiatis and Leon (2005) and Bang and

Robins (2005). What is not widely known, however,
is that the methods developed by Robins et al. are not
the only way to achieve double robustness. Many other
types of estimates possess the DR property. General

ized regression estimators developed for sample sur
veys (Cassel, S?rndal and Wretman, 1977), also known

IM!

ilil^o

FlG. 1. Schematic representation of sample data for estimating
(a) a population mean and (b) an average causal effect, with miss

as model-assisted survey estimators (S?rndal, Swens

ing values denoted by shading.

son and Wretman, 1989, 1992), have this property, as
does a new class of parametric methods developed by
Little and An (2004) and several other methods that do
not seem to have been described before.

of respondents and nonrespondents by n^ = J^? t? and

The first purpose of this article is pedagogical. We
review a variety of incomplete-data estimation strate
gies, describe various ways in which the DR property
can arise, and connect the recent articles on DR esti
mation to similar techniques found in the literature on
sample surveys and causal inference. Our second pur
pose is to investigate the practical behavior of these es
timators not only when either of the underlying mod
els is correct, but in a scenario where both models are

moderately misspecified.

1.2 Description of the Problem
For simplicity, we focus on the problem of estimat

ing a population mean from an incomplete dataset.
Many of the methods we present have been applied
to the more general problem of estimating population
average regression coefficients, and we will describe

n(0) _ ]T.(1 ? ti), the population response and non

response rates by r^ ? P{ti ? 1) and r^ = P(ti =
0), and the sample rates by f^ = n^/n and r^ =

n<?/n.

The sample mean of the observed y? 's,

i

consistently estimates the mean for the respondents,
?(l"> = E(y? I ti = 1), under any reasonable population
distribution and response mechanism. An estimator
having this property will be said to be strongly robust.

In general, there is no strongly robust estimate of the

mean for the nonrespondents, ?jl^ = E(y? \ ti = 0),
or for the mean of the entire population, ?jl = E(yi) =
r(0)^(0) _j_ r(i)^(i)^ 5asecj on the observed data alone.

Naive estimates such as y^ may work well enough

ing. For each unit, there is an observed ^-dimensional
vector of covariates x\ that may be related both to y?

if r(?) is small and the relationships among x?, t-x and
y i are weak. As the nonresponse rate and the strength
of these relationships grow, adjusting for selection bias
becomes important, and inferences become sensitive to
the assumptions underlying the adjustment.
This problem is closely related to estimating an aver
age causal effect from an experiment or observational
study. Suppose now that U is an indicator of the treat

and to ti. A schematic representation of the sample

ment received by unit i. Associated with unit i is a

data is shown in Figure 1(a). (In this figure, the indices

/ = 1,..., n have been permuted so that the sample

pair of potential outcomes: the response yu that is re
alized if ti = 1, and another response y?o that is real

units having t[ ? 1 appear first.) Denote the numbers

ized if ti = 0. This situation is depicted in Figure 1(b).

those extensions where appropriate. Let us suppose
that we have a random sample of units / = 1,..., n
from an infinite population. The variable of primary
interest is y?. Let t? be the response indicator for y?,
so that t[ ? 1 if y i is observed and t[ ? 0 if y\ is miss

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

DEMYSTIFYING DOUBLE ROBUSTNESS 525
The causal effect of the treatment on unit /, defined as

yn ? yod, is unobservable because one of the two po
tential outcomes is necessarily missing. It is often of
interest to estimate the average causal effect (ACE) in
the population,

ACE=E(yn)-E(yi0),
or the ACE's among the treated and the untreated,

ACE{l) = E(yn \ti = l)-E(yi0\ti = l),
ACE = E(yn I U = 0) - E(y?0 \ t{ = 0).
The notion of potential outcomes was introduced by
Neyman (1923) for randomized experiments and by
Rubin (1974a) for nonrandomized studies. Reviews of
causal inference from this perspective are given by

Holland (1986), Winship and Sobel (2004), Gelman
and Meng (2004) and Rubin (2005). From Figure 1(b),
it is apparent that the correlation between yn and y ?o

assumptions about P(ti | x/), P(yi \ Xi) or both. De
note the response probability for unit / by

(1) P(ti = l \xi) = 7ti(xi) = n?.
This probability is called the propensity score (Rosen

baum and Rubin, 1983). A proposed functional form
for (1) will be called a n -model. If estimates of the
propensity scores are needed, they are often taken to

be

w t^ exp(xf?)

Tti = expitCx; a) =-tt^'
1 + exp(x/ a)

where ? is the maximum-likelihood (ML) estimate of
the coefficients from the logistic regression of t\,..., tn

on x\,... ,xn. In many situations, of course, the as
sumed form of the rt -model is not correct, and this mis

specification can be problematic depending on how the
71/'s are used.
Let us also define E(yi \ x/) = rn(xi) = mi, so that

[more precisely, the partial correlation between them
given X[ ; see Rubin (1974b)] cannot be estimated from
the observed data. Without prior information on what
this correlation might be?and it is unclear from where

with E(s?) = 0. A functional form for ra(x/) will be

such information would come?one may separate the
problem of estimating an ACE into independent esti

an obvious candidate is m i = xj ?, where ? is the vec

mation of the means of y i \ and y ?o. Any of the methods

described in this article can be used to estimate an aver

age causal effect by applying the method separately to
each potential outcome. When estimating ACE's, rates
of missing information tend to be high and sensitivity
to modeling assumptions may be acute.

1.3 Assumptions

(2) yi=m(xi) + ?i
called a y-model. When an estimate of m/ is needed,
tor of coefficients from the linear regression of y i on Xi

estimated from the respondents; y -models with nonlin
ear link functions are also straightforward (McCullagh

and Neider, 1989). In most cases, an analyst's regres
sion model will be only a rough approximation to the
true y-model. The implications of this misspecification

can be serious if P(x/ \ U ? 1) and P(x? \ ti ? 0) are
very different, because the m/ 's for the nonrespondents

Throughout this article, we will assume that the re
sponse mechanism is unconfounded in the sense that y i

will then be based on extrapolation. This is particularly

true when x/ is high-dimensional because of the so

and ti are conditionally independent given X{ (Rubin,
1978); this assumption has also been called strong ig
norability (Rosenbaum and Rubin, 1983). Under strong
ignorability, the joint distribution of the complete data
can be written as

called curse of dimensionality. With many covariates,
it becomes difficult to specify a y -model that is suffi
ciently flexible to capture important nonlinear effects
and interactions, yet parsimonious enough to keep the
variance of prediction manageably low.

P(X, 7\ Y) = fl P(xi)P(ti | x?)P(yi | xt).

Under ignorability, the jt/'s play no role in like
lihood-based or Bayesian analyses for the parame
ters of the y -model (Rubin, 1976). The parametric

i

Strong ignorability implies that the missing y/'s are

missing at random (MAR) (Rubin, 1976; Little and
Rubin, 2002). In many applications, MAR is unreal
istic. Nevertheless, this assumption provides an impor
tant benchmark and point of departure for sensitivity
analyses, and it is the foundation upon which DR pro
cedures rest.

None of the methods we examine will require an ex
plicit model for the covariates, but they will all make

approach?specifying a full model for y i and ignoring

the 71/'s?is emphasized in texts on missing data by
Rubin (1987), Sch?fer (1997), Little and Rubin (2002)
and others. Nevertheless, many advocates of the para
metric approach also recognize that the 71/ 's are use
ful for model validation and criticism (Gelman, Carlin,

Rubin and Stern, 2004, Chapters 6-7). On the other
hand, much of the literature on causal inference in
the tradition of Rosenbaum and Rubin (1983) eschews

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

526 J. D. Y. KANG AND J. L. SCH?FER
models for y? in favor of matching and stratification

be drawn to models that are linear and logistic in the

based on propensity scores (e.g., Rosenbaum, 2002).

x/j's, and those incorrect models look trustworthy. To
illustrate, we drew a random sample of n ? 200 units
from this population, which happened to produce ex

The latter is motivated in part by a perceived inability
to model the responses well enough to mitigate the dan
gers of extrapolation. Other uses for propensity scores,
including inverse-propensity weighting (Robins, Rot
nitzky and Zhao, 1994), also rely heavily on a 7t -model
while relaxing assumptions about y i. DR methods will
require both a 3; -model and a n -model but remain con
sistent if one or the other is wrong. As we shall see,
however, this property does not necessarily translate
into improved performance when both models fail.

actly n^ ? 100 respondents and n^ = 100 nonre
spondents. Scatterplots of y i versus x?j-, j = 1,..., 4,
for the 100 respondents are shown in Figure 2. Regress
ing y i on the x/y- 's yields coefficients for x/1, x/3 and x/4

that are highly significant and a coefficient for x/2 that

is nearly significant at the 0.05-level; the prediction is
strong (R2 = 0.81), and a plot of residuals versus fitted

values reveals no obvious outliers and little evidence

1.4 A Simulated Example

of heteroscedasticity or nonlinearity. (In other samples,

Consider the following example which, although ar
tificial, bears some resemblance to what we have en

nificant and might be considered for inclusion in the

countered in a real study. For each unit / = 1,..., n,
suppose that {z?\,Z?i,Z??>,Z?4)t is independently dis
tributed as A^O, /) where / is the 4 x 4 identity matrix.

The y i 's are generated as

y/=210 + 27.4zn + 13.7zi2 + 13.7zI-3 + 13.7z/4 + ei,
where e? ~ Af(0, 1), and the true propensity scores are

it i = expit(-z/i + 0.5zi2 - 0.25zi3 - O.lz/4).
This mechanism produces an average response rate of

r^ = 0.5, and the means are \i = 210.0, /x(1) = 200.0
and ?1^ ? 220.0. The selection bias in this example is

not severe; the difference between the mean of the re

spondents and the mean of the full population is only
one-quarter of a population standard deviation. Never
theless, this difference is large enough to wreak havoc

on the performance of the naive estimate y^ when

used as the basis for confidence intervals and tests.

In this example, a logistic regression of t? on the Zij 's

would be a correct n -model, and a linear regression of

y i on the zZJ's would be a correct j-model. We will
suppose, however, that instead of being given the z?/s,
the covariates actually seen by the data analyst are

some higher-order terms such as x\ and X1X2, are sig

model. Those terms, however, do little to improve the
performance of any of the regression-based methods
discussed below, and sometimes they are harmful.)

The covariates seen by the analyst are also related
to the i/'s. Side-by-side boxplots of the x//s for the
ti = 0 and t? = 1 groups are shown in Figure 3(a)-(d).
Fitting a logistic model to this sample, we find that the
coefficients for x/i and x/2 are statistically significant,
and all of the deviance residuals lie between ? 1.85 and

+2.51. Figure 3(e) shows side-by-side boxplots of the
linear predictors ?7/ = logit(7T/). As one would expect,
the distributions of 717 in the two groups are different

but not drastically so. To check the appropriateness of

the link function, Hinkley (1985) suggested adding fjf

as another covariate to see whether it is related to the
response; the coefficient for this extra term was not

significantly different from zero (p ? 0.20), so in this
sample an analyst would have little reason to alter the

link.

Comparing the fitted values of yi under the true and
misspecified 3;-models, we find that the correlation be

tween them is approximately 0.9. Similarly, the corre
lation between the fji 's under the true and misspecified

xa =exp(zn/2),

71 -models is also about 0.9. This example appears to be
precisely the type of situation for which the DR estima

Xii = znl{\ +exp(z/i)) + 10,

tors of Robins et al. were developed. By relying on two

reasonably good models, one hopes that at least one is
close enough to the truth to yield satisfactory results.
Indeed, Bang and Robins (2005, Section 2.1) state:

*?3 = (znz?3/25 + 0.6)3,
Xi4 = (Z2 + Z4 + 20)2.
This implies that logit(7i?) and m/ are linear functions

of\og(xi\),X2,xfx2, l/log(xi),x3/log(xi) and*/ .

Except by divine revelation, it is unlikely that an an

alyst who sees only x? would ever formulate a cor
rect 71- or y-model. Rather, he or she would naturally

9 1/2

In our opinion, a DR estimator has the fol
lowing advantage that argues for its routine
use: if either the [j-model] or the [71 -model]
is nearly correct, then the bias of a DR esti
mator of ?JL will be small. Thus, the DR es

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

527

DEMYSTIFYING DOUBLE ROBUSTNESS

o

go ? Q> ? o ?o o
oo

O

> ? o ,

>> (M

o o

?&8
? o,
o o o
?I? ?I-1

8.5

9.0

9.5

10.0

x1

11.5

x2

? o

o *-o o

o o?> %

O ?0 OOD %0

o ?? <ti??

"> < > u ^ o

o
o

oo0 o CP oo ?

oo.

o o

10.5 11.0

o o o o ?

o oo

o

o@?<?
o(
o o o

o o
o

I

_o_??_l
l
I
I
I

I

0.10 0.15 0.20 0.25 0.30 0.35

300

350

450

400

x3

500

?I?
550

x4

FlG. 2. Scatterplots of response versus observed covariates for respondents in a sample of 200 units.

timator ... gives the analyst two chances to
get nearly correct inferences about the mean

of Y.

In Sections 2 and 3, we describe various techniques
for estimating /x based on the observed data and evalu

ate their performance in this simulated example. Some

(a)

(b)

(c)

0

(d)

1

t

FIG. 3. Distributions of (a)-(d) observed covariates and (e) estimated propensity scores for nonrespondents and respondents in a sample
of 200 units.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

(e)

0

1
t

528 J. D. Y. KANG AND J. L. SCH?FER
of these methods use a n -model, some use a y-model,
and some rely on both. All of the dual-modeling strate
gies possess a DR property, but they do not perform
equally well. Pooling information from two models can
be helpful, but the manner in which the information is
pooled makes a difference. (Due to space limitations,

we will not discuss computation of standard errors.
Tractable variance estimates are available for most of
these methods, but our purpose is to compare the per
formance of the estimates themselves.) In Section 4,
we will provide further justification for why we con
structed our example as we did, and we will outline the
crucial differences between this and simulated exam

ples used by Bang and Robins (2005) and others, so
that apparently contradictory conclusions can be rec

onciled.

2. WEIGHTING, STRATIFICATION

AND REGRESSION

2.1 Inverse-Propensity Weighting
Weighting observed values by inverse-probabilities
of selection was proposed by Horvitz and Thompson
(1952) in the context of survey inference for finite pop

ulations. The same idea is used in importance sam
pling, a Monte Carlo technique for approximating the
moments of a distribution using random draws from
another distribution that approximates it (Hammersley
and Handscomb, 1964; Geweke, 1989). It is easy to see
that n~l J2i U^?~ yii which can be computed from the
respondents alone, unbiasedly estimates the mean of
the entire population, because strong ignorability im

plies that

E{ti7trlyi) = E{E{ti7trlyi\xi))
= E(7ti7?:?~lmi) = ?.

Imbens, 2001). An estimate of /x(0) based on that idea

is

a (0) _ Y,iti?j~l(l-7r)yi
E/?/7T; (1-7T)
and a corresponding estimate of ?jl is

(4) /W-w = r(1)y(1) + r(0)A??V-^
The IPW estimator can also be regarded as the
solution to a simple weighted estimating equation

?/ Wi Ui = 0, where Wi = i/jr/"1 and [// = ()>/ - /x)/a2
for any a2 > 0. From this standpoint, the IPW method
can be generalized to estimate a vector of population
average coefficients for the regression of y? on an ar
bitrary set of covariates. In the regression setting, [//
becomes a vector representing the /th unit's contribu
tion to a quasi-score function. Coefficients estimated in
this manner are consistent and asymptotically normally

distributed provided that the 7i/'s are bounded away
from zero and the n -model has been correctly speci
fied. Asymptotic properties and methods for variance
estimation are described by Binder (1983) when the
propensities are known, and by Robins, Rotnitzky and
Zhao (1994, 1995) when the propensities have been
estimated.

In the original method of Horvitz and Thompson
(1952), the 71/'s were determined by a known survey

design. Surveys are usually designed to ensure that
IPW estimates are acceptably precise, but the forces
of nature that govern uncontrolled nonresponse are of

ten unkind. In missing-data problems, IPW methods
assign large weights to respondents who closely resem
ble nonrespondents, causing the estimates to have high

variance. IPW estimates are also sensitive to misspec
ification of the n -model, because even mild lack of fit

Precision is often enhanced if we use a denominator of

in outlying regions of the covariate space where 71/ % 0

J2i tiK?~1 rather than n, so that the estimate becomes
a weighted average of the j/'s for the respondents.

translates into large errors in the weights. These short
comings of IPW estimators have been known for many

Normalizing the weights in this manner, and replacing
the unknown propensities by estimates derived from a
71-model, the inverse-propensity weighted (IPW) esti

years; see, for example, the comments of Little and
Rubin (1987, Section 4.4.3) on the IPW methods for
nonresponse proposed by Cassel, S?rndal and Wret

mate becomes

man (1983).

P) ?ww-pop = ??rzT~
T,iti*i
The "POP" in the subscript indicates that we are
reweighting the respondents to resemble the full popu
lation. Alternatively, we may reweight them to approx

imate the population of nonrespondents (Hirano and

To see how well IPW performs on the artificial pop
ulation described in Section 1.4, we created 1000 sam

ples of n ? 200 and n = 1000 units each and, for each
sample, estimated the propensity scores in two ways.
First, we fit a correctly specified n -model, regress
ing the f/'s on zu, zu, Zi3 and z?a using a logit link.
Second, we fit the incorrect model which replaces the

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

DEMYSTIFYING DOUBLE ROBUSTNESS 529
Zij's with jc/y's. The behavior of the four IPW esti
mates (3)-(4) under the correctly and incorrectly spec
ified 7X -models is summarized in Table 1. In this table,
"Bias" is the average difference between the estimate

and ?i = 210, and "% Bias" is the bias as a percent
age of the estimate's standard deviation. (A useful rule
of thumb is that the performance of interval estimates
and test statistics begins to deteriorate when the bias

of the point estimate exceeds about 40% of its stan
dard deviation.) "RMSE" is square root of the aver

age value of (jl ? ?)2. Examining Table 1, we see

that the IPW estimates are biased when the n -model is

misspecified, and the biases are accompanied by huge
losses in precision. In fact, the bias and RMSE actu
ally get worse as the sample size grows! IPW esti
mates have higher variance than other procedures ex
amined in this article even when the propensities are
correctly modeled, but when the n -model is incorrect,

the method breaks down. Interestingly, NR weighting
performs better than POP weighting; we do not know
whether the superiority of NR is a peculiar feature of
this example or if it tends to hold more generally.
The poor performance of IPW is due in part to occa
sional highly erratic estimates produced by a few enor

mous weights. In practice, a good data analyst would
never use a simple IPW estimator if the weights were
too extreme. Unusually large weights may be taken as
a sign of model failure, prompting the researcher to re
vise the n -model. Outlying weights may be truncated
or shrunk to more sensible values, or the offending
units with large weights may be removed. (Removing
these units is not recommended, because the respon

dents with the lowest propensities are in fact those
that contain the best information for predicting nonre

spondent behavior.) Analysts who apply IPW to real
problems quickly learn that it often cannot be used
without ad hoc modifications. The column of Table 1

labeled "MAE" reports the median of the absolute er
rors \jx ? ?jl\, which discards the worst 50% of the esti

mates. Even by this robust measure of precision, IPW
performs more poorly than the other methods we ex
amine when the it -model is misspecified, and it fails to

improve as the sample size grows.
In many applications of IPW methodology, weights

are obtained by logistic regression. Logistic models
can be a poor way to estimate response propensities,
because ML estimates from the logistic model are not
resistant to outliers (Pregibon, 1982). A promising al
ternative is the robit model, which replaces the logistic
link by the cumulative distribution function of a Stu
dent's t-distribution with v degrees of freedom (Albert

and Chib, 1993). The logit link is well approximated
by the robit with v ? 1, and smaller values of v lead
to estimates that are more robust (Liu, 2004). In this
example, robit models produce minor improvements
when the covariates are correct and major improve
ment when the covariates are wrong. We found that,
with samples of n = 1000, replacing the logit link by
robit with v ? 4 reduces the bias and RMSE by nearly
50% when the n -model is incorrect. If IPW must be
used, replacing the logistic regression with a more ro
bust procedure can be advantageous.

2.2 Propensity-Based Stratification
To mitigate the dangers of extreme weights and mis
specification of the 7T-model, some prefer to coarsen
the estimated propensity scores into a few categories
and compute weighted averages of the mean response

across categories. In the context of survey nonre
sponse, the technique is known as weighting-cell es
timation or adjustment (Oh and Scheuren, 1983; Little,

1986; Little and Rubin, 2002). Strong ignorability im
plies that y i and ?? are conditionally independent within

Table 1
Performance of IPW estimators of ?jl over 1000 samples from the artificial population

Sample size n -model Method Bias

(a) n = 200 Correct
Incorrect

(b) n = 1000 Correct
Incorrect

IPW-POP -0.27
IPW-NR -0.29
IPW-POP 1.58
IPW-NR 0.61
IPW-POP -0.01
IPW-NR -0.03
IPW-POP 5.05
IPW-NR 3.22

% Bias RMSE MAE
-7.0 3.86 2.43
-8.2 3.60 2.36
19.2 8.35 3.32
10.3 5.99 3.03
-0.5 1.81 1.16
-1.5 1.68 1.09
45.9 12.10 2.80
49.1 7.29 2.34

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

530 J. D. Y. KANG AND J. L. SCH?FER
any subpopulation for which 717 (x/) is constant (Rosen

the stratified estimators are more biased than IPW for

baum and Rubin, 1983). In classes of constant propen
sity, the mean values of yi for respondents and nonre
spondents are equal, which implies that

because the bias of the stratified estimators does not

samples of n = 200 but less biased when n = 1000,

worsen as n increases.

2.3 Regression Estimation

(5) ? = J E(yi\7ti,ti = l)dP?7ti).
Suppose we fit a n -model and define strata s =
1,..., S by grouping units whose tt/'s are similar. De
fine CiS = 1 if unit / belongs to stratum s and 0 other
wise. The 7T -stratified estimate of ? approximates (5)

by a weighted average of respondents' mean in each

IPW and it -stratified estimators pay no heed to re
lationships between the covariates and y i. Regression
estimators, on the other hand, model y? from X[ directly

and use this information to predict the missing values.
Because strong ignorability implies that

E(yt | XiJi = 0) = E(yi \ XiJ? = 1) = E(y? | x?),

stratum, weighted by the proportion of sample units in
that stratum,

we can regress y? on x? among the respondents, apply
the estimated regression function to predict y? for the
entire sample, and then average the predicted values to
obtain an estimate of ?jl. Let

2-// cis\(L^i cisUy\

(6) frstrat-n ? 2_^ (

l^i cisU

s=\ V

Similarly, a tt-stratified estimate of jjl^ weights the
respondents' mean in each stratum by the proportion

? = u2tJxJxJj \HtJxjyj)

of nonrespondents in that stratum,

?)(0) _W

t^strai-n ? / A
5=1

denote the ordinary least-squares (OLS) coefficients

(0) J\ El Cist,

from the regression of y? on x? among the respondents,

and let m? ? xf ?. The OLS regression estimate for ?x

is

which may be combined with y^ as in (4) to produce
another estimate of jl. Rosenbaum and Rubin (1983)

(7) AoL5 = -T]wf.
n ??J

suggest classifying units into S = 5 strata defined by
the sample quintiles of ir/, as this tends to eliminate
more than 90% of the selection bias if the tt-model is

i

This estimate is unbiased if the v-model is true, that is,

correct (Cochran, 1968).
The performance of the tt -stratified estimator (6)
over the 1000 samples from the artificial population
is summarized in Table 2. Comparing these results to
those of Table 1, we see that stratification is less ef
fective than IPW at removing bias when the tt-model
is correct, but the stratified estimators still outper
form IPW in terms of RMSE. The increase in bias

if E(yi | xi) ? xf ? for some ? e ?Rp; in addition, it is
highly efficient if of = V(yi \ x?) is nearly constant. If
the response is heteroscedastic, efficiency can be im

proved by replacing ? with a weighted least-squares
estimate with weights proportional to o[~ .

From our 1000 samples, we computed OLS regres

sion estimates under a correct y -model (regressing j?
on the z//s) and an incorrect v-model (regressing y i
on the Xij's). The results, which are summarized in Ta
ble 3, verify that the bias is indeed removed when the
3;-model is correct but not when the model is wrong.

incurred by coarsening the 7T/'s is easily offset by
the greater efficiency that results from stabilizing the
largest weights. When the tt-model is misspecified,

Table 2
Performance of propensity-stratified estimators over 1000 samples from the

artificial population

Method

Bias

% Bias

RMSE

MAE

Correct

strat-7T

-1.15

Incorrect

strat-TT

Correct

strat-ir
strat-it

-38.1
-87.7
-81.5
-202.7

3.22
4.28

2.17
3.13
1.18
2.83

Sample size

it -model

(a) n = 200
(b) n = 1000

Incorrect

-2.82

-1.08

-2.87

1.71

3.19

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

DEMYSTIFYING DOUBLE ROBUSTNESS

531

Table 3
Performance of ordinary least-squares regression estimators over 1000 samples from the

artificial population

Sample size y -model Method Bias % Bias RMSE MAE
(a)rc = 200 Correct OLS -0.08 -3.4 2.48 1.68

Incorrect OLS -0.57 -17.7 3.26 2.24

(b)n = \000 Correct OLS -0.00 -0.1 1.17 0.79
Incorrect OLS -0.84 -56.0 1.72 1.15

Comparing the RMSE values in thisidea
table
those estimated propensity
of with
combining

in Tables 1 and 2, we see that estimates
based on
ditional covariate
information is not new

Rosenbaum
and Rubin (1985) recomm
the incorrect y-model are more stable
and efficient
than those based on the incorrect n ing
-model.
The bias to nonrespondents or
respondents
Mahalanobis-distance
criterion based
that remains due to misspecificationa of
the y-model
is not large in absolute terms, but itcalipers
is still troubling
defined by the estimated prop
in samples of n = 1000 because there
it amounts
to have performed reg
Numerous
authors
more than 50% of a standard errorments
and begins
to x/
imwithin strata defined b
based on
pair tests and intervals. Difficulties
with
parametric
ences, see D'Agostino (1998).
missing-data methods arise when the uncertainty
To illustratedue
a simple version of this
to the model specification, which is that
rarely
weaccounted
create 25 strata by cross-classify

for, grows relative to the sampling variation
under
cells defined
bythe
the sample quintiles of f
assumed model. In those cases, a point
estimate
based
then
estimate
?x by a weighted averag
on a misspecified but reasonable y-model
may still
perthe cells. If we apply
response
across
form better than other estimates, but
the repeated
analyst is
too
over
samples,
we will occasiona
optimistic about its precision.
a cell that contains nonrespondents but n
which case
the stratified estimates are
The performance of the regression in
estimate
depends

heavily on the strength of the correlation
R between
y we
i
those
samples,
must modify the esti

and m/. As R2 approaches 0, ?Iolsfashion.
converges
y^
Forto
example,
we may collapse

and suffers from the same bias as this
estimate.
or naive
columns
in the 5 x 5 table, fuse the
As R2 approaches 1, it converges to
thean
mean
of the
with
adjacent
cell, impute the missin
regression
estimate that assumes the re
full sample, y = n~] J2i yi, which isastrongly
robust.
row and the
column
effects but no inte
Therefore, if the y-model has stronghas
prediction,
re
on.
gression estimator tends to dominate other methods in
terms of bias, efficiency and robustness.
The we
IPW
andprocedures that require fre
In general,
dislike
n -stratified estimators, on the other
hand,
break
down
quent
ad hoc
adjustments
unless their operating char
acteristics
are
well
understood
and the variance of the
as the predictive ability of the n-model increases.

adaptive estimator can be approximated. Nevertheless,
it is interesting to see how well the method performs
Predicted Values
in our artificial example. For each of our samples, we
We saw that the efficiency and robustness
of an
computed (? x m)-stratified
estimators using all four
IPW estimator can be enhanced by coarsening
the 777of'scorrect and incorrect n- and
possible combinations
into a small number of categories. The
efficiency
of means were imputed by a re
y-models.
Missing cell
these estimators can be further increased
by adding
gression procedure
that assumes no row-by-column in
teractions. The
results,
covariates to the n -model that are predictive
of
y?, which are summarized in Ta

2.4 Stratification by Propensity Scores and

even if these covariates are unrelated
to t[
(Lunce
ble 4, show
that
dual stratification produces a crude
ford and Davidian, 2004). Vartivarian
and
Littlerobustness;
(2002) the bias is relatively low if
kind
of double
show that further improvement is possible
if is
we
cross specified or if the j-model is
the it -model
correctly
classify units by estimated propensity
scores
and Under
co
correctly
specified.
strong ignorability, a strati
variates that are strongly related tofied
the
outcome.
The
estimate
of the population
mean will be unbiased if

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

532

J. D. Y. KANG AND J. L. SCH?FER

Table 4
Performance of propensity and fitted-value stratified estimators over 1000 samples from the

artificial population

Sample size it -model j-model Method Bias % Bias RMSE MAE
(a) n = 200 Correct Correct strat-nm -0.34 -11.6 2.92
Incorrect strat-nm -0.59 -18.4 3.25
Incorrect
Correct strat-nm -0.49 -17.1 2.89
Incorrect strat-nm -2.00 -61.4 3.82
Correct strat-nm -0.27 -21.1 1.31
(b) n = 1000 Correct
Incorrect strat-nm -0.45 -33.7 1.42
Incorrect
Correct strat-nm -0.51 -39.6 1.38
Incorrect strat-nm -2.10 -148.7 2.53

1.90
2.19
1.96
2.62
0.87
0.92
0.92
2.11

either the true 777 's or the true m/ 's are constant within
To understand how these generalized regression es

strata.

It is also useful to compare the results in Table 4
where both models are incorrect with those of Ta
ble 2 where the tt-model is incorrect. This compari
son shows that a 71-stratified estimator can be improved

with predicted values for the y i 's, even if those predic

tions come from a coarsened, misspecified y-model.

The key idea of DR estimation?reducing your re
liance on one model by specifying two?does produce
modest gains in this example over estimates based on
a it -model alone. Comparing Tables 3 and 4, however,
we find that the approximate DR procedure based on
two incorrect models performs worse than OLS based
on the incorrect y-model. When neither model is ex
actly true, two models are not necessarily better than

timators work, consider the simple regression estima
tor (7). If the regression model holds in the sense that

E(yi \x?) = xf ? for some ? e Mp, then on average the
predictions m? = xf ? will be neither too high nor too
low; the mean of the estimated residuals ?/ = y? ? rh?

in the population will be zero. Of course, residuals are
seen only for sampled respondents. We can, however,
consistently estimate the mean residual for the full pop
ulation if we have access to a n -model, and this esti
mate can in turn be used to correct the OLS estimate for
bias arising from y-model failure. Cassel, S?rndal and
Wretman (1976) proposed the bias-corrected estimate

(8) ?BC-OLS = ?OLS +-J2nti??~[?i.
?-J l
i

one.

Notice that if the j-model is true, then E(s?) = 0, and
3. CONSTRUCTING DOUBLY ROBUST ESTIMATES
the second term on the right-hand side of (8) has ex

3.1 Regression Estimation with Residual

Bias Correction

pectation zero for arbitrary jt? 's. If the ix-model is true,

then the second term consistently estimates (minus one
times) the bias of the first term. Therefore, this estimate

is doubly robust.
Cassel, S?rndal and Wretman (1976, 1977) intro
Many variations on this approach are possible. For
duced a family of "generalized regression estimators"
example, we can normalize the weights in the correc
for population means and totals that combine model
tion term, so that the estimate becomes
based predictions for j/ with inverse-probability
weights. These methods, which are part of a methodol
ogy called model-assisted survey estimation (S?rndal,

Swensson and Wretman, 1992), are highly efficient

?OLS+ ^ A , .

when the y -model is true, yet remain asymptotically
Or we can replace the POP weights with NR weights,
unbiased when the y-model is misspecified. In so
the
that the correction term estimates the mean residual
original formulation, the response probabilities were
in the population of nonrespondents. A bias-corrected
a known feature of the survey design, but withestimate
un
of ?jl^ based on this idea is
controlled nonresponse the propensities may be esti
mated under a tt-model (Cassel, S?rndal and Wretman,

1983).

Eia-ti)xf? EjtiTt-Hl-n^Si
E/d-?i) EitiTt-Hi-rci) '

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

DEMYSTIFYING DOUBLE ROBUSTNESS 533
which can be combined with y^ as in (4) to produce
another DR estimate for /x. A third possibility is to re
place the weighted correction term with a ir-stratified

the solution to the AIPW estimating equation reduces
to the generalized regression estimator (8). More gen
erally, it becomes the solution to

estimate of ?(?/). Using five strata based on sample
quintiles of tt? would remove over 90% of the bias from
the OLS estimate if the n -model were true and reduce

(9) - J2 ?i i
+ - Ei^r1 m - U?=o,

problems of instability caused by very large weights.

A more general version of (8) was independently
proposed by Robins, Rotnitzky and Zhao (1994) for
estimating population-average regression coefficients
from incomplete data. Suppose ?// is the contribution
of sample unit / to a vector-valued quasi-score function
for the regression of y i on an arbitrary set of covariates.

As noted in Section 2.1, the solution to J2i WiUi = 0

with Wi = tift?~1 provides a consistent and asymptoti
cally normal estimate of the population-average regres
sion coefficients if the model used to estimate the tt/ 's

where

by

dicted

esti

By

analo

tion.

Any

normalizin
switching

class.

Nev

equations to J2dwiUi + (1 ? w/)0/] = 0, where 0/ =

The
perfo
timate
(8)

on y i. The mean of the additional term (1 ? Wi)<t>i is es

Table
5.
T
ish
when

sentially zero if the tt-model is true, because E(w?) ?

E(E(wi | Xi)) ? E(7t^XTCi) & 1. Therefore, the solu

over,
comp
POP
estim
IPW
proced
does
indee
tic
conditi

tion to these augmented inverse-probability weighted

(AIPW) estimating equations is again consistent and
asymptotically normally distributed under a correct
tt-model. Robins and Rotnitzky (1995) demonstrate
that a judicious choice for 0/ can greatly improve upon
the efficiency of the simple IPW estimator. In partic

ever,

this

lar
pattern
those
from
ble
3.
Bias
7T-model
i

ular, choosing (pi = E(Ui | x/), where the expectation
is taken with respect to the distribution for y i given x?,

produces a locally semiparametric efficient estimator,
the most efficient estimator within this class. This es

misspecif

timate is DR, maintaining its consistency if either the
tt-model or y-model is correct (Scharfstein, Rotnitzky

tially
wor
DR
proced
more
weig

and Robins, 1999). Taking [/,- = (j/ ? ?)/cr2, and es
timating E(yi | Xi) by (m/ ? ?a)/a2 where m? = xj?,
Table 5

Performance of bias-corrected regression estimators over 1000 samples from the

artificial population

Sample size n-model j-model Method Bias % Bias RMSE MAE
(a) n = 200 Correct Correct

Incorrect

Correct
Incorrect

Incorrect

p

misspecif

4> (xi ) is an arbitrary term that may depend on x/ but not

(b)rc = 1000 Correct

f

one?can
b
these
wou
improve

is correct. Now suppose that we change the estimating

Incorrect

Ui

placed

Correct
Incorrect

Correct
Incorrect

BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS
BC-OLS

-0.08
0.25
-0.08
-5.12
0.00
0.06
-0.02
-21.03

-3.4
7.5
-3.3
-43.0
-0.1
3.4
-1.4
-13.5

2.48
3.28
2.48
12.96
1.17
1.75

1.49

157.21

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

1.68
2.17
1.70
3.54
0.79
1.02
0.80
5.32

534 J. D. Y. KANG AND J. L. SCH?FER
trim away these "bad" samples and judge the perfor
mance by the MAE, however, the new procedure is still

worse than IPW and OLS. Once again, two models are

of E(yi \x?). This identity implies that the regression
estimator based on ?sAMP replicates the mean of y? in
the full sample,

not necessarily better than one.

- J2xf?sAMP
= - J2 .
yt= y>
n.
n

Why does this DR estimate fail to perform better

i

than IPW and OLS even though the tt- and y -models
are reasonably close to being true? The local semipara
metric efficiency property, which guarantees that the
solution to (9) is the best estimator within its class, was
derived under the assumption that both models are cor
rect. This estimate is indeed highly efficient when the
7T-model is true and the _y-model is highly predictive.
In our experience, however, if the n -model is misspeci
fied, it is not difficult to find DR estimators that outper

form this one by venturing outside the AIPW class. For
this particular example, normalizing the POP weights,
switching to NR weights, and using a 7t-stratified bias

correction all improve upon ?Xbc-ols- There are yet
more ways to construct DR estimates, as we now de
scribe.

3.2 Regression Estimation with Inverse-Propensity
Weighted Coefficients
The correction term in ?sc-OLS repairs the bias in

&OLS ? n~lJ2i XJ? by estimating the mean residual
in the full population. A different way to repair this
bias is to move the estimated coefficients away from ?.

Imagine that we could see the OLS coefficients based
on the full sample,

i

which

not
co
propen

pute

?wLS= \y2,U?^xXixf\ [y^ti?^1 Xiyiy
In a well-behaved asymptotic sequence, ?sAMP and
?wLS both converge to the coefficients from the linear
regression of yi on x? in the full population, regardless
of whether that regression is an accurate portrayal of
E(y? | Xi). If we compute a regression estimate for ?jl
based on the WLS coefficients,

(10) ?lWLS = - VV7?WLS,
n t-r1
i

the difference between this estimate and y converges

in probability to zero as n -> oo, provided that the
n -model holds.
From this discussion, we see that ?wLS consistently
estimates ?jl if the n-model is true. If the y-model is
true, then ?wLS will be an inefficient but consistent es
timate of ?, and frwLS will again be consistent; thus it

is DR.

?S?MP= Ij^Xixf] \Yxiyi\.
A well-known property of OLS regression is that the

In our simulated example, the WLS regression esti
mate is sometimes inferior to the bias-corrected OLS
estimate (8) when one of the models is true, but much

sum of the estimated residuals y i ? xJ ??samp, i =
1,..., n, is zero if x? includes a constant. This is an al

better when both models are misspecified (Table 6).
Comparing fiwLS to fioLS, we see that the inverse

gebraic identity that holds regardless of the actual form

propensity weighted estimate of ? effectively corrects

Table 6
Performance of regression estimators with inverse-propensity weighted coefficients over 1000

samples from the artificial population

Sample size it -model

j-model Method Bias

% Bias RMSE MAE

(a) n = 200 Correct

Correct WLS -0.09
Incorrect WLS 0.38
Correct WLS -0.08
Incorrect WLS -2.20
Correct WLS 0.00
Incorrect WLS 0.16
Correct WLS 0.00
Incorrect WLS -2.99

-3.4 2.48 1.68
13.2 2.88 1.92
-3.4 2.48 1.68
-70.0 3.83 2.74
-0.1 1.17 0.78
12.0 1.35 0.92
-0.1 1.17 0.78
-203.6 3.33 2.98

Incorrect

(b) n = 1000 Correct
Incorrect

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

a

DEMYSTIFYING DOUBLE ROBUSTNESS 535
the bias from a wrong y-model if the 7T-model is cor
rect, but makes matters worse if the tt -model is wrong.

Once again, many variations on (10) are possible.
Normalizing the POP weights ?/7T-- has no effect on
?wLS> but one might consider switching to NR weights.
Applying NR weights and averaging the predicted val

*1?

o_,

CM n O X>

o o oo ^b <%o ^o

? 0_2 0-^^^^g? ^ ^?

?- 0^ 1? CD
o 0 d? ^\?
o o o ^

ues of xj? among nonrespondents produces an esti
mate of fiP\ which can then be combined with y^
to produce another estimate of ?x. Another possibility
is to coarsen the weights into, say, five categories and
compute a tt-stratified estimate of ?.

3.3 Regression Estimation with

Propensity-Based Covariates
A third general strategy for constructing a DR esti
mate is to incorporate functions of estimated propensi
ties into the y-model as covariates. Ordinary regression
estimates are based on the relationship

/z= / E(y{ \xi)dP(xi)
and achieve consistency if E(yi \ x?) = E(yi | x/,
ti ? 1) is consistently estimated for all x/. In prac
tice, creating a model that gives unbiased predictions
for y i over the whole covariate space can be a daunt
ing task, because real data often exhibit nonlinearities,
interactions, etc. that are difficult to identify and por
tray, especially as the dimension of Xi grows. From (5),
however, we see that requiring unbiased prediction for
all Xi is much stronger than necessary; it would suffice
to have unbiased prediction of E(y? \ 7t(x;)) ? E(yi \
7i(xi),ti ? 1 ) for all n(xi) e (0, 1 ). If we want to repair
the bias in a parametric y -model, it makes sense to first

identify and correct for lack of fit in the direction of
the propensity score, because 71/ = tt(x?) is the coars
est summary of jc? that makes yi and ti conditionally
independent (Rosenbaum and Rubin, 1983).
Consider the sample of n ? 200 units from our arti
ficial population that we examined in Section 1.4. Fig
ure 4 shows the residuals e? from the linear regression
of y i on Xi, plotted against the linear predictors fji from

the logistic regression of ti on x/, for the n^ = 100 re
sponding units. A least-squares line fit to this plot has
an intercept and slope of zero, because the predictor is a
perfect linear combination of covariates already in the

y-model. A smooth curve created by a local polyno
mial (loess) fit, however, suggests that predictions from
the 3^-model tend to be slightly low in the middle of the

propensity scale and slightly high at the extremes. The

bias could be corrected by fitting a generalized addi
tive model (Hastie and Tibshirani, 1990) that allows the

7
- o o
?I-1-1-1-1-1
-3-2-10

1

linear

2

predictor

FlG. 4. Scatterplot
predictors from a
mial fit.

mean of y i to vary smoothly with 7r? in a nonparametric

fashion. Little and An (2004) incorporated a smooth
ing spline hased on fj? and demonstrated that the re
sulting regression estimate of ?jl is DR in the following
sense: If the y-model correctly describes E(yi \ x?) be
fore the propensity-related terms are added, these addi
tional terms (or any other functions of x? ) merely cause

the model to be overfitted and add mean-zero noise to
the predicted values. If the n -model is correct, then (5)

guarantees consistent estimation of /x, as long as the
mean of y? varies smoothly with 7i[ and this relation
ship can be arbitrarily well approximated by the linear
combination of basis functions added to the model. In
the latter case, the propensity-related covariates com
pletely remove the bias for estimating /x, and any ad
ditional information provided by X[ merely serves to
make the estimate more precise.
In the spirit of Little and An (2004), let S{ = S(x]i)
denote a vector of basis functions (e.g., a spline basis)
that can serve to approximate the relationship between
the mean of y? and fji, the estimated linear predictor

from the n-model. Let jc* = (xf, Sf)T denote the aug

mented vector of covariates, and let

(id ?*=(i>r*rr) (i>r?-)

denote the OLS-estimated coefficients from the aug
mented y-model. If Si is a spline basis of degree k>\,
the matrix inverse in (11) will not exist, because Si
will contain a constant and a linear function of fji,
which are themselves linear functions of X[. Problems
of collinearity can be alleviated by switching to a gen
eralized inverse or by removing the offending terms

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

o
n

536

J. D. Y. KANG AND J. L. SCH?FER

Table 7
Performance of propensity-covariate (four dummy indicators) regression estimators over 1000
samples from the artificial population

Sample size it -model y -model Method Bias % Bias RMSE MAE
Correct

Correct

(a) n = 200

7T-COV

Incorrect
Incorrect

7T-COV

Correct

7T-COV

Incorrect

Incorrect

Tt-COV

Incorrect

Tt-COV

Correct

Tt-COV

Incorrect

Tt-COV

-3.4
-13.5
-3.4

-0.55
0.00
-1.49

-42.1

-1.27
0.00

Tt-COV

Correct

Correct

(b) n = 1000

-0.09
-0.39
-0.09

2.48
2.93
2.48
3.51

-38.6
-0.1

-0.2
-100.6

1.17
1.41
1.17

2.10

1.69

2.00

1.68
2.43
0.79
0.87
0.79
1.56

from S?; either approach leads to the same predicted
values m* = x*T?*. The propensity-covariate regres

to distinguish among them. In other words, we approx

sion estimate for ?jl is then

by a piecewise-constant function with discontinuities
at the sample quintiles of tt; . The performance of this
estimate is summarized in Table 7. It performs better
than any of the other DR methods when the 7T-model

imated the relationship between the mean of y i and ir?

(12) ?n-cov = - Y\rh*i
n
i

and y -model are both incorrect. It performs better than

A particular case of (12) was proposed by Scharf stein,

Rotnitzky and Robins (1999) who took 5/ =ftj~l. Us
ing the inverse-propensity as a single additional covari
ate is sufficient to achieve double robustness, because
the estimate then becomes the solution to an AIPW es

any method based on a 7T-model alone. Yet it is still in
ferior to the simple OLS regression estimate under the
incorrect y-model.

In contrast, the regression estimate of Scharfstein,

Rotnitzky and Robins (1999) that uses the inverse

timating equation (Bang and Robins, 2005).

propensity as a covariate behaves poorly under a mis
specified 7T-model (Table 8). The performance of this

We tried (12) in our simulated example with a vari
ety of spline bases: a quadratic spline with a single knot

method is disastrous when some of the estimated

at the median of /}/, a linear spline with knots at the

propensities are small.

quartiles, and so on. We found that these polynomial
splines occasionally produced erratic predicted values
of y i for nonrespondents with low propensities, driving
up the variance of the regression estimate. The best per
formance was achieved by simply coarsening the fji's
into five categories and creating four dummy indicators

4. DISCUSSION
Double robustness is an interesting theoretical prop

erty that can arise in many ways. It does not neces
sarily translate into good performance when neither
Table 8

Performance of inverse-propensity covariate regression estimators over 1000 samples from the

artificial population

Sample size it -model y -modelMethod
Correct
(a) n = 200 Correct

Incorrect

Incorrect

Correct
Incorrect

(b)rc = 1000 Correct
Incorrect

Correct
Incorrect

Correct
Incorrect

1 /' Tt-COV

1/Tt-COV
1/' Tt-COV

1/Tt-COV
1/' Tt-COV

1 /Tt-COV
1/' Tt-COV

1/' Tt-COV

Bias

% Bias

-0.09
1.66
56.5
-4236
0.00
0.59

-3.7

-50.4

-7527

37.6
3.1

-3.4
-0.1

31.3
-3.2
-3.3

RMSE
2.48

4.70

1804

1.3 xlO5
1.17

1.97
1593
2.3 xlO5

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

MAE

1.69

2.84

1.76
7.79
0.78
1.26
0.83
5.75

DEMYSTIFYING DOUBLE ROBUSTNESS 537
model is correctly specified. Some DR estimators have
been known to survey statisticians since the late 1970s.
In survey contexts, these methods are not thought of

as doubly robust but simply as robust, because the
propensities are a known feature of the sample de
sign. When propensities are unknown and must be es

timated, care should be taken to select an estimator

that is not overly sensitive to misspecification of the
propensity model.

No single example can effectively represent all
missing-data problems that researchers will see in
practice. We constructed our simulation to vaguely re

semble a quasi-experiment to measure the effect of

dieting on body mass index (BMI) in a large sam
ple of high-school students. The study has a pre-post

design. Covariates x? measured at baseline include
demographic variables, BMI, self-perceived weight
and physical fitness, social acceptance and personal
ity measures. The treatment ti is dieting (0 = yes, 1 =
no) and the outcome y i is BMI one year later. The goal
is to estimate an average causal effect of dieting among
those who actually dieted. For that purpose, it suffices
to treat the dieters as nonrespondents, set their BMI

values to missing, and apply a missing-data method
to estimate what the mean BMI for this group would
have been had they not dieted. A simple linear regres
sion of yi on Xi among the nondieters yielded an R2
of 0.81, just as in our simulated data, and boxplots of
the linear predictors from a logistic propensity model
looked similar to those of Figure 3(e). The large degree
of overlap in the distributions of estimated propensities
for the two groups makes a causal analysis seem feasi
ble. The estimated propensities for some nondieters are
very small. Keeping these nondieters in the analysis is
highly desirable, because their covariate values closely
resemble those of dieters; they provide excellent proxy
information for predicting the missing values. Yet we
found no obvious way to use these cases in an inverse
propensity weighted estimate, because they exerted too

much influence.

Our simulation represents a situation where selection
bias is moderate, good predictors of yi are available,
both models are approximately but not exactly true,
and some estimated propensities are nearly zero. In sit
uations like these, a DR procedure that does not rely
on inverse-propensity weighting may perform reason
ably well, but there is no guarantee that it will outper
form a procedure based solely on a y -model. A model
that predicts yi reasonably well can enhance the per
formance of an approximate n -model. But in our sim
ulations, we found no way to use the fitted propensities

from the approximate tt -model to reduce the bias from
the approximate y -model. In every case, the bias cor
rection applied to ?Iols tended to move the estimate in
the wrong direction.

Some might argue that inference about E(ji) in
the full population should not be attempted in a sit
uation like the one shown in Figure 3(e), where the
estimated propensities for a few nonrespondents fall
outside the range of those seen among the respon
dents. In our opinion, requiring the empirical support
of P(?i | ti = 1) to completely cover that of P(tt? \
ti ? 0) is too stringent, especially given the sensitiv
ity of these ranges to minor changes in the 7T -model.

In all 1000 samples of n = 200 and n = 1000, the

distributions of the estimated propensities overlapped
sufficiently to compute a stratified estimate with five
quintile-based groups. Moreover, although some of the

estimated propensities were very small, none of the
true propensities were actually zero, so the conditions

required for DR estimation were not violated. Small
propensities frequently occur when missing data are
not missing by design, and data analysts need guidance
on how to deal with them. One who would argue for the
routine use of any kind of inverse-propensity weighted
estimator ignores the obvious fact that these estimators
cannot be used routinely.

Other evaluations of DR methods under dual mis

specification have yielded mixed results, because the
nature of the problems and degree of misspecification

have varied. Davidian, Tsiatis and Leon (2005) pre
sented a DR procedure analogous to ?Ibc-ols for a

pre-post analysis of a randomized clinical trial with
dropout. Sch?fer and Kang (2005) evaluated their pro
cedure and found that it performed slightly better than a

parametric method based on multiple imputation (Ru
bin, 1987). In that analysis, each of the two treatment

groups had its own y-model with 7?2's of about 0.5.
Each group also had its own 7T-model, and the smallest
fitted propensities were 0.14 and 0.07. It thus appears
that the use of AIPW estimating equations can produce
modest gains over a parametric method when the pre
dictive power of the y -model is not too strong and the
estimated propensities do not get close to zero.

The only other simulations that we know of that
compare the performance of DR and non-DR meth
ods under dual misspecification are those of Bang and

Robins (2005). Their first example pertains to the es
timation of a population mean \x. They compare the
performance of three methods?the unnormalized IPW

estimate n~lY?,itinj~lyi, the ordinary regression es
timate n~l J2i xi ?> and the propensity-covariate esti
mate (12) that augments the y-model with l/fti?when

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

538 J. D. Y. KANG AND J. L. SCH?FER
the n- and ^-models are correct and incorrect. In that
example, the predictive ability of the correct y -model
among the respondents is very strong (R2 ? 0.94), but

the incorrect version is worthless (R2 = 0.001); thus
it maximally punishes the simple regression method
when the y -model is misspecified. This approximates
a situation where an analyst wants to impute missing
values but has no idea how to use the covariates, so he
simply ignores them and replaces all the missing val
ues with y i . It may also represent a situation where
all of the confounders are hidden from the analyst for
purposes of y -modeling (though not, strangely, for pur
poses of 7T-modeling). Another noteworthy feature of
that example is that all of the covariates in the propen
sity model have been dichotomized and the selection

mechanism is weak; when n is large, all of the esti
mated propensities fall nicely between 0.25 and 0.5.
Bang and Robins (2005) present three additional ex
amples to demonstrate the performance of DR esti
mates in more elaborate problems. In each case, all of
the predictors in their tx -models were dichotomized,

which helps to keep the estimated propensities away
from zero. Despite these features, none of their ex
amples supports the claim that a DR method based
on two incorrect models is clearly and simultaneously

better than an IPW procedure based on an incorrect
n -model and a simple imputation procedure based on
an incorrect y -model. Only in the fourth example did
the DR method outperform both of its competitors un
der dual misspecification, and even there the advantage
was slight. Thus the results of Bang and Robins (2005)
support our contention that two wrong models are not
necessarily better than one.

ACKNOWLEDGMENT
This research was supported by National Institute on

Drug Abuse Grant P50-DA10075.

Cassel, C. M., S?rndal, C. E. and Wretman, J. H. (1976).
Some results on generalized difference estimation and general
ized regression estimation for finite populations. Biometrika 63

615-620. MR0445666
Cassel, C. M., S?rndal, C. E. and Wretman, J. H. (1977).
Foundations of Inference in Survey Sampling. Wiley, New York.

MR0652527

Cassel, C. M., S?rndal, C. E. and Wretman, J. H. (1983).

Some uses of statistical models in connection with the non

response problem. In Incomplete Data in Sample Surveys III.
Symposium on Incomplete Data, Proceedings (W. G. Madow
and I. Olkin, eds.). Academic Press, New York.

COCHRAN, W. G. (1968). The effectiveness of adjustment by sub
classification in removing bias in observational studies. Biomet

rics 24 205-213. MR0228136

D'AGOSTINO, R. B. Jr. (1998). Propensity score methods for bias
reduction in the comparison of a treatment to a non-randomized

control group. Statistics in Medicine 17 2265-2281.

Davidian, M., Tsiatis, A. A. and Leon, S. (2005). Semipara
metric estimation of treatment effect in a pretest-posttest study

without missing data. Statist. Sei. 20 261-301. MR2189002

Gelman, A. and Meng, X. L., eds. (2004). Applied Bayesian
Modeling and Causal Inference from Incomplete-Data Perspec
tives. Wiley, New York. MR2134796

Gelman, A., Carlin, J. B., Stern, H. S. and Rubin, D. B.
(2004). Bayesian Data Analysis. Chapman and Hall, London.

MR2027492

Geweke, J. (1989). Bayesian inference in econometric models
using Monte Carlo integration. Econometrica 57 1317-1339.

MR1035115

Hammersley, J. M. and Handscomb, D. C. (1964). Monte
Carlo Methods. Methuen, London. MR0223065
Hastie, T. J. and Tibshirani, R. J. (1990). Generalized Addi
tive Models. Chapman and Hall, London. MR1082147
HlNKLEY, D. (1985). Transformation diagnostics for linear mod
els. Biometrika 72 487-496. MR0817563

Hirano, K. and Imbens, G. (2001). Estimation of causal ef
fects using propensity score weighting: An application to data
on right heart catherization. Health Services and Outcome Re
search Methodology 2 259-278.
Holland, P. W. (1986). Statistics and causal inference. J. Amer.

Statist. Assoc. 81 945-970. MR0867618

Horvitz, D. G. and Thompson, D. J. (1952). A generalization
of sampling without replacement from a finite universe. J. Amer.

REFERENCES
Albert, J. H. and Chib, S. (1993). Bayesian analysis of binary
and polychotomous response data. J. Amer. Statist. Assoc. 88

669-679. MR1224394

Statist. Assoc. 47 663-685. MR0053460

Little, R. J. A. and An, H. (2004). Robust likelihood-based
analysis of multivariate data with missing values. Statist. Sinica

14 949-968. MR2089342

Little, R. J. A. (1986). Survey nonresponse adjustments for es
timates of means. Internat. Statist. Rev. 54 139-157.

Bang, H. and Robins, J. M. (2005). Doubly robust estimation in
missing data and causal inference models. Biometrics 61 962

Little, R. J. A. and Rubin, D. B. (1987). Statistical Analysis

Binder, D. A. (1983). On the variances of asymptotically normal

Little, R. J. A. and Rubin, D. B. (2002). Statistical Analysis

972. MR2216189

estimators from complex surveys. Internat. Statist. Rev. 51 279

292. MR0731144
Carpenter, J., Kenward, M. and Vansteelandt, S. (2006).

A comparison of multiple imputation and inverse probability
weighting for analyses with missing data. J. Roy. Statist. Soc.

Ser: A 169 571-584.

with Missing Data. Wiley, New York. MR0890519
with Missing Data, 2nd ed. Wiley, New York. MR1925014

Liu, C. (2004). Robit regression: A simple robust alternative
to logistic and probit regression. In Applied Bayesian Model
ing and Causal Inference from Incomplete-Data Perspectives
(A. Gelman and X. L. Meng, eds.) 227-238. Wiley, New York.

MR2138259

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

DEMYSTIFYING DOUBLE ROBUSTNESS 539
Lunceford, J. K. and Davidian, M. (2004). Stratification and
weighting via the propensity score in estimation of causal treat

ment effects: A comparative study. Statistics in Medicine 23

2937-2960.

McCULLAGH, P. and NELDER, J. A. (1989). Generalized Linear
Models, 2nd ed. Chapman and Hall, London. MR0727836
NEYMAN, J. (1923). On the application of probability theory to
agricultural experiments: Essays on principles, Section 9. Trans

lated from the Polish and edited by D. M. Dabrowska and
T. P. Speed. Statist. Sei. 5 (1990) 465-480. MR 1092986
Oh, H. L. and Scheuren, F. S. (1983). Weighting adjustments
for unit nonresponse. In Incomplete Data in Sample Surveys II.

Theory and Annotated Bibliography (W. G. Madow, I. Olkin
and D. B. Rubin, eds.) 143-184. Academic Press, New York.
Pregibon, D. (1982). Resistant fits for some commonly used lo
gistic models with medical applications. Biometrics 38 485

498.

Robins, J. M. and Rotnitzky, A. (1995). Semiparametric ef
ficiency in multivariate regression models with missing data.
J. Amer. Statist. Assoc. 90 122-129. MR1325119

Robins, J. M. and Rotnitzky, A. (2001). Comment on "In
ference for semiparametric models: some questions and an an
swer," by P. J. Bickel and J. Kwon. Statist. Sinica 11 920-936.

MR1867326

Robins, J. M., Rotnitzky, A. and Zhao, L. P. (1994). Es
timation of regression coefficients when some regressors are

not always observed. /. Amer. Statist. Assoc. 89 846-866.

MR1294730

Robins, J. M., Rotnitzky, A. and Zhao, L. P. (1995). Analysis
of semiparametric regression models for repeated outcomes in
the presence of missing data. J. Amer. Statist. Assoc. 90 106?

121.MR1325118

Rotnitzky, A., Robins, J. M. and Scharfstein, D. O.
(1998). Semiparametric regression for repeated outcomes with
ignorable nonresponse. J. Amer. Statist. Assoc. 93 1321-1339.

MR1666631

ROSENBAUM, P. R. (2002). Observational Studies, 2nd ed.
Springer, New York. MR1899138
ROSENBAUM, P. R. and Rubin, D. B. (1983). The central role of
the propensity score in observational studies for causal effects.

Biometrika 70 41-55. MR0742974

ROSENBAUM, P. R. and Rubin, D. B. (1985). Constructing a con
trol group using multivariate matched sampling methods that in

corporate the propensity score. American Statistician 39 33-38.

Rubin, D. B. (1974a). Estimating causal effects of treatments in
randomized and nonrandomized studies. /. Educational Psy
chology 66 688-701.
Rubin, D. B. (1974b). Characterizing the estimation of parameters
in incomplete data problems. /. Amer. Statist. Assoc. 69 467

474.

Rubin, D. B. (1976). Inference and missing data. Biometrika 63

581-592. MR0455196

Rubin, D. B. (1978). Bayesian inference for causal effects: The
role of randomization. Ann. Statist. 6 34-58. MR0472152
RUBIN, D. B. (1987). Multiple Imputation for Nonresponse in Sur
veys. Wiley, New York. MR0899519

Rubin, D. B. (2005). Causal inference using potential outcomes:
design, modeling, decisions. /. Amer. Statist. Assoc. 100 322
331. MR2166071

S?rndal, C.-E., Swensson, B. and Wretman, J. (1989). The
weighted residual technique for estimating the variance of the
general regression estimator of a finite population total. Bio

metrika 76 527-537. MR1040646

S?rndal, C.-E., Swensson, B. and Wretman, J. (1992).
Model Assisted Survey Sampling. Springer, New York.
MR 1140409
SCH?FER, J. L. (1997). Analysis of Incomplete Multivariate Data.

Chapman and Hall, London. MR1692799
Sch?fer, J. L. and Kang, J. D. Y. (2005). Discussion of "Semi
parametric estimation of treatment effect in a pretest-postest

study with missing data" by M. Davidian et al. Statist. Sei. 20

292-295. MR2189002

Scharfstein, D. O., Rotnitzky, A. and Robins, J. M.
(1999). Adjusting for nonignorable drop-out using semipara
metric nonresponse models. J. Amer. Statist. Assoc. 94 1096?

1120 (with rejoinder 1135-1146). MR1731478
van der Laan, M. J. and Robins, J. M. (2003). Unified Meth
ods for Censored Longitudinal Data and Causality. Springer,
New York. MR1958123

Vartivarian, S. and Little, R. J. A. (2002). On the formation
of weighting adjustment cells for unit nonresponse. Proceedings

of the Survey Research Methods Section, American Statistical
Association. Amer. Statist. Assoc, Alexandria, VA.

Wins hip, C. and S OB EL, M. E. (2004). Causal inference in soci
ological studies. In Handbook of Data Analysis (M. Hardy, ed.)
481-503. Thousand Oaks, Sage, CA.

This content downloaded from 134.174.144.116 on Tue, 05 Mar 2019 15:05:57 UTC
All use subject to https://about.jstor.org/terms

