Adjusting for Nonignorable Drop-Out Using Semiparametric Nonresponse Models
Author(s): Daniel O. Scharfstein, Andrea Rotnitzky and James M. Robins
Source: Journal of the American Statistical Association, Vol. 94, No. 448 (Dec., 1999), pp.
1096-1120
Published by: Taylor & Francis, Ltd. on behalf of the American Statistical Association
Stable URL: https://www.jstor.org/stable/2669923
Accessed: 21-10-2019 14:54 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

American Statistical Association, Taylor & Francis, Ltd. are collaborating with JSTOR to
digitize, preserve and extend access to Journal of the American Statistical Association

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Adjusting for Nonignorable Drop-Out Using

Semiparametric Nonresponse Models
Daniel 0. SCHARFSTEIN, Andrea ROTNITZKY, and James M. ROBINS

Consider a study whose design calls for the study subjects to be followed from enrollment (time t = 0) to time t = T, at
which point a primary endpoint of interest Y is to be measured. The design of the study also calls for measurements on a vector

V(t) of covariates to be made at one or more times t during the interval [0, T). We are interested in making inferences about

the marginal mean pto of Y when some subjects drop out of the study at random times Q prior to the common fixed end of
follow-up time T. The purpose of this article is to show how to make inferences about Ato when the continuous drop-out time Q is
modeled semiparametrically and no restrictions are placed on the joint distribution of the outcome and other measured variables.

In particular, we consider two models for the conditional hazard of drop-out given (V(T), Y), where V(t) denotes the history of

the process V(t) through time t, t C [0, T). In the first model, we assume that AQ(tlV(T), Y) = A(tIV(t)) exp(aoY), where ao

is a scalar parameter and A0(t1V(t)) is an unrestricted positive function of t and the process V(t). When the process V(t) is high
dimensional, estimation in this model is not feasible with moderate sample sizes, due to the curse of dimensionality. For such

situations, we consider a second model that imposes the additional restriction that AO(tlV(t)) = Ao(t) exp(-y6W(t)), where Ao(t) is
an unspecified baseline hazard function, W(t) = w(t, V(t)), w(., ) is a known function that maps (t, V(t)) to R', and -yo is a q x 1
unknown parameter vector. When ao #4 0, then drop-out is nonignorable. On account of identifiability problems, joint estimation

of the mean pto of Y and the selection bias parameter ao may be difficult or impossible. Therefore, we propose regarding the
selection bias parameter ao as known, rather than estimating it from the data. We then perform a sensitivity analysis to see how

inference about pto changes as we vary ao over a plausible range of values. We apply our approach to the analysis of ACTG 175,
an AIDS clinical trial.

KEY WORDS: Augmented inverse probability of censoring weighted estimators; Cox proportional hazards model; Identification;
Missing data; Noncompliance; Nonparametric methods; Randomized trials; Sensitivity analysis; Time-dependent
covariates.

Recent years have brought an explosive growth of litera-

1. INTRODUCTION

ture in this area. This is reflective of the increasing recog-

Rotnitzky, Robins, and Scharfstein (1998) proposed aug-

nition that subjects may drop out of a longitudinal study

mented inverse probability of censoring weighted (AIPCW)

semiparametric estimators for the marginal mean Auo of
an outcome of interest Y measured at a fixed time T

because of factors related either directly or indirectly to the
outcome under investigation. The literature can be divided

from longitudinal data when (a) some subjects drop out of

into likelihood-based and nonlikelihood-based approaches.

the study, (b) drop-out is nonignorable, and (c) the prob-

In the likelihood framework, full parametric specification

ability of drop-out is a function of the potentially unob-

of the joint distribution of outcomes and the nonresponse

served Y and additional time-dependent covariates V(t)

mechanism is required. Hogan and Laird (1997a) and Little

and follows a parametric model. The Rotnitzky-Robins-

(1995) have provided reviews of much of this literature, in-

Scharfstein AIPCW estimators are semiparametric in the

cluding the work of DeGruttola and Tu (1994), Diggle and

sense that they are guaranteed to be consistent and asymp-

Kenward (1994), Fitzmaurice, Clifford, and Heath (1996),

Fitzmaurice, Laird, and Zahner (1996), Fitzmaurice, Molentotically normal (CAN) for Auo regardless of the joint distribution of the outcome Y and the additional variables V(t),

berghs, and Lipsitz (1995), Hogan and Laird (1997b), Laird

provided that the parametric model for drop-out is correct.

(1988), Little (1993a,b), Mori, Woodworth, and Woolson

A natural extension of their approach is to allow the model

(1992), Schluchter (1992), Self and Pawitan (1992), Tsiatis,

for drop-out to be semiparametric. This generalization will

DeGruttola, and Wulfsohn (1994), Wu and Bailey (1988,

be particularly important in studies in which time to drop-

1990), Wu and Carroll (1988). In the nonlikelihood ap-

out is a continuous random variable. In particular, to ensure

proach considered by Robins (1997), Robins, Rotnitzky, and

additional robustness to model misspecification, we allow

Zhao (1995), Rotnitzky and Robins (1997), and Rotnitzky

the time to drop-out to depend on Y and other possibly

et al. (1998), the joint distribution of the outcomes is as-

time-dependent variables V(t) through a semiparametric

sumed to follow a nonparametric or semiparametric model,

proportional hazards model.

whereas the nonresponse mechanism is assumed to follow a

Before proceeding further, it is useful to place this article

parametric model. The current work extends the nonlikeli-

in the context of previous work on nonignorable drop-out.

hood approach by allowing for semiparametric nonresponse
mechanisms.

Daniel 0. Scharfstein is Assistant Professor of Biostatistics, Johns

In the next section we describe our data structure and de-

Hopkins School of Hygiene and Public Health, Baltimore, MD 21205.

fine and motivate models for these data. We discuss issues

Andrea Rotnitzky is Associate Professor of Biostatistics and James M.

of identifiability of parameters in these models, which lead

Robins is Professor of Epidemiology and Biostatistics, Harvard School of
Public Health, Boston, MA 02115. This research was partially

supported by National Institute of Health grants 1-R29-GM48704-0,
5ROIA132475-07, ROICA74112, 1-RO1-MH56639-OIA1, RO1-HD-

? 1999 American Statistical Association

38209-01, and 1-RO1-DA10184-OIA2. The authors wish to thank Victor

Journal of the American Statistical Association

DeGruttola for helpful discussions.

December 1999. Vol. 94. No. 448. Theory and Methods
1096

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1097

us into a exposition of our philosophy of sensitivity analy-

l(b) implies that model A(ao) is nonparametric (i.e., satu-

sis. We also set the stage for the remainder of the article.

rated) for FO in the sense that it places no restrictions on th
joint law of the observed data. That is, model A(cvo) fits the

2. DATA, MODELS, IDENTIFIABILITY, AND
PHILOSOPHY OF SENSITIVITY ANALYSIS
2.1 Identifiability

data perfectly and cannot be rejected by any statistical test.

The theorem also implies that model A(cvo) is just identified in the sense that the joint distribution of (V(T), Y, Q)
is uniquely determined by the law of the observables. We

We assume that we observe n iid copies, {Oi = (Qi, Ai,
i\iMi, Vi(Qi)): i 1,... ,n}, of

thus refer to model A(cvo) as a "nonparametric (just) identi-

0 (Q, A, AY, V(Q)),

an explicit characterization of the map from (Fo, ao) to the

fied" (NPI) model. In (A.la)-(A.lc) of Appendix A we give

where Q is time to drop-out, Y is the outcome of in-

law FV(T),Y,QIt follows that under model A(cvo), for any given law FO

terest measured at the fixed nonrandom end-to-follow-up

of 0, we can plot the mean of Y, say pu(ao), as a function of

time T, A = I(Q > T) is the drop-out indicator, and

the nonidentified selection bias parameter ozo. In practice,

V(t) = {V(u): 0 < u < t} is the history of all other vari-

the law FO is unknown, but it can be estimated from the

ables that would be recorded through time t in the absence

observed data. Thus we can replace pu(ao) by an estimator
ft(co) and provide a confidence interval for p,(ao) that will
be guaranteed to asymptotically cover pu(ao) at its nominal

of drop-out. Note that Y is observed if and only if A = 1.

For notational convenience, for subjects who do not drop
out, we set the drop-out time Q equal to the end of follow-

rate. Our estimation procedure is described in Section 3.

up time T.

We now illustrate our approach with a concrete example.

The goal of this article is to consider inference about a

smooth functional of the marginal distribution of Y using

2.2 Example: ACTG 175

the observed data {?O, i = 1,... .I n}. For concreteness, we

ACTG 175 was a randomized, double-blind clinical

concentrate on inference about the mean Auo of Y, although

trial designed to evaluate nucleoside monotherapy (zidovu-

we briefly consider the median in Section 7.1.

Consider model A, in which we assume that the condi-

dine or didanosine) versus combination therapy (zidovudine/didanosine or zidovudine/zalcitabine) in HIV- 1 in-

tional hazard of Q, given the data (V(T), Y) that would

fected individuals with CD4 cell counts of 200-500/mm3.

be observed in the absence of drop-out, follows a stratified

Specifically, 2,467 subjects were randomized to one of four

Cox proportional hazards model of the form

treatment arms: (1) zidovudine 200 mg three times daily
(AZT); (2) zidovudine 200 mg three times daily plus di-

AQ (t V(T), Y) Ao(t V(t)) exp(ao Y), (1)
where AQ(tIV(T), Y) limh-o Pr[t < Q < t +

h V(T), Y, Q > t]/h, AO (t V(t)) is an unrestricted positive

function, and ozo is an unknown parameter. Equation (1)
states that the hazard of drop-out at time t depends in an
arbitrary and unknown way on the observed past V(t), but
depends on the possibly unobserved future only through the

term exp(aoY). When ozo = 0, drop-out at time t is conditionally independent of the possibly unobserved outcome

danosine 200 mg twice daily (AZT + ddl); (3) zidovudine
200 mg three times daily plus zalcitabine .75 mg daily (AZT
+ ddC); and (4) didanosine 200 mg twice daily (ddl). Enroll-

ment began in December 1991 and was closed in October
1992. CD4 counts were obtained at baseline and again at

weeks 8, 20, 32, 44, and 56 (Hammer et al. 1996).
One goal of the investigators was to compare the four
treatment arm-specific mean CD4 counts at week 56 had

(possibly contrary to fact) all subjects complied with their
assigned therapy through that week. This goal differs from

Y given the observed past V(t). Thus oao = 0 corresponds
that of an intent-to-treat analysis, which aims to compare

to the assumption that the data are coarsened at random

(CAR) as defined by Heitjan and Rubin (1991). Robins and
Rotnitzky (1992) previously studied inference in model A

treatment arm-specific means of subjects as randomized,
regardless of compliance. Therefore, for the purpose of

our analyses, subjects were considered to be drop-outs if

when o0o = 0. This article extends their work by allowing
they died or were lost to follow-up prior to week 56, if

for nonzero ozo. The sensitivity analysis philosophy thatthey
we missed their 56 week clinic visit, or if they were ob-

adopt herein is motivated by the following identification
theorem, whose proof is given in Appendix A.
Theorem 1. Under the regularity conditions given in

Appendix A, (a) in model A, neither ao nor the distribu-

tion of (V(T), Y) is identified, and (b) for each law FO
of the observed data 0 and each value of ao, there exists

served to discontinue their assigned therapy prior to week
56. Drop-outs varied from 26.5 to 36% in the four arms.
An approximate time to drop-out was available for these

subjects. Note that, as is common in randomized trials, our
interest is in the unconditional mean of CD4 count Y at

week 56 rather than the conditional mean of Y given V(t).
The conditional mean of Y given baseline covariates V(O)

a unique Ao(tJV(t)) and a unique joint law, say FV(T),Y,might be of interest for "subset" analyses, which are not

of (V (T), Y) such that FO is the marginal distribution of
0 under the law FV(T)IY Q for (V(T), Y, Q) determined by
FV(T),Y and (1).

considered in this article. Figure 1 presents a sensitivity
analysis based on model A(cvo) in which we took V(t) to
be the time-independent indicator of whether the subject

Consider model A(cvo), which differs from model A only

was an IV drug user at baseline. In Figure 1 we show the

in that a0o is assumned known to the data analyst. Theoremestimated means along with 95% confidence intervals for

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1098

Journal

of

the

AZT

co

American

AZT+ddl

0o

cm

-0.02

-0.01

0.0

0.01

0.02

Statistical

0

-0.02

alphaO

-0.01

0.0

Association,

AZT+ddC

0o

0q

0.01

0.02

alphaO

December

-0.02

-0.01

1999

ddl

0o

04

0.0

0.01

alphaO

0.02

-0.02

-0.01

0.0

0.01

0.02

alphaO

Figure 1. Treatment-Specific Predicted Means and 95% Confidence Intervals for Varying aoo 's in Model A(c6o) with IV Drug User Status as the
Time-independent Regressor

oa 's ranging from -.02 to .02 for each of the four treatment

to unmeasured factors, it would not be desirable or scien-

groups. Between-treatment group comparisons are reported

tifically reasonable for ozo to be identified from the dat

in Section 6. In Figure 1 ao is interpreted as the log hazard

in the absence of further knowledge of these factors. Our

ratio for drop-out between subjects with the same baseline

model A(ao) formalizes this desiderata; we cannot iden-

IV drug user status, but who differ by 1 in CD4 count at

tify the magnitude of selection bias, but we can identify

week 56. Setting oz0 > 0 (< 0) is tantamount to assum-

the law of Y, and in particular its mean, as a function of

ing that among subjects with the same IV drug user status,

the selection bias parameter. Because the data contain no

those with higher (lower) CD4 counts at 56 weeks are more

independent evidence about oz0, final substantive conclu-

likely to be drop-outs than those with lower (higher) CD4

sions would depend on which values of oa0 are considered

counts. For example, setting oa0 = .01 specifies that at each

plausible by relevant subject matter experts. In Appendix

time t an IV drug user with a 200 CD4 count at 56 weeks

A we prove that Theorem 1 remains true if we replace

has a drop-out hazard 2.7 times that of an IV drug user
with a 100 CD4 count at 56 weeks and a drop-out hazard

oaoY in (1) by any other fixed function r(t,ao;V(T),Y)
of t, aoZ, V(T), and Y that satisfies the regularity conditions

(2.7)3/2 times that of a drug user with a CD4 count of 50

of Appendix A. Thus there will never be any data evidence

at 56 weeks. As expected, for each treatment group, the

that can determine either the magnitude of a0 or the func-

estimated means increased monotonically with ao0.

tional form r(t, a0; V(T), Y) of the selection bias process.

2.3 A Philosophy of Sensitivity Analysis

tivity analysis with oa0Y replaced by other functional forms

The reader should not be discouraged that we only pro-

It follows that one may wish to repeat the preceding sensi-

r(t, ozo; V(T), Y) satisfying r(t, 0; V(T), Y) = 0, so a0 = 0

vide a sensitivity analysis for the mean of Y. Because the

continues to imply CAR. Note that the substantive mean-

parameter oa0 represents the magnitude of selection bias due

ing of the magnitude of oa0 depends on the functional form

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1099

chosen for r(t, ozo; V(T), Y). Sensitivity analyses based on

2.4 The Curse of Dimensionality

other NPI models have been considered in the missingdata literature by Baker, Rosenberger, and DerSimonian

(1992), Nordheim (1984), Robins (1997), and Rotnitzky et

al. (1998) and in the competing risks literature by Klein
and Moeschberger (1988), Slud and Rubinstein (1983), and

Theorem 1 guarantees that both the law of (V(T), Y) and

A0 (tlV(t)) are nonparametrically identified under model
A(ao). Furthermore, in Section B.1.1 of Appendix B
we prove that the asymptotic semiparametric information

bound for n /2-consistent estimators of [Lo in model A(ao)

Zheng and Klein (1994, 1995). With the exception of those

is nonzero. Nonetheless, neither Theorem 1 nor the positive

of Robins (1997) and Rotnitzky et al. (1998), these NPI

information bound guarantees that we can construct estima-

models do not allow for time-dependent processes V(t).
It is important to note that it would be possible to jointly

tors of [Lo that perform well in the moderate-sized samples
found in practice. In fact, when V(t) is high dimensional

and the sample size is moderate (say, less than 1,000), then,
identify the nonignorable selection bias parameter ozo and
due to the curse of dimensionality, there is no estimator of
the mean [Lo of Y (as well as estimate them at nl/2-rates)
if, in addition to (1), we specified that either FYV(T)[to
orthat has, under all laws allowed by model A(ao), an ap-

Ao(tlV(t)) followed particular parametric models. However, one would rarely, if ever, have such firm prior knowl-

edge of the functional form of either FyV(T) or Ao(tJV(t))
so that such parametric restrictions should be used to iden-

tify the parameters of scientific interest. Little (1985) and
Little and Rubin (1987) expressed similar sentiments. In

proximately normal sampling distribution centered near [Lo

with variance sufficiently small to be of substantive inter-

est (Robins and Ritov 1997). This reflects the fact that to
estimate bto under model A(ao), it is necessary to use multi-

variate nonparametric smoothing techniques, which would
require impractically large samples when V(t) is high dimensional.

our opinion, it is preferable that [Lo and ao not be jointly
We regard the process V(t) as high dimensional if (a) for

identified from the data in the absence of additional well-

supported substantive knowledge. This position is in line
with the adage: "It's not what you don't know that hurts

you; it's the things you think you know, but don't." To para-

each t, the vector V(t) has two or more continuous com-

ponents or many discrete components, or (b) V(t) jumps at
many different times. In such cases we consider model B,

in which we assume that (1) holds and

phrase Freedman, Rothenberg, and Sutch (1984), identify-

ing ago and [Lo by specifying parametric models will increase
the stock of things that we think we know, but do not.
Clearly the biggest challenge in conducting such a sensi-

tivity analysis is the choice of one or more sensible parame-

terized selection bias functions r(t, ao; V(T), Y) whose interpretation can be communicated to relevant subject matter experts with sufficient clarity so that they can provide

Ao(t V(t)) = Ao(t) exp(ytoW(t)), (2)

where Ao (t) is an unspecified baseline hazard function,
W(t) = w(t,V(t)),w(., ) is a known function that maps

(t, V(t)) to Rq, and -yo is a q-dimensional unknown param-

eter. In Section 4 we show that inference about [Lo under
model B(ao) (i.e., model B with ozo assumed known) does
not require high-dimensional smoothing. Thus we can leave

a plausible range for the parameter aor, including its mag- the baseline hazard Ao (t) unrestricted and still obtain well-

nitude and direction. Hard as this challenge may sound,

we believe it to be a worthwhile exercise when compared

behaved estimates of [Lo.
Theorem 1 does not hold for model B. As a consequence

to the alternative of identifying oao and [Lo based on poorly
of the restriction on the functional form of Ao(tlV(t)) immotivated parametric functional forms and/or distributional
posed by (2), [Lo and aoo are often jointly identified. But if
we choose the dimension of W(t) in (2) moderately large,

shape restrictions.

When a decision is required (e.g., whether a drug should
be licensed based on the study results), a drawback of sensitivity analysis is that it produces a range of answers rather
than a single answer. In this case it would be reasonable
to place a prior distribution on the nonidentified selec-

tion bias parameter aeo, and also on the functional form of

r(t, ao; V(T), Y). Robins, Rotnitzky, and Scharfstein (1999,
sec. 11) provided details of this approach, although the discussion there is restricted to a rather simple setting because of unsolved technical problems with implementing
nonparametric Bayesian procedures. Even if one wished to
summarize inferences by Bayesian averaging over possi-

to preserve some robustness to misspecification, then there

would be generally little independent information about ao
and [Lo, and thus their joint estimation would require very
large sample sizes. Thus we continue to recommend that

one regard ozo as fixed and known when estimating [Lo and

vary aoo in a sensitivity analysis. As this model B(ao) is no
longer a nonparametric model for the distribution of the ob-

served data, it can in principle be subjected to a goodnessof-fit test. In conducting a sensitivity analysis, we would

like to choose the dimension of W(t) in (2) large enough
so that any goodness-of-fit test will have little power to re-

ject model B(ao), but choose the dimension small enough
so that the estimators described in Section 4 have a nearly

ble values of oao, we recommend that one also publish
the sampling distribution with variance small enough to
normal

results of the sensitivity analysis itself, to make the reader

be of substantive use to subject matter experts. It is not clear
aware of how inferences about pio vary with cr0. In this sense that both of these competing criteria can always be met.

we regard a sensitivity analysis as useful "preprocessing"

Clearly, the choice of the dimension of W(t) will depend

for any full Bayesian analysis that places prior distributions

on the size of the dataset and on the precision required by

on a0o and the other parameters.

the experts. Furthermore, because different models B(oao)

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1100

Journal

of

the

American

Statistical

associated with different choices for the functional form of

W(t) = w(t, V(t)) cannot be easily distinguished based on
a goodness-of-fit test and may lead to quite different infer-

Association,

December

1999

lor series arguments, it can be shown that n /2 (A (
[oL) is asymptotically normal with mean 0 and asym
totic variance T(b)-2 var[h(O; ,[o, AO; b)] where T(b)

ences for [Lo, it would be best to repeat a sensitivity analysis
&E[h(O; [t, AO; b)]1/&9uLJ[,=[,A. Given a consistent estima
a number of times, varying not only the functional form of

N(b) of T(b), the asymptotic variance can be consisten
the nonidentified selection bias function r(t, ozo; V(T),estimated
Y),
by Nr(b)>-2rn-v Z h(Oi; f(b), AO; b)2. When the
but also the functional form of w(t, v(t)) in (2).
functional [Lo is the mean of Y, T(b) = 1, and N(b) can be
taken to be 1 as well.
In Sections 3 and 4 we show how to estimate [Lo in modBecause in fact AO (u V(u)), and thus ir(V(T), Y) and the

els A(ao) and B(ao). These estimation procedures are a
special case of a general theory of inference in settings in

conditional expectations in (3) are unknown, we consider

which the full data (i.e., V(T) and Y) and the drop-out

estimators f(b) solving

mechanism (i.e., Q) follow arbitrary semiparametric modn

els with distinct parameters. For ease of presentation, we

Zh(Oi; tt A,; b) 0,

describe this general theory and then give specific applica-

i=1

tions to the models considered in this article in Appendix B.
In Section 5 we present the results of two simulation stud-

ies that evaluate the performance of our estimation proce-

where

dures in moderate-sized samples. In Section 6 we perform

h(O;At,;b)

a sensitivity analysis of the ACTG 175 dataset using our

A

two models. In Section 7 we describe settings in which our

ir- (V(T), Y)

method breaks down and offer alternative methods appropriate for these settings. We denote the final section to a

x (Y - t - E[(1 - A)b(V(Q), Q; )V(T), Y])

discussion.

+ (1 - A)b(V(Q), Q; 1),

3. ESTIMATION IN MODEL A(ao,)
To motivate our estimation method, suppose first that

7j(V(T), Y) is equal to exp(-A(TI V(T)) exp(ao Y)), E[(1-

A)b(V(Q),
Ao (t I V (t)) were known. Let Ao (t I V (t)) = Jo Ao (u I V (u))
du

denote the cumulative conditional baseline hazard. Then we

could estimate [to by f(b) solving

Q; At)|V(T),Y] is equal to f( b(V(t), t; At)

exp(-A,(tlV(t)) exp(oaoY)) exp(avoY) dA(tlV(t)), and A(tJ

V(t))_is the estimate of the cumulative baseline hazard

Ao(t V(t)) described later.

n

Sh(Oi;t,Ao;b) = O,
i=l1

where b = b(v(t), t; At) is a function specified by the data
analyst and

Unfortunately, due to the curse of dimensionality, non-

parametric estimation of Ao(tlV(t)) is not feasible when
V(t) has multiple continuous components or the process
V(t) jumps at many different times. In the remainder of

this section we consider the special case in which V(t) is
time independent so that V(t) = V for all t.

h(O; t,u Ao; b)

If V is discrete, then A(tJV) is estimated separately

=__ A

within each level of V. If V is univariate and continu-

-(V(T), Y)

ous, then A,(tJV) is nonparametrically estimated by a "his
togram" estimator that places subjects with similar values

x (Y - At - E[(1 - A)b(V(Q), Q; it) IV(T), Y])

+ (1 - A)b(V(Q), Q; /1), (3)
with -r(V(T), Y) = Pr[A - 1 V(T), Y]. By (1), we

have Pr[A 1IV(T), Y] S(TIV(T), Y), where

of V into a common bin and constructs estimators A(tJV)

separately for each bin. Suppose that V is discrete or has
been discretized by grouping into a finite number of "bins."
If we were always able to observe Y, then we could simply partition the sample into groups based on the value of

S(t V(T), Y) - exp(- Ao (t V(t)) exp(ao Y)). Furthermore,
V and estimate the cumulative baseline hazard separately
the conditional expectation in (3) can be explicitly evaluated
within each group using the Nelson-Aalen estimator with
as ir b(V(t), t; At) exp(- Ao(t V(t)) exp(aoY)) exp(ao Y)
censoring times as the jump times (Andersen, Borgan, Gill,
Ao(t V(t)) dt. In the special case in which b(v(t), t; At) is
and Keiding 1993). That is, we could estimate A0 (tlV = v)
chosen to be identically 0, we refer to 1(b) as an inverse
by
probability of censoring weighted (IPCW) estimator. This
is a generalization of the Horvitz-Thompson (Horvitz and
A(tJV = v)
Thompson 1952) estimator used in the sample survey liter-

ature. When b(V(t), t; At) is nonzero, we refer to A (b) as an
augmented IPCW (AIPCW) estimator.

;t

(n>\

The regularity condition 2 of Appendix A guaran-

tees that ir(V(T), Y) > 0 with probability 1. Thus

E[/\/r(V(T), Y)lV(T), Y] =1, and hence E[h(O;Ato,

A0; b)] 0 for any function b. Using standard Tay-

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1101

tor f(b) is asymptotically linear with influence function

where Niv(u) = I(Vi = v,Qi < u,Ai = 0) and nv =

nZ I(Vi = v). Because Y is not always observed,
d(O; b)we
if n1/2(fA(b) - p0) = n-i/2 En I d(Oi; b) + op
where E[d(O;b)] 0,0 < E[d(O;b)2] < oo, and op(1)

need to modify the foregoing estimator. The integrand
of (4) is not observable. So we would like to replace it
with an observable quantity that has the same probability

refers to a random variable converging to 0 in probabil-

ity. An estimator f(b) of [Lo is regular in a semiparametric model if its convergence to [Lo is locally uniform

limit. The key observation is that E[AI(V = v)S(ulV =
v,Y)/S(TIV = v,Y) V = v,Y,Q > u] = 1, so that by a

(See Bickel, Klassen, Ritov, and Wellner 1993 for a more

uniform large of large numbers,

precise definition.) Regularity is a technical condition imposed to prohibit superefficient estimators. In fact, even

sup - E I(Vi = V) exp(c0Yi)I(Qi > u)

a fully parametric model will have nonregular estima-

uE[O,T] nV i=

tors whose asymptotic variance is less than the Cramer-

Rao variance bound. If f(b) is asymptotically linear, then

1 n Ail(Vi = V) exp(aOYi)I(Qi > u)

(ft(b)
- [to)
is }asymptotically normal with mean 0 and
nv i=1 exp{-exp(ao Yi) (AO (TIVi = V) ni/2
- AO
(u Vi
V))
variance E[d(O; b)2]. Further, any two asymptotically linear
estimators with the same influence function are asymptot-

P

-+0.

ically equivalent in the sense that n'/2 times their difference converges to 0 in probability. In general, the influence

The latter quantity within the absolute value depends on

function d(O; b) of f(b) will not be equal to the influence

Ao(.IV = v), but we can substitute A(.IV = v) to define
function -T(b)- 1h(O; [to, A0; b) of f(b), and the asymp-

the recursive estimator

totic variance E[d(O; b)2] will not be consistently estimated

by

A(tlV = v)

n

_ t (sI n E il(Vi = V) exp(aoYi)I(Qi > u) 0 nv i=1 exp(- exp(eogYi)(lA(TJVi = v) - lA(ulVi = v)))J

nr1(b) 2 h(O; A (b), A; b)2. (5)
i=l1

This is because for most choices of b, estimation of
x -EdNiv(u))

Ao (t V) contributes a term to the asymptotic variance of f(b), in which case the asymptotic variance

Ao;b)2] of f(b) cannot be the same
We can obtain an explicit solution for A(tIVT(b)-2E[h(O;/[to,
= v) as folE[d(O; b)2].
lows. First, note that A(tIV = v) is a step function with

jumps at each of the unique censoring times in the group
with V = v. Thus we need only compute the jump sizes.

Henceforth, let Qvl), < ... < Qv denote these unique
times. Let cv denote the number of subjects who are cen-

sored at Qvk)' k 1,... kv. Note that when, as we have
assumed, Q has a continuous distribution function, cv will

only take value 1. Thus we can write A(tIV = v)

In fact, regardless of the choice of the function b, all es-

timators A(b) will have the same influence function with
asymptotic variance equal to the semiparametric variance

bound for estimators of [to in model A(ao). This follows

from the fact that by Theorem 1, model A(oao) is a nonparametric model for the observed data 0, and Bickel et al.

(1993) proved that for any nonparametric model, all RAL

estimators of any functional of Fo (such as [to) have the
Zv=L AvI(Qvk) < t), where the jump size Av is found by
same influence function. Thus if we can find a function b*
the following procedure:

for which estimation of A0o(t V) does not contribute to the

1. Akv A E1/il(Vi = v) exp(atoYi))-'cv

2. For k = kv-1,.. 1, sequentially compute

asymptotic variance of A(b), then for all b, A(b) will have
influence function-T(b*) -h(O; [to, A0; b*). For b /h b*, the

asymptotic variance of A(b) will be consistently estimated

not by (5), but rather by

AV (E h~il(Vi = v) exp(aoYi) A v

i=1 exp(-exp( joYv) kk+lA) J

n

n 1;(b*)-2 h(Oi; A(b), ;b*)2 (6)
it 1

Under regularity conditions, we would expect n/2{A(I IV We now present a heuristic approach to finding b*. Our
estimating function h(0; At, A0; b) depends on the unrev) - Ao(. V = v)} to converge to a Gaussian process.
stricted infinite-dimensional nuisance parameter A0o(tIV).
Hence we consistently estimate the survivor function of
Estimation
of A0o(tIV) does not contribute to the asympQ given V = v and Y by S(tIV = v, Y) = exp(-A(tIV
totic variance of A(b) when A0O(tIV) is unrestricted if and
v) exp(aoY)).
only if the same is true when Ao (tIV) follows any arbitrary
If V is discrete or V is univariate and continuous, Ao(tIV)
correctly specified parametric submodel. But if A0o(tlV),
is smooth as a function of V, and the binwidth is decreased
with increasing sample size at an appropriate rate, then, un-

or, equivalently A0 (t V), had a known parametric form in-

der some additional mild regularity conditions 8t(b) should dexed by r1 with true value r?o and estimated value i1, then
we could write h(0; At Ao; b) as ht (0; ,u, rp0; b) and expand
be a regular and asymptotically linear (RAL) estimator of
,u with influence function d(O; b). Recall that an estima-

ht (0; A,u1; b) around r1o to derive the asymptotic variance

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1102 Journal of the American Statistical Association, December 1999

of 8(b). Inspection of the Taylor expansion terms would

-T(b*)-lh(O; /to, Ao; b*) with asymptotic variance that can

reveal that a necessary and sufficient condition for the esti-

be consistently estimated by (6) with b* replaced by &*

mation of r1 not to affect the asymptotic variance of 8(b) is

that n- Ei aht (Oi; po, ?jo; b)/&9j converge to 0 in probabil-

Interestingly, when V(t) = V is time independent, our

estimate A(TJV = v) of Ao(TIV = v) depends on the data

ity, or, equivalently, that E[9ht (0; bo, qo; b)/9q] = 0. But it only through {(Ai, Yi Ai, Vi): i = 1, ... , n}. In particular, it

can be shown (Newey 1990) that E[9ht (0; /o0, bo9; q] = is not a function of the actual drop-out times Q or even of

E[h(O;[to,Ao;b)Sq], where S. = o9nL(to, Do; 0)/9qtheir

ranks. It follows that for choices of b(v(t), t; y) that do

is the derivative of the observed-data log-likelihood

not depend on t, including b* (v; At), At(b) is not a function of
ther.
Qi's.
In contrast, it follows from the proof of Theorem
In L(bto, q; 0) for a single subject with respect to
Thus
1 in Appendix A that if V(t) were time dependent or if we
we conclude that estimation of A0o(t V) will not contribute
to the asymptotic variance only for those choices of b such
replaced ao Y in (1) by a known function r(t, ao; V(T), Y)

that depended on t, then [Lo would not even be identified in
that h(O; [Lo, Ao; b) is uncorrelated with the scores S. of all
model A(cao) in the absence of data on the drop-out times
parametric submodels for Ao(t V). In Appendix B we show
that there exists one and only one such function b*, given
Q. Given data on Q, it is straightforward to generalize the
by

estimators f(b) to obtain estimators of [Lo in model A(ao)
when V(t) is time dependent (but still low dimensional)

b* (V, t; t) b* (V; t)

and/or r(t, co; V(T), Y) replaces aovY. In this setting the

E[(Y-t) exp(aoY) V]/E[exp(aoY) IV].
(7)
The function b* (V; At) is not available for data analysis,
because it depends on the unknown conditional expectations
in (7). However, using the arguments of Robins, Mark, and

function b*(V(t),t; /t), for which h(O;[to,Ao;b*) is uncorrelated with all nuisance scores, will depend on t and is
characterized in Appendix B.

When V(t) is low dimensional, an obvious competitor to

our AIPCW estimator At(b*) is the nonparametric maximum

likelihood estimator (NPMLE) of [to (van der Laan 1993),
which is asymptotically equivalent to f(b*). Indeed, it may

be algebraically equivalent, depending on which of sevNewey (1992), it can be shown that if b* (v; At) is a consistent
eral possible "nonparametric likelihood functions" is maxestimator of b* (v; At) for each v, then At(b*) and At(b*) have
imized (Murphy 1995). However, as shown in Section 4,
the same asymptotic variance, so that (6), with b* replaced
the AIPCW methodology generalizes straightforwardly to
by b*, is a consistent variance estimator for f(b*). Indeed
model B(ao) with V(t) high dimensional. In this latter setit is consistent for the asymptotic variance of any 8(b). In

practice, we recommend that one use the estimator ft(b*) in
lieu of the alternative estimators 8(b), because then one obtains "for free" a consistent variance estimator. Under regu-

ting, the NPMLE is undefined (Robins and Ritov 1997).
4. ESTIMATION IN MODEL B(ao,)

larity conditions, for any given function 1(), E[l (Y) V = v] 4.1 A Class of Estimators
is consistently estimated by

To motivate our estimator of b0 = (10, -yo,)' in m
B(ao), suppose for the moment that the baseline hazard

E[l(Y)IV = v] = 1 E AiI(V= v)l(Y2)
Thus we estimate b*(v;At) by b*(v;At) = E[(Y

Ao(t) in (2) is known. Let Ao (t) = Aof Ao(u) dt denote the cumulate baseline hazard. We assume that W(t) and -yo in (2)
are q-dimensional. Consider the q + 1 vector of augmented
IPCW estimating functions h(O; 'b, Ao; b), where h(O; 'b,

Ao;
b) = (hi
(O; 0, Ao, bi), I .. ., hq+1 (O;o I, AO I bq+l))', b =
t) exp(ao Y)IV = v]/E[exp(ao Y) V = v]. Note
that
A (b*)
(bi,.. I ,bq+) bj = bj (V(t), t; 'b) are real-valued functions

can be written in closed form as

of (v(t), t, 'b) chosen by the data analyst, hi(O; i7, AO, bl)

ni Ai

A(Y - /1)/1(V(T),Y;-y) + a(Ov;ib,Ao;bj), for j

A(b*) = - ;(Vi E
i)
1, hj(O;
0, AoIYi
bj) = a(O; I, Ao; bj) with wr(V(T), Y; -y)

S(T V(T), Y; -y), S(t V(T), Y; -y) _ exp(-j exp(-y'W(u)
Ai- -k(Vi, Yi) E[Y exp(atoY) IV = Vil
_k(Vi, Yi) E[exp(coY)[V = Vi]

To summarize the results of this section, we state the

following proposition. Here and throughout, results whose
proof would require the detailed checking of precise regularity conditions are termed propositions rather than theorems. Rigorous proofs would require modern empirical
process theory and are beyond the scope of this article.

+ aoY) Ao(u) du),

a(O; +, Ao; bj)
A

- - (V(T)Yy )EY[(l -A)bj(V(Q),Q;4')YV(T),Y]
+ (1 - A)bj (V(Q), Q; '),
and E [. V(T), Y] indicates expectations with respect to

Proposition]1. Suppose that A0(T V =v) is finite, V is

the distribution F(t V(T), Y; y) 1 1-S(t V(T), Y; -y).

a discrete random vector, and Y has bounded support. Then

Because E[a(O; ', Ao; ba)] =0, the estimating function
h(O;4o, A0, b) has mean 0. Thus, by standard Taylor se-

f(b*) and f(b), for any b, are RAL with influence function

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1103

under mild regularity conditions, + (b) would be a reg-

ries arguments, the solution +](b) to

ular asymptotically linear estimator of f0 with influence

n

function d(O; b), say. However, the asymptotic variance

Zh(Oi; +b,Ao;b) = 0

E[d(O; b)?2] of 4(b) will not in general be given by an

i=l1

analog of (8), because we need to adjust for the estimation

of Ao (t). Hence further work will be required to obtain
totic variance r(b)-1var[h(O; 'b0, Ao; b)]-r(b)1- provided
confidence intervals for 40. We consider three variance es-

will be asymptotically normal with mean 0 and asymp-

timation
that Ti(b) _ aE[h(O; bl, Ao; b)]1/a&Ip=,po is invertible.
The procedures.

asymptotic variance can be consistently estimated by

The first procedure is to follow the approach of Section

3 and determine those functions b* (v(t), t; 'i) for which

h(O; 'b0, Ao; b*) is uncorrelated with the scores S., for all

f(b)-1 [nr lE h(Oi; +(b), Ao; )2] 7(b)11, (8)parametric

models A(t; r1) for Ao(t) of (2), so that no adjust-

ment to the variance will be required. As in the previous

with '(b) = n-L En> &h(Oi; + (b), Ao; b)/&0.
Because Ao(u) is unknown, it must be estimated. If we
could always observe Y, then we could replace Ao in the
foregoing estimating functions by Breslow's profile estimator for the baseline hazard with censoring times representing the jump times (Andersen et al. 1993). We can express

case, b* will have to be estimated from the observed data.
If b(v(t), t; 'b) converges in probability to b*(V(t), t; +b),

then, under mild regularity conditions, the estimator +b(b*)
will be a RAL estimator with asymptotic variance that
can be consistently estimated by the following analog
of (8):

this profile estimator as

T(b*)-

A(t; y) (- exp(-y'Wi(U) + oYi)I(Qi > u))

x [n-1Eh(Oi;4(b*),A( 7(b*));b*)?21 #(b*>l (9)

n~~~~~
i=1~ni=

where Ti(b*) = r- ah (0i; (b A b*)); b*)
&g. The second approach is' to develop an analytic expres-

sion for the influence function d(O; b) of + (b) for any
where Ni(u) = I(Qi < u, Ai = 0). Because Y is not always
choice of b. In model B(ago) this approach is somewhat
observed, we modify the foregoing estimator using a similar
complex, and it is not considered further in this article. The
argument as in Section 3 to yield the following recursive
third approach is to recognize that if +b(b) is a RAL estimaprofile estimator for Ao(t):
tor, then we can obtain a consistent estimate of its asymptotic variance by the nonparametric bootstrap (Gill 1989).
A(t; y)
Because in conducting a sensitivity analysis it is necessary

- Jt I i Ai exp(y'Wi(u) + aoYi)I(Qi >) )
J n exp fexp(- f exp(yWi(x) + ao Yi)d(x; -))
x (IidNi(u).

We can obtain an explicit solution for A(t; -y) using
an approach analogous to that described in Section
3. Given A(t; -y), we can estimate S(t V(T), Y; y) by

S(t V(T), Y; y/) - exp(- ft exp(-y'W(u) + coYo) dA(u; ty))
and F(t V(T), Y; y) by F(t V(T), Y;ty) 1 1-S(tlV(T),

Y;y)

to calculate confidence intervals for p,o for many values
of the selection bias parameter og, bootstrap variance estimation may require impractically large computation time.
Thus in the simulations and data analyses reported in Sections 5 and 6, we use the first of the three approaches, which
we describe in the next subsection. However, it should be
noted that the bootstrap variance estimator, in contrast to
the analytic estimator (9), will remain a consistent estimator of the asymptotic variance even under misspecification
of model B(oao).
4.2 Estimation of b*

In model B(ao), in contrast to model A(ao), the set b* of

Now define +,(b) to be the solution to
n

Z h(Oi;+b,A(.;y);b) 0 ,
i=l1

where h(O;bt,A(; y);b) is defined like h(O A,tAo; b) ex-

functions b* such that h(O; 'Vo, AO, b*) is orthogonal to the
scores S,, for any parametric model A(t; r1) has an infinite
number of elements. In Appendix B we show that we can
map an arbitrary q?+ -dimensional function 4 4(V(t), t)
into a particular member b* of the set b* by solving the
Volterra integral equation,

cept that S and F are replaced by S and F, so E[(1-

3G)bi(V(Q),tQ; y)wV(T),eY] n eiatbe(V(t), t; ) dF(tV
(T),Y;ty) and Yr(V(T),Y;y) =t S(TYV(T),Y;=y). In the
foregoing estimating equation, the function b need be evaluated only at the censoring times. One would expect that

- q5(V(t), t) -E[S(t|V(T), y; yo)
x expQytoW(t) + otoY)]1 -qb* ,(t; '+b), (10)

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1104 Journal of the American Statistical Association, December 1999

where

function 4) = 4)(v(t), t) such that / and g,(b*) have the
same influence function, with b* determined by 4) via (11).

qb, (t; '00)

Efficiency
- E[/(V(t), t)S(t V(T), 4.3Y;
yO) exp(%y'W(t) + oY

efficiency of the estimator b(b*) will depend on
+ { E [b(V(u), u; 'V) The
dF(u
V(T), Y; yo)

the

choice of 4). The optimal choice 4)?pt will result in an es-

timator + (b*t) whose asymptotic variance will attain the
x exp(-yOW(t) + semiparametric
oaoy)] variance
}
bound for model Macgo). Furthermore, because model B(oao) does not suffer from the curse

-E[el (Y -,o) exp(%W(t) + atoY)]
and el is the q+l-dimensional vector whose first component
is 1 and whose remaining components are 0. We also show

that any b* E b* satisfies (10) for some 4(v(t),t).

of dimensionality due to the dimension reduction implicit

in (2), the finite-sample variance of +b(b*pt) should be generally close to the variance predicted by asymptotic theory
(Robins and Ritov 1997). Unfortunately, the optimal choice

4)opt is not available for two reasons. First, 4)opt is a function of the unknown distribution joint distribution Fo of the
on the unknown distribution Fo of the data, b* will have to
observed data. Second, even if Fo were known, calculation
be estimated. In practice, one selects a function 04(V(t), t),
of 4)opt would require solving an exceedingly complex intethen obtains an estimator b* (V(t), t; 'i) for the correspondAs in Section 3, because the solution b* to (10) depends

ing function b*(V(t), t; 'i) that is consistent at b = 'b0. Let

gral equation. In light of this second reason, we forego try-

ing to obtain a semiparametric efficient estimator. A simple

Q(j) be the jth ordered censoring time and define Q(o) = 0.
Then the estimator b* (V(t), t; t) is recursively defined (in
forward time) by the following empirical version of (10).

For t E (Q(k), Q(k+1)], k = 0, 1, 2, ... ,

choice of 4) that we use in our simulation studies and in our

reanalysis of the ACTG 175 data in Sections 5 and 6 is to
take

4)(V(t), t; sb) = (0, W(t))'. (12)

b* (V(t) t; sb)

= (V(t), t) -E [S(t V(T), Y; y)

Although not efficient, this choice of 4) will be suitable
when the uncertainty in the mean p,o due to not knowing the

x exp(-y'WMt + at?Y)1-ld6* ?,(t; O)' (11)
true
where, for any Z z(V(T),Y),E_(Z) _ n- i=

value of ao is considered by subject matter experts to

dominate the uncertainty due to sampling variability. However, in settings where sampling variability dominates, it

Zi /r(Vi(T), Yj; -y); ,F, and S are as defined earlier;

will often be useful to attempt to find more efficient choices

for 4). To this end, in Appendix C we propose an adaptive

db, 0(t; '0)

= k1(V(t), t)S(t V(T), Y; y) exp(y'W(t) + o oY)]

choice for 4), 4)adap, that will result in highly, although not

fully, efficient estimates of the mean p of Y under model
B(ago). Our approach is motivated by the observations that

k

+ E Ea[b(V(Qd), Q(; iP)dF(Q(j) [V(T), Y; y)
j=l

x exp(-y'W(t) + o0oY)]
- E [ei (Y - p) exp(y'W(t) + ao Y)];

(a) if a0 = 0, the semiparametric variance bounds in models

A(ago) and B(ago) will be identical (Robins and Rotnitzky

1992), and (b) even when aeo = 0, if W(t) in (2) is high
dimensional, the semiparametric variance bound in model
B(ago) will be only slightly less than the variance bound for

the larger model A(ago). Thus if we can obtain an estima-

and E_ = 0. To execute this recursive algorithm, it is suf-

tor of p,o whose asymptotic variance is close to the variance

ficient to have computed b*(V(Q(j)), Q(j); b), j =O,.. ,bound
k
for model A(ago), then it should have reasonably good
to compute b* (V(t), t; +b) for all t E (Q(k), Q(k+1)]. In sum-efficiency relative to the semiparametric efficient estimator
mary, we can state the following proposition.
b(b*pt) for model B(aeo).
Proposition 2. Suppose that Ao(T) is finite, V(t)

is a stochastic process with bounded support, bo0 lies
in the interior of a compact set 'L0 c Rq+l, and
b* is determined by some function 0 via (11). Then,
in model B(ago), g(b*) is RAL with influence function

5. SIMULATION STUDIES

To evaluate the finite-sample performance of our estima-

tion techniques under models A(ago) and B(ago), we conducted two simulation studies.

-o9E[h(O;4b,Ao;b*)]/a&b-l fOh(O;v7bO,Ao;b*) and with
5.1 Model A(aO)
asymptotic variance that can be consistently estimated by
We generated data under the assumption that V was a
(9). Here b* is the probability limit of b* at 'b = +.
Bernoulli random variable with mean .3 and that the con-

In Appendix B we show that our class of estimators

ditional law of Y given V was normally distributed with

{g,(V ) } contains, up to asymptotic equivalence, all RAL

mean V - .3 and variance 1, truncated at V - 2.26 and

estimators in model B(cgo). That is, if 4' is any other RAL
estimator of 4'o in model B(cgo), then there will exist some

of Y is 0. We also assumed that the conditional law of Q

V + 1.66. These assumptions imply that the marginal m

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1105

given V and Y follows an exponential distribution with

Table 2. Results of Simulation

hazard (6o + 6IV)exp(aoY), where 60 and 61 are fixed
constants. We took T 1. We selected 0, 61, and ao so

Fixed ao

that P[Q > 1IV = O, Y -.3] = .65, P[Q > 1IV = 1, Y =
.7] = .50, and P[Q > IIV = 1, Y = 2.35] = .40. These conALo

straints yield true values of 60, 61, and ao of .4308, .1849,

Average -.1782 -.0926 -.0041 .0869 .1771

Standard deviation .0500 .0513 .0539 .0577 .0618

Average of standard

and .1691, indicating that subjects with high values of Y

errors .0514 .0538 .0592 .0685 .0823

and V were more likely to drop out. We simulated 500
datasets of 500 subjects each. To reflect the fact that in

0 .2294 .4588 .6882 .9176

-yo Average .4138 .3524 .2884 .2238 .1622
Standard deviation .0887 .0917 .0968 .1047 .1161

practice one would not know the true value of ao, we fit

Average of standard

five models with equally spaced aoO's ranging from -.1691

errors .0808 .0811 .0827 .0866 .0934

to .5073. The results of this simulation study are presented

in Table 1. For each ao, the table displays the averages of
the parameter estimates, the standard deviation of the parameter estimates, and the averages of the standard errors.

We see that when we guess the true ao, we get an unbiased
estimate of the mean. Note that our variance estimator ap-

we do not know the true value of ao, we fit five models
with equally spaced ca0's ranging from 0 to .9176. In the

estimation procedure, we chose the 4 (V(t), t; 'i) given by
(12). The results of this simulation study are presented in

pears virtually unbiased for all values of ao. This reflects
the fact that model A(ao) is, as indicated by Theorem 1,

Table 2. For varying levels of aoE, this table displays the

a nonparametric model for the distribution Fo of the ob-

of the parameter estimates, and the averages of the stan-

averages of the parameter estimates, the standard deviation

served data. This implies that our variance estimate will be

dard errors. We see that when we guess the true ao, we

consistent for all values of ar0, not just for the value that

get unbiased parameter estimates. Finally, it is encourag-

generated the data.

ing to note that our variance estimator performs relatively

5.2 Model B(a0,)

is not nonparametric, our asymptotic theory only predicts

well at all values of ao. Note that because model B(ago)
For this simulation study, we conceived of a longitudinal study in which measurements were taken at five time

that our variance estimator should perform well at the true

value of ao0.

points, t = 0, .25, .5, .75, 1. Let Vt denote the measurement
6. SENSITIVITY ANALYSIS OF ACTG 175

at time t. We are interested in making inference about the

mean of the measurement Y = VI at time T - 1. We generated data under the assumption that the measurements

were multivariate normal with mean 0, variance 1, and an
AR-I covariance structure in which the covariance between

V, and Vt was equal to .64Is-tI. We truncated the measurements at -1.96 and 1.96. So the true mean of Y is 0.
We assumed that the measurements were constant between
measurements times so that

In this section we return to the analysis of ACTG 175

started in Section 2.2. Table 3 presents the estimated means
and standard errors for CD4 at week 56 for each of the

treatment groups using only the completers; that is, nondrop-outs. We have also included the drop-out rates. One

naive way to estimate the mean CD4 count pu0 at week 56
is to simply take the sample average over the completers.
This estimate will be unbiased if the data are missing com-

V(t) = VoI(0 < t < .25) + V.251(.25 < t < .5)
+ V.51(.5 < t < .75) + V.751(.75 < t < 1) + V1I(t > 1).

In model B(aco) we chose AQ(tlV(1),Y) = Ao(t)exp

pletely at random (MCAR). Treatment comparisons at week
56 using the naive approach show that AZT is inferior to
the other three treatments, with some mild evidence of su-

periority of AZT + ddl over ddl. We fit models A(ago) and
B(ago) to these data to see how robust this inference is to vi-

(-yoV(t) + aooY); that is, w(t,V(t)) = V(t). In generatolation of the

ing Q's, we assumed that the baseline hazard was constant.

MCAR assumption. Due to space limitations,

we provide the results of only two sensitivity analyses, one

We selected the baseline hazard, -yo, and ao so that Pr[Q >

for model A(ago) and one for model B(ato).

1 V(1-) = 0,Y = 0] = .65,Pr[Q > 1 V(1-) = 1.645,Y =

0] = .50, and Pr[Q > 1 V(1-) = 0, Y = 1.645] = .40. Thus
6.1 Model A(a0)
the true baseline hazard was set equal to .4308, the true -yo
As described in Section 2.2, we considered model A(ago)
equal to .2891, and the true ao equal to .4588. We simulated 100 datasets of 500 subjects each. Because in reality
with V(t) the time-independent covariate denoting IV drug
Table 1. Results of Simulation Study for Model A(cao)

Table 3. Comparison of Mean Observed CD4 Counts at Week 56

Fixed ao
-.1691 0 .1691 .3382 .5073

Average -.1548 -.0791 -.0026 .0747 .1520
Standard deviation .0584 .0592 .0604 .0618 .0638
Average of standard
error .0565 .0567 .0570 .0574 .0578

CD4 at 56 Weeks

Treatment

AZT

Mean

312.05

S.E.

Drop-outs

7.11

36.0%

AZT + ddl 384.42 8.54 33.6%
AZT + ddC 369.55 7.71 36.6%
ddl

359.60

7.68

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

26.5%

1106 Journal of the American Statistical Association, December 1999

that AZT + ddl is better than AZT. This plot shows that this

user status at baseline. Figure 1 presented the estimated

conclusion is quite robust. Significant differential selection
means along with 95% confidence intervals for aoo's ranging
biases would have to occur to alter this conclusion. For

from -.02 to .02 for each of the four treatment groups.

To compare treatment groups, consider Figure 2. Here

example, we would change our conclusion if the selection

we present six contour plots, each representing a pairwise

bias parameters in the AZT and AZT + ddl arms were .01

treatment comparison. To illustrate the AZT versus AZT +

and 0.

How did we decide to choose the range of -.02- +.02 for

ddl comparison, note that on the x-axis we have varying

ao in Figure 1? The simple rule, which we followed, is that

levels of selection bias for the AZT arm, and on the y-axis

a sensitivity analysis should include a range of selection

we have varying levels of selection bias in the AZT + ddl

bias parameters ao that contains all values that would be

arm. For each combination of selection biases, we perform

considered plausible by relevant subject matter experts. To

a test (at the .05 level) of the null hypothesis of no treatment

include values of ao that lie outside the plausible range does

difference between mean CD4 at week 56. The graph is a

no harm, because subject matter experts will discount the

contour plot of the Z statistic as a function of the two levels

results for values of ago outside this range.

of selection biases. The two lines in each plot represent the

combinations that lead to a Z statistic of 1.96 and -1.96.

6.2 Model B(a0,)

To the left of the -1.96 line, we conclude that the data

provide evidence that AZT + ddl is better than AZT, and

In model B(ago) we included CD4 as a time-varying

to the right of the 1.96 line, we conclude that the data favor

regressor as well as the baseline covariates: age, CD4

AZT. Between the lines, there is not enough evidence to

count, and IV drug use. As in the simulation study in

draw either conclusion. The point at (0, 0) represents the

the previous section, we assume that CD4 counts are con-

CAR comparison, which jibes with the MCAR conclusion

stant between measurements. Specifically, we let T -

AZT

?

?

/

0

vs.

AZT+ddl

Z+d

AZ+dd

l

Figure

A

l

0

AZT

vs.

ddl

d

AZT+ddC

ddl

l

Pairwise

AZTa
c'J
o
-18
1.8

AZT+ddC

N

V

2.

vs.

Z+d

lAZT+ddl

N
V

AZT

AZT

c'J
-18
1.8
0

Cf

aph

Gd

t

AZT)

s

seAZT^-

lpaO(Ar

c'J
-1
896
1.8

c; AZT+ddCipha (AZ) iddl AZT aphdd(ZT

alphaO ~ ~ AZ AZTTl lha ATdl lpa ATdC
AZ+dl s.AZTTddC ZT+dd AZs. dd lAZT+ddCvs.ddd
c'J

c'J

c'J

~~~ AZT+ddChO AT+dl lpa ddl T dd) lpa ArdC
Fiue2 arieCmaio
fTetetGop nMdlA j ihI rgUe ttsa h ieIdpnetRgesr
V V V~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1107

56, Z(t) denote the CD4 count at time t, Vo = Z(O),Y =

The conclusions based on Figures 3 and 4 are qual-

Z(T), V1 denote age, V2 denote IV drug user status, and

itatively the same as those based on Figures 1 and 2.

V(t) (VO, V1, V2, Z(t))'. Then, in model B(ago) we assume

That is, significant differential selection bias would have

to occur for us to change our inference about AZT rela-

that

tive to the other three treatments, and inference about the

AQ(t V(T), Y)

other treatment comparisons is highly sensitive to nonig-

norability. However, the sensitivity of the estimated mean

- Ao(u) exp(-yooVo + yo V1 + Yo2V2 + yo3Z(t) + Zo Y).

to comparable changes in oz0 is rather less in Figures 3

In the estimation procedure, we chose q (V(t), t; 'b) given

and 4 than in Figures 1 and 2. Specifically, the varia-

by (12). In this setting eog is interpreted as the log hazard

tion in the estimated mean CD4 count at week 56

ratio of nonresponse between patients who have the same

varies from -.02 to .02 is less in Figure 3 than in Fig-

covariate history, but differ by 1 CD4 count at week 56.

ure 1. Similarly, when we restrict oz0 in the arms be-

When ozo -0, the Y's are CAR. When ozo > 0, we are

ing compared to the interval (-.005,.005), we observe

assuming that among subjects with the same covariate his-

that in Figure 2 but not in Figure 4 there are small re-

tory, those with higher values of Y are more likely to drop

gions where AZT is preferred to the other treatments. In

out. The opposite interpretation holds when ozo < 0. Figures

Section 7.2 we consider possible explanations for these

3 and 4 are the exact analogs of Figures 1 and 2 for this

observations.

model. In general, we include time-independent and timedependent covariates in V(t) that are correlated with the

7. ADDITIONAL CONSIDERATIONS

outcome Y and may predict drop-out at t in the hopes of

making the selection process approximately ignorable. (See

In this section we take up a number of remaining issues,

Sec. 7.2 for further discussion of this matter.)
AZT

o

o

co

several of which were raised by the referees.

AZT+ddl

o

AZT+ddC

0

0

0

L

ddl

0

0

...?

-0.02 0.01 0.0 0.01 0.02 -0.02 -0.01 0.0 0.01 0.02 0.02 0.01 0.0 0.01 0.02 -0.02 0.01 0.0 0.01 0.02
alphaO

alphaO

Figure

3.

alphaO

alphaO

Treatment-S

User Status, and Time-Dependent CD4 as the Regressors.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1108 Journal of the American Statistical Association, December 1999

positive value of ozo, that the drop-outs consist largely of

7.1 Estimation of Other Smooth Functionals of the

subjects with values of Y in the extreme right tail.

Distribution of Y

It is easy to adapt the estimation procedures described

7.2 Bounds and the Breakdown of Augmented Inverse

in Sections 3 and 4 to estimate other smooth functionals of

Probability of Censoring Weighted Estimators

the marginal distribution of Y. One simply needs to replace

(Y - [) in the equations of these sections with the full

7.2.1 Bounds. An alternative to our approach based

data influence function for the functional of interest. For

on sensitivity analysis is one based on estimating upper

example, if we would like to estimate the median of Y,

and lower bounds for the mean pio compatible with the ob-

then we replace (Y - [) by I(Y > ,u) - .5, where [u now

served data. Specifically, if Y is a bounded random vari-

denotes the median. For influence functions that are not

able and the upper and lower bounds are known, then one

differentiable in [u, we suggest using numerical derivatives

obtains an estimate Atupper (Alower) of the upper (lower)
bound for pio by filling in the unobserved Y's with the

to estimate T(b) in the asymptotic variance. In model A(oo)
we estimated the median as a function of oz0 for each of

largest (smallest) possible value of variable Y, Ymax (Ymin).

the four treatment groups. As expected, for each treatment

It seems natural to hope that our choice of selection bias

group, the estimated medians increased monotonically with

function r (t, ozo; V(T), Y) attains these bounds in the sense
ozo. For positive values of oz0, the rate of increase was less
that, as ozo approaches infinity and minus-infinity, our esti

for the median than for the mean. This observation can be

mates of pio approach the estimated upper and lower bounds

explained as follows. Because the empirical distributions of

just described. In model A(cao) our choice of ao0Y for

the observed Y's have short left tails but long right tails,
we would expect that the mean, but not the median, would

r(t, cor; V(T), Y) often satisfies this hope even in finite samples when the random variable V(T) is discrete with only a

be highly sensitive to the assumption, encoded in a large

moderate number of levels. Specifically, suppose that V(t)

AZT

o

vs.

AZT+ddl

AZT+ddl

V

AZT

o

+

N

-

6

6

-0.01

0.01

alphaO

0.02

-0.02

(AZT)

vs.

ddl

ddl

Q

AZT

6~~~-

0.0

AZT

V2

N

AZT

-0.02

AZT+ddC

AZT+ddC

Vo

I-

vs.

-

-0.01

0.0

alphaO

AZT

6C
0.01

0.02

(AZT)

-0.02

-0.01

alphao

0.0

0.01

0.02

(AZT)

AZT+ddl vs. AZT+ddC AZT+ddl vs. ddl AZT+ddC vs. ddl
CD

o

-1

6

AZT+ddl

O

/

-16

AZT+ddl

~~ATddO

6o

-0.02

6D

-0.01

9

0.0

0.01

alphaO

Figure

4.

0.02

g

AZT+ddC

ddl

-16

-0.02

(AZT+ddl)

Pairwise

C

-0.01

alphaO

0.0

0.01

0.02

(AZT+ddl)

Comparison

s-

-0.02

alphaO

of

'ddl

1

-0.01

0.0

0.01

0.02

(AZT+ddC)

Treatment

as the Regressors.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Groups

in

M

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1109

alphaO =-0.02 alphaO =-0.016 alphaO =-0.012 alphaO =-0.008

rtm

o,

CfU~~

1

?If

lUO0

O

U

O

0

if0)0
Observed CD4 Count at Week 56 Observed
CD4 Count at Week 56 Observed CD4 Count at Week 56 Observed CD4 Count at Week 56

11

>
U
alphaO =-0.004
alphaO=O0.O
alphaO=0.0040
alphaO=0.008

o

o

0

;

20

_

400

<

600

0lphaO
Obsrve

0

200

CD

400

t

80c00

=A

Con

600

E

0.012

at

800

0

0

|

E

t

20406080o00

alphaO

Wek5

1000

0

=

0.016

bevdC4Cuta

200

400

600

0

ee

800

0

M

20406080100

alphaO

6Osre

1000

\60

0

D

200

0

0~~~~~~~0)

2040608010

=0.02

on

tWe

400

600

5

bevdC4Cuta

800

1000

0

200

ek5

400

600

800

1000

Observed CD4 Count at Week 56 Observed CD4 Count at Week 56 Observed CD4 Count at Week 56 Observed CD4 Count at Week56

o:
0)

0

1

0)1

00

0

0

0

0~~~~~~~~~~~~~~~~~~~~~
alphaO 0.004 alphaOa 0.0W alphaOt
0.004 Model = 0.008

~~

i1~~

0

0

~000
0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

0
0

200

400

600

9

0

800

0

1000

200

0~~~~(0
400

600

(,0
1N
800
1000
0 200

400

600

800

0
1000

0

20

40

60

80

10

Observed CD4 Count at Week 56 Observed CD4 Count at Week 56 Observed CD4 Count at Week 56ObevdC4outaWek5

F ague5 aObseveC0 4tW012VesuthlnvereofheAs0.016dstiatedeihtsnMdIA 0.02febyVDuUsrtau
91 0VDu Ue;0*NnDugUe)

is discrete for each t and the selves)
number
of weight
potential
jump
times
and an additional
n' ropfnvopiete
to account
for the process V(t) is small. Then, if at each possible level

for the drop-outs. Because model A(ao) leaves the baseline

v-(T) of V(T) there is a subject in the dataset whose ob-

hazard Ao(tlV) unrestricted, all redistribution of weight is

served value of Y attains the upper (lower) bound for Y,

then the estimates 8(b) and f(b*) of Section 3 will approach

stratum specific. For ao 74 0, in stratum v the fraction of
the drop-outs' total contribution nvrop assigned to a com-

Aupper (Alower) as ao -X oo (oo -X -oo).

pleter will depend on the completer's outcome Y. Let yvax

To see why, we study the simplest case. Specifically, we

(yv in) be the maximum (minimum) of the observed values

consider the behavior of the IPCW estimator ,i(O) solving
of Y among completers in stratum v, and let nvmax (nin)
the estimating equation 0 = Ei Ai (Yi - t)/1(Vi, Yi)beofthe number of completers in stratum v with Y = yvax
Section 3, when V(t) = V is time independent and dis(YV.in). Then as cao X oc (cao - -oc), completers in stra-

crete and r(t, ao; V(T), Y) = ao Y. Each completer (non-

tum v with Y = Yv ax (Yv in) are assigned weights tending to

drop-out) contributes a weight iK` that depends on ao.

- 1 +- Tidrop/nmax (fr1 1 + nvdrop/nrin); completers

When co = 0, each completer in stratum V = v rewhose observed Y do not equal Yv ax (Yv in) are assigned
ceives weight fr I = 1 + nv rop/vompiete, where ndrop
andtending to 1. The intuition is as follows. Consider
weights
nvomp ete are the number of drop-outs and the number of
two values Yi and Y2 of Y with Y2 > Yl. Then within stratum
completers in stratum v. This is because in stratum v we

v, the hazard ratio for drop-out of a subject with Y = Y2

need to redistribute the contribution of the nrop drop-outs

compared to a subject with Y = Yi is exp(cao(Y2 -YO),

to the completers. When co = 0, within stratum v all com- which goes to oo(O) as cao 4 oc (cao - -oc). Thus when
pleters are exchangeable. So we redistribute the drop-outs'
cao X oo (c'1o -4 -o), our estimation assigns any drop-out
contribution equally among the nvomp ete completers. Thus

the largest (smallest) possible value of Y in the stratum; that

each completer receives a weight 1 (corresponding to them-

is, YVmax (Yv in). It follows that as cao - oc (cao - -oc), ,(O)

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1110 Journal of the American Statistical Association, December 1999

a parametric
likelihood-based
estimator
(which effectively
[and indeed /(b*) and 8(b)
for
any b]
tends
to fma

imputessample
values of Y to the
drop-outs that lieof
outside
theover
where /Umax (Amin) is the
average
Y

study subjects when the drop-outs in stratum v have been

observed sample range); and (f) replace model A(cao) with

an alternative NPI model that naturally allows for extrapimputed the common value Yv ax (Yv in)* If Yvnax = Ymax
outside the range of Y in the completers, by not
(Yv in = Ymin) for all v, then ftmax and fLmin will equalolation
the

upper and lower bounds /tupper and AUlower.
To illustrate the foregoing discussion of weights, we re-

turn to our analysis of the ACTG 175 data under model

requiring that ir(V, Y) > 0 with probability 1 for identifi-

cation of the mean. None of these alternatives is necessarily
a satisfactory solution.

A(cao). Figure 5 plots, for the AZT treatment arm, the in-

For instance, whether strategy (a) is satisfactory will de-

verse weights fr for the completers as a function of the ob-

pend on the substantive setting. For example, in ACTG 175,

served outcome Y and IV drug user status V for different

values of ca0. As expected, when ca0 is very positive (neg-

the estimator ,i(b*) of Section 6.1 will break down only for
values of co that imply that the mean of Y among the drop-

ative), the weights ft-- greatly exceed 1 for only the few

outs in at least one stratum v is nearly as large (small) if

subjects with extremely large (small) values for Y. Further,
as seen in Figure 1, as ca0 becomes very positive (nega-

not larger (smaller) than y'ax (y' ij. The AIDS clinicians

we have consulted do not find this magnitude of selection

bias credible. Suggestion (b) may be unsatisfactory for two

tive), f(b*) approaches an asymptote equal to Amax (fmin).
The weights in our simulation experiment did not blow up

similarly, because of our truncation of the range of Y.
7.2.2 Breakdown of Augmented Inverse Probability of

Censoring Weighted Estimators. It is well known that

reasons. First, the median may not be an estimand of scientific interest. Second, the estimated median might on occasion be surprisingly sensitive. As an extreme but illustra-

tive example, suppose that no covariate data V are available

as f(b*) can degrade as the weights i-I become highly

and that 51% of the subjects drop out. Then as cao - Xo
(ceo -4 -oo), the estimate of the median converges to the
maximum (minimum) observed Y and will be greater (less)

skew, because the estimator f(b*) is then largely deter-

than the estimated mean, indicating greater sensitivity of

mined by those few individuals with large weights. When

the median than of the mean to the changes in cao. Suggestion (c) may be unsatisfactory when, based on subject mat-

the performance of IPCW and AIPCW estimators such

as in the ACTG 175 data (with V being IV drug user
status), the empirical conditional distributions of Y given

ter considerations, the exponential form form exp(caoY) is

V = 1 and V = 0 in the completers are reasonably

considered to be more plausible than other forms. However,

spread out and have substantial overlap, and ca is chosen

we used the exponential form in our analysis of ACTG 175,

very positive (negative), the estimated weights fi-K will be

not because we thought it substantively plausible, but rather

markedly skew and highly positively (negatively) correlated because it is the usual default choice, and because it can result in the breakdown of AIPCW estimators, opening the

with the observed Y. This indicates that it is likely that un-

der the law Fo of the observed data, the population weightsdoor to this very discussion. Suggestion (d) is considered
r(V, Y) - = Pr[[A = IIV,Y]V- will also be quite skew in the next section. Suggestion (e) can be unsatisfactory beand highly positively (negatively) correlated with Y given

cause, as discussed earlier, assuming a parametric model

A = 1. In such a case the AIPCW estimator of the mean

may result in scientifically unjustified identification of cao
and bLo. In fact, we recommend option (f) whenever it is

breaks down, because, with high probability, subjects with

large (small) values of Y will not be captured in the sample.

substantively plausible that the support of the distribution

As a result, with high probability, the estimator ,i(b*) will

of Y among the drop-outs may differ from that among the

seriously underestimate (overestimate) the mean ,uo, and,

furthermore, the variance estimator (6) will severely under-

completers. (See Sec. 7.3.2 for details and caveats.)
7.2.3 Adjustment for Additional Covariates and Plausi-

estimate the true variability of /(b*). Indeed, /o is identified
ble Ranges for Sensitivity Analysis Parameters. It is sciunder model A(cao) if and only if ir(V, Y) > 0 with probaentifically desirable to adjust for selection bias due to mea-

bility 1, which is equivalent to saying that at each level of V,

the support of Y among the drop-outs (A = 0) is contained
within the support of Y for the completers (A = 1). Regu-

larity condition 2 of Appendix A implies that ir(V, Y) > 0
with probability 1.
One can try to deal with the breakdown of the estimator

sured covariates by including them in V(t). In this sense,

suggestion (d) is always a good one. Because the number
and nature of measured factors varies from study to study,
it is important that subject matter experts be able to pro-

vide a plausible range for cao in (1) for various choices of
V(t). Adding to V(t) data on additional time-independent

/(b*) by a combination of one or more of the following:
and dependent covariates that are both correlated with the
(a) reassess the substantive plausibility of the values of cao

outcome Y and predict drop-out at t will usually serve to

causing the trouble; (b) restrict attention to functionals suchdiminish the degree of nonignorable selection bias due to
as the median that are less sensitive to the tails of the dis-

unmeasured factors. Initially, we had expected this to im-

tribution of Y; (c) replace exp(caoY) in (1) by a bounded,

ply that adding covariates to the analysis would also serve

less rapidly increasing function of Y; (d) incorporate in the

to restrict the range of values of c>o considered plausible.

analysis additional time-independent or dependent covari-

We were mistaken, because the meaning of the parameter

ates V(t) (as in Sec. 6.2); (e) specify a parametric model for

c>0 of the multiplicative hazard model (1) changes when

the law of (V, Y) and replace our AIPCW estimator with

we change the covariates in (1), as we now explain. We

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1111

use the subscript 1 to indicate models in which the co-

duced by F2(caO2), with V being IV drug user status. We

variate V(t) = V is the dichotomous covariate IV drug

then say that model A1 is incompatible with model A2 at

user status and the subscript 2 to denote models in which

ca02 if there exists no value of caoi for which F1 (aol) equals

V(t) is IV drug user status, age, baseline CD4, and cur-

Fmarginal,2 (a>o2) -

rent CD4 count. We also use these subscripts to distin-

We now show, somewhat informally, that the ACTG 175

guish, when necessary, the selection bias parameter ca of

data are not anomalous. Specifically, we argue that when,

model A1 from that of model A2 or B2. Thus Cao2 is the

as in the ACTG 175 data, V(t) and Y are highly correlated among the completers (A = 1) for most times t,

selection bias parameter of models A2 and B2. Let Al (ao)
we would expect Ai (cao) to be steeper than A2(ao).
and f2(ao) denote the maps from a0 to A = (b*), de-

picted in Figures 1 and 3, where in the definition of il (cao)was first suggested to us by Victor DeGruttola. Informally
and 12(aO) we have suppressed their dependence on b*.

and qualitatively, we can think of representing the time-

independent and time-dependent covariates in model A2 as

Inspection of these figures reveals that il(a'o) and A2(aO)

a single, discrete covariate V with many strata. We know

are both monotone increasing, with il (cao) increasing more
rapidly. Each value of Ca02 determines a unique value of

that as C002 -4 ? (C002 -4 -oc), each drop-out in stratum

V = v will effectively be imputed Yv ax (yrvin), as discusse
aro, through the map Al l(ft2(c0102)). This map is evaluated
earlier. If V is highly correlated with Y among the comin Table 4 for various values of Cao2. For the moment, suppose that sampling variability and model misspecification
are absent so that models A2 and B2 are correct with com-

pleters, then the difference in a given stratum v between

Ymax and Yvmin will be small, and thus we get little differ-

ence in the estimated mean for Ca02 very positive versus

mon parameter C002 and model A1 is correct with paramCa02 very negative. In contrast, when there is a single di-

eter ca0l. Then, by Theorem 1, if Ca02 is the true value of
chotomous covariate V, as in model A1, there will often be
cao in (1) that generated the underlying data (Y, V(T), Q)
a large difference between Yrvax and Yvmin, so that, as dis-

under model A2 and B2, then cao= ,= j4 (A2 (a02)) must cussed previously, the estimated mean will depend greatly
be the true value of ca under model A1, as 1{/J2(0102)} on whether the drop-outs are assigned Yrvax versus in
is the only value of cao, that implies the same mean for Thus, as suggested by Figures 1 and 3, we would expect

Y. It follows that if a subject matter expert has specified

a plausible range of, say, (-.01,.01) for Ca02 in the AZT

that for large values of co0, uft (czo) - Al (-cao) would great

exceed A2(aO) - A2(-cao) whenever Y is highly correlat

arm, then the expert's plausible range for caol, once the
dis-the covariates among the completers (A = 1).
with
tribution Fo of the data becomes known, is logically fixed
To illustrate the connection between the adjustment for
at (1(f,201=))141(ft2(01))) (-.0070,.0025). Quite
additional covariates and the breakdown of our AIPCW esgenerally if, as in the ACTG 175 data, the slope timators,
of fAl (cao)
Figureis6 plots the estimated inverse weights -r
steeper than that of b2 (aO), then, as is borne out
Table 4
as ain
function
of the observed Y's for various values of
and contrary to our initial intuition, the length of any plau-

Ca02 obtained from our fit of model B2(caO2) in Section 6.
sible range for ca01 will be narrower than that for CaO2. Putto the data for the AZT treatment arm. We note two im-

differently, in the ACTG 175 data, the magnitude of non-

portant differences from Figure 5. For the same value of

ignorable selection bias for estimation of po encoded by

a>O = a>Oc = aO02, both the skewness of the weights and
their correlation with the observed Y's are less in model
-o, = c for some nonzero constant c is generally greater

than that encoded by CaO2 = c. In practice, due to sampling

B2(caO2) than in model Al(ceol), particularly for large pos-

variability and model misspecification or incompatibility,

itive values of ca0. A full explanation of these differences

aroi will not actually be logically tied to ca02 through the

would require careful consideration of the smoothing effect

of model restriction (2) and of the effect of inclusion of
function ,Il (ft2(c2aO2)), but the foregoing discussion should
remain qualitatively correct. Incompatibility of models Al time-dependent CD4 count. Here we provide just one possible qualitative explanation for the weight distribution. Our
and A2 is defined as follows. Given Fo, let F1(arol) and

F2(caO2) be the laws for (V,Y,Q) and (V(T),Y,Q) under

purpose is solely to provide a sense of the issues involved.

models Al(caol) and A2(caO2), as described in Theorem 1.

To this end, we again informally represent V(t) as a sin-

gle, discrete covariate V with very many levels. If V were
Let Fmarginal,2(c002) be the marginal law for (V, Y, Q) inonly weakly predictive of drop-out, then there would be at
Table 4. f-I7 1(f2(a o2)) for Various Values of a02
aoi = j-1 (/i2(a02))
aO2 AZT AZT + ddl AZT + ddC ddl
-.020

-.0110

-.0125

-.0140

-.0103

most a few dropouts at any level. Then, even as cao - oc

(ceo -4 -oo), the maximal (minimal) weight 1 + ndrop/
mrnax (1 ? ndrop/nr2in) assigned to any individual in each

stratum v would not be large. But in Figure 6, at Cao2 = 0,

we see that ir ranges from about .22 to .85, indicating a

-.015 -.0090 -.0105 -.0110 -.0083

rather strong effect of V on drop-out at time t. Thus the

-.010

pattern of weights seen in Figure 6 could occur if in addi-

-.0070

-.005
.000

-.0083

-.0040
-

.005

.0020

-.0045
-

.0008

-.0075

-.0035
-

.0008

-.0060

-.0040
-

.0013

tion to V being highly predictive of drop-out, it was also

.0000

.0043

.0025

.0033

the case that Yrvax differed markedly across strata of v but
yrvi did not. Such a distribution would imply that, as seen

.010

.0025

.0070

.0048

.0053

.015

.0040

.0080

.0053

.0064

.020

.0045

.0085

.0060

.0068

in Figure 6, when c>0 is very negative, all subjects with
large estimated weight have small CD4 counts, but when

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1112 Journal of the American Statistical Association, December 1999

alphaO= -0.02 alphaO = -0.016 alphaO= -0.012 alphaO = -0.008

40.+

-++

-

4 +~~~~~~~~~4

R

.

4

++
C+
4*4*i
4
4)
4*
+~+*.*~**~*4

+

O

+~~~~~~~~~+

++

0

++

++

0

+

+

9

0 200 400 600 800 1000 0 200 400 600 800 1000 0 200 400 600 800 1000 0 200 400 600 800 1000

Observed 004 Count at Week 56 Observed 004 Count at Week 56 Observed 004 Count at Week 56 Observed 004 Count at Week 56

alphaO = -0.004 alphaO = 0.0 alphaO = 0.004 alphaO = 0.008
+ + ++I-+ + + + + ++~~~~~~~~~~~~~~~~~~~~~~~.,* +
+

CR
++

+

~~~~

+

+

~

+

~+

*+
+

C>

+

+
+

+

+

4+

*?*-

+

+~

4*

++*+4

+~~~~~~~~~~*4

;*-~~~~~~~~~~~~~4+

?

+*--

++

+44
4

4+4

++

++

+4t-fl-

_~~~~~~~~~

_

CR ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~~~+ +4 4+ + + s4?+
0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~+ *++ +0 4*- ++ +: C

9
o

+

~~ '4+ + .5 4*-I + 0 + 0 4*++ ++ + +~~~~~~~~~~~~~++ 3
+

9

+~~~~~~

~~

~~~+

Ci

t

+

?-*
=
+
+~~~~~~~~~~~~~~
++~~~~~~~~~~~~~~~~
+

o

9

0

9+C

++

+

+

++

0 200 400 600 800 1000 0 200 400 600 800 1000 0 200 400 600 800 1000 0 200 400 600 800 1000

Observed 004 Count at Week 66 Observed 004 Count at Week 66 Observed 004

alphaO= 0.012 alphaO= 0.01 6 alphaO= 0.02
4*-

+

++i$~

+

+++

+44

OR
CD4*~
i.+ ~ 4+ +
0)
+40*
59
+

+
(

9

4

++

o

*

44

+

+

e

4

+

.*+

'I-+

+

**8

+

4

0

4*

+

++

+

'0+++

4*

+

4*0

4*

+

+4*+

+.+

+

+

00
++
$i

4

0

+

++

4*4*

4~*+4

**.4
+

++

+

++

+

+

+

+

++

4*

+

++

+

++

0 200 400 600 800 1000 0 200 400 600 800 1000 0 200 400 600 800 1000
Observed 004 Count at Week 66 Observed 004 Oount at Week 56 Observed 004 Count at Week 56

Figure 6. Observed CD4 at Week 56 Versus the Inverse of the Associated Estimated Weights in Model B

variates V(t)
cao is very positive, there is little correlation between
the in model A2 are highly associated with the
observed Y's and the estimated weights.
What are the lessons of this subsection? First, it is im-

outcome Y among the completers (A = 1). Thus if one
wishes to assess the relationship between plausible ranges

parameter ca0 depends on the covariates V(t) that are condi-

for ceol and Ce02 before seeing the data and learning about
Fo, then it is important to understand when V(t) and Y will

tioned on in (1). Second, if we were previously so confused

be highly associated among the completers. Subject matter

portant to remember that the meaning of the selection bias

experts will generally have stronger prior opinions about
about how to logically map a range for Cv02 to one for ceol

(or vice-versa), then how can we expect statistically naive

qualitative aspects of the marginal distribution of Y and

subject matter experts to succeed at doing so? Obviously we

V(t) than about their conditional distribution given A = 1.

cannot without providing guidance. Third, suggestion (d) of

Thus it is important to recognize that when Ca02 o 0 and

the preceding subsection may help avoid the breakdown of

V(t) is a strong predictor of drop-out, Y and V(t) can,

AIPCW estimators in model Al(caol) in the sense that the

in principle, be highly correlated given A = 1 under the

value of cv02 at which breakdown will occur will exceed,

multiplicative hazard model (1), even if they are marginally

in absolute value, that of ca01. However, the foregoing dis-

independent. In contrast, if we had replaced the multiplica-

cussion implies that this help would best be understood as
possibly alerting our expert to the fact that her plausible

range for ca01 should not have reached the breakdown point
after all.

tive hazard model A of (1) with the additive hazard model
Aadd that specifies

AQ(tJV(T), Y) = Ao(tlV(t)) + exp(r(t, cao; Y))

7.2.4 Multiplicative Versus Additive Hazard Models.

with r(t, cao; Y) a known function, then marginal indepen-

We argued earlier that the length of any plausible range

dence of V(t) and Y imply conditional independence given

for cv02 should logically exceed that for ca01 when the co-

A = 1. Estimators of the mean bto under an additive haz-

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1113

ard model can be straightforwardly obtained by merging

ternative NPI models that we could have used to conduct a

the methods described by Lin and Ying (1994) with the in-

sensitivity analysis. The choice among NPI models should

verse probability of censoring weighting method described

ultimately depend on the ease with which subject matter ex-

in Sections 3 and 4.

perts can provide meaningful opinions about the sign and

To clarify the potential importance of the foregoing ob-

magnitude of the nonidentified selection bias parameters,

servations, consider the following hypothetical scenario,

such as the parameter cao in model A(oao). In the follow-

where, to simplify matters, we now let models A1 and

ing subsections we describe several alternative models and

Aadd,1 represent models in which no covariate data are

compare the strengths and weaknesses of the NPI model

available. Models A2 and Aadd,2 denote models in which

A(cao) with those of the alternative models.

there is a single continuous covariate V. Suppose that a subject matter expert believes that there is selection bias and
specifies a plausible range of (.003, .010) for ca01. Data now
become available on the covariate V that is known to be

highly correlated with time to drop-out Q, and the data are

reanalyzed using model A2(caO2). The expert is thus asked
to provide a plausible range for cao2- Suppose that the expert is quite uncertain as to the marginal association of V

7.3.1 A Nonparametric Identified Selection Model for

the Effect of Y Only on Selection. The most general form
of our model A(oao) is

AQ(t V(T), Y) = Ao(t V(t)) exp(r(t, cao; V(T), Y)) (13)
with r(t, ca0; V(T), Y) known to the data analyst. Our model
(1) specified that

and Y. At one extreme, he or she believes that it is possible
that the assumed correlation between Q and Y (encoded in

c>ol) is completely explained by the covariate V, and thus
caO2 = 0. At the other extreme, he or she believes it is possible that V and Y are marginally independent. He or she

thus provides a plausible interval (0, .010) for cv02, naively
assuming that if V is independent of Y, then the magni-

tude of the conditional selection bias (encoded in caO2) will
equal the magnitude of the marginal selection bias encoded
in ca01. But the expert can be quite wrong. To see why,

we consider a result of Hougaard (1986), which shows that

r(t, co; V(T), Y) = aoY. (14)
In Appendix A we prove that there can never be any data ev-

idence contradicting (14), as r(t, cao; V(T), Y) is not identified. Nonetheless, a subject matter expert would most likely

be unwilling to believe (14), because there is no good substantive reason why drop-out at time t should depend on

the unobserved future (Y, V(t) {V(zu); t < ui < T}) only
through the outcome of interest Y. Yet it seems an impos-

sible burden for a subject matter expert to specify plausible

functional forms for r(t, cao; V(T), Y) if V(T) is a highdimensional process. Thus model A(cao) may not be useful

if Ao(tlV) = AV and V has an c-stable distribution with
ca < 1, then Cv02 = Ceo/cl. For instance, if it was known
that ca was .5, then logically the expert should have pro-

vided an interval of (0, .020) for Ca02 to be consistent with
her interval for ca01. This reflects the fact that under these

conditions, V and Y will be dependent given A = 1. Thus
even conditioning on a covariate V independent of Y can
greatly increase the plausible range for the selection bias

parameter. In contrast, under the additive hazard model, the
expert would have been correct in his or her intuition that
if V is independent of Y, then the marginal and conditional

selection bias parameters ce01 and Ca02 would be equal.
Should the foregoing counterintuitive result for the multiplicative hazard model A(cao) suggest that we use the addi-

tive hazard model Aadd (co) in conducting sensitivity analyses? We think not, for several reasons. First, epidemiologists are more familiar with modelling the shape and magni-

tude of a rate ratio function than a rate difference function.

Second, marginal independence of Y and V does not imply

conditional independence given A = 1 even under an additive hazard model, when there is an interaction between Y

and V on an additive hazard scale; that is, when we replace

r(t, co; Y) by r(t, co; V(T), Y) in model Aadd. Third, ca-

for a sensitivity analysis.

The way out of this apparent dilemma is to ask the subject

matter expert to provide plausible functional forms only for
the effect of the outcome of interest Y on drop-out at t,

ignoring the future covariate process V(t). Formally, this

means that we consider a model A* (ao),
AQ (t IV(t) , Y) = Ao (t IV (t)) exp (r* (t, ao0; V (t), Y)), (15)
for the hazard of drop-out at t conditional on and

only on past covariate history V(t) and future Y with
r*(t, ca0; V(t), Y) a known function satisfying r*(t, 0; V(t),

Y) = ?,Ao(tJV(t)) an unrestricted positive function, and
the parameter cao assumed known. Robins and Rotnitzky
(1992) studied model A*(ao) in the special case in which

ao = 0. In Lemma A. 1 of Appendix A, we show that model
A* (ao) is a nonparametric model for the distribution Fo of
the observed data. Furthermore, we show that the distri-

bution of Y is identified under model A* (ao) (although the

distribution of V(T) is not identified). Under model A* (ao),
the functional form ca0Y for r*(t, co; V(t), Y) might well
be viewed as substantively plausible by a subject matter expert, because it only says that the effect of Y on the hazard

of drop-out at time t has an exponential dependence on Y
they have no moments), and it may be rare to find Y and V with no interaction on a hazard ratio scale with the past
covariates V(t). Model B* (ao), which imposes restriction
strongly conditionally correlated when they are marginally
(2)
in addition to (15), may be used in lieu of A*(cao) when
independent.
stable distributions with ca < 1 are quite pathological (e.g.,

the covariate process V(t) is high dimensional.

7.3 Alternative Nonparametric Identified Models

Our NPJ selection model A(cvo) is but one of many al-

If we agree that when our goal is to make inferences concerning a functional of the marginal distribution of Y such

as the mean bto, it is more natural to consider models A* (do0)

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1114

Journal

of

the

American

Statistical

Association,

December

1999

and B* (a>o) than models A(ao ) and B (ao), then we are left

where now S(t V(t)) exp(- fo AQ V(tu)) du) and

with the question of how to estimate bto under these new

AQ(t V(t)) is the hazard of drop-out at t given V(t). Robins

models. Fortunately, we can borrow, without modification,

et al. (1995) showed that when ao = 0, the mean bto of Y is
the same functional of the law of Fo under the mean model

the estimation methods used for model A(cao) and B(cao)
discussed in Sections 3 and 4. Specifically, suppose that we

Amean(ceo) as under model A* (ao) and model A(cao). When
0, this equivalence no longer holds. Indeed, when
replace (1) by (15) with r*(t, ao; V(t), Y) = aoY. Thenaothe
ao 0, in contrast to model A* (ao),,uo remains identified
under
model Amean (co) even when the support of Y for the
estimators of bto and 04. It may help to restate this result

estimators fi(b) and i(b) of Sections 3 and 4 remain RAL

in a slightly different manner. Suppose that model A(cao)

drop-outs (A = 0) is not contained within the support of Y

given by (1) was misspecified, because AQ(t V(T), Y) ac-

for the completers (A = 1).

tually depended on future covariate history V(t). Suppose,

When V(t) is high dimensional, we consider a model

however, that (15) was true with r*(t, ao; V(t), Y) = aoY.

Bmean(ceo) that imposes, in addition to (16), the time-

Then the estimators of bto in Sections 3 and 4 remain RAL

dependent Cox model AQ(tlV(t)) Ao(t) exp(0OW*(t)),

estimators.

where Ao (t) is an unspecified positive function, 00 is an un-

The foregoing results follow from the fact that, as

known parameter to be estimated, and W* (t) is a known

vector-valued function of V(t). We then estimate bto by reshown in Lemma A. 1, bto is the same functional of Fo
in both model A(cao) and model A* (ao) when the functionplacing the expectation in (17) by a sample average and
r(t, ao; V(T), Y) specified in model A(cao) does not depend
estimating AQ(tMV(t)) and S(t V(t)) based on the fit of t
on V(t) and is equal to the function r* (t, ao; V(t), Y) specCox model.
ified in model A*(cao).
Finally, consider the case where Y is a positive random
7.3.2 Nonparametric Identified Mean Models. Con-

sider the "mean" model Amean(cao), which specifies that

4D(E[Y|Q = t, V(t)]

variable whose distribution is otherwise unrestricted. Then

Robins et al. (1999) showed that model Amean(ao) with

b(x) = ln(x) is a nonparametric model for Fo and that the
marginal mean bto of Y is identified. These authors also provided an identifying formula for bto and proposed a method

estimation.
=4D(E[YIQ > t, V(t)]) + r(t, ao; V(t)), t E (O, T),of(16)

where r(t, ao; V(t)) is a known selection bias function satisfying r(t, 0; v(t)) = 0; a0 is a parameter assumed known

to the data analyst, (x) is a known monotone increas-

ing function, and E[Y Q = t,V(t)] is assumed smooth in
(t, V(t)). The function r(t, cao; V(t)) contrasts the mean of
Y among subjects who drop out at time t with the mean
among subjects continuing on study at t. Note that ago = 0
implies the absence of selection bias on unobservables.

Suppose that Y is a dichotomous (0,1) variable and

we choose 4(x) = ln(x/(1 - x)). Then it follows by

7.3.3 Comparison of Model A*(ao) With Amean(ao).
We spoke with a number of epidemiologists about our sen-

sitivity analysis of ACTG 175. They were split as to the ease
with which they could provide meaningful opinions about

the selection bias functions and parameters in model A* (ao)
versus model Amean(ao) with 4(x) either x or ln(x). Those
who preferred model Amean (aeo) made two points. First, the
mean model, in contrast to the selection model, asks one to
form opinions about unknowns that are directly related to

the final estimated of interest, the mean puo of Y. (However,

an advantage of the selection model A*(ao) over the mean
an application of Bayes' theorem that model Amean(010)

model is that one can treat the multiple functionals of the
with selection bias function r(t,cxO;v(t)) is equivalent to
law of Y that may be of interest in a unified fashion.) Secmodel A* (ao) with selection bias function r* (t, cao; v(t), y)
ond, because the outcome Y is observed only (if ever) at
given by r* (t, co; v (t), y) = yr (t, co; v (t)). In a modificaweek 56, it is more natural to think about the mean of Y
tion of the usual nomenclature, in this case we refer to
given the past as in model Amean(aeO) than to think about
model Amean (ceO) as a "continuous-time sequential-patternthe effect of the yet (and possibly never) to be observed Y
mixture" representation of the selection model A* (go).
on drop out at earlier times as in model A* (ao). This critConversely, model A* (go) with selection bias function
icism of model A* (ao) loses some of its sting if we allow
r*(t, cao; v(t), y) is equivalent to model Amean(aeO) with
our experts to reassess their plausible range for ago after the

r(t, (x0; v(t)) = r*(t, cao; v(t), 1) - r*(t, co; v(t), 0). Having
data have been analyzed and they are provided with both

two representations may help subject matter experts in spec-

ifying functional forms for r and r* and plausible values for

the parameter ago.
Next, suppose that Y is a random variable whose distribution may be arbitrary. Then Robins et al. (1999) showed
that model Amean(aeO) with 1?(x) = x is a nonparametric

the difference between the mean of Y in the completers

and the estimated (i.e., imputed) mean in the drop-outs and
a plot of the estimated weights as a function of Y. At first,

this might seem totally unacceptable. However, as pointed

out by I. J. Good (Good 1983), if the expert were to carry
out this reassessment for multiple simulated datasets before
model for the distribution of Fo of the observed data. Furseeing the actual data, then this would be a perfectly valid

thermore, the marginal mean -no of Y is identified via

method for eliciting the expert's actual prior beliefs about
ogo. This method is Good's "device of imaginary results."

If one's prior uncertainty concerning the distribution F0 of

ii ::: \{Y +fc7Tr(t cxo; V(t))AQ(t |V(t)) dt}j (17)

the observed data is much less than that concerning the non-

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1115

identified selection bias parameter ao, as should often be the

we have worked only with the proportional hazards nonre-

case, then most of the "imaginary" (i.e., simulated) datasets

sponse models, we also plan to develop methods to handle

would result in a similar "reassessed" plausible range for

other nonresponse models, such as the accelerated failure

time and additive hazard models.
aoo. In this case one perhaps might dispense with the simulations altogether and reassess only the actual data. The

APPENDIX A: PROOF OF THEOREM 1

problem of course is that we may, as humans, react quite
differently to the same data, depending on whether we know
it to be real versus "imaginary."

A major difference between models A* (ao) and

We actually prove a generalization of Theorem 1 in which

we replace (1) by the more general expression (13), where

r(t,ceo; V(T),Y) is any known function satisfying condition 3

given here. Throughout this proof, we assume that the observed
AmeanQ(YO) is that the latter model can lead to out-of-sample
data law Fo is absolutely continuous with respect to a dominating
extrapolation. Specifically, as discussed in Section 7.2, the
measure v and we denote expectations, densities, and probabili-

AIPCW estimators ,u(b) of puo in model A* (go) are guaranteed to lie within the range of the observed Y's. In con-

ties under Fo with the superscript *. We assume the following

conditions:

trast, for large values of oo, estimates of puo under model
A* ean(ago) can lie outside that range. In general, a method

1. Given A = 1, the process V(T) has CADLAG sample paths

that can extrapolate far outside the range of the data will be

with all discontinuities occurring at a finite number of fixed non-

extremely sensitive to the choice of selection bias function

and should be used with caution. However, whenever it is
considered plausible that selection bias is so extreme that
the support of Y in the dropouts and the completers differ,
it is essential to use methods that extrapolate.

random times O-to < ti < < tA,[ with tA< < T.
2. For t c [0, T), A* (tlV(t)) is bounded by a constant c with
probability 1 and has a bounded derivative except at tk, k C

{O,. ,MV}.

3. For t c [O,T) and v(t) in the support of V(t) on A -

1, Ir(t, ao; V(T), Y) I < k(ago) with probability 1 for some con

stant k(ceo) under FV(T),YjA=1,V(t)=V(t)' and r(t, aoo; V(T), Y

8. SUMMARY

has a bounded derivative with respect to t except at tk, k C

{?,..,MA}.
4. f*(YQI = 1,V(tA,,)) and f*(V(tk)jV(tk-1),Q > tk) are
puo of an outcome of interest Y measured at a fixed bounded
time with probability 1 for k c {, . . . , M}.
In this article we have shown how to estimate the mean

T when (a) some subjects drop out of the study, (b) drop
out is nonignorable, (c) the probability of nonresponse is
a function of Y and additional time-independent and time-

We first prove part (b) of the theorem. We establish that the

map from (Fo, ao) to FV(T),Y and Ao(tIV(t)) is given by

dependent covariates V(t) and follows a semiparametric
model, and (d) no restrictions are placed on the joint dis-

f (v(T), y) = g9(0, y, v-(T)) f* (v (O)) (A.l1a)
and

tribution of V(T) and Y. From a practical and philosophical perspective, we argued that it was more natural to fix

Ao (tlv (t)) = AQ* (tlv (t))Ipg (t, ato, v-(t)), (A. l b)

the parameter associated with Y in the nonresponse model

where

and perform a sensitivity analysis to see how inference

pg(t, aeo, v(t)) = f exp(r(t, ao; v-(T), y))

about po changes as we vary this parameter over a plausible range of values. We illustrated our technique with data

x g(t, y, v(T)) dv(y) I| dl,(v(tk))

from an AIDS clinical trial, ACTG 175. We described settings in which our method breaks down and offered alternative methods appropriate for these settings. We discussed,
but left unresolved, the question of whether subject matter
experts will be able to provide a plausible range of values

for the selection bias parameter. If not, then these methods
may ultimately be of limited scientific value. On a similar note, it is unknown whether our formal methods will
prove of more use to practicing scientists than the informal

sensitivity analyses they already conduct, based on "back

k:tk >t

and g(t, y, v(T)) is the unique solution on t C [0, T] to the nonlinear Volterra integral equation

g(t, y, V(T))

f*(ylA 1,V(tm)) J7 f*(V(tk)!V(tk-1),Q > tk)
k:tk >t

x exp(fT AQ (xlv(x)) {1 - exp(r(x, a o; V(T), y)) } dx

of the envelope" calculations. Our guess is that many sci-

(A.ic)

entists underestimate uncertainty, and our formal methods

combined with informative graphical displays can usefully
serve as a brusque reminder of just how much is uncertain.
In Appendix B we present a general theory for construct-

ing estimators of a parameter of interest when drop-out is
nonignorable and both the full-data and nonresponse mech-

anism follow semiparametric models. In later reports we
plan to use this general theory to extend our results to failure time outcomes, repeated-measures outcomes, and re-

We now prove (A.la)-(A.lc). First, it can be shown that, under Assumption 2, the conditional densities on the right side of

(A.1c) have well-defined versions that are continuous (with respect to the weak topology) in all of their arguments, by arguing as in Gill and Robins (1999). Assumptions 3 and 4 guarantee

that exp(r(x, aeo; v(T), y))/pg(x, aeo, v (x)) in (A. c) is bounded.

Arguing as in the work of Tricomi (1957, sec. 1.13), it follows

that by the smoothness assumptions 2-4, (A.lic) has a solution,
and it is unique. We next show that the right side of (A. la) in-

gression and counterfactual causal models for the effect of

tegrates to 1, 50 f(v(T), y) is a density. It is sufficient to show

baseline and time-dependent covariates on the outcome. As

that Z(t) f f g(t, y, v(T)) dv~(y) Fktk >t di'(v(tk)) =1 for

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1116

Journal

of

the

American

Statistical

Association,

December

1999

all t. Under our smoothness assumptions, Z(t) is continuous on

ential equations, fcand (y, V(T) IV(t), Q > t) = g(t, y, V(T)) for

[0, T] and differentiable except at the tk's. Now it follows from

t E [O, ti). But then they are equal at t, and thus on [tl, t2). Con-

tinuing,
(A.1c) and the definition of pg that Z(t) A S(tIV(t))(Z(t)
- 1)we

conclude equality for all t, proving part (b) of the

theorem.
for t ? tk, where for any function h(t, ),h(t,.) Oh(t, .)/0t.

The proof of part (a) follows from the fact that the foregoing

Because Z(t) is equal to 1 at t = T, it follows by the uniqueness

construction depends on the values of aoO. As aoO varies, the map-

of solutions to differential equations that Z(t) = 1 for all t.

ping from the law of the observed data to the law of the full data

We now prove that any candidate law FV(T),YQ marginalizing
changes. This shows the lack of identifiability.
to FO satisfying (13) will have density f(y, v(T)Iv(t), Q > t) that
satisfies (A. lc) and Ao(tlv(t)) given by (A.lb). If FO _ F* is the

Corollary A.]. In_model A(cao) defined by (13), if r(t,ao;

marginal of our candidate law, then

V(T), Y) = r*(t, ao; V(t), Y), then the density f(yIv(t), Q > t
is the unique solution g(t, y, v(t)) to the nonlinear Volterra integral

f(y, v(T)Iv(t), Q > t) Pr[A = IKV(T), y, Q > t]

equation

= f * (A\ = 1, v-(T), y|Iv-(t), Q > t) . (A. 2)

g(t, y, v(t))

Dividing both sides of (A.2) by Pr[A = llv(T),y,Q > t]

exp(- fT AQ (xIv(T), y) dx) and noting that

f / /y fYI A = 1, v-(tm))

f*((A = 1, v(T),yIV(t),Q > t)

x fJ dF*(v(tk)lv(tk-1), Q > tk)

f * (ylA 1, V(tM)) 17 f*(V(tk)lV(tk-1), Q > tk)

k:tk >t

k:tk >t

x exp (- fT A*( ))

x

exp

(T

(xl

(A.3)

x exp (r* (X,a O; v(x),Y)) dx>

X fexp(r*(x, ao; v(x), y))g(x, ,v(x)) dv (y) X)'

and, by (13),

AQ (tIV(T), y) _ exp(r(t, a o; v(T), y))
AQ A*
(tVt)
Pf (t, oeo,
v(t))
(tIVpft,
eo,t(t)
'

(A.5a)

(A.4)

and Ao(tIV(t)) is given by

where f in pf is equal to f (y, v(T)I v(t), Q > t), we
obtain
that
Ao(tIv-(t))
= A*Q(tlv-(t))

f(y,v(T)Iv(t),Q > t) must solve (A.1c). It thus follows that
(A.la) is the unique candidate density f(y, v(T)) for the marginal
law of (Y, V(T)). Further, (A.4) and (13) imply the unique candi-

* J exp(r* (t, ceo; v(t), y)) f (yI-(t), Q > t) dvz(y). (A.5b)

date (A.1b) for Ao(tIv(t)). Thus it only remains to show that our
unique candidate law Fcand =FV(T) yQ determined by (A.la)-

Proof. Under our regularity conditions, (A.5a) has a

(A. 1c) has marginal law Fmarg for 0 equal to the given F*.

unique solution. In the proof of Theorem 1 we showed that

Now it is easy to see by inspection that the map from F*

f(y, v(T)Iv(t), Q > t) solves (A. c). The corollary now follows

to the solution g of (A.1c) is 1 to 1. Hence we can con-

from (A.1b) and (A.1c) on integrating out the necessary v(tk).

clude that Fnarg = F* if we can show that the density

When co = 0, so r*(x,Iao;v(x),y) = 0, the solution to (A.5a)

is given by the g-computation algorithm formula of Robins (1986
1987),

fcand(y, v(T)|v(t), Q > t, ) derived from Fcand solves (A. c), because, by the arguments in (A.2)-(A.4), this density solves (A.1c)

when F* is replaced by Fnarg in (A.1c). Now, taking deriva-

tives with respect to t for t y tk, by (A.1c), g(t,y,v(T)) =

f (YIV(t) IQ > t) f * tf(Yl IA 1v(t.A,))

g(t, y, v(T))Ao(tlv(t)){pg(t, eo, v(t)) - exp(r(t, o; V(T), y))}.
Also,

x fl dF*(V(tk)lv-(tk-1), Q > tk)k:tk >t

fcand (y, v(T) Iv(t), Q > t) = fcand (Y,v (T) |v(t), Q > t)
x Ao (t I V (t)) {Pfcand (t, aeo, V (t)) - exp (r (t, ao; v- (T), y))},
because

Lemma A.1. Suppose that assumptions 1-4 of Theorem 1

hold, except that in 3 we replace r by r* and T by t. Then model

A*(ao) defined by (15) is a nonparametric model for Fo with

fcand (Y, v (T) I v (t), Q > t)

= Y(0yv(T)) exp {-j o(x (x)) exp(r(x, ao;

f(yIV(t),Q > t) identified and given by (A.5a) and Ao(tIV(t))
given
v(T), y))}by (A.5b).

. {Y(0 oxylv(T))
x exp {-j Ao(xLv(x)) exp(r (x, ao; v(T), y))}

x dvi(y) ]7 dz(v(tk)4.
k:tk

>t

Proof. As in the proof of Theorem 1, let f * denote densities under Fo. By the proof of Theorem 1, (A.6) has unique
nonnegative solutions g1(t,y,V(t)),g2( (tk),y),k C {k: tk >
t}, and p(t, v(t)) satisfying the unit integral restrictions 1

jr g (t, y, v(t)) dv(y) =fjr 92(v(tk), y) dv(Vt(tk)):

jf*(q,v_(q),yIv_(t),Q > t)j'ff*(q,v_(q)Iv_(t),Q > t)11-6

)

Further, from its definition, fcand(y, v(T)jv(0), Q > 0)=
g(O, y, v(T)). Hence, by the uniqueness of solutions to differ-

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1117

x exp (-j p(x,v(x))exp(r*(x,ayo;v(x),y)) dx) (A.6)

an individual and the true values of the parameters 4'o, 00, and

Tro. Denote this function by H _ h(O; 4'o, 0o, rio). Suppose that
we estimate 4'o by 4' solving >_1h(Oi; 4', 0(4'), i)(4)) = 0,

where if d = 1, then the first integration is not performed. As

model A(cao) is nonparametric, we can regard (A.6) as the density

where 0(4'o) and f1(4'o) converge to 00 and 'ro. Then Bickel et
al. (1993) and Newey (1990) showed that under suitable regularity

of the observed data given the event (V(t) = v(t), Q > t) un-

conditions 4' is a RAL estimator with influence function r-1H,

der model A(ago) with r(t, aeo; v(T), y) = r* (t, ao; v(t), y). where
Hence T = E[HS'] -OE[h(O; 4', Oo,' r)]/O4l+=fo But this
we conclude that gi(t, y, v(t)) = f(yIv(t), Q > t) solves (A.5a),
is the same influence function as would have been obtained by

p(t,v(t)) = Ao(tIv(t)) is given by (A.5b), and g2(v(tk),y)=
solving the estimating equation E_1 h(Oi;4'0o,rio) 0 in
f(v(tk)IV(tk-1), Y) = f(v(tk)lv(tk-1), Y, Q > tk) is determined
which the infinite-dimensional components (o, 'r/o) are known
by the law fV(T),y defined by (A.la)-(A.lc), as (A.6) uniquely rather than estimated. It is precisely the orthogonality of H to
determines the conditional density of (V(T), Y, Q) through the
AO that obviated the need to adjust the asymptotic variance
foregoing formulas, according to our proof of Theorem 1 and

Corollary A.1. However, (A.6) is also the density of the observed

data under model A*(cao) [i.e., (15)], with 92(v(tk),y) now only

f(v(tk)IV(tk-1), y, Q > tk). Because we have just shown that

(A.6) has a unique solution satisfying the foregoing positivity

and unit integral restriction, we conclude that there exists only

estimation of the nuisance parameters.

Taking orthogonal complements, AO," AO" n n 0Ag". Let
a(L) and b(R, L(R)) be p + q-dimensional functions of L and
(R, L(R)). Rotnitzky and Robins (1997) showed how to compute
AO,7". Specifically,

one law FY Q V(Q)IV(t) Q>t that satisfies (15) and marginalizesAO,
to
F V(Q) Y|Q>tV(t) and that this law has Ao(tlv(t)) satisfying

(A.5b) and f(ylv(t), Q > t) solving (A.5a). This concludes the
proof of the lemma.

= A/ Pr[/\ = I I L]- a(L) + b(R, L(R)):
a(L) C A(FL)' and E[b(R, L(R)) IL] = 0}.

By the relationship between ranges and null spaces, we know

APPENDIX B: GENERAL THEORY
Let L denote the complete (full) data. Suppose that we observe

only (R, L(R)), where L(R) = pR (L) and r (L) is a known func-

that AO," = N(IIT o gT), where N(.) is the null space of an
operator and superscript T denotes the adjoint of an operator. As

a projection operator, IJt H2 and gT is the identity operator.
So,

tion of L that depends on r. Specifically, R indexes the part of

AO,' = {b(R, L(R) ): rl[b(R, L(R) ) I A(FRIL)] = ?

L that is actually observed. We assume that there exists a unique

value of R,r*, such that (pr*(L) = L. Let A = I(R = r*).

= { b(R, L(R) ) b (R, L(R) ) EE A(FRIL)'

Furthermore, we assume that (a) L follows an arbitrary semiparametric model, FL, indexed by a p x 1 parameter ,i and an infinite-

dimensional parameter 0; (b) R given L follows an arbitrary semi-

B.1. Application of the General Theory to Models A(cao)
parametric model, FRIL, indexed by a q x 1 parameter -y and anand B(cao)
infinite-dimensional parameter j; and (c) Pr[A\ = IIL] > cr > 0.
We now apply this general theory to obtain AO," in mo
We assume that the parameters in model FL are variation inde-

pendent of those in the model FRIL. We let ,uo, o Oo, andA(cxo)
Tqo and B(cxo). In these models we have L = (V(T), Y), R =
Q, L(R) = ( Q(L) = (V(Q), I(Q = T)Y), r* = T, and
denote the true values of i, -y, 0, and r,. We are interested in esti-

A = I(R = T). We actually consider a generalization of model

mating 4'o = (i4p )'. We observe n independent and identically
distributed copies of 0 = (R, L(R))

A(cao) in which (1) is replaced with the more general expression

(13), where r(t, ceo; V(T), Y) is any known function satisfying
Let A1 = A(FL) and A2 = A(FRIL) denote the (nuisance) tanthe condition 3 of Theorem 1 in Appendix A. Define S(t)
gent spaces for 0 and q had we observed (R, L). (For a defini-

tion of nuisance tangent space see, e.g., Newey 1990). Through-

exp(- fo Ao(uIV(u)) exp(r(u, aeo; V(T), Y)) du), S _ S(T), and

out, our spaces are subspaces of the Hilbert space of q + p-

E = Y - uo. Note that under (13), S-P[A = 1I V(T), Y]. Note
also that under model B(ceo), Ao (tIV(t)) = Ao (t) exp{-yOW(t) },

dimensional mean 0 random vectors with the covariance inner

product, and H(. .) denotes the projection operator. Note that

and hence S(t) depends on the value of -yo. To emphasize this

when developing the results for model B(cao), we
A(FL) and A(FRIL) are orthogonal. For the "observed data," dependence,
there
is an induced semiparametric model that we denote by 0. In model

write S(t;-yo) for S(t). Throughout, we use N(t) to denote the

counting process for censoring I(Q < t, A 0) and M(t)
O the observed data nuisance tangent space is AO = - A + AO,
where AO7 is the observed data nuisance tangent space for 0 N(t)--ftI(Q
and
> u)Ao(ulV(u))exp{r(u,cao;V(T),Y)}du to deAO is the observed data nuisance tangent space for r,. Specifinote its associated martingale.
In model A(ceo),
cally, A9 = R(g o rj), where R(.) is the range of an operator, g:

Q(R,L) _ Q(R,L(R)) 9( ) = E[.IR,L(R)])Q (R,L) and Q(R,L(R))
are spaces of p + q-dimensional mean 0 random functions of

A(FL) = {a(E) + a(V(T), E): a(6) and a(V(T), E)

(R, L) and (R, L(R)), Hj is the projection operator from Q(R,L)
onto Aj, and S denotes the closed linear span of the set S (Bickel
et al. 1993). A space superscripted by I denotes the orthogonal

are scalar functions with E[a(E)] = E[Ea(E)]
- E[a(V(T), E) |Y] = 0}

complement of that space. We are interested in finding AO," because in sufficiently smooth models including all those studied in
this article, the set of influence functions of all RAL estimators

and

A(FL)'1 ={kf: k E R1}

of +b0 is the set {E[ASpV,]1A;A E A?,"}, where SVp is the obby theorem 8.3 of Robins et al. (1994). To compute As"l, note
served data score for '+/ evaluated at the truth. Another motivation
for our interest in this space is as follows. An element in the A0"l that any function c(R, L(R) ) admits the unique representation
space is a (p + q)-dimensional function of the observed data for

A\a(V(T), Y) + (1 - A)b(V(Q), Q). Thus E[c(R, L(R))IL] 0 if

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1118

Journal

of

the

American

Statistical

and only if

Association,

December

1999

f, b(V(u), u)fQ(uIV(T), Y) du

B v [V(t), t S(t)

C(R, L(R)) = _ E[(1 - A)b(V(Q), Q)JV(T), Y]
+ (1 - A)b(V(Q), Q)

- S(t) Q=tV(t) =0. (B

Thus we have

Equation (B.2) can be rewritten as the Volterra integral equation

AO, 1={A (kE E[(1 - A)b(V(Q), Q) V(T),Y])

t

b(V(t) t)= Jm(t) - b(V( u), u)f (u, t, V(t)) du, (B.3
+ (1- A)b(V(Q), Q): k R}.

where

Jm (t) E[m(V(T), Y) exp{r(t, xo; V(T), Y)}IV(t)] (B.3

In model B(ago) the preceding representations of A(FL), A(FL)',

and AO, I still hold, except that k is replaced by k C Rq+l, and
the functions a and b are (q + 1) dimensional and denoted by a

E - [S (t) exp{fr (t, cxo; V (T), Y) V (t)]

and

and b.

E[Ao(ujV(u))S(u) exp{r(t, cxo; V(T), Y)

B.1.1 Computation of A0" in Model A(ao0). To compute AO",
we first compute AO, " , then intersect it with AO, 1 given earlier.

f(U, t V(t)) + r(u, ao; V(T), Y)}IV(t)]
' ~~E[S(t) exp{r(t,acx;V V(T), Y)} V (t)]

It follows from Ritov and Wellner (1988) that in model A(ato),

(B.3c)

For each m(V(T), Y), (B.3a) has a unique solution. Because AO)"

A(FRIL) g {J g(t, V(t)) dM l(t): g (t, V(t))

is comprised precisely by all the functions of the observed data

that belong to A(FRIL)', we conclude that
is an arbitrary function of t and V(t) }

AO, ' ={i Sm(V(T), Y) + (1- A)b(V(Q), Q)
and

S - A)b(V(Q), Q) IV(T), Y]:

A(FRIL)

E [m (V(T), Y) 0 , b (V (t), t)

{a(V(T), Y) + j g(t, V(T), Y) dM(t):

solves (B.3a) for Vt E [0, T)

E[g(t, V(T), Y)IQ t, V(t)] = 0,

Finally, intersecting AO, and AO, ", we obtain

and E[a(V(T),Y)] 0}

AO, 1
A

= kH: k c R1 and H E + (1 - A)b(V(Q), Q)

To compute AO," , we write an arbitrary function c(R, L(R))
Aa(V(T), Y) + (1 - A)b(V(Q), Q) as

- SE[(1 - A)b(V(Q), Q)YV(T), Y],

C(R, L(R)) A{A + (1- A)B + S E[(l A)BIV(T), Y]}

where b(V(t), t) solves (B.3a) with m(V(T), Y) =cE}.
(B.4)

- m(V(T), Y) + (1- A)B

Because this set comprises multiples of the unique random vari-

able H, we conclude that there is a single influence function for

the parameter ,uo. This must be the case, because by Theorem 1,

-S E[(1- A)BIV(T), Y]

model A(cgo) is a nonparametric model for the observed data.

=m(V(T), Y) + j g(t, V(T), Y) dM(t), (Bi)
where A =a(V(T), Y), B =b(V(Q), Q), m(V(T), Y)=

E[A\A + (1 -A)B EV(T), Y], and

In the special case in which V(t) =V and r(t, cxo;V, Y)=
r(cxo; V, Y) for all t, (B.3a) has an explicit solution b(V, t)=

b* (V) independent of t given by

g(t, V(T), Y) = b(V(t), t)

b* (V) - E[m(V, Y) exp{r(coO; V, Y)} IV]

b(V(u), u) fQ(uIV(T), Y) du m(V(T), Y)
S(t)
with

We now prove that h(O; io, Ao; b*) with b* as in (7) is the

unique h(O, po, Ao; b) uncorrelated with all nuisance scores S.

S(t)

fQ(.IV(T),

Y)

The third identity in (B. 1) follows from lemma 4.1 of Robins et
al. (1999). Note that because A is arbitrary, so is m(V(T), Y).

E[exp{r(cxo; V, Y)}lV]

In particular, when m(V, Y) = Y - to, b*(V) coincides
with b* (V; Ito) in (7) and H in the set (B.4) coincides with

the b*).
conditional
dens
h(O,uyo,Alo;
Thus h(O,uyo,Alo; b*) is uncorrelated
with th
nuisance scores Sb , because it is an element of Ar". The uniqueness of H follows from the uniqueness of b*.

From the representation of A(FRIL)' just given, we conclude

that C(R, L(R)) E A(FRIL)' if and only if E[m(V(T), Y)] 0 B.1.2 Computation of A0" in Model B(060). It follows from
and for all t E [O, T),

the results of Ritov and Wellner (1988) that in model B(ctO),

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

Scharfstein, Rotnitzky, and Robins: Adjusting for Nonignorable Drop-Out 1119

A

AO' {H: H -= kE + (1-A)b(V(Q), Q)

A(FRIL) { g(t) dM(t): g(t) is an arbitrary

A

- E[(1 - A)b(V(Q), Q)IV(T), Y]:

(q + 1) dimensional function of t}

k E Rq+l and b(V(t),t) E bm
and

with m(V(T), Y) = kE}.

A(FRIL)= {a(V(T) Y) + j g(t, V(T), Y) dM(t):
E[g(t, V(T), Y) IQ = t] = O,

E[a(V(T), Y)] = 0,
and a and g are (q + 1) dimensional }

This indeed shows that (10) characterizes the members of the

set b* of Section 4.2, because b*(V(t), t; ?b0) satisfies (10) if and

only if b*(V(t), t; ?b0) E bm with m(V(T), Y) = kelE and el is
the (q+1) dimensional vector (1, 0, . . ., 0)'. Further, it is simple to
show that the set of influence functions corresponding to the class

of estimators { b(b*)} contains all influence functions for 0o.

We now use the representation (B. 1) for any c(R, L(R))

APPENDIX C: AN ADAPTIVE ESTIMATOR

and conclude that c(R, L(R)) c A(FRIL)1 if and only if
E[m(V(T), Y)] 0 and for all t c [O, T),

E [b(V(t)t) fo b(V(u), u)fQ(uIV(T), Y) du

We propose an adaptive choice by ?5adap for the function 4).
?adap will depend on both the data and the selection bias parame-

ter ao. The estimator Aa(bdap) determined by q5adap via (11) will
have asymptotic variance that should be close to the semiparamet-

ric variance bound for model A(ago). To allow us to reuse the no-

m(V(T), Y) Q = t 0, (B.5)
tation from Section 4.1, we assume that r(t, ceo; V(T), Y) = ce0Y.

We calculate 4adap (V(t), t) using the following five-step procewhere m is now a (q + 1) dimensional function.
Equation (B.5) can be rewritten as

E[b(V(t), t)D(t) + Cb,m(t)] = 0, (B.6)

dure:

1. Obtain a preliminary inefficient RAL estimator +(b)
(,u(b), '(b)')' based on a convenient choice of b as in Section
4.1.

where

D(t) = S(t; 'yo) exp{ O'W(t) + r(t, ato; V(T), Y)}

2. Specify a parametric model f(E, V(T); r) with r an unknown finite-dimensional parameter for the unknown law of

(e, V(T)) with E _ Y - o.

and

3. Estimate rj by the solution ij to the IPCW score equation

Cb,m (t)

0- E(b) [ n f (Y -(b)) V(T);

E [exp{'Y6W(t) + r(t, ato; V(T), Y)}

4. Replace the Volterra integral equation (B.3a)-(B.3c) by an
estimated version where, in the estimated version, we replace

x j b(V(u), u)fQ (uIV(T)) Y; yo) du]
-E[m(V(T), Y) exp{'y6W(t) + r(t, ato; V(T), Y)}]

a. in (B.3b) and (B.3c), E[.IV(t)] with expectations Et, (b)
[ IV(t)] computed under f (E(b), V(T); ij) with ?(b)-=Yf(b)

b. in (B.3b) and (B.3c), S(.) by S(. V(T),Y; -(b)) of SecFor any fixed function m(V(T), Y), (B.6) has an infinite num- tion 4.1
ber of solutions. But we now show that the set bm of solutions c. in (B.3c), Ao (uIV(u)) by exp('a (b)'W(u))dA(u; 7(b))
to (B.6) is equal to the set
d. in (B.3c), f (u, t, V(t)) by dF(u, t, V(t))

b - {b(V(t), t) = q5(V(t), t) -E[D(t)]
x {E[q(V(t), t)D(t)] + Cb,m(t)}

e. in (B.3a), f (u, t, V(t)) du by dF(u, t, V(t)).
5. Solve the estimated version of (B.3a)-(B.3c) and call

the solution )1,adap(V(t), t), and define q5adap(V(t), t

O(V(t), t) is an arbitrary q + 1 dimensional function}.
(41,adap (V(t), t), W(t)').
That bm C bm follows by direct verification that the elements of

Then, under mild regularity conditions, (badap) will be a R
bm solve (B.6). That bm C bm follows because for any arbitraryestimator under model B(ao) with asymptotic variance equal to
solution b(V(t), t) to (B.6),
the semiparametric variance bound for model A(ago) if the parametric model f (E, V(T); r) is correctly specified. Even under misb(V(t), t)

= b(V(t), t)-E[D(t)] 1{E[b(V(t), t)D(t)] + Cb,m(t)}.

specification of the parametric model, fu(badap) will remain a RAL
estimator under model B (ao) with asymptotic variance that should

Because AO"1 is comprised precisely by all (q + 1)-dimensional
remain close to the bound for model A(ago) if rq is a rather highfunctions c(R, L(R)) of the observed data that belong to
dimensional parameter.

A(FRIL)', we conclude that

AO'' m {m(V_(T), Y) + (I1- A) b(V (Q), Q)

[Received February 1998. Revised June 1999.]

REFERENCES

- SE[(1 - A)b(V(Q), Q)IV(T), Y]:

Andersen, P. K., Borgan, O., Gill, R. D., and Keiding, N. (1993), Statistical
Models Based on Counting Processes, New York: Springer-Verlag.

Baker, S. G., Rosenberger, W. F., and DerSimonian, R. (1992), "ClosedE[m(V(T),Y)] 0 and b(V(t),t) E bm}.

Form Estimates for Missing Counts in Two-Way Contingency Tables,"

Finally, intersecting AV?7" and A0r", we obtain

Statistics in Medicine, 11, 643-657.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

1120 Journal of the American Statistical Association, December 1999

Bickel, P. J., Klaasen, C. A. J., Ritov, Y., and Wellner, J. A. (1993), Efficient
and Adaptive Estimation for Semiparametric Models, Baltimore: Johns

Hopkins University Press.

ical Data: An Example From a Genetic Study on Turner's Syndrome,"
Journal of the American Statistical Association, 7, 772-780.

Ritov, Y., and Wellner, J. A. (1988), "Censoring, Martingales, and the Cox

DeGruttola, V., and Tu, X. M. (1994), "Modeling the Progression of CD4Lymphocyte Count and Its Relationship to Survival Time," Biometrics,

Model," Contemporary Mathematics, 80, 191-219.

Robins, J. M. (1986), "A New Approach to Causal Inference in Mortality
Studies With Sustained Exposure Periods-Application to Control of

50, 1003-1014.

Diggle, P., and Kenward, M. G. (1994), "Informative Drop-Out in Longitudinal Data Analysis," Applied Statistics, 43, 49-93.

the Healthy Worker Survivor Effect," Mathematical Modelling, 7, 13931512.

Fitzmaurice, G. M., Clifford, P., and Heath, A. F. (1996), "Logistic Re-

(1987), "A New Approach to Causal Inference in Mortality Stud-

gression Models for Binary Panel Data With Attrition," Journal of the

ies With Sustained Exposure Periods-Application to Control of the

Royal Statistical Society, Ser. A, 159, 249-263.

Fitzmaurice, G. M., Laird, N. M., and Zahner, G. E. P. (1996), "Multivari-

Healthy Worker Survivor Effect (Addendum)," Computers and Mathematics With Applications, 14, 923-945.

(1997), "Non-Response Models for the Analysis of Non-Monotone

ate Logistic Models for Incomplete Binary Responses," Journal of the

American Statistical Association, 91, 99-108.

Fitzmaurice, G. M., Molenberghs, G., and Lipsitz, S. (1995), "Regres-

Non-Ignorable Missing Data," Statistics in Medicine, 16, 21-38.
Robins, J. M., Mark, S. D., and Newey, W. K. (1992), "Estimating Expo-

sion Models for Longitudinal Binary Responses With Informative Drop-

sure Effects by Modeling the Expectation of Exposure Conditional on

Outs," Journal of the Royal Statistical Society, Ser. B, 57, 691-704.

Confounders," Biometrics, 48, 479-495.

Freedman, D., Rothenberg, T., and Sutch, R. (1984), "On Energy Policy
Models," Journal of Business and Economic Statistics, 1, 24-36.

Good, I. J. (1983), Good Thinking: The Foundations of Probability and Its
Applications, Minneapolis: University of Minnesota Press.

Gill, R. D. (1989), "Non- and Semi-Parametric Maximum Likelihood Estimators and the von Mises Method," Scandinavian Journal of Statistics,

16, 97-128.

Gill, R. D., and Robins, J. M. (1999), "Causal Inference from Complex
Longitudinal Data: The Continuous Case," The Annals of Statistics, under review.

Hammer, S. M., Katzenstein, D. A., Hughes, M. D., Gundacker, H., Schooley, R. T., Haubrich, R. H., Henry, W. K., Lederman, M. M., Phair, J. P.,

Niu, M., Hirsch, M. S., and Merigan, T. C. (1996), "A Trial Comparing
Nucleoside Monotherapy With Combination Therapy in HIV-Infected
Adults With CD4 Cell Counts from 200 to 500 per Cubic Millimeter,"
The New England Journal of Medicine, 15, 1081-1090.

Heitjan, D. F., and Rubin, D. B. (1991), "Ignorability and Coarse Data,"
The Annals of Statistics, 19, 2244-2253.

Hogan, J. W., and Laird, N. M. (1997a), "Model-Based Approaches to
Analyzing Incomplete Longitudinal and Failure Time Data," Statistics
in Medicine, 16, 259-272.

(1997b), "Mixture Models for the Joint Distribution of Repeated
Measures and Event Times," Statistics in Medicine, 16, 239-257.

Horvitz, D. G., and Thompson, D. J. (1952), "A Generalization of Sampling
Without Replacement From a Finite Universe," Journal of the American
Statistical Association, 47, 663-685.

Hougaard, P. (1986), "Survival Models for Heterogeneous Populations Derived From Stable Distributions," Biometrika, 73, 387-396.

Klein, J. P., and Moeschberger, M. L. (1988), "Bounds on Net Survival
Probabilities for Dependent Competing Risks," Biometrics, 44, 529-538.

Laird, N. M. (1988), "Missing Data in Longitudinal Studies," Statistics in
Medicine, 7, 305-315.

Robins, J. M., and Ritov, Y. (1997), "Toward a Curse of Dimensionality
Appropriate (CODA) Asymptotic Theory for Semi-Parametric Models,"

Statistics in Medicine, 16, 285-319.
Robins, J. M., and Rotnitzky, A. (1992), "Recovery of Information and Adjustment for Dependent Censoring Using Surrogate Markers," in AIDS
Epidemiology: Methodological Issues, eds. N. Jewel, K. Dietz, and V.

Farewell, Boston: Birkhauser.

(1995), "Semiparametric Efficiency in Multivariate Regression
Models With Missing Data," Journal of the American Statistical Association, 90, 122-129.
Robins, J. M., Rotnitzky, A., and Scharfstein, D. 0. (1999), "Sensitivity
Analysis for Selection Bias and Unmeasured Confounding in Missing
Data and Causal Inference Models," in Statistical Methods in Epidemiology, ed. E. Halloran, New York: Springer-Verlag, 1-92.

Robins, J. M., Rotnitzky, A., and Zhao, L. P. (1994), "Estimation of Regression Coefficients When Some Regressors are not Always Observed,"
Journal of the American Statistical Association, 89, 846-866.

(1995), "Analysis of Semiparametric Regression Models for Repeated Outcomes in the Presence of Missing Data," Journal of the American Statistical Association, 90, 106-121.

Rotnitzky, A., and Robins, J. M. (1997), "Analysis of Semiparametric
Regression Models With Non-Ignorable Non-Response," Statistics in
Medicine, 16, 81-102.

Rotnitzky, A., Robins, J. M., and Scharfstein, D. 0. (1998), "Semiparametric Regression for Repeated Outcomes with Non-Ignorable NonResponse," Journal of the American Statistical Association, 93, 13211339.

Schluchter, M. D. (1992), "Methods for the Analysis of Informatively Censored Longitudinal Data," Statistics in Medicine, 11, 1861-1870.
Self, S., and Pawitan, Y. (1992), "Modeling a Marker of Disease Progression and Onset of Disease," in AIDS Epidemiology: Methodological
Issues, eds. N. Jewel, K. Dietz, and V. Farewell, Boston: Birkhauser.

Slud, E., and Rubinstein, L. V. (1983), "Dependent Competing Risks and
Lin, D. Y., and Ying, Z. (1994), "Semiparametric Analysis of the Additive
Summary Survival Curves," Biometrika, 70, 643-649.
Risk Model," Biometrika, 81, 61-71.

Little, R. J. (1985), "A Note About Models for Selectivity Bias," Econometrica, 53, 1469-1474.

(1993a), "Pattern-Mixture Models for Multivariate Incomplete
Data," Journal of the American Statistical Association, 88, 125-134.
(1993b), "Pattern-Mixture Models for Normal Missing Data,"
Biometrika, 81, 471-483.

(1995), "Modeling the Drop-Out Mechanism in RepeatedMeasures Studies," Journal of the American Statistical Association, 90,
1112-1121.

Little, R. J., and Rubin, D. B. (1987), Statistical Analysis with Missing
Data, New York: Wiley.

Mori, M., Woodworth, G. G., and Woolson, R. F. (1992), "Application
of Empirical Bayes Inference to Estimation of Rate of Change in the

Tricomi, F. G. (1957), Integral Equations, London: Interscience.
Tsiatis, A. A., DeGruttola, V., and Wulfsohn, M. S. (1994), "Modeling the
Relationship of Survival and Longitudinal Data Measured With Error,"
Journal of the American Statistical Association, 90, 27-37.

van der Laan, M. (1993), "Efficient and Inefficient Estimation in Semiparametric Models," CWI Tract 114, Centre for Mathematics and Computer

Science, Amsterdam.

Wu, M. C., and Bailey, K. R. (1988), "Analyzing Changes in the Presence of Informative Right Censoring Caused by Death and Withdrawal,"
Statistics in Medicine, 7, 337-346.

(1989), "Estimation and Comparison of Changes in the Presence
of Informative Right Censoring: Conditional Linear Model," Biometrics,
45, 939-955. Corr.: 1990, 46, 88.

Wu, M. C., and Carroll, R. J. (1988), "Estimation and Comparison of

Presence of Informative Right Censoring," Statistics in Medicine, 11,

Changes in the Presence of Informative Right Censoring by Modeling

621-631.

the Censoring Process," Biometrics, 44, 175-188.

Murphy, S. (1995), "Likelihood Ratio-Based Confidence Intervals in Survival Analysis," Journal of the American Statistical Association, 90,
1399-1405.
Newey, W. K. (1990), "Semiparametric Efficiency Bounds," Journal of
Applied Econometrics, 5, 99-135.
Nordheim, E. V. (1984), "Inference From Nonrandomly Missing Categor-

Zheng, M., and Klein, J. P. (1994), "A Self-Consistent Estimator of
Marginal Survival Functions Based on Dependent Competing Risk Data
and an Assumed Copula," Communications in Statistics, Part A-Theory
and Methods, 23, 2299-2311.
(1995), "Estimates of Marginal Survival for Dependent Competing
Risks Based on an Assumed Copula," Biometrika, 82, 127-138.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:21 UTC
All use subject to https://about.jstor.org/terms

