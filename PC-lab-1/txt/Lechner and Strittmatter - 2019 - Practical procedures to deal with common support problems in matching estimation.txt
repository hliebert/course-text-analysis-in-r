Econometric Reviews

ISSN: 0747-4938 (Print) 1532-4168 (Online) Journal homepage: https://www.tandfonline.com/loi/lecr20

Practical procedures to deal with common support
problems in matching estimation
Michael Lechner & Anthony Strittmatter
To cite this article: Michael Lechner & Anthony Strittmatter (2019) Practical procedures to deal
with common support problems in matching estimation, Econometric Reviews, 38:2, 193-207, DOI:
10.1080/07474938.2017.1318509
To link to this article: https://doi.org/10.1080/07474938.2017.1318509

View supplementary material

Accepted author version posted online: 17
Apr 2017.
Published online: 25 May 2017.
Submit your article to this journal

Article views: 400

View related articles

View Crossmark data

Citing articles: 7 View citing articles

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=lecr20

ECONOMETRIC REVIEWS
2019, VOL. 38, NO. 2, 193–207
https://doi.org/10.1080/07474938.2017.1318509

Practical procedures to deal with common support problems in
matching estimation
Michael Lechner and Anthony Strittmatter
Swiss Institute for Empirical Economic Research (SEW), University of St. Gallen, St. Gallen, Switzerland
ABSTRACT

KEYWORDS

This paper assesses the performance of common estimators adjusting for
differences in covariates, such as matching and regression, when faced with the
so-called common support problems. It also shows how different procedures
suggested in the literature affect the properties of such estimators. Based on an
empirical Monte Carlo simulation design, a lack of common support is found
to increase the root-mean-squared error of all investigated parametric and
semiparametric estimators. Dropping observations that are off support usually
improves their performance, although the magnitude of the improvement
depends on the particular method used.

Common support; empirical
Monte Carlo study; matching
estimation; outlier;
regression; small sample
performance
JEL CLASSIFICATION

C21; J68

1. Introduction
It is a common task in applied econometrics to compare moments or distributions of random variables
of two subsamples that are free of differences due to some observed variables. One example that received
much attention in the recent applied literature is the evaluation of active labor market programs (ALMP)
based on very informative and large administrative data (see the metastudy by Card et al., 2010, for
a comprehensive summary of this literature). Usually, the main goal in this literature is to compare
expected future reemployment and earnings (“outcomes”) of participants in a program (“treatment”)
with nonparticipants. In many cases, identification is based on a selection-on-observable identification
strategy exploiting the rich data available (e.g., see Imbens, 2004, for an overview).
Essentially, all estimation procedures used in this context are based on predicting average outcomes
in one treatment state (e.g., for nonparticipants who are called “nontreated” from now on) based on the
distribution of exogenous variables in the other treatment state (e.g., the programme participants who are
called “treated” from now on). Apparently, in this example, if the values of the characteristics observed for
the treated are not observable among the nontreated, the mean outcome for the nontreated who would
have such characteristics cannot be estimated without strong assumptions. These assumptions allow
some extrapolation for such values of characteristics. This is the so-called no common support problem.
A related (finite sample) problem appears when there are only a few observations in some relevant part
of the covariate space in the particular sample at hand. This is called the thin common support problem.
Such areas of no or thin support may increase biases and variances of estimators (e.g., Crump et al., 2009;
Khan and Tamer, 2010). Surprisingly, and different from other aspects of treatment effect models, these
issues have received little attention in the literature.
Here, we investigate the impact of these problems on commonly used estimators and analyze
procedures proposed to address it. Similar to Huber et al. (2013), we do this in the context of a large-scale
CONTACT Michael Lechner
Michael.Lechner@unisg.ch
Swiss Institute for Empirical Economic Research (SEW), University of
St. Gallen, Varnbüelstrasse 14, St. Gallen CH-9000, Switzerland.
Color versions of one or more of the figures in the article can be found online at www.tandfonline.com/lecr.
Supplemental data for this article can be accessed on the publisher’s website.
© 2017 Taylor & Francis Group, LLC

194

M. LECHNER AND A. STRITTMATTER

active labor market policy evaluation and use empirical Monte Carlo methods. One of the contributions
of this paper is to show that common support problems as well as the “remedies” chosen matter for the
results obtained (see also Busso et al., 2014a; Dehejia and Wahba, 1999; Smith and Todd, 2005). When
there are support problems, they are addressed in different ways in applied studies. The most convenient
way is to ignore the problem and take as given the way that the specific estimators (as implemented in the
software used) deal with it. If support problems are explicitly addressed, then one possibility is to change
the population for which the effects are estimated to the one for which the distributions of characteristics
overlap. This matters if the effects are heterogeneous. Alternatively, one may use a parametric model to
predict mean outcomes in no support regions. A third alternative is to give up point identification and
confine oneself to a set-identified parameter (e.g., Lechner, 2008).
We stick to the more popular point-identified case and analyze several practical adjustment procedures proposed in the literature. For example, Rosenbaum and Rubin (1983) suggest dropping treated
observations for which there are no nontreated observations with the same covariate values. However,
this procedure may lead to drastic reductions in sample size if the covariate space is large or if there
are (almost) continuous covariates. Thus, most procedures used in practice, and analyzed in this paper,
focus directly on the propensity score, i.e., the conditional probability of treatment given the values of
the covariates.
There are also suggestions to address simultaneously problems of common support as well as (too)
important nontreated observations. These issues are related because, in regions of thin support, the
predictions are based on only few observations. This potentially leads to finite-sample bias and increased
variance. Therefore, Imbens (2004) and Huber et al. (2013) develop ways to address this issue, which
appear to be effective in the simulation study conducted by the latter authors. Finally, Crump et al. (2009)
suggest explicitly focusing the estimation on a subsample of the data with “strong common support” to
maximize the precision of the estimators.
Recently, Busso et al. (2014a) investigated some of those procedures. They find that some of the
approaches (i.e., those by Crump et al., 2009; Dehejia and Wahba, 1999; Ho et al., 2007; Smith and
Todd, 2005, to be explained in detail below) have the potential to reduce the bias and partly increase the
efficiency of the estimators. However, their simulation study is based on rather artificial distributional
assumptions that are unlikely to be observed in reality.
To address the issue of using a realistic design in a simulation study, recently, Lechner and Wunsch
(2013), and Huber et al. (2013) advocated using what they call an empirical Monte Carlo study (EMCS).
The main idea is to use a large data set, which is similar to the data typically used in relevant applied
work. In this large data set, considered to be the “population” in the simulation exercise, a propensity
score is estimated. Then, random samples are drawn from the subpopulation of the nontreated. For this
group, the effect of treatment is known to be zero. Next, the estimated propensity score is used to assign
a (pseudo)treatment status to these nontreated. Such a procedure reflects the same selectivity observed
in the population while insuring that the true effect is known (and zero) and does not require a priori
specifying the joint distribution (or conditional moments) of outcomes, confounders, and treatment.1
Our results suggest that dropping observations that are off support improve the performance of
many estimators, mainly by increasing their precision. For matching estimators, this improvement can
exceed 20 standard deviations in some specifications. Even for parametric estimators, the performance
improvements may be nontrivial and worth pursuing. The procedures of Dehejia and Wahba (1999),
Grzybowski et al. (2003), and Vincent et al. (2002) appear to improve the performance of different
estimators in (almost) all specifications. We suggest dropping-treated observations with propensity score
values above a specific threshold. Our findings suggest specifying the cutoff value at the maximum or
1

There are alternatives in the literature that share the goal of making simulation studies more relevant but do not share
this feature. For example, Abadie and Imbens (2011) and Busso et al. (2014b) propose to apply more structural empirical
simulation designs. The dependence structures among the control, treatment, and outcome variables are estimated with
real data. Afterward, the treatment and outcome variables are simulated using the distribution of control variables from
real data and the coefficients estimated in the first step. This approach has the advantage that the size of the treatment
effect can be restricted, but it requires assumptions about the distribution of the “error terms.”

ECONOMETRIC REVIEWS

195

the 99% quantile of the propensity score in the nontreated subpopulation. This procedure might be
combined with an adjustment among the nontreated. Nontreated observations with a high importance
(in the matching) should be dropped in the first place. Afterward, treated observations with propensity
score values above a threshold are dropped, with the threshold value being specified in the remaining
nontreated sample (two-step procedure suggested by Huber et al., 2013).
The remainder of this study is organized as follows. In the next section, we introduce the econometrics
framework. The underlying data and the simulation design are presented in Section 3. The results are
presented in Section 4, and conclusions are drawn in Section 5. Furthermore, we provide a discussion
about the detection of support problems and possibly remedies in Online Appendix A. Some details of
the data, the simulation procedures, and supplementary results are provided in Online Appendices B–H.

2. The econometric model
2.1. Parameter of interest
Consider a setup with a binary treatment D, d ∈ {0, 1} (e.g., participation in a program), and an outcome
variable Y (e.g., postprogram employment or earnings). X is a K-dimensional vector of covariates with
support X ⊂ RK .2 The goal of the empirical analysis is to obtain mean comparisons of the outcome
variable in the subsamples defined by D that are free of any differences due to the covariates X. If
the covariate space is sufficiently rich, such a comparison will uncover parameters that have a causal
interpretation, e.g., the average treatment effect on the treated (for detail, see Imbens, 2004 or Rubin,
1973). More specifically, the focus is on the following estimand:
γ = E [Y|D = 1] − E [E (Y|X = x, D = 0) |D = 1] .
In analogy to this definition, one can define similar parameters for other subpopulations as well. Here,
for simplicity, the focus is only on γ , because (i) this parameter is of interest in most evaluation studies,
and (ii) because support problems appearing for most other parameters can be addressed in a symmetric
way.
Assume that an i.i.d. sample of size N is available containing measurements of yi , di , and xi . Thus,
under usual regularity conditions, γ can be nonparametrically identified. However, when the dimension
of X is high, the so-called curse of dimensionality makes reliable nonparametric estimation difficult
to impossible. In this case, the balancing score property introduced by Rosenbaum and Rubin (1983)
obtains practical relevance. It implies the following equality, which also holds in all subpopulations
defined by X:



E [E (Y|X = x, D = 0) |D = 1] = E E Y|p (X) = p (x) , D = 0 |D = 1 .
p(x) = P(D = 1|X = x) denotes the propensity score. In most applications, the propensity score is
approximated by a parametric model so that the resulting nonparametric estimation problem becomes
essentially one dimensional.
2.2. The common support assumption
Implicitly, the estimand defined above requires that for every unit with d = 1, there should be a unit
with the same (or a similar) value of p(x) among the group of units with d = 0. Let f (p(x)|D = d) be the
density of the propensity score p(x) conditional on the treatment status d. The density f (p(x)|D = 1)
can be consistently estimated in the treated subsample under some regularity conditions. The same is
true for f (p(x)|D = 0) in the nontreated subsample. There are “support problems” (in the population)

2

We use the convention that capital letters denote random variables, whereas small letters denote particular values. If small
letters are subscripted with i, such values are observed in a random sample.

196

M. LECHNER AND A. STRITTMATTER


when f (p(x)|D = 0) = 0 and f p (x) |D = 1 > 0. The set Wd = {p(x) ∈ (0, 1) : f (p(x)|D = d) > 0}
represents the support of p(x) for d being zero or one.
Common support assumption
W1 ⊆ W0 .
This assumption is automatically satisfied in the population when p(x) < 1. However, even if this
assumption holds in the population, the actual sample available may still be plagued by a lack of overlap.
A comprehensive summary of different ways to detect support problems as well as a description of
possible identification and estimation approaches in the presence of support problems is in Online
Appendix A.

2.3. Balance of propensity score distributions
Even if the common support assumption is satisfied, an imbalance in the sample propensity score
distributions could still lead to regions with only few (or none) treated or nontreated observations.
Imbens (2004) suggests generating measures for the importance of each observation. A high importance
indicates a high probability for a large imbalance in the conditional propensity score distributions
with respect to the treatment status (for a given sample size). Following Huber et al. (2013), we drop
nontreated observations with a high importance weight, which we denote by ω̂i in the following. For
details about the implementation, please, see Online Appendix A.4.

2.4. Estimation
We assess the impact of support problems and their remedies on three different classes of estimators. In
the following, we give a brief overview of the applied estimators. The details of the implementation can
be found in Section C.4 of Online Appendix C.
The first class consists of parametric regressions. We use ordinary least-squares (OLS) regressions
for continuous and discrete nonbinary outcome variables. For binary outcome variables, we specify
parametric probit models. These estimators also “work” without common support. However, because
parametric models are only approximations of the true model, one may suspect that their out-of-support
predictions might be particularly unreliable.
The second class of estimators considered is based on inverse probability weighting (IPW) using the
propensity score. The estimated propensity score is obtained from a parametric probit model. Therefore,
the common support assumption is, again, not required for this estimator either. However, as before, the
results outside the common support depend on the correct specification of the parametric model for the
propensity score.
The third class of estimators considered is propensity score matching estimators. In particular, we
investigate the popular modified and bias adjusted propensity score radius-matching estimator suggested
by Lechner et al. (2011).

3. Empirical Monte Carlo study
The analysis of the common support issues is based on an EMCS, as suggested by Huber et al. (2013)
and Lechner and Wunsch (2013). It combines the advantages of a “classical” Monte Carlo study with the
advantages of using real data. The idea is to use a large data set, which is similar to data in the respective
field of study. To obtain appropriate random samples for the Monte Carlo study, the first step consists of
estimating the propensity score in the full data. This estimated model will reflect the “true” selectivity.

ECONOMETRIC REVIEWS

197

Subsequently, random samples from the nontreated subpopulation are drawn. A (pseudo) treatment
is assigned according to the “true” selection model. Because there are only nontreated individuals in
the samples used in the simulations, the true effect of the assigned treatment is known to be zero. The
key advantages of this procedure are that the selectivity in the samples reflects the selectivity in the
larger population, and that there is no need for stipulating a model on how the outcomes depend on
treatment and covariates. Adding some more structure allows varying various components of the data
generating process that are deemed relevant in the particular analysis. We vary the sample size (N = 500,
2,000, 8,000), the share of treated (10%, 50%, 90%), the outcome variable (earnings, months employed,
employment), the degree of effect heterogeneity, the propensity score specification, and the severity of
the support problem. The details of the simulation process are described in Online Appendix C. In the
next section, we discuss the administrative data used for the simulation.

3.1. Empirical bases for the simulations: German administrative data
3.1.1. Data base
The German Federal Employment Agency generated the data for this study from their social security
records. It contains information regarding individuals having received a training voucher in 2003 or 2004
and those who did not. Training vouchers certify the eligibility for public sponsored further training
(see Doerr et al., 2014, for more details). Unemployed awarded with a voucher may redeem it at certified
training providers.
The data contain extensive daily information on employment subject to social security contributions,
receipt of transfer payments during unemployment, job search, and participation in different ALMP as
well as rich individual information. It is a combination of two populations: A 3% random sample of
those individuals in Germany who experienced at least one switch from employment to nonemployment
in 2003 and did not receive any voucher are merged with all voucher recipients. We account for the
treatment-based sampling scheme by using sampling weights when necessary. This type of data has been
frequently used to evaluate German active labor market policies (e.g., Biewen et al., 2014; Lechner et al.,
2011; Rinne et al., 2013). It is comparable with many administrative data sets in Europe (Lechner and
Wunsch, 2013).
The treatment consists of receiving a voucher for further training during the first 20 months
of unemployment. Training vouchers indicate the particular type of course for which they may be
redeemed. We only consider vouchers awarded to obtain skills for manufacturing or service workers
(in the following: vouchers for manufacturing and service workers, VMSW) and vouchers to obtain skills
for technicians (in the following: vouchers for technicians, VTEC). These are interesting because their
selection processes show considerable heterogeneity: the award of VTEC is far more selective than the
award of VMSW.
3.1.2. Control variables and common support
The choice of control variables follows Lechner and Wunsch (2013). We consider all variables identified
as important confounders in their study, i.e., baseline personal characteristics, timing of program start,
regional dummies, benefit and unemployment insurance claims, preprogram outcomes, and the shortterm labor market history. Measurements regarding individual characteristics refer to the time of inflow
into unemployment. Further information about the control variables and the support of the propensity
score in the different samples can be found in Online Appendix B. The full list of variables used for the
propensity scores (including interaction terms) is given in Tables B.1 and B.2.
Individuals with high educational or occupational degrees who work as technicians, professionals, or
managers are very likely to obtain a VTEC (but not necessarily a VMSW). For simulation and modeling
purposes, it is useful to relate the support problems to particular variables. Thus, three interactions
between occupation and educational/vocational degree are included in the propensity score probit
model: (i) being a technician or having an associate profession interacted with a higher secondary

198

M. LECHNER AND A. STRITTMATTER

schooling degree (S1 ); (ii) being a professional or manager interacted with a higher secondary schooling
degree (S2 ); and (iii) being a professional or manager interacted with a university or college degree (S3 ).
The three interaction terms, which are binary, are collected in the “support variable” S:
Si = max (S1i , S2i , S3i ) .
The support variable Si equals one for 66% of all individuals who are awarded with VTEC, but only for
21% of all individuals who are awarded with VMSW and for 20% of those not receiving a voucher at all.

4. Results
4.1. General remarks
There are results for 252 different Data Generating Processes (DGPs), 46 procedures to deal with support
problems, three outcomes, three estimators, and up to three different model specifications.3 It is not
possible to report (and understand!) all of these results without reducing their dimensionality. Therefore,
linear regressions provide summary measures. In these regressions, the dependent variables consist of
measurements of the quality of the estimators, such as the root-mean-squared error (RMSE), the absolute
bias, and the standard errors. The independent variables reflect different features of the DGPs (treatment
shares, types of effect heterogeneity, sample size, and type of voucher), of the model specifications, of the
estimators, and of the various rules to tackle the support problem (see Table 1 for the list of all procedures
used; a more comprehensive description is provided in Online Appendix A).
Controls for model specifications, treatment shares, and types of effect heterogeneity are interacted
with each other (but not with the dummies for the different procedures to handle support problems).
Furthermore, separate regressions are reported for different types of vouchers, estimators, sample sizes,
and types of support reductions as, a priori, considerable heterogeneity is expected with respect to those
features.
In the regressions, three different outcome variables (earnings, months employed, employment) are
pooled. Because they are measured on different scales, they are normalized by their standard deviation
in the baseline specification (see Online Appendix D for details). Therefore, for a given estimation
procedure, the regression coefficients of the binary control variables indicate by how many standard
deviations the performance measure changes if this dummy turns on in comparison with the omitted
category. In addition, Tables H.1–H.12 in Online Appendix H report heterogeneous results by the type
of outcome.
The next section reports regression results for the case without additional support restrictions. It is
followed by the case with restricted support. Detailed results are reported in Online Appendix G.
4.2. Regression results for DGPs not restricting common support
The DGPs for which the treatment is based on the award of VMSW are expected not to be subject
to severe support problems because of their low degree of selectivity (see Tables B.1 and B.2 in Online
Appendix B). Although the award of VTEC is more selective, even in this case, the population propensity
scores exceed the level of 0.9 only when the treatment share is 90%. Even then, it remains below one
(see Figures B.1 and B.2 in Online Appendix B) so that the DGPs considered in this section show
no asymptotic support problems. Nevertheless, issues of thin support may still be relevant. Tables 2
and 3 report the results from the regressions of the normalized RMSE on different procedures to
handle support problems (the reference category is ignoring the problem, i.e., Procedure A). Negative
coefficients indicate improvements, and positive ones indicate impairments in RMSE. We report the
results for selected procedures only. The results for the complete set of common support procedures
3

The DGPs vary by sample size, treatment share, type of treatment (VMSW or VTEC), type of effect heterogeneity, and type of
support restrictions. Overall, there are 90,720 different results.

ECONOMETRIC REVIEWS

Table 1. Procedures for handling support problems.
Procedure
Description

Rule

Assumption

199

References

Drop treated based on fixed value of propensity score
A
WA
B1
B2
WBx

Drop no observations
Drop nontreated if weights high (ω̂ ≥ 0.04)
Drop if 0.1 < p(x) < 0.9
Drop if p(x) < 0.9
Bx and WA

D

Imbens (2004)
Crump et al. (2009)

Heckman et al. (1998, 1997), and
Smith and Todd (2005)

Drop treated based on density of propensity score
C1

Drop treated if f (p(x)) < q2

1

D

C2
C3

Drop treated if f (p(x)) < q10
Drop treated if f (p(x)) < qτ with
τ = (100/N) × 100%
Cx and WA

1

D

1

D

WCx

Drop treated based on lack of nontreated neighbors in terms of radius of propensity score
D1
D2
WDx

Drop treated if no close match in 0.01 radius
(u = 0.01)
Drop treated if no close match in 0.1 radius
(u = 0.1)
Dx and WA

2

D

2

D

2

D

Grzybowski et al. (2003)
Vincent et al. (2002)

Drop treated based on upper limits of distribution of propensity score among nontreated
E1
E2
E3
WEx

Drop treated above highest nontreated
p-score
Drop treated above 99% highest nontreated
p-score
Drop treated above 95% highest nontreated
p-score
Ex and WA

3

D

3

D

3

D

3

D

3

E

3

E

3

E

3
3

E
F

3

F

3

F

3
3
3

F
B
B

3

B

3
3

B
C

3

C

3

C

3

C

Dehejia and Wahba (1999) and
Huber et al. (2013)

Procedures that extrapolate into lack of support region
F1
F2
F3
WFx
G1
G2
G3
WGx
H1
H2
H3
WHx
I1
I2
I3
WIx

E1 and estimate Y1|N − Y0|N at highest
nontreated p-score
E2 and estimate Y1|N − Y0|N at 99% highest
nontreated p-score
E3 and estimate Y1|N − Y0|N at 95% highest
nontreated p-score
Fx and WA
E1 + lin. approx. of Y1|N −Y0|N above highest
nontreated p-score
E2 + lin. approx. of Y1|N − Y0|N above 99%
highest nontreated p-score
E3 + lin. approx. of Y1|N − Y0|N above 95%
highest nontreated p-score
Gx and WA
Estimate Y0|N at highest nontreated p-score
Estimate Y0|N at 99% highest nontreated
p-score
Estimate Y0|N at 95% highest nontreated
p-score
Hx and WA
Lin. approx. of Y0|N above the highest
nontreated p-score
Lin. approx. of Y0|N above the 99% highest
nontreated p-score
Lin. approx. of Y0|N above the 95% highest
nontreated p-score
Ix and WA

Note: WA indicates that nontreated observations with ω̂ ≥ 0.04 are dropped (see Section 2.3 and Online Appendix A.4). This procedure
is used in combination with other procedures (two-step procedure). A complete description of all support procedures can be found
in Online Appendix D.

200

M. LECHNER AND A. STRITTMATTER

Table 2. Effect of support-adjustment procedures on normalized RMSE in DGPs without support restrictions for the treatment “award
of VMSW.”
Sample size
Support
Procedures

500

2,000

8,000

Parameter

IPW

Match.

Parameter

IPW

Match.

Parameter

IPW

Match.

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

−0.012

0.003

0.005

−0.017

0.004

0

0

0

0.220***

0.187***

0.188***

0.701***

0.640***

0.611***

0.001
0.007
0.209

0
−0.017
−0.021

0.002
0.005
−0.021***

0
0
0.104

0
0
−0.015

0
0
0.176

0
0
0
0

0
0
0
0

−0.001
−0.001
0
0

No adjustment (A: reference)
WA

0.002

Drop treated based on fixed value of propensity score
B2

−0.007

−0.015*

−0.007

Drop treated based on density of propensity score
C2
WC2
C3

0.017
0.018
0.441

0.019**
0.007
−0.020*

0.011
0.013
0.486

Drop treated based on lack of nontreated neighbors in terms of radius of propensity score
D1
WD1
D2
WD2

−0.016
−0.016
−0.001
0

0.007
−0.006
0
−0.012

−0.025
−0.025
−0.002
0.001

−0.001
0.001
0
0.005

0
−0.017
0
−0.017

−0.001
0
0
0.003

Drop treated based on upper limits of distribution of propensity score among nontreated
E1
WE1
E2
WE2
E3
WE3

−0.013
−0.013
−0.010
−0.009
0.037
0.038

0.003
−0.009
−0.025***
−0.025***
−0.004
−0.004

−0.019***
−0.020
−0.018
−0.018
0.017
0.018

−0.013
−0.015
−0.006
−0.008
0.070***
0.072***

0.001
−0.018
−0.021
−0.026*
0.027*
0.028*

−0.013**
−0.016***
−0.004
−0.005
0.058***
0.059***

−0.003
−0.003
0.028
0.028
0.242***
0.242***

−0.001
−0.001
−0.001
−0.001
0.182***
0.182***

−0.004
−0.004
0.019
0.019
0.186***
0.186***

0.047
0.050
0.032
0.036
−0.001
0.004
0.022
0.026
2,484

0.259***
0.221*
0.014
0.013
0.448**
0.544***
−0.003
−0.004
3,726

0.006
0.011**
0.017***
0.019***
0.004
0.009*
0.001
0.001
3,726

0.078
0.078
0.020
0.020
−0.062**
−0.062**
0.022
0.022
2,484

0.255*
0.255*
0.004
0.004
0.234
0.234
−0.003
−0.003
3,726

0.157
0.157
0.013
0.013
−0.052**
0.052**
0.010
0.010
3,726

Procedures that extrapolate into lack of support region
F2
WF2
G2
WG2
H2
WH2
I2
WI2
# of obs.

0.633
0.770*
0.042
0.046
1.039*
0.792**
0.037
0.042
828

0.031***
0.034***
0.013*
0.015**
0.023***
0.026***
0.005
0.007
1,242

0.249
0.251
−0.002
−0.001
−0.033
0
−0.009
−0.007
1,242

Note: The results are obtained from OLS regressions. The dependent variable is the normalized RMSE. The covariates contain a full set
of dummy variables for the different procedures to handle support problems. The reference category is to drop no observations
(Procedure A, a full description of the different procedures is given in Table 1). Further control variables are the tuning parameters
of the different DGPs in a fully interacted way (see description in main text). Only selected coefficients for the different procedures
are reported in this table. A complete set of results, including standard errors and R2 s, is shown in Online Appendix E. There are
fewer observations for the small N, because only the case of 50% treatment shares is considered. The same holds for the parametric
estimations, because only two specifications are considered (instead of 3, see Online Appendix C).
IPW, inverse probability weighting; OLS, ordinary least-squares; RMSE, root-mean-squared error; VMSW, vouchers for manufacturing and
service workers.
***, **, * Significance at the 1, 5, and 10% levels, respectively (based on robust standard errors).

(including the standard errors of the estimated coefficients and R2 s), as well as for other performance
measures (normalized absolute bias, standard deviation) can be found in Online Appendix E (Tables E.1–
E.6).
Both tables show that for most procedures, the case with a reduction of the normalized RMSE (in
comparison with the omitted category of dropping no observations) most likely occur in the smallest
samples. Interestingly, it appears that almost all procedures either have no effect on the normalized
absolute bias of the estimators (see Tables E.3 and E.5 in Online Appendix E), or increase it (somewhat).
However, such increases are usually (over-)compensated for by a reduction in the variability of the

ECONOMETRIC REVIEWS

201

Table 3. Effect of support-adjustment procedures on normalized RMSE in DGPs without support reduction for the treatment “award of
VTEC.”
Sample size
Support
Procedures

500

2,000

8,000

Parameter

IPW

Match.

Parameter

IPW

Match.

Parameter

IPW

Match.

(10)

(11)

(12)

(13)

(14)

(15)

(16)

(17)

(18)

−0.097***

0.037***

0.018*

−0.092***

0.018***

0.001

−0.037

0.003

0.163***

0.036

0.118***

0.576***

0.374***

0.461***

0.002
0.020*
−0.029**

0
−0.091***
−0.028

0.003
0.021***
−0.054***

0
0.001
−0.097***

0
−0.037
0.207

0
0.003
−0.012

−0.001
0
0
0.001

0
−0.037
0
−0.037

−0.004
−0.001
0
0.003

No adjustment (A: reference)
WA

0.014

Drop treated based on fixed value of propensity score
B2

−0.038*

−0.112***

−0.069***

Drop treated based on density of propensity score
C2
WC2
C3

−0.007
0.006
−0.060**

0.014
−0.089***
−0.035**

−0.036***
−00.006
−0.087***

Drop treated based on lack of nontreated neighbors in terms of radius of propensity score
D1
WD1
D2
WD2

−0.047**
−0.045**
−0.002
0.006

0.017
−0.095***
0
−0.099***

−0.113***
−0.112***
−0.004
0.021**

−0.011
−0.023**
−0.001
0.017

0.001
−0.102***
0
−0.092***

−0.020***
−0.029***
0
0.018***

Drop treated based on upper limits of distribution of propensity score among nontreated
E1
WE1
E2
WE2
E3
WE3

−0.039*
−0.046**
−0.039*
−0.037
0.032
0.040

0.004
−0.101***
−0.123***
−0.132***
−0.106***
−0.101***

−0.082***
−0.096***
−0.098***
−0.098***
−0.059***
−0.054***

−0.039***
−0.039***
−0.019
−0.014
0.132***
0.140***

0
−0.106***
−0.097***
−0.121***
−0.013
−0.007

−0.048***
−0.054***
−0.049***
−0.050***
0.053***
0.059***

−0.016
−0.018
0.073**
0.075**
0.489***
0.490***

−0.003
−0.043*
−0.040*
−0.040*
0.312***
0.313***

−0.023
−0.026
0.020
0.021
0.363***
0.364***

0.048***
0.065***
0.077***
0.100***
0.041***
0.059***
0.044***
0.061***
2,484

0.156
0.141
−0.012
−0.019
−0.028
−0.037**
−0.055***
−0.065***
3,726

0.005
0.030***
0.008
0.021***
−0.003
0.022***
−0.027***
−0.019***
3,726

−0.019
−0.017
0.085***
0.086***
0.020
0.022
0.067**
0.068**
2,484

0.072
0.072
−0.012
−0.012
−0.049**
−0.048**
−0.052*
−0.051*
3,726

0.013
0.015
0.022
0.023
−0.023
−0.021
−0.009
−0.008
3,726

Procedures that extrapolate into lack of support region
F2
WF2
G2
WG2
H2
WH2
I2
WI2
# of obs.

0.094***
0.305*
0.091***
0.125***
0.086***
0.125***
0.048***
0.067***
828

0.264
0.205
−0.010
0.002
−0.006
0.007
−0.059***
−0.057***
1,242

−0.013*
0.001
−0.026***
−0.013
−0.026***
−0.010
−0.066***
−0.061***
1,242

Note: The results are obtained from OLS regressions. The dependent variable is the normalized RMSE. The covariates contain a full set
of dummy variables for the different procedures to handle support problems. The reference category is to drop no observations
(Procedure A, a full description of the different procedures is given in Table 1). Further control variables are the tuning parameters
of the different DGPs in a fully interacted way (see description in main text). Only selected coefficients for the different procedures
are reported in this table. A complete set of results, including standard errors and R2 s, is shown in Online Appendix E. There are
fewer observations for the small N, because only the case of 50% treatment shares is considered. The same holds for the parametric
estimations, because only two specifications are considered (instead of 3, see Online Appendix C).
IPW, inverse probability weighting; OLS, ordinary least-squares; RMSE, root-mean-squared error; VTEC, vouchers for technicians.
***, **, * Significance at the 1, 5, and 10% levels, respectively (based on robust standard errors).

estimators (see Tables E.4 and E.6 in Online Appendix E). Accordingly, the performance of the estimators
can be improved, even in DGPs where the support conditions are not violated in the population. This
is in line with the arguments of Busso et al. (2014a), Crump et al. (2009), and Khan and Tamer (2010)
suggesting that thin support issues lead to a loss of precision. Finally, note that for the treatment award of
VTEC, with a strong selection into treatment, the potential performance improvements are considerably
larger than for the treatment award of VMSW. Next, the performance of the single procedures is
discussed in more detail.

202

M. LECHNER AND A. STRITTMATTER

Dropping observations with high importance (WA) improves only the performance of IPW estimators. However, when this approach is combined with other procedures, then these (joint) procedures
(beginning with W) have the potential to improve the performance of the single procedure with which
it is combined. This is consistent with the findings of Huber et al. (2013).
The procedure of Crump et al. (2009) is applied in two different specifications. First, we drop all
observations with a propensity score below 0.1 and above 0.9 (B1; see Online Appendix E). Second, only
observations with a propensity score above 0.9 (B2) are dropped. Although B1 and B2 seem to work for
the small samples, for the larger sample, they lead to biases that are large enough to dominate the RMSE.
The results for the procedure dropping treated observations with a low marginal density I are not
encouraging either. Although there appears to be some possibility of improvements on the performance
of estimators if the selectivity is strong enough (Table 3), in the case of weak selectivity (Table 2), the
small sample performance deteriorates. For procedure C3, which is adaptive to the sample size, we find
improvements in RMSE particularly for smaller sample sizes. Reduction in the standard deviations and
not improvements in the biases drive this result.
Procedure D drops treated observations for which the distance to the closest one-to-one match is
below u, i.e., all treated observations with a propensity score difference to the closest control observation
above u are dropped, with u ∈ {0.01; 0.001} (see Grzybowski et al., 2003; Vincent et al., 2002). Procedure
E drops treated observations with a propensity score above a cutoff value p̄ (Dehejia and Wahba,
1999). In general, D and E improve the performances of the estimators equally well. Unlike most other
procedures, only in very rare cases, do these procedures hurt the performances of the estimators in terms
of normalized RMSE. The largest improvement (originating from the standard deviations) can most
often be obtained from E. This procedure works better than D, particularly in larger samples, when p̄
is specified as being either the maximum or the value of the 99% quantile of the propensity score in
the nontreated sample. In the smallest sample, Procedure D appears to have slightly better properties
than E. In most cases, D works best with u = 0.01 for parametric and matching estimators. Using D
with u = 0.01 or u = 0.1 performs about equally well for IPW estimators. Both procedures improve
somewhat when combined with W.
All procedures that aim to estimate the conditional treatment effect γN = Y1|N − Y0|N or Y0|N
off support (F, G, H, I) do not perform well. In most cases, there are no performance improvements.
However, if any improvements show up, then they are, with rare exceptions, smaller than for the other
procedures discussed above. A noticeable exception is support procedure H, which seems to be one of
the few procedures that may improve the RMSE even in the absence of support problems.
4.3. Regression results for DGPs with reductions of common support
Next, DGPs are considered for which the support with respect to S is restricted in a way that causes
(serious) support problems. For this purpose, we restrict P (D = 1|S = 1). In particular, we replace
P (D = 1|S = 1) by P (D = 1|S = 1)′ = 1 − φ, where the prime indicates the restricted conditional
treatment probability. If φ = 0, then even asymptotically, there is no common support. When 0 < φ < 1,
there is common support in the population, but it may be thin when φ is small. Remember, the share
of observations with S = 1 is much larger for individuals awarded with VTEC than with VMSW.4
Accordingly, the treatment award of VTEC is considerably more affected by the support reductions than
the treatment award of VMSW.
Figure F.1 in Online Appendix F shows the performance of parametric, IPW, and matching estimators
when no observations are dropped (A). In this figure, P(D = 1|S = 1)′ is gradually increased based on
the grid {0.9, 0.91, . . . , 1}. To be precise, the figures show the coefficients of the indicator variables for
the different points of the grid based on the same regressions reported before but pooled for the two
treatments. We find an increase in the average normalized RMSE between 0.1 and 1 standard deviation
if P(D = 1|S = 1)′ = 0.9 in comparison with the specifications with no support restrictions. However,
4

From Section 3.2, we obtain P (S = 1)′ = δP (D = 1) with δ = 0.21 for VMSW and δ = 0.66 for VTEC.

ECONOMETRIC REVIEWS

203

if P(D = 1|S = 1)′ = 1, the average normalized RMSE can be increased by up to eight standard
deviations. Support reductions have the strongest impact on the matching estimator. Interestingly,
matching estimators appear to have on average lower normalized absolute biases than parametric and
IPW estimators. This is in line with the findings of Busso et al. (2014b), who report that the biases
of matching estimators are less affected by overlap problems than the bias of IPW estimators. The
normalized absolute bias of matching estimators exceeds those of parametric and IPW estimators, only
for very strong support reductions. However, the average normalized standard deviation of matching
estimators becomes very large under strong support restrictions. This is the main reason for the bad
performance of matching in the specifications with strong support reductions. For parametric and
IPW estimators, the performance in terms of average normalized absolute bias and average normalized
standard deviation is more balanced in this situation. However, the average normalized RMSE, average
normalized absolute bias, and average normalized standard deviation of these estimators may increase
by up to one standard deviation when support reductions are substantial. The performance of these
estimators is almost linearly decreasing when the support is reduced.
Tables 4 and 5 report the results from regression for the normalized RMSE for the case of such support
reductions. For the sake of computation time, only specifications with φ = 0 and φ = 0.01 are included
because these two scenarios lead to the most serious support problems. Thus, the specification of the OLS
regressions is similar to the one used in the previous section. The only difference is that an additional
dummy variable for the case P(D = 1|S = 1)′ = 0.99 is included. As before, Tables 4 and 5 report only
a subset of the results. The complete set of results can be found in Online Appendix F (Tables F.1–F.6).
Not surprisingly, the performance improvements for the different estimators are more pronounced
than for the DGPs without support restrictions. Furthermore, parametric, IPW, and matching estimators
have very different properties for the DGPs with restricted support (see Tables 4 and 5 as well as Tables
F.1 and F.2 in Online Appendix F). The greatest improvements occur for matching estimators for which
all procedures handling support problems work well. However, note that various procedures improve
the performance of parametric and IPW estimators as well: their normalized RMSE improves by up to
0.7 standard deviations.
Noticeably, the performance of the matching estimator improves when the sample size increases,
whereas the performance of the parametric and IPW estimator is much less affected by the sample size.
This finding suggests that the matching estimator can address support problems appropriately when the
sample size is increasing and thin support regions are filled. Under the strong support restrictions we
simulate, the performance improvements of parametric and IPW estimators do not increase with sample
size.
As before, Procedure WA used alone only improves the performance of IPW estimators, but when
combined with other procedures, such two-step procedures may improve the performance of all
estimators.
Procedure B strongly reduces the normalized standard deviation of all estimators (the parametric
estimators in the largest sample are an exception; see Tables F.5 and F.6 in Online Appendix F). However,
as the normalized absolute bias increases (see Tables F.3 and F.4 in Online Appendix F), the overall effect
on the normalized RMSE is ambiguous. It is only for the matching estimators that this procedure always
leads to such performance improvements.
In contrast, Procedure C has again only little impact on the performance of the different estimators.
With few exceptions, C neither harms nor improves their performance. In addition, the data-adaptive
procedure C3, which adjusts to the sample size, does (with few exceptions) not affect the performance
of the estimators.
Procedures D and E have the largest positive effect on the performance of the estimators when
there are strong support problems. They improve the normalized standard deviation of all estimators,
particularly in the smaller samples. These improvements are largest for matching estimators. For the
award of VTEC, they can exceed 20 standard deviations. D and E also reduce the normalized RMSE and
normalized absolute bias, particularly when the treatment is award of VTEC. In some specifications,
the normalized RMSE can be improved by up to 20 and the absolute bias by up to 5 standard

204

M. LECHNER AND A. STRITTMATTER

Table 4. Effect of support-adjustment procedures on normalized RMSE in DGPs with support restrictions for the treatment “award of
VMSW.”
Sample size
Support
Procedures

500

2,000

8,000

Parameter

IPW

Match.

Parameter

IPW

Match.

Parameter

IPW

Match.

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

(9)

−0.096***

0.070

0.017

−0.081***

0.155

0

−0.009

4.590

0.112***

0.020

−3.709***

0.563***

0.394***

−7.292***

0.003
0.021
−0.006

0.001
−0.080***
−0.013

0.005
0.160
−0.016

0
0
−0.021

0
−0.009
−0.026

0
4.590
6.114

0.015
0.015
0.002
0.003

−0.051*
−0.061**
−0.009
−0.018

−7.524***
−7.675***
−7.112***
−7.184***

No adjustment (A: reference)
WA

0.019

Drop treated based on fixed value of propensity score
B2

−0.110***

−0.109***

−1.624***

Drop treated based on density of propensity score
C2
WC2
C3

−0.091***
−0.077***
−0.106***

0.001
−.102***
−0.024***

0.002
0.049
−0.403

Drop treated based on lack of nontreated neighbors in terms of radius of propensity score
D1
WD1
D2
WD2

−0.124***
−0.124***
−0.012
−0.016

0.009
−0.095***
−0.003
−0.103***

−1.641***
−1.648***
−1.493***
−1.501***

−0.023
−0.050***
0
0.018

−0.014
−0.110***
−0.001
−0.082***

−3.768***
−3.903***
−3.516***
−3.611***

Drop treated based on upper limits of distribution of propensity score among nontreated
E1
WE1
E2
WE2
E3
WE3

−0.109***
−0.121***
−0.116***
−0.114***
−0.064***
−0.060**

0.001
−0.100***
−0.113***
−0.127***
−0.119***
−0.115***

−1.625***
−1.641***
−1.635***
−1.636***
−1.593***
−1.591***

−0.067***
−0.075***
−0.040
−0.0421
0.043
0.047

−0.017
−0.114***
−0.102***
−0.115***
−0.052
−0.050

−3.875***
−3.919***
−3.910***
−3.913***
−3.840***
−3.838***

0.009
0.009
0.177***
0.177***
0.376***
0.376***

−0.071**
−0.084***
−0.020
−0.021
0.201***
0.201***

−7.764***
−7.901***
−7.910***
−7.910***
−7.730***
−7.729***

.270***
0.266***
0.063**
0.069**
0.079***
0.075***
−0.008
−0.008
2,376

−3.539***
−3.543***
−3.732***
−3.723***
−3.646***
−3.649***
−3.844***
−3.842***
4,752

.221***
0.222***
0.110***
0.110***
0.118***
0.119***
0.051
0.051
2,376

.202***
0.203***
0.039
0.038
0.051
0.052*
−0.015
−0.015
2,376

−7.664***
−7.671***
−7.856***
−7.851***
−7.681***
−7.697***
−7.956***
−7.953***
4,752

Procedures that extrapolate into lack of support region
F2
WF2
G2
WG2
H2
WH2
I2
WI2
# of obs.

0.266***
0.248***
0.149***
0.199***
0.131***
0.150***
0.041***
0.059***
792

.267***
0.277***
0.142***
0.177***
0.188***
0.187***
0.042***
0.047***
792

−1.281***
−1.273***
−1.404***
−1.388***
−1.387***
−1.385***
−1.571***
−1.568***
1,584

.180***
0.190***
0.106***
0.121***
0.083***
0.094***
0.033*
0.043**
2,376

Note: The results are obtained from OLS regressions. The dependent variable is the normalized RMSE. The covariates contain a full set
of dummies for the different procedures handling support problems. The reference category is to drop no observations (Procedure
A). Further covariates are the tuning parameters of the different DGPs fully interacted (see description in Online Appendix B). Only
selected coefficients for the different procedures are reported in this table. A complete set of results, including standard errors and
R2 s, are found in Online Appendix F.
IPW, inverse probability weighting; OLS, ordinary least-squares; RMSE, root-mean-squared error; VMSW, vouchers for manufacturing and
service workers.
***, **, * Significance at the 1, 5, and 10% levels, respectively (based on robust standard errors).

deviations. In rare cases when the treatment is award of VMSW, E increases the normalized absolute
bias of the parametric and IPW estimators,5 whereas D does not affect them. However, E leads to
larger improvements in the normalized standard deviations than does D in these specifications. Both
procedures work better when combined with W.
All procedures aiming to estimate γATET|N or Y0|N off support (F, G, H, I) work only for matching
estimators, if they work at all. However, even for matching estimators, they do not outperform procedures
D and E, which are much easier to implement.
5

This appears only very rarely when the threshold p̄ is specified at the highest propensity score value of the nontreated
subpopulation.

ECONOMETRIC REVIEWS

205

Table 5. Effect of support-adjustment procedures on normalized RMSE in DGPs with support restrictions for the treatment “award of
VTEC.”
Sample Size
Support
Procedures

500

2,000

8,000

Parameter

IPW

Match.

Parameter

IPW

Match.

Parameter

IPW

Match.

(10)

(11)

(12)

(13)

(14)

(15)

(16)

(17)

(18)

−0.654***
−0.112

3.642**
0.494

0.130
−0.041

−0.393*
−0.092

0.797
2.268

0.0291
0.006

−0.173
0.004

7.955
−1.211

−0.538**

−0.649**

−22.42***

−0.501**

0.011
0.143
−0.041

0.001
−0.391*
−0.092

0.018
0.819
2.268

0
0.029
0.006

0
−0.173
0.004

0
7.955
−1.211

−0.182
−0.157
−0.036
−0.007

−0.186
−0.368**
−0.027
−0.200

−19.93***
−20.23***
−18.51***
−18.15***

No adjustment (A: reference)
WA
J1

0.257***
0.014

Drop treated based on fixed value of propensity score
B2
−0.702*** −0.629*** −6.017***
Drop treated based on density of propensity score
C2
WC2
C3

−0.048
0.207***
0.014

−0.013
−0.675***
−0.112

−0.031
3.663**
0.494

−0.770*** −19.57***

Drop treated based on lack of nontreated neighbors in terms of radius of propensity score
D1
WD1
D2
WD2

−0.594***
−0.005
−5.327***
−0.733*** −0.650*** −6.113***
−0.038
−0.007
−4.112***
−0.527*** −0.708*** −5.721***

−0.124
−0.396*
−0.003
0.127

−0.008
−0.495***
0.030
−0.362*

−22.80***
−23.32***
−22.01***
−21.68***

Drop treated based on upper limits of distribution of propensity score among nontreated
E1
WE1
E2
WE2
E3
WE3

−0.576***
−0.746***
−0.712***
−0.739***
−0.683***
−0.654***

−0.018
−0.670***
−0.581***
−0.701***
−0.704***
−0.689***

−5.554***
−6.117***
−6.069***
−6.109***
−6.042***
−6.026***

−0.336*
−0.466***
−0.447**
−0.495***
−0.445***
−0.442***

−0.038
−0.505***
−0.458**
−0.537***
−0.533***
−0.534***

−23.10*** −0.334**
−0.279
−20.28***
−23.45*** −0.379** −0.552*** −20.75***
−23.61*** −0.507** −0.626*** −21.86***
−23.67*** −0.518*** −0.636*** −21.88***
−23.63*** −0.531*** −0.661*** −21.90***
−23.63*** −0.531*** −0.661*** −21.90***

Procedures that extrapolate into lack of support region
F2
WF2
G2
WG2
H2
WH2
I2
WI2
# of obs.

1.450***
1.861***
1.499***
3.515***
1.017***
1.005***
0.144***
0.446***
792

1.261***
1.540***
1.275***
3.089***
0.895***
0.803***
0.072
0.338***
792

−3.332***
−3.388***
−3.888***
−2.975***
−4.431***
−4.533***
−5.494***
−5.353***
1,584

3.017***
2.997***
2.043***
2.226***
1.351***
1.334***
0.188
0.263
2,376

2.740***
2.682***
1.800***
1.947***
1.141***
1.092***
0.018
0.075
2,376

−19.27***
−19.29***
−21.49***
−21.34***
−20.78***
−20.79***
−23.21***
−23.13***
4,752

2.474***
2.471***
1.167***
1.201***
2.034***
2.034***
0.279
0.304*
2,376

2.169***
2.161***
0.898***
0.927***
1.736***
1.732***
0.015
0.037
2,376

−19.18***
−19.17***
−20.51***
−20.48***
−19.69***
−19.69***
−21.33***
−21.31***
4,752

Note: The results are obtained from OLS regressions. The dependent variable is the normalized RMSE. The covariates contain a full set
of dummies for the different procedures handling support problems. The reference category is to drop no observations (Procedure
A). Further covariates are the tuning parameters of the different DGPs fully interacted (see description in Online Appendix B). Only
selected coefficients for the different procedures are reported in this table. A complete set of results, including standard errors and
R2 s, are found in Online Appendix F.
IPW, inverse probability weighting; OLS, ordinary least-squares; RMSE, root-mean-squared error; VTEC, vouchers for technicians.
***, **, * Significance at the 1, 5, and 10% levels, respectively (based on robust standard errors).

In Online Appendix G, we provide a detailed description of further results.

5. Conclusion
This paper studies the performance of different parametric and semiparametric estimators adjusting
observable characteristics in no- or thin-support situations and the performance of remedies suggested
in the literature. An EMCS is used to obtain performance measures using simulation designs based on
particular real data. Therefore, the many different data generating processes investigated should be close
to what is encountered in empirical applications in the context of program evaluation.

206

M. LECHNER AND A. STRITTMATTER

Our findings suggest that almost all procedures proposed in the literature to mitigate support problems have the potential to improve the performance of the estimators investigated, in particular when
support problems become severe. Although the largest improvements can be achieved for matching
estimators, parametric estimators benefit as well. However, not surprisingly, some procedures are more
effective than others are.
The results obtained for support problems of different severity, different estimators, specifications,
and other features of the data generating process suggest that procedures based on trimming observations in the treated group with propensity scores larger than the maximum value (or the 99% quantile) of
the propensity score in the nontreated group consistently outperform the other procedures considered.
Furthermore, when these procedures are combined with further trimming nontreated observations that
receive a “too large” weight, additional improvements were observed. When support problems are mild,
the gains usually come from an improvement in the precision of the estimators. When support problems
are strong, biases are generally reduced and precision increases. Therefore, we recommend using these
methods in applied work independent of the type of estimator used.
Clearly, due to the empirical design of the Monte Carlo approach used, the results of this study should
be valid for similar program evaluation studies based on large administrative databases. Furthermore,
many features of the data generating processes have also been varied. Thus, we are tempted to claim
that our simulation designs contain many different cases relevant in practice and have external validity
beyond such program evaluation studies. Whether this claim can be confirmed in another EMCS based
on a different applied field remains speculative and deserves further research. For a general argument on
how to address support problems, one has to provide technical comparisons among different estimators
in finite or large samples. So far, only Crump et al. (2009), who aimed to find the most precise estimator,
have provided such an investigation.

Acknowledgments
Michael Lechner is also affiliated with CEPR and PSI, London, CESIfo, Munich, IAB, Nuremberg, and IZA, Bonn. This
project is part of the project “Regional Allocation Intensities, Effectiveness and Reform Effects of Training Vouchers in
Active Labor Market Policies”, IAB project number 1155. This is a joint project of the Institute for Employment Research
(IAB) and the University of Freiburg. We gratefully acknowledge financial and material support by the IAB. We thank
Lorenzo Camponovo, Bernd Fitzenberger, and Andreas Steinmayr for helpful comments on a previous draft of the paper.
The usual disclaimer applies.

References
Abadie, A., Imbens, G. W. (2011). Bias-corrected matching estimators for average treatment effects. Journal of Business and
Economic Statistics 29(1):1–11.
Biewen, M., Fitzenberger, B., Osikominu, A., Paul, M. (2014). The effectiveness of public sponsored training revisited: the
importance of data and methodological choices. Journal of Labor Economics 32(4):837–897.
Busso, M., DiNardo, J., McCrary, J. (2014a). Finite sample properties of semiparametric estimators of average treatment
effects. Journal of Business and Economic Statistics, forthcoming.
Busso, M., DiNardo, J., McCrary, J. (2014b). New evidence on the finite sample properties of propensity score reweighting
and matching estimators. Review of Economics and Statistics 96(5):885–896.
Card, D., Kluve, J., Weber, A. (2010). Active labour market policy evaluations: a meta-analysis. The Economic Journal
120(548):452–477.
Crump, R. K., Hotz, J. V., Imbens, G. W., Mitnik, O. A. (2009). Dealing with limited overlap in estimation of average
treatment effects. Biometrika 96(1):187–199.
Dehejia, R. H., Wahba, S. (1999). Causal effects in nonexperimental studies: reevaluating the evaluation of training
programs. Journal of the American Statistical Association 94(448):1053–1062.
Doerr, A., Fitzenberger, B., Kruppe, T., Paul, M., Strittmatter, A. (2014). Employment and earnings effects of awarding
training vouchers. Industrial and Labor Relations Review, forthcoming.
Grzybowski, M., Clements, E. A., Parsons, L., Welch, R., Tintinalli, A. T., Ross, M. A., Zalenski, R. J. (2003). Mortality benefit
of immediate revascularization of acute ST-segment elevation myocardial infarction in patients with contraindications
to thrombolytic therapy: a propensity analysis. The Journal of the American Medical Association 290(14):1891–1898.

ECONOMETRIC REVIEWS

207

Heckman, J. J., Ichimura, H., Smith, J., Todd, P. (1998). Characterizing selection bias using experimental data. Econometrica
66(5):1017–1098.
Heckman, J. J., Ichimura, H., Todd, P. E. (1997). Matching as an econometric evaluation estimator: evidence from evaluating
a job training programme. Review of Economic Studies 64(4):605–654.
Hirano, K., Imbens, G. W., Ridder, G. (2003). Efficient estimation of average treatment effects using the estimated
propensity score. Econometrica 71(4):1161–1189.
Ho, D., Imai, K., King, G., Stuart, E. (2007). Matching as nonparametric preprocessing for reducing model dependence in
parametric causal inference. Political Analysis 15(3):199–236.
Huber, M., Lechner, M., Wunsch, C. (2013). The performance of estimators based on the propensity score. Journal of
Econometrics 175(1):1–21.
Imbens, G. W. (2004). Nonparametric estimation of average treatment effects under exogeneity: a review. Review of
Economics and Statistics 86(1):4–29.
Khan, S., Tamer, E. (2010). Irregular identification, support conditions and inverse weight estimation. Econometrica
78(6):2021–2042.
Lechner, M. (2008). A note on the common support problem in applied evaluation studies. Annales d’Economie et de
Statistique 91–92:217–234.
Lechner, M., Miquel, R., Wunsch, C. (2011). Long-run effects of public sector sponsored training. Journal of the European
Economic Association 9(4):742–784.
Lechner, M., Wunsch, C. (2013). Sensitivity of matching-based program evaluations to the availability of control variables.
Labour Economics 21:111–121.
Rinne, U., Uhlendorff, A., Zhao, Z. (2013). Vouchers and caseworkers in training programs for the unemployed. Empirical
Economics 45(3):1089–1127.
Rosenbaum, P. R., Rubin, D. B. (1983). The central role of propensity score in observational studies for causal effects.
Biometrika 70(1):41–55.
Rubin, D. B. (1973). Matching to remove bias in observational studies. Biometrics 29(1):159–183.
Smith, J. A., Todd, P. E. (2005). Does matching overcome LaLonde’s critique of nonexperimental methods? Journal of
Econometrics 125(1–2):305–353.
Vincent, J. L., Baron, J.-F., Reinhart, K., Gattinoni, L., Thijs, L., Webb, A., Meier-Hellmann, A., Nollet, G., Peres-Bota, D.
(2002). Anemia and blood transfusion in critically ill patients. The Journal of the American Medical Association
288(12):1499–1507.

