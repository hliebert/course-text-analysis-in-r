NORC at the University of Chicago
Measurement Error and Misclassification: A Comparison of Survey and Administrative
Data
Author(s): Arie Kapteyn and Jelmer Y. Ypma
Source: Journal of Labor Economics , Vol. 25, No. 3 (July 2007), pp. 513-551
Published by: The University of Chicago Press on behalf of the Society of Labor
Economists and the NORC at the University of Chicago
Stable URL: https://www.jstor.org/stable/10.1086/513298
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

The University of Chicago Press , Society of Labor Economists and NORC at the University of
Chicago are collaborating with JSTOR to digitize, preserve and extend access to Journal of Labor
Economics

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and
Misclassification: A Comparison of
Survey and Administrative Data
Arie Kapteyn,
Jelmer Y. Ypma,

RAND

RAND and University of Groningen

We provide both a theoretical and empirical analysis of the relation
between administrative and survey data. By distinguishing between
different sources of deviations between survey and administrative
data we are able to reproduce several stylized facts. We illustrate the
implications of different error sources for estimation in (simple) econometric models and find potentially very substantial biases. This article shows the sensitivity of some findings in the literature for the
assumption that administrative data represent the truth. In particular,
the common finding of substantial mean reversion in survey data
largely goes away once we allow for a richer error structure.
I. Introduction
Microdata are an essential ingredient of research in economics and other
social sciences. Such data, where information is available for each microunit (individual, firm, etc.) separately, are usually obtained through a
survey or from administrative records. Both methods of data collection
have their advantages and disadvantages.
This article is part of an NIA-funded project (Comparison of Survey and
Register Data: The Swedish Case, R03AG21780) in collaboration with Anders
Klevmarken (Uppsala University) and Susann Rohwedder (RAND). We thank
Susann Rohwedder, Anders Klevmarken, Fredrik Johansson, and two anonymous
referees for their helpful comments. Contact the corresponding author, Arie Kapteyn, at kapteyn@rand.org.
[ Journal of Labor Economics, 2007, vol. 25, no. 3]
䉷 2007 by The University of Chicago. All rights reserved.
0734-306X/2007/2503-0004$10.00

513

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

514

Kapteyn/Ypma

One problem in surveys is nonresponse, both to single questions (item
nonresponse) and to the entire questionnaire (unit nonresponse). Another
problem is measurement error. Furthermore, surveys are generally costly.
In administrative files, such as the U.S. Social Security Administration
(SSA), information is typically available for large numbers of individuals.
These data are generally assumed to be reliable but may not measure
exactly the concept a researcher is interested in.
There is an additional problem with administrative data that may have
severe consequences for the models that one would want to estimate based
on these data: administrative databases typically need to link data from
different sources, introducing the possibility of mismatching, due to imperfect linkage information (e.g., errors in social security numbers [SSNs]
that would be used for linking records for a given individual).
In this article we concentrate on sources of measurement error in survey
and administrative data by comparing individual survey information and
administrative information on the same variables. By doing so, we both
replicate a number of earlier studies using new data and propose extensions
of models in the literature that may help us better understand the nature
of measurement error in both survey data and administrative data.
The number of data sets allowing for validation studies of survey information appears to be quite limited. We discuss three of them here.1
A first example of a study comparing survey data and data from administrative sources is the Panel Study of Income Dynamics Validation
Study (PSIDVS). In 1983 and 1987 a questionnaire based on the PSID
questionnaire, but shorter, was administered to employees of a manufacturing company in the Detroit area to measure their earnings in the preceding years. At the same time, payroll records of the employees were
collected from this firm. The data are assumed to be very accurate, since
the firm was highly cooperative (Pischke 1995).
Duncan and Hill (1985) use the PSIDVS from 1983, which includes
questions about annual earnings in the 2 preceding years (1981 and 1982).
They find that means of log earnings in the survey data and the validation
data do not differ significantly. However, at the individual level there may
still be substantial differences. Assuming the administrative data to contain
the “true” values, measurement error can be defined as the difference
between survey data and administrative data. They find a reliability ratio
between .64 and .84, depending on which year they look at and whether
outliers are removed or not. As expected, the reliability ratio is lower for
the question with a longer recall period, that is, earnings in 1981 versus
earnings in 1982. Pischke (1995) finds, when using data from 1982 and
1986, that administrative data and survey data do not differ much in either
1

Bound, Brown, and Mathiowetz (2001) provide a more extensive overview of
validation studies dealing with earnings measures.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

515

mean or variance. However, measurement error is found to be weakly
negatively correlated with “true” log earnings. In cross-section data of
1982 this correlation is stronger than in cross-section data of 1986. When
restricting data to respondents who are present in both years, no significant correlation is found between true log earnings and measurement
error. The negative correlation is not significant when leaving out hourly
workers, that is, when looking only at salaried employees. Rodgers,
Brown, and Duncan (1993) and Bound et al. (1994) also report a negative
correlation between measurement error and the true value. In contrast to
Pischke (1995), they do not distinguish between hourly workers and salaried employees.
Another data set suitable for comparison of survey and administrative
data is a match constructed between the Current Population Survey (CPS)
and data from the SSA for the years 1976 and 1977 (see, e.g., Bound and
Krueger 1991). Once again, the maintained hypothesis for most of their
paper is that the administrative data are error free. Using cross-section
data, the reliability ratio for log earnings for men is .844 in 1976 and .819
in 1977. For women this ratio is higher, .939 and .924. For men they find
large negative correlations between measurement error and true log earnings, ⫺.46 in 1976 and ⫺.42 in 1977. This correlation is small for women.
Bollinger (1998) finds that the negative relationship between measurement
error and earnings is mainly driven by overreporting among low earners.
When comparing their results obtained with the PSIDVS with the CPSSSA data, Bound et al. (1994) find that, qualitatively, the results are similar.
However, they notice a large difference in the standard deviation of the
measurement error (.13 in the PSIDVS data vs. .32 in the CPS-SSA data).
The difference seems to lie in the tails of the measurement error distribution, with very large outliers in the CPS-SSA data. Bound et al. (1994)
suggest that these very large measurement errors are not necessarily due
to misreporting in the survey but rather to errors in the SSA data.
A number of studies have addressed the possibility of measurement
error in the earnings data collected in the Survey of Income and Program
Participation (SIPP). We briefly discuss two studies relevant to our analysis. Pedace and Bates (2001) use a match between the 1992 SIPP longitudinal file and the Social Security Summary Earnings Records. These
authors also assume the administrative data to represent the truth. It
appears that respondents with low SSA earnings tend to overreport their
earnings, whereas respondents with high earnings underreport. In contrast
to the studies mentioned so far, Stinson (2002) does not make the assumption that the administrative data represent the truth. She instead
estimates an earnings function allowing for (mutually uncorrelated) measurement error in both the survey and administrative data. She finds that
both measures have similar magnitudes of measurement error, with the

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

516

Kapteyn/Ypma

error in the administrative data being slightly larger than in the survey
data.
The studies cited here reach somewhat contrasting conclusions regarding whether there is negative correlation between the true value and measurement error or not. While this correlation seems evident in the CPSSSA data and the SIPP data, in the PSIDVS data no such correlation is
found for the salaried workers, but it is found when including hourly
workers. This “mean reversion” in the measurement error has gradually
attained the status of a stylized fact. Kim and Solon (2005) discuss its
implications for the modeling of earnings dynamics.
In the remainder of the article we will provide both a theoretical and
empirical analysis of the relation between administrative and survey data.
We distinguish a number of different sources of measurement error. Measurement error in the administrative data will be due only to mismatching;
that is, with a certain probability a value recorded in an administrative
file refers to a different observation. Measurement error in survey data
can be (1) absent, (2) classical but potentially mean reverting, or (3) the
result of contamination. By distinguishing between different sources of
deviations between survey and administrative data we will be able to
reproduce several stylized facts in the literature. In doing so, we deviate
from the almost universal assumption that the administrative data represent the truth.2 We will illustrate the implications of these error sources
for estimation in (simple) econometric models. The analysis is applied to
Swedish data that have been collected for a validation study as part of a
larger European health and retirement study (SHARE: Survey of Health,
Ageing, and Retirement in Europe). Thus this article makes two contributions: (1) it adds to the limited number of empirical validation studies
of earnings measurement in surveys, and (2) it shows the sensitivity of
some findings in the literature for the assumption that administrative data
represent the truth.
In Section II we describe the data. In Section III a relatively straightforward model of different error sources is proposed and their empirical
implications are explored, both for the observed relation between survey
and administrative data and for some econometric models incorporating
survey and/or administrative data. Among other things we address the
question when it is preferable to use administrative data and when survey
data are to be preferred. Section IV estimates the model of Section III
using our Swedish data set. We are able to identify various sources of
error in the data and actually flag observations that suffer from different
types of error. Section V concludes.
2
As in most of the papers discussed above. The same assumption is made in
more formal analyses of the use of validations samples, including Lee and Sepanski
(1995) and Chen, Hong, and Tamer (2005).

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

517

II. Data and Project Description
The Scandinavian countries have 30 years of experience with using
administrative data for statistical purposes. The statistical offices in Denmark, Norway, Sweden, and Finland have made important progress in
making information from various administrative files compatible and to
ensure the link among various sources. The wealth of information contained in these administrative files is considerable. In our empirical work
we will use Swedish data.
Every Swede has a unique SSN, which is also available in every administrative record. In principle this allows interviewers to ask respondents for their SSN and permission to link them to the information available in the administrative files. If the respondent agrees this may
substantially shorten interviews, because questions, for instance about
income, can be skipped. Interviews can then focus on information not
available in administrative files, while combining the interview information with the (presumably) more reliable administrative information.
The experiment generating our data is motivated exactly by this consideration. As part of SHARE, a pan-European data collection effort
among individuals 50 and over, an experiment was devised in Sweden to
assess the usefulness of combining survey and administrative data. The
purpose of the experiment was to inform SHARE about the possibilities
of combining such data and potentially implement it in other countries
than Sweden. Aspects to be investigated include (1) selectivity in survey
responses in a number of important domains; (2) reliability of selected
survey measures including income and pension entitlements by comparison with administrative data; (3) estimating biases in a number of important
empirical relationships (e.g., health and socioeconomic status) when using
survey data rather than administrative data; (4) generalizing from these
findings to the limitations of international comparisons if administrative
data are available in some countries, but not in others. In this article we
mainly concentrate on aspect 2 and pay some attention to aspect 3.
Administrative Data
In our empirical analysis we will use a sample of individuals over age
50 from LINDA (Longitudinal Individual Data for Sweden). LINDA is
a registry-based longitudinal database that is representative of the Swedish
population since 1960. LINDA has two subsamples. The first subsample
is the population sample, representative of the entire population, with a
coverage rate of 3.35%. The second subsample is the immigrant sample,
covering 19.5% of the immigrant population. The samples are kept both
cross-sectionally and longitudinally representative of their respective populations. There are two principal data sources: (1) the Income Registries,
available annually since 1968 and (2) the Population Censuses, available

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

518

Kapteyn/Ypma

Fig. 1.—Some of the registries used in LINDA, linked via SSNs

every fifth year from 1960 to 1990 (no census has been taken after 1990).
Other administrative files have been added during the nineties (see Edin
and Frederiksson [2000] for more details).
By drawing from LINDA we have a wealth of information available
about our respondents from the administrative data.3 The information in
the different administrative files is linked by the SSN of individuals (see
fig. 1). Since the information comes from several administrative files an
incorrect SSN in an administrative record may lead to a wrong link.
As Abowd and Vilhuber (2005) noticed while looking at unemployment
spells, errors in linking can be a real problem. Biases arise that are the
result of errors in period-to-period linking of records. When using a
different probabilistic matching algorithm, Abowd and Vilhuber achieve
smaller error rates than the overall error rate of 7.8%, the Bureau of
Labor Statistics found in an SSN validation project. Errors in databaselinking can be caused by similar errors in period-to-period linking. These
would be most likely the result of recording a wrong or mistyped SSN.
We will be using mostly demographic variables (e.g., education, age,
and gender) and financial variables (earnings, pensions, and taxes). Since
the survey contained mostly questions about 2002, we will be using data
from that year.
The LINDA data are generally thought to be a reasonably accurate
measure of earnings of the population they cover. At the same time, as
with the American data discussed above, the administrative files are based
on the linking of data from different sources, and, hence, one would
suspect that a certain number of errors will occur. How serious this problem is will be a focus of our empirical analysis. We believe that mismatching is likely to be the most important source of error. Conditional
3
Among others, LINDA includes annual cash earnings, annual taxable benefits,
social security sickness compensation (only if not old-age pension), if single family
home (owner occupied), if condominium, if secondary house, tax assessed value
on house, market value of house, stocks and shares, bank holdings, bonds, mutual
funds, mortgages, other loans, schooling by number of years and category, pensions (social security, old age and disability pension, group [occupational] pensions, private pension insurance [annuity]), capital incomes (interest and dividends
received, realized capital gains, interest paid), and total tax (income tax on earnings,
capital income tax, real estate tax, wealth tax).

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

519

Table 1
Evolution of the Sample

Total number of persons in sample
Number of respondents
Number of respondents with positive
administrative values
Number of respondents with positive
survey values
Both values positive

Earnings

Pensions

Taxes

1,431
881

1,431
881

1,431
881

511

492

845

414
400

376
369

495
487

on correctly identifying an observation, errors in financial variables are
less likely. For instance, a variable representing pension benefits will be
verified by both the beneficiary and the payee, since both have an interest
in avoiding errors. The same is true of other financial variables like earnings. There is no such mechanism that would verify the correct linking
of records in the construction of administrative analysis files.
Survey Data
In the beginning of every year, just before tax returns need to be filed,
people in Sweden receive preprinted tax statements from the tax authorities. Around this time in 2003 a survey was conducted of 1,431 individuals
age 50 or over. Out of the 1,431 individuals who were contacted, 881
responded—469 of them women and 412 men. The timing of the survey
was chosen so as to optimize the information available to respondents
when answering the questions in the survey. The questionnaire contains
several questions about household income and expenses, partner income,
and assets. Besides the financial questions there are some smaller sections
about household composition, health, retirement, and education of the
respondent.
Descriptive Comparisons of Administrative and Survey Data
Our analysis will concentrate on three monetary variables: earnings,
pensions, and taxes. Table 1 shows the evolution of the sample if we move
from the gross sample of 1,431 respondents drawn from the administrative
files to the sample of respondents who answered at least some questions
over the phone. The survey has 881 respondents, a response rate of 61.6%.
In view of the age distribution of the sample, it is not surprising that
many respondents report zero earnings. The answer to the survey question
about taxes could be given either as an amount or as a percentage of
income. We do not consider the percentage answers, as the calculated
amount of taxes paid would most likely exhibit an error structure different
from the other responses. Roughly speaking, the implied error is a result
of taking the ratio of two variables (cf. Duncan and Hill 1985). Thus the

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

520

Kapteyn/Ypma

Table 2
Comparison of Population and Sample Characteristics

Administrative
Variable

Original
Sample*
(1)
Mean

Female (%)
53.0
Age
63.6
Education (%):
Low
28.1
Middle
35.8
High
17.5
Missing
18.6
Earnings‡
114
Earnings 1 0
214
Pensions‡
74
Pensions 1 0
128
Taxes‡
59
Taxes 1 0
64
N
1,431

Respondents
Sample†
(2)

SD
9.6

153
149
129
147
85
87

Mean
53.2
63.5
26.1
37.8
19.1
17.0
122
211
78
140
64
67
881

SD
9.5

153
147
154
184
100
101

Earnings
Sample
(3)
Mean
52.5
57.1

SD
5.3

20.0
48.3
31.3
.5
...
246
138
...
...
...
...
400

Pension
Sample
(4)

Taxes
Sample
(5)

Mean

SD

Mean

53.7
70.8

7.2

54.4
64.3

28.2
27.4
11.9
32.5
...
...
...
141
74
...
...
369

SD
9.4

24.8
39.4
18.1
17.7
...
...
...
...
...
67
121
487

Note.—Earnings, pension, and taxes are given in 1,000 SEK per year.
* In the original sample the number of observations with a positive amount is 765 for earnings, 828
for pensions, and 1,328 for taxes.
† In the respondents sample the number of observations with a positive amount is 511 for earnings,
492 for pensions, and 845 for taxes.
‡ 1,430 observations are used, since administrative values are missing for one individual.

number of respondents in the survey with positive survey taxes is much
lower than in the administrative data.
Table 2 compares a number of administrative variables across different
subsamples. Comparing the sample of respondents (col. 2) to the original
(gross) sample (col. 1) shows that the age and gender composition is
essentially the same. The respondent sample is slightly better educated.
Perhaps related to that, the respondent sample exhibits somewhat higher
(administrative) earnings (7%). If we only consider observations with
positive earnings the difference disappears: respondents earn 1.5% less
on average than the overall mean of the gross sample. Pensions among
the respondents are 5% higher on average in the respondent sample than
in the gross sample, and 9% higher if we only consider positive pensions.
For taxes the difference is 8.5% and 6% if we consider only respondents
with positive (administrative) tax payments.
Our empirical analysis will be primarily concerned with a comparison
of nonzero observations in both the administrative and survey data. Columns 3–5 present administrative values for the subsamples that have positive values for both the administrative and survey variables. Now age
and education vary considerably across subsamples for obvious reasons.
Respondents with earnings are typically younger and respondents with
pensions are typically older. Education levels are also different, reflecting

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

521

Fig. 2.—Histogram of administrative earnings (in 1,000 SEK/year) for respondents reporting no earnings.

cohort differences in educational achievement. Comparing column 2 with
columns 4 and 5 shows essentially no difference in means for pensions
and taxes, respectively. A comparison of columns 2 and 3 shows that mean
earnings are substantially higher in the latter column than in the former.
It is worthwhile therefore to investigate the differences between administrative data and survey data in some more detail.
The survey contained a number of questions on income and incomerelated variables. A number of measures were taken to improve survey
quality and to improve immediate comparison to the administrative variables. According to Hurd et al. (2004), one way to increase the quality
of report is by giving respondents the opportunity to report income in
a time span consistent with how they receive their income. For example,
instead of forcing respondents to provide a yearly amount for earnings
and pensions, they were given the possibility to report these amounts
either per month or per year.
The question “Did you have any income from employment in 2002?”
was answered affirmatively by 435 respondents. When comparing these
answers with the administrative files, some discrepancies are found (see
table 3). Seventeen respondents claimed to have earnings, when according
to the administrative files they have zero earnings. Ninety-three respondents reported to have no earnings, when they should have earnings according to the administrative files. As can be seen from figure 2, two
groups can be distinguished. One large group has low earnings (e.g., 34

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Table 3
Correspondence between Administrative and Survey “Answers” on
Relevant Questions
Yes
Did you have any income from employment in 2002?
Adm. 1 0
Adm. p 0
Did you receive any type of old-age
pension in 2002, such as . . . ?
Adm. 1 0
Adm. p 0

No

RF

418 81.8% 93 18.2%
17 4.6% 352 95.1%

0 0%
0 0%

0
1

0%
.3%

430 87.4% 62 12.6%
7 1.8% 381 97.9%

0 0%
1 .3%

0
0

0%
0%

10

How much did you earn per month in
2002, before taxes?
Adm. 1 0
Adm. p 0
Altogether, about how much did you
earn from your main job in 2002,
before taxes?
Adm. 1 0
Adm. p 0
How much did you receive in pension
payments per month in 2002, before taxes?
Adm. 1 0
Adm. p 0
Altogether, about how much did you
receive in old-age pension payments (before taxes) in 2002?
Adm. 1 0
Adm. p 0
Think about the total income you received in 2002 from employment,
pensions and taxable benefits.
About how much did you pay
(will you pay) in income tax on
that amount?
Amount
Adm. 1 0
Adm. p 0
Percentage
Adm. 1 0
Adm. p 0

DK

p0

DK

RF

327
7

1
1

6
1

5
0

73
7

0
0

6
1

0
0

353
6

2
0

43
0

6
0

16
1

1
0

8
0

0
0

487
8

1
8

12
0

0
0

230
3

0
0

10
0

0
0

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

523

respondents earn less than 10,000 SEK per year), which are easy to forget
or perhaps thought not to be worth mentioning.4 Since this group is
included in the mean earnings in column 2 of table 2, but not in column
3, the mean in column 3 is substantially higher than in column 2. For the
other group, respondents with substantial amounts of earnings, the explanation of rounding to zero is less plausible. Errors can be made by
both the respondent and the interviewer (e.g., an interviewer may simply
type in the wrong code). A different explanation could be mismatching,
where a nonearning respondent is incorrectly matched with an individual
in the administrative files who has positive earnings.
It is interesting to compare these findings to those of Pedace and Bates
(2001) in their analysis of the SIPP. They find that, of those who had
earnings according to the administrative data, 5.5% of those surveyed said
that they did not have any earnings in the survey. In our survey that
percentage is 18.2. However, Pedace and Bates (2001) find that, of those
who had no earnings according to the administrative files, 18% reported
earnings in the SIPP. In our data that percentage is 4.6. Thus, in percentage
terms, the discrepancy between administrative data and survey data appears similar across the two data sets, but in the SIPP zero administrative
earnings are reported to be positive in the survey data at about the same
rate as positive administrative earnings in Sweden are reported to be zero
in the survey. Not too much should be read into this, if only because of
the different age compositions of the Swedish and U.S. samples.
For the pension data we find a similar pattern of false responses. The
percentage of respondents with positive administrative pensions but stating they do not have any pensions is 12.6. A smaller percentage of respondents (1.8%) report having a pension, while this pension is not found
in the administrative data. Four hundred ten respondents gave an answer
to the monthly pension question, including 2 zeros, 6 refusals, and 43
don’t knows. Only 26 respondents chose to give a yearly amount. For
369 respondents we have both a positive administrative value and a positive survey value.
From now on we concentrate on positive values of the monetary variables. We will not pay attention to sources of selectivity, such as refusals,
zero responses, and don’t knows. See Johansson and Klevmarken (2006)
for a detailed analysis of various sources of nonresponse in the data. We
will generally use logarithms of the monetary variables we are considering
to achieve distributions that are approximately symmetric.
In table 4 some statistics for the monetary variables of interest are given.
The difference between log earnings measured in the survey and the administrative data is on the order of .02 on average. Strikingly, the variance
4

SEK represents the Swedish kronor. In 2002, 10 SEK equal approximately
one U.S. dollar.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

524

Kapteyn/Ypma

Table 4
Summary of Administrative and Survey Variables
N

Survey

Administrative

s⫺r

Reliability*

corr(m, r)

Log earnings

400

.3595

⫺.2699

Log taxes

487

.0243
(.656)
⫺.0451
(.878)
.0828
(.577)

⫺.5395

369

12.172
(.961)
11.694
(.658)
10.786
(.829)

.6821

Log pension

12.196
(.821)
11.649
(.945)
10.869
(.917)

.6734

⫺.1875

Note.—SD is given in parentheses.
* j2r /(jr2 ⫹ jm2 ), where r is the administrative variable and m is the difference between survey and
administrative variable.

of the survey data is smaller than the variance of the administrative data.
Under the assumption of classical measurement error for the survey data
and no error in the administrative data, this would not be possible. Looking at log-pensions, we again observe modest, though somewhat larger,
differences between the log-means of the administrative values and the
survey values. Just as in the earnings data, we see a substantial negative
correlation between the difference between survey and administrative
data, s ⫺ r, and the administrative data, r. Finally, mean log-taxes are about
.08 higher in the survey data than in the administrative data. The correlation between s ⫺ r and r is still negative but closer to zero than for
earnings and pensions.
Ten people (2.5%) gave an earnings amount exactly equal to the administrative value, while an additional 49 (12.3%) respondents provided
amounts within 1,000 SEK of the administrative value. For the pension
and taxes data we find, respectively, 40 (13.3%) and 25 (5.1%) answers
exactly equal to the administrative value, with an additional 59 (16.0%)
and 72 (14.8%) answers within the 1,000 SEK bound.
Figure 3 presents histograms of the difference between survey data and
administrative data for earnings, pensions, and taxes. Most of the values
are close to zero, but we also see a large positive difference for earnings
and large negative differences for pensions and taxes. The large positive
and negative values force the scales in figure 3 to be rather coarse. Hence,
in figure 4 the same histograms are given but now truncated at a value
of Ⳳ.6. Although the mean difference between survey and administrative
earnings is positive (table 4), we see from the truncated histogram that
for most observations administrative earnings are larger than survey earnings. If the administrative data are assumed correct, this would indicate
that most people underestimate their earnings. The difference in pensions
data seems to center around zero, whereas the difference in taxes data is
mostly positive.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Fig. 3.—Histograms of mi p si ⫺ ri for earnings, pensions, and taxes

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Fig. 4.—Histograms of mi p si ⫺ ri for earnings, pensions, and taxes, truncated at Ⳳ.6

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

527

III. Modeling Different Errors
Let yi be the logarithm of the true value of the variable or interest (e.g.,
log-income) for individual i. This true value is not measured directly, but
instead two sources of data, capturing the same concept, are available. In
contrast to the assumptions typically made in the literature, we will assume
that both sources of information, administrative and survey data, may
contain error. The structure of the error, however, is different per source.
Define four independently and identically distributed and mutually independent normal variables: yi ∼ N(my , jy2 ), zi ∼ N(mz , jz2 ), hi ∼ N(m h , jh2 ),
and qi ∼ N(mq , jq2 ), where i indexes the unit of observation. Denote the
value elicited in the survey by si and the corresponding administrative
value by ri. For the derivations in this section the normality assumptions
we are making are not necessary, but will be exploited later in maximum
likelihood estimation.
Errors in the administrative data are assumed to be due only to mismatching. With probability pr the observed administrative value, ri , is equal
to the true value of individual i, yi. In the case of a mismatch, which
occurs with probability 1 ⫺ pr , the administrative value ri corresponds to
the true value of someone else.5 This mismatched value will be denoted
by zi, where no correlation exists between yi and zi . Note that our sample
comes from a subset of the population, containing only individuals of age
50 and older, whereas a mismatch may come from the complete sample
available in LINDA. The distributions of y and z can therefore be different. The observed values ri are a mixture of correct matches and mismatches:
y with probability pr

ri p  i
.
zi with probability (1 ⫺ p r)








(1)

For the survey data we distinguish three cases. The observed survey value
is correct with probability ps. With probability 1 ⫺ ps the survey data
contain response error, part of which is mean-reverting. Some of these
observations, a proportion pq , are contaminated, modeled by adding an
extra error term, qi:
yi

with probability ps


si p yi ⫹ r(yi ⫺ my ) ⫹ hi
with probability (1 ⫺ p s )(1 ⫺ pq ) .


yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi with probability (1 ⫺ ps )pq


(2)

5
Although it is attractive to think of mismatch as administrative data being
linked to the wrong individual, other cases may be covered as well. For instance
in some cases administrative data may be formally correct but measure something
that is conceptually different. An example would be an individual who writes off
a heavy capital loss in a given year. This may lead to low or even negative taxable
income, while for most modeling purposes income would probably be defined
differently.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

528

Kapteyn/Ypma

Contamination can, for instance, be the result of erroneously reporting
income as annual, whereas the amount is a monthly amount, or vice versa,
omitting a second job or working only part of the year. Each of these
cases may result in large differences between survey value and true value.
A value of r smaller than zero implies mean-reverting response error in
the sense of Bound and Krueger (1991).
Next define the difference between survey data and administrative data,
mi, as
mi { si ⫺ ri .

(3)

Note that the difference between survey data and administrative data
no longer equals the response error, since in this model the administrative
data may contain error. It is useful to calculate a number of moments of
ri, si, and mi to gain insight in the behavior of the model and its differences
with a model without administrative error. We have (for derivations, see
app. A):
m r { E(ri ) p pr my ⫹ (1 ⫺ pr)mz,

(4)

ms { E(si ) p my ⫹ (1 ⫺ ps )[m h ⫹ pq mq ],

(5)

m m { E(si ) ⫺ E(ri ) p (1 ⫺ pr)[my ⫺ mz] ⫹ (1 ⫺ ps )[m h ⫹ pq mq ],

(6)

jr2 { Var (ri ) p prjy2 ⫹ (1 ⫺ pr)jz2 ⫹ pr(1 ⫺ pr)[my ⫺ mz] 2,

(7)

js2 { Var (si )
p psjy2 ⫹ (1 ⫺ ps )((1 ⫹ r) 2jy2 ⫹ jh2 ⫹ pqjq2 ⫹ ps [m h ⫹ pq mq ] 2

(8)

⫹ pq(1 ⫺ pq )m2q ),
jm2 { Var (mi )
p [(1 ⫺ pr)ps ⫹ pr(1 ⫺ ps )r 2 ⫹ (1 ⫺ pr)(1 ⫺ ps )(1 ⫹ r) 2 ]jy2
⫹ (1 ⫺ pr)jz2 ⫹ (1 ⫺ ps )[jh2 ⫹ pqjq2 ] ⫹ pr(1 ⫺ pr)[my ⫺ mz] 2

(9)

⫹ ps (1 ⫺ ps )[m h ⫹ pq mq ] 2 ⫹ (1 ⫺ ps )pq(1 ⫺ pq )m2q ,
jmr { E [(mi ⫺ m m)(ri)]
2

prpr(1 ⫺ ps )jy2 ⫺ (1 ⫺ pr)jz2 ⫺ pr(1 ⫺ pr)[my ⫺ mz] .

(10)

The last expression can be seen as a measure of mean reversion we expect
to see in the data under the (possibly incorrect) assumption that the
administrative data are measured without error. We note that jmr is, for
negative r, unambiguously negative, implying indeed mean reversion. Observe, however, that jmr is still negative if r p 0. That is, even without

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

529

“true” mean reversion the data will still suggest that mean reversion is
present as long as pr ( 1, that is, if the administrative data suffer from
at least some mismatch. This is not unique to the current set-up and is
essentially an example of regression toward the mean. As soon as ri suffers
from measurement error, we expect si ⫺ ri to be negatively correlated with
ri. As a second observation we consider
js2 ⫺ jr2 p jy2 [ps ⫺ pr ⫹ (1 ⫺ ps )(1 ⫹ r) 2 ] ⫹ (1 ⫺ ps )[jh2 ⫹ pqjq2 ]
⫺ (1 ⫺ pr)jz2 ⫺ pr(1 ⫺ pr)[my ⫺ mz] 2.

(11)

For pr p 1, that is, no mismatch in the administrative data, (11) reduces
to
js2 ⫺ jr2 p (1 ⫺ ps ){[(1 ⫹ r) 2 ⫺ 1]jy2 ⫹ jh2 ⫹ pqjq2 },

(12)

which shows that if the administrative data are assumed to be measured
perfectly, the variance of the survey data can only be smaller than the
variance of the administrative data if the survey data exhibit mean reversion (r ! 0). As a matter of fact, (12) will be negative if
(1 ⫹ r) 2 ! 1 ⫺

jh2 ⫹ pqjq2
.
jy2

(13)

Thus, the bigger the measurement errors in the survey data are assumed
to be, the more mean reversion one needs to rationalize the data.
Under the scenario that neither the survey data nor the administrative
data are flawless the question arises, which of the two should one use in
modeling, and under what circumstances. An alternative, related, question
would be: given that survey data are usually more easily available than
administrative data, how much do we lose by using survey data rather
than administrative data? Below we illustrate the answers to these questions for a very simple linear model. One could also ask, what is the best
way of combining survey and administrative data if both are available,
but that question is beyond the scope of this article.6
Implications if yi Is a Dependent Variable
We consider a very simple linear regression model of the form:
yi p b0 ⫹ b1 xi ⫹ ␧i ,

(14)

where we make the conventional assumption that ␧i is uncorrelated with
xi (and with any of the other random variables we have defined so far).
If we have only survey data available, we would replace yi by si on the
6

Our ML estimation using both administrative and survey data is one answer
to that question.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

530

Kapteyn/Ypma

left-hand side of (14). Denote the ensuing estimate of b1 by bˆ 1. Then we
have
p lim bˆ 1 p b1 [1 ⫹ r(1 ⫺ ps )] .

(15)

Thus the estimator is consistent if r p 0, that is, if there is no mean
reverting error. The biasing effect of the mean reversion is mitigated by
the observations that are exactly correct.
If we replace yi by ri we obtain for the probability limit of the estimator
(say b̃1):
p lim b˜ 1 p pr b1 ,

(16)

so that the percent bias is equal to the percentage of mismatched administrative observations. Comparing (15) to (16) shows that, for r ! 0, using
survey data will lead to less bias if
1 ⫹ r(1 ⫺ ps ) 1 pr .

(17)

Clearly, this always holds if r p 0 and the administrative data are not
perfect.
Implications if yi Is an Independent Variable
Now consider a model of the form:
zi p g0 ⫹ g1 yi ⫹ ni .

(18)

Let ĝ1 be the ordinary least squares (OLS) estimator of g1 if we replace
yi by si. It is straightforward to show that
p lim gˆ 1 p g1

[1 ⫹ r(1 ⫺ ps )]jy2
p j ⫹ (1 ⫺ ps )((1 ⫹ r) j ⫹ jh2 ⫹ pqjq2 ⫹ ps [m h ⫹ pq mq ] 2 ⫹ pq(1 ⫺ pq )mq2 )
2
s y

2

2
y

,

(19)
where the denominator is equal to (8). Clearly if r p 0, ps p 0, and
pq p 0, we are back in the case of classical measurement error. In that
case (19) reduces to
p lim gˆ 1 p g1[jy2 /(jy2 ⫹ jh2 )].

For r p 0 and ps, pq ( 0 (19) reduces to
p lim gˆ 1 p g1

jy2
j ⫹ (1 ⫺ ps )(j ⫹ p j ⫹ ps [m h ⫹ pq mq ] 2 ⫹ pq(1 ⫺ pq )mq2 )
2
y

2
h

2
q q

.

(20)

As one would expect, having a proportion ps of exactly measured variables
mitigates the attenuation due to measurement error in the explanatory
variable, while on the other hand a proportion pq of contaminated samples

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

531

worsens the effect. Having measurement errors or contaminated samples
with mean unequal to zero also increases the bias.
Let g̃1 be the OLS estimator of g1 if we replace yi by ri . Now we obtain:

p lim g˜ 1 p g1

prjy2
,
p j ⫹ (1 ⫺ pr)j ⫹ pr(1 ⫺ pr)(my ⫺ mz) 2
2
r y

2
z

(21)

where the denominator is equal to (7). Clearly g̃1 is consistent for pr p
1, as it should be. A special case of interest is where a mismatch is a
drawing from the same distribution, that is, my p mz , jy2 p jz2 . In that case
(21) reduces to p lim g˜ 1 p g1pr. This is exactly the same shrinkage as in
(16).
Comparison of biases introduced by either using less than perfect survey data or partly mismatched administrative data shows that survey data
are to be preferred if
[1 ⫹ r(1 ⫺ ps )] jy2
psjy2 ⫹ (1 ⫺ ps )((1 ⫹ r) 2jy2 ⫹ jh2 ⫹ pqjq2 ⫹ ps [m h ⫹ pq mq ] 2 ⫹ pq(1 ⫺ pq )mq2 )
1

prjy2
,
p j ⫹ (1 ⫺ pr)j ⫹ pr(1 ⫺ pr)(my ⫺ mz) 2
2
r y

2
z

(22)

which is not particularly informative. More insight can be gained for the
case where r p 0 (which is close to the empirically relevant case as we
shall see for our data), mq p m h p 0 and my p mz, jy2 p jz2. In that case
(22) reduces to
jy2
1 pr .
j ⫹ (1 ⫺ ps )[jh2 ⫹ pqjq2 ]
2
y

(23)

Thus, survey data exhibit less bias if the reliability ratio of the survey
data is greater than the proportion of perfect administrative data. In the
more general case where my ( mz and j␵2 ≥ jy2, the balance tips a little
more in favor of the survey data.
IV. Estimation and Results
We extend the model, discussed in the last section, by including covariates. We parameterize my as a function of individual characteristics.
The “true” variable, yi, is assumed to be dependent on variables such as
gender, age, and education. In this case we have
yi p xi b ⫹ ␧i ,

(24)

where ␧i is Gaussian noise. Note that, when covariates are included, meanreversion gets a slightly different interpretation. Values do not get adjusted
toward the overall mean, but toward the mean within a group of people

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

532

Kapteyn/Ypma

with the same values of xi. Both the model with covariates, where yi ∼
N(xi b, jy2 ), and the model without covariates, where yi ∼ N(my , jy2 ), are
estimated. The covariates used are age, age2, and dummies for gender,
degree of education, and self-assessed retirement status.7 These are all
survey values in order to avoid the mismatching problems accompanying
administrative values. One drawback of this method is possible error in
survey data and a lot of don’t know values for education (coded as dkedu).
For estimation we write the model as a mixture of one univariate normal
distribution, when ri p yi and si p yi, and five bivariate normal distributions with different means and covariance matrices. Maximum likelihood is used to obtain estimates. For a detailed description of the estimation procedure we refer to appendix B. It is perhaps somewhat
remarkable that such a rich error structure can be identified. This is the
direct result of the nonnormality of the error structure. It has been known
for quite a while that normality is a very unfavorable assumption for
identifiability of parameters in linear errors in variables models (see, e.g.,
Aigner et al. 1984; and Bekker 1986). Kane, Rouse, and Staiger (1999)
provide an example of how exploiting nonnormality aids identifiability.
Meijer and Ypma (2006) provide a simple proof of identification for the
case of a mixture of two normal distributions, of which the current model
is a generalization. A different strand of literature examines how bounds
on measurement error can be exploited to bound parameter estimates (see,
e.g., Klepper and Leamer 1984; and Bekker, Kapteyn, and Wansbeek
1987). In the current context such bounds do not seem necessary, although
conceivably this would further narrow the range of plausible parameter
estimates.
Appendix C presents all estimation results. For each of the variables
of interest, earnings, pensions, and taxes, two tables are presented—one
with covariates included and one without. Besides the full model, three
other models are estimated, with certain constraints imposed on the full
model. These include a model without contamination of the survey data,
pq p 0, a model where no mismatching occurs, pr p 1 , and a model where
both are left out. This last model can be seen as the model used in most
previous studies, with only the addition that survey observations are equal
to the truth with positive probability.8
7
The LINDA variable used to define age is bald, which is the age of the
individual at the end of the tax year. We define age p bald ⫺ 40 and age2 p
bald ⫺ 402/100.
8
Since it is sometimes found that women provide more accurate answers than
men (see, e.g., Bound and Krueger 1991), we have also estimated a model where
m␧ and j␧ are allowed to differ by gender, but the differences are negligible. For
instance, for earnings the estimate of j␧ is .100 for men and .104 for women; the
t-value of the difference is .33. The t-value for the difference in m␧ is even lower:
.10.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

533

Table 5
Proportional Biases Resulting from Using Administrative or Survey Data
Earnings

yi LHS
yi RHS

Pensions

Taxes

Administrative

Survey

Administrative

Survey

Administrative

Survey

.959
.491

.989
.701

.981
.719

.904
.363

.935
.789

.991
.735

Note.—Cells present proportional asymptotic biases in OLS estimates if we replace the true variable
by administrative or survey data; 1 means no bias.

Table C2 presents the estimation results for earnings when no covariates
are included. The most striking observation is probably that allowing for
mismatches or contaminated samples in the model leads to a dramatic fall
in the estimated value of the mean-reversion parameter, r. Only when we
do not allow for either contamination or mismatches, do we reproduce
the “stylized fact” of substantial mean reversion. Table C1, which includes
covariates, leads to qualitatively similar conclusions. The fact that allowing
for mismatch may lead to a sharp drop in the estimate of r is consistent
with equation (10), which shows that a negative covariance between the
“measurement error” and the administrative values can be generated by
mismatches even if r p 0. The fact that contamination of the survey data
can also rationalize a negative covariance between m and r is a little harder
to grasp intuitively.
With respect to the pattern of estimated mean reversion, tables C4 and
C3 (for pensions) provide a qualitatively similar picture, although mean
reversion in the full model is somewhat higher than for earnings. For
taxes, mean reversion in the full model and in the models with only
mismatches or only contaminated samples is essentially zero (tables C6
and C5).
The estimated percentage of correct survey data, ps , ranges from 15%
in the earnings data to a little over 25% in the pension data. The fraction
of contaminated survey values, pq(1 ⫺ ps ), lies between .04 and .13.
A parameter of particular interest is pr , or rather 1 ⫺ pr , the proportion
of mismatched administrative values. The estimate of 1 ⫺ pr varies from
2% in the pension data to about 8% in the tax data. We can use equations
(15), (16), (19), and (21) to assess the biases that would arise in the estimate
of a slope parameter if yi were either a dependent (left-hand side) or an
independent (right-hand side) variable in a univariate regression. Table 5
presents the proportional biases for both cases and for the three variables
we are considering in this article.9 When yi is a dependent (left-hand side)
variable, biases are modest, with the administrative data leading to slightly
smaller biases than the survey data for pensions, whereas for earnings and
taxes survey data yield less bias. Biases are on the order of 5%. When
9

We use the estimates for the models without covariates.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

534

Kapteyn/Ypma

yi is a right-hand side variable, the picture is dramatically different. Biases
are much larger, up to 65%. When using administrative data, we find that
the bias is largest for earnings, about 50%. Inspection of formula (21)
shows that this is due to the fact that the 4% mismatched data appear to
be drawn from a distribution that has a much lower log-mean (mz p
9.187, while my p 12.283) and substantially higher dispersion (jz p
1.807, while jy p .717). For the survey data the bias is particularly large
in the case of pensions, about 65%. Inspection of formula (19) suggests
that the main cause for the big bias lies in the low mean and high variance
of the contaminated data (mq p ⫺1.632, jq p 3.801).
A different way to gauge the importance of a proper treatment of the
various error sources is to compare different conventional estimation
methods and how their results differ from the full model. Tables C7–C9
present estimates of the parameters of economic interest for a number of
different estimation methods: ML on the full model; OLS, robust regression, and median regression. The latter three estimation methods are
applied twice, once with administrative data as dependent variable and
once with survey data as dependent variable.
Considering earnings (table C7) we note that the estimates of the effect
of education on earnings may vary by at least a factor of two, depending
on the estimation method chosen. Table C7 suggests that running OLS
of the administrative variables on the explanatory variables provides estimates close to those of the full model. However when we consider
pensions that conclusion changes quite a bit. Robust regression and median regression yield estimates that may be quite far removed from the
estimates obtained with ML on the full model. Another noteworthy phenomenon is the wide variation in the estimates of the effect of the semiretired dummy on pensions (table C8). Estimates vary from significantly
positive to significantly negative depending on the estimation method used
and the choice of dependent variable. For taxes the different estimation
methods appear to provide roughly comparable estimates of parameters
of economic interest.
Since the full model is a mixture of a number of different regimes it is
of interest to assign observations to different regimes. To do so we have
used the fact that the likelihood for each observation is a weighted sum
of densities corresponding to the different regimes. We have assigned
observations to the regime that produces the highest density for that
observation. Figures C1–C3 present the results. For the earnings data
there is some suggestion that respondents with low earnings tend to give
high survey values, as also found by Bollinger (1998). Of particular interest
are the observations that are classified as mismatched administrative variables. Most of these points lie above the 45 degree line, whereas the
points classified as contaminated in the survey data lie below the 45 degree
line. Naturally, the assignment procedure used here is merely indicative

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

535

and probabilistic, and hence no great importance should be attached to
the classification of each observation.
It is of interest to see if some of the classifications may be externally
validated in some way. For about 70% of the LINDA sample, a third
source of earnings information is available from employer records. It
consists of two variables, one containing the full-time equivalent monthly
earnings and one containing the percentage of full-time equivalent employed. Although there are some problems with this information, we can
still compare these values with the survey value and the administrative
value. A simple way to look for possible mismatches is to consider observations where survey and employer earnings are fairly close, while
differing substantially from the administrative data. For instance, if we
select observations for which survey earnings and administrative earnings
are at least 50,000 SEK apart, while survey earnings and employer earnings
differ by less than 10,000 SEK, we find 12 cases where this condition
holds true. For these 12 observations the ratio of survey and administrative
earnings varies between .5 and 4.5.
V. Conclusion
In comparison with most studies in the literature we have allowed for
a richer specification of possible error sources in survey data and administrative data. Our results suggest that some conclusions in the literature
may be quite sensitive to the assumption that administrative data are
flawless. In a sense, the question if administrative data represent the truth,
is almost a philosophical question. For instance, the examples of detected
mismatches given above do not necessarily imply there is true mismatching going on in the administrative data. Rather, it appears that sometimes
the survey data (and the alternative source of administrative data) measure
a different concept than the administrative data. Be this as it may, also
under the latter interpretation one would be hard pressed to maintain that
the difference between survey data and administrative data exhibits strong
mean reversion.
Our results also suggest that substantive conclusions may be affected
quite a bit by changes in assumptions on the nature of error in survey
and administrative data. Application of robust methods, such as median
or robust regression, yields results quite far removed from ML on the
full model. Thus these methods do not appear to provide a solution for
dealing with different sources of error in survey or administrative data.
There are many good reasons for wanting to use administrative data,
including sample sizes, cost of surveys, and data quality. However, unless
administrative data measure exactly the concept that one is interested in
and do so without error, these data are not a panacea. Our illustrative
calculations in table 5 suggest that biases resulting from using adminis-

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

536

Kapteyn/Ypma

trative data as right-hand side variables may be very substantial. As always,
one has to be careful in modeling the sources and nature of errors and
take that into account when investigating hypotheses of substantive
interest.
Appendix A
Derivation of Moments
The expectation of ri
m r { E[ri ] p pr E[rFr
i i p yi ] ⫹ (1 ⫺ pr)E[rFr
i i p zi ]
p pr E[yi ] ⫹ (1 ⫺ pr)E[zi ]
p pr my ⫹ (1 ⫺ pr)mz .

The expectation of si
ms { E[si ]
p ps E[siFsi p yi ] ⫹ (1 ⫺ ps )(1 ⫺ pq )E[siFsi p yi ⫹ r(yi ⫺ my ) ⫹ hi ]
⫹ (1 ⫺ ps )pq E[siFsi p yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi ]
p ps E[yi ] ⫹ (1 ⫺ ps )(1 ⫺ pq )E[yi ⫹ r(yi ⫺ my ) ⫹ hi ]
⫹ (1 ⫺ ps )pq E[yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi ]
p ps my ⫹ (1 ⫺ ps )(1 ⫺ pq )[my ⫹ m h ] ⫹ (1 ⫺ ps )pq [my ⫹ m h ⫹ mq ]
p my ⫹ (1 ⫺ ps )[m h ⫹ pq mq ].

Expectation of mi
m m { E[mi ] p E[si ⫺ ri ] p E[si ] ⫺ E[ri ]
p (1 ⫺ pr)[my ⫺ mz] ⫹ (1 ⫺ ps )[m h ⫹ pq mq ].

The variance of ri is
jr2 { E[ri ⫺ m r] 2
p pr E[ri ⫺ m rFri p yi ] 2 ⫹ (1 ⫺ pr)E[ri ⫺ m rFri p zi ] 2
p pr E[yi ⫺ pr my ⫺ (1 ⫺ pr)mz] 2 ⫹ (1 ⫺ pr)E[zi ⫺ pr my ⫺ (1 ⫺ pr)mz] 2
p pr E[(yi ⫺ my ) ⫹ (1 ⫺ pr)(my ⫺ mz)] 2 ⫹ (1 ⫺ pr)E[(zi ⫺ mz) ⫺ pr(my ⫺ mz)] 2
p pr [jy2 ⫹ (1 ⫺ pr) 2 (my ⫺ mz) 2 ] ⫹ (1 ⫺ pr)[jz2 ⫹ pr2 (my ⫺ mz) 2 ]
p prjy2 ⫹ (1 ⫺ pr)jz2 ⫹ pr(1 ⫺ pr)(my ⫺ mz) 2.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

537

The variance of si is
js2 p E[si ⫺ ms ] 2
p ps E[si ⫺ msFsi p yi ] 2
⫹ (1 ⫺ ps )(1 ⫺ pq )E[si ⫺ msFsi p yi ⫹ r(yi ⫺ my ) ⫹ hi ] 2

(A1)

⫹ (1 ⫺ ps )pq E[si ⫺ msFsi p yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi ] 2.

First calculate the three variances separately. We have
E[si ⫺ msFsi p yi ] 2 p E[yi ⫺ my ⫺ (1 ⫺ ps )(m h ⫹ pq mq )] 2
p E[yi ⫺ my ⫺ (1 ⫺ ps )(m h ⫹ pq mq )] 2

(A2)

p jy2 ⫹ (1 ⫺ ps ) 2 (m h ⫹ pq mq ) 2,

and
E[si ⫺ msFsi p yi ⫹ r(yi ⫺ my ) ⫹ hi ] 2
p E[yi ⫹ r(yi ⫺ my ) ⫹ hi ⫺ my ⫺ (1 ⫺ ps )(m h ⫹ pq mq )] 2
p E[(1 ⫹ r)(yi ⫺ my ) ⫹ (hi ⫺ m h ) ⫹ ps (m h ⫹ pq mq ) ⫺ pq mq ] 2

(A3)

p (1 ⫹ r) 2jy2 ⫹ jh2 ⫹ [ps (m h ⫹ pq mq ) ⫺ pq mq ] 2,

and
E[si ⫺ msFsi p yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi ] 2
p E[yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi ⫺ my ⫺ (1 ⫺ ps )(m h ⫹ pq mq )] 2
p E[(1 ⫹ r)(yi ⫺ my ) ⫹ (hi ⫺ m h ) ⫹ (qi ⫺ mq ) ⫹ ps (m h ⫹ pq mq ) ⫹ (1 ⫺ pq )mq ] 2

(A4)

p (1 ⫹ r) 2jy2 ⫹ jh2 ⫹ jq2 ⫹ [ps (m h ⫹ pq mq ) ⫹ (1 ⫺ pq )mq ] 2.

Define
d p my ⫺ mz ,

and

D p m h ⫹ pq mq .

Substituting (A2), (A3), and (A4) in (A1) we have
js2 p E[si ⫺ ms ] 2
p ps [jy2 ⫹ (1 ⫺ ps ) 2D2 ]
⫹ (1 ⫺ ps )(1 ⫺ pq )[(1 ⫹ r) 2jy2 ⫹ jh2 ⫹ [ps D ⫺ pq mq ] 2 ]
⫹ (1 ⫺ ps )pq [(1 ⫹ r) 2jy2 ⫹ jh2 ⫹ jq2 ⫹ [ps D ⫹ (1 ⫺ pq )mq ] 2 ]
p [ps ⫹ (1 ⫺ ps )(1 ⫹ r) 2 ]jy2 ⫹ (1 ⫺ ps )[jh2 ⫹ pqjq2 ] ⫹ Q,

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

(A5)

538

Kapteyn/Ypma

where Q is
Q p ps (1 ⫺ ps ) 2D2 ⫹ (1 ⫺ ps )(1 ⫺ pq )[ps D ⫺ pq mq ] 2 ⫹ (1 ⫺ ps )pq [ps D ⫹ (1 ⫺ pq )mq ] 2
p ps (1 ⫺ ps ) 2D2 ⫹ (1 ⫺ ps )ps2D2 ⫹ (1 ⫺ ps )(1 ⫺ pq )pq2mq2 ⫹ (1 ⫺ ps )pq(1 ⫺ pq ) 2m2q
⫺ 2(1 ⫺ ps )(1 ⫺ pq )ps Dpq mq ⫹ 2(1 ⫺ ps )pqps D(1 ⫺ pq )mq

(A6)

p [ps (1 ⫺ ps ) 2 ⫹ (1 ⫺ ps )ps2 ]D2 ⫹ (1 ⫺ ps )[(1 ⫺ pq )pq2 ⫹ pq(1 ⫺ pq ) 2 ]m2q
p ps (1 ⫺ ps )D2 ⫹ (1 ⫺ ps )pq(1 ⫺ pq )m2q .

We can now calculate the variance using (A5), (A6), and the definition
of D:
js2 p [ps ⫹ (1 ⫺ ps )(1 ⫹ r) 2 ]jy2 ⫹ (1 ⫺ ps )[jh2 ⫹ pqjq2 ]
⫹ ps (1 ⫺ ps )(m h ⫹ pq mq ) 2 ⫹ (1 ⫺ ps )pq(1 ⫺ pq )mq2 .

Using the same procedure as above, the covariance between r and s is
jrs { E[ri ⫺ m r][si ⫺ ms ]
p prps (jy2 ⫺ (1 ⫺ pr)(1 ⫺ ps )dD) ⫹
⫹ pr(1 ⫺ ps )(1 ⫺ pq )((1 ⫹ r)jy2 ⫹ (1 ⫺ pr)ps dD ⫺ (1 ⫺ pr)dpq mq )
⫹ pr(1 ⫺ ps )pq((1 ⫹ r)jy2 ⫹ (1 ⫺ pr)ps dD ⫹ (1 ⫺ pr)d(1 ⫺ pq )mq )
⫹ (1 ⫺ pr)ps (pr(1 ⫺ ps )dD)
⫹ (1 ⫺ pr)(1 ⫺ ps )(1 ⫺ pq )(⫺prps dD ⫹ pr dpq mq )
⫹ (1 ⫺ pr)(1 ⫺ ps )pq(⫺prps dD ⫺ pr d(1 ⫺ pq )mq )
p prjy2 ⫹ pr(1 ⫺ ps )rjy2.

The variance of mi is then easily obtained as
jm2 { E[mi ⫺ m m ] 2 p E[(si ⫺ ms ) ⫺ (ri ⫺ m r)] 2 p js2 ⫹ jr2 ⫺ 2jrs
p [ps ⫹ (1 ⫺ ps )(1 ⫹ r) 2 ⫹ pr ⫺ 2pr ⫺ 2pr(1 ⫺ ps )r]jy2
⫹ (1 ⫺ pr)jz2 ⫹ (1 ⫺ ps )[jh2 ⫹ pqjq2 ] ⫹ pr(1 ⫺ pr)[my ⫺ mz] 2
⫹ ps (1 ⫺ ps )[m h ⫹ pq mq ] 2 ⫹ (1 ⫺ ps )pq(1 ⫺ pq )mq2 ,

which is equivalent to
jm2 p [(1 ⫺ pr)ps ⫹ pr(1 ⫺ ps )r 2 ⫹ (1 ⫺ pr)(1 ⫺ ps )(1 ⫹ r) 2 ]jy2
⫹ (1 ⫺ pr)jz2 ⫹ (1 ⫺ ps )[jh2 ⫹ pqjq2 ] ⫹ pr(1 ⫺ pr)[my ⫺ mz] 2
⫹ ps (1 ⫺ ps )[m h ⫹ pq mq ] 2 ⫹ (1 ⫺ ps )pq(1 ⫺ pq )mq2 .

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

539

Finally, the covariance between m and r is
jmr { jsr ⫺ jr2
p prjy2 ⫹ pr(1 ⫺ ps )rjy2 ⫺ [prjy2 ⫹ (1 ⫺ pr)jz2 ⫹ pr(1 ⫺ pr)(my ⫺ mz) 2 ]
p rpr(1 ⫺ ps )jy2 ⫺ (1 ⫺ pr)jz2 ⫺ pr(1 ⫺ pr)(my ⫺ mz) 2.

Appendix B
Maximum Likelihood
As described in Section IV, we assume that the administrative data are
a mixture of two normal distributions, while the survey data are a mixture
of three different normal distributions. Since we assume the processes
underlying the administrative data and the survey data to be independent,
the combined set of observations (ri , si ) follow a mixture of six distributions.
The general shape of the log-likelihood function of a mixture of M
distributions and N observations is the following (Redner and Walker
1984):

冘 (冘
N

l(v) p

M

log

ip1

mp1

)

pm fm(xiFv) ,

where v is the vector of parameters, including mixing proportions pm and
parameters describing the distributions. Redner and Walker (1984) mention some special cases of mixtures, for instance, when some of the observations are labeled. In our case, the observations where ri p si can be
seen as labeled observations. We assume that these observations come
from the distribution, where both administrative and survey data are
correct, referred to as group 1. Since all of the observations from group
1 can be labeled, we have a completely labeled group.
Let’s assume that observations i p 1, … , n1 are observations from the
completely labeled group 1, and the other observations, i p n1 ⫹
1, … , N are a mixture of the remaining five distributions. The following
log-likelihood can then be derived

冘
n1

l(v) p

ip1

冘 (冘
N

log (p1 f1 (xiFv)) ⫹

ipn1⫹1

5

log

mp2

)

pm fm(xiFv) ,

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

540

Kapteyn/Ypma

where
p1 p prps
p2 p pr(1 ⫺ ps )(1 ⫺ pq )
p3 p pr(1 ⫺ ps )pq
p4 p (1 ⫺ pr)ps
p5 p (1 ⫺ pr)(1 ⫺ ps )(1 ⫺ pq )
p6 p (1 ⫺ pr)(1 ⫺ ps )pq .

The density function f1 is the probability density function of a N(my , jy2 )
distribution, since both ri and si are equal to yi in this case. In the five other
cases we have the bivariate normal distributions listed below:

f2 (ri , si ) ∼ N



(1 ⫹ r)j2y

jy冑(1 ⫹ r) 2jy2 ⫹ jh2

jy2

( m ⫹m m ) , 
y

y

(1 ⫹ r)jy2

h

jy冑(1 ⫹ r) j



2

2
y

(1 ⫹ r)2jy2 ⫹ jh2

⫹j

2
h



(B1)

,

when ri p yi and si p yi ⫹ r(yi ⫺ my ) ⫹ hi;

f3 (ri , si ) ∼ N

(



)



my
,
my ⫹ m h ⫹ mq

(1 ⫹ r)j2y

jy2

jy冑(1 ⫹ r) 2jy2 ⫹ jh2 ⫹ jq2

(1 ⫹ r)jy2

(1 ⫹ r)2jy2 ⫹ jh2 ⫹ jq2

jy冑(1 ⫹ r) j ⫹ j ⫹ j
2

2
y

2
h

2
q





,

(B2)

when ri p yi and si p yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi;
f4 (ri , si ) ∼ N

2
z

[(mm ) , (j0 j0 )] ,
z

(B3)

2
y

y

when ri p zi and si p yi;
f5 (ri , si ) ∼ N

2
z

[(m ⫹m m ) , (j0
z

y

h

)]

0
,
(1 ⫹ r) 2jy2 ⫹ jh2

(B4)

when ri p zi and si p yi ⫹ r(yi ⫺ my ) ⫹ hi; and
f6 (ri ,si ) ∼ N

2
z

[(m ⫹ mm ⫹ m ) , (j0
z

y

h

q

)]

0
,
(1 ⫹ r) 2jy2 ⫹ jh2 ⫹ jq2

(B5)

when ri p zi and si p yi ⫹ r(yi ⫺ my ) ⫹ hi ⫹ qi. One final note has to be
made about the labeling of group 1. Observations are labeled as a member
of group 1 if the difference between ri and si is smaller than 1,000 SEK.
The proportion ps then is the proportion of survey observations that differ
less than 1,000 SEK from the administrative data. In principle, this broader
definition of “equal” observations affects the consistency of our estimates.
However, we expect these effects to be minor.

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Appendix C
Estimation Results
Table C1
Estimates Using Log Earnings
No
Contamination

Full Model

Log likelihood
Female
Age
Age2
Fullret
Semiret
Midedu
Highedu
Dkedu
my
jy
mz
jz
mq
jq
mh
jh
pr
ps
pq
r

Coefficient

SD

Coefficient

SD

⫺503.2
⫺.268
.087
⫺.275
⫺1.015
⫺.421
.244
.345
.568
11.592
.543
9.843
2.026
⫺.259
1.313
⫺.046
.102
.948
.155
.123
⫺.064

.052
.024
.062
.125
.114
.102
.101
.104
.262
.021
.646
.334
.211
.152
.007
.008
.015
.019
.028
.020

⫺558.8
⫺.253
.095
⫺.275
⫺1.152
⫺.273
.370
.438
.694
11.335
.653
11.385
1.738
...
...
⫺.053
.110
.864
.170
...
⫺.002

.062
.031
.082
.091
.112
.117
.122
.119
.315
.021
.243
.170
...
...
.008
.007
.020
.020
...
.024

No Mismatch
Coefficient
⫺623.4
⫺.163
.136
⫺.421
⫺1.253
⫺.694
.266
.364
.603
11.092
.840
...
.442
1.791
⫺.040
.104
...
.148
.168
⫺.072

Basic Model

SD

Coefficient

SD

.100
.025
.059
.127
.276
.128
.148
.120
.301
.032
...
...
.234
.174
.008
.006
...
.018
.024
.021

⫺762.8
⫺.225
.111
⫺.330
⫺1.210
⫺.378
.361
.435
.684
11.181
.754
...
...
...
...
...
.523
...
...
...
⫺.525

.071
.034
.095
.114
.106
.228
.211
.197
.287
.031
...
...
...
...
...
.020
...
...
...
.036

Table C2
Estimates Using Log Earnings
Full Model

Log likelihood
my
jy
mz
jz
mq
jq
mh
jh
pr
ps
pq
r

No
Contamination

No Mismatch

Basic Model

Coefficient

SD

Coefficient

SD

Coefficient

SD

Coefficient

SD

⫺607.5
12.283
.717
9.187
1.807
⫺.304
1.239
⫺.048
.099
.959
.152
.156
⫺.013

.032
.021
.691
.424
.174
.129
.007
.007
.013
.018
.028
.014

⫺646.5
12.246
.843
11.387
1.751
...
...
⫺.056
.112
.867
.169
...
.022

.041
.026
.254
.178
...
...
.007
.006
.020
.020
...
.012

⫺708.5
12.178
1.116
...
...
.432
1.407
⫺.047
.100
...
.148
.187
⫺.013

.046
.035
...
...
.187
.151
.008
.007
...
.018
.026
.014

⫺881.2
12.191
.960
...
...
...
...
...
.552
...
...
...
⫺.369

.038
.030
...
...
...
...
...
.019
...
...
...
.029

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Table C3
Estimates Using Log-Pensions
No
Contamination

Full Model

Log likelihood
Female
Age
Age2
Fullret
Semiret
Midedu
Highedu
Dkedu
my
jy
mz
jz
mq
jq
mh
jh
pr
ps
pq
r

No Mismatch

Basic Model

Coefficient

SD

Coefficient

SD

Coefficient

SD

Coefficient

SD

⫺589.5
⫺.422
.058
⫺.085
.527
.034
.224
.156
.487
10.379
.501
8.957
.764
⫺1.472
3.676
⫺.049
.212
.981
.267
.056
⫺.199

.048
.025
.041
.154
.187
.055
.089
.068
.429
.021
.307
.235
.983
.713
.013
.012
.007
.023
.018
.032

⫺755.7
⫺.423
.020
⫺.011
.276
⫺.487
.167
.352
.520
10.964
1.060
11.234
1.206
...
...
⫺.037
.187
.907
.295
...
⫺.161

.106
.061
.100
.268
.554
.124
.167
.155
.814
.071
.226
.160
...
...
.022
.012
.021
.025
...
.027

⫺653.6
⫺.375
.077
⫺.111
.575
⫺.219
.201
.111
.489
9.948
.669
...
...
⫺.305
3.707
⫺.040
.209
...
.263
.077
⫺.186

.063
.029
.048
.163
.253
.075
.090
.099
.379
.027
...
...
.809
.610
.015
.012
...
.023
.019
.031

⫺775.8
⫺.410
.072
⫺.100
.531
⫺.150
.165
.088
.407
10.059
.572
...
...
...
...
...
.838
...
...
...
⫺.459

.059
.028
.047
.159
.273
.069
.099
.091
.390
.021
...
...
...
...
...
.031
...
...
...
.073

Table C4
Estimates Using Log-Pensions
Full Model

Log likelihood
my
jy
mz
jz
mq
jq
mh
jh
pr
ps
pq
r

Coefficient

SD

⫺650.5
11.742
.628
9.023
.843
⫺1.632
3.801
⫺.044
.217
.981
.268
.050
⫺.131

.032
.030
.409
.344
1.077
.775
.014
.012
.008
.023
.017
.023

No
Contamination

No Mismatch

Basic Model

Coefficient SD Coefficient SD Coefficient SD
⫺777.3
11.679
1.123
11.256
1.202
...
...
⫺.036
.190
.905
.295
...
⫺.117

.056
.033
.222
.159
...
...
.015
.012
.022
.025
...
.022

⫺696.4
11.693
.769
...
...
⫺.302
3.608
⫺.038
.211
...
.263
.080
⫺.128

542

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

.038
.033
...
...
.773
.584
.015
.012
...
.023
.020
.023

⫺830.3
11.685
.657
...
...
...
...
...
.845
...
...
...
⫺.361

.025
.023
...
...
...
...
...
.022
...
...
...
.067

Table C5
Estimates Using Log-Taxes
Full Model

Log likelihood
Female
Age
Age2
Fullret
Semiret
Midedu
Highedu
Dkedu
my
jy
mz
jz
mq
jq
mh
jh
pr
ps
pq
r

No
Contamination

No Mismatch

Basic Model

Coefficient

SD

Coefficient

SD

Coefficient

SD

Coefficient

SD

⫺759.2
⫺.453
.030
⫺.070
⫺.409
.153
.332
.381
.648
10.752
.686
9.846
1.197
⫺.591
1.847
.095
.105
.921
.216
.094
⫺.043

.064
.023
.040
.129
.120
.083
.103
.110
.293
.026
.300
.145
.360
.267
.007
.006
.023
.020
.028
.013

⫺818.5
⫺.412
.028
⫺.076
⫺.368
.234
.290
.406
.664
10.741
.890
10.235
1.097
...
...
.097
.103
.848
.239
...
⫺.043

.080
.022
.042
.117
.129
.095
.110
.099
.269
.028
.137
.094
...
...
.007
.006
.020
.021
...
.015

⫺788.0
⫺.471
.039
⫺.097
⫺.381
.156
.291
.389
.648
10.647
.790
...
...
.025
1.639
.101
.106
...
.199
.180
⫺.056

.076
.020
.035
.132
.157
.091
.107
.109
.258
.028
...
...
.188
.136
.005
.006
...
.018
.024
.014

⫺924.4
⫺.509
.035
⫺.087
⫺.320
.198
.284
.394
.641
10.709
.689
...
...
...
...
...
.567
...
...
...
⫺.192

.059
.020
.036
.100
.183
.077
.099
.097
.256
.022
...
...
...
...
...
.018
...
...
...
.037

Table C6
Estimates Using Log-Taxes
Full Model

Log likelihood
my
jy
mz
jz
mq
jq
mh
jh
pr
ps
pq
r

No
Contamination

No Mismatch

Basic Model

Coefficient

SD

Coefficient

SD

Coefficient

SD

Coefficient

SD

⫺840.0
10.839
.846
9.645
1.189
⫺.474
1.640
.092
.107
.935
.213
.111
⫺.011

.089
.117
.448
.167
.442
.471
.010
.008
.031
.020
.045
.021

⫺876.0
10.801
1.006
10.220
1.109
...
...
.088
.108
.853
.235
...
⫺.0004

.043
.037
.140
.095
...
...
.010
.007
.020
.021
...
.019

⫺862.8
10.784
.958
...
...
.051
1.500
.095
.105
...
.199
.189
⫺.015

.042
.019
...
...
.174
.130
.007
.005
...
.018
.024
.012

⫺1018.2
10.809
.828
...
...
...
...
...
.572
...
...
...
⫺.133

.034
.023
...
...
...
...
...
.015
...
...
...
.030

543

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

544

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Female
Age
Age2
Fullret
Semiret
Midedu
Highedu
Dkedu
Cons

SD
.052
.024
.062
.125
.114
.102
.101
.104
.262

Coefficient

⫺.268
.087
⫺.275
⫺1.015
⫺.421
.244
.345
.568
11.592

⫺.142
.133
⫺.416
⫺1.260
⫺.520
.219
.334
.511
11.158

Coefficient
.076
.038
.102
.176
.175
.136
.141
.138
.385

SD
⫺.256
.049
⫺.152
⫺.663
⫺.433
.145
.283
.461
11.943

Coefficient
.036
.018
.048
.084
.084
.065
.067
.066
.184

SD
⫺.226
.126
⫺.380
⫺.826
⫺.544
.120
.313
.404
11.326

Coefficient
.037
.019
.049
.085
.084
.065
.068
.067
.188

SD
⫺.262
.101
⫺.292
⫺1.189
⫺.316
.423
.479
.759
11.192

Coefficient

SD
.065
.032
.086
.149
.148
.115
.119
.117
.326

⫺.244
.068
⫺.203
⫺.591
⫺.594
.192
.317
.504
11.708

Coefficient

.036
.018
.048
.084
.083
.064
.067
.066
.183

SD

Robust
Regression

OLS

Full Model

OLS

Survey Earnings

Robust
Regression

Median
Regression

Administrative Earnings

Both Sources

Table C7
Different Regressions for Log Earnings

⫺.249
.081
⫺.233
⫺.857
⫺.597
.168
.302
.476
11.590

Coefficient

.039
.020
.052
.089
.089
.069
.072
.071
.197

SD

Median
Regression

545

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Female
Age
Age2
Fullret
Semiret
Midedu
Highedu
Dkedu
Cons

OLS

⫺.422
.058
⫺.085
.527
.034
.224
.156
.487
10.379

Coefficient
.048
.025
.041
.154
.187
.055
.089
.068
.429

SD
⫺.395
.083
⫺.120
.605
⫺.066
.180
.036
.401
9.861

Coefficient
.062
.030
.049
.172
.257
.072
.105
.096
.419

SD
⫺.432
.064
⫺.099
.649
.675
.200
.256
.440
10.246

Coefficient
.042
.020
.033
.116
.174
.049
.071
.065
.284

SD
⫺.410
.057
⫺.083
.679
⫺.465
.169
.196
.401
10.294

Coefficient
.054
.025
.041
.145
.214
.062
.091
.082
.354

SD
⫺.476
.028
⫺.018
.223
⫺.501
.099
.304
.428
10.881

Coefficient

SD
.096
.046
.075
.266
.398
.111
.162
.148
.648

⫺.405
.063
⫺.097
.616
⫺.232
.221
.289
.496
10.223

Coefficient

.041
.020
.032
.113
.169
.047
.069
.063
.276

SD

Robust
Regression

Median
Regression

Robust
Regression

Full Model

OLS

Survey Pensions

Administrative Pensions

Both Sources

Table C8
Different Regressions for Log-Pensions

⫺.381
.034
⫺.044
.538
⫺.695
.244
.299
.505
10.647

Coefficient

.053
.025
.041
.143
.211
.061
.088
.081
.357

SD

Median
Regression

546

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Female
Age
Age2
Fullret
Semiret
Midedu
Highedu
Dkedu
Cons

⫺.453
.030
⫺.070
⫺.409
.153
.332
.381
.648
10.752

Coefficient
.064
.023
.040
.129
.120
.083
.103
.110
.293

SD
⫺.528
.037
⫺.092
⫺.314
.182
.286
.387
.632
10.663

Coefficient

SD
.063
.022
.039
.109
.192
.084
.102
.101
.271

⫺.394
.025
⫺.045
⫺.405
⫺.207
.218
.324
.465
10.789

Coefficient
.041
.014
.026
.071
.126
.055
.066
.066
.177

SD
⫺.391
.042
⫺.071
⫺.496
⫺.118
.203
.337
.458
10.578

Coefficient
.041
.014
.025
.070
.121
.054
.065
.064
.174

SD
⫺.456
.027
⫺.073
⫺.338
.242
.282
.412
.666
10.834

Coefficient

SD
.073
.025
.045
.126
.221
.097
.117
.116
.312

⫺.406
.024
⫺.041
⫺.496
⫺.158
.292
.393
.557
10.864

Coefficient

.046
.016
.028
.079
.139
.061
.074
.073
.196

SD

Robust
Regression

OLS

Full Model

OLS

Survey Taxes

Robust
Regression

Median
Regression

Administrative Taxes

Both Sources

Table C9
Different Regressions for Log-Taxes

⫺.379
.058
⫺.101
⫺.575
⫺.174
.277
.379
.530
10.459

Coefficient

.053
.018
.033
.091
.156
.070
.085
.083
.227

SD

Median
Regression

Fig. C1.—Log earnings without (upper) and with (lower) covariates

547

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Fig. C2.—Log pensions without (upper) and with (lower) covariates. Two observations,
with logarithmic survey values smaller than 3 and logarithmic administrative values between
11 and 11.5, are outside the scale of this figure. Both are classified as correct administrative
data and a contaminated survey value.

548

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Fig. C3.—Log taxes without (upper) and with (lower) covariates. One observation, with
logarithmic survey value smaller than 4 and logarithmic administrative value between 11
and 11.5, is outside the scale of this figure. The survey value is classified as contaminated
and the administrative value is classified as correct (with covariates) or as a mismatch (without
covariates).

549

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

550

Kapteyn/Ypma

References
Abowd, John M., and Lars Vilhuber. 2005. The sensitivity of economic
statistics to coding errors in personal identifiers. Journal of Business
and Economic Statistics 23, no. 2 (April): 133–52.
Aigner, Dennis, Cheng Hsiao, Arie Kapteyn, and Tom Wansbeek. 1984.
Latent variable models in econometrics. In Handbook of econometrics,
vol. 2, ed. Zvi Griliches and Michael Intriligator, 1321–93. Amsterdam:
Elsevier.
Bekker, Paul A. 1986. Comment on identification in the linear errors in
variables model. Econometrica 54:215–17.
Bekker, Paul, Arie Kapteyn, and Tom Wansbeek. 1987. Consistent sets
of estimates for regressions with correlated or uncorrelated measurement error in arbitrary subsets of all variables. Econometrica 55:
1223–30.
Bollinger, Christopher R. 1998. Measurement error in the current population survey: A nonparametric look. Journal of Labor Economics 16,
no. 3 (July): 576–94.
Bound, John, Charles Brown, Greg J. Duncan, and Willard L. Rodgers.
1994. Evidence on the validity of cross-sectional and longitudinal labor
market data. Journal of Labor Economics 12, no. 3 (July): 345–68.
Bound, J., C. Brown, and N. Mathiowetz. 2001. Measurement error in
survey data. In Handbook of labor economics, vol. 5, ed. J. Heckman
and E. Leamer, 3707–3843. Amsterdam: Elsevier.
Bound, John, and Alan B. Krueger. 1991. The extent of measurement
error in longitudinal earnings data: Do two wrongs make a right? Journal of Labor Economics 9, no. 1 (January): 1–24.
Chen, Xiaohong, Han Hong, and Elie Tamer. 2005. Measurement error
models with auxiliary data. Review of Economic Studies 72, no. 2
(April): 343–66.
Duncan, Greg J., and Daniel H. Hill. 1985. An investigation of the extent
and consequences of measurement error in labor-economic survey data.
Journal of Labor Economics 3, no. 4 (October): 508–32.
Edin, Per-Anders, and Peter Frederiksson. 2000. LINDA—Longitudinal
INdividual DAta for Sweden. Working Paper no. 2000:19, Department
of Economics, Uppsala University (November).
Hurd, Michael, F. Thomas Juster, and James P. Smith. 2004. Enhancing
the quality of data on income: Recent developments in survey methodology. Labor and Demography 0412001, EconWPA (December),
http://ideas.repec.org/p/wpa/wuwpla/0412001.html.
Johansson, Fredrik, and Anders Klevmarken. 2006. Explaining the size
and nature of response behavior in a survey on health status and economic standard. Working Paper no. 2006:2, Department of Economics,
Uppsala University (January).

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

Measurement Error and Misclassification

551

Kane, Thomas, Cecilia Rouse, and Douglas Staiger. 1999. Estimating returns to schooling when schooling is misreported. NBER Working
Paper no. 7235, National Bureau of Economic Research, Cambridge,
MA.
Kim, Bonggeun, and Gary Solon. 2005. Implications of mean-reverting
measurement error for longitudinal studies of wages and employment.
Review of Economics and Statistics 87, no. 1 (December): 193–96.
Klepper, Steven, and Edward Leamer. 1984. Consistent sets of estimates
for regressions with errors in all variables. Econometrica 52:163–84.
Lee, Lung-Fei, and Jungsywan H. Sepanski. 1995. Estimation of linear
and nonlinear errors-in-variables models using validation data. Journal
of the American Statistical Association 90, no. 429 (March): 130–40.
Meijer, Erik, and Jelmer Ypma. 2006. A simple identification proof for a
mixture of two univariate normal distributions. Working paper, University of Groningen (March).
Pedace, Roberto, and Nancy Bates. 2001. Using administrative records
to assess earnings reporting error in the survey of income and program
participation. Journal of Economic and Social Measurement 26, nos.
3–4:173–92.
Pischke, Jörn-Steffen. 1995. Measurement error and earnings dynamics:
Some estimates from the PSID validation study. Journal of Business and
Economic Statistics 13, no. 3 (July): 305–14.
Redner, Richard A., and Homer F. Walker. 1984. Mixture densities, maximum likelihood and the EM algorithm. SIAM Review 26, no. 2 (April):
195–239.
Rodgers, Willard L., Charles Brown, and Greg J. Duncan. 1993. Errors
in survey reports of earnings, hours worked, and hourly wages. Journal
of the American Statistical Association 88, no. 424 (December): 1208–18.
Stinson, Martha. 2002. Estimating measurement error in SIPP annual job
earnings: A comparison of census survey and SSA administrative data.
U.S. Census Bureau Technical Report TP-2002-24, Suitland, MD
(September).

This content downloaded from
206.253.207.235 on Mon, 11 Mar 2019 17:04:23 UTC
All use subject to https://about.jstor.org/terms

