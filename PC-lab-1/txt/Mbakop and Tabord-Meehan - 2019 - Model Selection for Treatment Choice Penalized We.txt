Model Selection for Treatment Choice:
Penalized Welfare Maximization
Max Tabord-Meehan
Department of Economics
University of Chicago
maxtm@uchicago.edu ∗

arXiv:1609.03167v5 [math.ST] 7 Dec 2019

Eric Mbakop
Department of Economics
University of Calgary
eric.mbakop@ucalgary.ca

10th December 2019
Abstract
This paper studies a penalized statistical decision rule for the treatment assignment problem.
Consider the setting of a utilitarian policy maker who must use sample data to allocate a binary
treatment to members of a population, based on their observable characteristics. We model this
problem as a statistical decision problem where the policy maker must choose a subset of the
covariate space to assign to treatment, out of a class of potential subsets. We focus on settings
in which the policy maker may want to select amongst a collection of constrained subset classes:
examples include choosing the number of covariates over which to perform best-subset selection,
and model selection when approximating a complicated class via a sieve. We adapt and extend
results from statistical learning to develop the Penalized Welfare Maximization (PWM) rule.
We establish an oracle inequality for the regret of the PWM rule which shows that it is able
to perform model selection over the collection of available classes. We then use this oracle
inequality to derive relevant bounds on maximum regret for PWM. An important consequence
of our results is that we are able to formalize model-selection using a “hold-out” procedure,
where the policy maker would first estimate various policies using half of the data, and then
select the policy which performs the best when evaluated on the other half of the data.

KEYWORDS: Treatment Choice, Minimax-Regret, Statistical Learning
JEL classification codes: C01, C14, C44, C52

∗

We are grateful for advice and encouragement from Ivan Canay, Joel Horowitz, Chuck Manski and Alex Torgovit-

sky. We would also like to thank Toru Kitagawa, Azeem Shaikh, Alex Tetenov, Stefan Wager, the editor, anonymous
referees, and seminar participants at Northwestern University, (continued on next page)

1

1

Introduction

This paper develops a new statistical decision rule for the treatment assignment problem. A major
goal of treatment evaluation is to provide policy makers with guidance on how to assign individuals
to treatment, given experimental or quasi-experimental data. Following the literature inspired
by Manski (2004) (a partial list in econometrics includes Armstrong and Shen, 2015; Athey and
Wager, 2017; Bhattacharya and Dupas, 2012; Chamberlain, 2011; Dehejia; Hirano and Porter,
2009; Kasy, 2014; Kitagawa and Tetenov, 2018; Kock and Thyrsgaard, 2017; Rai, 2018; Schlag,
2007; Stoye, 2009, 2012; Tetenov, 2012; Viviano, 2019), we treat the treatment assignment problem
as a statistical decision problem of maximizing population welfare. Like many of the above papers,
we evaluate our decision rule by its maximum regret.
The rule we develop, the Penalized Welfare Maximization (PWM) rule, is designed to address
situations in which the policy maker can choose amongst a collection of constrained classes of
allocations. To be concrete, suppose we have two treatments, and we represent assignment into these
treatments by partitioning the covariate space into two pieces. We can then think of constraints
on assignment as constraints on the allowable subsets that we can consider for the partitions. For
example, policy makers may face exogenous constraints on how they can use covariates for legal,
ethical, or political reasons. Even in cases where policy makers have leeway in how they assign
treatment, plausible modeling assumptions may imply certain restrictions on assignment. Kitagawa
and Tetenov (2018) develop what they call the Empirical Welfare Maximization (or EWM) rule,
whose primary feature is its ability to solve the treatment choice problem when certain exogenous
constraints are placed on assignment. Kitagawa and Tetenov (2018) focus on deriving bounds on
maximum regret of the EWM rule for a fixed class of subsets of finite VC dimension (see Györfi
et al., 1996, for a definition). In this paper, however, we consider settings where the class of
allowable subsets is “large”. We approach the problem by approximating our class of allowable
allocations by a sequence of subclasses of finite VC dimension. We establish an oracle inequality
for the regret of the PWM rule which shows that it behaves as if we knew the “correct” class to
use in the sequence. We then use this result to derive bounds on the maximum regret of the PWM
rule in two empirically relevant settings.
The first setting that we consider is one where the class of feasible allocations has infinite
VC dimension. In particular, we argue that economic modeling assumptions may sometimes put
restrictions on the unconstrained optimum that naturally generate classes of infinite VC dimension.
For example, plausible assumptions may only impose shape restrictions on the optimal allocation.
To solve the optimal welfare assignment problem in this setting, we approximate these large classes
0

(continued from previous page), NASMES 2017, and the Bristol Econometrics Study Group for helpful com-

ments, as well as Nitish Keskar for help in implementing EWM. This research was supported in part through the
computational resources and staff contributions provided for the Social Sciences Computing Cluster (SSCC), and the
Quest high performance computing facility at Northwestern University. All mistakes are our own.

2

of feasible allocations by sequences of classes of finite VC dimension. The strength of the PWM rule
in this setting will then be to provide a data-driven method by which to select an “appropriate”
approximating class. In doing so we will derive bounds on the maximum regret of the PWM rule
for a large set of classes of infinite VC dimension.
The second setting we consider is one where the class of feasible allocations may have large
VC dimension relative to the sample size. This could arise, for example, if the planner has many
covariates on which to base assignment. As is shown in Kitagawa and Tetenov (2018), when the
constraints placed on assignment are too flexible relative to the sample size available, the EWM rule
may suffer from overfitting, which can result in inflated values of regret. By the same mechanism
that allows PWM to select an appropriate approximating class in our first application, we can
use PWM in order to select amongst simpler subclasses in this setting as well, in a way that
improves the performance of the allocation rule in finite samples. We illustrate PWM’s ability to
reduce regret in a simulation study where the policy maker has many covariates on which to base
treatment assignment, but does not know how many to use when performing best-subset selection.
The PWM rule is heavily inspired by the literature on model selection in classification: see
for example the seminal work of Vapnik and Chervonenkis (1974), as well as Györfi et al. (1996),
Koltchinskii (2001), Bartlett et al. (2002), Boucheron et al. (2005), Scott and Nowak (2006), Bartlett
(2008), Koltchinskii (2008) among many others. The theoretical contribution of our paper is to
modify and extend some of these tools to the setting of treatment choice. As pointed out in Kitagawa
and Tetenov (2018), there are substantive differences between classification and treatment choice:
observed outcomes are real-valued in the setting of treatment choice, and only one of the potential
outcomes is observed for any given individual. When we say that we extend these tools, we mean
that we prove results for settings where the data available to the policy maker is quasi-experimental.
As we will see, in such a setting the policy maker’s objective function contains an estimated quantity,
which is not an issue that arises in the classification problem. In deciding which tools to extend,
we have attempted to strike a balance between ease of use for practitioners, theoretical appeal, and
performance in simulations. An important consequence of our results is that we are able to formalize
model-selection using a “hold-out” procedure, where the policy maker would first estimate various
policies using half of the data, and then select the policy which performs the best when evaluated
on the other half of the data. The connection between classification and treatment choice has
been explored in various fields, including machine learning, under the label of policy learning (see
Beygelzimer and Langford, 2009; Kallus, 2016; Swaminathan and Joachims, 2015; Zadrozny, 2003,
among others), and in epidemiology under the label of individualized treatment rules (examples
include Qian and Murphy, 2011; Zhao et al., 2012). Kitagawa and Tetenov (2018) and Athey and
Wager (2017) provide a discussion on the link between these various literatures.
The remainder of the paper is organized as follows. In Section 2, we set up the notation and
formally define the problem that the policy maker (i.e. social planner) is attempting to solve.
3

In Section 3, we introduce the PWM rule, present general results about its maximum regret,
and explain how our results allow us to study the properties of the “hold-out” model-selection
procedure. In Section 4 we derive bounds on maximum regret of the PWM rule when the planner
is constrained to what we call monotone allocations, and then illustrate these in an application to
the Job Training Partnership Act (JTPA) study.

2

Setup and Notation

Let Yi denote the observed outcome of a unit i, and let Di be a binary variable which denotes the
treatment received by unit i. Let Yi (1) denote the potential outcome of unit i under treatment 1
(which we will refer to as “the treatment”), and let Yi (0) denote the potential outcome of unit i
under treatment 0 (which we will refer to as “the control”). The observed outcome for each unit is
related to their potential outcomes through the expression:
Yi = Yi (1)Di + Yi (0)(1 − Di ) .

(1)

Let Xi ∈ X ⊂ Rdx denote a vector of observed covariates for unit i. Let Q denote the distribution
of (Yi (0), Yi (1), Di , Xi ), then we assume that the planner observes a size n random sample
(Yi , Di , Xi )ni=1 ∼ P n ,
where P is jointly determined by Q, and the expression in (1). Throughout the paper we will
assume unconfoundedness, i.e.
Assumption 2.1. (Unconfoundedness) The distribution Q satisfies:


(Y (1), Y (0)) ⊥ D



X .

This assumption asserts that, once we condition on the observable covariates, the treatment is
exogenous. This assumption will hold in a randomized controlled trial (RCT), which is our primary
application of interest, since the treatment is exogenous by construction. This assumption is sometimes also made (possibly tenuously) in observational studies; it is a key identifying assumption
when using matching or regression estimators in policy evaluation settings with observational data
(Imbens, 2004, provides a review of these techniques, and discusses the validity of Assumption 2.1
in economic applications).
The planner’s goal is to optimally assign the treatment to the population. The objective function
we consider is utilitarian welfare, which is defined by the average of the individual outcomes in the
population:
EQ [Y (1)1{X ∈ G} + Y (0)1{X ∈
/ G}] ,
4

where G ⊂ X represents the set of covariate values of the individuals assigned to treatment. The
planner is tasked with choosing a treatment allocation G ⊂ X using the empirical data. Using
Assumption 2.1, we can rewrite the welfare criterion as:
EQ [Y (0)] + EP

h Y D
i
Y (1 − D) 
−
1{X ∈ G} ,
e(X)
1 − e(X)

where e(X) = EP [D|X] is the propensity score. Since the first term of this expression does not
depend on G, we define the planner’s objective function given a choice of treatment allocation G
as:
W (G) := EP

i
h Y D
Y (1 − D) 
−
1{X ∈ G} .
e(X)
1 − e(X)

Let G be the class of all feasible treatment allocations. Here, we consider the possibility that
the planner may be restricted in what type of allocations she can (or wants to) consider. These
restrictions may arise from legal, ethical, or political considerations, or could arise as natural
constraints from the economic model. Consider the following three examples of G:
Example 2.1. G could be the set of all measurable subsets of X . This is the largest possible class
of admissible allocations. It is straightforward to show that the optimal allocation in this case is
as follows: define
τ (x) := EQ [Y (1) − Y (0)|X = x] ,
then the optimal allocation is given by
G∗F B := {x ∈ X : τ (x) ≥ 0} ,
which assigns an individual with covariate x to treatment or control depending on whether the
conditional average treatment effect at x is non-negative.
Example 2.2. Suppose X ⊂ R, and consider the class of threshold allocations:
G = {G : G = (−∞, x] ∩ X or G = [x, ∞) ∩ X , for x ∈ X } .
Such a class G would be reasonable, for example, when assigning scholarships to students: suppose
the only covariate available to the planner is a student’s GPA, then it may be school policy that
only threshold-type rules are to be considered.
Example 2.3. Let X = X1 × X2 ⊂ R2 , and consider the class of monotone allocations:

G = G : G = {(x1 , x2 ) ∈ X | x2 ≥ f (x1 ) for f : X1 → X2 increasing} .
As an example, consider again the setting of assigning scholarships to students (Example 2.2), but
now suppose that the covariates available to the planner are parental income (x1 ) and a student’s
GPA (x2 ). The allocation rules considered in G are such that the GPA requirement for scholarship
eligibility increases with parental income. In fact, even if the planner is not exogenously constrained
5

to such allocations, this type of shape restriction could arise naturally from an economic model.
Suppose, for instance, that the outcome of interest depends only on a student’s innate “ability”
(which is unobservable) and on whether or not the student receives the scholarship. Furthermore,
suppose that the planner can only use information on GPA and parental income to assign scholarships, which have a per-unit cost. Under some modeling assumptions (outlined in Appendix D) on
the outcome equation, and the relationship between the distributions of ability, GPA, and parental
income, it can be shown that the optimal allocation is in G. See Appendix D for details.
Given a feasible class G, we denote the highest attainable welfare by:
WG∗ := sup W (G) .
G∈G

A decision rule is a function Ĝ from the observed data {(Yi , Di , Xi )}ni=1 into the set of admissible
allocations G. We call the rule that we develop and study in this paper the Penalized Welfare
Maximization (or PWM) rule. As in much of the literature that follows the work of Manski (2004),
we assume that the planner is interested in rules Ĝ that, on average, are close to the highest
attainable welfare. To that end, the criterion by which we evaluate a decision rule is given by what
we call maximum G-regret:
sup EP n [WG∗ − W (Ĝ)] .
P

We note that, in contrast to many papers on statistical treatment rules which employ maximumregret criteria, this notion of regret is defined relative to the optimum attained in G, which is not
necessarily the first-best unrestricted optimum (see Example 2.1). Kitagawa and Tetenov (2018)
and Athey and Wager (2017) are recent papers which also focus on the G-regret criterion.

3

Penalized Welfare Maximization

In this section, we present the main results of our paper. In Section 3.1, we review the properties
of the empirical welfare maximization (EWM) rule of Kitagawa and Tetenov (2018), which will
motivate the PWM rule and serve as an important building block in its construction. In Section
3.2, we define the penalized welfare maximization rule and present bounds on its maximum G-regret
for general penalties. In Section 3.3 we illustrate these results by applying them to some specific
penalties, and in particular we show that a standard “hold-out” procedure can be formalized as a
penalty which satisfies our assumptions. In Section 3.4 we present results for a modification of the
PWM rule for quasi-experimental settings where the propensity score is not known and must be
estimated.

6

3.1

Empirical Welfare Maximization: a Review and Some Motivation

The idea behind the EWM rule is to solve a sample analog of the population welfare maximization
problem:
ĜEW M ∈ arg max Wn (G) ,
G∈G

where
Wn (G) :=

n
n
i
1X
1 X h Yi Di
Yi (1 − Di ) 
τi 1{Xi ∈ G} :=
−
1{Xi ∈ G} .
n
n
e(Xi )
1 − e(Xi )
i=1

(2)

i=1

In general this problem could be computationally challenging. However, Kitagawa and Tetenov
(2018) show that solving such a problem is practically feasible for many applications by formulating
it as a Mixed Integer Linear Program (MILP): see Appendix D.1 for details. Note that to solve
this optimization problem, the planner must know the propensity score e(·). This assumption is
reasonable if the data comes from a randomized experiment, but clearly could not be made in a
setting where the planner is using observational data. Kitagawa and Tetenov (2018) derive results
for a modified version of the EWM rule where the propensity score is estimated, which we will
review in Section 3.4.
To derive their non-asymptotic bounds on the maximum G-regret of the EWM rule, Kitagawa
and Tetenov (2018) make the following additional assumptions, which we will also require for our
results:
Assumption 3.1. (Bounded Outcomes and Strict Overlap) The set of distributions P(M, κ) has
the following properties:
• There exists some M < ∞ such that the support of the outcome variable Y is contained in
M
[− M
2 , 2 ].

• There exists some κ ∈ (0, 0.5) such that e(x) ∈ [κ, 1 − κ] for all x.
The first assumption asserts that the outcome is bounded. Since the implementation of the
EWM rule or the PWM rule does not require that the planner knows M , and the existence of some
bound on outcomes of interest to economics seems tenable (the assumption holds, for instance,
if the outcome variable is binary), we view this assumption as mild. The second assumption
ensures overlap in the covariate distributions, and is standard when imposing unconfoundedness.
In an RCT, this assumption can be made to hold by design, but may be violated in settings with
observational data.
In order to derive their results, Kitagawa and Tetenov (2018) also make the following assumption, which we will not require:
Assumption 3.2. (Finite VC Dimension): G has finite VC dimension V < ∞.
7

Such an assumption may or may not be restrictive depending on the application in question.
Consider Example 2.2, the class of threshold allocations on R. This class has VC dimension 2, thus
Assumption 3.2 holds. On the other hand, it can be shown that the class of monotone allocations
on [0, 1]2 that was introduced in Example 2.3 has infinite VC dimension (see Györfi et al., 1996).
Given Assumptions 3.1 and 3.2, Kitagawa and Tetenov (2018) derive the following non-asymptotic
upper bound on the maximum G-regret of the EWM rule:
sup
P ∈P(M,κ)

EP n [WG∗

M
− W (ĜEW M )] ≤ C
κ

r

V
,
n

(3)

for some universal constant C. Moreover, when X has sufficiently “large” support, they derive the
following lower bound: for any decision rule Ĝ,
r
sup
P ∈P(M,κ)

EP n [WG∗

− W (Ĝ)] ≥ RM

V −1
,
n

(4)

for R a universal constant and for all sufficiently large n. This shows that the rate of convergence of
maximum G-regret implied by (3) is the best possible, i.e. that no other decision rule could achieve
a faster rate without imposing additional assumptions.
Remark 3.1. Theorem 2.2 in Kitagawa and Tetenov (2018), which establishes (4), has another
interesting implication: if X has “large” support and we do not impose additional restrictions on
the set of distributions P(M, κ), then it is impossible to derive a uniform rate of convergence of
maximum G-regret for any rule, for classes G of infinite VC dimension. This is in line with the
results derived in Stoye (2009), where he shows that in a setting with a continuous covariate, and
for any sample size, flipping a coin to assign individuals is minimax-regret optimal despite this
rule not even being point-wise consistent. Since we will be interested in classes G of infinite VC
dimension, we will revisit this problem later in Section 3.
Remark 3.2. As pointed out in Kitagawa and Tetenov (2018), the EWM rule is not invariant
to positive affine transformations of the outcomes, and thus the researcher could manipulate the
treatment rule in settings where they have leeway in how to code the outcome variable. To deal
with this issue they suggest solving a demeaned version of the welfare maximization problem. In
Appendix D we discuss the demeaned version of EWM and repeat the exercise of Section 4 using
a demeaned version of EWM and PWM.

3.2

Penalized Welfare Maximization: General Results

We now consider a setting where the class G of admissible rules is “large”, but can be “approximated” by a sequence of less complex subclasses Gk :1
G1 ⊆ G2 ⊆ G3 ⊆ · · · ⊆ Gk ⊆ · · · ⊆ G .
8

Let Ĝn,k be the EWM rule in the class Gk . Then we can decompose the G-regret of the rule Ĝn,k
as follows:
EP n [WG∗ − W (Ĝn,k )] = EP n [WG∗k − W (Ĝn,k )] + WG∗ − WG∗k .
Given this decomposition, we call
EP n [WG∗k − W (Ĝn,k )] ,
the estimation error of the rule Ĝn,k in the class Gk , and we call
WG∗ − WG∗k ,
the approximation error (or bias) of the class Gk . Note that since the classes {Gk }k are nested, the
estimation error (respectively approximation bias) is non-decreasing (resp. non-increasing) with
respect to k. If one had sharp uniform bounds on these errors, then an appropriate choice of
k would be one that minimizes the sum of these bounds. In Theorem 3.1, we derive an oracle
inequality which shows that PWM selects such a k, in a data-driven fashion. We use this feature
of PWM to derive bounds on maximum regret in two settings of empirical interest.
The first setting we consider is one where G has infinite VC dimension (consider Examples
2.1 and 2.3). In this setting, performing EWM on the whole class G may be undesirable. For
example, the regret may not converge to zero, the rate of convergence may be suboptimal (see
Birgé and Massart, 1993, for such results in a regression context), or it may simply be the case that
maximization over G is computationally difficult. Instead, we apply EWM to an approximating class
Gk , and we allow the complexity of the approximating class to grow as the sample size increases.
We present examples of relevant approximating classes in Examples 3.2 and 3.3 below. In Corollary
3.1 we establish a bound on maximum regret in this setting.
The second setting that we consider is one where the class G has finite but large VC dimension
relative to the sample size. This situation can arise, for instance, in applications where the planner
has a large set of covariates on which to base treatment, and where the feasible allocations are
threshold allocations (see Example 3.1 below). The bound on regret given by (3) increases with
the VC dimension V of G, so that EWM tends to “overfit”’ the data when V is large relative to
the sample size. In such a situation, it may be beneficial to perform EWM in a class G 0 of smaller
VC dimension, resulting in a smaller bound on the estimation error
EP n [WG∗0 − W (ĜEW M )] .
However, this will only be useful if it is also the case that
WG∗ − WG∗0 ,
1

As can be seen from the proofs, the results we present below remain valid even if the sequence {Gk }k is not

nested.

9

is small. Hence we face the same tradeoff between estimation and approximation error that was
noted above. In Corollary 3.2 we specialize Theorem 3.1 to a finite collection of approximating
classes, and then in Corollary 3.3 establish a bound on maximum regret for the PWM rule which
shows that it behaves as if we knew the correct class G 0 to use ex-ante, in the special case where
the optimal allocation for G is contained in G 0 . We then apply these results to select the number
of covariates over which to perform best-subset selection with threshold allocations (see Example
3.1 below).
We consider the following assumption on our sequence of classes, which we call a sieve of G:
Assumption 3.3. The sequence of classes
G1 ⊆ G2 ⊆ G3 ⊆ · · · ⊆ Gk ⊆ · · · ⊆ G
is such that each class Gk has VC dimension Vk , which is finite.2
We illustrate this with some examples:
Example 3.1. Recall the class of threshold allocations introduced in Example 2.2. Let X =
1 to be the threshold allocations on X and G 2 to be the threshold
X1 × X2 ⊂ R2 , and define GX
1
X

allocations on X2 . We can now define the set of two-dimensional threshold allocations on X :
1
2
G = {G ⊂ X : G = G1 × G2 , G1 ∈ GX
and G2 ∈ GX
}.

To make this concrete, suppose that covariates X1 and X2 respectively denote age and income.
Then G contains (for instance) allocations of the type: “receive treatment if age is above x1 and
income is below x2 ” for some x1 and x2 .
With K available covariates, it is straightforward to extend this definition to the class of Kdimensional threshold allocations. For large K, the VC dimension of G can become large relative to
the sample size, and we may want to base treatment only on a smaller subset of the covariates. This
is a variant of the best-subset selection problem, which has been recently studied in the classification
context by Chen and Lee (2016). However, the question still remains as to how many covariates
should be considered (that is, the size of the subset). An interesting sieve sequence for G is given
by the following: let G1 , G2 , G3 be defined as
1
2
G1 = {∅, X } , G2 = (GX
⊗ X2 ) ∪ (X1 ⊗ GX
) , G3 = G ,

where
1
1
2
2
GX
⊗ X2 := {G × X2 : G ∈ GX
}, X1 ⊗ GX
:= {X1 × G : G ∈ GX
}.
2

Kitagawa and Tetenov (2018) additionally assume that their class G is countable so as to avoid potential meas-

urability concerns. We instead choose not to address these concerns explicitly, as is done in most of the literature on
classification. See Van Der Vaart and Wellner (1996) for a discussion of possible resolutions to this issue.

10

The sequence {Gk }3k=1 corresponds to the sequence of threshold allocations that use zero, one and
two covariates respectively (that each class Gk has finite VC dimension follows from the fact a class
of threshold allocations in one dimension has finite VC dimension, and that unions of classes of
finite VC dimension have finite VC dimension, see Dudley, 1999). As we will illustrate below, PWM
will determine in a data-driven way the number of covariates to use for treatment assignment. We
perform a simulation study using this example in Appendix B.
Example 3.2. Recall the class of monotone allocations introduced in Example 2.3. Suppose that
X = [0, 1]2 , so that G has infinite VC dimension (see Györfi et al., 1996, for a proof of this fact). We
will construct a useful sieve for G, where we approximate sets in G with sets that feature monotone,
piecewise-linear boundaries. We proceed in three steps.
First define, for T an integer and 0 ≤ j ≤ T , the following function ψT,j : [0, 1] → [0, 1]:

1 − |T x − j|, x ∈ [ j−1 , j+1 ] ∩ [0, 1]
T
T
ψT,j (x) =
0,
otherwise .
The function ψT,j (·) is simply a triangular kernel whose base shifts with j and is scaled by T . For
example, ψ4,1 (·) is a triangular kernel with base [0, 0.5], and ψ8,1 (·) is a triangular kernel with base
[0, 0.25]. Next, using these functions, we define the following classes Sk :
T
n
o
X
Sk = G : G = {x = (x1 , x2 ) ∈ X |
θj ψT,j (x1 ) + x2 ≥ 0} for θj ∈ R, ∀ 0 ≤ j ≤ T ,
j=0

where T = 2k−1 . These Sk are a special case of what Kitagawa and Tetenov (2018) call generalized
eligibility scores, which, as shown in Dudley (1999), have VC dimension T +2. The intuition behind
the class Sk is that it divides the covariate space into treatment and control such that the boundary
is a piecewise linear curve. Note that by construction it is the case that Sk−1 ⊂ Sk for every k.
Finally, to construct our approximating class Gk , we will modify the class Sk such that we ensure
that the resulting treatment allocations are monotone.
For T an integer, let DT be the following T × (T + 1) differentiation matrix :


−1 1 0 . . . 0 0


 0 −1 1 . . . 0 0


DT :=  .
.
..
.. . .
..
.. 
 ..
.
.
.
.
.


0
0 0 . . . −1 1
Then Gk is defined as follows:
n
o
Gk = G : G ∈ Sk and DT ΘT ≥ 0 , ΘT = [θ0 · · · θT ]0 ,
for T = 2k−1 . Note that the purpose of the constraint DT ΘT ≥ 0 is to ensure that θk − θk−1 ≥ 0 for
all k, which is what imposes monotonicity on the allocations. This construction, which we borrow
11

from Beresteanu (2004), is useful as it imposes monotonicity through a linear constraint, which
is ideal for our implementation. In Section 4, we use of this sequence of approximating classes in
an application to the JTPA study, and then derive bounds on the maximum regret of PWM when
X = [0, 1]2 ; Proposition 4.1 provides a uniform rate at which WG∗k → WG∗ under some additional
regularity conditions, and Corollary 4.1 derives the corresponding bound on maximum G-regret.
Example 3.3. Suppose the planner faces no restrictions on treatment assignment, so that G is the
class of all measurable subsets of X . Recall from Example 2.1 that that the optimal allocation in
this case is given by G∗F B . In this setting it may seem natural to employ the plug-in decision rule:
Ĝplug−in := {x : τ̂ (x) ≥ 0} ,
where τ̂ (·) is a non-parametric estimate of τ (·). Under Assumption 2.1 many non-parametric estimates of τ (·) are well understood. The Penalized Welfare Maximization Rule could provide an
interesting alternative to plug-in rules in this setting by considering a sequence of classes made of
decision trees. Decision trees are popular rules in classification because of their natural interpretability. Intuitively, a decision tree recursively partitions the covariate space in such a way that the
resulting decision rule can be understood as a series of “yes-or-no” questions involving the covariates. Using decision trees for the estimation of causal effects has recently become a popular idea
(see for example Athey and Imbens, 2016; Wager and Athey, 2017). Although we do not explore
decision trees extensively in this paper, in Appendix D we explain how we could accommodate them
in our framework and relate them to recent work on the use of decision trees for treatment assignment, as presented in Kallus (2016) and Athey and Wager (2017). We also provide a preliminary
comparison to plug-in decision rules.
Remark 3.3. Certain applications may suggest a natural (or convenient) choice of sieve {Gk }k ,
either for logistical or computational reasons. For example, the linear construction in Example 3.2
gives rise to a computationally tractable sieve, and the sieve introduced in Example 3.3 produces
an easily interpretable decision rule. On the other hand, we may ask how to construct an optimal
sieve for a given class G and set of regularity conditions on P . In Remark C.2 we suggest such a
possible construction in the special case where G satisfies certain polynomial entropy restrictions.
However, we leave the study of operationalizing such a construction, and the question of optimal
sieve construction in more general problems, to future research.
Given a sieve {Gk }k , let
Ĝn,k := arg max Wn (G) ,
G∈Gk

be the EWM rule in the class Gk . Our goal is to select the appropriate class k ∗ in which to perform
EWM. We do this by selecting the class k ∗ in the following way: for each class Gk , suppose we had
some (potentially data dependent) measure Cn (k) of the amount of “overfitting” that results from
using the rule Ĝn,k (we will be more precise about the nature of Cn (k) in a moment). Given such
12

a measure Cn (k), let {tk }∞
k=1 be an increasing sequence of real numbers, and define the following
penalized objective function:
r
Rn,k (G) := Wn (G) − Cn (k) −

tk
.
n

(5)

Then the penalized welfare maximization rule Ĝn is defined as follows:
Ĝn := Ĝn,k̂∗ ,
where
k̂ ∗ := arg max Rn,k (Ĝn,k ) .
k

In words, the PWM rule selects an allocation which maximizes a penalized version of the empirical
welfare, with the penalty for allocations in Gk given by the term Cn (k) (plus the auxiliary term
p
tk /n).
Remark 3.4. Note that the PWM objective function Rn,k (·) includes the term:

p

tk /n. This

component of the objective is a technical device that is used to ensure that the classes get penalized
at a sufficiently fast rate as k increases. The dependence of the penalty term on the sequence {tk }k
is somewhat undesirable, as it implies that the size of the penalty term for a given class depends
on the location of the class in the sieve, as well as the specific choice of the sequence {tk }k . Ideally,
we would like the penalty term to be completely determined by the class. This technical device
seems−however−unavoidable, and similar terms are pervasive throughout the literature on model
selection in classification: see Koltchinskii (2001), Bartlett et al. (2002), Boucheron et al. (2005),
Koltchinskii (2008). We make three additional comments regarding this term. First, our results
hold for many choices of {tk }∞
k=1 (including our preferred choice tk = k; see the proof of Lemma
A.2 for details), and the choice is reflected explicitly in the bounds that we derive. Second, if one is
only interested in using PWM in settings where the sequence of classes is finite, then we will show
p
in Corollary 3.2 that the tk /n term is not required. Third, from our simulation results, PWM
performs well for the choice tk = k, and its performance is essentially unaffected by this term. For
simplicity, and unless otherwise specified, we will present all of our results with the specific choice
tk = k.
Remark 3.5. As noted by Kitagawa and Tetenov (2018), given a sieve {Gk }k , one can use their
results to derive uniform (w.r.t P(M, κ)) bounds on the estimation error. If one has in addition
uniform bounds on the approximation bias, then one can consider the decision rule Ĝn,k(n) , where
k(n) is constructed to minimize the sum of these bounds. However, the merit of such an approach
would depend on obtaining “good” computable bounds for the estimation and approximation error,
which may be difficult to do in practice. For instance, the uniform bounds on the estimation error
implied by the results of Kitagawa and Tetenov (2018) depend on the VC dimension of the classes
{Gk }k which may be hard to compute or bound in practice. Furthermore, such a deterministic
13

choice of k(n) may lead to suboptimal rates if the true DGP satisfies additional regularity conditions
which may be unknown to the econometrician; for instance, if the true DGP belongs to a much
smaller class P 0 (M, κ) ⊆ P(M, κ), over which the approximation bias (uniformly) decays at a much
faster rate than on P(M, κ), then the original choice of k(n) will be suboptimal. Given these
challenges, PWM displays two advantages. First, As shown in Theorem 3.1 and Corollary 3.1,
PWM will perform−in a data-driven way−the optimal tradeoff between the approximation and
estimation error, without relying on explicit bounds for these quantities. Second, PWM will select
the subclass k̂ over which to perform EWM in a way that adapts to additional “regularities” that
may be satisfied by the true DGP (see Corollary 3.1 below).
Before stating our main results about the G-regret of the PWM rule, we first list some high-level
assumptions on the penalty term Cn (k). In Section 3.3, we will provide some specific examples of
penalties that satisfy these assumptions. In particular, we will show that a standard “hold-out”
procedure can be formalized as a penalty which satisfies our assumptions.
Assumption 3.4. There exist positive constants c0 and c1 such that Cn (k) satisfies the following
tail inequality for every n, k, and for every  > 0:
sup

2

P n (Wn (Ĝn,k ) − W (Ĝn,k ) − Cn (k) > ) ≤ c1 e−2c0 n .

P ∈P(M,κ)

We provide some intuition for this assumption. Given an EWM rule Ĝn,k , the value of the
empirical welfare is given by Wn (Ĝn,k ). From the perspective of G-regret, what we would really
like to know is the value of population welfare W (Ĝn,k ). Although the latter quantity is unknown,
if we could define the (infeasible) penalty Cn (k) as Wn (Ĝn,k ) − W (Ĝn,k ), then the penalized objective Wn (Ĝn,k ) − Cn (k) would be exactly equal to W (Ĝn,k ). Since implementing such a Cn (k) is
impossible, our assumption requires for our feasible penalty to be a good (empirical) upper bound
on Wn (Ĝn,k ) − W (Ĝn,k ). We are now ready to state our main workhorse result: an oracle inequality
that chracterizes the G-regret of the PWM rule.
Theorem 3.1. Suppose that Assumptions 2.1, 3.1, 3.3 and 3.4 hold, and set tk = k in (5). Then
there exist constants ∆ and c0 such that for every P ∈ P(M, κ):
EP n [WG∗

h

− W (Ĝn )] ≤ inf EP n [Cn (k)] +
k

WG∗

−

WG∗k



r i s
k
log(∆e)
+
+
.
n
2c0 n

Theorem 3.1 forms the basis of all the results we present in Sections 3.2 and 3.3. It says that,
at least from the perspective of pointwise (as opposed to maximum) G-regret, the PWM rule is
able to balance the tradeoff between EP n [Cn (k)] and the approximation error, at the cost of adding
√
two additional terms that are O(1/ n). The relative importance of these terms is hard to quantify
at this level of generality, and we will attempt to shed some light on them, for specific penalties,
14

in Section 3.3. Note that this result does not quite accomplish our initial goal of balancing the
estimation and approximation error along our sieve: it is possible to choose a Cn (k) that satisfies
Assumption 3.4 for which EP n [Cn (k)] is too large a bound for the estimation error. For this reason,
we also impose the requirement that any penalty we consider should have the following additional
property:
Assumption 3.5. There exists a positive constant C1 such that, for every n, Cn (k) satisfies
r
Vk
,
sup EP n [Cn (k)] ≤ C1
n
P ∈P(M,κ)
where Vk is the V C dimension of Gk .
This assumption ensures that EP n [Cn (k)] is comparable to the estimation error for EWM
derived in (3), which was shown to be rate-optimal (for the class P(M, κ)) in (4).
The next result we present is a bound on maximum regret for our first setting of interest:
choosing the appropriate approximating class when G has infinite VC dimension. Note that, as discussed in Remark 3.1, a bound on maximum regret may not exist unless we impose some additional
regularity conditions on the family of DGPs under consideration. Hence we make the additional
assumption that we restrict ourselves to a set of distributions Pr for which there exists a uniform
bound on the approximation error. Note however that we do not assume that the rate of decay of
the approximation bias is necessarily known to the econometrician, thus illustrating the “oracle”
nature of our results.
Assumption 3.6. Let Pr be a set of distributions such that
sup WG∗ − WG∗k = O(γk ) ,

P ∈Pr

sup

EP n [Cn (k)] = O(ζ(k, n)) ,

P ∈Pr ∩P(M,κ)

for a sequence γk → 0, and ζ(k, n) non-decreasing in k, ζ(k, n) → 0 as n → ∞.
The first assumption asserts that we have a uniform bound on the approximation error. As
we pointed out in Remark 3.1, an assumption of this type is necessary to derive a bound on
maximum regret when the class G has infinite VC dimension. We present an example of such a
uniform bound for our application in Section 4. The second assumption is made to highlight the
following possibility: although Assumption 3.5 guarantees that we can satisfy this restriction with
p
ζ(k, n) = Vk /n, it is possible that, once we have imposed that P must lie in Pr , an even tighter
bound may exist on Cn (k) (for example, in the classification context, Scott and Nowak, 2006, obtain
a tighter bound on the estimation error in their problem when the covariates are assumed to be
continuous with a bounded density). We make this point to emphasize that PWM will balance the
15

tradeoff between the estimation and approximation error according to the tighest possible bounds
on EP [Cn (K)] and WG∗ − WG∗k , regardless of whether or not we know these bounds for a given
application.
Remark 3.6. A well-known restriction on the class of distributions which may lead to faster
rates ζ(k, n) for certain choices of Cn (k) is the margin assumption (see Kitagawa and Tetenov,
2018, for a formal definition in the context of treatment choice). Roughly, the margin assumption
imposes restrictions on the behavior of τ (·) near zero, and thus allows for faster than root-n rates
of convergence. We leave the study of “margin-adaptive” penalties for future research, for two
reasons. First, to our knowledge, current results exploiting the margin assumption crucially rely
on the assumption that the first-best allocation can be achieved, which we do not maintain in our
paper. Second, the constructions of margin-adaptive penalties developed in the statistical learning
literature may be difficult to implement in practice (see for example the discussion in Arlot et al.,
2011). One notable exception is the hold-out penalty, which is simple to implement and, as argued
by Massart (2007) in the classification context, is margin-adaptive. We introduce this penalty in
Section 3.3 below.
Given Assumption 3.6, we immediately obtain our first corollary:
Corollary 3.1. Under Assumptions 2.1, 3.1, 3.3, 3.4, and 3.6, we have that
r i s
k
log(∆e)
sup
EP n [WG∗ − W (Ĝn )] ≤ inf O(ζ(k, n)) + O(γk ) +
+
.
k
n
2c0 n
P ∈Pr ∩P(M,κ)
h

As mentioned in Remark 3.5, if {ζ(k, n)}k,n and {γk }k were known, then we could achieve such
a result with a deterministic sequence k(n). The strength of the PWM rule then is that we achieve
the same behavior for any class G and approximating sequence {Gk }k without having to know
these quantities in practice. We present an application of this result in Section 4, in the setting of
Example 3.2.
Remark 3.7. It is important to note that for some classes G of infinite VC dimension, there exist
regularity conditions Pr such that the G-regret of EWM converges to zero. In Appendix C we derive
such results under suitable entropy restrictions on the class G, and suitable regularity conditions
on the covariates. In contrast, Corollary 3.1 establishes a bound on the maximum regret of PWM
which holds more generally. We revisit this observation in the discussion which follows Corollary
4.1 below.
The second Corollary we present specializes Theorem 3.1 to our second setting of interest: the
appropriate selection of a subclass when the VC-dimension of G is finite and large (or comparable)
in magnitude to the sample size (for example, when selecting amongst many covariates when
performing best-subset selection). The result highlights two features of PWM. First, it shows that
16

by balancing the trade-off between the approximation and estimation error, PWM can potentially
lead to a reduction in regret (relative to EWM) for values of the sample size that are comparable
in magnitude to the VC-dimension of G. Second, it illustrates how our bound changes when the
p
sieve is finite and we drop the auxiliary k/n component of our penalty.
Corollary 3.2. Suppose that Assumptions 2.1, 3.1, 3.3, 3.4, and 3.5 hold, and that GK = G for
p
some finite K. Furthemore, suppose that in our definition of the penalty we omit the term k/n.
Then we have that
h rV
i
k
∗
EP n [WG − W (Ĝn )] ≤ inf C1
+ WG∗ − WG∗k +
1≤k≤K
n

s

log(Kc1 e)
.
2c0 n

Note that if the above bound is minimized at k = K, then the approximation error WG∗ − WG∗k
is zero and the resulting bound is comparable to the one derived in (3), with one additional term.
In Section 3.3 we argue that for specific choices of the penalty term Cn (k) this additional term is
p
generally smaller than the Vk /n component of the bound.
Our final corollary of Section 3.2 considers the particular setting in which the constrained
optimum WG∗ over the class G is achieved in Gk0 , for some k0 , but that this class is unknown to the
econometrician. The result shows that the resulting upper bound on maximum regret for PWM is
as if we had performed EWM in the appropriate class Gk0 .
Corollary 3.3. Suppose that Assumptions 2.1, 3.1, 3.3, 3.4, and 3.5 hold, and let Pk ⊂ P(M, κ)
be the set of distributions such that G∗ ∈ Gk , then
r
sup EP n [WG∗ − W (Ĝn )] ≤ C1

P ∈Pk

Vk
+
n

r

k
+
n

Furthermore, if {Gk }K
k=1 is finite, and we do not include the

s

log(∆e)
.
2c0 n

p
k/n term as discussed in Remark

3.4, then we have that:
r
sup EP n [WG∗ − W (Ĝn )] ≤ C1

P ∈Pk

Vk
+
n

s

log(Kc1 e)
,
2c0 n

where c0 , c1 are as in Assumption 3.4.

3.3

Penalized Welfare Maximization: Some Examples of Penalties

This section serves two purposes. First, it illustrates the results of Section 3.2 with two concrete
choices for the penalty Cn (k). Second, the results help quantify the size of the auxiliary term in the
bound of Theorem 3.1 for these penalties, so as to address the concerns presented in the discussion
following Theorem 3.1. The first penalty we present, the holdout penalty, is intuitive and is
tractable in applications. However, the holdout penalty involves a sample-splitting procedure. The
17

second penalty, the Rademacher penalty, does not involve sample-splitting but is computationally
burdensome in practice. Both of the penalties share the property that they do not require the
practitioner to know the VC dimensions Vk of the approximating classes, which we feel is important
to make the method broadly applicable.

3.3.1

The Holdout Penalty

The first penalty we introduce is motivated by the following idea: First fix some number ` ∈ (0, 1)
such that m := n(1 − `) (for expositional clarity suppose that m is an integer)3 , and let r := n − m.
Given our original sample Sn = {(Yi , Di , Xi )}ni=1 , let SnE := {(Yi , Di , Xi )}m
i=1 denote what we call
the estimating sample, and let SnT := {(Yi , Di , Xi )}ni=m+1 denote the testing sample. Now, using
SnE , compute Ĝm,k for each k. It seems intuitive that we could get a sense of the efficacy of Ĝm,k by
applying this rule to the subsample SnT and computing the empirical welfare Wr (Ĝm,k ). We could
then select the class k that results in the highest empirical welfare Wr (Ĝm,k ).
It turns out this idea can be formalized in our framework by treating it as a PWM-rule on the
estimating sample, with the following penalty: for each EWM rule Ĝm,k estimated on SnE , let
m

1 X
τi 1{Xi ∈ Ĝm,k } ,
Wm (Ĝm,k ) =
m
i=1

be the empirical welfare of the rule Ĝm,k on SnE and let
Wr (Ĝm,k ) =

n
1 X
τi 1{Xi ∈ Ĝm,k } ,
r
i=m+1

be the empirical welfare of the rule Ĝm,k on SnT . We define the holdout penalty to be
Cm (k) := Wm (Ĝm,k ) − Wr (Ĝm,k ) .
Now, recall that the PWM rule is given by
"

r

Ĝm = arg max Wm (Ĝm,k ) − Cm (k) −
k

which, given the definition of Cm (k), simplifies to
"
Ĝm = arg max Wr (Ĝm,k ) −
k

r

k
m

k
m

#
,

#
.

Hence we see that the PWM rule with the holdout penalty reproduces the intuition presented above
p
(with the usual addition of the k/m term; see Remark 3.4).
We check the conditions of Assumptions 3.4 and 3.5:
3

The results would continue to hold if one were to instead define m := bn(1 − `)c.

18

Lemma 3.1. Assume Assumptions 2.1, 3.1, 3.3. Suppose we have a sample of size n and recall
that m = n(1 − `) and r = n − m. Let Cm (k) be the holdout penalty as defined above. Then we
have that

and



 κ 2
n`2 ,
P n (Wm (Ĝm,k ) − W (Ĝm,k ) − Cm (k) > ) ≤ exp − 2
M
r
M
Vk
EP n [Cm (k)] ≤ C p
,
κ (1 − `) n

where C is the same universal constant that appears in equation (3).
With Lemma 3.1 established, Theorem 3.1 becomes:
Proposition 3.1. Assume Assumptions 2.1, 3.1, 3.3. Suppose we have a sample of size n, and let
m = n(1 − `), r = n − m. Let Cm (k) be the holdout penalty as defined above. Then we have that
for every P ∈ P(M, κ):
EP n [WG∗

h

− W (Ĝm )] ≤ inf EP n [Cn (k)] +
k

WG∗

−

WG∗k

with
M

EP n [Cn (k)] ≤ C p
κ (1 − `)



r i
r
M
k
1
+ g(M, κ, `) √
,
+
n
n
κ `

r

Vk
,
n

where C is the same universal constant as that in equation (3) and
s
r e M 
.
g(M, κ, `) := 2 log
2` κ
As we will see in the next section, the bound in Proposition 3.1 is similar to what we will
derive for the Rademacher penalty, but with larger constants, which reflect the fact that we split
the sample. However, a major benefit of the holdout penalty lies in the fact that it is much more
practical to implement. The only remaining issue with the holdout penalty is how to split the data.
Deriving some sort of data-driven procedure to choose the proportion ` is beyond the scope of our
paper, but as a rule of thumb, we have found that it is much more important to focus on accurate
estimation of the rule Ĝm,k than on the computation of Wr (Ĝm,k ). In other words, we recommend
that the estimating sample SnE be a large proportion of the original sample Sn . Throughout the
rest of the paper we designate three quarters of the sample as the estimating sample.

3.3.2

The Rademacher Penalty

The second penalty we present is attractive in that it does not introduce sample splitting, but may
be computationally burdensome when compared to the holdout procedure. Let Sn := {(Yi , Di , Xi )}ni=1
be the observed data. Then the Rademacher penalty is given by
n
h
i
2X
Cn (k) = Eσ sup
σi τi 1{Xi ∈ G} | Sn ,
G∈Gk n
i=1

19

where τi is defined as in equation (2), and {σ1 , ..., σn } are a sequence of i.i.d Rademacher variables,
i.e. they take on the values {−1, 1}, each with probability half.
To clarify the origin of this penalty, recall that Cn (k) must be a good upper bound on Wn (Ĝn,k )−
W (Ĝn,k ), which is the requirement of Assumption 3.4. Bounding such quantities is common in the
study of empirical processes, and the usual first step is to use what is known as symmetrization,
which gives the following bound:
n
h 
i
2X
σi τi 1{Xi ∈ G} | Sn .
EP n [sup Wn (G) − W (G)] ≤ EP n Eσ sup
G∈G
G∈G n
i=1

It is thus this inequality that inspires the definition of Cn (k). The concept of Rademacher complexity4 is pervasive throughout the statistical learning literature (see for example Bartlett et al., 2002;
Bartlett and Mendelson, 2002; Koltchinskii, 2001). Intuitively, it measures a notion of complexity
that is finer than that of VC dimension, and is at the same time computable from the data at hand.
Furthermore, it allows both the objective function and the penalty to be estimated with all of the
data.
First we prove that the conditions of Assumptions 3.4 and 3.5 hold for the Rademacher penalty:
Lemma 3.2. Consider Assumptions 2.1, 3.1, 3.3. Let Cn (k) be the Rademacher penalty as defined
above. Then we have that

 κ 2 
n2 ,
P n (Wn (Ĝn,k ) − W (Ĝn,k ) − Cn (k) > ) ≤ exp − 2
3M
and

r
M Vk
EP n [Cn (k)] ≤ C
,
κ
n
where C is the same universal constant that appears in equation (3).
We are thus able to refine Theorem 3.1 to the case of the Rademacher penalty.
Proposition 3.2. Consider Assumptions 2.1, 3.1, 3.3. Let Cn (k) be the Rademacher penalty as
defined above. Then we have that for every P ∈ P(M, κ):
EP n [WG∗

h

− W (Ĝn )] ≤ inf EP n [Cn (k)] +

with EP n [Cn (k)] ≤ C M
κ

k

q

Vk
n ,

WG∗

−

WG∗k



r i
r
k
M 1
+
+ g(M, κ)
,
n
κ n

where C is the same universal constant as that in equation (3) and
 3√e M 
log √
.
2 κ

s
g(M, κ) := 6
4

Note that the definition of Rademacher complexity is slightly different than the definition of our penalty. Here

we follow Bartlett et al. (2002) and do not include the absolute value in our definition of the penalty.

20

Remark 3.8. We can now revisit the discussion following Theorem 3.1, about quantifying the size
of the constants in the auxiliary term of our bounds. In Appendix D we perform a back-of-theenvelope calculation that provides insight into the size of g(M, κ), and compares it to the size of
the universal constant C derived in Kitagawa and Tetenov (2018). Performing the same analysis
for the holdout penalty, we see that sample-splitting introduces distortions into the constant terms
through `. Indeed, the tradeoff between splitting the sample into the estimating sample and testing
sample is reflected precisely in the constants.
Despite this penalty being theoretically appealing, implementing it in practical applications is
problematic. The standard approach suggested in the statistical learning literature is to compute
Cn (k) by simulation: first, we repeatedly draw samples of {σi }ni=1 , then we solve the problem
n

2X
max
σi τi 1{Xi ∈ G} ,
G∈Gk n
i=1

for each draw, and then average the result. Unfortunately, the optimization problem to be solved
in the second step is computationally demanding for most classes Gk of interest, so that repeatedly
solving it for multiple draws of {σi }ni=1 is impractical. Moreover, this procedure must be repeated
for each class Gk , which makes it even more prohibitive.

3.4

Penalized Welfare Maximization: Estimated Propensity Score

In this section we present a modification of the PWM rule where the propensity score is not known
and must be estimated from the data. This situation would arise if the planner had access to observational data instead of data from a randomized experiment. Before describing our modification
of the PWM rule, we must review results about the corresponding modification of the EWM rule
in Kitagawa and Tetenov (2018). The modification we consider here is what they call the e-hybrid
EWM rule. Recall the EWM objective function as defined in equation (2). To define the e-hybrid
EWM rule we modify this objective function by replacing τi with
τ̂i :=

hYD
Yi (1 − Di ) i
i i
−
1{n ≤ ê(Xi ) ≤ 1 − n } ,
ê(Xi )
1 − ê(Xi )

where ê(·) is an estimator of the propensity score, and n is a trimming parameter such that
n = O(n−α ) for some α > 0. The e-hybrid EWM objective function is defined as follows:
n

Wne (G) :=

1X
τ̂i 1{Xi ∈ G} .
n
i=1

Since we are now estimating the propensity score, we must impose additional regularity conditions on P to guarantee a uniform rate of convergence. We make a high level assumption:

21

Assumption 3.7. Given an estimator ê(·), let Pe be a class of data generating processes such that
sup EP n

n
h1 X

P ∈Pe

n

i
|τ̂i − τi | = O(φ−1
n ) ,

i=1

where φn → ∞.
Although we do not explore low-level conditions that satisfy this assumption here, Kitagawa
and Tetenov (2018) do so in their paper. To summarize their results, they show that if ê(·) is a local
polynomial estimator, and that e(·) and the marginal distribution of X satisfy some smoothness
conditions, then Assumption 3.7 is satisfied with φn = n
determines the smoothness of

− n+d1 /β
x

e

, where βe is a constant that

e(·).5

Let Ĝe−hybrid be the solution to the e-hybrid problem in a class G of finite VC dimension, then
Kitagawa and Tetenov (2018) derive the following bound on maximum G-regret:

sup

E

Pn

P ∈Pe ∩P(M,κ)

h
i
∗
−1/2
WG − W (Ĝe−hybrid ) ≤ O(φ−1
).
n ∨n

With a non-parametric estimator of e(·), φn will generally be slower than

√

(6)

n and hence determine

the rate of convergence. In a recent paper, Athey and Wager (2017) argue that more sophisticated
estimators of the welfare objective can improve performance relative to the e-hybrid rule, and derive
corresponding bounds on the maximum regret of their procedure. Importantly, by exploiting an
√
orthogonal moments construction, the procedure in Athey and Wager (2017) converges at a nrate even when the propensity score is estimated non-parametrically. Modifying our method using
their techniques would be an interesting direction for future work.
We are now ready to present the construction of the corresponding e-hybrid PWM estimator.
Let G be an arbitrary class of allocations, and let {Gk }k be some approximating sequence for G.
Let Ĝen,k be the hybrid EWM rule in the class Gk . Let Cne (k) be our penalty for the hybrid PWM
rule. We now require that the penalty satisfies the following properties:
Assumption 3.8. (Assumptions on Cne (k))
In addition to making assumptions about Cne (k), we assume there exists an “infeasible penalty”
C̃n (k) with the following properties:
• There exist positive constants c0 and c1 such that C̃n (k) satisfies the following tail inequality
for every n, k and for every  > 0:
sup
P ∈Pe ∩P(M,κ)
5

2

P n (Wn (Ĝen,k ) − W (Ĝen,k ) − C̃n (k) > ) ≤ c1 e−2c0 n

To be more precise, βe is the degree of the Holder class to which e(·) must belong.

22

• There exists a positive constant C1 such that, for every n, C̃n (k) satisfies
r
Vk
sup
EP n [C̃n (k)] ≤ C1
,
n
P ∈Pe ∩P(M,κ)
where Vk is the VC dimension of Gk .
• C̃n (k) and Cne (k) are such that

sup
P ∈Pe ∩P(M,κ)

EP n sup
k

Cne (k)


− C̃n (k)

= O(φ−1
n ) .

We will provide context for these assumptions. First of all, included in the assumptions on
Cne (k)

is the existence of an object C̃n (k) which we call an infeasible penalty. The first assumption

asserts that the infeasible penalty obeys a similar tail inequality to Cn (k), which was the penalty
when the propensity score was known. The main difference is that C̃n (k) satisfies this assumption
with respect to the e-hybrid EWM rule, and not the EWM rule with a known propensity. What
is strange about this condition is that it is as if we were evaluating the hybrid rule through the
empirical objective Wn (·), which is the objective when the propensity score is known. This is our
motivation for calling C̃n (k) an infeasible penalty. Luckily, C̃n (k) is purely a theoretical device and
does not serve a role in the actual implementation of PWM. We provide an example of such an
infeasible penalty in the setting of the holdout penalty below.
The second assumption is the same as Assumption 3.5, but now with respect to the infeasible
penalty C̃n (k). The third assumption simply links the true penalty Cne (k) to the infeasible penalty
C̃n (k) in such a way that both should agree asymptotically and do so at an appropriate rate.
Given this, we obtain the following analogue to Theorem 3.1:
Theorem 3.2. Given assumptions 2.1, 3.1, 3.3, 3.7 and 3.8, there exist constants ∆ and c0 such
that for every P ∈ Pe ∩ P(M, κ):
h

EP n [WG∗ − W (Ĝen )] ≤ inf EP n [C̃n (k)] + WG∗ − WG∗k
k



s
r i
k
log(∆e)
+
+ O(φ−1
.
n )+
n
2c0 n

As we can see, the only difference between this bound and the bound derived in Theorem 3.1 is
that there is an additional term of order φ−1
n . This is also the case with the hybrid EWM estimator,
as shown in (6).
Next, we check that the conditions in Assumption 3.8 are satisfied with a modified version of
the holdout penalty (the results for the Rademacher penalty follow similarly). Recall from Section
3.3 that the holdout method splits the sample Sn = {(Yi , Di , Xi )}ni=1 into the estimating sample
T
n
SnE = {(Yi , Di , Xi )}m
i=1 of size m = n(1 − `) and the testing sample Sn = {(Yi , Di , Xi )}i=m+1 of

size r = n − m. The holdout penalty was then defined as
Cm (k) = Wm (Ĝm,k ) − Wr (Ĝm,k ) ,
23

where Wm (·) was the empirical welfare computed on SnE and Wr (·) was the empirical welfare
computed on SnT .
To define the hybrid holdout penalty, let êE (·) be the propensity estimated on SnE , and let êT (·)
be the propensity estimated on SnT . Define
m

e
Wm
(G)

1 X E
:=
τˆi 1{Xi ∈ G} ,
m
i=1

where
τˆi E =

h YD
Yi (1 − Di ) i
i i
−
1{n ≤ êE (Xi ) ≤ 1 − n } .
êE (Xi ) 1 − êE (Xi )

Define Wre (G) on the testing sample analogously. Letting Ĝem,k be the hybrid EWM rule computed
on the estimating sample in the class Gk , the hybrid holdout penalty is defined as:
e
e
Cm
(k) := Wm
(Ĝem,k ) − Wre (Ĝem,k ) .

We can now check the conditions of Assumption 3.8 for the hybrid holdout penalty. To do so,
we must assert the existence of an infeasible penalty C̃m (k) that satisfies our assumptions. The
infeasible penalty we consider is given by
C̃m (k) := Wm (Ĝem,k ) − Wr (Ĝem,k ) ,
where Wm (·) and Wr (·) are defined as in Section 3.3, that is, they are computed as if the propensity
score were known. We present the following lemma:
Lemma 3.3. Assume Assumptions 2.1, 3.1, 3.3, and 3.7. Suppose we have a sample of size n and
e (k) be the hybrid holdout penalty and C̃ (k) be the
recall that m = n(1 − `) and r = n − m. Let Cm
m

infeasible penalty as defined above. Then we have that

 κ 2

P n (Wm (Ĝem,k ) − W (Ĝem,k ) − C̃m (k) > ) ≤ exp − 2
n`2 ,
M
r
M
Vk
EP n [C̃m (k)] ≤ C p
,
κ (1 − `) n
and


e
sup EP n sup |Cm
(k) − C̃m (k)| = O(φ−1
n ) ,

P ∈Pe

k

where C is the same universal constant as that in equation (3).
We thus obtain an analogous result to Proposition 3.1 for PWM with the hybrid holdout penalty.

24

4

An Application using Monotone Allocations

In this section we apply the PWM rule to the sieve we constructed in Example 3.2 for monotone
allocations. First, we apply our method to experimental data from the Job Training Partnership
Act (JTPA) Study. Then, we derive bounds on maximum regret in a setting where our class has
infinite VC dimension.
The JTPA study was a randomized controlled trial whose purpose was to measure the benefits
and costs of employment and training programs. The study randomized whether applicants would
be eligible to receive a collection of services provided by the JTPA related to job training, for a
period of 18 months. The study collected background information about the applicants prior to
the experiment, as well as data on applicants’ earnings for 30 months following assignment (for a
detailed description of the study, see Bloom et al., 1997).6
We revisit the setup in Kitagawa and Tetenov (2018), which has frequently been considered in
recent related papers. The outcome that we consider is total individual earnings in the 30 months
following program assignment. The covariates on which we define our treatment allocations are
the individual’s years of education and their earnings in the year prior to the assignment. The set
of allocations we consider is the set of monotone allocations defined in Example 2.3, but with a
non-increasing monotone function. To be precise, let X1 be the covariate set of years of education,
and let X2 be the covariate set of previous earnings, then the set of allocations we consider is given
by:

G = G : G = {(x1 , x2 ) ∈ X | x2 ≤ f (x1 ) for f : X1 → X2 non-increasing} .
Let us discuss what this set of allocations means in the context of this application. This restriction
imposes that, the less education you have, the more accessible is the program based on your previous
earnings. For example, if an applicant with 12 years of education and previous earnings of $20,000
is to be accepted into the program, then an applicant with the same previous earnings and less
education must also be accepted, as well as an applicant with the same level of education and less
earnings. In Example 2.3 we discussed a situation where application-specific assumptions impose
this type of constraint. In this setting, we instead argue that it is plausible that such a restriction
may be exogenously imposed on the planner for political reasons; after all, it may not be politically
viable to implement a job-training program where only those with high levels of education or income
are accepted.
The approximating sequence we consider is the one described in Example 3.2, but now with
a non-increasing monotonicity constraint. Recall that this was a sequence such that the resulting
6

The sample we use is the same as that in Abadie et al. (2013),

which we downloaded from

ideas.repec.org/c/boc/bocode/s457801.html. We supplemented this dataset with education data from the expbif.dta
dataset available at the W.E. Upjohn Institute website. Observations with years of education coded as ‘99’ were
dropped.

25

allocations partitioned the covariate space with a progressively refined, piecewise-linear, monotone
boundary. Given any fixed class in this sequence, we can perform EWM in that class. For example,
Figure 1 below illustrates the result of performing EWM on the simplest class in the approximating
sequence. This class is equivalent to the class of linear treatment rules from Kitagawa and Tetenov
(2018), but with an additional slope constraint.

Figure 1: The resulting treatment allocation from performing EWM in G1 .
Each point represents a covariate pair in the sample. The region shaded in green (dark) is the
prescribed treatment region, the region shaded in red (light) is the prescribed control region.
At the other end of the spectrum, we could consider performing EWM in the most complicated
class in our approximating sequence: this class corresponds to allocations that stipulate a threshold
for previous income at every level of education (note that such a class exists here because years of
education is discrete with finite support). Figure 2 below illustrates the result of performing EWM
in this class.
As we can see, the resulting allocation in the simplest class and in the most complicated class
look quite different, and given the option to choose any class from our sequence, it is not obvious
which one should be chosen given the size of the experiment. Given that we have a finite sieve in
this application, we can view the use of PWM in this context through the lenses of Corollaries 3.2
26

Figure 2: The resulting treatment allocation from performing EWM in G5 .
Each point represents a covariate pair in the sample. The region shaded in green (dark) is the
prescribed treatment region, the region shaded in red (light) is the prescribed control region.
or 3.3. In Figure 3, we illustrate the result of performing PWM on our sequence of classes, where
we used 3/4 of our sample for estimation. In Appendix D.1 we discuss the computational details of
our implementation. Note that PWM selects the allocation from the second class in our sequence,
which corresponds to a piecewise-linear allocation with one possible “kink”.
Next, we derive a bound on maximum regret in the setting where X = [0, 1]2 , so that our class
has infinite VC dimension. Recall from Remark 3.1 that, if the class G has infinite VC dimension,
then we cannot establish a bound on maximum regret without imposing additional regularity
conditions. Accordingly, we will first establish some regularity conditions under which we derive a
bound on maximum regret for the PWM rule:
Assumption 4.1. Let Pr be a set of DGPs such that there exists some constant A > 0, where for
every distribution in Pr , the marginal distribution of X = (X1 , X2 ) can be decomposed as follows:
Z
PX (M1 × M2 ) =
PX1 |x2 (M1 )dPX2 ,
M2

27

Figure 3: The resulting treatment allocation from performing PWM on the approximating
sequence {Gk }5k=1 . Each point represents a covariate pair in the sample. The region shaded in
green (dark) is the prescribed treatment region, the region shaded in red (light) is the prescribed
control region.
where M1 and M2 are measurable subsets of [0, 1], and PX1 |x2 is continuous with density bounded
above by A, for all x2 ∈ [0, 1].
In words, Assumption 4.1 requires that the conditional distribution of X1 given X2 is continuous
with a uniformly bounded density. It is worth emphasizing that we do not require the first best
to be contained in G, nor do we require that WG∗ even be attained. With this regularity condition
imposed, we are able to derive the following uniform bound on the approximation bias WG∗ − WG∗k :
Proposition 4.1. Under Assumption 4.1, the approximation bias of the approximating sequence
{Gk }∞
k=1 from Example 3.2 satisfies
sup
P ∈Pr ∩P(M,κ)

WG∗ − WG∗k ≤ A

M −k
2 ,
κ

To illustrate the use of Proposition 4.1 in our setting, we derive a bound on maximum regret
28

for monotone allocations. Proposition 4.1 and Corollary 3.1, along with the bound on Vk given in
Example 3.2 allow us to conclude that:
Corollary 4.1. Let Cn (k) be the Rademacher or holdout penalty. Under Assumptions 2.1, 3.1,
3.3, and 4.1, we have that
sup
P ∈Pr ∩P(M,κ)

1
EP n [WG∗ − W (Ĝn )] = O n− 3 .

Corollary 4.1 establishes a polynomial rate of convergence for PWM. In contrast, we are not
aware of any results which would allow us to derive a bound on maximum regret for EWM (or
other related methods which do not employ a sieve construction) under Assumption 4.1.
In Appendix C, we derive a series of results (which may be of independent interest) which show
that under the stronger assumption that X is continuous with a bounded density, EWM in fact
achieves a root-n rate (up to a log factor) in this example, and that this rate is optimal. As we
explain in Remark C.3, PWM also achieves the same optimal rate of convergence in this setting
(at least when using the holdout penalty), which would not be the case for a deterministic k(n)
chosen to obtain the rate derived in Corollary 4.1. This further reinforces the observation made in
Remark 3.5 about the adaptation of PWM to additional regularities.

29

A

Proofs of Main Results

Recall that the planner’s objective function is given by



YD
Y (1 − D)
W (G) = EP
−
· 1{X ∈ G} .
e(X)
1 − e(X)

(7)

To each treatment allocation G ∈ G we associate a function fG : R × X × {0, 1} → R defined by:


YD
Y (1 − D)
fG (Z) = fG (Y, X, D) =
−
· 1{X ∈ G} ,
e(X)
1 − e(X)
where Z = (Y, X, D). Let F := {fG : G ∈ G} denote the corresponding set of functions associated to decision
rules in G. By (7), any optimal allocation in G solves



YD
Y (1 − D)
∗
G ∈ arg max EP
−
· 1{X ∈ G} .
G∈G
e(X)
1 − e(X)
Equivalently, functions associated to optimal allocations solve
f ∗ ∈ arg max EP f (Z) .
f ∈F

By an abuse of notation, for G ∈ G, we set
W (fG ) = EP fG (Z) .
Given an approximating sequence {Gk }k of classes of treatment allocations, let {Fk }k denote the sequence
of associated classes of functions.
The following lemma, whose proof is given in Kitagawa and Tetenov (2018) (Lemma A.1), establishes
the relevant link between the classes of sets {Gk }k and the classes of functions {Fk }k . It shows that if a
class G has finite VC dimension, then the associated class F is a VC-subgraph class with dimension bounded
above by that of G.
Lemma A.1. Let G be a VC-class of subsets of X with finite VC dimension V . Let g be a function from
Z := R × X × {0, 1} to R. Then the set of functions F defined by
F = {g(z) · 1{x ∈ G} : G ∈ G}
is a VC-subgraph class with dimension at most V .
For each k ≥ 1, let fˆn,k be a maximizer of the empirical welfare over the class Fk ; that is:
fˆn,k = arg max Wn (f ) ,
f ∈Fk

and for f ∈ Fk , define the complexity-penalized estimate of welfare by
r
k
.
Rn,k (f ) = Wn (f ) − Cn (k) −
n
The PWM rule fˆn,k̂ is then chosen such that
k̂ = arg max Rn,k (fˆn,k ) .
k≥1

30

In what follows, we set fˆn := fˆn,k̂ and Rn (fˆn ) := Rn,k̂ (fˆn,k̂ ).
To bound the regret, we decompose it as follows

 

WF∗ − W (fˆn ) = WF∗ − Rn (fˆn ) + Rn (fˆn ) − W (fˆn ) .

(8)

The following lemma yields (under Assumption 3.4) a subgaussian tail bound for the second term on the
right hand side of the preceding equality.
Lemma A.2. Given Assumption 3.4, there exists a positive constant ∆ (that does not depend on n) such
that:
P (Rn (fˆn ) − W (fˆn ) > ) ≤ ∆e−2co n

2

for every n.
Proof. First note that:



P (Rn (fˆn ) − W (fˆn ) > ) ≤ P sup Rn,k (fˆn,k ) − W (fˆn,k ) >  ,
k

then by the union bound:

 X

P sup Rn,k (fˆn,k ) − W (fˆn,k ) >  ≤
P (Rn,k (fˆn,k ) − W (fˆn,k ) > ) .
k

k

Now by definition of Rn,k , we have
r
X

P (Rn,k (fˆn,k ) − W (fˆn,k ) > ) =

X

k

P Wn (fˆn,k ) − Cn (k) − W (fˆn,k ) >  +

k

k
.
n

By Assumption 3.4,
r
X

P (Wn (fˆn,k ) − W (fˆn,k ) − Cn (k) >  +

√k 2
X
2 X
k
)≤
c1 e−2co n(+ n ) ≤ e−2co n
c1 e−2kco .
n
k

k

k

By setting
∆ :=

X

c1 e−2kco < ∞ ,

(9)

k

the result follows.
Proof of Theorem 3.1. We follow the general strategy from Bartlett et al. (2002). For every k, we have

 
(10)
WF∗ − W (fˆn ) = WF∗ − WF∗k + WF∗k − W (fˆn ) .
We first consider the second term in (10), and expand it as follows

 

WF∗k − W (fˆn ) = WF∗k − Rn (fˆn ) + Rn (fˆn ) − W (fˆn ) .
By the definition of Rn , the first term of expression (11) is bounded by
r
WF∗k

− Rn (fˆn ) ≤

WF∗k

− Wn (fˆn,k ) + Cn (k) +

31

k
.
n

(11)

Fix δ > 0, and choose some fk∗ ∈ Fk such that W (fk∗ ) + δ ≥ WF∗k .7 . We have
r
WF∗k

− Wn (fˆn,k ) + Cn (k) +

k
≤ W (fk∗ ) + δ − Wn (fk∗ ) + Cn (k) +
n

r

k
.
n

Taking expectations of both sides and letting δ converge to 0 yields
r
k
∗
ˆ
E[WFk − Rn (fn )] ≤ E[Cn (k)] +
.
n
By Lemma A.2 and a standard integration argument (see for instance problem 12.1 in Györfi et al., 1996),
the second term on the right hand side of (11) is bounded by
s
E[Rn (fˆn ) − W (fˆn )] ≤

log(∆e)
.
2co n

Combining these bounds yields
s
E[WF∗

− W (fˆn )] ≤ E[Cn (k)] +

WF∗

−

WF∗k

+

log(∆e)
+
2co n

r

k
,
n

for every k, and our result follows.
Proof of Lemma 3.2. We first establish the inequality

κ 2
P (Wn (fˆn,k ) − W (fˆn,k ) − Cn (k) > ) ≤ exp −2n2 (
)
.
3M

(12)

By two standard symmetrization arguments, we get
n






1X
E sup Wn (f ) − W (f ) ≤ 2E sup
σi f (Zi ) = E Cn (k) ,
f ∈Fk
f ∈Fk n i=1


where we recall that Cn (k) = E 2 supf ∈Fk

1
n

Pn

i=1

(13)


σi f (Zi )|Z1 , Z2 , · · · , Zn and {σi }ni=1 is an i.i.d sequence

of Rademacher random variables independent from the data {Zi }ni=1 . Note that
P (Wn (fˆn,k ) − W (fˆn,k ) − Cn (k) > ) ≤ P ( sup ((Wn (f ) − W (f )) − Cn (k) > ) ,
f ∈Fk

and set Mn,k := supf ∈Fk (Wn (f ) − W (f )) − Cn (k). Combining the preceding inequality with (13) yields
P (Wn (fˆn,k ) − W (fˆn,k ) − Cn (k) > ) ≤ P (Mn,k − EMn,k > ) .
To control the deviations of Mn,k from its mean, we use McDiarmid’s inequality (see Györfi et al., 1996,
Theorem 9.2; note that Mn,k satisfies the bounded difference property with increments bounded by

3M
nκ )

which yields the inequality

κ 2
P (Mn,k − EMn,k > ) ≤ exp −2n2 (
)
,
3M
from which our result follows.
7

If the welfare criterion achieves its maximum on Fk , then fk∗ can be set equal to any maximizer. In general

however such an optimum may not exist, and thus we must choose fk∗ will to be an ”almost maximizer” of the welfare
criterion on Fk .

32

The second inequality (where C is a universal constant)
r
M Vk
E[Cn (k)] ≤ C
,
κ
n
follows from a chaining argument and a control on the universal entropy of VC subgraph classes (see for
instance the proof of Lemma A.4 in Kitagawa and Tetenov, 2018), along with Lemma A.1.
Proof of Lemma 3.1. Let us assume for notational simplicity that the quantity m = n(1 − `) is an integer.
We first establish the inequality

κ 
P (Wm (fˆm,k ) − W (fˆm,k ) − Cm (k) > ) ≤ exp −2n`2 ( )2 .
M
By the definition of Cm (k), we have

(14)

P (W (fˆm,k ) − W (fˆm,k ) − Cm (k) > ) = P (Wr (fˆm,k ) − W (fˆm,k ) > ) .
Now, working conditionally on {Zi }m
i=1 , we get by Hoeffding’s inequality that


2 κ 2
P (Wr (fˆm,k ) − W (fˆm,k ) > |{Zi }m
)
.
i=1 ) ≤ exp −2n` (
M
Since the right hand side of the preceding inequality is non random, the inequality holds unconditionally as
well.
We now establish the inequality
M
E[Cm (k)] ≤ C p
κ (1 − `)

r

Vk
.
n

By the definition of Cm (k), we have
E[Cm (k)] = E[Wm (fˆm,k ) − Wr (fˆm,k )] = E[Wm (fˆm,k ) − W (fˆm,k ) + W (fˆm,k ) − Wr (fˆm,k )] .
Note that by the law of iterated expectations, we have
E[W (fˆm,k ) − Wr (fˆm,k )] = 0 ,
and by Lemma A.4 in Kitagawa and Tetenov (2018) combined with Lemma A.1 there exists some universal
constant C such that:
M
E[Wm (fˆm,k ) − W (fˆm,k )] ≤ C
κ
Since m = (1 − `)n, the result follows.

r

Vk
.
m

Proof of Propositions 3.2 and 3.1. From the inequality
e−x
1
≤ ,
(1 − e−x )
x
and from (9) and (12), we derive that

∆ ≤ 1/2

3M
κ

2



2

.

Similarly, we derive from (9) and (14) that
∆ ≤ 1/(2l)

M
κ

.

The results then follow by substituting these into the inequalities of Theorem 3.1.

33

Proof of Theorem 3.2. Our strategy here is to proceed analogously to the proof of Theorem 3.1 with
some additional machinery. Let fˆe and Re (·) be defined analogously to the case when the propensity score
n

n

is known. For every k, we have that:

 
WF∗ − W (fˆne ) = WF∗ − WF∗k + WF∗k − W (fˆne ) .

(15)

Adding and subtracting Rne (fˆne ) to the last term yields

 

WF∗k − W (fˆne ) = WF∗k − Rne (fˆne ) + Rne (fˆne ) − W (fˆne ) .

(16)

Let fk∗ := arg maxf ∈Fk W (f ) , (if the supremum is not achieved, apply the argument to a δ-maximizer of
the welfare, and let δ tend to zero). Now consider the first term on the right hand side of (16). Expanding
yet again gives
WF∗k − Rne (fˆne ) = WF∗k − Wn (fk∗ ) + Wn (fk∗ ) − Rne (fˆne ) .

(17)

From the definition of Rne , we have
r
Wn (fk∗ )

−

Rne (fˆne )

≤

Wn (fk∗ )

−

Wne (fk∗ )

+

Cne (k)

+

n

k
1X
|τ̂i − τi | + Cne (k) +
≤
n
n i=1

r

k
.
n

Hence, considering the above inequality and taking expectations in (17) yields
r
n
i
h1 X
k
e
∗
e ˆe
|τ̂i − τi | + E[Cn (k)] +
E[WFk − Rn (fn ))] ≤ E
,
n i=1
n
and thus by Assumption 3.7
r
e
E[WF∗k − Rne (fˆne ))] ≤ O(φ−1
n ) + E[Cn (k)] +

k
.
n

(18)

We now consider the second term on the right hand side of (16). Let k̂ be the class k such that
e
fˆne = fˆn,
.
k̂

Note that k̂ is random. We have
s
e
Rne (fˆne ) − W (fˆne ) = Wne (fˆn,
) − Cne (k̂) −
k̂

k̂
e
− W (fˆn,
).
k̂
n

e
By adding and subtracting Wn (fˆn,
) and the function C̃n (k̂), we get
k̂

r
e
Wne (fˆn,
)
k̂





−

Cne (k̂)

−

k
e
)=
− W (fˆn,
k̂
n





e
ˆe ) + C̃n (k̂) − C e (k̂) + Wn (fˆe ) − W (fˆe ) − C̃n (k̂) −
Wne (fˆn,
)
−
W
(
f
n
n
k̂
n,k̂
n,k̂
n,k̂

Note again that
n

1X
e
e
sup Wne (fˆn,k
) − Wn (fˆn,k
) ≤
|τ̂i − τi | ,
n i=1
k

34

s


k̂ 
.
n

(19)

and so by Assumptions 3.7 and 3.8, the first two terms of (19) are of order O(φ−1
n ) in expectation. By the
first part of Assumption 3.8, and an argument similar to the one used in the proof of Lemma A.2, it can be
shown that
r

h

e
e
E sup Wn (fˆn,k
) − W (fˆn,k
) − C̃n (k) −
k

s

k i
≤
n

log(∆e)
,
2c0 n

where ∆ and co are the same constants that appear in A.2. We thus get
r
log(∆e)
e ˆe
e
−1
.
E[Rn (fn ) − W (fˆn )] ≤ O(φn ) +
2m

(20)

Now combining (18) and (20), we conclude that
r
E[WF∗k

e
− W (fˆne )] ≤ O(φ−1
n ) + E[Cn (k)] +

r

log(∆e)
.
2m

r

r

k
+
n

Finally, by Assumption 3.8, we get
E[WF∗

∗
∗
− W (fˆne )] ≤ O(φ−1
n ) + E[C̃n (k)] + WF − WFk +

k
+
n

log(∆e)
,
2m

for all k, and hence the result follows.
Proof of Lemma 3.3. In what follows, we verify that the third condition of Assumption 3.8 is satisfied for
the holdout and Rademacher penalties with estimated propensity scores, as the first two conditions follow
from previous arguments. In the case of the holdout penalty, we can set
e
e
C̃m (k) = Wm (fˆm,k
) − Wr (fˆm,k
).

Note that since the propensity score is unknown, the empirical welfare criteria Wm and Wr are infeasible.
It can easily be shown that for this choice of C̃m (k), we have
|C̃m (k) −

e
Cm
(k)|

m
n
1 X E
1 X
≤
|τˆi − τi | +
|τˆi T − τi | ,
m i=1
r i=m+1

which yields
e
E sup C̃m (k) − Cm
(k) = O(φ−1
n ) .
k≥1

For the Rademacher penalty,
"
C̃n (k) = Eσ

n

1X
2 sup
σi f (Zi )|Z1 , Z2 , · · · , Zn
f ∈Fk n i=1

#
,

which is the infeasible Rademacher penalty that depends on the unknown propensity score, then it can be
shown that

"
|C̃n (k) −

Cne (k)|

≤ Eσ

n

2X
|τ̂i − τi | Z1 , Z2 , · · · , Zn
n i=1

#

Since the right hand side does not depend on k, we conclude that
E sup C̃n (k) − Cne (k) ≤ 2E
k≥1

n
X
i=1

by Assumption 3.7.

35

|τˆi − τi | = O(φ−1
n ) ,

.

Next, we prove Proposition 4.1.
Proof of Proposition 4.1. . Let G be the set of monotone allocations. Let πk denote the partition of
[0, 1] formed by the points xi = i/2k , i = 0, · · · , 2k . Let {Gk }k be the approximating sequence defined in
Example 3.2, and define G∗ ∈ G to be a set such that W (G∗ ) = WG∗ (if no such G∗ exists, the argument
proceeds by considering an “almost maximizer”). By definition, for each G ∈ G, there is an associated
function bG : [0, 1] → [0, 1] which determines the boundary of the allocation region, that is, such that
G = {(x1 , x2 ) ∈ X : x2 ≤ bG (x1 )}.
Fix some P ∈ Pr , where Pr is as defined in Assumption 4.1. By definition,
WG∗ − WG∗k ≤ W (G∗ ) − W (G̃k ) ,
where G̃k ∈ Gk is the allocation such that bG̃k (·) is the linear interpolation of bG∗ on the partition πk . We
can re-write this as


∗

W (G ) − W (G̃k ) = E

Y (1 − D)
YD
−
e(X)
1 − e(X)

 

∗
· 1{X ∈ G } − 1{X ∈ G̃k }
(21)

M
PX (G∗ ∆G̃k ) ,
≤
κ
where ∆ denotes the symmetric difference operator, A∆B := A\B ∪ B\A. Let
Mi = [xi−1 , xi ] × [bG∗ (xi−1 ), bG∗ (xi )] ,

for i = 1, . . . , 2k . It follows from the monotonicity of bG∗ that the graphs of the restrictions of bG∗ (·) and
bG̃k (·) to [xi−1 , xi ] are contained in Mi . Hence we have that
k

∗

PX (G ∆G̃k ) ≤

2
X

k

PX (Mi ) =

i=1

2
X

PX (M1i × M2i ) ,

i=1

where M1i = [xi−1 , xi ], M2i = [bG∗ (xi−1 ), bG∗ (xi )]. By Assumption 4.1,
Z
1
PX (M1i × M2i ) =
PX1 |x2 (M1i )dPX2 ≤ k APX2 (M2i ) .
2
M2i
Summing over i:
k

2
X

k

2
X
1
A
PX (Mi ) ≤
APX2 (M2i ) ≤ k ,
k
2
2
i=1
i=1

since the {M2i }i form a partition of [0, 1]. We thus obtain that
WG∗ − WG∗k ≤ A

M −k
2 ,
κ

as desired.

B

A Simulation Study

In this section we perform a small simulation study to highlight the ability of the PWM rule to reduce G-regret
in an empirically relevant setting. We consider a situation where the planner has access to threshold-type

36

allocations over five covariates, as described in Examples 2.2 and 3.1, and wishes to perform best-subset
selection. The sieve sequence we consider is the same as in Example 3.1, where Gk is the set of threshold
allocations on k − 1 out of the 5 covariates. For example, G1 contains only the allocations G = ∅ and G = X ,
which correspond to threshold allocations that use zero covariates, G2 contains all threshold allocations on
one out of the five covariates, etc. We focus here on the setting with five covariates for computational
simplicity, but recent work by Chen and Lee (2016) suggests that solving this problem with ten or more
covariates could be feasible in practice.
The problem that the planner faces is choosing how many covariates to use in the allocation: for example
suppose that the distribution P is such that some of the available covariates are irrelevant for assigning
treatment. Of course, the planner could perform EWM on all the covariates at once, and by the bound in
equation (3) this is guaranteed to produce small regret in large enough samples. However, if the sample is
not large, the planner may be able to achieve a reduction in regret by performing PWM. Through the lens
of Corollary 3.3, our results say that PWM should behave as if we had performed EWM in the smallest
class Gk that contains all of the relevant covariates.
We consider the following data generating process: Let X = [0, 1]5 , and
Xi = (X1i , X2i , ..., X5i ) ∼ (U [0, 1])5 .
The potential outcomes for unit i are specified as:
Yi (1) = 50(2X2i − (1 − X1i )4 − 0.5 + 0.5(X3i − X4i )) + U1i ,
Yi (0) = 50(0.5(X3i − X4i )) + U2i ,
where U1 and U2 are distributed as U [−80, 80] random variables which are independent of each other and
of X. The covariates enter the potential outcomes in three different ways:
• X5i is an irrelevant covariate; it does not play a role in determining potential outcomes at all.
• X3i and X4i affect both treatment and control equally; there will be a nonzero correlation between
the observed outcome Yi and these covariates, but they serve no purpose for treatment assignment.
• X1i and X2i do serve a purpose for assigning treatment, and both are used in the optimal threshold
allocation. See Figure 4 below.
Finally, the propensity score P (D = 1|X) is specified to be constant at 0.2.
To implement PWM we used the holdout penalty, with 3/4 of our sample designated as the estimating
sample. In Appendix D.1 we explain in detail how to implement PWM as a mixed integer linear program.
Our results compare the G-regret of the PWM rule against the regret of performing EWM in G6 (which
corresponds to the class that uses all five covariates) or performing EWM in G3 computed using 1000 Monte
Carlo iterations. Recall that G3 is the smallest class that contains the optimal threshold allocation. In light
of Corollary 3.3, we would hope that PWM behaves similarly to doing EWM in G3 directly. In Figure 5, we
plot the regret of these rules for various sample sizes.
First we comment on the regret of performing EWM in G6 (recall that this corresponds to the set of
allocations using all five covariates) vs. performing EWM in G3 (which corresponds to the set of allocations

37

Figure 4: Shaded in green: the best threshold-allocation for our design. Second-best welfare: 21.3
Traced in black: the boundary of the first-best allocation.
that use two of the five covariates). As we would expect, regret decreases as sample size increases. Moreover,
performing EWM in G6 results in larger regret at every sample size: performing EWM in G3 results in a 34%
improvement in regret relative to EWM in G6 on average, across the sample sizes we consider.
Next, we comment on the performance of PWM. As we had hoped, the regret of PWM is smaller than
the regret of performing EWM in G6 at every sample size: performing PWM results in a 19.8% improvement
in regret relative to EWM in G6 on average, across the sample sizes we consider.

C

Welfare Maximization with Entropy Restrictions on G

In this section we study the treatment choice problem when certain entropy restrictions are imposed on
G. First we derive an upper bound on the maximum regret of EWM under assumptions on the bracketing
entropy of G:
Throughout this section let X = [0, 1]dx . Given a class of sets G of X , let H := {1G : G ∈ G}. Let
|| · ||p be the Lp (µ) metric on H, where µ is Lebesgue measure on X . Given h1 , h2 ∈ H, with h1 ≤ h2 , let
[h1 , h2 ] := {h ∈ H : h1 ≤ h ≤ h2 }. We call the set [h1 , h2 ] a bracket. Given  > 0, define NpB (, H, µ) to be
U
L
U
U
L
the smallest k such that for some pairs (hL
j , hj ), j = 1, ..., k ∈ H, with hj ≤ hj and ||hj − hj ||p < ,

H⊂

k
[

U
[hL
j , hj ] .

j=1

We call HpB (, H, µ) := log N1B (, H, µ) the Lp (µ) bracketing entropy in the sense of Alexander.

38

Figure 5: Estimated regret by sample size. Optimal (second-best) welfare: 21.3. EWM5
corresponds to G6 (five covariates), EWM2 corresponds to G3 (two covariates).
Remark C.1. When we say “in the sense of Alexander” we mean that H1B (, H, µ) is defined as the
bracketing entropy where the bracketing functions must be members of H, as is done in Alexander (1984).
This is in contrast to the more standard definition where this is not the case. As explained below this will
not be an issue in the case of monotone allocations and many other cases of interest, but may be a relevant
restriction in other contexts.
Given this definition, we impose the following assumption on the bracketing entropy of G:
Assumption C.1. There exist positive constants K, r for which
H1B (, H, µ) ≤ K−r ,
for all  > 0.
Dudley (1999) provides many examples for which this assumption holds. In particular, if G is the set of
monotone allocations in [0, 1]dx , then Assumption C.1 holds with r = dx − 1 (and an inspection of his proof
shows that the brackets can be constructed in the sense of Alexander).

39

As we have emphasized throughout the paper, to obtain bounds on maximum regret for classes of infinite
VC dimension, we must impose additional regularity conditions on the DGP. To that end, we consider the
following assumption:
Assumption C.2. Let Pr be a set of DGPs such that there exists some constant A > 0, where for every
distribution in Pr , the distribution of X is continuous with density bounded above by A.
With this additional regularity condition, we obtain the following upper bound on maximum regret for
EWM:
Proposition C.1. Under Assumptions 2.1, 3.1, C.1, and C.2, we have that
EP n [W (G∗ ) − W (ĜEW M )] = O(τ (n)) ,

sup
P ∈Pr ∩P(M,κ)

√
where τ (n) = n−1/2 if r < 1, τ (n) = log(n)/ n if r = 1, and τ (n) = n−1/(1+r) if r > 1.
Note that this result does not assume that the first-best allocation is contained in G. From Proposition
C.1 we see that for r sufficiently small, EWM converges at a parametric rate (under suitable regularity
conditions). Similar results have been obtained in the classification context by Mammen et al. (1999) and
Tsybakov (2004).
Next, we present a lower-bound on maximum regret under the following assumption on the L1 (µ) capacity:
Given  > 0, define Dp (, H, µ) to be the largest k such that there exist functions h1 , ...hk ∈ H with
||hi − hj ||p >  for i 6= j. We call Hp (, H, µ) := log Dp (, H, µ) the Lp (µ) epsilon-capacity.
Given this definition, we impose the following assumption on the -capacity of G:
Assumption C.3. There exist positive constants K1 , K2 , 1 > 0, r ≥ 1 such that
K2 −r ≤ H1 (, H, µ) ≤ K1 −r ,
for all 0 <  ≤ 1 .
It can be shown that if G satisfies Assumption C.1, then the upper bound in Assumption C.3 will also
hold. However, the reverse may not be true. Dudley (1999) provides many examples for which Assumption
C.3 holds, and in particular it holds for the set of monotone allocations in [0, 1]dx with r = dx − 1.
With this assumption we obtain the following lower bound on maximum regret:
Proposition C.2. Let P ∗ (µ) ⊂ P(M, κ) be the set of DGPs such that the marginal distribution of X is µ,
and G∗ = G∗F B . Under Assumption C.3, there exists a positive constant B (which depends on M , K1 , K2 ,
r), such that
inf

sup

EP n [W (G∗ ) − W (Ĝ)] ≥ Bn−1/(1+r) ,

Ĝ P ∈P ∗ (µ)

for all n ≥ 1.

40

Remark C.2. Under Assumption C.3 we obtain a very natural construction of a sieve-sequence for G: Let
C̄1 , C̄2 be positive constants, and let Nn be a n covering of G such that
n = C̄1 n−1/(1+r) ,
and
log |Nn | ≤ C̄2 −r
n .
We conjecture that performing PWM on the resulting sieve-sequence could achieve the rate established in
Proposition C.2 under appropriate regularity conditions, at least for r ≥ 1 (Audibert, 2004, establishes a
similar result in the classification context). Operationalizing such a construction could be an interesting
direction for future research.
For classes G such that Assumptions C.1 and C.3 both hold, Propositions C.1 and C.2 immediately imply
the following rate optimality result for EWM:
Corollary C.1. Given Assumptions C.1, C.2, and C.3, EWM is rate-optimal over Pr ∩ P(M, κ) for r > 1
and rate-optimal up to a log factor for r = 1.
Proof. This follows immediately from the fact that P ∗ (µ) ⊂ Pr ∩ P(M, κ), and hence
inf

sup

EP n [W (G∗ ) − W (Ĝ)] ≥ inf

sup

EP n [W (G∗ ) − W (Ĝ)] .

Ĝ P ∈P ∗ (µ)

Ĝ P ∈Pr ∩P(M,κ)

As we remarked above, for the set of monotone allocations on [0, 1]2 , Assumptions C.1 and C.3 hold with
r = 1. Hence we can conclude that EWM is rate-optimal up to a log-factor for monotone allocations when
the distribution of X is continuous with a bounded density. Note that Corollary C.1 only establishes rate
optimality when r is sufficiently large. For r < 1, the lower bound presented in Proposition C.2 is certainly
too loose: the set of DGPs used in the proof of Proposition C.2 impose a “hard margin”, and hence converge
much faster than the parametric rate when r < 1.
Remark C.3. It can be shown that the PWM procedure implemented as in Section 4 also achieves the rate
established in Corollary C.1 (up to a log factor). To see why, note that by using arguments similar to those
used in the proof of Propositions C.1, it can be shown that

sup

E[Cm (k)] = O

P ∈Pr ∩P(M,κ)

log(n)
√
n


,

where Cm (k) is the holdout penalty. Combining this result with Proposition 4.1 and Corollary 3.1 we get
that the maximum regret of PWM is bounded above by (up to constants),
r !
log(n)
k
−k
√
+ inf 2 +
,
k
n
n
whose rate of convergence is dominated by the leading term.

41

References
Abadie, Alberto, Matthew M Chingos, and Martin R West (2013), “Endogenous stratification in
randomized experiments.” Technical report, National Bureau of Economic Research.
Alexander, Kenneth S (1984), “Probability inequalities for empirical processes and a law of the
iterated logarithm.” The Annals of Probability, 12, 1041–1067.
Arlot, Sylvain, Peter L Bartlett, et al. (2011), “Margin-adaptive model selection in statistical
learning.” Bernoulli, 17, 687–713.
Armstrong, Timothy and Shu Shen (2015), “Inference on optimal treatment assignments.”
Athey, Susan and Guido Imbens (2016), “Recursive partitioning for heterogeneous causal effects.”
Proceedings of the National Academy of Sciences, 113, 7353–7360.
Athey,

Susan

and

Stefan

Wager

(2017),

“Efficient

policy

learning.”

arXiv preprint

arXiv:1702.02896.
Audibert, J-Y (2004), “Classification under polynomial entropy and margin assumptions and randomized estimators.”
Audibert, Jean-Yves, Alexandre B Tsybakov, et al. (2007), “Fast learning rates for plug-in classifiers.” The Annals of statistics, 35, 608–633.
Bartlett, Peter L (2008), “Fast rates for estimation error and oracle inequalities for model selection.”
Econometric Theory, 24, 545–552.
Bartlett, Peter L, Stéphane Boucheron, and Gábor Lugosi (2002), “Model selection and error
estimation.” Machine Learning, 48, 85–113.
Bartlett, Peter L and Shahar Mendelson (2002), “Rademacher and gaussian complexities: Risk
bounds and structural results.” Journal of Machine Learning Research, 3, 463–482.
Beresteanu, Arie (2004), “Nonparametric estimation of regression functions under restrictions on
partial derivatives.” Technical report, Duke University, Department of Economics.
Bertsimas, Dimitris, Angela King, Rahul Mazumder, et al. (2016), “Best subset selection via a
modern optimization lens.” The Annals of Statistics, 44, 813–852.
Beygelzimer, Alina and John Langford (2009), “The offset tree for learning with partial labels.”
In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and
data mining, 129–138, ACM.
Bhattacharya, Debopam and Pascaline Dupas (2012), “Inferring welfare maximizing treatment
assignment under budget constraints.” Journal of Econometrics, 167, 168–196.
42

Birgé, Lucien and Pascal Massart (1993), “Rates of convergence for minimum contrast estimators.”
Probability Theory and Related Fields, 97, 113–150.
Bloom, Howard S, Larry L Orr, Stephen H Bell, George Cave, Fred Doolittle, Winston Lin, and
Johannes M Bos (1997), “The benefits and costs of jtpa title ii-a programs: Key findings from
the national job training partnership act study.” Journal of human resources, 549–576.
Blundell, Richard, Amanda Gosling, Hidehiko Ichimura, and Costas Meghir (2007), “Changes in
the distribution of male and female wages accounting for employment composition using bounds.”
Econometrica, 75, 323–363.
Boucheron, Stéphane, Olivier Bousquet, and Gábor Lugosi (2005), “Theory of classification: A
survey of some recent advances.” ESAIM: probability and statistics, 9, 323–375.
Boucheron, Stéphane, Gábor Lugosi, and Pascal Massart (2013), Concentration inequalities: A
nonasymptotic theory of independence. Oxford university press.
Chamberlain, Gary (2011), “Bayesian aspects of treatment choice.” The Oxford Handbook of
Bayesian Econometrics, 11–39.
Chen, Le-Yu and Sokbae Lee (2016), “Best subset binary prediction.” arXiv preprint
arXiv:1610.02738.
Dehejia, Rajeev H (????), “Program evaluation as a decision problem.” Journal of Econometrics,
125.
Dudley, Richard M (1999), Uniform central limit theorems, volume 23. Cambridge Univ Press.
Geer, Sara A (2000), Empirical Processes in M-estimation, volume 6. Cambridge university press.
Györfi, L, L Devroye, and G Lugosi (1996), A probabilistic theory of pattern recognition. SpringerVerlag.
Hirano, Keisuke and Jack R Porter (2009), “Asymptotics for statistical treatment rules.” Econometrica, 77, 1683–1701.
Imbens, Guido W (2004), “Nonparametric estimation of average treatment effects under exogeneity:
A review.” Review of Economics and statistics, 86, 4–29.
Kallus, Nathan (2016), “Learning to personalize from observational data.” arXiv preprint
arXiv:1608.08925.
Kasy, Maximilian (2014), “Using data to inform policy.” Technical report.
Kitagawa, Toru and Aleksey Tetenov (2018), “Who should be treated? empirical welfare maximization methods for treatment choice.” Econometrica, 86, 591–616.
43

Kock, Anders Bredahl and Martin Thyrsgaard (2017), “Optimal sequential treatment allocation.”
Koltchinskii, V (2008), “Oracle inequalities in empirical risk minimization and sparse recovery
problems: Lecture notes.” Technical report, Technical report, Ecole d’ete de Probabilités de
Saint-Flour, 2008. 12.6.
Koltchinskii, Vladimir (2001), “Rademacher penalties and structural risk minimization.” IEEE
Transactions on Information Theory, 47, 1902–1914.
Lugosi, Gábor and Marten Wegkamp (2004), “Complexity regularization via localized random
penalties.” Annals of Statistics, 1679–1697.
Mammen, Enno, Alexandre B Tsybakov, et al. (1999), “Smooth discrimination analysis.” The
Annals of Statistics, 27, 1808–1829.
Manski, Charles F (2004), “Statistical treatment rules for heterogeneous populations.” Econometrica, 72, 1221–1246.
Massart, Pascal (2007), “Concentration inequalities and model selection.”
Massart, Pascal and Élodie Nédélec (2006), “Risk bounds for statistical learning.” The Annals of
Statistics, 34, 2326–2366.
Qian, Min and Susan A Murphy (2011), “Performance guarantees for individualized treatment
rules.” Annals of statistics, 39, 1180.
Rai, Yoshiyasu (2018), “Statistical inference for treatment assignment policies.”
Schlag, Karl H (2007), “Eleven% designing randomized experiments under minimax regret.” Un%
published manuscript, European University Institute.
Scott, Clayton and Robert Nowak (2002), “Dyadic classification trees via structural risk minimization.” In Advances in Neural Information Processing Systems, 359–366.
Scott, Clayton and Robert D Nowak (2006), “Minimax-optimal classification with dyadic decision
trees.” IEEE transactions on information theory, 52, 1335–1353.
Stoye, Jörg (2009), “Minimax regret treatment choice with finite samples.” Journal of Econometrics, 151, 70–81.
Stoye, Jörg (2012), “Minimax regret treatment choice with covariates or with limited validity of
experiments.” Journal of Econometrics, 166, 138–156.
Swaminathan, Adith and Thorsten Joachims (2015), “Batch learning from logged bandit feedback
through counterfactual risk minimization.” Journal of Machine Learning Research, 16, 1731–
1755.
44

Tetenov, Aleksey (2012), “Statistical treatment choice based on asymmetric minimax regret criteria.” Journal of Econometrics, 166, 157–165.
Todd, Petra E and Kenneth I Wolpin (2003), “On the specification and estimation of the production
function for cognitive achievement.” The Economic Journal, 113, F3–F33.
Tsybakov, Alexandre B (2004), “Optimal aggregation of classifiers in statistical learning.” Annals
of Statistics, 135–166.
Van Der Vaart, Aad W and Jon A Wellner (1996), “Weak convergence.” In Weak Convergence and
Empirical Processes, 16–28, Springer.
Vapnik, Vladimir N and Alexey J Chervonenkis (1974), “Theory of pattern recognition.”
Viviano,

Davide (2019),

“Policy targeting under network interference.” arXiv preprint

arXiv:1906.10258.
Wager, Stefan and Susan Athey (2017), “Estimation and inference of heterogeneous treatment
effects using random forests.” Journal of the American Statistical Association.
Zadrozny, Bianca (2003), “Policy mining: Learning decision policies from fixed sets of data.”
Zhao, Yingqi, Donglin Zeng, A John Rush, and Michael R Kosorok (2012), “Estimating individualized treatment rules using outcome weighted learning.” Journal of the American Statistical
Association, 107, 1106–1118.

45

D

Supplementary Appendix (for online publication)

D.1

Computational Details

In this section we provide details on how we perform the computations of Section 4 and Appendix B. All of
our work is implemented in Python paired with Gurobi. We begin with Section 4, then proceed to Appendix
B.

D.1.1

Application Details

First we describe how to compute each Ĝn,k to solve PWM over monotone allocations. Recall the definition
of ψT,j (x) as defined in Example 3.2. We modify this definition to accommodate the fact that our covariates
do not lie in the unit interval. In particular, we restrict ourselves to levels of education that lie in the interval
[5, 20], which leads to the following modification.

1 − | T (x − 5) − j|, x ∈  j−1 + 5, j+1 + 5 ∩ [5, 20]
15
T /15
T /15
ψT,j (x) =
0,
otherwise .
h
Let ΘT = θ0

θ1

···

θT

i0

h
and let Θ̄T = −1

θ0

θ1

···

i0
θT . Let our two dimensional covariate

be denoted as x = (x(1) , x(2) ) where x(1) is level of education and x(2) is previous earnings. Let
h
ΨT (x) = x(2)

ψT,0 (x(1) ) · · ·

i0
ψT,T (x(1) ) .

To compute Ĝn,k we solve the following mixed integer linear program (MILP), which modifies the MILP
described in Kitagawa and Tetenov (2018) for “Single Linear Index Rules”:
max

θ0 ,θ1 ,...,θT ,
z1 ,...,zn

subject to

n
X

τi · zi

i=1

Θ̄0 ΨT (xi )
Θ̄0T ΨT (xi )
< zi ≤ T
+ 1, i = 1, . . . , n
ciT
ciT
zi ∈ {0, 1}, i = 1, . . . , n
DT ΘT ≤ 0

where T = 2k−1 , τi is as defined in equation (2), cT is an appropriate constant (to be discussed in the following
sentence), and DT is the differentiation matrix as defined in Example 3.2. ciT is a constant chosen such that
ciT > supΘT |Θ̄0T ΨT (xi )|, which allows us to formulate a set of what are known as “big-M” constraints. To
implement such a constraint it must necessarily be the case that ΘT is bounded, so in order to implement
PWM we also include an implicit (very large) bound on the possible treatment allocations.8
8

Big-M constraints have the potential to cause numerical instabilities when solving MILPs that are poorly formu-

lated. We found that it was important to ensure that the covariates are scaled to within the same order of magnitude
and that the IntFeasTol and FeasibilityTol parameters in Gurobi were set to their smallest possible values.

46

The first two sets of constraints impose that the treatment allocation result in a piecewise linear boundary,
the third set of constraints impose that this boundary is monotone. The strength of this formulation is that
it imposes monotonicity via a linear constraint, which allows us to solve the problem as a MILP.

D.1.2

Simulation Details

We describe a MILP to compute each Ĝn,k over threshold allocations on d covariates. Define x to be a (d+1)dimensional vector where x = (1, x(1) , x(2) , ..., x(d) ), with the last d components denoting the d covariates,
and suppose x ∈ [0, 1]d+1 , which is the case in the simulation design. We define the threshold βk on covariate
x(k) to be a (d + 1)-dimensional vector such that the first component is in [−1, 1], all other components other
than the (k + 1)st are zero, and the (k + 1)st component is one of {−1, 0, 1}. Let A = {1, 2, ..., d} index the
dimension of the threshold. We modify the MILP described in Kitagawa and Tetenov (2018) for “Multiple
Linear Index Rules”:

max

{βa }a∈A ,
a
∗
{z1a ,...,zn
}a∈A ,z1∗ ,...,zn

subject to

n
X

τi · zi∗

i=1

x0i βa
x 0 βa
< zia ≤ i + 1, i = 1, . . . , n, a ∈ A
c
c
X
1 X a
a
1 − |A| +
zi ≤ zi∗ ≤
zi , i = 1, . . . , n
|A|
a∈A

βa(1)

a∈A

∈ [−1, 1], a ∈ A

βa(j) = 0, j > 1, j 6= a + 1, a ∈ A
X
ea = k
a∈A

− ea ≤ βa(1) ≤ ea , a ∈ A
βa(a+1) = ya,1 − ya,2 , a ∈ A
ya,1 + ya,2 = ea , a ∈ A
{zia }a∈A , zi∗ ∈ {0, 1}, i = 1, . . . , n
{ea }a∈A ∈ {0, 1}, a ∈ A
{ya,1 }a∈A , {ya,2 }a∈A ∈ {0, 1}, a ∈ A
The constraints serve the following roles: the first two constraints enforce the assignment of observations
to treatment, the next two constraints enforce part of the structure of the threshold allocation, the fifth
constraint specifies that only k thresholds can be used, and the three subsequent constraints enforce this.
Again we require an appropriately chosen constant c to implement a set of big-M constraints, but in this
case the choice is straightforward: c = d + 2 will suffice since this guarantees that c > x0i βa for any possible
xi and βa , by construction.
Remark D.1. Solving the above program for the simulation design of Appendix B with a sample size of
2000 took approximately one hour and fifteen minutes on a 2018 iMac. In practice, the solution of this

47

MILP could potentially be further optimized using the improvements developed in Bertsimas et al. (2016)
and Chen and Lee (2016).

D.2
D.2.1

Supplementary Results
Supplement to Example 2.3

We work through the claim of Example 2.3 in detail. Suppose the outcomes of interest to the planner are
described by
Y (k) = g(k, A) − 1{k = 1}c ,
where A is an unobserved measure of a student’s ability, and c is the per-unit cost of the scholarship to the
planner. Let
h(a) := g(1, a) − g(0, a) .
Suppose the planner has two covariates X = (Z, T ), on which to base treatment, where Z is parental income
and T is a student’s GPA. Define
Z
τ (t, z) := E[h(A)|Z = z, T = t] =

h(a)dFA|Z,T (a|z, t) ,

to be the average treatment effect (ignoring costs) conditional on Z = z, T = t (note that if we consider
Assumption 3.1 then h(A) has finite support, which guarantees the existence of τ ). The unrestricted optimal
allocation is given by
G∗F B := {(z, t) : τ (z, t) ≥ c} .
We claimed in Example 2.3 that some plausible assumptions about h(·) and (A, T, Z) could give rise to an
optimal allocation which is monotone, as defined in Example 2.3.
First, the planner makes the following assumption on h(·):
Assumption D.1. h(a) is increasing in a.
This assumption asserts that the function g has increasing differences, which is a common assumption
made in economics when doing comparative statics analysis. Intuitively, it says that higher ability students
will realize a larger difference in outcomes if they receive the scholarship than lower ability students.
Next, the planner makes the following assumptions about the conditional distribution of (A|Z, T ):
Assumption D.2. (FOSD of A in (Z,T))
• FA|Z,T (·|z, t) F OSD FA|Z,T (·|z, t0 ) for t ≥ t0
• FA|Z,T (·|z, t) F OSD FA|Z,T (·|z 0 , t) for z ≤ z 0
Stochastic-dominance assumptions of this type have been employed by, for example, Blundell et al. (2007)
in the study of wage distributions. Intuitively, Assumption D.2 asserts that, given a fixed level of parental
income, a higher GPA is an indication of higher innate ability, and that given a fixed GPA, lower levels of

48

parental income are an indication of higher innate ability. An assumption of this type could come out of a
production function for cognitive achievement, for example as studied in Todd and Wolpin (2003).
Given these assumptions, we can show that τ (z, t) ≥ τ (z, t0 ) if t ≥ t0 , and τ (z, t) ≥ τ (z 0 , t) if z ≤ z 0 . This
follows by the fact that, for an increasing function f (·) and two distributions G1 and G2 , such that G1 first
order stochastically dominates G2 , it is the case that
Z
Z
f dG1 ≥ f dG2 .
This establishes that the first best allocation is indeed monotone.

D.2.2

Supplement to Example 2.1

We elaborate on the example introduced in Example 2.1. We construct an approximating sequence that
results in what Scott and Nowak (2002) call a dyadic decision tree. From now on assume it is the case that
X = [0, 1]d . First, we define a sequential dyadic partition (SDP). Let {R1 , R2 , ..., Rk } be a partition of the
the covariate space where each Ri is a hyper-rectangle with sides parallel to the co-ordinate axes. Given a cell
(1,j)

Ri , let Ri

(2,j)

and Ri

be the hyper-rectangles formed by splitting Ri at its midpoint along the co-ordinate

j. A SDP is defined recursively as follows:
• The trivial partition {[0, 1]d } is a SDP
• If {R1 , R2 , ..., Rk } is a SDP, then so is
(1,j)

{R1 , ..., Ri−1 , Ri

(2,j)

, Ri

, Ri+1 , ..., Rk } ,

where 1 ≤ i ≤ k and 1 ≤ j ≤ d.
In words, a SDP is formed by recusively splitting a hyper-cube at its midpoint on some coordinate. A
dyadic decision tree (DDT) with k splits is a SDP with k partitions, paired with a {0, 1} label for each
hyper-rectangle in the SDP. Given a DDT Tk with k splits, let G(Tk ) be the set of covariate points in X
such that those covariates are labeled with a 1 in Tk . Our approximating class is defined as follows:

Gk = {G ⊂ X : G = G(Tk ) for some DDT Tk with k splits} .
It follows by results in Scott and Nowak (2002) that Gk has finite VC dimension. Given this approximating sequence, the PWM procedure can be applied to choose the appropriate DDT. In other words, our
method could be used to choose the appropriate depth of a decision tree. Kallus (2016) develops Optimal
Personalization Trees, which solve a similar problem for a given class Gk , i.e. for trees of a fixed depth.
Athey and Wager (2017) use decision trees with a fixed depth as a primary motivating example for their
method, and derive a bound on the Hamming entropy of the class of fixed-depth decision trees without the
dyadic-split assumption we present here.
We expect that under appropriate regularity conditions we could derive bounds on the maximum regret
of this version of PWM with respect to the unrestricted optimum. The first question one might ask is how
the bounds on maximum regret of PWM with this approximating sequence would compare to the bounds on

49

maximum regret that exist for plug-in rules. As discussed in Kitagawa and Tetenov (2018), if the plug-in rule
is implemented with appropriate local-polynomial estimators, and smoothness conditions on the regression
functions E(Y (d)|X = x) are imposed, a bound on maximum regret can be derived. On the other hand,
as explained in Audibert et al. (2007) in the context of classification, although results for plug-in rules
typically require assumptions on smoothness of the regression functions, the analogues to our approach in
classification typically require regularity conditions on the boundary of the decision set G∗F B . In this sense,
a comparison of the regularity conditions for plug-in rules and PWM-type rules would suggest that they are
complementary approaches.

D.2.3

Supplement to Remark 3.2

The demeaned EWM rule is defined as follows: Let Yidm := Yi − En [Yi ], then the demeaned EWM rule solves
the following problem:

max En
G∈G


Yidm Di
Yidm (1 − Di )
1{Xi ∈ G} +
1{Xi ∈ G} .
e(Xi )
1 − e(Xi )

In Figures 6, 7, 8, we reproduce the exercise of Section 4. What is interesting to note is that PWM
selects the fourth class in the sequence when using the demeaned version, whereas PWM selected the second
class in the sequence for the original problem.

50

Figure 6: The resulting treatment allocation from performing demeaned EWM in G1 .
Each point represents a covariate pair in the sample. The region shaded in green (dark) is the
prescribed treatment region, the region shaded in red (light) is the prescribed control region.

51

Figure 7: The resulting treatment allocation from performing demeaned EWM in G5 .
Each point represents a covariate pair in the sample. The region shaded in green (dark) is the
prescribed treatment region, the region shaded in red (light) is the prescribed control region.

52

Figure 8: The resulting treatment allocation from performing demeaned PWM on the
approximating sequence {Gk }5k=1 . Each point represents a covariate pair in the sample. The
region shaded in green (dark) is the prescribed treatment region, the region shaded in red (light)
is the prescribed control region.

D.2.4

Supplement to Remark 3.8

In this subsection we provide some simple calculations that justify the comments made in Remark 3.8.
Consider first the Rademacher penalty, then Proposition 3.1 shows that
r i
r
h M rV

k
M 1
k
∗
∗
∗
EP n [WG − W (Ĝn )] ≤ inf C
+ W G − WG k +
+ g(M, κ)
,
k
κ
n
n
κ n
where C is the universal constant derived in the bound of EWM in Kitagawa and Tetenov (2018) and g is
defined as

s
g(M, κ) := 6

 3 √e M 
.
log √
2 κ

Our first task is to quantify the size of C. By the proof of Lemma A.4. in Kitagawa and Tetenov (2018), we
can see that the constant C depends on a universal constant K derived in Theorem 2.6.7 of Van Der Vaart
and Wellner (1996), which establishes a bound on the covering numbers of a VC subgraph class. Inspection
of the proof in Van Der Vaart and Wellner (1996) allows us to conclude that a suitable K is given by

53

√
K = 3 e/8. Plugging this in to the expression for C derived in Kitagawa and Tetenov (2018) allows us to
conclude that a suitable C is given by C = 36.17. Turning to g(M, κ), we can calculate that in order for it
to surpass C by an order of magnitude, we would need M/κ to be about as large as 10120 . This give us a
sense of the relative sizes of the terms in our bound.

D.3

Proofs for Appendix C

Proof for Proposition C.1
Proof. We follow the general strategy of Mammen et al. (1999). Let W̄ (·) = (κ/M )W (·) be a normalized
version of W (·). Let G∗ be a maximizer of W̄ (·) in G. Let P = Pr ∩ P(M, κ) and define
Tn =

√ W̄ (G∗ ) − W̄ (Ĝ) − (W̄n (G∗ ) − W̄n (Ĝ))
n
,
qn

where qn = 1 if r < 1, qn = log(n) if r = 1 and qn = n(r−1)/2(r+1) if r > 1. By the definition of Ĝ, and G∗
we have that W̄n (Ĝ) ≥ W̄n (G∗ ), W̄ (Ĝ) ≤ W̄ (G∗ ), and hence we have that

√ −1 
nqn W̄ (G∗ ) − W̄ (Ĝ) ≤ Tn .
Now we argue that E[Tn ] is uniformly bounded over P for n sufficiently large, which given the definition of
qn implies the statement of the theorem. To that end, note that
E[Tn ] ≤ E[Sn ] ,
where
Sn = sup
G∈G

= sup
G∈G

√

√

nqn−1 |W̄ (G∗ ) − W̄ (G) − (W̄n (G∗ ) − W̄n (G))|

n

nqn−1

1X
(ḡ(Zi )(1{Xi ∈ G∗ } − 1{Xi ∈ G}) − E[ḡ(Zi )(1{Xi ∈ G∗ } − 1{Xi ∈ G})]) ,
n i=1

with



κ
κ
Yi Di
Yi (1 − Di )
ḡ(Zi ) =
g(Yi , Di , Xi ) =
−
.
M
M e(Xi )
1 − e(Xi )
For the case r < 1, we can invoke Lemma D.1 to conclude immediately that:
sup E[Sn ] = O(1) ,
P ∈P

√
so we are done. For the case r ≥ 1, note that Sn ≤ 2 n/qn , which gives that for any D > 0,
√
n
E[Sn ] ≤ D + 2
P (Sn > D) ,
qn
hence we can apply Corollary D.1 to the last probability to conclude that supP ∈P E[Sn ] = O(1). Let
Fe = {ḡ · (1G∗ − 1G ) : G ∈ G}, then for an appropriate choice of D (which depends on P only through K
and r, and A), Corollary D.1 gives
P (Sn > D) ≤ C exp(−D2 qn2 ) ,
for some constant C which depends on P only through K, r, and A. Hence we can conclude that
√
sup nqn−1 E[W̄ (G∗ ) − W̄ (G)] ≤ sup E[Tn ] ≤ sup E[Sn ] = O(1) ,
P ∈P

P ∈P

as desired.

54

P ∈P

Proof of Proposition C.2
Proof. Define
Ln := inf

EP n [W (G∗ ) − W (Ĝ)] .

sup

Ĝ P ∈P ∗ (µ)

We follow the general strategy of Massart and Nédélec (2006). For every h ∈ H = {1G : G ∈ G}, set
τh (x) = (M/4)(2h(x) − 1), γh (x) = (2/M )τh (x), and define Ph as the joint distribution on X × {0, 1} × Y 2
(i.e. the set of realizations of (X, D, Y (1), Y (0))) such that under Ph , X has distribution µ,

1+γf (x)
M
with prob.
2
2
Y (1)|{X = x} =
− M with prob. 1−γf (x)
2
2
Y (0)|{X = x} = 0, and D is Bernoulli(0.5) independent of everything else. Note that by construction we
have that τh (x) = EPh [Y (1) − Y (0)|X = x] = τ (x), h describes the first-best decision rule under Ph , and
Ph ∈ P ∗ (µ).
Next, let C be a finite subset of H, then it follows that:
inf

sup

EP n [W (G∗ ) − W (Ĝ)] ≥ inf sup Eh [W (G∗ ) − W (Ĝ)] ,

Ĝ P ∈P ∗ (µ)

Ĝ h∈C

where Eh = EPhn . Since, under Ph , G∗ is the first best allocation by construction, we get that
Z
∗
W (G ) − W (G) =
|τ (X)|dPX ,
G∗ ∆G

for any G ∈ G. Hence it follows that, given the construction of τh :
W (G∗ ) − W (G) =

M
µ(G∗ ∆G) .
4

Putting all this together and using the fact that h = 1G∗ under Ph :
Ln ≥ inf sup
ĥ∈H h∈C

M
Eh [||h − ĥ||1 ] ,
4

where ĥ = 1Ĝ , and || · ||1 is the L1 (µ) norm. Define the statistic
h̃ = arg min ||h − ĥ||1 ,
h∈C

then by the triangle inequality it follows that
inf sup Eh [||ĥ − h||1 ] ≥
ĥ∈H h∈C

1
inf sup Eh [||h̃ − h||1 ] .
2 h̃∈C h∈C

We now construct the appropriate set C. Let C 0 be an -packing set of H, and let C 00 be a C cover of H for
some C > 1,  > 0 to be specified later. By definition, each h ∈ C 0 lies in some ball of radius C centered
at a point in C 00 . So by taking C to be the intersection of C 0 with such a ball in C 00 which results in a set of
maximal cardinality, we get that for h1 , h2 ∈ C, where h1 6= h2 ,
 ≤ ||h1 − h2 ||1 ≤ C ,
and moreover,
log(|C|) ≥ H1 (, H, µ) − H1 (C, H, µ) .

55

To see this, note that since we have constructed C to have maximal cardinality, it must be the case that
|C| ≥

|C 0 |
,
|C 00 |

and by definition, |C 0 | = H1 (, H, µ), |C 00 | ≤ H1 (C, H, µ).
Now, by Markov’s inequality,
inf sup Eh [||h̃ − h||1 ] ≥  inf (1 − inf Phn (h̃ = h)) ,

h̃∈C h∈C

h∈C

h̃∈C

and hence by Lemma 8 in Massart and Nedelec (2006),
M
(1 − α) ,
8

Ln ≥

where α := 0.71, as long as K̄ ≤ α log(|C|), where, for some fixed h0 ∈ C:
K̄ :=

=

1
|C| − 1

n
|C| − 1

X

K(Phn , Phn0 )

h∈C,h6=h0

X

K(Ph , Ph0 ) ,

h∈C,h6=h0

and K(·, ·) is the Kullback-Leibler divergence. By Lemma D.2 we have that
K̄ ≤ n sup ||h − h0 ||1 ≤ n ,
h∈C

where the last inequality follows by the construction of C.
Again by the construction of C, we can choose C such that there exists some positive constant C1 for
which log(|C|) ≥ C1 −r for  ≤ 1 , and therefore
K̄
n 1+r
≤

.
log |C|
C1
Hence we can conclude that Ln ≥ (M /8)(1 − α) whenever
n 1+r

≤α,
C1
that is,
 ≤ (αC1 )

1/(1+r)

n−1/(1+r) .

Now, we may also choose C such that αC1 ≤ 1+r
, so that the constraint  ≤ 1 is satisfied if we set
1
 = (αC1 )

1/(1+r)

n−1/(1+r) .

Hence we have that
Ln = inf

sup

EP n [W (G∗ ) − W (Ĝ)] ≥ An−1/(1+r) ,

Ĝ P ∈P ∗ (µ)

where A is a constant which depends on K1 , K2 , M , and r as desired.

56

Corollary D.1. Let {Zi }ni=1 be a sequence of i.i.d random vectors with distribution P . Let Z = (Z1 , Z2 ),
and let F be a class of real-valued functions of the form f (z) = f (z1 , z2 ) = g(z) · h(z2 ), where h ∈ H, H is
a class of functions with values in {0, 1}, and g is some fixed real-valued function (which may depend on P )
such that |g| ≤ 1. Suppose H satisfies Assumption C.1, and suppose that P2 , the marginal distribution of
Z2 , has a density with respect to Lebesgue measure bounded above by A. Then there exist positive constants
D1 , D2 , D3 (which depend only on K, r, and A) such that for n ≥ 3:
!
n
X
1
P n sup √
[f (Zi ) − Ef (Zi )] > xqn ≤ D3 exp(−x2 qn2 ) ,
n i=1
f ∈F
√
for D1 ≤ x ≤ D2 n/qn , where
qn =


log n,

r=1

n(r−1)/2(r+1) ,

r>1

Proof. First note that, since H consists of {0, 1}-valued functions, any -bracket for H in L1 is an 1/2 -bracket
in L2 and vice versa. Combining this with the fact that P2 has density bounded above by A, we have that
H2B (, H, P2 ) ≤ K 0 −r/2 ,
for some constant K 0 which depends only on K, r, and A. The result then follows immediately by Proposition
D.1.
Proposition D.1. Let {Zi }ni=1 be a sequence of i.i.d random vectors with distribution P . Let Z = (Z1 , Z2 ),
and let F be a class of real-valued functions of the form f (z) = f (z1 , z2 ) = g(z) · h(z2 ), where h ∈ H, H is
a class of functions with values in {0, 1}, and g is some fixed real-valued function (which may depend on P )
such that |g| ≤ 1. Let P2 be the marginal distribution of Z2 and suppose H satisfies
H2B (, H, P2 ) ≤ K−` ,

(22)

for some constants K > 0, ` ≥ 2, for all  > 0. Then there exist positive constants C1 , C2 , C3 , C4 (which
depend only on K and `) such that if

√

ξ≤
and

n
,
128


C n(`−2)/2(`+2) ,
1
ξ≥
C log max(n, e),
2

then

n

P

n

(23)

`≥2

(24)

`=2

1 X
sup √
[f (Zi ) − Ef (Zi )] > ξ
n i=1
f ∈F

!
≤ C4 exp(−ξ 2 ) .

Proof. We follow the general strategy of Alexander (1984). Let
n

1 X
[f (Zi ) − Ef (Zi )] .
νn (f ) = √
n i=1
We begin with a series of definitions. Let δ0 > δ1 > ... > δN > 0 be a sequence of real numbers where {δj }j
and N are to be specified precisely later in the proof. For every 0 ≤ j ≤ N , there exists a set of δj -brackets

57

U
B
HjB of H such that |HjB | = N2B (δj , H, P2 ). For each h ∈ H let (hL
j , hj ) ∈ Hj be the brackets such that
U
H
L
hL
j ≤ h ≤ hj and ||hj − hj ||2 < δj . Define the function Hθ (·) : (0, ∞) → [0, ∞) as follows:




Ku−` ,


Hθ (u) = − K
θ u+



0,

u≤1
K(1+θ)
,
θ

u ∈ (1, 1 + θ]
u>1+θ .

Note that by construction Hθ is continuous on [0, ∞), and by Assumption (22), N2B (δj , H, P2 ) ≤ exp(Hθ (δj ))
for θ sufficiently small. From now on, we fix such a θ > 0, and suppress θ from our notation. For any
U
f ∈ F, we have by definition that f = g · h for some h ∈ H, and so given the bracket (hL
j , hj ), define
U
U
U
L
fjL := g · hL
j 1{g ≥ 0} + g · hj 1{g < 0}, and fj := g · hj 1{g ≥ 0} + g · hj 1{g < 0}, and note that by

construction (fjL , fjU ) is a bracket for f . Let fj = fjL , and let Fj = {fj : f ∈ F}, then |Fj | ≤ exp(H(δj ))
and for every f ∈ F, ||f − fj ||2 < δj .
By a standard chaining argument:
!
sup |νn (f )| > ξ

P

≤ R1 + R2 + R3 ,

f ∈F

where


R1 = |F0 | sup P

|νn (f )| >

f ∈F

R2 =

N
−1
X


,

|Fj ||Fj+1 | sup P (|νn (fj − fj+1 )| > ηj ) ,
f ∈F

j=0

R3 = P
where {ηj }j are chosen such that

7
ξ
8

PN

j=0

ξ
sup |νn (fN − f )| >
+ ηN
16
f ∈F

!
,

ηj ≤ ξ/16 and will be specified precisely later in the proof. We now

choose {δj }j , {ηj }j and N to make these three terms sufficiently small.
First consider R1 . Take δ0 such that H(δ0 ) = ξ 2 /4. Then by Hoeffding’s inequality,
 2 !

7
R1 ≤ 2|F0 | exp −2
ξ
≤ 2 exp −ξ 2 .
8
Next, we develop a bound on R2 . Since by construction ||fj −fj+1 ||2 ≤ 2δj , it follows by repeated applications
of Bennet’s inequality (see Lemma D.3) that
R2 ≤

N
−1
X

2 exp(2H(δj+1 )) exp(−ψ1 (ηj , n, 4δj2 )) ,

j=0

where ψ1 has the properties described in Lemma D.3. Next, consider R3 . Given the construction of FN and
writing f = g · h:

√
U
L
U
L
|νn (fN − f )| ≤ |νn (fN
− fN
)| + 2 n||fN
− fN
||1
√
U
L
2
≤ |νn (fN
− fN
)| + 2 nδN
,

58

√ 1/2
U
L
L
2
since ||fN
− fN
||1 ≤ ||hU
, then by the above derivation and
N − hN ||1 ≤ δN . Take δN ≤ s := (ξ/(32 n))
Bennet’s inequality,
!
R3 ≤ P

sup
f ∈F

U
|νn (fN

−

L
fN
)|

> ηN

2
≤ 2|FN | exp(−ψ1 (ηN , n, δN
)) .

To complete our bounds on R2 and R3 we consider two separate cases. First suppose δ0 ≤ s as defined
above. Then by taking N = 0 and η0 = ξ/16, we have that R2 = 0 and
R3 ≤ 2|F0 | exp(−ψ1 (η0 , n, δ02 )) .
Since δ0 ≤ s, we have that
2η0 =

√
ξ
=4 n
8



ξ
√
32 n



√
≥ 4 nδ02 ,

and hence by the properties of ψ1 :
ψ1 (η0 , n, δ02 ) ≥

1
1 √
ψ1 (2η0 , n, δ02 ) ≥ η0 n .
4
4

Using Assumption (23), we can then conclude that
ψ1 (η0 , n, δ02 ) ≥

1 √
ξ √
η0 n =
n ≥ 2ξ 2 .
4
64

By the definition of δ0 ,

|F0 | ≤ exp

ξ2
4


,

so that putting everything together yields
R2 + R3 ≤ 2 exp(−ξ 2 ) .
Next consider the case where δ0 > s. Let N and {δj }N
j=1 be as in Lemma D.4, where t = δ0 , and s is as
√
√
1/2
for 0 ≤ j < N , ηN = 8 2δN H(δN )1/2 . Then by Lemma D.4:
defined above. Let ηj = 8 2δj H(δj+1 )
N
X
j=0

N
√ Z
√ X
1/2
δj H(δj+1 )
≤ 64 2
ηj = 8 2

δ0

H(u)1/2 du .

s/4

j=0

Now, by the definition of H(·), we have that for 0 < s < t,

Z t
K 1/2 log(1/s),
H(u)1/2 du ≤
2K 1/2 (` − 2)−1 s(2−`)/2 ,
s

` = 2 and t ≤ 1
`>2

and so by combining this with Assumption (24), it can be shown that
N
X

ηj ≤

j=0

ξ
,
16

and hence our choice of {ηj }j is consistent with our construction (note that when ` = 2, the above inequality
P
only applies when t ≤ 1, however we can argue using δ0 ≤ 1 + θ that
ηj ≤ ξ/16 + C 0 θ for some constant
C 0 > 0, for all θ > 0, and hence our result holds for P (supf |νn (f )| ≥ ξ + C 0 θ) where θ > 0 can be made
arbitrarily small). By Assumption (24), it can also be shown that
√
ξ n
H(s) ≤
,
16

59

and hence it follows that
ηj
√
2

!2
<

4δj n

8H(s)
≤ 16 ,
ns2

so that by the properties of ψ1 ,

ηj2
.
16δj2

ψ1 (ηj , n, 4δj2 ) ≥
Using our bound on R2 we can then conclude that
R2 ≤

N
−1
X
j=0

ηj2
2 exp 2H(δj+1 ) −
16δj2

!
≤

N
−1
X


2 exp −4j+1 H(δ0 ) ,

j=0

Similarly, we can argue that

R3 ≤ 2 exp −4N +1 H(δ0 ) .
Putting these together, and using Assumption (24):
∞
X

R2 + R3 ≤


2 exp −4j+1 H(δ0 ) ≤ C exp(−ξ 2 ) ,

j=0

where C is a constant that depends only on K and `.
Lemma D.1. Maintain the assumptions of Proposition C.1 with r < 1. Let Sn be as in the proof of
Proposition C.1. Then
sup E[Sn ] = O(1) .
P ∈P

Proof. By definition, Sn ≤

√

(1)

(2)

nSn + Sn , where
n

Sn(1) =

Sn(2)

=

1X ˜
(fG (Zi ) − E[f˜G (Zi )]) ,
n i=1

sup
G∈G:||fG ||≤n−1/(2+2r)

√

sup

n

1
n

Pn

˜

i=1 (fG (Zi )

G∈G:||fG ||≥n−1/(2+2r)

− E[f˜G (Zi )])

||f˜G ||1−r

,

with f˜G = ḡ · (1{X ∈ G∗ } − 1{X ∈ G}) and || · || the L2 (P ) norm, and we have used the fact that ||f˜G || ≤ 1.
We will use Lemma 5.13 in Geer (2000) to bound each of these quantities. To apply the lemma, let g in her
notation be f˜G in ours, and g0 in her notation be zero. Set α = 2r, β = 0 in the statement of her lemma.
It remains to verify condition (5.40) in her lemma for the class Fe = {f˜G : G ∈ G}, but this follows by
Assumption C.1 by combining the arguments from the proof of Corollary D.1 and the proof of Proposition
D.1. By inequality (5.42) in her lemma:
sup n1/(1+r) E[Sn(1) ] = O(1) ,

P ∈P

and hence since r < 1,
sup

√

P ∈P

nE[Sn(1) ] = O(1) .

By inequality (5.43),
sup E[Sn(2) ] = O(1) .

P ∈P

Combining both of these together gives our desired result.

60

Lemma D.2. Let Pf be specified as in the proof of Proposition C.2. Then for f, g ∈ H such that f 6= g:
K(Pf , Pg ) ≤ ||f − g||1 ,
where K(·, ·) is the Kullback-Leibler divergence.
Proof. Let Qf,x (·) denote the probability mass function of (Y (1), D)|X = x under Pf (recall that Y (0)|X = x
is degenerate, so we omit it from the calculation). If f 6= g, a direct calculation shows that:
K(Qf,x , Qg,x ) =
Hence

1
log(3) .
2

Z
K(Pf , Pg ) =

K(Qf,x , Qg,x )1{f (x) 6= g(x)}dµ =
X

1
log 3||f − g||1 ≤ ||f − g||1 .
2

Lemma D.3. (Bennet’s Inequality: see Theorem 2.9 in Boucheron et al. (2013)) Let {Zi }ni=1 be a sequence
of independent random vectors with distribution P . Let f be some function taking values in [0, 1] and define
1
νn (f ) := √ [f (Zi ) − Ef (Zi )] .
n
Then for any ξ ≥ 0,
P n (|νn (f )| > ξ) ≤ 2 exp(−ψ1 (ξ, n, α)) ,
where α = var(νn (f )) and ψ1 has the following two relevant properties:
ψ1 (ξ, n, α) ≥ ψ1 (Cξ, n, ρα) ≥ C 2 ρ−1 ψ1 (ξ, n, α) ,
for C ≤ 1, ρ ≥ 1, and

 ξ2
ψ1 (ξ, n, α) ≥ 4α√
ξ
2

√
if ξ < 4 nα
√
if ξ ≥ 4 nα

n

Lemma D.4. (Lemma 3.1 in Alexander (1984)) Let H : (0, t] → R+ be a decreasing function, and let
0 < s < t. Let δ0 := t, δj+1 := s ∨ sup{x ≤ δj /2 : H(x) ≥ 4H(δj )} for j ≥ 0, and N := min{j : δj = s}.
Then

N
X

δj H(δj )1/2 ≤ 8

Z

t

s/4

j=0

61

H(u)1/2 du .

