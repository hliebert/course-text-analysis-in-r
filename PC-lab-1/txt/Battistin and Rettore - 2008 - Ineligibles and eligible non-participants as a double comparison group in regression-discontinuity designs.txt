ARTICLE IN PRESS

Journal of Econometrics 142 (2008) 715–730
www.elsevier.com/locate/jeconom

Ineligibles and eligible non-participants as a double comparison
group in regression-discontinuity designs
Erich Battistina,b,, Enrico Rettorea
a

Department of Statistics, University of Padova, Italy
b
Institute for Fiscal Studies, London, UK
Available online 21 May 2007

Abstract
In a sharp regression-discontinuity design (RDD) the participation status deterministically depends on whether a preprogramme characteristic is above or below a speciﬁed threshold. The attractiveness of such a design rests on close
similarities with a formal experiment. Nevertheless, it is of limited applicability since participation into a programme is
seldom determined according to this rule. Besides, in the presence of heterogeneous effects a sharp RDD only allows
identiﬁcation of mean effects for individuals around the threshold for participation. Two results are presented in this
paper, and they both partially overcome the two limitations described above. We show that when individuals self-select
into participation conditional on some eligibility criteria a sharp RDD provides a natural framework to deﬁne a
speciﬁcation test for the non-experimental estimation of programme effects for participants away from the threshold. We
also show that, in this set-up, the regularity conditions required for the identiﬁcation of the mean counterfactual outcome
for participants marginally eligible for the programme are essentially the same as in a sharp RDD.
r 2007 Elsevier B.V. All rights reserved.
JEL classification: C4; C8
Keywords: Programme evaluation; Second comparison group; Speciﬁcation tests; Treatment effects

1. Introduction
In this paper we show how discontinuities in the probability of participation induced by the eligibility
criteria for being enrolled in a programme can be used to test the performance of alternative non-experimental
estimators of the programme effects.
The central issue in the evaluation of the impact of an intervention is to separate its causal effect from the
confounding effect of other factors inﬂuencing the outcome of interest. Random assignment of individuals to
the intervention deﬁnes treatment and control groups that are equivalent in all respects, except for their
treatment status. Thus, if a randomized experiment is well implemented, any post-intervention difference
between treatment and control individuals can safely be attributed to the intervention itself. The main
Corresponding author. Department of Statistics, University of Padova, Italy. Tel.: +39 049 8274165;
fax: +39 049 8274170.
E-mail address: erich.battistin@unipd.it (E. Battistin).

0304-4076/$ - see front matter r 2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.jeconom.2007.05.006

ARTICLE IN PRESS
716

E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

advantage of experiments is that the assumptions they rest upon are generally more plausible than those made
in an observational setting (see Heckman and Smith, 1995). In the latter case, the identiﬁcation of causal
relationships rests on assumptions about individuals’ behaviour whose plausibility is often controversial.
In the absence of random assignment a fairly favourable situation to the researcher arises when the
assignment mechanism leading individuals to participate into the programme is fully speciﬁed. This situation
applies to those instances in which participation follows a sharp regression discontinuity design (RDD; see
Thistlethwaite and Campbell, 1960; Rubin, 1977; Trochim, 1984). In this design, assignment to the
programme solely depends on whether one or more observable pre-intervention variables satisfy a set of
conditions known to the analyst. As an example, we can think of situations in which individuals willing to
participate are divided into two groups according to whether or not a pre-intervention measure exceeds a
known threshold, but only individuals scoring above that threshold are assigned to the programme.
This design features both advantages and disadvantages with respect to its non-experimental competitors.
On the one hand, in a neighbourhood of the threshold for selection a sharp RDD presents some features of a
pure experiment. In this sense, it is certainly more attractive than other non-experimental designs. Since
individuals in the treatment and comparison group solely differ with respect to the variable determining the
participation status (and with respect to any other variable correlated to it), one can control for confounding
factors by contrasting marginal participants to marginal non-participants. In this context, the term ‘marginal’
refers to those units not too far away from the threshold for selection.
The comparison of mean outcomes for participants and non-participants at the margin identiﬁes the mean
impact of the intervention locally at the threshold for selection. Intuitively, for identiﬁcation at the cut-off
point to hold it must be the case that any discontinuity in the relationship between the outcome of interest and
the variable determining the treatment status is fully attributable to the treatment itself. This requires some
regularity conditions at the threshold for selection discussed by Hahn et al. (2001; HTV in the following).
On the other hand, the sharp RDD features two main limitations. First, its feasibility is conﬁned to those
instances in which assignment takes place only on observable pre-intervention variables; as a matter of fact,
this is not often the case. Second, even when such a design applies, it only allows identiﬁcation of the mean
impact of the intervention at the threshold for selection. In the common situation of heterogeneous returns to
participation, the local effect might be very different from the effect for individuals away from the threshold
for selection. To identify the mean impact on a broader population of participants one has to rely on nonexperimental estimators, whose consistency for the intended impact rests on assumptions about the behaviour
of individuals.
Throughout this paper we consider the case in which an eligibility rule splits the relevant population into
eligible and ineligible individuals, and participation of the former group is determined according to rules
potentially unknown to the researcher. Examples of such a design are labour market programmes for which
participation is voluntary for individuals satisfying a condition on age, or means tested programmes. College
enrollment, for which only a subset of applicants is enrolled amongst those passing an achievement test, also
ﬁts this design.
The plan of the paper is as follows. First, we show that in the set-up described above the mean impact for
participants around the threshold for eligibility is identiﬁed essentially under the same regularity conditions
required in a sharp RDD, no matter how eligible individuals are selected into the programme (see Section 3).
Although references have been made in the literature to the potential of using eligibility rules to identify mean
impacts (see Heckman, 1992; Angrist, 1998; Heckman et al., 1999; van der Klaauw, 2002), to the best of our
knowledge the regularity conditions required for identiﬁcation have not been discussed so far.
Second, we show that eligibility rules for participation into a programme can be used to assess the validity
of non-experimental estimators for the programme effects (see Section 4). In particular, we show that the
selection bias arising from the non-random selection of eligible individuals into the programme is identiﬁed at
the threshold for eligibility, so that one can formally test whether any of the long array of existing nonexperimental estimators can correct for this bias. If this hypothesis is not rejected at the threshold for
eligibility, one may feel more conﬁdent to use that non-experimental estimator to identify the causal effect on a
broader population (typically, the one represented by all participants).
Several links to the literature are established. In particular, we show that our ﬁrst result is closely related to
what discussed by Bloom (1984), Heckman (1990) and Angrist and Imbens (1991). We also stress the

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

717

relationship with the idea in Rosenbaum (1987) of using two comparison groups for the identiﬁcation of
causal effects. Finally, we point out similarities between our speciﬁcation test and the set of speciﬁcation tests
derived by Heckman and Hotz (1989), as well as the link to the characterization of the selection bias provided
by Heckman et al. (1998).
The remainder of this paper is organized as follows. Section 2 discusses similarities between a fully
randomized experiment and a RDD. Section 3 describes the set-up in which participation is determined by
self-selection amongst eligible individuals and derives the regularity conditions required for identiﬁcation of
the average effect on marginal participants. Section 4 shows how to use this set-up to validate nonexperimental estimators for the treatment effect. Section 5 presents an empirical application of the
identiﬁcation strategies discussed in the paper and Section 6 concludes.
2. Identiﬁcation of treatment effects in RDD
This section presents the basic features of a RDD and highlights the similarities with a randomized
experiment. The discussion of identiﬁcation issues arising in a RDD is based on HTV, to which the interested
reader is referred for further details.
Following the notation of the potential outcome approach to causal inference, let ðY 1 ; Y 0 Þ be the two
potential outcomes one would experience by participating and not participating into the programme,
respectively.1 The causal effect of the treatment on that speciﬁc subject is then deﬁned as the difference
between these outcomes, b ¼ Y 1  Y 0 , which is not observable since being exposed to (denied) the
programme reveals Y 1 ðY 0 Þ but conceals the other potential outcome.2
Let I be the binary variable for the treatment status, with I ¼ 1 for participants and I ¼ 0 for nonparticipants. If the assignment is determined by randomization and subjects comply with the assignment, the
following condition holds true by construction:
ðY 1 ; Y 0 Þ ? I.
The attractiveness of randomization is that the difference between mean outcomes for participants and nonparticipants identiﬁes the mean impact of the programme
Efbg ¼ EfY 1 jI ¼ 1g  EfY 0 jI ¼ 0g,

(1)

since conditioning on I in the right-hand side of (1) is irrelevant by construction. In other words,
randomization allows the researcher to use information on non-participants to identify the mean
counterfactual outcome for participants, namely what participants would have experienced had they not
participated into the programme.
A RDD arises when the treatment status depends on an observable individual characteristic S and there exist
a known point in the support of S where the probability of participation changes discontinuously. Throughout
this paper, S is assumed to be continuous on the real line. Formally, if s̄ is the discontinuity point, then a RDD
is deﬁned if
PrfI ¼ 1js̄þ ga PrfI ¼ 1js̄ g.

(2)

Here and in the following s̄þ and s̄ refer to those individuals marginally above and below s̄, respectively.
Moreover, to ease the exposition and without any loss of generality, we will deal with the case in which the
following inequality holds:
PrfI ¼ 1js̄þ g  PrfI ¼ 1js̄ g40.
Following Trochim (1984), the distinction between sharp and fuzzy RDD depends on the size of the
discontinuity in (2). The former design occurs when the probability of participating conditional on S steps
1
For reviews of the evaluation problem see Heckman et al. (1999) and Imbens (2004). For the potential outcome framework, the main
references are Fisher (1935), Neyman (1935), Quandt (1972), Roy (1951) and Rubin (1974).
2
In what follows we will discuss the case in which the programme impact b varies across individuals, which in most instances is the
relevant case. HTV also derive the regularity conditions required for the identiﬁcation of treatment effects in the case of constant impact
across individuals.

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

718

from zero to one as S crosses the threshold s̄. That is, the treatment status deterministically depends on
whether individuals’ values of S are above s̄:
I ¼ 1ðSXs̄Þ.

(3)

A fuzzy RDD occurs when the size of the discontinuity at s̄ is smaller than one. For example, a fuzzy RDD
can be thought as an instance in which I is a deterministic function of S for all subjects but this function is
different across individuals (see HTV).
Although a RDD lacks random assignment of individuals to the treatment group, it shares an attractive
feature with experimental designs. We will address this issue by considering the case of a sharp RDD; we will
discuss the fuzzy case further below in this section. Let
Y ¼ Y 0 þ IðsÞb
be the observed outcome as it results from taking or not taking part into the programme. The dependence of
the treatment status I on the variable S is stressed by writing IðsÞ. The difference of mean outcomes for
individuals marginally above and below the threshold s̄
EfY js̄þ g  EfY js̄ g

(4)

can be written as
EfY 0 js̄þ g  EfY 0 js̄ g þ EfIðsÞbjs̄þ g  EfIðsÞbjs̄ g,

(5)

which simpliﬁes to
EfY 0 js̄þ g  EfY 0 js̄ g þ Efbjs̄þ g
because of (3). The following condition is then sufﬁcient for the mean impact of the treatment at s̄þ to be
identiﬁed in a sharp RDD (it corresponds to Assumption (A1) in HTV).
Condition 1. The mean value of Y 0 conditional on S is a continuous function of S at s̄.
Accordingly, Condition 1 requires that in the counterfactual world no discontinuity would take place at the
threshold for selection. The attractiveness of the RDD is apparent here. By contrasting mean outcomes for
participants and non-participants at the margin, one can identify the average impact of the programme for
individuals in a right-neighbourhood of s̄, thus a local version of the parameter in (1)
Efbjs̄þ g ¼ EfY js̄þ g  EfY js̄ g.
The identiﬁcation of Efbjs̄ g, that is of the mean impact from extending the programme to marginally
excluded individuals, requires an additional continuity condition on the conditional mean EfY 1 jSg.3 This
additional assumption together with Condition 1 are equivalent to Assumptions (A1) and (A2) in HTV. Note
that, by exploiting the relationship in (3) and by assuming that the distribution of ðY 0 ; Y 1 Þ as a function of S is
continuous at the discontinuity point, the following condition holds true:
ðY 1 ; Y 0 Þ ? IjS ¼ s̄.

(6)

Because of this property, perhaps a bit rethorically, a sharp RDD is often referred to as a quasi-experimental
design (Cook and Campbell, 1979).4,5
When individuals do not comply with the mandated status resulting from a sharp assignment, drop out of
the programme or seek alternative treatments if denied it (see, for example, Battistin and Rettore, 2002), a
fuzzy RDD arises. In this case, the continuity of Y 0 and Y 1 at s̄ is no longer enough to ensure the
3

Note that, in practice, it is difﬁcult to think of cases where Condition 1 is satisﬁed and the same condition does not hold for Y 1 .
It is worth stressing again that to meaningfully deﬁne marginal units (with respect to s̄) the selection variable S has to be continuous.
Estimation of the right-hand side (left-hand side) of (4) makes use of data only in a neighbourhood on the right (left) side of the
discontinuity point. Unless one is willing to make some parametric assumptions about the regression curve away from s̄, only data local to
the discontinuity point help to estimate the jump. Asymptotically the neighbourhood needs to shrink as with usual non-parametric
estimation, implying a non-standard asymptotic theory for the resulting estimator of the mean impact (see HTV; Porter, 2002).
5
Lee (2004) suggests simple tools to test for the validity of (6) based on the idea of comparing individuals marginally above and below
the threshold with respect to variables which cannot be affected by the programme. Finding that the two groups of individuals present
systematic differences in the values of these variables would cast serious doubts on the validity of (6).
4

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

719

orthogonality condition in (6). Accordingly, the mean impact at s̄ cannot be identiﬁed by simply comparing
the mean outcome for marginal participants to the mean outcome for marginal non-participants, and
additional conditions are required to recover meaningful causal parameters from (4). The following condition
corresponds to Assumption (A3)(i) in HTV.6
Condition 2. The triple ðY 0 ; Y 1 ; IðsÞÞ is stochastically independent of S in a neighbourhood of s̄.
The stochastic independence between IðsÞ and S in a neighbourhood of s̄ corresponds to imposing the
restriction that assignment at s̄ takes place as if it were randomized. On the other hand, the stochastic
independence between ðY 1 ; Y 0 Þ and S at s̄ corresponds to an exclusion restriction asserting that, in a
neighbourhood of s̄, S affects the outcomes only through its effect on I (see the discussion on the role of the
exclusion restriction in Angrist et al., 1996).
If Condition 2 is satisﬁed, then expression in (4) can be written as
EfbjIðs̄þ Þ4Iðs̄ Þg PrfIðs̄þ Þ4Iðs̄ Þg  EfbjIðs̄þ ÞoIðs̄ Þg PrfIðs̄þ ÞoIðs̄ Þg.
Then, under the additional:
Condition 3. Participation into the programme is monotone around s̄, that is it is either the case that
Iðs̄þ ÞXIðs̄ Þ for all subjects or the case that Iðs̄þ ÞpIðs̄ Þ for all subjects.
the mean impact
EfbjIðs̄þ ÞaIðs̄ Þg ¼

EfY js̄þ g  EfY js̄ g
EfIjs̄þ g  EfIjs̄ g

ð7Þ

is identiﬁed (Condition 3 corresponds to Assumption (A3)(ii) in HTV). The parameter in (7) represents the
mean impact of the programme on those individuals in a neighbourhood of s̄ who would switch their
treatment status if the threshold for participation switched from just above their score to just below it (see
Imbens and Angrist, 1994; Angrist et al., 1996).
It is worth noting that Condition 3 is an assumption on individuals’ behaviour which is not testable. It
corresponds to assuming that the individual speciﬁc function IðsÞ is monotone the same way for all subjects in
a neighbourhood of s̄. Moreover, if Condition 3 holds, the denominator in the right-hand side of the previous
expression identiﬁes the proportion of complying individuals at s̄, that is the subpopulation the effect in (7)
refers to. Nevertheless, it is not observable which individuals the group of compliers consists of. Whether or
not the resulting mean impact is a policy relevant parameter depends on the speciﬁc case (see Heckman, 1997,
for a discussion).
Apparently, a sharp RDD allows the identiﬁcation of the mean impact on a broader population than the
one identiﬁed in a fuzzy RDD. Moreover, stronger regularity conditions are needed in the fuzzy case. While in
the sharp case Condition 1 is sufﬁcient to ensure the identiﬁcation of the mean impact for marginal
participants, in the fuzzy case Conditions 2 and 3 together imply that the impact on the subpopulation of
compliers in a neighbourhood of s̄ is identiﬁed. Heckman et al. (1999) emphasize this point by saying that
much of the simplicity of the design is lost moving from a sharp RDD to a fuzzy RDD.
Two major drawbacks hamper the applicability of the RDD. Firstly, in an observational study it is very
often the case that units self-select into the treatment rather than being exogenously selected on a preprogramme measure. If this is the case, the RDD set-up as introduced so far no longer applies. Secondly, even
in those instances in which the RDD applies, if the impact is heterogeneous across individuals such a design
is not informative about the impact on individuals away from s̄. These two issues will be dealt with in the
next sections.
6

As an alternative to Condition 2, HTV also consider the following local orthogonality condition:

ðY 1 ; Y 0 Þ ? IjS ¼ s̄,
which rules out non-random selection based either on ðY 1 ; Y 0 Þ or on any variable stochastically related to ðY 1 ; Y 0 Þ.

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

720

3. A partially fuzzy design
Social interventions are often targeted to speciﬁc groups of individuals meeting a fully speciﬁed set of
conditions for eligibility. Means tested programmes (such as food stamp programmes) or labour market
programmes whose eligibility criteria depend on the duration of unemployment or on the age of individuals
are frequently encountered examples of such a scheme.
To ﬁx ideas, let S be a continuous pre-programme characteristic and let the eligibility status be established
according to the deterministic rule 1ðSXs̄Þ. That is, subjects are eligible for the programme if and only if they
present a value of the variable S above a known threshold s̄. Throughout our discussion it will be assumed that
S is observable for all individuals. If all eligibles (and only them) participated into the programme, a sharp
RDD would arise. For example, if participation were mandatory for all eligible individuals, the effect of the
programme at the threshold for eligibility would be identiﬁed by (4) provided that Condition 1 holds.
As a matter of fact, it is often the case that some eligible individuals self-select into the programme while
some others do not (typically, when participation is on a voluntary basis). Individuals’ heterogeneity about
information on the availability of the programme, preferences and opportunity costs are factors likely to
inﬂuence the participation decision in several instances. Accordingly, the population turns out to be divided
into three subgroups: ineligibles, eligible non-participants and participants. Our analysis develops with reference
to the general case in which the researcher has no knowledge of the rule leading eligible individuals to selfselect into the programme (that is, selection is on unobservables). In what follows, it will be assumed that
information on the three groups of individuals is available to the researcher.
As a result of the eligibility rule and of self-selection, the probability of participation for those individuals
scoring a value of S below the threshold s̄ is zero by deﬁnition, since they are not eligible for the programme.
The probability of participation for those scoring above s̄ is smaller than one because participation is not
mandatory. As a result, the probability of participation is discontinuous at the threshold for eligibility and the
size of the discontinuity is less than one (i.e. according to the terminology introduced in the previous section, a
fuzzy RDD is deﬁned).
van der Klaauw (2002, p. 1284) explicitly mentions the potential for using the RDD arising from the
eligibility criteria for a social programme. Heckman et al. (1999, pp. 1971–1972) recognize the fuzzy RDD
nature of this set-up and point out that in this case the estimand in (7) identiﬁes the mean impact on
participants at s̄.
3.1. Identification of programme effects
To recover the regularity conditions required for identiﬁcation consider again the difference in (4). Since
participation is precluded to marginally ineligibles (Iðs̄ Þ ¼ 0), the expression in (5) becomes
EfY 0 js̄þ g  EfY 0 js̄ g þ EfIðsÞbjs̄þ g.
If Condition 1 holds, by using the law of iterated expectations and by noting that EfIðsÞbjI ¼ 0; s̄þ g ¼ 0 the
previous expression equals
EfIðsÞbjs̄þ g ¼ EfbjI ¼ 1; s̄þ g PrfI ¼ 1js̄þ g,
so that the mean impact on participants in a right-neighbourhood of s̄ is identiﬁed by
EfbjI ¼ 1; s̄þ g ¼

EfY js̄þ g  EfY js̄ g
.
EfIjs̄þ g

(8)

In other words, Condition 1 is sufﬁcient for the average effect of the treatment on the treated to be identiﬁed
locally at the threshold for eligibility s̄.
It turns out that, despite the prima facie fuzzy RDD nature of this set-up, the LATE (Imbens and Angrist,
1994) at the discontinuity point is identiﬁed under the same condition used to estimate the average treatment
effect in the sharp design. The result rests on the fact that the probability of participation on the left-hand side

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

721

of s̄ is zero by design, and this simpliﬁes the expression in (5) without further assumptions on individuals’
behaviour.7
An alternative way of deriving the result exploits a close analogy between the set-up discussed in this section
and the one in Bloom (1984). In a fully experimental setting, Bloom (1984) notes that even if some individuals
randomly assigned to the treatment eventually do not show up, the identiﬁcation of the mean impact on
participants is still secured by the experiment. By analogy, exploiting the fact that the eligibility rule deﬁnes a
randomized experiment in a neighbourhood of s̄ and the fact that eligible non-participants play the role of
Bloom’s (1984) no-shows, the intuition suggests that the mean impact on participants in a neighbourhood of s̄
is also identiﬁed.
This is exactly what we have derived so far. The key relationship identiﬁcation rests upon is the equality
stated by Condition 1, that is
EfY 0 js̄þ g ¼ EfY 0 js̄ g.

(9)

The left-hand side of (9) can be written as the weighted average of the mean outcome for eligible participants
and for eligible non-participants, respectively,
EfY 0 jI ¼ 1; s̄þ gf þ EfY 0 jI ¼ 0; s̄þ gð1  fÞ,
where f ¼ EfIjs̄þ g is the probability of self-selection into the programme conditional on marginal eligibility.
The last expression combined with (9) yields
EfY 0 js̄ g
1f
 EfY 0 jI ¼ 0; s̄þ g
.
(10)
EfY 0 jI ¼ 1; s̄þ g ¼
f
f
Namely, the counterfactual mean outcome for marginal participants is identiﬁed by a linear combination of
factual mean outcomes for marginal ineligibles and for marginal eligibles not participating into the
programme. The coefﬁcients of this combination add up to one and are a function of f, which is identiﬁed
from observed data.
Hence, Eq. (10) implies that the mean impact on participants is identiﬁed, since by deﬁnition
EfbjI ¼ 1; s̄þ g ¼ EðY 1 jI ¼ 1; s̄þ Þ  EðY 0 jI ¼ 1; s̄þ Þ.
The right-hand side of the previous expression can be rearranged using (10) to obtain the expression in (8).
The result that the counterfactual mean outcome for marginal participants is identiﬁed will play a crucial role
in the next section.
The identiﬁcation of EfbjI ¼ 1; s̄ g, namely the impact on individuals who would participate into the
programme if the threshold for eligibility were marginally reduced, requires regularity conditions stronger
than Condition 1. More precisely, if Condition 2 holds then the following two equalities are jointly satisﬁed:
EfIðsÞbjs̄ g ¼ EfIðsÞbjs̄þ g,
EfIjs̄ g ¼ EfIjs̄þ g.
As the former equality implies
EfbjI ¼ 1; s̄ gEfIjs̄ g ¼ EfbjI ¼ 1; s̄þ gEfIjs̄þ g,
we have
EfbjI ¼ 1; s̄ g ¼ EfbjI ¼ 1; s̄þ g.
3.2. Related results
Five general comments follow from the results presented so far.
First, the comparison of participants to ineligible individuals or the comparison of participants to eligible
non-participants do not allow identiﬁcation of any causal parameter. It follows from Bloom’s (1984) key result
in (10) adapted to the RDD case that identiﬁcation of the mean counterfactual outcome for participants
7

Results by HTV and Porter (2002) on non-parametric inference in a RDD straightforwardly apply to the estimation of (8).

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

722

around s̄ is achieved by using information on both groups of non-participants. In this sense, the availability of
information separately on three groups of subjects—participants, eligible non-participants and ineligibles—is
crucial for identiﬁcation.
Second, as pointed out by Little and Yau (1998) following the discussion in Angrist et al. (1996), the validity
of the result in Bloom (1984) rests upon an exclusion restriction stating that, net of the actual participation
status, the random assignment is irrelevant for the outcome of interest (see also Heckman et al., 1999). By
analogy, an exclusion restriction must be satisﬁed in our set-up locally at s̄. Note that such a restriction is
implicit in Condition 1: if, by ﬁxing the actual participation status, Y 0 were affected by the status deﬁned by
the eligibility rule, then EðY 0 jSÞ would be discontinuous at s̄.
Third, to achieve identiﬁcation we do not need to model how eligible individuals self-select (or are selected)
into the programme. Thus, identiﬁcation of the mean impact does not need any behavioural assumptions on
the selection process.
Fourth, our result (as well as Bloom’s, 1984, one) can also be derived as a special case of Heckman (1990)
and Angrist and Imbens (1991). The authors prove that even if participation into the programme takes place
as a result of self-selection, the mean impact on participants is identiﬁable provided that (i) there exists a
random variable Z affecting the participation into the programme and orthogonal to the potential outcomes
and (ii) the probability of participation conditional on Z is zero in at least one point of the support of Z.
Condition (i) qualiﬁes Z as an instrumental variable for the problem.
In our case, since the eligibility status is orthogonal to the potential outcomes in a neighbourhood of s̄ and
PrðI ¼ 1js̄ Þ ¼ 0, the eligibility status meets the conditions stated by Angrist and Imbens (1991) in a
neighbourhood of s̄. Identiﬁcation of the mean impact on participants at s̄ follows (see the discussion in HTV
on the property of the IV estimator in this instance). Accordingly, in the set-up considered in this paper S is
exploited both as a control variable and to deﬁne an instrumental variable.8
Finally, the case in which the partially fuzzy design is characterised by the conditions PrðI ¼ 1js̄þ Þ ¼ 1 and
PrðI ¼ 1js̄ Þ40 straightforwardly ﬁts our framework. Moving from the continuity restriction EfY 1 js̄þ g ¼
EfY 1 js̄ g one recovers EfY 1 jI ¼ 0; s̄ g, the counterfactual mean outcome for non-participants at s̄ . Then,
both the mean impact for non-participants at s̄ and the selection bias with respect to Y 1 at s̄ are identiﬁable.
4. Validating non-experimental estimators of the mean impact on participants
4.1. Specification tests
This section shows that if data are available on the three groups of individuals resulting from the set-up
discussed in Section 3, one can use the information around the threshold for eligibility to test for the validity of
non-experimental estimators of the programme effect for participants away from the threshold.
As pointed out in the previous section, Condition 1 is sufﬁcient to identify the mean impact of the
programme on participants marginally eligible for it, even if they are a non-random sub-group from the set of
eligible individuals. However, if the gain from being exposed to the programme is heterogeneous with respect
to S, the mean impact for individuals in a neighbourhood of the threshold for eligibility is not informative on
the impact of the programme for individuals away from this point, thus precluding identiﬁcation of the effect
for all participants.9
In order to identify the mean impact on participants away from s̄
EfbjI ¼ 1; sg ¼ EfY 1 jI ¼ 1; sg  EfY 0 jI ¼ 1; sg;
8

sXs̄

(11)

In a fully parametric set-up (and under the additional linearity assumption) the following regression could be estimated:

Y ¼ a0 þ a1 S þ a2 I þ e,
using the eligibility status Z ¼ 1ðSXs̄Þ as an instrumental variable for I with S entering the equation to control for the selection induced by
the eligibility rule.
9
Note that local identiﬁcation provided by the RDD can be used to test for the heterogeneity of the effect. Under a smoothness
condition, a constant (with respect to S) treatment impact implies that the derivatives of the regression curve are the same on both sides of
s̄. One could test for this by directly modelling the regression of Y on S and I. Alternatively, a non-parametric implementation of this idea
could compare the partially linear (Battistin and Rettore, 2002; Porter, 2002) and the local polynomial (HTV, 2002) estimators of the
discontinuity, which have the same convergence rate under constant treatment effects (Porter, 2002).

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

723

one must resort to one of the long array of non-experimental estimators available in the literature which adjust
for selection bias under alternative assumptions (see Heckman et al., 1999; Blundell and Costa Dias, 2000;
Imbens, 2004, for a review). The main problem with non-experimental identiﬁcation strategies is that these
assumptions are intrinsically not testable.
To ﬁx the ideas, in what follows we will focus on the class of non-experimental estimators based on the
assumption of selection on observables, but the same line of reasoning applies to other estimators. If the
restriction of selection on observables holds true, all the variables driving self-selection of individuals and
stochastically related to the potential outcomes are observable to the researcher. Formally, identiﬁcation of
the mean impact on participants rests on the existence of an observable vector of individual characteristics X
such that the following conditions are jointly satisﬁed:
Y 0 ? IjS; X ;

SXs̄,

varfI ¼ 1jS; X g40;

ð12aÞ
SXs̄.

ð12bÞ

Then, it is as if eligible individuals were randomly assigned to the treatment with a probability of assignment
depending on S and X, provided that such probability is non-degenerate at each value of these variables. If the
set of variables X is rich enough for this assumption to be credible, the counterfactual outcome for participants
presenting characteristics ðS; X Þ can be approximated by the actual outcome of non-participants presenting
the same characteristics.10 It follows that the effect on participants away from the threshold s̄ could be
identiﬁed after controlling for X at each given value of S.
Let
sbðsÞ ¼ EfY 0 jI ¼ 1; sg  EfY 0 jI ¼ 0; sg;

sXs̄

(13)

be the selection bias that affects the raw comparison of participants and eligible non-participants scoring
S ¼ s, with SXs̄. The ﬁrst term on the right-hand side of (13) is the mean counterfactual outcome for
participants. The second term is the mean factual outcome for eligible non-participants. This quantity
summarizes pre-programme differences between eligible individuals self-selected in and out of the programme
at each level of S, with SXs̄.
Using the result stated in (10), the mean counterfactual outcome for participants on the right-hand side of
(13) is identiﬁed in a neighbourhood of s̄ provided that Condition 1 holds. Accordingly sbðs̄þ Þ, the selection
bias for individuals marginally eligible for the programme, is also identiﬁed. Clearly, identiﬁcation is
precluded as S moves away from s̄.
Let
sbðs; xÞ ¼ EfY 0 jI ¼ 1; s; xg  EfY 0 jI ¼ 0; s; xg;

sXs̄

be the bias term for a speciﬁc subpopulation of eligibles indexed by x and s, where X are the variables claimed
to properly account for the selection bias. If the orthogonality condition (12a) holds, then sbðs; xÞ ¼ 0
uniformly with respect to x and s. In particular, a necessary condition for the validity of the estimator based
on the ignorability condition (12a) is
sbðs̄þ ; xÞ ¼ 0,

(14)

which is directly testable since sbðs; xÞ is identiﬁed in a right-neighbourhood of s̄ (provided Condition 1 holds).
It follows that in a neighbourhood of s̄ any test of the equality of the mean outcomes for ineligibles and eligible
non-participants conditional on X is a test for the ignorability of participation into the programme, thus a test
on the validity of the estimator that corrects for X.
The rejection of the null hypothesis is sufﬁcient to conclude that condition (12a) does not hold. On the other
hand, by not rejecting the null hypothesis one might feel more conﬁdent in controlling for X to estimate the
effect away from s̄. However, the acceptance of the null hypothesis is not conclusive about the validity of the
10

The two conditions stated in (12) are stronger than is required, as conditional mean independence, instead of full independence, would
sufﬁce to identify the impact of the treatment on participants and the second condition need not to hold for values of X with no
participants. Note that (12b) implies that both participants and non-participants can be found at each value of ðS; X Þ, SXs̄, thus ruling out
any common support problem.

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

724

estimator for the whole population of participants: in fact, the test is not informative on whether the
ignorability condition holds away from s̄.
The testing procedure can be non-parametrically implemented along the lines of what discussed by HTV
and Porter (2002). Once the different composition with respect to the X’s of ineligibles and eligible nonparticipants around the threshold is accounted for, an estimate for the discontinuity of the regression of Y on
S at s̄ is required. Porter’s (2002) approach yields more precise estimates of such quantity, hence more
powerful test of the no discontinuity hypothesis, at the cost of imposing extra regularity conditions. Battistin
and Rettore (2002) point out that under the no discontinuity hypothesis it is hard to imagine cases in which
such extra regularity conditions are not met. Accordingly, the strategy suggested by Porter (2002) seems to be
preferred.11
4.2. Related results
The results presented in the previous section are easily summarized as follows. The ignorability condition
(12a) represents an identifying restriction for the effect of the programme on participants. On the other hand,
for the set-up considered in this paper the condition in (14) represents an over-identifying restriction for the
same parameter in a neighbourhood of s̄. Hence, the parameter of interest is locally over-identiﬁed, and
condition (12a) can be tested at s̄. Exploiting restrictions to test the assumptions non-experimental estimators
rest upon is also the idea in Rosenbaum (1984) and Heckman and Hotz (1989).
Strong similarities with other results presented in the literature can be established. First, since a RDD can be
interpreted as an experiment at s̄, the speciﬁcation test presented above develops along the same lines of what
LaLonde (1986) and Heckman et al. (1998) develop in a fully experimental set-up. In both cases there is a
benchmark estimate of the mean impact—the RDD estimate in the former case, the experimental estimate in
the latter case—to which the researcher is ready to give credibility. Then, the researcher compares nonexperimental estimates to ‘benchmark’ estimates and interprets any discrepancy thereof as a violation of the
identifying restrictions the non-experimental estimator rests upon.12
Experimental data allow to characterize the selection bias and to test the validity of non-experimental
estimators for the effect on participants (see Heckman et al., 1998). In the current set-up, this result is attained
only with reference to participants around s̄. However, the availability of experimental data is rarely
encountered in the evaluation of social policies, especially in European countries, while it is very often the case
that a policy is targeted to a population of eligible individuals whose participation into the programme is on a
voluntary basis. In this situation the information required to implement the speciﬁcation test described in the
previous section is in principle available. This provides researchers with a tool to validate non-experimental
estimators of the mean impact on participants.
Finally, while discussing the role of a second comparison group in observational studies Rosenbaum (1987,
example 2) provides an example which resembles, albeit loosely, the set-up we refer to. The advanced
placement programme (APP) provides students with the opportunity to earn college credits for work done in
high school. Some schools do not offer APP, and in those that do only a small minority of students
participate. Two comparison groups naturally arise in this context: students enrolled in high schools not
offering APP and students who do not participate although enrolled in schools offering APP.
Rosenbaum (1987) argues that the two comparison groups can be exploited to test the ignorability
condition on which the matching estimator for the effect of APP on participants relies. This can be achieved
11

The core of the testing procedure can easily be implemented by exploiting the parametric set-up presented at the end of Section 3. By
considering information for ineligibles and eligible non-participants (and assuming linearity throughout), the following regression can be
estimated:
Y ¼ a0 þ a1 S þ a2 X þ a3 Z þ e,
where Z ¼ 1ðSXs̄Þ denotes the eligibility status, and then test for a3 ¼ 0.
12
Interpreting the speciﬁcation test as a comparison of a non-experimental estimate of the mean impact on participants to the RDD
benchmark clariﬁes why the speciﬁcation test is unfeasible in the standard fuzzy RDD. As in a fuzzy set-up the RDD estimand
corresponds to the mean impact on compliers at s̄, non-experimental estimates of this parameter cannot be recovered being the set of
compliers unobservable to the researcher.

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

725

Table 1
Households living in pilot localities by eligibility status in November 1998
Poverty index
Mean

Min

Max

Participants
Eligibles
Densiﬁcados

4,000
496

0.6891
0.3068

2.8811
0.0008

0.0000
2.1676

Non-participants
Ineligibles
Forgotten

1,046
731

0.8564
0.4560

0.0030
0.0029

3.3530
2.3256

by testing whether the two groups present the same mean outcomes after their composition is balanced by
using a matching procedure. Clearly Rosenbaum’s (1987) comparison groups resemble ineligibles and eligible
non-participants of our set-up. The crucial difference is that in the former case the rule according to which
high schools decide whether to offer APP is unknown to the researcher while in the current set-up the
eligibility rule is fully speciﬁed. As a consequence, the null hypothesis tested by Rosenbaum (1987) is whether
the matching procedure is able to compensate for the selection bias induced by the two-stage (schools and
students) selection process. Our null hypothesis (14) is whether the matching procedure is able to compensate
only for the selection bias induced by self-selection amongst the eligibles, locally at s̄. Otherwise stated,
Rosenbaum (1987) puts a heavier burden on the matching procedure than we do by assuming that it solves for
a more complex selection process.
5. An empirical application
In this section we use survey data collected for the evaluation of PROGRESA (programma de Educaciòn,
Salud y Alimentacion) to apply the estimation and speciﬁcation strategies discussed above.
The PROGRESA programme aimed at encouraging investments in education, health and nutrition through
relatively large monetary transfers and in-kind beneﬁts given to poor households in rural Mexico. The
programme had three main components: an education component, for which transfers were contingent upon
children’s regular attendance at school; a health component, which consisted of a vaccination programme,
growth and development checkups for children as well as courses for mothers; and ﬁnally, a component
consisting of monetary and nutritional supplements supplied to infants and lactating mothers.13
Participation of households into the programme was originally designed to be the result of a two step
procedure (see Behrman and Todd, 1999). In the ﬁrst step, around 500 localities sharing a high degree of
marginality were randomized into a ‘pilot’ group and a ‘control’ one, respectively. In the second step, only
poor households living in ‘pilot’ localities were considered eligible to receive the programme, the eligibility
status being determined on the basis of a poverty index at the household level obtained from a discriminant
analysis applied separately on each of the seven geographical regions involved in the experiment.
As discussed by Buddelmeyer and Skouﬁas (2003, see Table 1), a simple descriptive analysis conﬁrms that
eligibility was well approximated by a sharp design for ﬁve out of seven regions, with eligible households
scoring values of the discriminant score below a region-speciﬁc threshold.14 The programme was rolled out in
‘pilot’ localities in July 1998.
All households in the evaluation sample were surveyed for the ﬁrst time in October/November 1997, thus
before the programme was introduced, and were re-interviewed six times over the three following years. The
criterion described above resulted in just above 50% of the households in the total sample being eligible for
13

The evaluation of the impact of PROGRESA was done by IFPRI in a series of reports that are summarized in Skouﬁas (2001).
In fact, as discussed by Buddelmeyer and Skouﬁas (2003), these thresholds fell roughly at the mode of the distribution of the poverty
index and were approximately the same across regions.
14

ARTICLE IN PRESS
726

E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

receiving the programme. However, this number increased to nearly 80% of the evaluation sample during
 which is the Spanish name that was
1998 as a result of a major revision to the eligibility rule (the densificacion,
given to this process). Such a revision was undertaken to increase the number of households with certain
characteristics that were felt to be under-represented when the eligibility status was ﬁrst determined, although
not much is known about the criteria actually followed to boost the eligible population (see, for example, the
discussion in Buddelmeyer and Skouﬁas, 2003).
Despite this revision process, administrative errors prevented the majority of the boosted sample from
receiving the programme. In particular, according to ofﬁcial payment records around 60% of this group had
not received any beneﬁts by March 2000, mostly because they were never incorporated into the programme
due to some administrative errors and, only to a minor extent, because of non-compliance (see Hoddinott
et al., 2000).
In our analysis we exclusively focus on ‘pilot’ localities, in which four groups of households can be deﬁned
on the basis of their participation status: eligibles, i.e. participating households who were eligible for the
programme before the revision was undertaken; densificados, i.e. participating households who became eligible
 ineligibles, i.e. households who were not eligible for the programme
for the programme after the densificacion;
 forgotten densiﬁcados, i.e. households who did not participate in the programme
after the densificacion;

though they were eligible for it after the densificacion.
Because of the randomization, the comparison of the mean outcome for eligibles in the ‘pilot’ areas to the
mean outcome for eligibles in the ‘control’ areas identiﬁes the mean impact on eligibles. Note however that the
experimental design fails to identify the mean impact on participants, namely eligibles and densificados, since
 took
the selection of densificados from the pool of households who were ineligible before the densificacion
place according to a non-random and at least partly unknown rule.
Table 1 presents a breakdown of households by the aforementioned groups using data from the second
follow-up (November 1998).15 For simplicity, we keep only households living in the ﬁve regions where the
 is well approximated by a sharp rule, dropping the very few
eligibility status before the densificacion
households whose index was not consistent with the eligibility status.16 Separately for each group of
households, we report the minimum value, the maximum value and the mean value of the poverty index,
whose values have been standardized by within-region standard deviations after calculating the differences
from the region-speciﬁc thresholds.17
In what follows we will work with two groups of participant households (i.e. those labeled eligibles and
those labeled densificados) and one group of non-participant households (obtained by pooling those labeled
ineligibles and forgotten). We will focus on educational outcomes of children in the aforementioned groups
using individual level data from the baseline survey collected in October/November 1997, as well as from two
follow-up surveys collected in October/November 1998 and October/November 1999. In particular, we will
look at the effect of PROGRESA on the proportion of children enrolled at school separately for four groups
deﬁned by gender and age. In sum, there are almost 11; 000 children aged 6–16 belonging to the eligibles
group, 1; 127 belonging to the densificados group and 3; 600 belonging to the group of non-participants. The
full report on the estimation of the impact on educational outcomes can be found in Behrman et al. (2001).
By deﬁning these three groups of children we are replicating the design described in Section 3, where the
labels for participation and eligibility have been symmetrically reversed: all subjects below the threshold
comply with the original sharp RDD assignment while some of the subjects above the threshold violate the
sharp RDD assignment according to an unknown rule. It is therefore straightforward to show that the average
effect of the treatment on non-participants (ETNP) around the threshold s̄ ¼ 0 is identiﬁed
EfY 1  Y 0 jI ¼ 0; s̄þ g ¼

15

EfY js̄ g  EfY js̄þ g
,
PrfI ¼ 0js̄þ g

The breakdown by November 1999 is informationally equivalent and therefore is not reported.
A further set of immigrant households was added to the original sampling frame starting from the ﬁrst follow-up survey (see
Angelucci, 2004), but they are not considered in the analysis presented below.
17
We used a robust estimator of the standard deviation to control for the effect of outliers in the score.
16

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

727

provided that the continuity condition on the mean of Y 1 conditional on S holds at s̄. Accordingly, selection
bias is deﬁned with respect to the outcome Y 1 .
The plan of our analysis is to replicate (for the ETNP) results presented in Figure 2a–2c in Behrman et al.
(2001) using an identiﬁcation strategy based on the regression discontinuity. First, we estimate the ETNP
around s̄ ¼ 0, separately for boys and girls and for the age groups 6211 and 12216 (to distinguish between
primary and secondary school levels). Second, we test for the presence of selection bias at s̄ ¼ 0 by comparing
school enrollment amongst marginal eligibles to school enrollment amongst marginal densificados. Third, in
those cases where the selection bias is not zero at s̄ ¼ 0, we look for a set of pre-programme characteristics x
such that the bias is zero once they are controlled for in the analysis. The effects on school enrollment are
evaluated one year (1998) and two years (1999) after the programme started.
Note that in this context the test for the presence of selection bias is a tool to check whether selection of
 is locally ignorable with
densificados from the pool of households who were not eligible before the densificacion
respect to Y 1 . Otherwise stated, we test whether the pool of densificados on the one hand and the pool of
ineligibles and forgotten densiﬁcados on the other hand share, on average, the same outcome Y 1 locally at
s̄ ¼ 0. On failing to reject the null, that is on ﬁnding that there is no systematic difference between these two
groups, one would be more conﬁdent to compare densificados to non-participants (either in ‘pilot’ or in
‘control’ areas) to identify the mean impact on densificados. By averaging the mean impacts on eligibles and on
densificados, respectively, using the relative size of the two groups as weights one gets the mean impact on
participants.
Discontinuities in the outcome of interest are estimated by contrasting the mean outcome for individuals
whose distance from s̄ ¼ 0 is within a ﬁxed bandwidth, and a sensitivity analysis with respect to different
values of this bandwidth is presented. To test for the presence of selection bias at s̄ ¼ 0, whether conditional or
unconditional on x, we use information for eligibles and for densificados only. We control for x using three
different methods: a linear probability model, where school enrollment is regressed on a dummy variable for
whether or not individuals have sp0 and the additional controls x; propensity score matching, where
individuals with sp0 are matched to individuals with s40 presenting similar values of the propensity score;
and propensity score weighting, where mean outcomes for participants are compared to weighed outcomes for
non-participants to balance the composition of the two groups with respect to the propensity score (see
Imbens, 2004). As the three sets of results were informationally equivalent, we decided to report only those
from matching.
Estimation results for the parameters of interest are reported in Table 2, together with the sample size
associated to the values of the bandwidth h considered (h is expressed in unit of standard deviation). The
signiﬁcance level has been derived by considering bootstrap conﬁdence intervals, obtained by clustering
children outcomes at the household level. In line with the results discussed by Behrman et al. (2001), the
programme effect on non-participants is larger in the second year, for the age group 12216 (for which the
enrollment rate is much smaller than for the younger group) and for girls.
As for the bias at s̄ our results suggest that it is of non-negligible size and statistically signiﬁcant for girls in
the age group 12216. In correcting for this bias, we consider a number of individual speciﬁc and village level
variables known from previous studies to be good predictors of participation at school, such as family
characteristics and family composition as well as a rich list of village level characteristics. After matching
children around the discontinuity point on this set of variables separately for the four groups considered, the
bias turns out to be statistically zero in all cases, though not negligible in some of them. In particular, for
h ¼ 0:1 the sample size might be too small resulting in large sample variability for the estimates.
6. Conclusions and caveats
It is well known from the literature on the Regression-Discontinuity Design (RDD; see HTV) that when
participation into a programme deterministically depends on whether an observable pre-programme
characteristic lies on either side of a speciﬁed threshold (sharp design), the identiﬁcation of mean effects for
marginal participants is attained under fairly weak conditions.
On the other hand, when the probability of participation change discontinuously at a speciﬁed point of the
support of the pre-programme characteristic but the size of the discontinuity is less than one, a fuzzy design

ARTICLE IN PRESS
728

E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

Table 2
Estimation and speciﬁcation testing results
h ¼ 0:10

h ¼ 0:15

h ¼ 0:20

Boys

Girls

All

Boys

Girls

All

Boys

Girls

All

Sample size 1998
6–11
Eligibles
Densiﬁcados
Non-participants
12–16
Eligibles
Densiﬁcados
Non-participants

158
80
80
141
66
92

176
67
71
125
63
82

334
147
151
266
129
174

273
119
146
237
100
145

281
108
123
216
97
140

554
227
269
453
197
285

380
141
183
328
118
199

399
127
173
296
115
188

779
268
356
624
233
387

Sample size 1999
6–11
Eligibles
Densiﬁcados
Non-participants
12–16
Eligibles
Densiﬁcados
Non-participants

138
74
71
105
42
67

158
61
62
101
49
56

296
135
133
206
91
123

238
106
133
167
64
101

264
100
106
160
72
94

502
206
239
327
136
195

344
127
163
227
73
133

370
117
153
219
86
126

714
244
316
446
159
259

Average effect for non-participants at s̄ ¼ 0
6–11
1998
3.67
12–16
0.19
6–11
1999
5:42
12–16
6.99

0.61
7.24
7:43
9.48

2.19
3.60
6:06
0.90

2.06
1.71
2.25
2.38

0.23
7.53
4.62
15:60

0.93
2.83
3:21
6.55

2:25
0.13
1.50
0.19

0.14
11:73
4:69
18:45

1.17
5.80
3:03
9:16

Bias at s̄ ¼ 0
6–11
1998
12–16
6–11
1999
12–16

1.14
10.03
3.02
15:44

0.46
6.80
1.21
5.35

1.31
0.19
0.10
3.48

0.50
11:82
1.11
16:74

0.42
5.93
0.55
7.11

1.15
1.60
0.08
3.40

0.47
12:54
1.21
19:15

0.35
5.39
0.52
8:68

1.05
25.39
7.46
13.21

0.14
8.55
3.02
7.26

0.39
0.04
0.24
5.09

0.50
8.01
0.54
8.41

0.24
7.97
5.82
9.89

0.06
1.61
0.13
0.56

0.04
0.86
2.00
4.95

0.26
1.16
1.24
1.49

1.87
3.45
0.00
6.67

Bias at s̄ ¼ 0 after controlling for x
6–11
1998
1.43
12–16
17.88
6–11
1999
0.00
12–16
12.30

Signiﬁcance based on bootstrap conﬁdence intervals, obtained by 500 replications and by clustering at the household level.

: 90%.



: 95%;

arises, which requires stronger regularity conditions and allows identiﬁcation of mean effects for a sub-set of
marginal participants.
In this paper we have shown that when an intervention is targeted to a population of eligible individuals but
is actually administered only to self-selected eligibles, it is worth collecting information separately on three
groups of subjects: ineligibles, eligible non-participants and participants. A ‘‘partially fuzzy’’ design is then
deﬁned, since individuals ineligible for the programme are denied participation but the participation status
varies amongst eligible individuals (typically, if participation is on a voluntary basis). We have derived the
regularity conditions required to identify the mean impact on participants marginally eligible for the
programme by jointly exploiting both groups. Despite the prima facie fuzzy nature of the design we deal with,
we have shown that identiﬁcation requires the same regularity conditions as in a sharp design.
Second, we have shown that the selection bias for subjects at the margin between eligibility and ineligibility
is identiﬁable. Local identiﬁcation provided by the RDD can then be used to test the validity of alternative
identifying restrictions on which non-experimental estimators for participants rely. By design, such a test is
informative only at the threshold for eligibility, thus results cannot be generalized to the whole population
(unless one is willing to impose additional restrictions). The value of the speciﬁcation test is that if it rejects the
non-experimental estimator locally then this is enough to reject it altogether.

ARTICLE IN PRESS
E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

729

The results presented rest on the Stable Unit Treatment Value Assumption (SUTVA; Rubin, 1977).
According to this assumption, the outcome experienced by each individual is not affected by assignment and
receipt of treatment by other individuals. In particular SUTVA rules out substitution effects (see the
discussion in Battistin and Rettore, 2003).
A further threat to the validity of our results occurs when subjects ineligible for the programme on the basis
of a pre-programme observable characteristic purposively modify it to become eligibles. For example, meantested policies targeted to improve family income might induce some subjects to deliberately reduce their
labour income to become eligible. If this is the case, the design loses its fundamental feature, namely to provide
a nearly randomized assignment rule in a neighbourhood of the threshold for eligibility. Simple tests to detect
entry effects are presented in Battistin and Rettore (2003) and in Lee (2004).
Acknowledgements
This paper, previously circulated as ‘‘Another Look at the Regression Discontinuity Design’’ (ﬁrst version
January 2002), beneﬁted from helpful comments by two anonymous referees and the editors, from discussion
with Alberto Abadie, Manuela Angelucci, Orazio Attanasio, Richard Blundell, David Card, Vincenzo Di
Maro, Hide Ichimura, Andrea Ichino and Barbara Sianesi and from comments by audiences at ESEM 2002,
CEPR/IZA Conference ‘‘Improving Labor Market Performance: The Need for Evaluation’’ (Bonn, October
2002), Statistics Canada Symposium 2002, LABORatorio Conference ‘‘New perspectives in public policy
evaluation’’ (Turin, November 2002), Brucchi Luchino workshop (Padova, December 2002), Dalarna
University, Cemmap, ‘‘The Regression Discontinuity Method in Economics: Theory and Applications’’
(Banff, May 2003) and Ente Einaudi. Financial support from MIUR to the project ‘‘Dynamics and inertia in
the Italian labour market and policies evaluation (data-bases, measurement issues, substantive analyses)’’ is
gratefully acknowledged.
References
Angelucci, M., 2004. Border enforcement aid, and migration. Ph.D. Thesis in Economics, University College London.
Angrist, J.D., 1998. Estimating the labor market impact of voluntary military service using social security data on military applicants.
Econometrica 66 (2), 249–288.
Angrist, J.D., Imbens, G.W., 1991. Sources of identifying information in evaluation models. NBER Technical Working Paper 117.
Angrist, J.D., Imbens, G.W., Rubin, D.B., 1996. Identiﬁcation of causal effects using instrumental variables (with discussion). Journal of
the American Statistical Association 91 (434), 444–472.
Battistin, E., Rettore, E., 2002. Testing for programme effects in a regression discontinuity design with imperfect compliance. Journal of
the Royal Statistical Society A 165 (1), 1–19.
Battistin, E., Rettore, E., 2003. Another look at the regression discontinuity design. Working Paper 01/03, Cemmap, London.
Behrman, J., Todd, P.E., 1999. Randomness in the experimental samples of PROGRESA (education, health, and nutrition programme).
International Food Policy Research Institute, Washington, DC.
Behrman, J., Sengupta, P., Todd, P.E., 2001. Progressing through PROGRESA: an impact assessment of a school subsidy experiment.
University of Pennsylvania and the International Food Policy Research Institute, Washington, DC.
Bloom, H.S., 1984. Accounting for no-shows in experimental evaluation designs. Evaluation Review 8, 225–246.
Blundell, R., Costa Dias, M., 2000. Evaluation methods for non-experimental data. Fiscal Studies 21 (4), 427–468.
Buddelmeyer, H., Skouﬁas, E., 2003. An evaluation of the performance of regression discontinuity design on PROGRESA. IZA
Discussion Paper 827.
Cook, T.D., Campbell, D.T., 1979. Quasi-Experimentation. Design and Analysis Issues for Field Settings. Houghton Mifﬂin, Boston.
Fisher, R.A., 1935. The Design of Experiments. Oliver & Boyd, Edinburgh.
Hahn, J., Todd, P.E., van der Klaauw, W., 2001. Identiﬁcation and estimation of treatment effects with a regression-discontinuity design.
Econometrica 69 (1), 201–209.
Heckman, J.J., 1990. Varieties of selection bias. The American Economic Review, vol. 80, p. 2. Papers and Proceedings of the Hundred
and Second Annual Meeting of the American Economic Association, pp. 313–318.
Heckman, J.J., 1992. Randomization and social policy evaluation. In: Manski, C., Garﬁnkel, I. (Eds.), Evaluating Welfare and Training
Programs. Harvard University Press, Cambridge, MA, pp. 201–230.
Heckman, J.J., 1997. Instrumental variables: a study of implicit behavioral assumptions used in making programme evaluations. Journal
of Human Resources XXXII, 441–462.
Heckman, J.J., Hotz, V.J., 1989. Choosing among alternative nonexperimental methods for estimating the impact of social programmes:
the case of manpower training. Journal of the American Statistical Association 84, 862–874.

ARTICLE IN PRESS
730

E. Battistin, E. Rettore / Journal of Econometrics 142 (2008) 715–730

Heckman, J.J., Smith, J., 1995. Assessing the case for social experiments. The Journal of Economic Perspectives 9 (2), 85–110.
Heckman, J.J., Ichimura, H., Smith, J., Todd, P.E., 1998. Characterizing selection bias using experimental data. Econometrica 66,
1017–1098.
Heckman, J.J., Lalonde, R., Smith, J., 1999. The economics and econometrics of active labor market programmes. In: Ashenfelter, A.,
Card, D. (Eds.), Handbook of Labor Economics, vol. 3. Elsevier Science, Amsterdam.
Hoddinott, J., Skouﬁas, E., Washburn, R., 2000. The impact of PROGRESA on consumption: a ﬁnal report. International Food Policy
Research Institute, Washington, DC.
Imbens, G.W., 2004. Semiparametric estimation of average treatment effects under exogeneity: a review. The Review of Economics and
Statistics 86 (1), 4–29.
Imbens, G.W., Angrist, J.D., 1994. Identiﬁcation and estimation of local average treatment effects. Econometrica 62, 467–476.
van der Klaauw, W., 2002. Estimating the effect of ﬁnancial aid offers on college enrollment: a regression-discontinuity approach.
International Economic Review 43 (4), 1249–1287.
LaLonde, R., 1986. Evaluating the econometric evaluations of training programmes with experimental data. American Economic Review
76, 604–620.
Lee, D., 2004. Randomized experiments from non-random selection in US house elections. Revision of the NBER Working Paper 8441.
Little, R.J.A., Yau, L., 1998. Statistical techniques for analyzing data from prevention trials: treatment of no-shows using Rubin’s causal
model. Psychological Methods 3 (2), 147–159.
Neyman, J., (with co-operation by Iwaszkiewicz, K., Kolodziejczyk, S.), 1935, Statistical problems in agricultural experimentation.
Journal of the Royal Statistical Society 2(Suppl.), 107–180.
Porter, J., 2002. Asymptotic bias and optimal convergence rates for semiparametric kernel estimators in the regression discontinuity
model. Discussion Paper 1989, Harvard Institute of Economic Research.
Quandt, R., 1972. Methods for estimating switching regressions. Journal of the American Statistical Association 67, 306–310.
Rosenbaum, P.R., 1984. From association to causation in observational studies: the role of tests of strongly ignorable treatment
assignment. Journal of the American Statistical Association 79 (385), 41–48.
Rosenbaum, P.R., 1987. The role of a second control group in an observational study. Statistical Science 2 (3), 292–306.
Roy, A., 1951. Some thoughts on the distribution of earnings. Oxford Economic Papers 3, 135–146.
Rubin, D.B., 1974. Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational Psycology
66, 688–701.
Rubin, D.B., 1977. Assignment to treatment group on the basis of a covariate. Journal of Educational Statistics 2, 4–58.
Skouﬁas, E., 2001. PROGRESA and its impacts on the human capital and welfare of households in rural mexico: a synthesis of the results
of an evaluation by IFPRI. International Food Policy Research Institute, Washington, DC.
Thistlethwaite, D.L., Campbell, D.T., 1960. Regression discontinuity analysis: an alternative to the ex post facto experiment. Journal of
Educational Psycology 51 (6), 309–317.
Trochim, W., 1984. Research Design for Program Evaluation: The Regression-Discontinuity Approach. Sage, Beverly Hills.

