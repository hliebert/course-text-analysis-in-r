Econometrica, Vol. 72, No. 5 (September, 2004), 1329–1376

MEASURING EXPECTATIONS1
BY CHARLES F. MANSKI
To predict choice behavior, the standard practice of economists has been to infer
decision processes from data on observed choices. When decision makers act with partial information, economists typically assume that persons form probabilistic expectations for unknown quantities and maximize expected utility. Observed choices may
be consistent with many alternative specifications of preferences and expectations, so
researchers commonly assume particular sorts of expectations. It would be better to
measure expectations in the form called for by modern economic theory; that is, subjective probabilities. Data on expectations can be used to relax or validate assumptions
about expectations. Since the early 1990’s, economists have increasingly undertaken to
elicit from survey respondents probabilistic expectations of significant personal events.
This article discusses the history underlying the new literature, describes some of what
has been learned thus far, and looks ahead towards making further progress.
KEYWORDS: Choice analysis, beliefs, subjective probabilities, survey research.

1. INTRODUCTION
ECONOMISTS HAVE LONG SOUGHT to predict choice behavior. The standard
practice, often called revealed preference analysis, has been to infer decision
processes from data on observed choices. These inferences are then used to
predict behavior in other settings.
The form of revealed preference analysis introduced by Samuelson (1938,
1948) supposes that a researcher observes the consumption bundles that a
single person chooses when facing different budget sets with varying relative
prices. Samuelson showed that observation of multiple (consumption, price,
income) realizations, when combined with basic assumptions of consumer theory, implies restrictions on the consumption bundles that this person would
choose when facing other budget sets. This idea, while beautifully simple, is
more a thought experiment than a practical proposal; empirical researchers
rarely observe the person-specific data that Samuelson envisioned.2 Research
in axiomatic decision theory similarly rests on a thought experiment in which
one can observe the decisions that one person would make when facing many
alternative choice sets (e.g., Savage (1954)).
The more practical form of revealed preference analysis developed by
McFadden (1974) supposes that a researcher observes the decisions made by a
1

This article is based on my Fisher–Schultz Lecture presented at the 2003 Econometric Society
European Meeting in Stockholm. Partial support was provided by National Science Foundation
Grant SES-0314312. I am grateful to Larry Blume, Jeff Dominitz, David Easley, Yitzhak Gilboa,
Michael Keane, Francesca Molinari, and Jörg Stoye for comments.
2
Economists applying Samuelson’s idea usually have used data for multiple persons and have
assumed that their preferences are homogeneous in some respects. Blundell (2003) reviews the
literature and explores the extent to which heterogeneity in preferences can be accommodated.
1329

1330

CHARLES F. MANSKI

random sample of heterogeneous persons, each of whom faces one discrete
choice problem. McFadden showed that these data, combined with assumptions on the population distribution of preferences, enable estimation of probabilistic choice models. He then showed how probabilistic choice models may
be used to predict population choice behavior in other settings.
Use of the term revealed preference analysis to describe econometric analysis
of choice data has become imprecise. The meaning of the term is clear when
decision makers know the outcomes of alternative actions. However, most
empirical research today concerns choice problems in which decision makers act with partial information. Economists commonly assume that persons
form probabilistic expectations for unknown quantities and maximize expected
utility. Hence, the research problem is to infer the subjective probability distributions that express expectations and the utility functions that embody preferences.3
The difficulty is that observed choice behavior may be consistent with many
alternative specifications of preferences and expectations. Hence, identification of decision processes from choice data must rest on strong maintained
assumptions. The prevailing practice has been to assume that decision makers
have specific expectations that are objectively correct (i.e., rational). This practice reduces the task of empirical inference to revelation of preferences alone,
but has contributed to a crisis of credibility. Researchers performing econometric analysis of choice data often have enormous difficulty defending the
expectations assumptions they maintain and, as a consequence, have similar
difficulty justifying the findings they report.
I have concluded that econometric analysis of decision making with partial
information cannot prosper on choice data alone. However, combination of
choice data with other data should mitigate the credibility problem and improve our ability to predict behavior. The data I have in mind are self-reports
of expectations elicited in the form called for by modern economic theory; that
is, subjective probabilities. Researchers can use data on expectations to relax
or validate assumptions about expectations.
Since the early 1990’s, economists engaged in survey research have increasingly asked respondents to report probabilistic expectations of significant personal events. Expectations have been elicited for macroeconomic events (stock
market returns), for risks that a person faces ( job loss, crime victimization,
mortality), for future income (earnings and Social Security benefits), and for
choices that persons make (durable purchases and voting choices). In this article, I discuss the history underlying this new literature, describe some of what
has been learned thus far, and look ahead towards making further progress.
3
Here and elsewhere, I use the single word “preferences” to mean preferences over outcomes.
This usage has been standard in applications of the expected utility model, but not in the literature on decision theory. Decision theorists often use the unadorned word “preferences” to mean
preferences over actions.

MEASURING EXPECTATIONS

1331

Sections 2 and 3 make the case that choice data alone do not provide an adequate empirical foundation for econometric analysis of decision making with
partial information. Section 2 uses two specific decision problems to illustrate
how alternative combinations of preferences and expectations can produce the
same choice data. Section 3 considers the conventional assumption that persons have rational expectations. Observing that persons forming expectations
face the same inferential problems that empirical economists confront in their
research, I find it generally implausible to assume rational expectations.
Section 4 traces the emergence of the modern economic literature eliciting probabilistic expectations from survey respondents. I critique the verbal
expectations questions posed in attitudinal research and discuss elicitation of
probabilistic expectations in cognitive psychology. I call attention to the early
work in economics of Juster (1966).
Section 5 describes some of what I have learned from my own collaborative
research measuring probabilistic expectations. I discuss worker perceptions of
job insecurity and student perceptions of the returns to schooling. I present
findings on expectations of income in the year ahead, Social Security benefits, and returns to mutual-fund investments. I suggest probabilistic polling to
measure voting expectations.
Section 6 describes three ways in which researchers have sought to evaluate the accuracy of elicited expectations. In each case, I summarize available
findings. I also suggest that probabilistic questioning may improve traditional
survey research practices asking respondents about facts.
Section 7 considers two ways in which expectations data may be used to predict choice behavior. One approach directly asks respondents to predict their
own behavior. The other combines elicited expectations with choice data to
estimate econometric decision models. I observe that use of an econometric
model to predict behavior may require an understanding of how persons would
form expectations in the setting of interest.
By and large, Sections 2–7 do not question the psychological realism of probabilistic expectations, nor that measured expectations faithfully describe persons’ internal beliefs.4 Section 8 entertains the idea, considered in research on
ambiguity, that beliefs have some but not all the structure of a probability distribution. To enable persons to express ambiguity, I suggest elicitation of ranges
of probabilities rather than precise probabilities for events of interest.
Measurement of expectations is not the only possible way to enrich choice
data. Collection of other subjective data may be useful as well. The possibilities range from elicitation of preferences to verbal probes asking persons to
describe how they make decisions. I do not discuss these other forms of subjective data here, because I have not had experience with them.
4
One exception is Section 4.2, which discusses a controversy within cognitive psychology as to
whether humans process information using verbal or numerical modes of thinking. Another is the
introduction to Section 5, which discusses concerns that probabilistic questioning may not reveal
persons’ thinking.

1332

CHARLES F. MANSKI

Nor do I discuss neuroeconomics. Interpretation of responses to subjective
questions has always run up against the problem that a researcher cannot
directly observe a person’s thinking. However, neuroscientists have recently
begun to use brain imaging technology to observe aspects of the biological
processes that accompany decision making (e.g., McCabe et al. (2001), Smith
et al. (2002)). It is too early to judge how neuroeconomics may eventually contribute to the prediction of behavior.
2. INFERENCE USING CHOICE DATA ALONE: TWO ILLUSTRATIONS
The illustrations in this section are drawn from Manski (1993a, 2002a).
The former article critiques practices in the econometric analysis of schooling
choice, and the latter calls attention to identification problems in experimental economics. Both articles assume that persons maximize subjective expected
utility. Within this paradigm, both explore how preferences and expectations
may combine to yield observed choices.
2.1. Schooling Choices and Perceptions of the Returns to Schooling
Economists analyzing schooling decisions assume that youth, having formed
expectations for the returns to schooling, choose between schooling and other
options. Given the centrality of the returns to schooling in economic thinking
on schooling behavior, it might be anticipated that economists would make
substantial efforts to learn what expectations youth hold. However, the standard practice has been to make assumptions without the benefit of data on
expectations.
Economic studies of schooling behavior have generally supposed that all
youth condition their beliefs on the same variables and process information
in the same way. However, the hypothesized conditioning variables and information processing rule vary considerably across studies. For example:
(a) In his analysis of the major field decisions of male college students,
Freeman (1971) assumed that each student observes the incomes realized by
earlier cohorts of male students and believes that, should he select a given college major, he would obtain the mean income realized by the members of a
specified earlier cohort who made that choice.
(b) In their study of college enrollment, Willis and Rosen (1979) supposed
that youth condition their expectations on sex, armed forces status, and ability.
They assumed that youth know the actual process generating life-cycle incomes
conditional on these personal covariates, and thus are able to form rational
expectations for the returns to college enrollment.
(c) In their analysis of college choice, Manski and Wise (1983, Ch. 6) assumed that youth condition their expectations for the utility of enrolling in a
given college on their own SAT score and on the average SAT score of students
enrolled at the college. Youth do not necessarily know either the outcomes re-

MEASURING EXPECTATIONS

1333

alized by earlier cohorts nor the actual process generating outcomes. Rather,
they believe the returns to enrolling to be a function of their own SAT score
and the average at the college.
The expectations assumptions in these studies differ in many respects, one of
which is the way in which youth are assumed to use ability information to form
expectations. Whereas Freeman (1971) assumed that youth do not condition
their expectations on ability, Willis and Rosen (1979) assumed that they do
condition on ability and that they have rational expectations. Manski and Wise
(1983) assumed that they use SAT score, which may be associated with ability,
to form expectations that may or may not be rational.
This variation in expectational assumptions is consequential. Manski (1993a)
used a simple human capital model to demonstrate that interpretation of data
on schooling choices can depend critically on how youth actually use ability
information to form expectations of the returns to schooling. A particularly
striking finding was that, if youth do not condition their expectations on ability,
a researcher who assumes they do so may mistakenly conclude from observed
choices that youth are unconcerned with the returns to schooling.
2.2. Identification of the Decision Rules of Proposers in Ultimatum Games
The behavior of subjects playing the ultimatum game has been of considerable interest to experimental economists. The ultimatum game is a game of
proposal–response in which the proposer offers a division of a specified sum
of money. The responder either accepts the offer, in which case the division is
realized, or rejects it, in which case both players receive nothing. Roth (1995,
Ch. 4) reviews the empirical findings. A particularly common finding has been
that proposers often offer responders an even division of the money. Experimental economists have taken this as evidence of a prevalent preference for
fairness. However, the decision to offer an even division can also arise when a
proposer who wants to maximize private utility has appropriate expectations
about the behavior of responders.
To illustrate, suppose that a proposer is given K dollars and that C = [0 K]
is the set of offers he can make to the responder. For c ∈ C, let d(c) = 1 if the
responder would accept an offer of size c and let d(c) = 0 if he would reject
the offer. Then the payoffs to the proposer and responder are y(1 c d) = (K −
c)d(c) and y(2 c d) = cd(c), respectively.
Assume that agents playing the role of proposer are known to be of six types,
each having one of two utility functions and one of three forms of expectations.
The possible utility functions are:
U1 [y(1 c d) y(2 c d)] = y(1 c d) = (K − c)d(c)
U2 [y(1 c d) y(2 c d)] = y(1 c d) · y(2 c d)
= [(K − c)d(c)]cd(c)

1334

CHARLES F. MANSKI

Agents with the first utility function aim to maximize their own payoff. Those
with the second exhibit a strong form of fairness in which they care equally
about their own payoff and that of the other player.
Suppose that the three forms of expectations are
1
+ min(c/K 1/2)
2
Q2 [d(c) = 1] = min[c/(K − c) 1]

Q1 [d(c) = 1] =

Q3 [d(c) = 1] = min(c/K 1)
Agents with the first form of expectations believe that the probability with
which a responder would accept a proposal rises from 1/2 to 1 as the size of the
offer rises from 0 to K/2. Those with the second form believe that the chance
of acceptance rises from 0 to 1 as the offer rises from 0 to K/2. Those with the
third form believe that the chance of acceptance rises from 0 to 1 as the offer
rises from 0 to K.
Let c(i j) be the action chosen by a proposer who has the ith utility function
and the jth form of expectations. Maximization of expected utility by the six
types of agents yields these chosen actions:
c(1 1) = K/4

c(1 2) = K/2

c(1 3) = K/2

c(2 1) = K/2

c(2 2) = K/2

c(2 3) = 2K/3

Observe how preferences and expectations combine to determine the chosen
actions. Fully four of the six types offer the responder an even division of the
money. Agents with both utility functions offer an even division if they have
the second form of expectations. Thus, choice data do not reveal the preferences of agents playing proposer in the ultimatum game. They reveal only that
preferences and expectations combine to yield the observed offers.
3. RATIONAL EXPECTATIONS ASSUMPTIONS
The above illustrations exemplify a familiar abstract problem of decision
making with partial information. Let C be a choice set, Γ be a space of feasible
states of nature, γ ∗ ∈ Γ denote the true state of nature, and f (· ·) : C × Γ → R
be an objective function. Assume that a decision maker wants to choose an
action that solves
(1)

max f (c γ ∗ )
c∈C

The problem is that the decision maker does not know the value of γ ∗ . In
the schooling-choice illustration, the unknown state of nature was the return
to schooling. In the ultimatum-game illustration, it was the function d(·) expressing how the responder would react to offers of different sizes.

MEASURING EXPECTATIONS

1335

A person who does not know γ ∗ can solve problem (1) only if there is a dominant action; that is, a c ∈ C such that f (c γ) ≥ f (d γ), all (d γ) ∈ C × Γ .
Decision theorists have sought to prescribe how persons should behave when
there is no dominant action, but no consensus has emerged. One normative
principle is that a person should not choose a weakly dominated action; action d is weakly dominated if there exists another action, say c, such that
f (d γ) ≤ f (c γ) for all γ ∈ Γ and f (d γ) < f (c γ) for some γ ∈ Γ .
Economists regularly assume that decision makers place subjective probability distributions on the feasible states of nature and maximize subjective
expected utility. It is routine to assume that a person who cannot solve problem (1) instead solves the problem

max u[f (c γ)] dQ
(2)
c∈C

where Q denotes the subjective distribution on Γ and where u(·) : R → R is
an increasing transformation of f . Economists also regularly assume that γ ∗ is
the realization of a random variable and that decision makers have rational
expectations; that is, they know the objective probability distribution that generates γ ∗ .5
Although economists routinely assume rational expectations, they only occasionally ask how persons could know the objective distribution, say P, generating γ ∗ . Researchers have shown that particular learning processes reveal some
features of P in specific circumstances. See, for example, Cyert and DeGroot
(1974), Blume and Easley (1982), Bray and Kreps (1987), Marcet and Sargent
(1989), Kalai and Lehrer (1993), and Manski (1993b). However, the plausibility of rational expectations has been questioned sharply by authors such as
Pesaran (1987), who writes (p. 2) that the rational expectations hypothesis “is
based on extreme assumptions and cannot be maintained outside the tranquility of a long-period steady state.” Considering the problem of expectations
formation, I too have concluded that rational expectations assumptions often
are implausible in the extreme.
Suppose that the true state of nature actually is the realization of a random variable distributed P. A decision maker attempting to learn P faces the
same inferential problems—identification and induction from finite samples—
that empirical economists confront in their research. Whoever one is, decision
5
To justify the assumption that persons solve (2), economists may cite the Savage (1954) axiomatic derivation of the subjective-expected utility criterion. Savage assumed that a person has
a complete preference ordering on a universe of actions and showed that if this ordering satisfies
certain other axioms, the preference ordering can be obtained by maximization of subjective expected utility. The normative appeal and empirical realism of the Savage axioms have long been
debated. Whatever one’s view on these matters may be, it is important to understand that the
axioms imply no restrictions on the substantive form of probabilistic expectations. In particular,
they do not imply that expectations are rational.

1336

CHARLES F. MANSKI

maker or empirical economist, the inferences that one can logically draw are
determined by the available data and the assumptions that one brings to bear.
Empirical economists seldom are able to completely learn objective probability
distributions of interest, and they often cannot learn much at all. It therefore
seems hopelessly optimistic to suppose that, as a rule, expectations are either
literally or approximately rational.
To illustrate, consider again the problem of schooling choice. In Manski
(1993a), I observed that youth who form earnings expectations confront the
same inferential problems as do labor economists when they study the returns
to schooling. The literature in labor economics exhibits much debate on the
credibility of assumptions and many disagreements about findings. If experts
disagree on the returns to schooling, is it plausible that youth have rational
expectations? I think not.
I would particularly stress that decision makers and empirical economists
alike must contend with the logical unobservability of counterfactual outcomes. Much as economists attempt to infer the returns to schooling from data
on schooling choices and outcomes, youth may attempt to learn through observation of the outcomes experienced by family, friends, and others who have
made their own past schooling decisions. However, youth cannot observe the
outcomes that these people would have experienced had they made other decisions. The possibilities for inference, and the implications for decision making,
depend fundamentally on the assumptions that youth maintain about these
counterfactual outcomes.
Even if the assumption of rational expectations were plausible, this assumption per se does not specify the expectations that persons hold; it asserts only
that persons hold objectively correct expectations conditional on the information they possess. Economists typically assume much more than this. The standard practice has been for a researcher to pose a model of the economy, to
assert that this model is correct, and also to assert knowledge of the information on which agents condition their expectations. The rational expectations
hypothesis in combination with these additional assumptions closes the model.
Why do economists so often assume that they and the decision makers they
study share rational expectations? Part of the reason may be the elegant manner in which these assumptions close an economic model. A researcher specifies his own vision of how the economy works, and he assumes that the persons
who populate the economy share this vision. This is tidy and self-gratifying.
Another part of the reason must be the data used in empirical research.
As illustrated in Section 2, choice data do not necessarily enable one to infer the expectations that decision makers hold. Hence, researchers who are
uncomfortable with rational expectations assumptions can do no better than
invoke some other unsubstantiated assumption. Rather than speculate on how
expectations actually are formed, they follow convention and assume rational
expectations.

MEASURING EXPECTATIONS

1337

4. ELICITATION OF EXPECTATIONS FROM SURVEY RESPONDENTS
If choice data alone do not suffice to infer how persons make decisions
with partial information, one might anticipate that economists would ask persons about their preferences and expectations. However, economists have been
deeply skeptical of subjective statements; they often assert that one should believe only what people do, not what they say. As a result, the profession for
many years enforced something of a prohibition on the collection of subjective
data.
It is reasonable to ask whether the conventional economic wisdom on collection of subjective data is well grounded. I sought to determine the scientific basis underlying economists’ hostility to measurement of expectations, but
found it to be meager. One influential event appears to have been the Machlup
(1946) criticism of then ongoing efforts by economists to interview businessmen about their cost and revenue expectations. Another important part of
the story occurred in the 1950’s and early 1960’s, when economists reported
negative evidence on the usefulness in predicting consumer purchase behavior of verbal assessments of expected household finances (National Bureau
of Economic Research (1960), Juster (1964)). These specific events appear to
have predisposed academic economists to draw the broad but unsubstantiated
conclusion that all data on expectations are suspect.6
Other social scientists have not shared economists’ inhibitions about collection of expectations data. Section 4.1 critiques the verbal expectations questions posed in attitudinal research. Section 4.2 discusses elicitation of verbal
and probabilistic expectations in cognitive psychology. I then turn to the economics literature from Section 4.3 onward.
6
Dominitz and Manski (1997a, 1999) describe this history. In the 1940’s, the Federal Reserve
Board began to fund an annual Survey of Consumer Finances, conducted by the University of
Michigan Survey Research Center (SRC), that elicited verbal assessments of expected household
finances. The usefulness of responses to the SRC questions was controversial and the Board of
Governors appointed a committee to assess their value. The Federal Reserve Consultant Committee on Consumer Survey Statistics (1955) questioned the predictive value of subjective data,
with the exception of purchase intentions. The conclusions were at odds with the views of SRC
researchers, notably George Katona, a leading proponent of research on consumer attitudes
(Katona (1957)). A contentious conference on expectations data at the National Bureau of Economic Research (1960) was followed by an intensive study by Juster (1964) that drew largely
negative conclusions on the usefulness of verbal expectations data in predicting individual behavior.
Although academic economists retreated from collection and analysis of personal expectations data by the early 1960’s, SRC has continued to elicit verbal expectations in its Survey of
Consumers and to report aggregate findings in its Index of Consumer Sentiment (Curtin (1982)).
Other nonacademic organizations, such as the Conference Board (Linden (1982)) have since initiated their own surveys of consumer confidence. Moreover, the Livingston Panel and the Survey
of Professional Forecasters elicit point predictions of macroeconomic variables from experts; see
Caskey (1985) and Keane and Runkle (1990).

1338

CHARLES F. MANSKI

4.1. Attitudinal Research
Attitudinal researchers have long used verbal questions to measure expectations. When asked to predict some outcome, respondents may be asked to
report whether they “think” or “expect” that the event will occur. Sometimes
they are asked to report the strength of this belief by attaching one of a choice
of modifiers, such as “very,” “fairly,” “not too,” or “not at all” likely that the
event will occur. A prominent example is this Michigan Survey of Consumers
question on business conditions (Curtin (1982)):
Survey of Consumers Business-Conditions Question: Now turning to business conditions in
the country as a whole—do you think that during the next 12 months we’ll have good times
financially, or bad times, or what?

Another is this question on job loss in the General Social Survey (Davis and
Smith (1994)):
General Social Survey Job-Loss Question: Thinking about the next twelve months, how
likely do you think it is that you will lose your job or be laid off—very likely, fairly likely,
not too likely, or not at all likely?

These questions illustrate a persistent problem that researchers face in interpreting verbal expectations data—assessment of the interpersonal comparability of responses. How do respondents to the Michigan survey interpret the
phrases “business conditions” and “good times financially?” Do different respondents to the General Social Survey interpret the phrases “very likely, fairly
likely, not too likely, or not at all likely” in the same way? Cognitive research
does not give reason to think that responses should be or are comparable. Indeed, the available empirical evidence indicates that interpretations of verbal
expectations questions vary substantially between persons (Lichtenstein and
Newman (1967), Beyth-Marom (1982), Wallsten et al. (1986)). One may also
question whether responses are intra-personally comparable; that is, a given
respondent may interpret verbal phrases in different ways when asked about
different events.
A second persistent problem is that the coarseness of the response options
limits the information contained in the responses. Consider, for example, the
fertility question asked female respondents in the annual June Supplement to
the Current Population Survey of the U.S. Bureau of the Census:
Current Population Survey Fertility Question: Looking ahead, do you expect to have any
(more) children?
Yes No Uncertain.

The three response options express little of the richness of the uncertainty
that women may perceive about their future childbearing.
The influential Fishbein-Ajzen model of intentions illustrates the loose manner in which attitudinal researchers have thought about expectations. Fishbein
and Ajzen (1975) propose that “intention” is a mental state that causally precedes behavior and that can be elicited through questionnaires or interviews.

MEASURING EXPECTATIONS

1339

According to Ajzen and Fishbein (1980), a person’s “behavioral intention” is
his subjective probability that the behavior of interest will occur. (They refer to
the response to a yes/no intentions question as “choice intention.”) It seems,
however, that social psychologists do not use the term “subjective probability”
as a Bayesian statistician would. Ajzen and Fishbein (1980, p. 50) state: “we
are claiming that intentions should always predict behavior, provided that the
measure of intention corresponds to the behavioral criterion and that the intention has not changed prior to performance of the behavior.” In a review
of attitudinal research, Schuman and Johnson (1976, p. 172) write that the
Fishbein–Ajzen model implies that “the correlation between behavioral intention and behavior should approach 1.0, provided that the focal behavior is the
same in both cases and that nothing intervenes to alter the intention.” It is difficult to reconcile these statements with the idea that behavioral intention is a
subjective probability, unless that probability is always zero or one.
4.2. Probabilistic Expectations in Cognitive Psychology
If persons can express their expectations in probabilistic form, elicitation of
subjective probability distributions should have compelling advantages relative to verbal questioning. Perhaps the most basic attraction is that probability
provides a well-defined absolute numerical scale for responses; hence, there
is reason to think that responses may be interpersonally comparable. Another
attraction is that empirical assessment of the internal consistency of respondents’ expectations is possible. A researcher can use the algebra of probability
(Bayes Theorem, the Law of Total Probability, etc.) to examine the internal
consistency of a respondent’s expectations about different events.
When probability has a frequentist interpretation, a researcher can compare elicited subjective probabilities with known event frequencies and reach
conclusions about the correspondence between subjective beliefs and frequentist realities. Such calibration studies have a long history in cognitive psychology. Lichtenstein, Fischhoff, and Phillips (1982) review findings from 1906 on,
and McClelland and Bolger (1994) update the review with findings from 1980
through 1994. Whereas the older studies mostly examined the accuracy of experts (e.g., weather forecasters’ reported probabilities of precipitation), much
recent research analyzes the expectations of nonexperts, especially students in
a cognitive laboratory.
Within cognitive psychology, there has been controversy about the way in
which humans internally represent their beliefs, and their ability and willingness to express their beliefs as numerical probabilities. Koriat, Lichtenstein,
and Fischhoff (1980) and Ferrell and McGoey (1980) posed models in which
individuals may have some difficulty expressing beliefs as numerical probabilities, but nevertheless concluded that elicitation of numerical subjective probabilities is feasible. However, Zimmer (1983, 1984) argued that humans process
information using verbal rather than numerical modes of thinking, and he

1340

CHARLES F. MANSKI

concluded that expectations should be elicited in verbal rather than numerical forms.
Erev and Cohen (1990) and Wallsten et al. (1993) have reported that a majority of respondents prefer to communicate their own beliefs verbally and to
receive the beliefs of others in the form of numerical probabilities. This asymmetry is intriguing but only marginally relevant to the design of expectations
questions. The relevant question is not what communication mode respondents prefer to use, but rather what modes they are willing and able to use.
Wallsten et al. (1993) report that virtually all of their respondents were willing
to communicate their beliefs numerically, should the situation warrant it.
Another ongoing controversy concerns the manner in which persons process
objective probabilistic information. In an influential article, Tversky and
Kahneman (1974) summarized some randomized experiments in which subjects were presented with statistics of various forms and were asked for
probabilistic predictions of specified events. They interpreted the findings as
showing that persons tend to use certain heuristic rules to process data, rather
than Bayes theorem. To the extent that the Tversky and Kahneman experiments shed light on expectations formation in real life, they cast doubt on the
assumption of rational expectations, not on the representation of expectations
through subjective probability distributions.7
The controversy concerns the degree to which the Tversky–Kahneman and
similar experiments do shed light on subjects’ use of Bayes theorem to process
data. Gigerenzer (1991) argued that the reported empirical regularities result
not from respondents’ use of heuristics but from the manner in which statistical
information was presented to them. Here and elsewhere (e.g., Hoffrage et al.
(2000)), Gigerenzer and his colleagues have reported experimental evidence
indicating that respondents perform much better in applying probability theory
when statistics are presented in the form of natural frequencies rather than
objective probabilities (e.g., “30 out of 10,000 cases,” rather than “.3 percent
of cases”).
7
Some researchers have used Tversky and Kahneman (1974) to argue that expectations should
be elicited in verbal rather than probabilistic form (e.g., Jamieson and Bass (1989)). However, the
experimental evidence does not relate to this question. Tversky and Kahneman did not report
experiments with verbal elicitation of expectations. The deviations from correct application of
probability theory that they found were discoverable only because they elicited expectations in
probabilistic form.
Indeed, Tversky and Kahneman (1974) argued for the psychological realism of subjective probabilities. Considering the propensity of decision theorists to view subjective probabilities as constructs that may be inferred from choices, they wrote (p. 1130): “It should perhaps be noted that,
while subjective probabilities can sometimes be inferred from preferences among bets, they are
normally not formed in this fashion. A person bets on team A rather than on team B because
he believes that team A is more likely to win; he does not infer this belief from his betting preferences. Thus, in reality, subjective probabilities determine preferences among bets and are not
derived from them, as in the axiomatic theory of rational decision.”

MEASURING EXPECTATIONS

1341

4.3. Probabilistic Expectations in Economics
Among economists, the idea that measurement of probabilistic expectations
might improve on the verbal approaches of attitudinal research appears to have
originated with Juster (1966). Considering the case in which the behavior of
interest is a binary purchase decision (buy or not buy), Juster considered how
responses to traditional yes/no buying intentions questions should properly be
interpreted. He wrote (Juster (1966, p. 664)): “Consumers reporting that they
‘intend to buy A within X months’ can be thought of as saying that the probability of their purchasing A within X months is high enough so that some
form of ‘yes’ answer is more accurate than a ‘no’ answer.” Thus, he hypothesized that a consumer facing a yes/no intentions question responds as would
a statistician asked to make a best point prediction of a future random event.
Working from this hypothesis, Juster concluded that it would be more informative to ask consumers for their purchase probabilities than for their buying
intentions.8 In particular, he proposed questions that associate verbal expressions of likelihood with numerical probabilities to elicit purchase expectations
for automobiles and other household appliances:
Juster Purchase Probability Questions: Taking everything into account, what are the
prospects that some member of your family will buy a ____ sometime during the next
_____ months, between now and ____ ?
Certainly, Practically Certain (99 in 100); Almost Sure (9 in 10); Very Probably
(8 in 10); Probably (7 in 10); Good Possibility (6 in 10); Fairly Good Possibility
(5 in 10); Fair Possibility (4 in 10); Some Possibility (3 in 10); Slight Possibility
(2 in 10); Very Slight Possibility (1 in 10); No Chance, Almost No Chance (1 in 100).

He went on to collect data and found that elicited purchase probabilities are
better predictors of subsequent individual purchase behavior than are yes/no
intentions data.
Some market researchers were attracted to Juster’s proposal (e.g., Morrison
(1979)). The idea that expectations might be elicited probabilistically from survey respondents did not, however, draw the immediate attention of economists.
By the time Juster’s article was published, economists were preaching that empirical research on decision making should be based on choice data alone.
A quarter century passed before economists began to systematically collect
and analyze probabilistic expectations data.
The conventional economic wisdom unraveled in the 1990’s. Various largescale sample surveys now use probabilistic formats to elicit expectations, and
a new field of empirical research on expectations has emerged. The major
platforms for methodological exploration and substantive research include the
Health and Retirement Study (Juster and Suzman (1995), Hurd and McGarry
8
Tobin (1959) interpreted intentions data in much the same way, but he did not go on to propose elicitation of probabilities. More recently, I derived a formal upper bound on the information about probabilistic expectations that a researcher can extract from responses to Yes/No
intentions questions (Manski (1990)).

1342

CHARLES F. MANSKI

(1995)), the Bank of Italy’s Survey of Household Income and Wealth (Guiso,
Jappelli, and Terlizzese (1992), Guiso, Jappelli, and Pistaferri (2002)), the Survey of Economic Expectations (Dominitz and Manski (1997a, 1997b)), the
Dutch VSB Panel Survey (Das and Donkers (1999)), and the 1997 cohort of
the National Longitudinal Survey of Youth (Fischhoff et al. (2000), Dominitz,
Manski, and Fischhoff (2001), Walker (2001)). Even the venerable Michigan
Survey of Consumers now includes some probabilistic questions along with its
traditional verbal questions (Dominitz and Manski (2003, 2004)).9
5. A SELECTION OF FINDINGS
This section describes some of what I have learned from my collaborative
research eliciting probabilistic expectations from respondents to surveys in the
United States. This work has mainly sought to answer basic empirical questions: How willing and able are respondents to reply to such questions? What
expectations do persons hold for their futures?
Although a long-term objective is to use expectations data to predict behavior, it has been natural to focus first on elementary matters. Showing that
respondents are willing and able to respond to probabilistic questions is an obvious prerequisite for substantive interpretation of the data. When I began to
collect expectations data in the early 1990’s, I encountered considerable skepticism from researchers who asserted that probabilistic questioning would not
“work.” One common assertion was that respondents would either refuse to
answer the questions or would only give the responses 0, 50, and 100 percent.
This concern has largely been laid to rest as empirical evidence has accumulated. I and other researchers have repeatedly found that respondents are as
willing to respond to probabilistic questions as they are to traditional attitudinal questions on the same subjects. Moreover, they use the full expanse of the
0–100 percent chance scale, typically rounding to the nearest 5 percent.10
9
These are all surveys of individuals or households. I am aware of only one survey of firms
that has used probabilistic questioning to elicit business expectations. This is the Italian Survey
of Investment in Manufacturing, which has asked firms to provide probabilistic predictions of
product demand. See Guiso and Parigi (1999).
10
Respondents tend to report values at one-percent intervals at the extremes (i.e., 0, 1, 2, and
98, 99, 100) and at five-percent intervals elsewhere (i.e., 5, 10     90, 95). Responses tend to be
more bunched at 50 percent than at adjacent round values (40, 45, 55, 60), but not excessively
so. The studies summarized in this section provide detailed information on the distributions of
response to specific questions.
To encourage full use of the percent chance scale, it helps to familiarize respondents with the
scale before commencing substantive questioning. The Survey of Economic Expectations, which
will be discussed in Sections 5.1–5.3, uses this introductory statement and opening question about
the weather:

Survey of Economic Expectations Introduction and Opening Question: Now I will ask you
some questions about future, uncertain outcomes. In each case, try to think about the

MEASURING EXPECTATIONS

1343

Another common assertion was that, in the absence of incentives for honest revelation of expectations, responses to expectations questions might not
reveal the expectations that persons truly hold.11 It is not possible to directly
observe respondents’ thinking; hence, this assertion is not formally refutable.
However, it is possible to informally judge the face validity of responses by
examining the degree to which persons give internally consistent, sensible responses to the questions posed. The studies described in this section and in
Section 6 mainly, although not always, conclude that responses do possess face
validity when the questions concern well-defined events that are relevant to
respondents’ lives.
Having demonstrated that probabilistic questioning does “work,” straightforward description of respondents’ risk perceptions, income and employment
expectations, and beliefs about other events has been interesting per se to
economists who heretofore have only been able to speculate about the expectations that people hold. Thus, the work described below is descriptive rather
than applied directly to the analysis of decision making. I discuss aspects of my

whole range of possible outcomes and think about how likely they are to occur during
the next 12 months. In some of the questions, I will ask you about the percent chance of
something happening. The percent chance must be a number from 0 to 100. Numbers like
2 or 5 percent may be ‘almost no chance,’ 20 percent or so may mean ‘not much chance,’
a 45 or 55 percent chance may be a ‘pretty even chance,’ 80 percent or so may mean a ‘very
good chance,’ and a 95 or 98 percent chance may be ‘almost certain.’ The percent chance
can also be thought of as the number of chances out of 100.
Let’s start with the weather where you live. What do you think is the percent chance
(what are the chances out of 100) that it will rain tomorrow?
11
An absence of incentives is a common feature of all survey research, not a specific attribute
of expectations questions. I am aware of no empirical evidence that responses to expectations
questions suffer more from incentive problems than do responses to other questions commonly
asked in surveys.
The literature on proper scoring rules develops incentive mechanisms for honest revelation of
expectations concerning observable events (e.g., Shuford, Albert, and Massengill (1966), Savage
(1971)). These mechanisms encourage honest revelation under the assumption that respondents
maximize expected utility and are risk neutral. Perhaps the simplest one, applicable when the
event is binary, gives the respondent a reward whose magnitude decreases with the squared deviation between the event realization (0 or 1) and the elicited probability. The mean of a distribution
is the optimal prediction under square loss, and the mean of a binary event is the probability that
the event will occur. Hence, with this reward function, a person’s optimal forecast is his subjective
probability for the event.
Proper scoring rules have been applied in experimental research (e.g., Nyarko and Schotter
(2002)) and in educational testing (see Section 6.4), but not in survey research eliciting expectations. An important reason is that application of a proper scoring rule requires the researcher to
verify what events do and do not occur. Verification commonly is not practical and sometimes is
not possible in principle. Another reason may be doubt about the validity of the assumption that
respondents are risk-neutral expected-utility maximizers who are able to correctly deduce what
response is optimal given the specified reward function.

1344

CHARLES F. MANSKI

research on perceptions of job insecurity (Section 5.1), income expectations
(Section 5.2), Social Security expectations (Section 5.3), mutual-fund investment expectations (Section 5.4), probabilistic polling (Section 5.5), and expectations of the returns to schooling (Section 5.6).
5.1. Perceptions of Job Insecurity
Worker perceptions of job insecurity have been hypothesized to be determinants of economic outcomes ranging from wages and employment to consumption and savings. Meaningful empirical conclusions about the effects of
job insecurity can be drawn only if the concept is defined clearly and measured
appropriately. Writers often use the expression job insecurity without formal
definition, but usage indicates that the expression is commonly intended to
convey the chance that a worker will lose his present job and subsequently not
obtain a position of comparable value.
Until recently, the only measures of perceptions of job insecurity available
in the United States were the responses to verbal questions such as the General Social Survey question about job loss cited in Section 4.1.12 For the period 1994–2002, probabilistic measures of job insecurity are available through
the nationwide Survey of Economic Expectations (SEE), a repeated crosssectional survey designed by Jeff Dominitz and myself. The survey procedures
are described in Dominitz and Manski (1997b).13
Following an introductory segment familiarizing respondents with the percent chance scale, persons holding jobs were asked these questions eliciting
expectations of job loss and search outcomes:
SEE Job-Loss Question: I would like you to think about your employment prospects over
the next 12 months. What do you think is the percent chance that you will lose your job
during the next 12 months?
SEE Search-Outcome Question: If you were to lose your job during the next 12 months,
what is the percent chance that the job you eventually find and accept would be at least as
good as your current job, in terms of wages and benefits?

Respondents were also asked for the percent chance that they would voluntarily quit in the next 12 months.
12
The General Social Survey also asks this verbal question about search outcomes: “About how
easy would it be for you to find a job with another employer with approximately the same income
and fringe benefits that you now have? Would you say very easy, somewhat easy, or not easy at
all?”
13
SEE was administered as a module in WISCON, a continuous national random-digit telephone survey conducted by the University of Wisconsin Survey Center. The data for the 5432
SEE interviews completed from 1994 through early 1998 have been archived by the Data and
Program Library Service of the University of Wisconsin-Madison, and are available on the web at
http://dpls.dacc.wisc.edu/econexpect/index.html. The data for all interviews completed from 1994
through 2002 are available from the author.

1345

MEASURING EXPECTATIONS
TABLE I
Job Loss

Search Outcome

Quantile

Quantile

Mean

.25

.50

.75

Mean

.25

.50

.75

14.7

0

5

20

57.0

30

60

89

Source: Manski and Straub (2000).

Manski and Straub (2000) examine 3561 responses to these questions obtained from 1994 through early 1998.14 As shown in Table I, the distribution
of responses to the job-loss question is highly skewed. Most respondents perceive little or no chance of job loss in the year ahead, but some view themselves
as facing a moderate to high risk. The distribution of responses to the searchoutcome question has a very different shape. This distribution is approximately
symmetric and quite dispersed.
The shape of the empirical distribution of search-outcome responses has an
interesting interpretation in terms of the theory of job search. Standard models
of job search with time-invariant reservation wages imply that the responses to
the search-outcome question should be distributed uniformly on [0 1]. The
empirical distribution of responses is reasonably close to uniform.
The responses to the job-loss and search-outcome questions can be combined to yield a composite measure of job insecurity. Let L denote the response to the job-loss question and S denote the response to the question on
search outcome conditional on job loss. Then L × (100 − S)/100 gives the percent chance that a worker will lose his job in the year ahead and subsequently
not obtain a position of comparable economic value. Examination of the crosssectional and time-series variation across respondents in their perceptions of
job insecurity yields several interesting findings: (a) Expectations of job loss
tend to decrease markedly with age, but so do expectations of a good outcome
should job search become necessary. The net result is that the measure of composite job insecurity tends not to vary at all with age. (b) Subjective probabilities of job loss tend to decrease with schooling, and subjective probabilities of
good search outcomes tend to increase with schooling. Hence composite job
insecurity tends to decrease with schooling. (c) Perceptions of job insecurity
vary little by sex but vary substantially by race. The main differences are in expectations of job loss, with the subjective probabilities of blacks tending to be
nearly double those of whites.
14

These questions were posed to the 3812 respondents who reported that they were working at
the time of the interview. Of these, 3561 provided basic demographic information and answered
the job-loss, search-outcome, and voluntary-quit questions.

1346

CHARLES F. MANSKI

5.2. Income Expectations
Economic analysis of household behavior assigns a central role to income expectations as a determinant of consumption/savings decisions. Not having data
on income expectations, economists studying consumption/saving have made
assumptions. Consider, for example, Hall and Mishkin (1982), Skinner (1988),
Zeldes (1989), Caballero (1990), and Carroll (1992). Each study assumes that
persons use their own past incomes to forecast their future incomes. Perhaps
so, but how do persons form expectations of future income conditional on past
income? Each study assumes that persons know the actual stochastic process
generating their income streams; thus, they have rational expectations. Perhaps
so, but what is this stochastic process? Each study specifies some parametric
model of the income process and uses available data on income realizations to
estimate the parameters.
Dominitz and Manski (1997a) analyzed household income expectations reported by respondents to a preliminary version of the Survey of Economic Expectations in 1993.15 In principle, expectations for a continuous variable such
as income could be elicited in various ways. Respondents might be asked to
report quantiles of their subjective distributions, moments of the distribution,
or points on the cumulative distribution function. Morgan and Henrion (1990)
discuss the practical pros and cons of different procedures for eliciting subjective distributions. Their recommendations formed the basis for our approach,
with some tailoring of the procedures to fit the survey medium (telephone interview) and subject matter. In a telephone survey it is infeasible to present
visual aids that may help respondents to understand questions and to think
probabilistically. Use of the telephone medium led us to reject elicitation of
quantiles or moments of the subjective income distribution in favor of eliciting
points on the distribution function.16
Respondents were first asked to report the lowest and highest levels of income that they think possible in the year ahead. The responses to these preliminary questions were used to set thresholds (Y ) for a series of four probabilistic
questions, of this form:17
15
Expectations for household income were elicited only in the 1993 version of SEE. Expectations of personal income were elicited from 1994 onward.
16
We did elicit the medians of subjective income distributions in an explanatory study of the
returns-to-schooling expectations of high school and college students (Dominitz and Manski
(1996)). That study used an interactive computer program to elicit expectations. See Section 5.6
for further discussion.
17
We did not interpret the answers to the preliminary questions literally as minimum and
maximum incomes; the phrases “lowest possible” and “highest possible” are too vague to warrant this formal interpretation. Instead, we used the responses to suggest the support of the
respondent’s subjective distribution. Our reasoning was that responses to questions about a
range of thresholds spanning the support of a respondent’s subjective distribution should yield
more information about the shape of the distribution than would the same number of questions
asked about a narrower or wider range of thresholds. Morgan and Henrion (1990) offer two

MEASURING EXPECTATIONS

1347

SEE Household Income Expectations Questions: What do you think is the percent chance
(or what are the chances out of 100) that your total household income, before taxes, will
be less than Y over the next 12 months?

After division by 100, the responses give four points on a person’s subjective
distribution for household income in the year ahead. Thus, for each respondent i, we observe Fik ≡ P(y < Yik |Ψi ) k = 1 2 3 4, where y denotes future
income, Ψi is the information available to respondent i, and (Yi1  Yi2  Yi3  Yi4 )
are the income thresholds about which this respondent is queried.18
The subjective probabilities (Fik  k = 1     4) elicited from respondent i
imply bounds on his subjective income distribution but do not identify the
distribution. To facilitate analysis, we used the expectations data to fit a
respondent-specific parametric distribution. Let F(Y ; M Q) denote the lognormal distribution function with median M and interquartile range (IQR) Q,
evaluated at any point Y . Let (Mi  Qi ) solve the least-squares problem
inf

MQ

4


[Fik − F(Yik ; M Q)]2 

k=1

We used Mi and Qi to estimate respondent i’s subjective median and IQR for
income in the year ahead.
Assuming that subjective distributions are log-normal, analysis of the crosssectional distribution of (M Q) enables assessment of the expectations assumptions made in research on consumption/savings behavior. It has been
common to assume a fixed relationship between the spread and central tendency of income expectations; some authors assume that spread does not vary
with central tendency and others that spread is proportional to central tendency.19 We found that Q tends to rise with M, but more slowly than propor-

additional, psychological, reasons for asking such preliminary questions. One is to decrease
overconfidence problems wherein respondents focus too heavily on central tendencies, downweighting their uncertainty about outcomes. Another is to decrease anchoring problems wherein
respondents’ beliefs are influenced by the questions that interviewers pose. Suppose, for example, that a respondent expects his income to be no less than $30,000. If the first question asked
concerns the probability that income will be less than $20,000, the respondent may perhaps be
influenced to think that this amount is objectively reasonable. Thus, asking respondents to provide their own minimum and maximum income levels, and basing subsequent thresholds on these
values, replaces interviewer-induced anchoring with respondent self-anchoring. See Section 6.4
for further discussion of anchoring.
18
The thresholds Yi1      Yi4 were posed in increasing order. The interviewer informed the
respondent if a probability elicited at threshold Yi2 , Yi3 , or Yi4 was smaller than one elicited
earlier. This ensured that the sequence of responses was always coherent. The one exception to
the protocol occurs if a response of “100 percent chance” is given when the first, second, or third
threshold is posed. Then it is not necessary to elicit further responses as a coherent distribution
must give “100 percent chance” to all subsequent thresholds.
19
In Hall and Mishkin (1982), the subjective distribution of next year’s income is assumed
normal with household-specific median and constant IQR. Skinner (1988) and Zeldes (1989)

1348

CHARLES F. MANSKI

tionately. We also found substantial variation in Q among respondents with the
same value of M.
Many authors studying consumption/savings behavior have sought to explain
the substantial cross-sectional variation in savings, conditional on observable
attributes, documented by Avery and Kennickell (1991) and others. Hubbard,
Skinner, and Zeldes (1995), for example, argue that some cross-sectional variation in savings reflects the incentive effects of asset-based, means-tested social
insurance programs on precautionary savings. Other studies attribute crosssectional variation in savings to heterogeneous preferences or to liquidity constraints. Our empirical finding of substantial variation in Q among persons with
the same M suggests that cross-sectional variation in the spread of income expectations may account for at least some of the observed cross-sectional variation in savings.
5.3. Social Security Expectations
Americans may be uncertain of their future Social Security retirement benefits for several reasons, including uncertainty about their future labor earnings,
the formula now determining benefits, and the future structure of the Social
Security system. Research aiming to understand the impact of Social Security
policy on labor supply, retirement savings, and other household decisions has
long been hampered by a dearth of empirical evidence on Social Security expectations. Respondents to the Retirement History Survey and to the Health
and Retirement Study (HRS) provided point predictions of their future benefits (Bernheim (1988), Gustman and Steinmeier (1999, 2001)), but uncertainty
about benefits was not measured.
Probabilistic expectations of Social Security retirement benefits have been
elicited from respondents to the Survey of Economic Expectations from 1999
through 2002. Respondents of ages 18–69 were read a brief description of the
Social Security program and were then asked to predict their eligibility for
benefits when 70 years old, as follows:
SEE Social Security Eligibility Question: Politicians and the news media have been talking
recently about the future of the Social Security retirement system, the federal program
providing benefits to retired workers. The amount of benefits for which someone is eligible
is currently determined by the person’s retirement age and by earnings prior to retirement.
There has been much discussion of changing the form of the Social Security system, so the
future shape of the system is not certain. With this in mind, I would like you to think about
what kind of Social Security retirement benefits will be available when you are older. In
particular, think ahead to when you are about to turn 70 years old and suppose that you

assume the subjective distribution of next year’s log-income to be normal with household-specific
mean log(Mi ) and constant variance δ2 . Equivalently, the subjective distribution of income is lognormal with median Mi and IQR Mi [exp(6745δ)−exp(−6745δ)]. Thus, the IQR is proportional
to the median in these studies.

MEASURING EXPECTATIONS

1349

are not working at that time. What is the percent chance that you will be eligible to collect
any Social Security retirement benefits at that time?

Respondents who report a positive probability of eligibility were asked a series of questions eliciting their subjective distribution of benefits, conditional
on eligibility. This series follows the format of the income-expectations questions described in Section 5.2. That is, respondents were first asked to report
the lowest and highest possible levels of their future benefits. The responses to
these preliminary questions were then used to set thresholds (Y ) for up to six
probabilistic questions about the level of benefits, as follows:
SEE Social Security Benefit Questions: Suppose you are eligible to collect Social Security
benefits when you turn 70. Please think about how much money you would be eligible to
collect each year. When considering the dollar value, please ignore the effects of inflation
or cost-of-living increases. That is, please respond as if a dollar today is worth the same as a
dollar when you turn 70. What do you think is the lowest amount of Social Security benefits,
per year, that you would be eligible to receive? What do you think is the highest amount
of Social Security benefits, per year, that you would be eligible to receive? What is the
percent chance (or chances out of 100) that you would be eligible to receive over ${Y },000
of Social Security benefits per year, when you turn 70?

Dominitz, Manski, and Heinz (2003) study the responses to these questions. The eligibility question was posed to 2457 SEE respondents. Of the 2384
who reported a valid probability of eligibility for benefits at age 70, the mean
subjective probability of eligibility was .57 and the median was .60. Figure 1
presents kernel-smoothed quantiles of eligibility probabilities conditional on
age. The overall pattern is striking, with older respondents tending to report
much higher probabilities of eligibility than do younger ones. For example, the
estimated median subjective probability of eligibility is .40 at age 30, .50 at age
40, .70 at age 50, .90 at age 60, and 1.00 at age 65. Thus, older Americans tend
to be almost certain that, in one form or another, the Social Security system
will survive at least ten more years. However, younger Americans have no such
confidence in the continuation of the system until their retirement.
The 2161 persons who reported a positive chance of eligibility were asked
the questions eliciting lowest/highest possible benefits and the probabilities of
benefits exceeding specified thresholds, conditional on eligibility. Of these 2161
persons, 1398 gave a complete set of responses that could be used to fit personspecific log-normal subjective distributions.20 As in Section 5.2, we characterize
the fitted distributions through their medians M and interquartile ranges Q.
20
The overall response rate of .65 (i.e., 1398/2161) to the sequence of Social Security benefit questions is considerably lower than those experienced asking SEE respondents to forecast
simple binary events (typically .95 or more) and somewhat lower than the experience eliciting
income expectations one-year-ahead (typically .80), reported in Dominitz and Manski (1997a).
About 80 percent (664 out of 836) of the nonresponse occurs when respondents do not report
lowest/highest possible benefits. Another 14 percent did not respond to all of the probability
questions asked, and the remaining 6 percent gave complete reports that could not be used to
estimate person-specific subjective distributions. The rate of response to the SEE Social Security

1350

CHARLES F. MANSKI

FIGURE 1.—Quantiles of subjective probability of social security eligibility at age 70, conditional on current age.
Conditional quantiles estimated using Gaussian kernel with bandwidth of two years (2384 observations). Solid curves depict point estimates. Dashed curves depict bootstrap 90% confidence intervals. Source: Dominitz, Manski, and Heinz (2003).

Figure 2 presents kernel-smoothed .25, .50, and .75-quantile regressions
of M on age. The main impression is that the central tendencies of persons’
expectations of benefit levels vary relatively little with age, but for a tightening
of the cross-sectional distribution of M above age 45.21 In contrast, Figure 1
showed that expectations of eligibility rise dramatically with age. Juxtaposing
these findings, we conclude that the prevalent concern among younger persons
appears to be that the Social Security system will collapse entirely, not that
benefits will be reduced to keep the system going.
Figure 3 presents kernel-smoothed .25, .50, and .75-quantile regressions of Q
on age. The figure shows that subjective uncertainty about the magnitude of

benefit questions, while troubling to some degree, nevertheless compares favorably with the rate
of response to the Social Security benefit question posed in the HRS. The HRS question asks for
a point estimate of benefits, not a subjective distribution.
21
Figure 2 also shows that expectations of benefit levels vary substantially among persons of
any given age. This heterogeneity in expectations presumably reflects a combination of real and
perceptual factors. On the real side, the current system makes benefits vary with a person’s own
earnings and, in the case of survivor benefits, with the earnings of spouses; hence expectations
should vary with personal and spousal past and expected labor earnings. On the perceptual side,
persons may vary in their knowledge of how the Social Security system currently operates and in
their expectations for the future structure of the system.

MEASURING EXPECTATIONS

1351

FIGURE 2.—Quantiles of subjective median of benefits at age 70, conditional on current age.
Conditional quantiles estimated using Gaussian kernel with bandwidth of two years (1398 observations). Solid curves depict point estimates. Dashed curves depict bootstrap 90% confidence intervals. Source: Dominitz, Manski, and Heinz (2003).

Social Security benefits is very substantial among young persons but decreases
with age. That uncertainty about benefit levels should decrease with age makes
much sense, because uncertainty about future labor earnings and about the future structure of Social Security should decrease as retirement nears. However,
we take the main message of Figure 3 to be that even middle-aged persons who
are nearing retirement tend to be rather uncertain of their future benefit levels,
conditional on eligibility. For example, the median value of Q is $6100 among
respondents of age 55, who are typically only ten years from retirement.
It is of interest to learn how different sources of uncertainty—about future
labor earnings, the formula now determining benefits, and the future structure
of the Social Security system—combine to produce the findings about benefit expectations displayed in Figures 2 and 3. With this in mind, Dominitz,
Manski, and Heinz (2003) performed an exploratory face-to-face interview of
a small random sample of 49 staff members at a midwestern university. These
respondents were administered the SEE questions. Then, to shed some light on
formula uncertainty, they were asked for their perceptions of the current maximum annual Social Security benefit. In particular, respondents were asked for
their subjective probabilities that the maximum benefit exceeds various thresholds Y , ranging from $5000 to $25,000:

1352

CHARLES F. MANSKI

FIGURE 3.—Quantiles of subjective IQR of benefits at age 70, conditional on current age.
Conditional quantiles estimated using Gaussian kernel with bandwidth of two years (1398 observations). Solid curves depict point estimates. Dashed curves depict bootstrap 90% confidence intervals. Source: Dominitz, Manski, and Heinz (2003).

Social Security Maximum Benefit Questions: Now think about Social Security benefits today.
In particular, imagine a person who is now 70 years old. Suppose that this person retired
from work at age 65 and began collecting benefits after working full time for 40 years.
Suppose that, while working, this person had high enough income to be eligible for the
maximum Social Security benefit that is currently paid. What is the percent chance that
this person currently receives over ${Y },000 of Social Security benefits per year?

The maximum Social Security benefit is a fact whose value can be determined through scrutiny of Social Security Administration documents; in 2001,
when the interviews were performed, the maximum benefit was $16,860 per
year. Of the 49 respondents, 6 reported a 100 percent chance that the maximum benefit exceeds $25,000. We were able to estimate subjective distributions
for the remaining 43 respondents.
The cross-sectional median value of their subjective medians was about
$18,500, which is reasonably close to the actual maximum benefit. However, respondents tended to exhibit substantial uncertainty. The subjective interquartile range was above $5000 for most respondents, and above $10,000 for many.
These findings, albeit for a small and special sample of respondents, suggest
that much of the uncertainty that SEE respondents displayed about the magni-

MEASURING EXPECTATIONS

1353

tudes of their own future Social Security benefits may reflect uncertainty about
the current Social Security formula.22
5.4. Mutual-Fund Investment Expectations
The Michigan Survey of Consumers has long used verbal questions to measure expectations for personal finances and for the economy as a whole.
Beginning in June 2002, the Survey of Consumers has also included some probabilistic questions derived from the Survey of Economic Expectations. One
elicits expectations concerning the performance of a mutual-fund investment
in the year ahead:
SEE/Michigan Mutual-Fund Investment Question: The next question is about investing in
the stock market. Please think about the type of mutual fund known as a diversified stock
fund. This type of mutual fund holds stock in many different companies engaged in a wide
variety of business activities. Suppose that tomorrow someone were to invest one thousand
dollars in such a mutual fund. Please think about how much money this investment would
be worth one year from now. What do you think is the percent chance that this one thousand dollar investment will increase in value in the year ahead, so that it is worth more
than one thousand dollars one year from now?

This question may be contrasted with the verbal question on business conditions cited in Section 4.1. Whereas that question asked about a vague event
and did not permit respondents to express uncertainty, the present one asks
about a well-specified event and enables respondents to express uncertainty
through their subjective probabilities.
Dominitz and Manski (2003, 2004) analyzed the responses to the SEE-based
questions in the Survey of Consumers. A particularly intriguing finding was the
existence of substantial heterogeneity in responses to the mutual-fund investment question. A total of 3543 persons were asked this question from June
2002 through May 2003, and 3257 responded. Table II describes the crosssectional variation in responses.
We conjecture that most people have no meaningful private information
about mutual funds. If so, the observed variation in expectations mainly reflects differences in the way people process the available public information.
The mean response was a 42.0 percent chance of an increase in the value of
22
To learn something about respondents’ knowledge of the current formula, we followed the
question about the maximum benefit with this open-ended question: “Describe as best you can
the current system that the government now uses to determine social security benefits. What
are the main factors in calculating the size of the benefit? And so on.” More than half of the
respondents indicated a link between earnings histories and benefits, but the responses rarely
suggested a full understanding of the formula. Some persons expressed a belief that benefits are
based on earnings at retirement or over the preceding few years, as is common in defined-benefit
pension plans. Six respondents expressed a belief that benefits are mean-tested. These responses
suggest that respondents not only have heterogeneous beliefs about the magnitude of current
benefits but also vary in their understanding of the structure of the Social Security system.

1354

CHARLES F. MANSKI
TABLE II
PERCENT CHANCE MUTUAL -FUND INVESTMENT
WILL INCREASE IN VALUE
Responses

Mean

Std. Dev.

Total

3257

42.0

28.6

Male
Female

1480
1777

45.4
39.1

29.3
27.7

White
Black
Hispanic
American Indian
Asian

2633
260
183
25
65

42.5
39.2
40.9
30.4
43.3

28.5
28.6
29.7
25.6
31.4

Age 18–34
Age 35–49
Age 50–64
Age 65+

808
1151
788
510

46.3
43.2
41.1
33.5

26.1
27.9
30.4
29.4

0–12 years schooling
13–15 years schooling
16+ years schooling

1113
878
1251

38.4
41.9
45.3

27.8
28.4
29.1

Source: Dominitz and Manski (2004).

the mutual fund, and the standard deviation of the responses was 28.6. Some
of this heterogeneity was systematic, in the sense that persons with different
demographic attributes tended to have different expectations. Males tended to
be more optimistic than females. Optimism increased with schooling. Younger
persons were more optimistic than older ones, and most of this decline occurs
at the highest age group (65 and older). The empirical existence of such strong
heterogeneity in investment expectations runs counter to the usual rational expectations assumption that all persons access and process public information
in the same way.23
These findings raise important questions: Why do investment expectations
vary so sharply and systematically across the population? How does the observed variation in expectations affect investment behavior? The data available
23
An economist who is predisposed to the rational expectations hypothesis might interpret the
heterogeneity displayed in Table II as evidence that responses to the SEE/Michigan mutual-fund
question do not accurately measure the expectations persons “truly” hold. However, an empirical
finding not shown in Table II makes me skeptical of the assertion. The finding is that individual
responses to the probabilistic questions asked in the Survey of Consumers exhibit considerable
temporal stability.
The Survey of Consumers has a rotating panel design, in which approximately 70% of first-time
respondents are re-interviewed six months later. Dominitz and Manski (2003) report linear autoregressions of individual expectations on the same expectations lagged six months. We find that
all auto-regressions have substantial predictive power. In particular, the estimated autoregression
of individual mutual-fund responses on responses six months earlier is Yt = 2414 + 43Yt−6 .

MEASURING EXPECTATIONS

1355

in the Survey of Consumers do not enable us to answer these questions, which
should be subjects for future research.
5.5. Probabilistic Polling
Public opinion researchers have long performed election polls asking citizens to predict their future voting behavior. Standard polling questions do not
enable respondents to express uncertainty about whether they will vote and, if
so, for whom. Consider, for example, this Gallup Poll question administered
early in the American 2000 Presidential campaign:24
Gallup Poll Question: Next, we’d like you to think about the general election for President
to be held in November. If Vice-President Al Gore were the Democratic Party’s candidate and Texas Governor George W. Bush were the Republican Party’s candidate, who
would you be more likely to vote for—[Al Gore, the Democrat (or) George W. Bush, the
Republican]?

Observe that this question specifies only the Democratic and Republican
candidates, making no mention of possible minor party candidates. Also observe that the question does not mention the possibility that the respondent
may choose not to vote.
Even if all respondents vote and no other candidates are on the ballot, responses to the Gallup question do not reveal much about whether sample
members will vote for Gore or Bush. They only reveal whether persons perceive themselves as more likely to vote for one candidate or the other. Thus
persons who respond “Gore” are saying that the chance they will vote for Gore
is at least 50 percent and the chance they will vote for Bush no more than 50
percent; analogous reasoning applies to persons who respond “Bush.”
In Manski (1990), I showed that questions of the Gallup form logically only
imply a bound of width .5 on the fraction of voters who would vote for each
candidate. Consider Gore, the reasoning for Bush being analogous. The lower
bound on the fraction voting for Gore occurs if all the sample members who
respond “Gore” have 50 percent chance of voting for Gore and all those who
respond “Bush” have no chance of voting for Gore. The upper bound occurs
if all the sample members who respond “Gore” have 100 percent chance of
voting for Gore and all those who respond “Bush” have 50 percent chance
of voting for Gore. Suppose, for example, that the fraction of persons who
respond “Gore” is .6. Then one can logically conclude only that the fraction
who would vote for Gore is between .3 and .8.
Manski (2000b, 2002b) suggests that probabilistic polling would improve on
standard polling practices by permitting citizens to express uncertainty about
24
CNN/USA Today/Gallup Poll, February 20–21, 2000, questions 5 and 5a, available online at
www.gallup.com/poll/surveys/2000/Topline000220/index.asp.

1356

CHARLES F. MANSKI

how they will vote.25 Pollsters could ask respondents to state, in percentage
terms, how likely it is that they will vote in an upcoming election. They could
then ask respondents how likely it is that they would vote for each candidate.
For example, pollsters could have asked these probabilistic questions during
the 2000 American presidential campaign:
Probabilistic Polling Questions:
P1. What do you think is the percent chance that you will cast a vote for President?
P2. Suppose now that you will vote for President. I will read five voting possibilities,
and then ask you the percent chance that you would vote for each one. Please listen to
the choices, allocating 100 percentage points total among all five: Al Gore, the Democrat;
George W. Bush, the Republican; Ralph Nader, the Green Party candidate; Pat Buchanan,
the Reform Party candidate; another candidate.

I performed a small pilot study in the weeks preceding the year 2000 American presidential election. Using conventional random-digit telephone sampling methods, an interviewer contacted fifty respondents in Evanston, Illinois
and posed the above probabilistic polling questions, as well as these traditional
questions taken from the CBS-New York Times poll:26
CBS-New York Times Questions:
Q1. How likely is it that you will vote in the 2000 election for President—would you say
that you will definitely vote, probably vote, probably not vote, or definitely not vote in the
election for President?
Q2. If the 2000 election were being held today and the candidates were Al Gore, the
Democrat, George W. Bush, the Republican, Ralph Nader, the Green Party candidate, and
Pat Buchanan, the Reform Party, would you vote for Al Gore, George Bush, Ralph Nader,
or Pat Buchanan?

All 50 respondents answered these questions. Juxtaposition of the responses
to P1 and Q1 shows how respondents answer questions requesting verbal and
probabilistic measures of the likelihood of voting. The responses, shown in
Table III, correspond well ordinally.
25
Probabilistic polling is too simple and appealing an idea to have been thought of only once.
From the time that I initially critiqued traditional polling questions in Manski (1990) through
the recent period in which I wrote Manski (2002b), I was unaware of related research. However,
after the latter paper was complete, I learned of some related studies analyzing data across the
world. Burden (1997) analyzed data collected in Ohio in 1986 and 1988 eliciting probabilities that
persons would vote for particular candidates in upcoming state and federal elections. Hoek and
Gendall (1993, 1997) elicited voting probabilities in elections in New Zealand. Maas, Steenbergen, and Saris (1990) analyzed probabilities of voting for particular parties reported by Dutch
voters in 1986. Earlier still, Meier (1980) and Meier and Campbell (1979) used a seven-point
scale to elicit voting expectations.
26
Questions P1 and Q1 ask for verbal and probabilistic responses about the same event,
whether the respondent will vote. However, questions P2 and Q2 do not inquire about the same
event. Whereas P1 asks a respondent to predict his choice of candidate conditional on voting,
Q2 is a forced-choice question, asking a respondent how he would vote if the election were held
today. See Manski (1990) for analysis of the conceptual difference between expectations and
forced-choice questions.

1357

MEASURING EXPECTATIONS
TABLE III
P1 Response (Percent Chance)
Q1 Response

0

Definitely vote
Probably vote
Probably not vote
Definitely not vote

0
0
0
4

[1–10]

[11–50]

[51–90]

[91–99]

100

0
1
0
0

4
3
0
0

5
0
0
0

27
6
0
0

0
0
0
0

Source: Manski (2002b).

The really interesting finding is that probabilistic elicitation of the likelihood
of voting reveals quantitative differences in expectations that verbal questioning misses entirely. It turns out that the thirty-six persons who state that they
will “definitely” vote when responding to Q1 are not uniformly certain that
they will vote. Responding to P1, most of these persons state a 99 or 100 percent chance of voting but one states only an 80 percent chance of voting and
another reports an 85 percent chance. We also learn that the ten persons who
state that they will “probably” vote in response to Q1 actually vary widely in the
chance that they will vote. One member of this subgroup states a 40 percent
chance, one states a 78 percent chance, and six state a 100 percent chance of
voting.
Juxtaposition of the responses to P2 and Q2 (Table IV) shows how respondents answer questions requesting verbal and probabilistic measures of the
prospects of voting for particular candidates. Again, the responses correspond
well ordinally.
Again, the really interesting finding is that probabilistic polling reveals quantitative differences in voting expectations that verbal questioning misses entirely. Thirty-three of the fifty respondents state a 100 percent chance that they
will vote for the candidate they named in response to Q2, but five respondents state no more than a 50 percent chance of voting for this candidate.
Two respondents seem the very model of the “undecided” voter. Both state
“Bush” when asked how they would vote if the election were held today, but
TABLE IV
P2 Response for the Candidate Named in Q2 (Percent Chance)
Q2 Response

[0–50]

[51–80]

[81–90]

[91–99]

100

Gore
Bush
Nader
Buchanan
Other

1
2
1
1
0

2
1
1
0
0

2
1
0
0
0

4
1
0
0
0

26
6
0
0
1

Source: Manski (2002b).

1358

CHARLES F. MANSKI

they then go on to express much uncertainty in their percent chance responses.
One states (Gore—40, Bush—60), while another states (Gore—30, Bush—40,
Nader—10, Buchanan—20).
5.6. Student Expectations of the Returns to Schooling
As discussed in Section 2.1, knowledge of how students perceive the returns
to schooling is a prerequisite for informed analysis of schooling decisions.
However, only the barest empirical evidence has been available. Freeman
(1971) and Betts (1996) asked college undergraduates about the average earnings of persons in various occupations or major fields—they did not ask respondents about the earnings they themselves would expect to receive if they
were in these fields. Smith and Powell (1990) asked a sample of college seniors
for point predictions of their “anticipated annual income in 10 years” and their
“expected earnings” in the first year of their first job. Blau and Ferber (1991)
asked a sample of college seniors to forecast “how much they would expect to
earn initially and after 10 and 20 years if they were to be continuously employed
in their preferred occupation after leaving school.”
Dominitz and Manski (1996) report an exploratory study eliciting probabilistic expectations of the returns to schooling from high school and university students in Madison, Wisconsin. The substantive findings are of some interest, but
the most innovative aspects of this study were its design and implementation.
I focus on these aspects here.
Whereas the surveys described earlier in this section were administered by
telephone, this one was implemented on personal computers at schools using computer-assisted self-administered interview (CASI) software. We found
the CASI medium to be well-suited to the task of eliciting probabilistic
expectations. CASI software enabled us to design a survey that appears
straightforward to respondents but that actually incorporates an extensive
question-branching algorithm. CASI also enabled us to incorporate several
tools intended to aid respondents in expressing meaningful expectations.
These included training screens which explain basic probabilistic ideas through
examples before the respondent begins the actual survey, help screens which
could be accessed by the respondent at any time, error checks informing the
respondent if a response to a probabilistic question is not a proper probability
or if the response is logically inconsistent with earlier responses, and reviewand-revise screens showing the respondent his responses to each completed
sequence of questions and allowing the respondent to revise these responses if
desired. I describe here the version of the survey administered to high school
students.
Let s denote a level of completed schooling. Let y(s x) denote the income
that a respondent would earn at age x if he were to complete schooling level s.
Let Ψ denote the information available to a respondent at the time of the
survey. Labor economists would ideally like to learn Q[y(s x), all x|Ψ ], the

MEASURING EXPECTATIONS

1359

subjective distribution of lifecycle earnings that the respondent associates with
schooling option s. Elicitation of entire distributions of lifecycle earnings was
impractical, so we focused on earnings at ages 30 and 40 and limited attention
to two schooling options: s = 0 indicating attainment of a high school diploma
but no further schooling, and s = 1 indicating attainment of at least a bachelor’s degree. Thus, we sought to learn P[y(s x)|Ψ ] for x = 30 40 and s = 0 1.
To elicit these distributions, we first gave respondents this on-screen introduction:
The next sets of questions ask you to put yourself in one of two hypothetical situations.
In the first situation, you assume that you continue in school until you finish your senior
year of high school and obtain your diploma, and you do not continue in school after
that. In the second hypothetical situation, you assume that you continue in school at least
until you finish your senior year of college and obtain your college diploma (a bachelor’s
degree). When responding to these questions, please attempt to fully place yourself in the
hypothetical situation as it is described.

After this, respondents received these more detailed instructions concerning
the first scenario (i.e., s = 0):
In the first hypothetical situation, assume that you continue in school until you complete
your senior year of high school and obtain your high school diploma. Please respond under
the assumption that you do not return to school at any time after high school. Remember,
this is a hypothetical situation. Just think about the kinds of jobs that would be available
for you and that you would accept. Think about the amount of money you would make on
these jobs. Again, you should ignore the effects of price inflation on earnings.27

Following this, respondents were asked to state their probabilities that earnings at age 30 or 40 would exceed several thresholds. The thresholds were determined by the answers that students gave to a preliminary question eliciting
their subjective median earnings at ages 30 and 40.28
Observe that the wording used to describe the two schooling scenarios offers
respondents no reason why one or the other scenario might be realized. This
was intentional—we did not want respondents to draw from the descriptions of
27
Respondents received this on-screen instruction before the first earnings question was posed:
“Also, please ignore the effects of price inflation on earnings. That is, assume that one dollar today
is worth the same as one dollar when you are 30 years old and when you are 40 years old.” Our
debriefings of respondents make us confident that this instruction was understood and adhered
to by most students.
28
The question on the median here takes the place of the preliminary questions on maximum
and minimum income or benefits used in the SEE telephone-administered survey. Eliciting the
median determines the probabilistic center of a respondent’s expectations and provides a natural self-anchor for subsequent selection of threshold values in probability elicitation. At the
beginning of the survey, respondents received this on-screen instruction defining the median of a
distribution: “The first question will ask you about the median amount of money that you think
you will earn at some time in the future. The median is the amount of money for which there is a
50 percent chance that you will earn more than it and a 50 percent chance that you will earn less
than it. So, to answer this question and others like it, you should try to pick the amount of money
that you think there is just as good a chance you will earn more than it as less than it.”

1360

CHARLES F. MANSKI

the scenarios information that might influence their expectations. In particular,
we did not want respondents to state earnings expectations conditional on a
specified choice of schooling level.
To understand this point, let c indicate the schooling level that a respondent
will eventually realize. Respondents do not know c at the time of the survey;
that is, c is not part of the information Ψ . Suppose that, in describing a scenario, we had instructed respondents to assume that they choose schooling
level s. Then a rational respondent would have reported earnings expectations
Q[y(s x)|Ψ c = s] rather than Q[y(s x)|Ψ ]. However, the subjective returns
to schooling are given by the latter distribution, not the former. Although the
distinction between Q[y(s x)|Ψ c = s] and Q[y(s x)|Ψ ] is well appreciated
by economists familiar with the selection problem in the analysis of treatment
response, we are not certain whether the wording of our questions on the returns to schooling succeeded in explaining the distinction to our student respondents.
6. EVALUATING THE ACCURACY OF ELICITED EXPECTATIONS
Researchers have many reasons to be interested in the correspondence
between subjective expectations and objective realities. Economists invoking
rational expectations assumptions should want to know how well such assumptions describe real decision makers. Social planners contemplating provision
of information to the public on the risks associated with detrimental behaviors
(e.g., smoking, drug use, school dropout) should want to know how accurately
persons presently perceive such risks.
Sections 6.1–6.3 describe three ways that researchers have evaluated the accuracy of elicited expectations, and summarizes some substantive findings. In
Section 6.4, I suggest that probabilistic questioning may improve survey research practices asking respondents about facts.
6.1. Comparison of Individual Expectations and Realizations
The most direct way to evaluate the accuracy of elicited expectations is to follow respondents over time and compare the events that they experience with
the expectations elicited from them. Fifty years ago, Federal Reserve Consultant Committee on Consumer Survey Statistics (1955) argued that “reinterviews provide the only satisfactory way to test the usefulness or relevance of
statistics on expectations and intentions.” Subsequently, Juster (1966) used
data on individual expectations and realizations to evaluate the predictive
power of consumer purchase expectations.
Dominitz (1998) used a one-year follow-up to a preliminary 1993 version
of SEE to evaluate the accuracy of respondents’ expectations of their weekly
earnings. He reasoned as follows. Suppose that subjective earnings distributions are continuous and that realizations are statistically independent across

MEASURING EXPECTATIONS

1361

respondents; thus, there are no aggregate shocks. Then rational expectations
implies that, for any α ∈ (0 1), a fraction α of respondents should report realized weekly earnings in 1994 that are less than or equal to the subjective
α-quantile of the expectations that they reported a year earlier. Applying this
criterion, he found that expectations and realizations matched up reasonably
well, but not entirely so. They differed in that expectations “tended to be too
optimistic (i.e., central tendency of expectations exceeds central tendency of
realizations) and too confident (i.e., spread of realizations exceeds spread of
expectations) ex post.”
Hurd and McGarry (2002) used mortality realizations to evaluate expectations of survival to ages 75 and 85 elicited from respondents to the HRS in
1992. They reported that, among the HRS respondents who died between 1992
and 1994, the average subjective survival probability to age 75 elicited in 1992
was .45. Among those who survived to 1994, the survival probability elicited
in 1992 was .65. These and other findings led them to conclude that subjective
survival probabilities have predictive power for actual survival.
6.2. Comparison of Mean Expectations and Realizations
The above approach to evaluation of accuracy requires longitudinal data.
When data are collected in repeated cross-sectional surveys, one may compare the expectations elicited from respondents in one wave of the survey with
the events realized by respondents in a later wave. Suppose that persons randomly selected are asked at date t to provide expectations for events that will
be realized at date t + 1. Suppose that a new random sample from the same
population is drawn following date t + 1, and those individuals are questioned
about their realizations at t + 1. If realizations are statistically independent
across respondents, then rational expectations implies that the distribution of
realizations at date t + 1 is the same as the cross-sectional mean distribution
of expectations elicited at date t.
Dominitz and Manski (1997b) used this approach to evaluate the one-yearahead expectations of SEE respondents interviewed in 1994, comparing their
expectations with the realizations reported by the new sample of respondents
interviewed in 1995. All SEE respondents were asked these questions eliciting
expectations of health insurance coverage and crime victimization, as well as
the job-loss question cited in Section 5.1:
SEE Health-Insurance Question: What do you think is the percent chance that you will have
health insurance coverage 12 months from now?
SEE Burglary Question: What do you think is the percent chance that someone will break
into your home and steal something, during the next 12 months?

In addition, all respondents were asked these questions inquiring about realized events:
SEE Health-Insurance Realization Question: Do you have any health insurance coverage?

1362

CHARLES F. MANSKI
TABLE V
SEE EXPECTATIONS IN 1994 AND REALIZATIONS IN 1995
No Health Insurance

Male
Female

Victim of Burglary

Job Loss

Exp

Real

Exp

Real

Exp

Real

.15
(01)
.16
(01)

.15
(02)
.13
(02)

.16
(01)
.17
(01)

.05
(01)
.03
(01)

.15
(01)
.21
(01)

.18
(02)
.18
(02)

Note: The estimates for 1994 and 1995 are based on the 1036 and 1024
SEE respondents in the labor force in those years. Standard errors are in
parentheses.
Source: Dominitz and Manski (1997b).

SEE Burglary Realization Question: During the past 12 months, did anyone break into or
somehow illegally get into your home and steal something?
SEE Job-Loss Realization Question: Have there been any times during the past 12 months
when you did not have a job and were looking for work?

The health-insurance and burglary questions elicit realizations of the same
events about which the expectations questions ask. The job-loss question does
not correspond as well to the expectations question.
Suppose that realizations of health insurance, burglary, and job loss are statistically independent across respondents. Subject to this assumption, we can
evaluate the accuracy of elicited risk perceptions by comparing population
mean subjective probabilities reported in 1994 with corresponding realized
rates of occurrence reported in 1995. Table V presents this comparison using
data from the 1036 SEE labor force participants in 1994 and the 1024 labor
force participants in 1995.
The table shows that mean expectations and realizations of health insurance
match up closely, for males and females. Mean expectations and realizations
of job loss also match up closely, notwithstanding that the expected and realized job-loss questions differ somewhat in the event of interest. The picture is
rather different with respect to crime victimization, where respondents tend to
substantially overpredict the risk of burglary. This finding corroborates those
of attitudinal researchers, who have reported that Americans perceive crime
to be far more prevalent than it actually is (Bursik and Grasmick (1993, Chapter 4)).
6.3. Comparison of Mean Expectations with Historical Realizations
The most common way that researchers have evaluated accuracy has been
to compare mean expectations with historical realizations. Such comparisons
assume that successive cohorts of persons have the same distribution of realizations for the event of interest. If so, the logic of Section 6.2 may be applied

MEASURING EXPECTATIONS

1363

when realizations are observed for earlier cohorts than the one from which
expectations were elicited.
Several studies have used historical mortality data to evaluate the accuracy
of probabilistic expectations of survival to specified ages. In a notably early effort, Hamermesh (1985) used historical mortality data to assess the accuracy
of expectations of survival to ages 60 and 80. He reported reasonable correspondence between expectations and life-table data on mortality conditioned
on various risk factors. However, his small sample was not randomly drawn
from the population to which available life tables pertain.
Hurd and McGarry (1995) used life-table data to evaluate expectations of
survival to ages 75 and 85 elicited from 51−61 year-old respondents to the HRS
in 1992. They concluded that the elicited subjective probabilities approximate
well the historical survival rates given in a life table from 1990. However, they
cautioned that life expectancy in the United States has been increasing over
time. Hence, it may not be appropriate to assume that the HRS respondents interviewed in 1992 have the same objective survival probabilities as those shown
in life tables.
Whereas the HRS elicited the expectations that middle-aged adults hold
for survival well into old age, the 1997 National Longitudinal Study of Youth
(NLSY97) elicited the expectations of 15−16 year-old adolescents for survival
one-year-ahead and to age 20. In this case, the expectations were wildly pessimistic relative to the life table evidence. Fischhoff et al. (2000) report that the
mean and median subjective percent chance of death before age 20 were 20.3
and 10 percent respectively, whereas the historical death rate of youth during
this period was .4 percent.
The NLSY97 mortality findings are startling, but one should not extrapolate to the conclusion that youth generally are so inaccurate when queried
about their expectations. The NLSY97 respondents were asked to report probabilistic expectations of various events, including school completion by age 20,
employment at age 30, pregnancy and parenthood in the year ahead and by
age 20, crime victimization and arrest in the year ahead, and confinement in
jail or prison by age 20. Comparing the elicited expectations with a variety
of historical sources, Fischhoff et al. (2000) conclude that these teens express
largely sensible beliefs about a range of consequential events. Similar conclusions have been reached in other research eliciting probabilistic expectations
from teenagers (Quadrel, Fischhoff, and Davis (1993), Dominitz and Manski
(1996)).
6.4. Using Probabilistic Expectations to Measure Knowledge of Facts
Survey researchers routinely ask respondents to report facts about which
they may have only partial knowledge. For example, persons may be asked
to report their pension types, the length of a past spell of unemployment, or
details of their medical histories. Respondents who are uncertain about these

1364

CHARLES F. MANSKI

matters sometimes choose not to respond to the questions posed. When they
do respond, their self reports may differ from actual values.
Empirical researchers often ignore missing data and misreporting problems,
discarding respondents with missing data and assuming that all reported data
are accurate. Researchers who are sensitive to these problems may impute
missing data and use models of measurement errors to describe potential discrepancies between self reports and objective characteristics. On occasion, researchers perform validation studies to empirically learn the distribution of
missing data and the accuracy of reported data.
Modifying survey research practices to permit respondents to express uncertainty about facts can potentially reduce nonresponse and misreporting. Constructive steps in this direction have been taken by the HRS, which has used
unfolding bracket questions to enable respondents to flexibly provide interval
data on their income and assets. Respondents who are willing to provide point
responses can do so. Those who are unwilling to respond to questions eliciting
point responses are asked whether the quantity of interest lies above or below
a sequence of specified thresholds. See Juster and Suzman (1995) and Hurd
(1999).
Probabilistic elicitation of facts offers another route for improvement of survey research practices. When the fact is categorical, respondents can be asked
to report their subjective probabilities of membership in each category. For example, consider the reporting of pension type, which may be defined-benefit or
defined-contribution. A respondent who knows that he holds a defined-benefit
pension can report that his pension is of this type with probability one. Someone who is unsure can place positive probability on both types of pensions.
When the fact of interest is real-valued, such as income or assets, the method
used by Dominitz, Manski, and Heinz (2003) to elicit expectations of the current maximum Social Security benefit may be applied (see Section 5.3). It
would be of interest to compare responses obtained using probabilistic elicitation with those generated by the unfolding brackets approach used in the
HRS. I conjecture that probabilistic elicitation would mitigate the anchoring
problem encountered in applications of unfolding brackets, wherein the initial
threshold specified by the survey researcher affects the data obtained at the
end of the unfolding bracket sequence.29
29
Psychologists have performed many randomized experiments showing that when subjects are
told the value of some real variable (say A) and are then asked to provide a point estimate of another real variable (say B), estimates of B often vary monotonically with the specified value of A.
Tversky and Kahneman (1974) named this phenomenon anchoring. In the experiments showing
the most substantial anchoring, the variable B is a fact about which most respondents are not well
informed. For example, Tversky and Kahneman (1974) report an experiment in which B is the
percentage of African countries in the United Nations, Jacowitz and Kahneman (1995) report
ones in which B is the length of the Amazon River or the height of the tallest redwood tree, and
Wilson et al. (1996) report one in which B is the number of physicians and surgeons listed in
the local phone book. Various researchers have reported that anchoring is less pronounced when

MEASURING EXPECTATIONS

1365

Although probabilistic elicitation of facts appears not to have previously
been proposed as a tool of survey research, the idea has long had proponents in educational testing. Shuford, Albert, and Massengill (1966) argued
that requiring a student to choose one answer to a true-false, multiple-choice,
or fill-in-the-blank question reveals (p. 125) “only a very small fraction of the
information potentially available from each query.” They proposed that students instead be asked to state subjective probabilities for the correctness of
alternative answers to a question. Moreover, they advocated use of reproducing
scoring systems (i.e., proper scoring rules) to grade examinations. These scoring
systems make it optimal for a student to honestly reveal his beliefs, provided
that his objective is to maximize expected test score.
7. USING EXPECTATIONS DATA TO PREDICT CHOICE BEHAVIOR
A long term objective of economists engaged in research on expectations
is to improve our ability to predict choice behavior. The research of the past
decade, with its emphasis on measurement of expectations, has been a necessary prelude to realization of this objective.
Expectations data may be used to predict behavior in two rather different
ways. Persons may be questioned about the choices that they would make in
specified scenarios, and the responses used directly to predict their behavior.
Or persons may be asked to report their expectations for unknown states of
nature, and these data may be combined with choice data to estimate econometric decision models. These approaches are discussed below.
7.1. Using Choice Expectations to Predict Choice Behavior
A common practice in market research and psychology, and an occasional
one in economics, has been to pose choice scenarios and ask respondents to
state what actions they would choose if they were to face these scenarios.30

persons report themselves to be, or are conjectured to be, more knowledgeable about variable B.
Wilson et al. (1996) asks subjects to classify themselves as less or more knowledgeable about variable B, and they find less anchoring among those who classify themselves as more knowledgeable.
Hurd (1999) reports that HRS respondents answering unfolding bracket questions exhibit less
anchoring when, in Hurd’s judgement, they are more knowledgeable about variable B.
The apparent relationship between anchoring and respondent knowledge suggests that elicitation of probabilistic expectations for variable B may mitigate anchoring problems by permitting
persons to express their uncertainty. Probabilistic questioning may be particularly effective when
the method of elicitation enables respondents to self-anchor, as recommended by Morgan and
Henrion (1990).
30
See, for example, Beggs, Cardell, and Hausman (1981), Fischer and Nagin (1981), Louviere
and Woodworth (1983), Tversky and Kahneman (1986), Manski and Salomon (1987), and
Ben-Akiva and Morikawa (1990).

1366

CHARLES F. MANSKI

I have cautioned in Manski (1999) that stated choices may differ from actual
ones if researchers provide respondents with different information than they
would have when facing actual choice problems. The norm has been to pose
incomplete scenarios, ones in which respondents are given only a subset of the
information they would have in actual choice settings. When scenarios are incomplete, stated choices are point predictions of uncertain actual choices.
Elicitation of probabilistic choice expectations overcomes the inadequacy of
stated-choice analysis by permitting respondents to express uncertainty about
their choice behavior in incomplete scenarios. The original Juster (1966) proposal was to elicit consumer subjective probabilities for future purchases and
uses the responses to predict actual purchases (see Section 4.3). Probabilistic polling elicits voting probabilities and uses the responses to predict actual
voting behavior (see Section 5.5). Hurd and Smith (2002) use probabilistic expectations of bequests provided by HRS respondents to predict the bequests
that these persons will actually make. One could also ask respondents to report
choice expectations in scenarios that specify some conditioning event; for example, purchase probabilities supposing that some new product were available
or voting probabilities supposing that some world event were to occur prior to
the election.
Use of choice expectations to predict actual choice behavior has two noteworthy features, one disadvantageous and the other advantageous. The disadvantageous feature is that if this approach is to yield accurate predictions,
persons should have rational (or at least unbiased) choice expectations and realized choices should be statistically independent (or at least not strongly dependent) across the population; see Manski (1999). The advantageous feature
is that the approach does not require the researcher to know anything about
the decision rules that persons use.
Both features are apparent in a set of exploratory questions on hypothetical
changes in Medicare policy posed in two waves of SEE. Respondents of age
50 to 64 were asked to report choice expectations in two scenarios. The first
scenario supposes that Medicare policy remains unchanged in the future:
Politicians and the news media have been talking recently about changes in Medicare,
the federal health insurance program for senior citizens. Currently, individuals 65 or older
receive free insurance coverage, called Medicare Part A, which covers the cost of inpatient
hospital care, home health care, hospice care, and some other services. In addition, these
individuals may choose to purchase Medicare Part B, an insurance program which covers the costs of doctor’s services, medical tests, and other health services not covered by
Medicare Part A. The basic premium paid for Medicare Part B coverage is currently about
$45 per month.
Think ahead to when you are about to turn 66 years old. Suppose that Medicare premiums stay as they currently are (about $45 per month for Part B). In this scenario, what do
you think is the percent chance (what are the chances out of 100) that you would choose to
purchase Medicare Part B coverage when you turn 66? What do you think is the percent
chance (what are the chances out of 100) that you would choose to work full-time when
you turn 66?

MEASURING EXPECTATIONS

1367

The second scenario supposes that premiums double to $90 per month, and
poses the same two questions about purchase of Medicare Part B coverage and
about labor supply at age 66.
Responses to these questions provide empirical evidence on a policy question of some interest. It is enticing to think that one may be able to predict the
impact of Medicare policy in such a straightforward manner, without knowledge of how persons make decisions about labor supply and insurance coverage. However, this presumes that the elicited choice expectations are accurate
predictions of behavior.
7.2. Using Expectations and Choice Data to Estimate Econometric
Decision Models
Researchers who employ econometric decision models to predict choice
behavior envision using expectations data to relax assumptions about expectations for states of nature. Consider, for example, the situation of a labor
economist studying schooling behavior. A researcher who observes only the
choices that youth make confronts the identification problem illustrated in Section 2.1, but observation of youths’ expectations of the returns to schooling
solves this problem. As discussed in Section 5.6, elicitation of entire distributions of life-cycle earnings may be impractical. Nevertheless, a researcher may
use whatever expectations data as are available to lessen the dependence of
inference on assumptions about expectations.
The advantages and disadvantages of this use of expectations data reverse
those of the approach discussed in Section 7.1. The advantageous feature is
that persons need not have rational expectations; it is enough to assume that
elicited expectations faithfully describe persons’ perceptions of their environments. The disadvantageous feature is that, given expectations and choice data,
econometric modeling still requires untestable assumptions about the distribution of preferences in the population of interest.
As far as I am aware, the only published research using probabilistic expectations data in econometric analysis of choice behavior is Nyarko and Schotter
(2002), who used a proper scoring rule to elicit expectations of opponent behavior from experimental subjects playing a certain two-person game. Their
analysis shows compellingly how probabilistic expectations data can enable experimental economists to overcome the identification problem illustrated in
Section 2.2. Further evidence on the usefulness of expectations data in experimental economics is provided by Dominitz and Hung (2003), who study the
dynamics of social learning in settings that theoretically yield information cascades.
Several recent unpublished studies use expectations data to analyze the actual decision making of respondents to sample surveys. Delavande (2003) surveyed a small sample of sexually active young women in Chicago regarding
their contraceptive choices, and elicited their expectations for the effectiveness and side effects of alternative contraceptive methods. She combined the

1368

CHARLES F. MANSKI

data on expectations and choices to estimate a random utility model of contraception behavior. Lochner (2003) combined NLSY97 data on arrest expectations and crime commission to estimate a random utility model of criminal
behavior. Hurd, Smith, and Zissimopoulos (2002) investigated how the subjective survival probabilities elicited from HRS respondents affect the times when
they choose to retire and to begin collecting Social Security benefits. Van der
Klaauw and Wolpin (2002) used the HRS data on survival expectations and
retirement expectations to help estimate a stochastic dynamic model of retirement behavior.31 These studies are a start, but economists have hardly begun to
use probabilistic expectations data in econometric analysis of decision making.
7.3. Understanding Expectations Formation
To perform the econometric analyses cited above, researchers did not need
to understand how persons form expectations and revise them with receipt of
new information. They needed only to measure the expectations that respondents held when they made their observed choices.
Suppose that one wants to use an econometric decision model to predict
choice behavior in a new scenario. Measurement of the expectations associated with observed choices suffices if it is plausible to assume that the new
scenario does not affect expectations or that it changes them in some obvious
way. However, econometric decision models often are used to predict behavior following policy interventions or other events that may alter expectations
in nonobvious ways. Then credible prediction requires an understanding of expectations formation, a large subject about which little is known.
Experimental psychologists and economists have studied how persons update objective probabilities following receipt of random sample data in highly
structured settings similar to those presented in textbook statistics exercises.
A particular concern has been to test adherence to and characterize departures
from application of Bayes theorem; see, for example, Tversky and Kahneman
(1974) and El-Gamal and Grether (1995). However, I find it difficult to draw
lessons from this work for expectations formation in real life, where the information that persons receive rarely maps cleanly into a textbook exercise
in probability updating. Bayesian updating, which expresses new information
through the likelihood function, presumes that data are generated by a welldefined sampling process. Expectations formation in real life requires persons
to assimilate government announcements, media reports, personal observations, and other forms of information that may be generated in obscure ways.
31
The last study differs from the others cited here. The other studies use expectations data to
relax assumptions about expectations. In contrast, van der Klaauw and Wolpin maintain a conventional rational expectations assumption that point-identifies their decision model. They use
expectations data to improve the precision with which they are able to estimate this model. See
also Dominitz (2001) for discussion of ways in which expectations data may be used in conjunction with rational-expectations assumptions.

MEASURING EXPECTATIONS

1369

One can learn something about updating in real life by eliciting expectations
longitudinally or from repeated cross sections of the population. Dominitz
(1998) elicited earning expectations at six-month intervals from a spring 1993
cohort of SEE respondents who were reinterviewed in fall 1993. He examined the association between revisions to expectations and the earnings that
respondents realized between interviews. Dominitz and Manski (2003) examined time trends in the mutual-fund investment expectations elicited from successive monthly cohorts of respondents to the Michigan Survey of Consumers.
They observed a positive time-series association between revisions to expectations and movements in the Standard and Poor stock index, but were not able
to discern whether this index “leads” expectations or vice versa.
Research that measures revisions to expectations and associates them with
observed event realizations can be informative. However, I think that understanding expectations formation will also require intensive probing of persons
to learn how they perceive their environments and how they process such
new information as they may receive. Large-scale population surveys such as
the HRS or SEE are not amenable to investigations of this type—the time
available to query respondents is too limited and the standardized questionresponse format of interviews is too confining. Economists may need to engage
small samples of respondents in lengthy, semi-structured “conversations.”
8. MEASURING AMBIGUITY
This paper has presented empirical evidence that survey respondents are
willing and able to report expectations in probabilistic form. This does not,
however, imply that persons actually think probabilistically and use subjective
probability distributions to make decisions. After all, survey respondents also
respond to questions seeking point predictions of uncertain events or verbal assessments of likelihood. Yet persons need not use point predictions or verbal
assessments of likelihood to make decisions. What the empirical evidence does
show is that, however they think and act, people are willing and able to report their beliefs in multiple forms—as point predictions, verbal assessments
of likelihood, or probabilistic expectations.
Among economists and decision theorists, perhaps the most compelling alternatives to the hypothesis of probabilistic expectations have been put forward in research on decisions under ambiguity. Studies of ambiguity maintain
that beliefs have some but not all the structure of a probability distribution.32
A particularly common idea has been that a person may hold a set of subjective distributions for an unknown event, not a single distribution. This idea is
32
The term ambiguity appears to originate in Ellsberg (1961). His famous thought experiment
required subjects to draw a ball from either of two urns, one with a known objective distribution
of colors and the other with an unknown objective distribution of colors. Ellsberg conjectured
that many persons facing this problem would not behave as if they place any single subjective
distribution on the composition of the second urn.

1370

CHARLES F. MANSKI

a primitive of research on robust Bayes analysis (e.g., Berger (1985)), which
supposes that persons hold multiple subjective distributions prior to observing data, and it is a conclusion of some work in axiomatic decision theory
(e.g., Gilboa and Schmeidler (1989)). It is also a conclusion of my research
on partial identification of probability distributions, which shows that combining available data with credible assumptions may enable a decision maker
to partially but not fully identify an objective probability distribution (Manski
(2000a, 2003, 2004)). Walley (1991) and Camerer and Weber (1992) review
parts of the literature.
Suppose that beliefs actually do take the form of sets of subjective distributions. Then the single distributions that we now elicit from survey respondents
are probabilistic summaries of ambiguity, much as point predictions are deterministic summaries of uncertainty. To enable persons to express ambiguity,
survey researchers could elicit ranges of probabilities rather than precise probabilities for events of interest. This should be straightforward in the case of
binary events, for which one could pose questions such as:
What do think is the percent chance that event A will occur? Please respond with a particular value or a range of values, as you see fit.

This format enables respondents to express whatever uncertainty or ambiguity they may feel. A respondent can express complete ignorance by reporting
“0 to 100 percent,” bounded ambiguity by reporting “30 to 70 percent,” uncertainty by reporting “60 percent,” or certainty by reporting “100 percent.”
Elicitation of ranges of probabilities should resolve the unease that researchers eliciting probabilistic expectations have felt about the appropriate
interpretation of the response “50 percent.” Bruine de Bruin et al. (2000), and
Fischhoff and Bruine de Bruin (1999) suggest that some respondents may report 50 as an expression of epistemic uncertainty (i.e., ‘fifty–fifty’), rather than
as a quantitative probability. Elicitation of ranges would enable respondents
to express ambiguity directly, rather than indirectly by saying “fifty–fifty.” Presumably, respondents who continue to report 50 when permitted to state a
range of values really mean 50 as a precise probability.
9. LOOKING AHEAD
Economists have long been hostile to subjective data. Caution is prudent,
but hostility is not warranted. The empirical evidence cited in this article shows
that, by and large, persons respond informatively to questions eliciting probabilistic expectations for personally significant events. We have learned enough
for me to recommend, with some confidence, that economists should abandon
their antipathy to measurement of expectations. The unattractive alternative
to measurement is to make unsubstantiated assumptions.
For all the progress that has been made in measurement, we may be able to
improve the way we now elicit expectations. The wording used in the studies

MEASURING EXPECTATIONS

1371

described in Section 5 has proved effective in eliciting expectations for binary
events, but it may be possible to outdo the method used to elicit expectations
for income and other real-valued variables. Little is known about how to elicit
expectations for high-dimensional events, such as lifetime earnings streams.
Looking beyond measurement, I see a critical need for basic research on
expectations formation. Understanding how persons revise their expectations
with receipt of new information often is a prerequisite for credible use of
econometric decision models to predict behavior.
Dept. of Economics and Institute for Policy Research, Northwestern University,
2001 Sheridan Road, Evanston, IL 60208, U.S.A.; cfmanski@northwestern.edu;
www.faculty.econ.northwestern.edu/faculty/manski/.
Manuscript received August, 2003; final revision received January, 2004.
REFERENCES
AVERY, R., AND A. KENNICKELL (1991): “Household Saving in the U.S.,” The Review of Income
and Wealth, 37, 409–432.
AJZEN, I., AND M. FISHBEIN (1980): Understanding Attitudes and Predicting Social Behavior. Englewood Cliffs: Prentice-Hall.
BEGGS, S., S. CARDELL, AND J. HAUSMAN (1981): “Assessing the Potential Demand for Electric
Cars,” Journal of Econometrics, 16, 1–19.
BEN-AKIVA, M., AND T. MORIKAWA (1990): “Estimation of Switching Models from Revealed
Preferences and Stated Intentions,” Transportation Research A, 24A, 485–495.
BERGER, J. (1985): Statistical Decision Theory and Bayesian Analysis. New York: Springer-Verlag.
BERNHEIM, D. (1988): “Social Security Benefits: An Empirical Study of Expectations and Realizations,” in Issues in Contemporary Retirement, ed. by R. Campbell and E. Lazear. Stanford:
Hoover Institution.
BETTS, J. (1996): “What Do Students Know about Wages?” Journal of Human Resources, 31,
27–56.
BEYTH-MAROM, R. (1982): “How Probable Is Probable? A Numerical Translation of Verbal
Probability Expressions,” Journal of Forecasting, 1, 257–269.
BLAU, F., AND M. FERBER (1991): “Career Plans and Expectations of Young Women and Men,”
Journal of Human Resources, 26, 581–607.
BLUME, L., AND D. EASLEY (1982): “Learning to be Rational,” Journal of Economic Theory, 26,
340–351.
BLUNDELL, R. (2003): “Measuring Consumer Behavior: Semiparametric Estimation and Revealed Preference,” Department of Economics, University College London.
BRAY, M., AND D. KREPS (1987): “Rational Learning and Rational Expectations,” in Arrow and
the Ascent of Modern Economic Theory, ed. by G. Feiwel. New York: New York University Press.
BRUINE DE BRUIN, W., B. FISCHHOFF, B. HALPERN-FELSHER, AND S. MILLSTEIN (2000): “Expressing Epistemic Uncertainty: It’s a Fifty–Fifty Chance,” Organizational Behavior and Human
Decision Processes, 81, 115–131.
BURDEN, B. (1997): “Deterministic and Probabilistic Voting Models,” American Journal of Political Science, 41, 1150–1169.
BURSIK, R., AND H. GRASMICK (1993): Neighborhoods and Crime. New York: MacMillan.
CABALLERO, R. (1990): “Consumption Puzzles and Precautionary Savings,” Journal of Monetary
Economics, 25, 113–136.
CAMERER, C., AND M. WEBER (1992): “Recent Developments in Modeling Preferences: Uncertainty and Ambiguity,” Journal of Risk and Uncertainty, 5, 325–370.

1372

CHARLES F. MANSKI

CARROLL, C. (1992): “The Buffer-Stock Theory of Saving: Some Macroeconomic Evidence,”
Brookings Papers on Economic Activity, 2, 61–156.
CASKEY, J. (1985): “Modeling the Formation of Price Expectations: A Bayesian Approach,”
American Economic Review, 75, 768–776.
CURTIN, R. (1982): “Indicators of Consumer Behavior: The University of Michigan Surveys of
Consumers,” Public Opinion Quarterly, 46, 340–352.
CYERT, R., AND M. DEGROOT (1974): “Rational Expectations and Bayesian Analysis,” Journal
of Political Economy, 82, 521–536.
DAS, M., AND B. DONKERS (1999): “How Certain Are Dutch Households about Future Income?
An Empirical Analysis,” Review of Income and Wealth, 45, 325–338.
DAVIS, J., AND T. SMITH (1994): The General Social Surveys, 1972–1994, Cumulative File. Chicago:
National Opinion Research Center.
DELAVANDE, A. (2003): “Pill, Patch, or Shot? Subjective Expectations and Birth Control Choice,”
Department of Economics, Northwestern University.
DOMINITZ, J. (1998): “Earnings Expectations, Revisions, and Realizations,” Review of Economics
and Statistics, 80, 374–388.
(2001): “Estimation of Income Expectations Models Using Expectations and Realization
Data,” Journal of Econometrics, 102, 165–195.
DOMINITZ, J., AND A. HUNG (2003): “Homogeneous Actions and Heterogeneous Beliefs: Experimental Evidence on the Formation of Information Cascades,” Heinz School of Policy and
Management, Carnegie Mellon University.
DOMINITZ, J., AND C. MANSKI (1996): “Eliciting Student Expectations of the Returns to Schooling,” Journal of Human Resources, 31, 1–26.
(1997a): “Using Expectations Data to Study Subjective Income Expectations,” Journal of
the American Statistical Association, 92, 855–867.
(1997b): “Perceptions of Economic Insecurity: Evidence from the Survey of Economic
Expectations,” Public Opinion Quarterly, 61, 261–287.
(1999): “The Several Cultures of Research on Subjective Expectations,” in Wealth, Work,
and Health, ed. by R. Willis and J. Smith. Ann Arbor, MI: University of Michigan Press.
(2003): “How Should We Measure Consumer Confidence (Sentiment)? Evidence from
the Michigan Survey of Consumers,” Working Paper 9926, National Bureau of Economic Research.
(2004): “How Should We Measure Consumer Confidence?” Journal of Economic Perspectives, 18, forthcoming.
DOMINITZ, J., C. MANSKI, AND B. FISCHHOFF (2001): “Who Are Youth At-Risk?: Expectations Evidence in the NLSY-97,” in Social Awakenings: Adolescents’ Behavior as Adulthood
Approaches, ed by R. Michael. New York: Russell Sage Foundation, 230–257.
DOMINITZ, J., C. MANSKI, AND J. HEINZ (2003): “Will Social Security Be There for You?”: How
Americans Perceive Their Benefits,” National Bureau of Economic Research Working Paper
9798.
EL -GAMAL, M., AND D. GRETHER (1995): “Are People Bayesian? Uncovering Behavioral Strategies,” Journal of the American Statistical Association, 90, 1137–1145.
ELLSBERG, D. (1961): “Risk, Ambiguity, and the Savage Axioms,” Quarterly Journal of Economics, 75, 643–669.
EREV, I., AND B. COHEN (1990): “Verbal versus Numerical Probabilities: Efficiency, Biases, and
the Preference Paradox,” Organizational Behavior and Human Decision Processes, 45, 1–18.
FEDERAL RESERVE CONSULTANT COMMITTEE ON CONSUMER SURVEY STATISTICS (1955):
“Smithies Committee Report in Reports of the Federal Reserve Consultant Committees on
Economic Statistics,” Hearings of the Subcommittee on Economic Statistics of the Joint Committee on the Economic Report, 84th US Congress.
FERRELL, W., AND P. MCGOEY (1980): “A Model of Calibration for Subjective Probabilities,”
Organizational Behavior and Human Performance, 26, 32–53.

MEASURING EXPECTATIONS

1373

FISCHER, G., AND D. NAGIN (1981): “Random versus Fixed Coefficient Quantal Choice Models,”
in Structural Analysis of Discrete Data with Econometric Applications, ed. by C. Manski and
D. McFadden. Cambridge, MA: MIT Press.
FISCHHOFF, B., AND W. BRUINE DE BRUIN (1999): “Fifty–Fifty = 50%?” Journal of Behavioral
Decision Making, 12, 149–163.
FISCHHOFF, B., A. PARKER, W. BRUINE DE BRUIN, J. DOWNS, C. PALMGREN, R. DAWES, AND
C. MANSKI (2000): “Teen Expectations for Significant Life Events,” Public Opinion Quarterly,
64, 189–205.
FISHBEIN, M., AND I. AJZEN (1975): Belief, Attitude, Intention, and Behavior: An Introduction to
Theory and Research. Reading: Addison-Wesley.
FREEMAN, R. (1971): The Market for College-Trained Manpower. Cambridge: Harvard University
Press.
GIGERENZER, G. (1991): “How to Make Cognitive Illusions Disappear: Beyond Heuristics and
Biases,” European Review of Social Psychology, 2, 83–115.
GILBOA, Y., AND D. SCHMEIDLER (1989): “Maxmin Expected Utility with a Non-Unique Prior,”
Journal of Mathematical Economics, 18, 141–153.
GUISO, L., T. JAPPELLI, AND L. PISTAFERRI (2002): “An Empirical Analysis of Earnings and Employment Risk,” Journal of Business and Economic Statistics, 20, 241–253.
GUISO, L., T. JAPPELLI, AND D. TERLIZZESE (1992): “Earnings Uncertainty and Precautionary
Saving,” Journal of Monetary Economics, 30, 307–337.
GUISO, L., AND G. PARIGI (1999): “Investment and Demand Uncertainty,” Quarterly Journal of
Economics, 114, 185–227.
GUSTMAN, A., AND T. STEINMEIER (1999): “What People Don’t Know about Their Pensions
and Social Security: An Analysis Using Linked Data from the Health and Retirement Study,”
National Bureau of Economic Research Working Paper 7368.
(2001): “Imperfect Knowledge, Retirement, and Savings,” National Bureau of Economic
Research Working Paper 8406.
HALL, R., AND F. MISHKIN (1982): “The Sensitivity of Consumption to Transitory Income: Estimates from Panel Data on Households,” Econometrica, 50, 461–477.
HAMERMESH, D. (1985): “Expectations, Life Expectancy, and Economic Behavior,” Quarterly
Journal of Economics, 100, 389–408.
HOEK, J., AND P. GENDALL (1993): “A New Method of Predicting Voting Behaviour,” Journal of
the Market Research Society, 35, 361–371.
(1997): “Factors Affecting Poll Accuracy: An Analysis of Undecided Respondents,” Marketing Bulletin, 8, 1–14.
HOFFRAGE, U., S. LINDSEY, R. HERTWIG, AND G. GIGERENZER (2000): “Communicating Statistical Information,” Science, 290, 2261–2262.
HUBBARD, G., J. SKINNER, AND S. ZELDES (1995): “Precautionary Saving and Social Insurance,”
Journal of Political Economy, 103, 360–399.
HURD, M. (1999): “Anchoring and Acquiescence Bias in Measuring Assets in Household Surveys,” Journal of Risk and Uncertainty, 19, 111–136.
HURD, M., AND K. MCGARRY (1995): “Evaluation of the Subjective Probabilities of Survival in
the Health and Retirement Study,” Journal of Human Resources, 30, S268–S292.
(2002): “The Predictive Validity of Subjective Probabilities of Survival,” The Economic
Journal, 112, 966–985.
HURD, M., AND J. SMITH (2002): “Expected Bequests and Their Distribution,” RAND.
HURD, M., J. SMITH, AND J. ZISSIMOPOULOS (2002): “The Effects of Subjective Survival on Retirement and Social Security Claiming,” Working Paper 9140, National Bureau of Economic
Research.
JACOWITZ, K., AND D. KAHNEMAN (1995): “Measures of Anchoring in Estimation Tasks,” Personality and Social Psychology Bulletin, 21, 1161–1166.

1374

CHARLES F. MANSKI

JAMIESON, L., AND F. BASS (1989): “Adjusting Stated Intentions Measures to Predict Trial Purchase of New Products: A Comparison of Models and Methods,” Journal of Marketing Research,
26, 336–345.
JUSTER, T. (1964): Anticipations and Purchases: An Analysis of Consumer Behavior. Princeton:
Princeton University Press.
(1966): “Consumer Buying Intentions and Purchase Probability: An Experiment in Survey Design,” Journal of the American Statistical Association, 61, 658–696.
JUSTER, T., AND R. SUZMAN (1995): “An Overview of the Health and Retirement Study,” Journal
of Human Resources, 30, S7–S56.
KALAI, E., AND E. LEHRER (1993): “Rational Learning Leads to Nash Equilibrium,” Econometrica, 61, 1019–1045.
KATONA, G. (1957): “Federal Reserve Board Committee Reports on Consumer Expectations and
Savings Statistics,” Review of Economics and Statistics, 39, 40–46.
KEANE, M., AND D. RUNKLE (1990): “Testing the Rationality of Price Forecasters: New Evidence
from Panel Data,” American Economic Review, 80, 714–734.
KORIAT, A., S. LICHTENSTEIN, AND B. FISCHHOFF (1980): “Reasons for Confidence,” Journal of
Experimental Psychology: Human Learning and Memory, 6, 107–118.
LICHTENSTEIN, S., B. FISCHHOFF, AND L. PHILLIPS (1982): “Calibration of Probabilities: The
State of the Art to 1980,” in Judgment Under Uncertainty: Heuristics and Biases, ed. by
D. Kahneman, P. Slovic, and A. Tversky. New York: Cambridge University Press.
LICHTENSTEIN, S., AND R. NEWMAN (1967): “Empirical Scaling of Common Verbal Phrases Associated with Numerical Probabilities,” Psychonomic Science, 9, 563–564.
LINDEN, F. (1982): “The Consumer as Forecaster,” Public Opinion Quarterly, 46, 353–360.
LOCHNER, L. (2003): “Individual Perceptions of the Criminal Justice System,” Department of
Economics, University of Rochester.
LOUVIERE, J., AND G. WOODWORTH (1983): “Design and Analysis of Simulated Consumer
Choice or Allocation Experiments: An Approach Based on Aggregate Data,” Journal of Marketing Research, 20, 350–367.
MAAS, K., M. STEENBERGEN, AND W. SARIS (1990): “Vote Probabilities,” Electoral Studies, 9,
91–107.
MACHLUP, F. (1946): “Marginal Analysis and Empirical Research,” American Economic Review,
36, 519–554.
MANSKI, C. (1990): “The Use of Intentions Data to Predict Behavior: A Best Case Analysis,”
Journal of the American Statistical Association, 85, 934–940.
(1993a): “Adolescent Econometricians: How Do Youth Infer the Returns to Schooling?”
in Studies of Supply and Demand in Higher Education, ed. by C. Clotfelter and M. Rothschild.
Chicago: University of Chicago Press, 43–57.
(1993b): “Dynamic Choice in Social Settings: Learning from the Experiences of Others,”
Journal of Econometrics, 58, 121–136.
(1999): “Analysis of Choice Expectations in Incomplete Scenarios,” Journal of Risk and
Uncertainty, 19, 49–66.
(2000a): “Identification Problems and Decisions Under Ambiguity: Empirical Analysis of
Treatment Response and Normative Analysis of Treatment Choice,” Journal of Econometrics,
95, 415–442.
(2000b): “Why Polls Are Fickle,”Op-Ed article, The New York Times, October 16, 2000,
p. A27.
(2002a): “Identification of Decision Rules in Experiments on Simple Games of Proposal
and Response,” European Economic Review, 46, 880–891.
(2002b): “Probabilistic Polling,” in Navigating Public Opinion: Polls, Policy, and the Future
of American Democracy, ed. by J. Manza, F. Cook, and B. Page. Oxford: Oxford University
Press, 251–271.
(2003): Partial Identification of Probability Distributions. New York: Springer-Verlag.

MEASURING EXPECTATIONS

1375

(2004): “Social Learning from Private Experiences: The Dynamics of the Selection Problem,” Review of Economic Studies, 71, 443–458.
MANSKI, C., AND I. SALOMON (1987): “The Demand for Teleshopping,” Regional Science and
Urban Economics, 17, 109–121.
MANSKI, C., AND J. STRAUB (2000): “Worker Perceptions of Job Insecurity in the Mid-1990s: Evidence from the Survey of Economic Expectations,” Journal of Human Resources, 35, 447–479.
MANSKI, C., AND D. WISE (1983): College Choice in America. Cambridge: Harvard University
Press.
MARCET, A., AND T. SARGENT (1989): “Convergence of Least Squares Learning in Environments with Hidden State Variables and Private Information,” Journal of Political Economy,
97, 1306–1322.
MCCABE, D., L. HOUSER, L. RYAN, V. SMITH, AND T. TROUARD (2001): “A Functional Imaging
Study of Cooperation in Two-Person Reciprocal Exchange,” Proceedings of the National Academy of Sciences, 98, 11832–11835.
MCCLELLAND, A., AND F. BOLGER (1994): “The Calibration of Subjective Probabilities: Theories
and Models 1980–94,” in Subjective Probability, ed. by G. Wright and P. Ayton. New York: Wiley.
MCFADDEN, D. (1974): “Conditional Logit Analysis of Qualitative Choice Behavior,” in Frontiers
in Econometrics, ed. by P. Zarembka. New York: Academic Press, 105–142.
MEIER, K. (1980): “Rationality and Voting: A Downsian Analysis of the 1972 Election,” Western
Political Quarterly, 33, 38–49.
MEIER, K., AND J. CAMPBELL (1979): “Issue Voting: An Empirical Examination of Individually
Necessary and Jointly Sufficient Conditions,” American Political Quarterly, 7, 21–50.
MORGAN, G., AND M. HENRION (1990): Uncertainty: A Guide to Dealing with Uncertainty in Quantitative Risk and Policy Analysis. New York: Cambridge University Press.
MORRISON, D. (1979): “Purchase Intentions and Purchase Behavior,” Journal of Marketing, 43,
65–74.
NATIONAL BUREAU OF ECONOMIC RESEARCH (1960): The Quality and Economic Significance of
Anticipations Data, Special Conference Series. Princeton: Princeton University Press.
NYARKO, Y., AND A. SCHOTTER (2002): “An Experimental Study of Belief Learning Using
Elicited Beliefs,” Econometrica, 70, 971–1005.
PESARAN, H. (1987): The Limits to Rational Expectations. Oxford: Blackwell.
QUADREL, M., B. FISCHHOFF, AND W. DAVIS (1993): “Adolescent (In)vulnerability,” American
Psychologist, 48, 102–116.
ROTH, A. (1995): “Bargaining Experiments,” in The Handbook of Experimental Economics, ed.
by J. Kagel and A. Roth. Princeton: Princeton University Press, 3–109.
SAMUELSON, P. (1938): “A Note on the Pure Theory of Consumer Behavior,” Economica, 5,
61–71.
(1948): “Consumption Theory in Terms of Revealed Preferences,” Economica, 15,
243–253.
SAVAGE, L. (1954): The Foundations of Statistics. New York: Wiley.
(1971): “Elicitation of Personal Probabilities and Expectations,” Journal of the American
Statistical Association, 66, 783–801.
SCHUMAN, H., AND M. JOHNSON (1976): “Attitudes and Behavior,” Annual Review of Sociology,
2, 161–207.
SHUFORD, E., A. ALBERT, AND H. MASSENGILL (1966): “Admissible Probability Measurement
Procedures,” Psychometrika, 31, 125–145.
SKINNER, J. (1988): “Risky Income, Life Cycle Consumption and Precautionary Savings,” Journal
of Monetary Economics, 22, 237–255.
SMITH, H., AND B. POWELL (1990): “Great Expectations: Variations in Income Expectations
Among College Seniors,” Sociology of Education, 63, 194–207.
SMITH, K., J. DICKHAUT, K. MCCABE, AND J. PARDO (2002): “Neuronal Substrates for Choice
Under Ambiguity, Risk, Gains, and Losses,” Management Science, 48, 711–718.

1376

CHARLES F. MANSKI

TOBIN, J. (1959): “On the Predictive Value of Consumer Intentions and Attitudes,” Review of
Economics and Statistics, 41, 1–11.
TVERSKY, A., AND D. KAHNEMAN (1974): “Judgement Under Uncertainty: Heuristics and Biases,” Science, 185, 1124–1131.
(1986): “Rational Choice and the Framing of Decisions,” in Rational Choice, ed. by
R. Hogarth and M. Reder. Chicago: University of Chicago Press, 67–94.
VAN DER KLAAUW, W., AND K. WOLPIN (2002): “Social Security, Pensions, and the Savings and
Retirement Behavior of Households,” Department of Economics, University of North Carolina
at Chapel Hill.
WALKER, J. (2001): “Adolescents’ Expectations Regarding Birth Outcomes: A Comparison of
the NLSY79 and NLSY97 Cohorts,” in Social Awakenings: Adolescents’ Behavior as Adulthood
Approaches, ed. by R. Michael. New York: Russell Sage Foundation, 201–229.
WALLEY, P. (1991): Statistical Reasoning with Imprecise Probabilities. London: Chapman and Hall.
WALLSTEN, T., D. BUDESCU, A. RAPOPORT, R. ZWICK, AND B. FORSYTH (1986): “Measuring
the Vague Meanings of Probability Terms,” Journal of Experimental Psychology: General, 115,
348–365.
WALLSTEN, T., D. BUDESCU, R. ZWICK, AND S. KEMP (1993): “Preferences and Reasons for
Communicating Probabilistic Information in Verbal or Numerical Terms,” Bulletin of the Psychonomic Society, 31, 135–138.
WILLIS, R., AND S. ROSEN (1979): “Education and Self-Selection,” Journal of Political Economy,
87, S7–S36.
WILSON, T., C. HOUSTON, K. ETLING, AND N. BREKKE (1996): “A New Look at Anchoring Effects: Basic Anchoring and Its Antecedents,” Journal of Experimental Psychology: General, 125,
387–402.
ZELDES, S. (1989): “Optimal Consumption with Stochastic Income: Deviations from Certainty
Equivalence,” Quarterly Journal of Economics, 104, 275–298.
ZIMMER, A. (1983): “Verbal vs. Numerical Processing of Subjective Probabilities,” in Decision
Making Under Uncertainty, ed. by R. Scholz. Amsterdam: North-Holland.
(1984): “A Model for the Interpretation of Verbal Predictions,” International Journal of
Man-Machine Studies, 20, 121–134.

