EVALUATING THE EFFECTS OF
JOB TRAINING PROGRAMS
ON WAGES THROUGH
PRINCIPAL STRATIFICATION
Junni L. Zhang, Donald B. Rubin and Fabrizia Mealli
ABSTRACT
In an evaluation of a job training program, the causal effects of the
program on wages are often of more interest to economists than
the program’s effects on employment or on income. The reason is that
the effects on wages reflect the increase in human capital due to the
training program, whereas the effects on total earnings or income may be
simply reflecting the increased likelihood of employment without any
effect on wage rates. Estimating the effects of training programs on wages
is complicated by the fact that, even in a randomized experiment, wages
are truncated by nonemployment, i.e., are only observed and well-defined
for individuals who are employed. We present a principal stratification
approach applied to a randomized social experiment that classifies
participants into four latent groups according to whether they would be
employed or not under treatment and control, and argue that the average
treatment effect on wages is only clearly defined for those who would be
employed whether they were trained or not. We summarize large sample

Modelling and Evaluating Treatment Effects in Econometrics
Advances in Econometrics, Volume 21, 117–145
Copyright r 2008 by Elsevier Ltd.
All rights of reproduction in any form reserved
ISSN: 0731-9053/doi:10.1016/S0731-9053(07)00005-9

117

118

JUNNI L. ZHANG ET AL.

bounds for this average treatment effect, and propose and derive a
Bayesian analysis and the associated Bayesian Markov Chain Monte
Carlo computational algorithm. Moreover, we illustrate the application of
new code checking tools to our Bayesian analysis to detect possible coding
errors. Finally, we demonstrate our Bayesian analysis using simulated
data.

1. INTRODUCTION
Consider the evaluation of a job training program through a social
experiment with eligible applicants randomized into either a treatment
group receiving training or a control group receiving no training. To
evaluate the social beneﬁt of the training, we wish to estimate the
treatment’s effect on wages. This estimation, however, is complicated by
the fact that wages are truncated by nonemployment, that is, not welldeﬁned for those who are not employed. This is a well-known problem in
econometrics, often referred to as sample selection (Heckman, 1979).
An obvious, but generally incorrect, approach to adjust for such
truncation is to compare the employed groups under the two treatment
arms, either through direct comparison of means or through regression
adjusted comparisons, using the treatment indicator as a regressor (O’Leary,
1995; Decker & Corson, 1995; Kodrzycki, 1997). This approach is generally
invalid even in a well-conducted randomized experiment, because even
though treated and control groups are comparable at the baseline, they may
be different conditional on being employed in a period after treatment
assignment. This is because the observed and unobserved characteristics of
those who are employed in the treatment and control groups may differ
between the groups. Speciﬁcally for this reason, most of the evaluation
studies of job training focus either on employment or on total earnings,
setting earnings to zero for those who are not working (Heckman, Lalonde, &
Smith, 1999).
An alternative approach to account for the nonobservability of wages for
those who are not employed is the use of selection models (Heckman, 1979).
The rationale is that the decision to work or not to work was made by the
individual, and thus those who are working comprise a self-selected sample.
More speciﬁcally, for individual i, let Zi denote the indicator for treatment
assignment: Zi=1 for assignment to treatment, Zi=0 for assignment to
control; let Si denote the observed employment indicator: Si=1 for
employed and 0 otherwise; and let Yi denote the individual’s wage, which

Evaluating the Effects of Job Training Programs on Wages

119

is only observed as a real number if Si=1. The selection model assumes that
there exists an underlying regression relationship
logðY i Þ ¼ b0 þ b1 Z i þ bT X 1i þ u1i
where the dependent variable Yi is observed only if Si=1, and the selection
equation is
Si ¼ g0 þ g1 Z i þ cT X 2i þ u2i
Si ¼ 1;

if S ni  0

Si ¼ 0;

if S i o0

(1)

n

Here X1i and X2i are two possibly overlapping sets of covariates, u1i and u2i
are jointly normal variables with mean 0 and covariance matrix S, and S ni is
a continuous latent variable underlying the observed employment indicator.
Implicitly, the selection model assumes that the wages the nonemployed
people would have if they were exposed to the same treatment but,
counterfactually, were employed, can be determined just as the wages for
those who would be employed (note that this assumption is based on
quantities that can never be observed). Under such an assumption, the
selection model is used to estimate the average treatment effect on wages for
all people. Extensions of this typical selection model include models with
heterogeneous treatments effects, and in particular, models with two
versions of the S ni and logðY i Þ corresponding to the two wages associated
with the two treatment levels Zi=0 and Zi=1.
If joint normality is assumed for logðY i Þ and Sni , identiﬁcation is driven by
this assumption, and even in cases where normality holds, identiﬁcation is
usually weak and estimates can be very sensitive to the inclusion/exclusion of
covariates and their interactions (see, e.g., Little, 1985; Copas & Li, 1997). If
normality is relaxed, identiﬁcation of selection models usually relies on an
instrument (or a set of instruments) that determines the employment status but
does not affect wages after controlling for other X variables (Heckman, 1990;
Heckman & Smith, 1998; Heckman & Vytlacil, 1999). Finding such a variable,
however, is not an easy task. In the absence of valid instruments, Lee (2005)
developed sharp bounds on treatment effects on wages, which are a special
case of those derived in Zhang and Rubin (2003) and discussed in Section 3.
Following Zhang and Rubin (2003) and Zhang, Rubin, and Mealli (2005),
we use a principal stratiﬁcation (Frangakis & Rubin, 2002) framework to
address the issue of sample selection (i.e., truncation by nonemployment),
where the primary target of estimation is the average treatment effect on
wages for those who would be employed irrespective of the treatment

120

JUNNI L. ZHANG ET AL.

assignment. Principal stratiﬁcation deﬁnes causal estimands about which
experimental data can provide direct evidence, and deﬁnes meaningful
subgroups of people, and expresses assumptions that are explicit behavioral
hypotheses. Another more standard example of the application of principal
stratiﬁcation is noncompliance with assigned treatment. Principal stratiﬁcation (Frangakis & Rubin, 2002) has been developed within randomized
studies in order to deal with posttreatment complications (such as
noncompliance, missing outcomes, truncation by death, surrogate outcomes)
but can, in principle, be extended to deal with such problems in observational
studies (Grilli & Mealli, 2005), which of course would require additional
assumptions on treatment assignment. The full Bayesian approach to the
problem of noncompliance is proposed in Imbens and Rubin (1997) and is
further developed in Hirano, Imbens, Rubin, and Zhou (2000).
The full Bayesian approach to our problem followed in this chapter is
more complex than is needed to deal with noncompliance. Also, it goes
beyond that of ﬁnding bounds on treatment effects, because it can help
remove assumptions or/and assess the sensitivity of results to deviations
from such assumptions. Here, we also describe the Markov Chain Monte
Carlo (MCMC) code for implementing the Bayesian analysis, and,
moreover, illustrate the use of new software-checking tools to help
ensure the correctness of the code. Using a small frequentist simulation,
we illustrate that our Bayesian analysis and code for it can correctly estimate
the causal effect of interest.
The rest of the chapter is organized as follows. In Section 2, we present
our causal inference framework. In Section 3, we display nonparametric
large sample bounds for the average treatment effect of interest following
Zhang and Rubin (2003), and describe two assumptions that can help
tighten these bounds. In Section 4, we present parametric models including
prior distributions for the parameters. Computational aspects for the
Bayesian analysis are addressed in Section 5. We then present an illustrative
simulated example in Section 6. Section 7 concludes the chapter.

2. THE CAUSAL INFERENCE FRAMEWORK:
POTENTIAL OUTCOMES, THE OBSERVED DATA,
AND PRINCIPAL STRATIFICATION
We use the potential outcomes framework to deﬁne causal effects, and place
a Bayesian model on the potential outcomes; this approach is known as the

Evaluating the Effects of Job Training Programs on Wages

121

Rubin Causal Model. It deﬁnes causal effects by the comparison of treated
and control potential outcomes on a common set of units (Rubin, 1974),
speciﬁes an assignment mechanism as a stochastic function of covariates and
possibly potential outcomes (Rubin, 1975), and derives causal inferences
using the posterior predictive distribution of the causal effects (Rubin,
1978).1
Let N denote the total number of participants in the social experiment for
the evaluation of a job training program. For participant i, let Xi denote the
pretreatment covariates; let Si(1) denote the potential employment indicator
when participant i is trained, and let Yi(1) denote the potential wage when
participant i is trained; let Si(0) and Yi(0), respectively, denote the potential
employment indicator and the potential wage when participant i is not
trained. For z ¼ 1; 0, Y i ðzÞ 2 Rþ (the set of positive real numbers) when
Si(z)=1, and Y i ðzÞ ¼  when Si ðzÞ ¼ 0.
The participants can be classiﬁed into four principal strata (Frangakis &
Rubin, 2002) according to the joint values of the two potential employment
indicators:
 EE ¼ fijS i ð1Þ ¼ S i ð0Þ ¼ 1g, those who would be employed whether
trained or not;
 EN ¼ fijS i ð1Þ ¼ 1; S i ð0Þ ¼ 0g, those who would be employed when
trained, but not employed when not trained;
 NE ¼ fijS i ð1Þ ¼ 0; Si ð0Þ ¼ 1g, those who would be not employed when
trained, but employed when not trained;
 NN ¼ fijS i ð1Þ ¼ S i ð0Þ ¼ 0g, those who would be not employed whether
trained or not.
Note that the principal strata may result from both observable and
unobservable characteristics that can also affect wages; it is precisely
because there can be unobservables inﬂuencing both posttreatment employment and wages that principal strata are deﬁned.
Because a unit-level causal effect is deﬁned by a comparison of potential
outcomes, the treatment effect on wages for participant i is a comparison of
Yi(1) and Yi(0), for example, Y i ð1Þ  Y i ð0Þ, which is well deﬁned on R (the
set of real numbers) only for the EE group. Consequently, we consider
the treatment effect of primary interest to be ATEEE ¼ Ȳ EE ð1Þ  Ȳ EE ð0Þ,
the average difference between Y i ð1Þ and Y i ð0Þ for the EE group. Some
labor economists might argue that it could also be meaningful to talk about
a treatment effect on wages for the NE group, the EN group or the NN
group, because for them, wages for individuals who are not employed can be
deﬁned, and the reason why these wages are not observed is that they are

122

JUNNI L. ZHANG ET AL.

lower than the individuals’ ‘‘reservation wages.’’ Here we do not want to
argue for this rationale, but want to emphasize that, at least in the
experiment we examine, individuals in the EN group or in the NN group are
never observed as employed when not trained (and so their wage is never
observed when not trained), and individuals in the NE group or in the NN
group are never observed as employed when trained (and so their wage is
never observed when trained). Thus, only by adding assumptions on
quantities that are never observed in this experiment is it possible to use the
observed data to estimate an effect of training on wages for the EN, NE or
NN groups. We prefer to avoid a priori deﬁning the problem in terms of
these assumptions and focus therefore on inferences about ATEEE .
As in Section 1, for each participant i, let Zi denote the observed
treatment assignment indicator. Because we can only observe the employment indicator and wage under the assigned treatment arm, the observed
data are fðX i ; Zi ; S obs
¼ S i ðZ i Þ; Y obs
¼ Y i ðZi ÞÞ; i ¼ 1; . . . ; Ng. Note that the
i
i
notation Si in Section 1 is replaced by Sobs
to reinforce that employment is
i
generally affected by Zi: Sobs
¼
Z
S
ð1Þ
þ
ð1
 Z i ÞS i ð0Þ. Classiﬁed by Zi and
i i
i
S obs
,
the
following
four
groups
can
be
observed:
i
 Oð1; 1Þ ¼ fijZ i ¼ 1; S obs
¼ 1g, those
i
group and were employed;
 Oð1; 0Þ ¼ fijZ i ¼ 1; S obs
¼ 0g, those
i
group and were not employed;
 Oð0; 1Þ ¼ fijZ i ¼ 0; S obs
¼ 1g, those
i
group and were employed;
 Oð0; 0Þ ¼ fijZ i ¼ 0; S obs
¼ 0g, those
i
group and were not employed.

who were assigned to the training
who were assigned to the training
who were assigned to the control
who were assigned to the control

For each observed group, Table 1 shows the observed data pattern
and corresponding principal strata. We can see that the principal stratum
Gi for participant i usually cannot be directly observed; hence, the EE group
Table 1.

Observed Data Pattern and Principal Strata for the Observed
Groups.

Observed Group O(Z, Sobs)

Zi

Sobs
i

Y obs
i

O(1,1)
O(1,0)
O(0,1)
O(0,0)

1
1
0
0

1
0
1
0

2 Rþ



2 Rþ



Principal Stratum Gi
EE
NE
EE
EN

or
or
or
or

EN
NN
NE
NN

Evaluating the Effects of Job Training Programs on Wages

123

is not an observable subgroup of participants although it is a meaningful
subgroup.

3. LARGE SAMPLE BOUNDS AND
IDENTIFYING ASSUMPTIONS
Zhang and Rubin (2003) showed that Manski’s approach (Manski, 1989,
1990, 1995, 2003) can be applied to obtain nonparametric large sample
bounds for ATEEE in the case when covariates do not exist and the
proportions of the principal strata are simply given by ðpEE ; pEN ; pNE ; pNN Þ,
where pg is the proportion of individuals belonging to principal stratum g.
Because the treatment is randomly assigned, we have
pEE þ pEN ¼ PrðS obs ¼ 1jZ ¼ 1Þ
pNE þ pNN ¼ PrðS obs ¼ 0jZ ¼ 1Þ
pEE þ pNE ¼ PrðS obs ¼ 1jZ ¼ 0Þ
pEN þ pNN ¼ PrðS obs ¼ 0jZ ¼ 0Þ
Also, pEE þ pEN þ pNE þ pNN ¼ 1. Therefore, for any value of pNE that
satisﬁes
max½0; PrðS obs ¼ 1jZ ¼ 0Þ  PrðS obs ¼ 1jZ ¼ 1Þ  pNE
 min½PrðS obs ¼ 1jZ ¼ 0Þ; PrðS obs ¼ 0jZ ¼ 1Þ

(2)

we have
pEE ¼ PrðS obs ¼ 1jZ ¼ 0Þ  pNE
pEN ¼ PrðS obs ¼ 1jZ ¼ 1Þ  PrðS obs ¼ 1jZ ¼ 0Þ þ pNE
pNN ¼ PrðS obs ¼ 0jZ ¼ 1Þ  pNE
Because the Oð1; 1Þ group is a pEE =ðpEE þ pEN Þ and pEN =ðpEE þ pEN Þ
mixture of the EE and EN principal strata, the upper bound for Ȳ EE ð1Þ ¼
E½Y obs jG ¼ EE; Z ¼ 1 is the average value of Y obs in the
p1 ðpNE Þ ¼

pEE
PrðS obs ¼ 1jZ ¼ 0Þ  pNE
¼
pEE þ pEN
PrðSobs ¼ 1jZ ¼ 1Þ

(3)

fraction of the Oð1; 1Þ group with the largest value of Y obs, which is denoted
by Ȳ Oð1;1Þ ½max jp1 ðpNE Þ. Analogously, the lower bound for Ȳ EE ð1Þ is the

124

JUNNI L. ZHANG ET AL.

average value of Y obs in the p1 fraction of the Oð1; 1Þ group with the smallest
value of Y obs, which is denoted by Ȳ Oð1;1Þ ½min jp1 ðpNE Þ. Analogously,
because the Oð0; 1Þ group is a pEE =ðpEE þ pNE Þ and pNE =ðpEE þ pNE Þ
mixture of the EE and NE principal strata, the upper bound and lower bound
for Ȳ EE ð0Þ are given by Ȳ Oð0;1Þ ½max jp0 ðpNE Þ and Ȳ Oð0;1Þ ½min jp0 ðpNE Þ,
respectively, where
p0 ðpNE Þ ¼

pEE
pNE
¼1
obs
pEE þ pNE
PrðS ¼ 1jZ ¼ 0Þ

(4)

Hence, the lower bound for ATEEE is
minfȲOð1;1Þ ½min jp1 ðpNE Þ  ȲOð0;1Þ ½max jp0 ðpNE Þg
pNE

(5)

and the upper bound for ATEEE is
maxfȲOð1;1Þ ½max jp1 ðpNE Þ  ȲOð0;1Þ ½min jp0 ðpNE Þg
pNE

(6)

where the range for pNE is given by Eq. (2), and p1 and p0 are given by
Eqs. (3) and (4) respectively.
Zhang and Rubin (2003) also examined two explicit assumptions that
may be considered plausible in speciﬁc applications and can help sharpen
the bounds. The ﬁrst, in the context of evaluation of job training programs,
assumes that the training is not harming anyone in the following sense: no
one would be employed when not trained, but not employed when trained.
Assumption 1. (Monotonicity): There is no NE group.
This assumption is less plausible in the job training context than the
analogous monotonicity assumption typically made in instrumental variable
(IV) analysis (e.g., with noncompliance to assigned treatment, see Angrist,
Imbens, & Rubin, 1996), because here monotonicity rules out, a priori, the
possibility of a negative treatment effect on employment, whereas in the IV
context the assumption rules out deﬁers, those who would do the opposite of
their assignment. It is plausible in practice that there are individuals who
would be employed when not trained but not employed when trained. This
result is especially possible for evaluations that look only at short-run
outcomes, because training programs produce what is known as lock-in
effects, in which control group members ﬁnd work while treatment group
members are taking training. Also, some people may take any job that is
available without training, but, after being trained, choose to wait for a

Evaluating the Effects of Job Training Programs on Wages

125

better job, and thus choose to be not employed (i.e., the training increases
their reservation wages). Note that when g1 40 in the selection Eq. (1), then
the monotonicity assumption is implicitly made, and this assumption is also
used by Lee (2005).
Under the monotonicity assumption, pNE ¼ 0, and hence the lower bound
and upper bound for ATEEE, respectively, are obtained by using pNE ¼ 0 in
Eqs. (5) and (6). The resulting bounds are



PrðSobs ¼ 1jZ ¼ 0Þ

 Ȳ Oð0;1Þ
Ȳ Oð1;1Þ min
PrðSobs ¼ 1jZ ¼ 1Þ
and

Ȳ Oð1;1Þ



PrðS obs ¼ 1jZ ¼ 0Þ

 Ȳ Oð0;1Þ
max
PrðS obs ¼ 1jZ ¼ 1Þ

where Ȳ Oð0;1Þ are equal to the average value of Yobs in the Oð0; 1Þ group.
These bounds are equal to those in Lee (2005), and hence our bounds in
Eqs. (5) and (6) are more general than those in Lee (2005) and can be
applied when the monotonicity assumption is not made.
A second assumption that can help sharpen the bounds is the stochastic
dominance condition, which is related to, but different from, both the
stochastic dominance assumption in Manski (1995), which assumes that
the wage under training stochastically dominates that under no training, and
the perfect positive rank correlation in Heckman, Smith, and Clements
(1997). For any principal stratum g 2 fEE; EN; NE; NNg and z ¼ 0; 1, let
Y g ðzÞ denote the wage under treatment assignment z for a random member of g.
Assumption 2. (Stochastic dominance): For any real number t,
PrðY EE ð1Þ  tÞ  PrðY EN ð1Þ  tÞ and PrðY EE ð0Þ  tÞ  PrðY NE ð0Þ  tÞ.
This assumption formalizes the notion that the EE group is more capable
with higher wages than either the EN group or the NE group; the EE group
would be employed under either treatment arm, whereas the EN group or
the NE group would be not employed under one treatment arm. Because
ability tends to be positively correlated with wages, Assumption 2 may often
be plausible in practice. The stochastic dominance assumption remains
invariant with respect to monotonically increasing transformations of Y,
such as the logarithm transformation. In other words, assuming stochastic
dominance for the logarithm of wages is equivalent to assuming stochastic
dominance for raw wages.

126

JUNNI L. ZHANG ET AL.

Under the stochastic dominance assumption, Ȳ EE ð1Þ achieves its
minimum when it equals Ȳ EN ð1Þ and hence equals Ȳ Oð1;1Þ . Analogously,
the lower bound for Ȳ EE ð0Þ is Ȳ Oð0;1Þ . So the lower bound and upper bound
for ATEEE without the monotonicity assumption, respectively, are
Ȳ Oð1;1Þ  max Ȳ Oð0;1Þ ½max jp0 ðpNE Þ
pNE

and
max Ȳ Oð1;1Þ ½max jp1 ðpNE Þ  Ȳ Oð0;1Þ
pNE

where the range for pNE is again given by Eq. (2). When the monotonicity
assumption is also made, these bounds become
Ȳ Oð1;1Þ  Ȳ Oð0;1Þ
and



PrðS obs ¼ 1jZ ¼ 0Þ
Ȳ Oð1;1Þ max
 Ȳ Oð0;1Þ
PrðS obs ¼ 1jZ ¼ 1Þ

4. PARAMETRIC MODELS AND
PRIOR DISTRIBUTIONS
4.1. Parametric Models
To sharpen inferences with real data and ﬁnite samples, we can specify a
parametric model. Note that, even if parametric models are required to
achieve identiﬁcation, the nature of our parametric assumptions is different
from the usual distributional assumptions employed in selection models: our
assumptions are related to variables observed on meaningful subgroups of
individuals, rather than to error terms, whose meaning strongly depends
upon and varies with functional form details of the model speciﬁcations. In
addition, covariates are included for two reasons. First, covariates generally
improve the precision of parameter estimates because they improve the
prediction of the missing potential outcomes, both wage and employment.
Second, covariates generally make assumptions more plausible because they
are conditional rather than marginal; for discussion, see Frangakis and
Rubin (1999) on the relative plausibility of latent ignorability versus
ignorability. Speciﬁc estimation and computational complications when

Evaluating the Effects of Job Training Programs on Wages

127

dealing with parametric mixture models, such as those used by us, are
detailed in Section 5.
Given covariates X, we ﬁrst model the potential outcomes
f ðSð1Þ; Sð0Þ; Y ð1Þ; Y ð0ÞjXÞ ¼ f ðSð1Þ; Sð0ÞjXÞf ðY ð1Þ; Y ð0ÞjSð1Þ; Sð0Þ; XÞ
where the ﬁrst factor is the conditional distribution of the principal strata
given the covariates, and the second factor is the conditional distribution of
the potential wages ðY ð1Þ; Y ð0ÞÞ given the principal stratum and the
covariates. Note that we specify the conditional distribution of the potential
wages given the principal strata, which are deﬁned by the joint values of the
potential employment indicators, both observed and missing.
We then model the treatment assignment mechanism that determines how
the participants are assigned to the training group or the control group, and
thereby which potential outcomes are observed
f ðZjSð1Þ; Sð0Þ; Y ð1Þ; Y ð0Þ; XÞ
In randomized studies with known covariates used to make decisions of
treatment assignment, the treatment assignment mechanism is ignorable,
i.e., it can be ignored when drawing Bayesian or likelihood-based inferences
about the treatment effects (Rubin, 1976, 1978).
For illustration, we model the probabilities of the principal strata using a
multinomial logit:
expðag þ bTg X i Þ
PrðG i ¼ gjX i ; hÞ ¼ P
expðag0 þ bTg0 X i Þ

for g 2 fEE; EN; NE; NNg

g0

where the EE group is taken as the baseline group (aEE ¼ 0; bEE ¼ 0), and h
represents all model parameters. Note that the usual weakness of the
Independence of Irrelevant Alternatives (IIA) property is not a concern here
because the ‘‘choices’’ are not real choices, instead they are memberships in
principal strata.2 Other models such as the multinomial probit could also be
used.
The log potential wages are modeled using standard normal linear
regressions:
for ðg; zÞ 2 fðEE; 1Þ; ðEE; 0Þ; ðEN; 1Þ; ðNE; 0Þg
logðY i ðzÞÞjG i ¼ g; X i ; h  Nðmg;z þ gTg;z X i ; s2g;z Þ
The family of t-based distributions could also be used, where the regressions
are still linear (Liu & Rubin, 1998).

128

JUNNI L. ZHANG ET AL.

The collection of all parameters is
h ¼ fðag ; bg Þ; g 2 fEN; NE; NNgg
[ fðmg;z ; gg;z ; s2g;z Þ; ðg; zÞ 2 fðEE; 1Þ; ðEE; 0Þ; ðEN; 1Þ; ðNE; 0Þgg

ð7Þ

Let X ¼ fX i ; i ¼ 1; . . . ; Ng, Z ¼ fZ i ; i ¼ 1; . . . ; Ng, Sobs ¼ fSobs
i ; i ¼ 1; . . . ; Ng,
and Yobs ¼ fY obs
;
i
¼
1;
.
.
.
;
Ng.
Let
p
¼
PrðG
¼
gjX
;
hÞ
for
g 2 fEE; EN;
g:i
i
i
i
NE; NNg, and let N i ðm; t2 Þ denote the probability density function of a
normal distribution with mean m and variance t2 evaluated at logðY obs
i Þ.
From Table 1, we can see that each of the four observed groups is generally
a mixture of two principal strata; hence, the likelihood function is
LðhjX; Z; Sobs ; Yobs Þ
i
Y h
pEE:i N i ðmEE;1 þ gTEE;1 X i ; s2EE;1 Þ þ pEN:i N i ðmEN;1 þ gTEN;1 X i ; s2EN;1 Þ
/
i2Oð1;1Þ



Y

ðpNE:i þ pNN:i Þ

i2Oð1;0Þ



i
Y h
pEE:i N i ðmEE;0 þ gTEE;0 X i ; s2EE;0 Þ þ pNE:i N i ðmNE;0 þ gTNE;0 X i ; s2NE;0 Þ

i2Oð0;1Þ



Y

ðpEN:i þ pNN:i Þ

ð8Þ

i2Oð0;0Þ

4.2. Incorporating Assumptions into Parametric Models
When the monotonicity assumption is made, the probabilities of the
principal strata and the potential wages can be modeled similarly, except
that the models are restricted to three principal strata – EE, EN, and NN. In
this case, members of the Oð1; 0Þ group all belong to the NN stratum,
whereas members of the Oð0; 1Þ group all belong to the EE stratum, and
therefore only the Oð1; 1Þ group and the Oð0; 0Þ group involve mixture of
principal strata.
The stochastic dominance assumption considering covariates is as
follows:
Assumption 2u (Stochastic dominance).
(2a) (Stochastic dominance under training): For any two individuals i
and j with G i ¼ EE and Gj ¼ EN and identical values of the

Evaluating the Effects of Job Training Programs on Wages

129

covariates X i ¼ X j ¼ X  ,
PrðY i ð1Þ  tjG i ¼ EE; X i ¼ X  ; hÞ  PrðY j ð1Þ  tjG j ¼ EN; X j ¼ X  ; hÞ
for any real number t.
(2b) (Stochastic dominance under no training): For any two individuals i
and j with Gi ¼ EE and Gj ¼ NE and identical values of the
covariates X i ¼ X j ¼ X  ,
PrðY i ð0Þ  tjG i ¼ EE; X i ¼ X  ; hÞ  PrðY j ð0Þ  tjG j ¼ NE; X j ¼ X  ; hÞ
for any real number t.
Consider the most general case when covariates are unbounded and can
have both positive and negative values. When the monotonicity assumption
is not made, the stochastic dominance assumption under training implies
that
gEE;1 ¼ gEN;1 ð¼ g:;1 Þ;

s2EE;1 ¼ s2EN;1 ð¼ s2:;1 Þ;

mEE;1  mEN;1

(9)

and the stochastic dominance assumption under no training implies that
gEE;0 ¼ gNE;0 ð¼ g:;0 Þ;

s2EE;0 ¼ s2NE;0 ð¼ s2:;0 Þ;

mEE;0  mNE;0

(10)

The readers are referred to the appendix for proof. If covariates are
bounded, then the implications of the stochastic dominance assumption
depend on the particular bounds of the covariates and could be very
tedious to derive. Hence, we still restrict our model to the parallel regression
case in Eqs. (9) and (10). Modeling under the stochastic dominance
assumption in the presence of the monotonicity assumption can be done
similarly.

4.3. Prior Distributions for the Parameters
Because job training datasets usually involve large sample sizes, the
inﬂuence of prior distributions should be relatively small. We will use some
relatively uninformative but convenient prior distributions for the parameters h. The simulation results in Section 6.1 show that these prior
distributions have little effect on the resulting estimates. For more careful
calibration and sensitivity analysis of the prior distribution, the readers are
referred to Bernardo and Smith (2000).

130

JUNNI L. ZHANG ET AL.

For the coefﬁcients in the multinomial logit model, we use the following
independent prior distributions:
for g 2 fEN; NE; NNg;

ðag ; bg Þ  Nð0; K 0 IÞ

where Nðk; RÞ stands for the multivariate normal distribution with mean
vector k and covariance matrix R, K0 is a relatively large constant for the
prior to be relatively uninformative (we use K0=100), and I denotes an
identity matrix of appropriate dimension. For other parameters in the
model for log potential wage, we use the following conjugate prior
distributions (given the principal stratum g):3
for

ðg; zÞ 2 fðEE; 1Þ; ðEE; 0Þ; ðEN; 1Þ; ðNE; 0Þg,
s2g;z  Inv  w2 ðv0 ; s20 Þ;

ðmg;z ; gTg;z ÞT js2g;z  Nð0; K 0 s2g;z IÞ

where Inv  w2 ðv0 ; s20 Þ stands for the scaled inverse chi-square distribution
with v0 degrees of freedom and scale parameter s20 , and where v0 and s20 are
small constants for the prior to be relatively uninformative. We use v0 ¼ 2
and s20 ¼ 1.
When the monotonicity assumption is made, we use similar prior
distributions as above except without those for ðaNE ; bNE Þ and
ðmNE;0 ; gNE;0 ; s2NE;0 Þ. When the stochastic dominance assumption is made
without the monotonicity assumption, the prior distributions for ðag ; bg Þ
remain the same as above, but the prior distributions for the other
parameters become:
s2;1  Inv  w2 ðv0 ; s20 Þ;

ðmEE;1 ; mEN;1 ; gT;1 ÞT js2;1  Nð0; K 0 s2;1 IÞ

for mEE;1  mEN;1

s2;0

ðmEE;0 ; mNE;0 ; gT;0 ÞT js2;0

for mEE;0  mNE;0

 Inv  w

2

ðv0 ; s20 Þ;



Nð0; K 0 s2;0 IÞ

When the stochastic dominance assumption is made in the presence of
monotonicity assumption, similar prior distributions can be used.

5. COMPUTATIONAL ASPECTS
Because the likelihood function involves mixture distributions, we may
encounter multimodality of the posterior distribution of h. Because our
primary objective here is to illustrate the usefulness of the straightforward
Bayesian approach within the principal stratiﬁcation framework, we
focus our discussion on cases when the possible modes are well separated

Evaluating the Effects of Job Training Programs on Wages

131

and a single mode dominates the other modes in probability mass.
Usual inferences about ATEEE, such as those using the posterior median
and posterior intervals, can then be made in the region of the dominating
mode.

5.1. Strategy
Our computations follow the general strategy of Gelman, Carlin, Stern,
and Rubin (2003). We describe the computing strategy in the more difﬁcult
and general case, when neither the monotonicity assumption nor the
stochastic dominance assumption is made. We ﬁrst search for all posterior
modes of h, and then estimate the probability mass around each mode as
follows:
1. Find the posterior modes hð1Þ ; . . . ; hðMÞ .
2. Approximate the posterior distribution around each mode using a
multivariate normal distribution centered at that mode with approximate
covariance matrix SðmÞ .4 The posterior density of h can then be
approximated by
M
X

fm NðhjhðmÞ ; RðmÞ Þ

(11)

m¼1

where fm denotes the probability mass around the mode hðmÞ and is
estimated in step 3 below.
3. Let qð1Þ ; . . . ; qðMÞ denote the (unnormalized) posterior densities at the
posterior modes. f1 ; . . . ; fM can be estimated by equating the actual
(unnormalized) posterior density q(m) at each mode hðmÞ to the
approximate density (11) at that mode. When the modes are well
separated, we obtain fm / qðmÞ jSðmÞ j1=2 .
If the estimated probability mass of a single mode dominates that of the
other modes, we then compute the posterior median and posterior intervals
in the region around that mode as if it were the only mode. If there is more
than one dominant mode, other more complicated strategies must be used,
but such discussion is beyond the scope of this chpater.
If we were considering making the monotonicity assumption and/or the
stochastic dominance assumption in an application, we could choose among
the models by computing the Bayes factors, or by conducting posterior

132

JUNNI L. ZHANG ET AL.

predictive checks (Rubin, 1984; Gelman, Meng, & Stern, 1996), or using
other methods for model choice. Because model choice is a completely
different issue than implementing Bayesian analysis in our principal
stratiﬁcation setting, further discussion of this topic is beyond the scope
of this chapter.

5.2. Finding the Modes and Approximating their Masses
We use the EM algorithm (Dempster, Laird, & Rubin, 1977) to search for
the posterior modes hð1Þ ; . . . ; hðMÞ (with the variance parameters being
logarithm-transformed). To estimate the covariance matrix RðmÞ around hðmÞ
for the normal approximation, one could use quadratic approximation
algorithms such as SEM (Meng & Rubin, 1991). However, because we will
use MCMC methods, e.g., the Gibbs sampler and the Metropolis–Hastings
algorithm, to sample from the posterior distribution, we also apply MCMC
to estimate the probability mass. We start C different chains from each
mode hðmÞ , use the R statistic of Gelman and Rubin (1992) to judge
ðmÞ
convergence of these C chains, and then obtain W draws of h, hðmÞ
1 ; . . . ; hW ,
after approximate convergence; RðmÞ can be estimated by the sample
covariance matrix. After the probability mass for each mode is approximated as described in Section 5.1, and a single dominating mode is
presumably found, draws from the dominating mode can then be used for
inference about ATEEE.

5.3. Markov Chain Monte Carlo Methods
MCMC methods were used because it is difﬁcult to draw the parameters
directly from their posterior distribution. However, if the principal stratum
indicators G were known, the conditional posterior distribution of h, given
G, is simply
f ðhjG; X; Z; Sobs ; Yobs Þ / pðhÞLðhjG; X; Z; Sobs ; Yobs Þ

(12)

where pðhÞ is the prior probability density of h, and LðhjG; X; Z; Sobs ; Yobs Þ is
the ‘‘complete-data’’ likelihood function. The conditional posterior distribution (12) has a much simpler structure for inference than the posterior
distribution of h. This suggests computing the posterior distribution of h
using a data augmentation approach (Tanner & Wong, 1987), where we can

Evaluating the Effects of Job Training Programs on Wages

133

treat G as missing data, and iteratively (a) impute G given h and (b) draw h
given G, in analogy with the EM algorithm.
In the imputation step, a random draw of G is taken from the conditional
distribution of the principal strata, which is given as follows:
for i 2 Oð1; 1Þ
f ðG i ¼ EEjh; X; Z; Sobs ; Yobs Þ
¼

pEE:i N i ðmEE;1 þ gTEE;1 X i ; s2EE;1 Þ
pEE:i N i ðmEE;1 þ gTEE;1 X i ; s2EE;1 Þ þ pEN:i N i ðmEN;1 þ gTEN;1 X i ; s2EN;1 Þ

f ðG i ¼ ENjh; X; Z; Sobs ; Yobs Þ
¼

pEN:i N i ðmEN;1 þ gTEN;1 X i ; s2EN;1 Þ
pEE:i N i ðmEE;1 þ gTEE;1 X i ; s2EE;1 Þ þ pEN:i N i ðmEN;1 þ gTEN;1 X i ; s2EN;1 Þ

f ðG i ¼ NEjh; X; Z; Sobs ; Yobs Þ ¼ f ðG i ¼ NNjh; X; Z; Sobs ; Yobs Þ ¼ 0
for i 2 Oð1; 0Þ
pNE:i
pNE:i þ pNN:i
pNN:i
f ðGi ¼ NNjh; X; Z; Sobs ; Yobs Þ ¼
pNE:i þ pNN:i
f ðGi ¼ NEjh; X; Z; Sobs ; Yobs Þ ¼

f ðG i ¼ EEjh; X; Z; Sobs ; Yobs Þ ¼ f ðG i ¼ ENjh; X; Z; S obs ; Y obs Þ ¼ 0
for i 2 Oð0; 1Þ
f ðG i ¼ EEjh; X; Z; Sobs ; Yobs Þ
¼

pEE:i N i ðmEE;0 þ gTEE;0 X i ; s2EE;0 Þ
pEE:i N i ðmEE;0 þ gTEE;0 X i ; s2EE;0 Þ þ pNE:i N i ðmNE;0 þ gTNE;0 X i ; s2NE;0 Þ

f ðGi ¼ NEjh; X; Z; Sobs ; Yobs Þ
¼

pNE:i N i ðmNE;0 þ gTNE;0 X i ; s2NE;0 Þ
pEE:i N i ðmEE;0 þ gTEE;0 X i ; s2EE;0 Þ þ pNE:i N i ðmNE;0 þ gTNE;0 X i ; s2NE;0 Þ

f ðG i ¼ ENjh; X; Z; Sobs ; Yobs Þ ¼ f ðG i ¼ NNjh; X; Z; Sobs ; Yobs Þ ¼ 0
for i 2 Oð0; 0Þ
pEN:i
pEN:i þ pNN:i
pNN:i
f ðG i ¼ NNjh; X; Z; Sobs ; Yobs Þ ¼
pEN:i þ pNN:i
f ðG i ¼ ENjh; X; Z; Sobs ; Yobs Þ ¼

f ðG i ¼ EEjh; X; Z; Sobs ; Yobs Þ ¼ f ðG i ¼ NEjh; X; Z; Sobs ; Yobs Þ ¼ 0

134

JUNNI L. ZHANG ET AL.

Partition h into hþ ¼ fðag ; bg Þ; g 2 fEN; NE; NNgg and the rest, h. Given
G, we can draw h as follows:
1. Use the Metropolis–Hastings algorithm (Metropolis, Rosenbluth,
Rosenbluth, Teller, & Teller, 1953; Hastings, 1970) to draw h+ from
its conditional posterior distribution
f ðhþ jh ; G; X; Z; Sobs ; Yobs Þ / pðhþ Þ
Q
Q

pEE:i 
pEN:i 
i2Oð1;1Þ\EE



Q

i2Oð1;1Þ\EN

pEE:i 

i2Oð0;1Þ\EE

Q

i2Oð0;1Þ\NE

Q
i2Oð1;0Þ\NE

pNE:i 

Q

Q

pNE:i 

pNN:i

i2Oð1;0Þ\NN

Q

pEN:i 

i2Oð0;0Þ\EN

pNN:i

i2Oð0;0Þ\NN

where p( ) again denotes the prior probability density function. For
example, use the modiﬁed Newton–Raphson method to estimate K, the
conditional posterior mode of h+, and O, the conditional posterior
covariance matrix at the mode. We then use the multivariate t
distribution td ðK; XÞ as the proposal distribution in the Metropolis–
Hastings algorithm. To be more speciﬁc, suppose that hcur
þ is the current
cur
parameter value, we then generate hnew
þ from td ðK; XÞ and update hþ to
new
be hþ with probability

min 1;

obs
f ðhnew
; Yobs Þtd ðhcur
þ jh ; G; X; Z; S
þ jK; XÞ

!

obs
; Yobs Þtd ðhnew
f ðhcur
þ jh ; G; X; Z; S
þ jK; XÞ

where td ðhþ jK; XÞ is the probability density function of td ðK; XÞ
evaluated at h+.
2. For ðg; zÞ 2 fðEE; 1Þ; ðEE; 0Þ; ðEN; 1Þ; ðNE; 0Þg, draw s2g;z from its conditional posterior distribution, which is an Inv  w2 distribution, then draw
ðmg;z ; gTg;z ÞT , given s2g;z , from their joint conditional posterior distribution,
which is a multivariate normal distribution.

5.4. Applying New Code Checking Tools
Although there has been a rich literature on algorithms ﬁtting Bayesian
models, there is only limited work on checking the correctness of the

Evaluating the Effects of Job Training Programs on Wages

135

software code implementing these algorithms. Cook, Gelman, and Rubin
(2006) proposed simulation methods that can partially ﬁll this gap. We will
apply these methods to our context.
The software validation methods in Cook et al. (2006) are based on the
posterior quantiles of the true values of scalar parameters over replications
of the simulation. In each replication of the simulation, the ‘‘true’’
parameter values htrue are ﬁrst generated from their prior distribution
p(h), and the ‘‘observed’’ data, Sobs and Yobs, are then generated from
pðSobs ; Yobs jhtrue ; X; ZÞ, where the covariates X and the treatment assignment
indicators Z are ﬁxed; W posterior draws ðh1 ; h2 ; . . . ; hW Þ are then generated
using the to-be-tested software implementing the algorithms in Sections 5.1–5.3.
Let j denote
a generic scalar component or function of u, and let
^ true Þ ¼ ððPW Iðjtrue 4j ÞÞ=W Þ, the estimated quantile of jtrue. With
bðj
w
w¼1
^ true Þ converges to
correctly written software, the distribution of bðj
Uniform(0,1) as W ! 1. We can repeat the simulation of utrue , Sobs,
Yobs, and ðh1 ; h2 ; . . . ; hW Þ for Rrep times, and calculate the estimated
PRrep quantile
b^r of utrue in each replication. The distribution of B2j ¼ r¼1
ðF1 ðb^r ÞÞ2
2
should converge to wRrep for correctly written software, where F is the CDF
for standard normal distribution. Deviation of the distribution of the
posterior quantiles from the uniform distribution can then be quantiﬁed by
pj ¼ F w2R ðB2j Þ, where F w2R is the CDF for the w2Rrep distribution. Extreme
rep

rep

values of pj (too close to either 0 or 1) indicate errors in the software.
To analyze the simulation output more efﬁciently, the monitored scalar
parameters (components of u or scalar functions of u) are ﬁrst divided into
‘‘batches,’’ each consisting of related parameters. In our context, when
neither the monotonicity assumption nor the stochastic dominance
assumption is made, each set of (ag, bg) (g=EN, NE, NN) forms a batch,
and each set of ðmg;z ; gg;z ; logðs2g;z ÞÞ (ðg; zÞ 2 fðEE; 1Þ; ðEE; 0Þ; ðEN; 1Þ;
ðNE; 0Þg) forms a batch; when only the monotonicity assumption is made,
we can form similar batches without ðaNE ; bNE Þ or ðmNE;0 ; gNE;0 ; logðs2NE;0 ÞÞ;
when only the stochastic dominance assumption is made, ðmEE;1 ; mEN;1 ;
g:;1 ; logðs2:;1 ÞÞ forms a batch and ðmEE;0 ; mNE;0 ; g:;0 ; logðs2:;0 ÞÞ forms another
batch; similar batches can be formed when both assumptions are made.
Cook et al. (2006) recommended two complementary approaches to
analyze the simulation output. In the exploratory approach, the pj-values
are ﬁrst transformed into statistics zj ¼ F1 ðpj Þ, and the absolute values of
these zj statistics are then plotted in batches. Large values of zj indicate
errors in the software. In the conﬁrmatory approach, for each batch of
related parameters, a new scalar parameter is deﬁned as the mean of all

136

JUNNI L. ZHANG ET AL.

parameters in the batch, and the pj -values for these new parameters are
calculated from the posterior samples. The (two-sided) p-value for each such
pj-value is multiplied by the total number of batches to achieve a simple
Bonferroni corrected p-value.
Because the monotonicity assumption is less plausible in practice than the
stochastic dominance assumption, below we focus on the case when the
monotonicity assumption is not made, and apply the new software checking
tools to the Bayesian analysis, with and then without the stochastic
dominance assumption. Code checking in the presence of the monotonicity
assumption can be done analogously.
5.4.1. Code Checking without the Stochastic Dominance Assumption
We ﬁrst perform a simulation of 20 replications to check the software
developed to ﬁt the model without the stochastic dominance assumption,
using the computing strategy and algorithms described in Sections 5.1–5.3
with C=3 and W=5000. We use one covariate X  Nð0; 4Þ and let each
participant be randomized into the training group (Zi=1) with probability
0.5 and the control group (Zi=0) with probability 0.5. The sample size is
N=300. We use the speciﬁc prior distribution in Section 4.3 with K0=100,
v0=2, and s20 ¼ 1:0.5
In each replication, there are multiple posterior modes; however, each
MCMC chain stayed around its starting mode, indicating that the modes are
well separated; moreover, there is a single major mode whose estimated
probability mass is almost 1. Therefore, we monitor the parameter draws
from the major mode. All zj statistics are plotted in Fig. 1, with each row
representing a different batch of parameters. Almost all zj statistics are less
than 2, except for one such statistic, which is neither overly large nor
unexpected, given the number of parameters. Moreover, the smallest
Bonferroni-adjusted p-value is 0.36. So there is no indication of an
incorrectly written software.
5.4.2. Code Checking with the Stochastic Dominance Assumption
We perform a simulation of 20 replications to check the software developed
to ﬁt the model with the stochastic dominance assumption. The simulation
setting is similar to that in Section 5.4.1. In each replication, there is only
one mode. The absolute zj statistics for the parameters are plotted in Fig. 2.
Only one zj statistic is moderately larger than 2. Moreover, the smallest
Bonferroni-adjusted p-value is 0.17. So there is no indication of an
incorrectly written software.

Evaluating the Effects of Job Training Programs on Wages

137

Without Stochastic Dominance
Batch 1
Batch 2
Batch 3
Batch 4
Batch 5
Batch 6
Batch 7
0.0

0.5

1.0

1.5

2.0

2.5

Absolute z Transformation of p Values

Fig. 1. Scalar Validation zj Statistics without Stochastic Dominance Assumption.
Each Row Represents a Batch of Parameters; the Hollow Circles in Each Row
Represent the zj Statistics Associated with the Corresponding Batch of Parameters.
Solid Circles Represent the zj Statistics Associated with the Mean of the
Corresponding Batch of Parameters. Batch 1={aEN, bEN}; Batch 2={aNE, bNE};
Batch 3={aNN, bNN}; Batch 4={mEE,1, ZEE,1, logðs2EE;1 Þ}; Batch 5={mEE,0, ZEE,0,
logðs2EE;0 Þ}; Batch 6={mEN,1, ZEN,1, logðs2EN;1 Þ}; Batch 7={mNE,0, ZNE,0, logðs2NE;0 Þ}.

6. A FREQUENTIST SIMULATION EXAMPLE
6.1. The Simulated Datasets with Fixed Parameters
We specify the ‘‘true’’ model to be the speciﬁc parametric model in Section
4.1, in which the monotonicity assumption does not hold but the stochastic
dominance assumption does. Then we apply our computating software
developed according to Section 5 to the simulated datasets with ﬁxed
parameters as below, and then illustrate that our Bayesian analysis can
correctly estimate ATEEE.
Assume there is only one pretreatment covariate X that follows an N(0,4)
distribution. The ‘‘true’’ parameters for the multinomial logistic regression
are set to be
aEN ¼ 1:13;
bEN ¼ 1
aNE ¼ 0:235;
aNN ¼ 1:205;

bNE ¼ 2:5
bNN ¼ 4

138

JUNNI L. ZHANG ET AL.
With Stochastic Dominance
Batch 1
Batch 2
Batch 3
Batch 4
Batch 5
Batch 6
Batch 7
0.0

0.5

1.0

1.5

2.0

2.5

Absolute z Transformation of p Values

Fig. 2. Scalar Validation zj Statistics with Stochastic Dominance Assumption.
Each Row Represents a Batch of Parameters; the Hollow Circles in Each Row
Represent the zj Statistics Associated with the Corresponding Batch of Parameters.
Solid Circles Represent the zj Statistics Associated with the Mean of the
Corresponding Batch of Parameters. Batch 1={aEN, bEN}; Batch 2={aNE, bNE};
Batch 3={aNN, bNN}; Batch 4={mEE,1, mEN,1, Z.,1, logðs2;1 Þ}; Batch 5={mEE,0, mNE,0, Z.,0,
logðs2;0 Þ}.

which gives us the following marginal proportions of the principal strata:
pEE=30%, pEN=30%, pNE=10%, pNN=30%. The ‘‘true’’ parameters in
the model for log potential wages are set to be
mEE;1 ¼ 8:5;

mEE;0 ¼ 7; mEN;1 ¼ 2:5; mNE;0 ¼ 6:5
Z:;1 ¼ Z:;0 ¼ 1; s2:;1 ¼ s2:;0 ¼ 1

The true value of ATEEE is
ATEEE ¼ E½Y ð1ÞjG ¼ EE  E½Y ð0ÞjG ¼ EE
EfIðG ¼ EEÞ½Y ð1Þ  Y ð0Þg
¼
pEE
EfPrðG ¼ EEjX ; hÞ½EðY ð1ÞjG ¼ EE; X ; hÞ  EðY ð0ÞjG ¼ EE; X ; hÞg
¼
pEE
2
3
1 6expðmEE;1 þ Z:;1 X þ 0:5  s2:;1 Þ  expðmEE;0 þ Z:;0 X þ 0:5  s2:;0 Þ7
P
¼
E4
5
pEE
expðag þ bg X Þ
g

ð13Þ

Evaluating the Effects of Job Training Programs on Wages

139

Table 2. Means and Standard Deviations (in Parentheses) of the
Employment Rates and the Average Wage for the Employed Groups
Within the Training Group and the Control Group for the 100 Simulated
Datasets.

Employment rate
Average wage for the employed

Training

Control

60.2% (4.2%)
1283.77 (440.24)

39.3% (4.3%)
1310.83 (532.86)

which, as estimated by simulating a large sample of X from N(0,4), is equal
to 2037:6. Therefore, training improves both the employment rate by
30%–10%=20%, and the average wage for the EE group by 2037.6.
We generated 100 sets of observed data with the above parameters ﬁxed.
Therefore, this is a frequentist simulation. In each dataset, X values for 300
participants were drawn according to N(0,4); the principal stratum for
each participant was then drawn according to PðG i ¼ gjX i ; hÞ. These 300
participants were then randomized into the training group (Zi=1) with
probability 0.5 and the control group (Zi=0) with probability 0.5; the
observed employment indicator Sobs
was 1 if Gi=EE, or Zi=1 and Gi=EN,
i
or Zi=0 and Gi=NE, and was 0 otherwise. The observed wage Y obs
was
i
drawn according to f ðY i ðZ i ÞjGi ; X i ; hÞ if ðG i ; Z i Þ 2 fðEE; 1Þ; ðEE; 0Þ;
ðEN; 1Þ; ðNE; 0Þg and was equal to * otherwise. Table 2 shows the means
and standard deviations of the employment rates and the average wages for
the employed groups within the training group and the control group for the
100 datasets.

6.2. Bayesian Analysis with Stochastic Dominance
Because the stochastic dominance assumption holds in the example of
Section 6.1, we ﬁrst discuss the Bayesian analysis of the simulated data
under the stochastic dominance assumption. We use a prior distribution
similar to that used in Section 5.4.1. For each of the 100 simulated datasets,
and for each posterior draw of h (given the observed dataset), ATEEE in
Eq. (13) is estimated using the empirical distribution of X by
P

PN 
expðmEE;1 þ Z:;1 X i þ 0:5 n s2:;1 Þ  expðmEE;0 þ Z:;0 X i þ 0:5 n s2:;0 Þ
i¼1
g expðag þ bg X i Þ

PN  P
i¼1 1=
g expðag þ bg X i Þ

140

JUNNI L. ZHANG ET AL.

Table 3. Frequentist Properties of Bayesian Analyses for ATEEE ¼
2037:6 for the 100 Simulated Datasets (SD: Stochastic Dominance
Assumption).
Estimator

Mean
Bias

Posterior median (with SD)
Posterior median (without SD)

56.24
217.07

Root Mean
Squared Error

95% Interval
Coverage
rate

Mean (s.d.) of
width

95%
99%

3105.49 (1001.19)
3850.83 (1461.19)

695.43
854.11

For the 100 simulated datasets, the frequentist properties of the Bayesian
analysis for ATEEE are demonstrated of Table 3. For all the 100 simulated
datasets, the 95% posterior intervals suggest correctly that the treatment
effect is positive for the EE group. The mean and the standard deviation of
the length of these intervals are 3105.49 and 1001.19, respectively, and the
coverage rate of these intervals for the true value of ATEEE is at the nominal
coverage rate of 95%. Also, the mean bias and the root mean squared error
for the posterior median are 56.24 and 695.43, respectively. Thus, we can see
that the Bayesian analysis has good frequentist properties for ATEEE in this
example.
6.3. Checking Stochastic Dominance
Suppose after analyzing the observed data under the stochastic dominance
assumption, we want to check whether this assumption is reasonable for
the observed data. We propose to use a posterior predictive check with the
discrepancy variable
ns

TðD; hs Þ ¼ log Lðhs jX; Z; Sobs ; Yobs Þ  log Lðb
h ðDÞjX; Z; Sobs ; Yobs Þ
where D is a dataset, hs is ans parameter vector satisfying the stochastic
dominance assumption, and b
h ðDÞ is the major posterior mode for h given
the dataset D when the stochastic dominance assumption is not made.
Speciﬁcally, let Dobs denote the observed dataset; given the V posterior
draws fhs1 ; . . . ; hsV g under the stochastic dominance assumption, we generate
a new dataset DrepðvÞ using each posterior draw hsv , with Z and X being ﬁxed
as in Dobs. The posterior predictive p-value can be calculated as
V
1X
I½TðDrepðvÞ ; hsv Þ  TðDobs ; hsv Þ
V i¼1

Evaluating the Effects of Job Training Programs on Wages

141

where I is a general indicator function. The posterior predictive p-value is a
counterpart of the classical p-value for assessing goodness-of-ﬁt for statistics
T (Rubin, 1984).
For each of the 100 simulated datasets, the posterior predictive p-value is
between 0.4 and 0.6, indicating that the stochastic dominance assumption is
reasonable.

6.4. Bayesian Analysis without Stochastic Dominance
Suppose we analyze the 100 simulated datasets using the general model with
neither the stochastic dominance assumption nor the monotonicity
assumption. For each of the 100 simulated datasets, we make inferences
about h and ATEEE based on the major posterior mode. For each posterior
draw of h, ATEEE in Eq. (13) is estimated using the empirical distribution of
X by
.P

PN  
expðmEE;1 þ ZEE;1 X i þ 0:5 n s2EE;1 Þ  expðmEE;0 þ ZEE;0 X i þ 0:5 n s2EE;0 Þ
g expðag þ bg X i Þ
i¼1

PN  P
g expðag þ bg X i Þ
i¼1 1=

As we can see from Table 3, inferences under the stochastic dominance
assumption are sharper than those without the stochastic dominance
assumption, in the sense that the bias and the root mean squared error of
the posterior median are smaller, and the 95% posterior intervals are
narrower. Moreover, the stochastic dominance assumption eliminates the
multimodality problem, because there is only one posterior mode with this
assumption, but multiple posterior modes without it.

7. DISCUSSION
In this chpater, we have shown how to address a common problem in the
evaluation of job training programs through randomized experiments. Our
approach is new, and hopefully innovative and helpful, and differs from the
more traditional econometric analysis. Critically, our approach, rather than
trying to estimate the effects of the training on wages for the entire
population, instead focuses on the subset of individuals who would be
employed, that is, those who would have positive wages, whether or not they
were job trained. This subgroup is not directly observed, and therefore

142

JUNNI L. ZHANG ET AL.

latent. But it is a well-deﬁned subgroup, and one of potentially much applied
interest, especially because its deﬁnition can be conveyed to people in
program evaluation without technical training in econometrics.
Moreover, because our general approach, principal stratiﬁcation (Frangakis &
Rubin, 2002), obtains estimates on the training’s effect in distinct
subgroups of people (i.e., the NE, EN, NN, and EE groups) on both
employment and wages (only the EE group), its resulting answers should
generalize better to environments outside the current experiment, for
example, to different job markets where the chance of getting employed may
be different but the effect of training on wages may be the same. That is,
because we estimate the effects of training on wages conditional on the type
of person, as deﬁned by that person’s covariates and principal stratum, our
estimates may generalize to other settings where the proportions of types of
people differ but the effects of training on wages for the EE subgroup
remain the same as in the current experiment. This is the same sort of
reasoning that is used whenever we obtain more conditional estimates (e.g.,
separately for men and women).

NOTES
1. A brief discussion of how this approach differs from previous approaches, e.g.,
in economics (Roy, 1951), appears in Imbens and Rubin (2006). The formal notation
for potential outcomes ﬁrst appeared in Neyman (1923) in the context of a
randomized experiment.
2. In addition, all of the covariates are individual characteristics (as opposed to
choice-speciﬁc characteristics), and each of them has coefﬁcients that are choicespeciﬁc (i.e., each of them enters the underlying stochastic utilities with a different
coefﬁcient): in this case, cross elasticities are not constant, and including a new
alternative to the choice set would not leave the odds of the other alternatives
unchanged, because a different model should be speciﬁed with an additional vector
of coefﬁcients.
3. Although zero might not be a good number for the means of the prior
distribution of intercepts of equations for log potential wages, because K0 is large
and the mean of log potential wage would not be an overly big number, the effect of
this prior distribution will be quite small given a large sample size. Hence, we do not
explore a careful calibration of the mean of the prior distribution.
4. To make the normal approximation more reasonable, we take the logarithm of
the variance parameters (i.e., s2EE;1 ; s2EE;0 ; s2EN;1 ; and s2NE;0 ) whereas keeping the other
components of h as in Eq. (7).
5. According to Cook et al. (2006) advice to choose un-nice numbers, we
recognize that the choice of these values could be have been better.

Evaluating the Effects of Job Training Programs on Wages

143

ACKNOWLEDGMENT
Junni L. Zhang’s research is sponsored in part by the Chinese NSF grant
10401003.

REFERENCES
Angrist, J., Imbens, G., & Rubin, D. B. (1996). Identiﬁcation of causal effects using
instrumental variables. Journal of the American Statistical Association, 91, 444–455.
Bernardo, J. M., & Smith, A. F. M. (2000). Bayesian theory. Wiley.
Cook, S., Gelman, A., & Rubin, D. B. (2006). Validation of software for Bayesian models using
posterior quantiles. To Appear in Journal of Computational and Graphical Statistics, 15,
675–692.
Copas, J. B., & Li, H. G. (1997). Inference for non-random samples (with discussion). Journal of
the Royal Statistical Society, Series B, 59, 55–96.
Decker, P. T., & Corson, W. (1995). International trade and worker displacement: Evaluation
of the trade adjustment assistance program. Industrial and Labor Relations Review, 48,
758–774.
Dempster, A. P., Laird, N., & Rubin, D. B. (1977). Maximum likelihood estimation from
incomplete data using the EM algorithm (with discussion). Journal of the Royal
Statistical Society, Series B, 39, 1–38.
Frangakis, C. E., & Rubin, D. B. (1999). Addressing complications of intention-to-treat
analysis in the combined presence of all-or-none treatment-noncompliance and
subsequent missing outcomes. Biometrika, 86, 365–379.
Frangakis, C. E., & Rubin, D. B. (2002). The deﬁning role of ‘principal stratiﬁcation and
effects’ for comparing treatments adjusted for posttreatment variables: From treatment
noncompliance to surrogate endpoints. Biometrics, 58, 191–199.
Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2003). Bayesian data analysis (2nd ed.).
Chapman and Hall.
Gelman, A., Meng, X. L., & Stern, H. (1996). Posterior predictive assessment of model ﬁtness
via realized discrepancies. Statistica Sinica, 6, 733–807.
Gelman, A., & Rubin, D. B. (1992). Inference from iterative simulation using multiple
sequences. Statistical Science, 7, 457–511.
Grilli, L., & Mealli, F. (2005). Causal inference through principal startiﬁcation to assess the
effect of university studies on job opportunities. Submitted.
Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their
applications. Biometrika, 57, 97–109.
Heckman, J. J. (1979). Sample selection bias as a speciﬁcation error. Econometrica, 47,
153–162.
Heckman, J. J. (1990). Varieties of selection bias. American Economic Review, 80, 313–318.
Heckman, J. J., Lalonde, R. J., & Smith, J. A. (1999). The economics and econometrics of active
labour market programs. In: O. Ashenfelter & D. Card (Eds), Handbook of labour
economics (Vol. 3A). Amsterdam: North Holland.

144

JUNNI L. ZHANG ET AL.

Heckman, J. J., & Smith, J. (1998). Evaluation the welfare state. In: S. Strom (Ed.),
Econometrics and economic theory in the 20th century: The Ragnar Frisch Centennial
Econometric Society monograph series. Cambridge University Press.
Heckman, J. J., Smith, J., & Clements, N. (1997). Making the most out of programme
evaluations and social experiments: Accounting for heterogeneity in programme
impacts. The Review of Economic Studies, 487–535.
Heckman, J. J., & Vytlacil, E. J. (1999). Local instrumental variables and latent variable models
for identifying and bounding treatment effects. Proceedings of the National Academy of
Sciences, USA, 96, 4730–4734.
Hirano, K., Imbens, G. W., Rubin, D. B., & Zhou, X. H. (2000). Assessing the effect of an
inﬂuenza vaccine in an encouragement design. Biostatistics, 1, 69–88.
Imbens, G. W., & Rubin, D. B. (1997). Bayesian inference for causal effects in randomized
experiments with noncompliance. Annals of Statistics, 25, 305–327.
Imbens, G. W., & Rubin, D. B. (2006). Rubin causal model. In: The new Palgrave dictionary of
economics. Palgrave: Macmillan.
Kodrzycki, Y. K. (1997). Training programs for displaced workers: What do they accomplish?
New England Economic Review, 3, 39–59.
Lee, D. S. (2005). Training, wages, and sample selection: Estimating sharp bounds on treatment
effects. NBER Working paper.
Little, R. J. A. (1985). A note about models for selectivity bias. Econometrica, 53, 1469–1474.
Liu, C., & Rubin, D. B. (1998). Ellipsoidally symmetric extensions of the general location model
for mixed categorical and continuous data. Biometrika, 85, 673–688.
Manski, C. F. (1989). Anatomy of the selection problem. Journal of Human Resources, 24,
343–360.
Manski, C. F. (1990). Nonparametric bounds on treatment effects. American Economic Review
Papers and Proceedings, 80, 319–323.
Manski, C. F. (1995). Identification problems in the social sciences. Harvard University Press.
Manski, C. F. (2003). Partial identification of probability distributions. New York: Springer.
Meng, X. L., & Rubin, D. B. (1991). Using EM to obtain asymptotic variance-covariance
matrices: The SEM algorithm. Journal of the American Statistical Association, 86,
899–909.
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953).
Equations of state calculations by fast computing machines. Journal of Chemical Physics,
21, 1087–1091.
Neyman, J. (1923). On the application of probability theory to agricultural experiments: Essay
on principles. Translated in Statistical Science, 5, 465–480.
O’Leary, C. L. (1995). An impact analysis of employment programs in Hungary. Upjohn Institute
Staff Working Paper.
Roy, A. (1951). Some thoughts on the distribution of earnings. Oxford Economic Papers, 3,
135–146.
Rubin, D. B. (1974). Estimating causal effects of treatments in randomized and nonrandomized
studies. Journal of Educational Psychology, 66, 688–701.
Rubin, D. B. (1975). Bayesian inference for causality: The importance of randomization.
Proceedings of the Social Statistics Section of the American Statistical Association,
American Statistical Association (pp. 233–239).
Rubin, D. B. (1976). Inference and missing data. Biometrika, 63, 581–592.
Rubin, D. B. (1978). Bayesian inference for causal effects. Annals of Statistics, 6, 34–58.

Evaluating the Effects of Job Training Programs on Wages

145

Rubin, D. B. (1984). Bayesianly justiﬁable and relevant frequency calculations for the applied
statistician. Annals of Statistics, 12, 1151–1172.
Tanner, M. A., & Wong, W. H. (1987). The calculation of posterior distributions by data
augmentation (with discussion). Journal of the American Statistical Association, 82,
528–550.
Zhang, J. L., & Rubin, D. B. (2003). Estimation of causal effects via principal stratiﬁcation
when some outcomes are truncated by ‘‘death’’. Journal of Educational and Behavioral
Statistics, 28, 353–368.
Zhang, J. L., Rubin, D. B., & Mealli, F. (2005). Using the EM algorithm to estimate the effects
of job training programs on wages. Proceedings of the 55th Session of the International
Statistical Institute. International Statistical Institute, Sydney, Australia.

APPENDIX. PROOF FOR IMPLICATIONS OF
STOCHASTIC DOMINANCE IN SECTION 4.2
We only prove the implications of stochastic dominance under training
when covariates can take unbounded values, and the proof for implications
of stochastic dominance under no training is analogous. For any real
number t and for any real values of the covariates X  ; PrðY i ð1Þ 
tjG i ¼ EE; X i ¼ X  ; hÞ  PrðY j ð1Þ  tjG j ¼ EN; X j ¼ X  ; hÞ. Equivalently,
Fððt  mEE;1  gTEE;1 X  Þ=sEE;1 Þ  Fððt  mEN;1  gTEN;1 X  Þ=sEN;1 Þ where F
is the CDF for the standard normal distribution. This holds if and
only if for any real number t and for any real values of the covariates
X  ; ððt  mEE;1  gTEE;1 X  Þ=sEE;1 Þ  ððt  mEN;1  gTEN;1 X  Þ=sEN;1 Þ or ðsEE;1 
sEN;1 Þt þ ðsEN;1 gEE;1  sEE;1 gEN;1 ÞT X   mEN;1 sEE;1  mEE;1 sEN;1 . Equivalently, sEE,1sEN,1=0, sEN,1gEE,1sEE,1gEN,1=0, and hence 0Z
mEN,1sEE,1mEE,1sEN,1. In other words, s2EE;1 ¼ s2EN;1 (¼ s2;1 ), gEE,1=gEN,1
(=g ,1) and mEE,1ZmEN,1.

