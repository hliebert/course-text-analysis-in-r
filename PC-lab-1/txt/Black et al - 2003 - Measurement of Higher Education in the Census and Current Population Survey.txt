Journal of the American Statistical Association

ISSN: 0162-1459 (Print) 1537-274X (Online) Journal homepage: https://www.tandfonline.com/loi/uasa20

Measurement of Higher Education in the Census
and Current Population Survey
Dan Black, Seth Sanders & Lowell Taylor
To cite this article: Dan Black, Seth Sanders & Lowell Taylor (2003) Measurement of Higher
Education in the Census and Current Population Survey, Journal of the American Statistical
Association, 98:463, 545-554, DOI: 10.1198/016214503000000369
To link to this article: https://doi.org/10.1198/016214503000000369

Published online: 31 Dec 2011.

Submit your article to this journal

Article views: 205

Citing articles: 35 View citing articles

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=uasa20

Measurement of Higher Education in the Census and
Current Population Survey
Dan B LACK , Seth S ANDERS , and Lowell TAYLOR
We examine measurement error in the reporting of higher education in the 1990 Decennial Census and the post-1991 Current Population
Survey (CPS). We document that measurement error in the reporting of higher education is prevalent in Census data. Further, these errors
violate models of classical measurement error in important ways. The level of education is consistently reported as higher than it is (errors
are not mean 0), errors in the reporting of education are correlated with covariates that appear in earnings regressions, and errors in the
reporting of education appear correlated with the error term in a model of earnings determination. Thus, neither well-known results on
classical measurement error nor recent models of nonclassical measurement error are likely valid when using Census and CPS data. We
 nd some evidence that the measurement error is lower in the CPS than in the Census, presumably because  rst interviews are generally
conducted in person.
KEY WORDS: Current Population Survey; Decennial Census; Measurement error.

1. INTRODUCTION
A vast literature in the social sciences reports inferences
drawn from regression analyses in which individuals’education
appears as a regressor. Education is often used as an explanatory
variable in the analysis of unemployment, migration, marriage,
fertility, public assistance program take-up, voting patterns, and
earnings. Economists routinely use earnings regressions, for example, to explore a range of important issues: What is the return
to college education and has this return increased over the last
decades? How much of the racial and ethnic disparity in earnings is accounted for by differences in the amount and quality of
education? What are the causes and consequences of the rapid
increase in the relative number of women enrolling in professional schools?
The validity of inferences drawn in this empirical enterprise
rests largely on the accuracy of measures of educational attainment in the datasets researchers use. For example, an important literature examines earnings differences between women
and minorities and white men and the role that education plays
in explaining these differences (for a review, see Altonji and
Blank 1999). Within this literature there is interest in the question of whether the earnings gap between women and men or
minorities and whites dissipates with higher levels of education
or instead increases (i.e., is there a “glass ceiling”?). There is
virtually no concern about the extent to which error in the reporting of education might affect  ndings in this literature.
Our article addresses the extent and form of errors made by
respondents in answering the 1990 Decennial Census and the
post-1991 Current Population Survey (CPS) question on their
level of education and the consequences of these errors for inferences in regression analyses. Evaluation of measurement error in these datasets is particularly useful because a great deal
of empirical work in the social sciences uses these data or data
that are collected using similar instruments and methods.
Dan Black is Professor, Center for Policy Research, 426 Eggers Hall,
Syracuse University, Syracuse, NY 13244 (E-mail: danblack@syr.edu). Seth
Sanders is Professor, Department of Economics, 3105 Tydings Hall, University of Maryland, College Park, MD 20742 (E-mail: sanders@econ.umd.edu).
Lowell Taylor is Professor, Heinz School, Carnegie Mellon University, Pittsburgh, PA 15213-3890 (E-mail: lt20@andrew.cmu.edu). We thank Xin Li for
her excellent research assistance, and thank Harley Frazis, Amelia Haviland,
Chris Ruhm, seminar participants at the BLS, CMU/Pittsburgh Applied Micro Workshop, University of Kentucky, University of Maryland, Southern Economic Association Meetings, Virginia Tech, three anonymous reviewers, and
the co-editor, Thomas A. Louis, for helpful comments. We gratefully acknowledge  nancial support from the NICHD Grant HD3703-01 430.

Key to our study is a resurvey of over 200,000 respondents to
the 1990 Decennial Census Long Form who reported that they
had received a bachelor’s or some other advanced degree. The
National Survey of College Graduates (NSCG) was collected
by the National Science Foundation to conduct a panel survey
on scientists and engineers. The initial wave of the NSCG in
1993 resurveyed respondents from the 1990 Decennial Census
Long Form without regard to whether they worked as a scientist or engineer. As the purpose of the NSCG was to study
the schooling and careers of scientists and engineers, the survey instrument collected exceedingly detailed information on
the level and type of education. For individuals contacted for
the 1993 NSCG, we not only have the education data collected
by the NSCG, but also the educational information as originally recorded in the 1990 Decennial Census. This feature of
the data in turn allows us to explore issues of data accuracy of
these individuals’ initial Census reports. Because the NSCG is
for college graduates speci cally, our article focuses primarily
on measurement error for the well educated.
Our exploration of data quality indicates that measurement
error in recording higher education is substantial and nonrandom. In our examination of Census data for individuals in the
NSCG, we  nd that the Census error rates are especially high
for the doctoral and professional degree categories. We estimate
that about one- fth of individuals reporting a doctoral degree
in the Census do not have the degree, and more than a third of
individuals claiming to have a professional degree in the Census do not have the degree. We  nd that errors in the reporting
of education are correlated with many covariates that are typically entered into regressions that social scientists estimate. In
addition, the measurement error appears to be correlated with
the residuals in an earnings regression. Because measurement
error in education is systematically related to both observed
earnings-related characteristics and the error term in earnings
regressions, it is likely that measurement error is positively correlated across multiple reports on education. If so, instrumental
variable (IV) estimates that rely on multiple reports of education are inconsistent, as are other recently proposed estimators
designed to deal with these biases.
Although we do not propose a statistical solution to the form
of measurement error that we  nd, we do  nd evidence that

545

© 2003 American Statistical Association
Journal of the American Statistical Association
September 2003, Vol. 98, No. 463, Applications and Case Studies
DOI 10.1198/016214503000000369

546

Journal of the American Statistical Association, September 2003

face-to-face interviews, as employed in the Current Population
Survey (CPS), reduce (but do not eliminate) error in the education measure.
2. CONSEQUENCES OF MEASUREMENT ERROR IN
EDUCATION IN REGRESSION ANALYSIS
Before turning to our empirical evaluation of measurement
error in education, it is helpful to brie y examine the consequences of measurement error in a regression model where education is coded as a discrete outcome (as is the case of higher
education in the Census or CPS). We do so in the following
concrete example. Let y be an individual’s earnings and let x be
a binary variable equal to 0 if the individual has a bachelor’s
degree and 1 if the individual has a master’s degree. The return
to earning the higher degree is ¯ in the following equation:
y D ® C ¯x C ":

(1)

Suppose that x is not observed but instead we use x1 , education measured with error. Let the miscode probabilities be
q0 D Pr.x D 1 j x1 D 0/ and q1 D Pr.x D 0 j x1 D 1/. If this measurement error is uncorrelated with the error term in (1) (e.g.,
if there are purely random miscodes), it is obvious that the ordinary least squares (OLS) estimator, yN 1 ¡ yN 0 , is subject to attenuation bias, just as in the classic errors-in-variables model
(Griliches 1986). Some individuals with the higher degree will
be incorrectly mixed in with those who have the lower degree
and vice versa, reducing the estimated difference in mean earnings; see Bollinger (1996). Formally,
plim.¯OOLS / D .1 ¡ q0 ¡ q1 /¯:

(2)

A far more problematic case is when the measurement error
is correlated with the error term in (1), such as when individuals
with poor cognitive skills earn lower wages and are more likely
than others to misreport education. Then
plim.¯OOLS/
D .1 ¡ q0 ¡ q 1 /¯
¤
£
C .1 ¡ q1 /E." j x D 1; x1 D 1/ C q1 E." j x D 0; x1 D 1/
£
¤
¡ .1 ¡ q0 /E." j x D 0; x1 D 0/ C q0 E." j x D 1; x1 D 0/ ;

(3)

and no general statements can be made about the direction of
the bias in the OLS estimator.
More typically, social scientists are interested in estimates
from multivariate regressions such as,
y D ® C ¯x C ° z C ";

(4)

where z is an additional determinant of wages. As a concrete
example let z be an indicator of gender .F D 1; M D 0/, so that
° is a measure of the “gender earnings gap.” It is an exercise in
simple algebra to show that the OLS estimators of ¯ and ° are
weighted averages of differences in group mean incomes (Nyij /,
where i indicates education, 0 or 1, and j indicates gender, F
or M:
¯OOLS D wF .Ny1F ¡ yN 0F / C .1 ¡ wF /.Ny1M ¡ yN 0M /;
°OOLS D w1 .Ny1F ¡ yN 1M / C .1 ¡ w1 /.Ny0F ¡ yN 0M /;

(5)
(6)

with weights constructed as follows: If nj is the number of gender j and rj the proportion of gender j with the higher degree
.x D 1/, and n i is the number with education i and ri is the proportion of this group who are female .z D 1/,
£
¤
wF D rF .1 ¡ rF /nF = rM .1 ¡ rM /nM C rF .1 ¡ rF /nF ;
£
¤
w1 D r1 .1 ¡ r1 /n1 = r1 .1 ¡ r1 /n1 C r0 .1 ¡ r0 /n0 :

When measurement error is uncorrelated with the regression
error, the inconsistency of the OLS estimator can be described
in a relatively intuitive form. Let q ij be the probability that an
observation with education i and gender j is a miscode, that is,
qij D Pr.x1 6D x j x1 D i; z D j/, and let ! indicate probability
limits of the weights de ned previously. Then
plim.¯OOLS /
£
¤
D !F .1 ¡ q 0F ¡ q1F / C .1 ¡ !F /.1 ¡ q0M ¡ q1M / ¯; (7)
plim.°OOLS /
£
¤
D ° ¡ ¯ !1 .q1F ¡ q1M / ¡ .1 ¡ !1 /.q0F ¡ q 0M / :

(8)

Expression (7) shows the familiar attenuation bias. Expression (8) shows that the estimator of the gender earnings gap
will generally be inconsistent unless ¯ is 0 (in which case the
misclassi cation of education is irrelevant) or there is equality
in the miscode probabilities ( q 0F D q0M ; q1F D q 1M /. This latter condition is likely to pertain only if both education and the
error rate are uncorrelated with gender. As a simple counterexample, suppose that the only miscodes in education are of 0s
randomly being recorded as 1s. (We will show that this “degree creep” is, in fact, a prevalent form of measurement error
in the Census.) If fewer women than men have the higher level
of education, the probability of miscodes appearing for welleducated women will be higher than that for men, q 1F > q1M ,
and the bias in °O is negative (e.g., a negative gender “earnings
gap” where none exists). This same bias appears if women and
men have identical levels of education, but miscodes are more
common for women than for men. As in the univariate regression, matters are worse if the measurement error is correlated
with the regression error.
Finally, we return to the simple univariate regression, but
consider the case in which two measures of education are available, say x1 and x2 . It is easy to con rm that use of x2 as an
instrumental variable for x1 gives an estimator that is biased
away from 0:
plim.¯OIV / D ¯=.1 ¡ p0 ¡ p1 /;

(9)

where p0 D Pr.x1 D 1 j x D 0/ and p1 D Pr.x1 D 0 j x D 1/.
Black, Berger, and Scott (2000) and Kane, Rouse, and Staiger
(1999) provided a correction to this inconsistency, but only for
the special case in which the measurement error in the education reports are uncorrelated with each other (conditional on x)
and with the regression error.
3. MEASUREMENT ERROR IN THE
DECENNIAL CENSUS
From our brief theoretical discussion, it is clear that researchers who use education data must consider both the level
of error in the recording of education and, in a regression context, the correlation between that error and other covariates. We

Black, Sanders, and Taylor: Measurement of Higher Education

547

examine these issues with Decennial Census data by examining
Census reports attached to the NSCG. Later in the article we
return to two remaining concerns: Is there correlation between
errors in the measurement of education and the error term of
the regression? And, for cases in which two measures of education are available, is the process that generates measurement
error likely to generate error that is correlated across the two
measures?
The Decennial Census is an important data source for social
scientists. The Decennial Census affords researchers extremely
large samples, which is important when examining regional differences or studying minorities. A second valuable data source,
which we discuss later, is the CPS March Supplement.This data
source provides annual data on earnings and income of a cross
section of about 60,000 households.The March Supplement has
been collected since 1962 and allows researchers to examine a
relatively long time series of responses.
Information about education of respondents is quite limited
in the Decennial Census and CPS. Table 1 reproduces the questions the surveys use to measure education,as well as those used
in the NSCG. The Census, which is a mail survey, relies on
a single question to measure educational attainment. Whereas
educational attainment is straightforward for those who have
completed a high school degree or less, the measurement of the
college educated is clearly more dif cult, as evidenced by the
Census Bureau’s attempt to help respondents by offering examples of the degrees in each category. The Decennial Census and
post-1991 CPS questions are very similar. (Prior to 1992 the
CPS collected a measure similar to the 1980 Census, measuring the highest grade completed. This change does not appear
to have drastically changed measures of schooling; see Frazis
and Stewart 1999; Jaeger 1997.) In contrast to the Decennial
Census, however, the CPS is conducted with trained interviewers who can ask follow-up questions. Because respondents are
reinterviewed repeatedly, interviewers can compare previous
responses to the current one and seek clari cation when necessary. In addition,if a person is unusually young to have obtained
a reported education, the interviewer can seek clari cation.
For the NSCG the NSF and Census Bureau were particularly
concerned about the respondents’ education and devoted much
effort to ensuring the accuracy of the education responses. The
survey asked detailed information about the college or university from which respondents graduated, the type of degree, and
the respondents’ major and minor  elds of study. Any individual having an advanced degree but no bachelor’s degree is included in the NSCG sample frame if they indicated that they
had the advanced degree on their Census forms. In what follows, we compare the education report from the Census to the
educational attainment of the respondent, as of April 1990, according to the NSCG. Finally, notice that the sample design
excludes anyone with a 4-year degree who incorrectly reported
they did not have a college degree on their Decennial Census
form.

data attached to the 1993 NSCG. The NSF and Census Bureau conducted the NSCG based on the 1990 Decennial Census
Long Form sampling frame, with the sample limited to those
with at least a baccalaureate degree and those who were aged
72 or younger as of April 1, 1990. The Census Bureau drew a
strati ed sample of 214,643 individuals from the approximate
4,728,000 eligible population (one in six Census respondents
 ll out the Long Form). The Bureau  rst contacted the respondents with a mail survey and next attempted a telephone interview for those not responding to the mail survey. Respondents
who did not respond to either the mail or telephone interviews
were then contacted for an in-person interview.
Panel A of Table 2 provides statistics concerning the disposition of the interviews. Because the respondents for the 1993
NSCG survey were drawn from the 1990 Census sampling
frame, a few—2.2% of the sample—had emigrated from the
United States, died, or were institutionalized and were hence
out of the survey’s scope. A small number of respondents (less
than .1%) were over 75 years old and also out of scope. About
22% of the sample declined participation. Fully 6.7% of those
who claimed to have at least a 4-year degree did not, in fact,
have a degree, a  rst indication of substantial measurement error in the Census education reports.
The Census Bureau imputes missing values, and the responses in Panel A include data that are imputed. An analysis of the imputed data, however, suggests extremely high error
rates. For instance, among individuals who are imputed to have
a bachelor’s degree in the 1990 Census, only 16% report having a bachelor’s degree in the NSCG; see Black, Sanders, and
Taylor (2003) for details. Thus, in the remainder of the article
we use only nonimputed responses from the Census.
Substantial disagreement between the NSCG and Census reports remains even when we eliminate imputed data. In Panel B
of Table 2, we examine the rate of disagreement between the
NSCG reports and the corresponding nonimputed Census reports. Of those reporting bachelor’s degrees in the 1990 Census, only 91.3% also reported having bachelor’s degrees in the
NSCG. Similarly, only 87.4% of those reporting a master’s degree and 82.3% of those reporting a doctorate in the Census do
indeed have these degrees. Among those incorrectly reporting
a doctoral degree, the modal report is a professional degree, as
many MD’s and JD’s mistakenly classify their degree as doctoral; 49% of respondents who are coded as “doctoral” in the
Census but “professional” in the NSCG list an occupation of
either physician or lawyer. We also notice some “degree creep,”
a propensity of those with bachelor’s degrees to report a master’s and those with master’s degrees to report a professional
degree or doctorate. The most striking  nding in Table 2 is that
only 66.4% of those reporting a professional degree in the Census report having a professional degree in the NSCG, and fully
17% of these respondents have no 4-year college degree at all.

3.1 The Level of Measurement Error in the
Decennial Census

Given that gender, race, and ethnicity are common covariates in regressions, our  rst concern is whether measurement
error differs systematically across these demographic groups.
In Table 3 we provide a breakdown by gender, race, and ethnicity. With one notable exception, professional degrees, the rates

In this section we focus on the accuracy of measures of educational attainment in the 1990 Census by examining Census

3.2 Correlation of Measurement Error in Education and
Demographic Characteristics

548

Journal of the American Statistical Association, September 2003
Table 1. Education Questionaire of the 1990 Census and Current Population Survey
Census Question
How much school has this person COMPLETED? Fill ONE circle for the highest level completed or degree RECEIVED. If
currently enrolled, mark the level of previous grade attended or highest degree received.
± Associate degree in college—occupational program
± Associate degree in college—academic program
± Bachelor’s degree (for example: BA, AB, BS)
± Master’s degree (for example: MA, MS, M.Eng., M.Ed., MSW, MBA)
± Professional school degree (for example: MD, DDS, DVM, LLB, JD)
± doctorate degree (for example: Ph.D., Ed.D.)
CPS Questions
What is the highest level of school (name/you) (has/have) completed or the highest degree (name/you) (has/have) received?
± Associate degree in college occupational/vocational program
± Associate degree in college academic program
± Bachelor’s degree (for example: BA, AB, BS)
± Master’s degree (for example: MA, MS, M.Eng., M.Ed., MSW, MBA)
± Professional school degree (for example: MD, DDS, DVM, LLB, JD)
± Doctorate degree (for example: Ph.D., Ed.D.)
Last month I was told that (name’s/your) education level was (level); however, this month you are reporting that the
education level is lower (level). Which one is correct?
You reported that (name’s/your) education level is the same or higher than ((that of a) master’s degree/(that of a) bachelor’s
degree/college level) even though (you/he/she) (are/is) only (age) years old. Is that correct?
NSCG Questions
a. From which school did you receive this degree?
(School Name)
(City/Town)
(State/Foreign Country)
b. In what month and year was this degree awarded?
c. What type of degree did you receive? Mark one.
¤ Bachelor’s
¤ Master’s (includes MBA)
¤ Doctorate
¤ Other professional degree (e.g., JD, LLB, Th.D., MD, DDS, etc.)
¤ Other specify
d. Using the Education codes, select the relevant degree  eld code(s) and title(s).
Major Field:
CODE:

Table 2. 1993 National Survey of College Graduates
Panel A. Disposition of sample by Census education report
Professional
Bachelor’s
Master’s
degree

Disposition
Completed survey
No 4-year degree
Over 75 (out of scope)
Emigrated (out of scope)
Deceased (out of scope)
Institutionalized (out of scope)
Nonparticipant, refused, ill, or incomplete
N

NSCG report
Bachelor’s
Master’s
Professional
Doctorate
No degree
Total

Doctorate

Total

91;279
10;150
126
1;139
1;454
98
30;551

38;589
1;792
47
591
567
34
9;673

10;996
2;040
29
157
267
18
4;239

8;064
337
9
245
119
9
2;024

148;928
14;319
211
2;132
2;407
159
46;487

134;797

51;293

17;746

10;807

214;643

Panel B. Rate of disagreement, nonimputed Census
Census report (%)
Bachelor’s
Master’s
Professional

Doctorate

91:3
1 :0
:3
:1
7:4

9:3
87:4
1:0
:3
2:0

8:7
5:0
66:4
2:9
17:0

2:5
6:0
6:9
82:3
2:3

100:0

100:0

100:0

100:0

NOTE: Authors’ calculations, National Survey of College Graduates. Data in Panel A include imputed Census data. In Panel B sample is weighted to re ect strati ed sampling, but contains no
imputed data or respondents who did not complete the NSCG survey.

Black, Sanders, and Taylor: Measurement of Higher Education

549

Table 3. Gender, Race, and Ethnicity Difference in Agreement of Education Reports
Men (%)
Census report

Women (%)
Census report

NSCG report

BA

MA

Prof.

Ph.D.

BA

MA

Prof.

Ph.D.

Bachelor’s
Master’s
Professional
Doctorate
No degree

91:2
1 :0
:3
:1
7 :4

9 :8
86:1
1 :2
:4
2 :5

7 :6
5 :5
77:4
3 :6
5 :8

2:4
5:4
7:5
82:8
1:9

91:5
:8
:2
:1
7:4

8:7
88:8
:74
:2
1:5

11:0
4:1
43:8
1:2
39:8

2:7
7:6
5:1
81:2
3:4

100:0

100:0

100:0

100:0

100:0

100:0

100:0

Total

NSCG report

BA

Ph.D.

BA

Black (%)
Census report
MA
Prof.

Bachelor’s
Master’s
Professional
Doctorate
No degree

92:5
:8
:2
:1
6 :4

8 :8
88:4
:9
:3
1 :6

7 :8
5 :0
67:9
2 :7
16:7

2:4
5:4
6:9
83:4
1:9

85:0
1:3
:4
:1
13:2

11:3
83:7
1:0
:5
3:5

12:0
5:0
52:9
2:3
27:8

3:5
9:3
7:6
73:9
5:7

100:0

100:0

100:0

100:0

100:0

100:0

100:0

100:0

Total

White, not Hispanic (%)
Census report
MA
Prof.

100:0

Hispanic, not black (%)
Census report

Ph.D.

Asian (%)
Census report

NSCG report

BA

MA

Prof.

Ph.D.

BA

MA

Prof.

Bachelor’s
Master’s
Professional
Doctorate
No degree

80:7
1 :7
:4
:2
17:0

12:8
76:7
1 :2
1 :0
8 :3

14:1
5 :9
50:7
5 :3
24:0

3:0
12:0
10:1
69:8
5:2

83:2
2:0
:8
:1
13:9

13:7
80:3
1:4
:6
4:0

16:6
5:3
66:6
3:8
7:7

3:6
7:5
5:6
79:8
3:5

100:0

100:0

100:0

100:0

100:0

100:0

100:0

100:0

Total

Ph.D.

Native American (%)
Census report
NSCG report

BA

MA

Prof.

Ph.D.

Bachelor’s
Master’s
Professional
Doctorate
No degree

85:6
1:7
:5
:2
12:1

13:5
80:4
:7
1:2
4:2

8:0
7:7
46:1
4:0
34:2

6 :2
28:8
2 :2
62:8
:0

100:0

100:0

100:0

100:0

Total

NOTE: Authors’ calculations, National Survey of College Graduates. There are 92,048 male and 65,507 female observations. There are 114,512 whites, 14,329 blacks, 9,649 Hispanics, 15,608
Asians, and 1,449 Native Americans. Sample weighted to re ect strati ed sampling, which excludes observations with imputed education, imputed sex, or imputed race or ethnicity.

of agreement in the Census and NSCG reports are similar for
males and females. For doctoral degrees there is no statistically
signi cant difference in the rate of agreement between men and
women. For bachelor’s and master’s degrees, we reject the hypotheses that rates of agreement are the same for each of these
categories (even at a .01% signi cance level), but the differences are quite small. There is, however, a substantial gender
difference in the agreement rates for the professional degrees.
Only 43.8% of the female respondents who indicated in the
Census that they had a professional degree did so in the NSCG.
The respondents’ occupations provide some insight into the
gender-related difference in measurement error among those reporting a professional degree. Among women whose Census
report is a professional degree but whose NSCG report indicates no 4-year college degree, 52.2% are employed in healthrelated  elds other than physician or other health diagnosing
occupations that require advanced degrees. These  elds include
nursing, therapist, health technologist and technicians (such as
clinical laboratory assistants and practical nurses), and health

service occupations (such as nursing aides, orderlies, and attendants). Another 5.4% are hairdressers and cosmetologists. Generally, these occupations are professions that require some form
of certi cation. We conjecture that some respondents interpret
these certi cations as “professional degrees.” As many of these
occupations are female dominated, women have much higher
rates than men of incorrectly reporting a professional degree.
We examine NSCG/Census education report agreement rates
for whites, blacks, Hispanics, Asians, and Native Americans
in the remaining portions of Table 3. In our work these are
mutually exclusive categories, as we code black Hispanics as
black, Asian Hispanics as Asian, and Native American Hispanics as Native American. Several features warrant mention. First,
all minority groups have lower rates of agreement than whites,
and differences are statistically signi cant at the 5% con dence
level, except for Asians with professional degrees. Second, Hispanics have lower rates of agreement than blacks, although the
differences are statistically signi cant only for the bachelor’s
and master’s degrees. Third, for bachelor’s and master’s degrees, Asians have signi cantly less agreement than blacks, but

550

Journal of the American Statistical Association, September 2003

for professional and doctoral degrees, Asians have signi cantly
more agreement than blacks.
In a regression model these  ndings about racial and ethnicity differences in agreement rates continue to hold even
when we control for differences in age, gender, and other demographic covariates. (See Black et al. 2003 for estimates
and more detail.) Interestingly, when we also control for selfreported English skills, whether the respondent speaks English
at home, whether the respondent is a U.S. citizen, and, if an immigrant, the year of immigration, there is a dramatic reduction
in the magnitude of the coef cient for Hispanics, and we  nd
that Asians are actually less likely to make errors than whites.
Although this is suggestive that language skills may play an important role in the measurement error, it may simply re ect that
immigrants often have a lack of familiarity with the U.S. higher
education system.
4. MEASUREMENT ERROR IN THE CPS: DOES
PERSONAL CONTACT LIMIT ERRORS?
Although the questions asked of respondents are virtually the
same in the Decennial Census and CPS surveys, there is an important difference between the two: The CPS survey attempts to
interview  rst-time respondents in person. (When face-to-face
interviews are not possible, telephone interviews are used.) Respondents have the ability to ask questions of the interviewer
if the education question confuses them, and similarly the interviewer can seek clari cation. In this section we ask if this
personal contact reduces the measurement error.
There are two immediate problems in addressing the degree
of measurement error in higher education in the CPS. First,
the CPS offers relatively small samples of college graduates
(as the CPS surveys are much smaller than the Decennial Census or NSCG). Second, and more important, there is no direct
method of validating the CPS education responses. To address
the  rst problem, we pool data from 1993 to 1996 March CPS.
We select the March CPS, which is often used by social scientists because it contains the Annual Demographic Supplement,
which includes measures of annual earnings. For this exercise
we exclude the 1992 survey because Frazis and Stewart (1999)
documented that responses of the new education question  rst
 elded in early 1992 resulted in a distribution of responses that
differs from that found in later months—an outcome that they
ascribed to interviewer inexperience in working with the new
question. CPS households are in the sample for four months,
rotated out of the sample for 8 months, and then are rotated
back into the sample for another 4 months; see the U.S. Bureau
of Labor Statistics and U.S. Census Bureau (2000) for details.
Thus, respondents who are in the sample in March of 1993 may
reappear in March of 1994. To obtain independentobservations,
we limit our sample to those respondents who are in their  rst
4-month rotation. To ensure comparability with our other estimates, we again limit the sample to respondents aged 25–55.
As we are unable to compare the CPS responses directly to
an NSCG-like response, we rely instead on how the distributions of responses line up across three different measures of
education—the Census education measure in the NSCG, the
NSCG measure, and the CPS measure. In Panel A of Table 4
we present the distribution of responses for the Census measure
from the NSCG, the NSCG education measure, and the 1993

through 1996 CPS for individuals who report a bachelor’s degree or higher. Not surprisingly, given our large samples, using
a chi-square test we reject the hypothesis that any two of the
distributions are the same, at a signi cance level in excess of
.001. Importantly, the CPS reports a lower level of professional
degrees than the Census, suggesting that the CPS reduces the
high levels of false reports of professional degrees in the Census.
As discussed previously, we can  nd useful clues about the
nature of misreports of the professional degree by examining
the occupational distribution of respondents reporting these degrees. Panel B of Table 4 provides the occupation distribution
for individuals who are reported to hold a professional degree.
The  rst two columns are individuals who reported a professional degree in the Census report (from the NSCG sample), in
the next two columns we use individuals identi ed as holding a
professional degree in the CPS, and in the last two columns we
rely on the NSCG reports themselves. For occupations such as
lawyer or physician, which do require a professional degree, the
men’s occupation distribution is found to be quite similar when
we use the Census reports and the CPS, but the NSCG indicates
a substantially higher rate of employment in these occupations.
These  ndings are consistent with the view that, for men, the
level of measurement error in the professional degree report is
similar in the Census and the CPS. In contrast, for women, the
CPS reports a substantially higher level of employment in occupations that likely require a professional degree. This suggests that the face-to-face interviews used in the CPS substantially reduce the measurement error for women. Comparing the
NSCG and CPS reports for women, however, suggests that considerable measurement error remains in the CPS; there is a 17
percentage point difference in reported employment rates in occupations that require a professional degree. Both the CPS and
the Census appear to contain less measurement error for men
than for women, though there is substantial measurement error
for both genders.
We also examined occupations for which the respondent was
unlikely to be a professional degree holder. Although our categorizations are inherently subjective, differences in the distributions across samples are informative. Three observations are
in order. First, the CPS does a relatively good job of identifying
nurses (RN’s and LPN’s) as not holding a professional degree.
Second, among men, both the CPS and the NSCG data record
substantially lower rates of employment than does the Census
in occupations that are unlikely to have a professional degree.
Third, the NSCG itself likely contains some measurement error; among individuals who report a professional degree, 8% of
women and 3% of men are employed in occupations in which
the respondent is unlikely to hold a professional degree.
5. CONSEQUENCES OF MEASUREMENT ERROR
IN EDUCATION
As discussed in Section 2, a key issue concerning measurement error in a regressor is whether this measurement error is
correlated with regression residuals. For example, the assumption that the measurement error is uncorrelated with the regression residuals is used in establishing the familiar attenuation
bias result and is necessary for the applicationof models of nonclassical measurement error such as Kane et al. (1999), Black
et al. (2000), or Hyslop and Imbens (2001).

Black, Sanders, and Taylor: Measurement of Higher Education

551

Table 4. Comparison of Responses in the Census, CPS, and NSCG
Panel A. Distribution of degree, conditional on reporting at least a bachelor’s degree
NSCG, Census report
NSCG report
1993–1996 March CPS
Degree
Bachelor’s
Master’s
Professional
Ph.D.
N

Men

Women

Men

Women

Men

Women

63:6
21:7
9:9
4 :8
125,889

69:7
22:8
5:5
1:9
88,754

64:0
22:1
9 :0
5 :0
87,423

71:2
23:9
3 :1
1 :9
60,889

65:5
21:8
7 :6
5 :1
16,552

70:5
23:3
3:9
2:4
15,443

Panel B. Occupational distribution of respondents reporting a professional degree
Census report
of the NSCG
(%)
Occupation
Occupations for which professional
degree is likely:
Lawyers
Physicians
Dentists
Veterinarians
Others likely to hold professional degree
Total percentage
Occupations for which professional
degree is unlikely:
Registered and licensed practical nurses
Pharmacists
Teachers, elementary or secondary school
Hairdressers and cosmetologists
Others unlikely to hold professional degree
Total percentage
Observations

1993–1996
March CPS report
(%)

NSCG report
(%)

Men

Women

Men

Women

Men

Women

32:6
25:2
7:7
1:9
4:4
71:8

23:2
14:2
1 :7
1 :5
2 :3
42:9

33:8
25:8
6:0
1:1
3:6
70:3

29:4
15:8
2:8
1:5
3:2
52:7

37:6
26:0
8:9
2:4
5:2
80:1

39:7
21:4
2 :4
2 :9
3 :7
70:1

1:0
1:8
:6
:1
:9
4:4

17:9
1 :6
2 :2
1 :9
3 :8
27:4

:3
:8
:8
:1
:3
2:3

3:1
1:9
4:6
:0
1:0
10:6

:4
1:0
:6
:0
:9
2:9

2 :0
1 :3
2 :6
:1
2 :4
8 :4

8,992

4,303

1,286

603

5,700

2,073

NOTE: Authors’ calculations, 1993 NSCG and 1993–1996 March CPS. The March CPS sample includes only respondents from the  rst four rotations to ensure independent observations across
years. All respondents are aged 25–55, inclusive. Imputed data are not included in the calculations. In Panel B, “Others likely to hold professional degree” are medical scientists, optometrists,
podiatrists, health diagnosing practitioners not elsewhere classi ed, law teachers, and judges, whereas “Others unlikely to hold professional degree” are legal assistants, secretaries, and nursing
aides, orderlies, and attendants.

Results from the previous section suggest that this key assumption may be invalid for the case of education as an explanatory variable in earnings regressions, which implies the
possibility of serious biases in the estimated parameters of most
earnings equations. To see if misreports substantially bias estimated coef cients, we estimate a conventional earnings equation using NSCG data, with a dependent variable logarithm of
weekly earnings and independent variables that include such
earnings-related characteristics as age, race, ethnicity, and education as given by the Census report or, alternatively, as collected speci cally by the NSCG. We use the NSCG’s Census annual earnings report and limit our analysis to those who
report wage and salary workers’ compensation as their major source of earnings, eliminating the unincorporated selfemployed. (Because the NSCG Census earnings measure is
truncated at $999,999 rather than the $150,000 cutoff released
from the Census, the rate of top coding in the NSCG is .03%;
the rate would increase to 1.27% if the $150,000 cutoff were
used.) As is common practice when using the Census earnings
reports, we divide the annual earnings by the weeks worked to
obtain average weekly earnings. We use no imputed earnings or
weeks worked measure in the creation of the weekly earnings
variables. For regressors we use the respondent’s degree (bachelor’s degree is the excluded category), indicators for whether
the respondents is black, Hispanic, Asian, or Native American
(white is the excluded category), and a vector of dummy vari-

ables for age, which we do not report. We estimate separate
equations for men and women.
In Panel A of Table 5 we report three sets of estimates for
each sex. Columns (1) and (4) report results in which we use
nonimputed Census reports for the entire NSCG sample. These
results are indicative of what one would generally  nd using
Census data. The other columns restrict the sample to cases in
which we have both a Census report and an NSCG report. This
subsample of the NSCG drops respondents who were found not
to have a 4-year degree (as well as others who failed to complete the NSCG). By comparing results in columns (1) and (4)
with results in columns (3) and (6), we can see how inferences change when we rely on NSCG reports rather than the
less accurate Census data. For both men and women, the return to a professional degree (relative to a bachelor’s degree)
is underestimated with Census data. Inferences regarding race
and ethnicity earnings gaps also differ. For men the absolute
value of estimated coef cients decline in magnitude by 12% for
blacks, 27% for Native Americans, 36% for Asians, and 66%
for Hispanics. Among women, with the exception of Native
Americans, well-educated minority women are found to earn
more than comparable white women, but the Census understates those differences. For instance, the estimated coef cients
increase in magnitude by 18% for blacks, 66% for Asians, and
85% for Hispanics.
Results in columns (2) and (5) use Census reports, but systematically exclude cases for which individuals are found to

552

Journal of the American Statistical Association, September 2003
Table 5. Earnings Equation for Workers Aged 25–55 (NSCG), Coef cients Multiplied by 1,000
Panel A. Earnings equation estimates
Men
Sample for which
both reports are available:

Entire
sample:
Census
report
(1)
Master’s
Professional degree
Ph.D.
Worker is black
Worker is non-black Hispanic
Worker is Asian
Worker is Native American
N

75( 8)
427(14)
150(11)
¡220(10)
¡193(12)
¡159(10)
¡298(28)
72,031

Census
report
(2)

NSCG
report
(3)

Entire
sample:
Census
report
(4)

71( 8)
448(17)
149(12)
¡198(11)
¡120(13)
¡118(11)
¡242(31)

70( 8)
506(16)
159(12)
¡197(11)
¡116(13)
¡117(11)
¡235(31)

258(10)
344(20)
441(20)
124( 9)
10(13)
14(12)
¡50(36)

53,680

53,680

46,883

Panel B. BBDR decompositions using NSCG sample

Men
Master’s degree
Professional degree
Ph.D.
N D 53,680

Women
Master’s degree
Professional degree
Ph.D.
N D 35,094

Women
Sample for which
both reports are available:
Census
report
(5)

NSCG
report
(6)

264(11)
582(25)
466(22)
149(10)
61(16)
38(14)
¡27(48)

266(11)
627(26)
475(22)
152(10)
67(16)
40(14)
¡24(48)

35,094

35,094

Difference from
correlation of
measurement error
and regression error
[.X 0M X M /¡1 X 0M e]
(3)

Difference in
coef cients
[bM ¡ b C ]
(1)

Difference from
measurement error
[b0UM b C ]
(2)

1
¡58
¡11

¡4
¡85
10

5
27
¡20

¡2
¡44
¡8

¡25
¡125
¡23

23
80
15

NOTE: Authors’ calculations, 1993 NSCG. OLS estimates are reported. Dependent variable is natural logarithm of average weekly earnings constructed as wage and salary earnings divided by
weeks worked. The holdout group in each regression is “bachelor’s,” so coef cients are estimated returns relative to a bachelor’s degree (multiplied by 1,000). The holdout group for race/ethnicity
is “white.” Additional controls in the regressions include dummy variables for each age. Robust standard errors reported in parentheses; sample weighted to re ect strati ed sampling. The sample
excludes any respondent with imputed values for education, age, race, ethnicity, earnings, and sex.

have no bachelor’s degree. By comparing column (2) with column (3) for men, and column (5) with column (6) for women,
we notice that even in this subsample—in which all individuals hold at least a bachelor’s degree—some differences remain
in inferences one draws using the Census and NSCG reports.
If we are willing to take the strong stand that the NSCG report
is correct, we can adapt a decomposition that Bound, Brown,
Duncan, and Rodgers (1994) (BBDR) used when working with
validationdata. Consider the linear model y D X¯ C ", where X
is the vector of (correctly measured) variables. Let X M D X C u
be the mismeasured variables, where u is the measurement error. If the correctly measured data were observed, the appropriate OLS estimator would be bC D .X0 X/¡1 X0 y. Without correctly measured data researchers typically use the estimator
bM D .X0M XM /¡1 X0M y. BBDR showed that the difference between the two estimators can be decomposed as
bM ¡ bC D b0UM bC C .X 0M XM /¡1 X0M e;
where bUM are the coef cient estimators from the regression of
u on XM and e D y ¡ Xb C . The term b0UM bC estimates the bias
that arises from measurement error in the explanatory variables;
the term .X 0M XM /¡1 X0M e estimates the bias that arises from the
correlation of the measurement error with the regression error.
If the measurement error and regression error are uncorrelated,

the second term disappears in the probability limit. BBDR reported that the second term is usually quite small in validation
data of the Panel Study of Income Dynamics. As we will show,
however, this second term can be substantial in our context.
Column (1) of Panel B in Table 5 reports the difference between the estimates using the Census education report in the
NSCG sample [columns (2) and (5)] and the corresponding
estimates using the NSCG education reports themselves from
Panel A [columns (3) and (6)]. There are notable differences
between estimates of bM and bC , particularly in returns to the
professional degree. More important, the BBDR decomposition
suggests the presence of both forms of bias, bias due to the measurement error in the explanatory variables and bias due to the
correlation between the measurement error and the regression
error.
Interestingly, in this well-educated sample (individuals who
report a bachelor’s degree or higher on the NSCG), the two
forms of bias in the BBDR decompositiontend to offset one another, most visibly for women who report a professional degree.
The direct consequence of misreporting a professional degree
is to substantially reduce the estimated return to a professional
degree as women with other degrees generally earn less than
women who truly have professional degrees. Offsetting this,
however, is that for any true level of education, women who
are mistakenly recorded as having a professional degree tend to

Black, Sanders, and Taylor: Measurement of Higher Education

have higher earnings than those who have their level of education recorded correctly. For example, women with a bachelor’s
degree in the NSCG who incorrectly report a professional degree in the Census earn on average $617 a week, whereas the
mean earnings for all women who report a bachelor’s degree
in the NSCG is $525 a week. More generally, conditional on
their true (NSCG-measured) education level, women who incorrectly report having a professional degree in the Census earn
about .088 log points more per week than otherwise comparable
women.
Of course, the validity of the BBDR decomposition exercise
rests on the assumption that the NSCG reports are indeed the
correct reports. If we treat both the NSCG and the Census education measures as having measurement error, then the relatively high earnings of women who claim a professional degree
in the Census and a bachelor’s degree in the NSCG could simply re ect that the NSCG has incorrectly coded some individuals who have professional degrees as having just a bachelor’s
degree. Evidence indicates, however, that this simple mixing
story is at best an incomplete explanation. For example, men
who reported having a professional degree in the Census but a
master’s degree in the NSCG earn $885 a week, compared to
$1,029 a week for all men who reported having a master’s degree in the NSCG, and $1,701 a week for all men who reported
having a professional degree in the Census. This pattern is dif cult to reconcile unless the measurement error in education is
correlated with the regression error.
A number of recent articles used samples of siblings or
twins to estimate the returns to schooling, including Ashenfelter and Rouse (1998) and Ashenfelter and Krueger (1994).
(See Card 1998 for a review.) These articles used differences of
within-twin or within-siblingeducation to identify the returns to
schooling. Because differencing data exacerbate measurement
error, these articles used reports from respondents on their siblings’ education as an instrument for the measurement error. If
the measurement error is correlated with the regression error (as
suggested in Table 5), the IV estimates may be highly biased,
a point that Bound and Solon (1999), Bronars and Oettinger
(2000), and Hyslop and Imbens (2001) also raised.
More generally, our  ndings that measurement error is correlated with the respondent’s education itself, as well with other
covariates often used in a regression, and that the measurement error is correlated with the regression residual, imply
that many suggestions for dealing with measurement error will
not prove helpful when working with these data. Hausman,
Ichimura, Newey, and Powell (1991), Hausman, Newey, and
Powell (1995), Lewbel (1998), Wall and Amemiya (2000), and
Schennach (2000) examined nonlinear models with measurement error in which the distribution of the measurement error
is unknown. As Schennach (2000) noted, however, nonlinearity
in these models requires that the measurement error be uncorrelated with the true value of the variable of interest and other
covariates, which appears untrue in the Census data.
6. THE ISSUE OF NONRESPONSE
Although we have taken care in this article to examine measurement error in the Census, we have done little to study the
closely related issue of nonresponse. Given that the questionnaire announced on the front page, “National Survey of College Graduates,” we would not be surprised if the relatively

553

high nonresponse rate was due in part to disproportionately high
nonresponse by individuals who are, in fact, not college graduates. To get a rough idea about the prevalence of such behavior,
we undertake a simple back-of-the-envelope calculation: We
take the strong stand that, conditional on whether one has a degree or not, the mean earnings are the same for nonresponders
as for responders. Letting ¹NR be the mean earnings for nonresponders, ¹R;D be the mean earnings of responders that have
a degree, and ¹R;N be the mean earnings of responders who do
not have degrees, we have ¹NR D µ¹R;N C .1 ¡ µ /¹R;D , where
µ is the fraction of nonresponders who do not have degrees.
Solving this equation for µ , using the sample employed in the
Table 5 analyses, we  nd that nearly 35% of the nonresponding
males and over 23% of the nonresponding females do not have
college degrees. This suggests that ignoring the nonresponders
causes us to understate the number of women without degrees
by nearly 57% and the number of men by nearly 134%.
Of course, our back-of-the-envelope estimates rely on extremely strong assumptions and may be seriously biased. They
indicate to us, however, that the estimates of the level of measurement error derived previously may be quite conservative,
an issue we explore in greater detail in Black et al. (2003). Although nonresponse in the NSCG in general seems likely to
cause us to underestimate the rate of education mismeasure in
the Census, there is a factor that partially offsets this underestimate. Evidence presented by Burns (1997) indicates that among
individuals who were deemed out of scope for the NSCG because they had no bachelor’s degree, as many as 1 in 5, in fact,
do have a bachelor’s degree. Some of these individuals may indeed have a correct Census education report, leading us to overestimate the extent of disagreement between the Census and
NSCG reports.
7. CONCLUDING REMARKS
Our work documents that measurement error in the reporting of higher education is a very serious problem in Census
data. Not only are error rates high, but errors are systematic in
nature (e.g., the presence of “degree creep”) and vary widely
by demographic group. As an especially impressive example,
we estimate that well over half of women who report that they
have a professional degree in the the Census, in fact, have no
such degree. In general, blacks, Hispanics, Asians, and Native
Americans are much more likely to misreport their educational
attainment than whites. A substantial portion of these misreported data—particularly for Hispanics and Asians—appears
to be related to language problems or a misunderstanding of
the U.S. degree classi cation. We also  nd some evidence
that, despite the similarity in the structure of the questions, the
CPS responses contain less measurement error than the Census.
Nonetheless, substantial measurement error appears to remain
in the CPS, particularly among respondents reporting a professional degree.
We  nd that misreports in education lead to incorrect inferences regarding the return to higher education. For example,
using Census data, one would greatly underestimate the return
to a professional degree (relative to having a bachelor’s degree
only), especially among women. We  nd also that misreports in
education produce biases in estimating racial and ethnic earnings differences among the highly educated. For example, for

554

Journal of the American Statistical Association, September 2003

both Hispanic men and Asian men, we  nd that measurement
error in the Census results in estimated earnings gaps relative
to white men that are severely biased away from 0. Clearly, researchers who study the earnings of the highly educated using
Census and CPS data should be concerned about being misled
by inferences that do not account for the presence of measurement error.
[Received April 2001. Revised May 2003.]

REFERENCES
Altonji, J., and Blank, R. (1999), “Gender and Race in the Labor Market,” in
Handbook of Labor Economics (Vol. 3), eds. O. Ashenfelter and D. Card,
New York: Elsevier Science.
Ashenfelter, O., and Krueger, A. (1994), “Estimates of the Economic Return to
Schooling From a New Sample of Twins,” American Economic Review, 84,
1157–1173.
Ashenfelter, O., and Rouse, C. (1998), “Income, Schooling, and Ability: Evidence From a New Sample of Identical Twins,” Quarterly Journal of Economics, 113, 253–284.
Black, D., Berger, M., and Scott, F. (2000), “Bounding Parameter Estimates
With Nonclassical Measurement Error,” Journal of the American Statistical
Association, 95, 739–748.
Black, D., Sanders, S., and Taylor, L (2003), “Causes and Consequences of
Mismeasurement of Education in the Census,” Working Paper, Syracuse University.
Bollinger, C. (1996), “Bounding Mean Regression When a Binary Regressor Is
Mismeasured,” Journal of Econometrics, 73, 387–399.
Bound, J., Brown, C., Duncan, G., and Rodger, W. (1994), “Evidence on the
Validity of Cross-Sectional and Longitudinal Labor Market Data,” Journal of
Labor Economics, 3, 345–368.
Bound, J., and Solon, G. (1999), “Double Trouble: On the Value of TwinsBased Estimation of the Returns to Schooling,” Economics of Education, 18,
169–182.

Bronars, S., and Oettinger, G. (2000), “Reassessing Twins-Based Estimates of
the Returns to Schooling Using a Representative Sample of Siblings,” unpublished manuscript, University of Texas at Austin.
Burns, G. (1997), “National Survey of College Graduates Follow-up Results
From the No Bachelor’s Degree Study,” unpublished manuscript, National
Science Foundation.
Card, D. (1998), “The Causal Effect of Education on Earnings,” in Handbook
of Labor Economics (Vol. 3), eds. O. Ashenfelter and D. Card, New York:
Elsevier Science.
Frazis, H., and Stewart, J. (1999), “Tracking the Returns to Education in the
1990’s: Bridging the Gap Between the New and Old Current Population Survey Education Items,” Journal of Human Resources, 34, 629–641.
Griliches, Z. (1986), “Economic Data Issues,” in Handbook of Econometrics
(Vol. 3), eds. Z. Griliches and M. Intriligator, Amsterdam: North-Holland.
Hausman, J., Ichimura, H., Newey, W., and Powel, J. (1991), “Measurement
Error in Polynomial Regression Models,” Journal of Econometrics, 50, 271–
295.
Hausman, J., Newey, W., and Powel, J. (1995), “Nonlinear Errors in Variables
Estimation of Some Engel Curves,” Journal of Econometrics, 65, 205–233.
Hyslop, D., and Imbens, G. (2001), “Bias From Classical and Other Forms of
Measurement Error,” Journal of Business & Economic Statistics, 19, 475–
481.
Jaeger, D. A. (1997), “Reconciling the Old and New Census Bureau Education
Questions: Recommendation for Researchers,” Journal of Business & Economic Statistics, 15, 300–309.
Kane, T., Rouse, C., and Staiger, D. (1999), “Estimating Returns to Schooling
When Schooling Is Misreported,” NBER Working Paper 7235, Cambridge,
MA: National Bureau of Economic Research.
Lewbel, A. (1998), “Semiparametric Latent Variable Model Estimation With
Endogenous or Mismeasured Regressors,” Econometrica, 66, 105–121.
Schennach, S. (2000), “Estimation of Nonlinear Models With Measurement
Error,” unpublished paper, University of Chicago.
U.S. Bureau of Labor Statistics and U.S. Census Bureau (2000), “Current Population Survey,” Technical Paper 63.
Wall, M., and Amemiya, Y. (2000), “Estimation of Polynomial Structural Equations Models,” Journal of the American Statistical Association, 95, 929–940.

