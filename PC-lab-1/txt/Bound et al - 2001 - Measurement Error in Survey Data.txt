Chapter 59
MEASUREMENT ERROR IN SURVEY DATA

JOHN BOUND' University of Michigan and NBER

CHARLES BROWN University of Michigan and NBER

NANCY MATHIOWETZ
University of Maryland
Contents
Abstract Keywords 1 Introduction 2 The impact of measurement error on parameter estimates
2.1 Special cases 2.2 General results linear model 2.3 Differential measurement error an example 2.4 Bounding parameter estimates 2.5 Contaminated and corrupted data 2.6 Measurement error in categorical variables 2.7 Nonlinear models
3 Correcting for measurement error
3.1 Instrumental variables in the bivariate linear model 3.2 Multivariate linear model 3.3 Nonlinear models 3.4 The contribution of validation data
4 Approaches to the assessment of measurement error 5 Measurement error and memory: findings from household-based surveys
5.1 Cognitive processes 5.2 Social desirability

3707 3707 3708 3710 3712 3715 3716 3721 3723 3724 3727 3728
3729
3733 3735 3737 3740 3743
3743
3745

* We are grateful to Joe Altonji, Dan Hamermesh, Jeff Wooldridge, Michael Baker, Gary Solon, Shinichi Sakata, participants at the conference for this volume and especially to Jim Heckman and Ed Leamer for extremely helpful comments on previous versions of this paper and to Mari Ellis for help with the preparation of the manuscript.
Handbook of Econometrics, Volume 5, Edited by J Heckman and E Leamer © 2001 Elsevier Science B V All rights reserved

3706

J Bound et a.

5.3 Essential survey conditions

3746

5.4 Applicability of findings to the measurement of economic phenomena

3747

6 Evidence on measurement error in survey reports of labor-related phenomena 3748

6.1 Earnings

3748

6.1 1 Annual earnings

3748

6.1 2 Monthly, weekly, and hourly earnings

3766

6.2 Transfer program income

3770

6.3 Assets

3779

6.4 Hours worked

3784

6.5 Unemployment

3791

6.5 1 Current labor force status, and transitions to and from unemployment

3792

6.5 2 Retrospective unemployment reports

3799

6.6 Industry and occupation

3802

6.7 Tenure, benefits, union coverage, size of establishment, and training

3805

6.8 Measurement error in household reports of health-related variables

3811

6.8 1 Health care utilization, health insurance, and expenditures

3811

6.8 2 Health conditions and health/functional status

3817

6.9 Education

3823

7 Conclusions

3830

References

3833

Ch 59: Measurement Error in Survey Data

3707

Abstract

Economists have devoted increasing attention to the magnitude and consequences of measurement error in their data Most discussions of measurement error are based on the "classical" assumption that errors in measuring a particular variable are uncorrelated with the true value of that variable, the true values of other variables in the model, and any errors in measuring those variables In this survey, we focus on both the importance of measurement error in standard survey-based economic variables and on the validity of the classical assumption.
We begin by summarizing the literature on biases due to measurement error, contrasting the classical assumption and the more general case We then argue that, while standard methods will not eliminate the bias when measurement errors are not classical, one can often use them to obtain bounds on this bias Validation studies allow us to assess the magnitude of measurement errors in survey data, and the validity of the classical assumption In principle, they provide an alternative strategy for reducing or eliminating the bias due to measurement error.
We then turn to the work of social psychologists and survey methodologists which identifies the conditions under which measurement error is likely to be important. While there are some important general findings on errors in measuring recall of discrete events, there is less direct guidance on continuous variables such as hourly wages or annual earnings.
Finally, we attempt to summarize the validation literature on specific variables: annual earnings, hourly wages, transfer income, assets, hours worked, unemployment, job characteristics like industry, occupation, and union status, health status, health expenditures, and education In addition to the magnitude of the errors, we also focus on the validity of the classical assumption Quite often, we find evidence that errors are negatively correlated with true values.
The usefulness of validation data in telling us about errors in survey measures can be enhanced if validation data is collected for a random portion of major surveys (rather than, as is usually the case, for a separate convenience sample for which validation data could be obtained relatively easily); if users are more actively involved in the design of validation studies; and if micro data from validation studies can be shared with researchers not involved in the original data collection.

Keywords
measurement error, validation studies, survey data, validity, reliability, retrospective recall, income, earnings, health, errors in variables, instrumental variables, attenuation
JEL classification:C1O, C33, C42, C81, JOO

3708

Bound et al

1 Introduction
Empirical work in economics depends crucially on the use of survey data The evidence we have, however, makes it clear that survey responses are not perfectly reliable Even such salient features of an individual's life as years of schooling seem to be reported with some error While economists have been aware of the errors in survey data for a long time, until recently most empirical studies tended to ignore it altogether. However, perhaps stimulated by increases in the complexity of the models we have been estimating, and in particular, with the increasing use of panel data that can seriously exacerbate the effect of measurement error on our estimates, economists have been paying an increasing amount of attention to measurement error
Most assessments of the consequences of measurement error and methods for correcting the biases it can cause have emphasized models that make strong and exceedingly convenient assumptions about the properties of the error Most frequently, measurement error in a given variable is assumed to be independent of the true level of that and all other variables in the model, measurement error in other variables, and the stochastic disturbance We will refer to such purely random measurement error as "classical" measurement error In some applications such as the case where the error is a sampling error in estimating a population mean these assumptions can be justified But in most micro data analyses using survey data, they reflect convenience rather than conviction.
From these assumptions comes much of the conventional wisdom about the effects of measurement error on estimates in linear models: (i) error in the dependent variable neither biases nor renders inconsistent the parameter estimates but simply reduces the efficiency of those estimates; (ii) error in the measurement of an independent variable produces downward-biased (attenuated) and inconsistent parameter estimates of its effect, while inadequately controlling for the confounding effects of this variable on the well measured variables; and (iii) the inclusion of other independent variables that are correlated with the mis-measured independent variable accentuates the downward bias 2.
In fact, these conclusions need to be qualified The bias introduced by measurement error depends both on the model under consideration (e g , whether it is linear) and on the joint distribution of the measurement error and all the variables in the model The

I Thus, for example, the volatility of earnings and consumption data have often been attributed measurement error lMaCurdy (1982), Abowd and Card (1987, 1989), Hall and Mishkin (1982), Shapiro (1982)l On the other hand a variety of authors have rationalized a dramatic drop in the magnitude of coefficient estimates associated with the move to fixed effects models in terms of measurement error in key variables and have used a variety of techniques to undo the presumed damage lFreeman (1984) and Card (1996) follow this kind of strategy when using fixed effect models to estimate union premia, Krueger and Summers (1988) do so when estimating industry premia, and Ashenfelter and Krueger (1994) do so when estimating educational premial. 2 The notion that fixed effect models tend to seriously accentuate the effect of measurement error on parameter estimates represents an important special case of this last point.

Ch 59: Measurement Error in Survey Data

3709

effect of measurement error can range from the simple attenuation described above to situations where (i) real effects are hidden; (ii) observed data exhibit relationships that are not present in the error free data; and (iii) even the signs of the estimated coefficients are reversed.
Standard methods for correcting for measurement error bias, such as instrumental variables estimation, are valid when errors are classical and the underlying model is linear, but not, in general, otherwise While statisticians and econometricians have been quite clear about the assumptions built into procedures they have developed to correct for measurement error, empirical economists have often relied on such procedures without giving much attention to the plausibility of the assumptions they are explicitly or implicitly making about the nature of measurement error Not only can standard fixes not solve the underlying problem, they can make things worsel
Twenty years ago, analysts would typically have ignored the possibility that the data they were using was measured with considerable error Rarely, if ever would such researchers acknowledge, let alone try to justify their tacit assumption that measurement error in the data they were using was negligible More recently, it has become quite common for analysts to correct for measurement error However, when doing so, researchers virtually always rely on the assumption that measurement error is of the classical type, usually with no justification at all If we are to be serious regarding measurement error in our data, we need to understand the relationship between the constructs that enter our models and the measures we use to proxy them This is a tall order However, even when this "gold standard" is unattainable it will often be possible to put some kind of plausible bounds on the extent and nature of the measurement error of key variables, and use these bounds to work out bounds for estimated parameters of interest.
In addition to providing some evidence about the magnitude of measurement errors, validation studies that compare survey responses to more accurate data such as payroll records permit one to determine whether measurement errors are indeed uncorrelated with other variables In principle though this possibility has been realized only incompletely in practice validation studies can provide more general information on the relationships among errors in measuring each variable, its true value, and the errors and true values in each of the other variables The research summarized in this chapter is based on direct observation of the measurement error properties of interview reports for a wide range of economic measures The evidence provides much information to challenge the conventional wisdom.
One general conclusion from the available validation evidence is that the possibility of non-classical measurement error should be taken much more seriously by those who analyze survey data, both in assessing the likely biases in analyses that take no account of measurement error and in devising procedures that "correct" for such error. A second result is that it is important to be at least as explicit about one's model of the errors in the data as about the relationship among the "true" variables that we seek to estimate Unless one is comfortable assuming that the classical assumptions apply, arguing informally based on that standard case may be dangerous, and writing out the

3710

J Bound et al.

alternative model that better describes one's data can often give real insight into the biases one faces and the appropriateness of traditional cures A third finding is that, all too often, validation studies are not as helpful to data analysts as they ought to be Even for the relatively simple goal of assessing the extent of measurement error in individual variables, the "extent" of the error is often not summarized in ways that are suggested by the simple models that guide our thinking Too few studies take the next step of relating errors in one variable to true values and errors in other variables We hope that by contrasting the information that is often provided with that which would be most helpful to analysts, we can increase the contribution made by future validation studies Given the difficulty of mounting a successful validation effort, maximizing the payoff from such efforts is important In addition to these general themes, we present a variable-by-variable summary of what is known about the accuracy of survey measures.
We begin by reviewing what is known about the impact of measurement error on parameter estimates in Section 2, and possible corrections for the effect of such error in Section 3 This review is not meant as an exhaustive survey the large statistical literature on this subject, but rather is meant to introduce the reader to various issues and to set the stage for our discussion of the validation studies we review 3 What summary measures of the errors in survey data would be most valuable to an analyst for deciding how important such errors are for his/her analysis? How appropriate are standard techniques for "correcting" for measurement errors, given what validation studies can tell us about such errors? In Section 4 we briefly discuss the design of validation studies, while Section 5 reviews what is known about the circumstances under which phenomena are likely to be well reported by survey respondents Finally, Section 6 reviews validation studies across a large range on substantive areas This review is organized by variable, so readers can concentrate on the variables that are most important in their own research We offer some conclusions in Section 7.

2 The impact of measurement error on parameter estimates
We start with the presumption that we are interested in using survey data to estimate some parameters of interest These parameters might be means or medians, as is the case when we are interested in tracking the unemployment rate or median earnings, but will often represent more complicated constructs such as differences in means between groups or regression slope coefficients Measurement error in survey data will typically introduce biases into such estimates If what we are interested in is the

3 Fuller (1987) contains a thorough discussion of the biases measurement error introduces into parameter
estimates and on standard methods for correcting such biases within the context of the linear model, when measurement error is random (classical) Carroll, Ruppert and Stefanski (1995) contains a more general discussion of the same issues within the context of non-linear models, with considerable attention to models in with errors are not purely random.

Ch 59: Measurement Errorin Survey Data

3711

estimate of simple means, then, as long as measurement error is mean 0, it will not bias our estimates However, as is well known, if we are interested in parameters that depend on relationships between variables, then even mean O measurement error will typically bias our estimates.
In what follows we will focus primarily on the impact of measurement on parameter estimates within the context of the linear model 4 Most of the statistics and
econometrics literature on the subject has dealt with this case, presumably because it is in this case that the impact of measurement error on parameter estimates can be well characterized5 There is a growing literature focusing on the impact of measurement error on parameter estimates within the context of non-linear models; however it remains unclear the extent to which the intuitions we develop within the context of the linear model remain true within this context (see Sections 2 7 and 3 3 for further discussion of this point).
Assume the true model is

y* =x*/ + ,

(1)

where y* and are both scalars and X* and /3 are vectors We will maintain the assumption that is uncorrelated with X* The motivation for this assumption is largely strategic we are interested in the impact that measurement error has on our estimates and so focus on the case where our estimates would be unbiased in its absence Instead of X* and y*, we observe X and y, where

X=X*+p; y=y*+v

( 2)

In general, we will not assume p and v are uncorrelated with X*, y* or We will use the term classical measurement error to refer to the case where t and v are assumed to be uncorrelated with X*, y* or 6, and the term nondifferential lCarroll, Ruppert and Stefanski (1995)l measurement error (in explanatory variables) to refer to the case where, conditional on X*, X contains no information about y* 7 implying that is uncorrelated with either y* or 8.

4 The framework we present here derives from Bound et al (1994). 5 Fuller's excellent monograph focuses solely on the linear model. h For the more general case (i e , nonlinear modes), this condition needs to be strengthened to refer to the case where and v are assumed to be independent of X*, y* or e. 7 More technically, measurement error in X* is referred to a non-differential if the distribution of y* given X* andX depends only on X* (i e , f(y* IX*,X) =f(y* X*)). 8 A few examples may clarify the kind of contexts in which differential measurement can occur. Kaestner, Joyce and Wehbeh (1996) estimate the effect of maternal drug use on an infant's birth weight. They find that self-reported drug use has a larger estimated effect on birth weight than does drug use as assessed from clinical data They argue that this is because casual users tend to under-report drug use. Thus, if X* is a binary measure of drug use based on clinical data and X the self report, and y* is birth

3712

J Bound et al.

Measurement error in the above sense can occur for a number of reasons that are worth keeping distinct Respondents can simply misreport on a measure because, for example, their memory is flawed Here it is possible to imagine obtaining a perfectly measured and therefore valid measure of the quantity in question An example of this might be pre-tax wage and salary income (i e , earnings) for a specific calendar year Alternatively we may be using X and y to proxy for the theoretical constructs of our economic models Thus, for example, we might use reported years of educational attainment as a proxy for human capital In this case, the errors will importantly include the gap between what the survey intended to measure and our theoretical construct. While something of the same statistical apparatus can be used to analyze the impact of either kind of error on parameter estimates, clearly validation data can shed light on only the first kind of error.
In the absence of validation data, the analyst observes only X and y We will be primarily interested in the effect of measurement error on the consistency of our estimates For this reason, we will not distinguish between populations and samples. The "least squares estimator" of / is

fvx = lX'Xl-X'Y

( 3)

2.1 Special cases
We will present a general approach to dealing with measurement errors in X* and y* which are correlated with the true X, y and Before doing so, however, it is useful to highlight a few results that can be derived from the general approach for the biases due to measurement errors when convenient assumptions hold To simplify discussion of the various biases, we assume throughout that the X's have been defined so that ilyX ) O Consider three special cases.
First, if there is classical measurement error in only one independent variable xj, the proportional bias in estimating /,i depends on the noise to total variance ratio, a/c. In particular, with only one independent variable in the regression, the proportional bias is just equal to this ratio,

&,x1l= 2·

(4)

weight, E(y* IX*,X) is decreasing in X It is also plausible for measurement error to be differential in the context inwhich X does not merely represent a mismeasured version ofX*, but is a separate variable representing a proxy for X* lCarroll, Ruppert and Stefanski (1995)l Thus, for example, if there are contextual effects, the use of aggregate proxies for micro level constructs can exaggerate causal effects lLoeb and Bound (1996), Geronimus, Bound and Neidert (1996)l.

Ch 59: Measurement Errorin Survey Data

3713

With other variables in the regression:

hyX Z =

2
R2j Z ) + a,2

where Z* represents the elements of X* other then x* (X* = lx> I Z*l), Rx,2z represents the R2 from the regression of xj* on the remaining elements of X*, and byxj, z represents the least squares regression of y on xj holding Z constant Thus, classical measurement error in just one explanatory variable attenuates estimates of the effect of this variable on outcomes The magnitude of this attenuation depends both on the noise to signal ratio and on the extent of multi collinearity between the error ridden variable and the other variables in the equation lLevi (1973), Garber and Klepper (1980)l.
The measurement error in xj biases not just estimates of f, but also the coefficients on the accurately measured variables Letting H represent the coefficient vector from the least squares regression of Xj on Z*, then

3yZ xj = /ii j + ( yxj z) 11

(6)

Thus, classical measurement error in xj* implies that using xj as a proxy for xj* will partially, but only partially, control for the confounding effects of X* on the estimates of the effect of other variables on outcomes lMcCallum (1972), Wickens (1972), Garber and Klepper (1980)l.
Second, even if the error, tji, is correlated with the true xj* (or other X*'s), but is uncorrelated with e, the proportional downward bias is equal to the regression coefficient from a hypothetical regression of utj on the set of measured X's If there is only one independent variable in the model, this reduces to the simple regression coefficient A1x,

nyx =fi l1 &Uxl

When Mand X* are uncorrelated, f3 x is equal to the variance ratio 2/(ja + ,2) and, as such, will be between 0 and 1 More generally, this will not be true In particular if tt and X are negatively correlated (the error p is "mean reverting"), Pfix will typically be smaller than in the classical case (this happens as long as 2 < a 2 ) and can even be negative that is, &x > Pl More generally, if the error in one variable is correlated with other variables in the model, the biases on various coefficients depend on the direction of the partial correlation between the error and the various variables in the model.
Third, if the dependent variable y is measured with error, and that error is correlated with the true y* (where v = 6 y + v* and v* is uncorrelated with X* and E), and the X*'s are measured without error, then the proportional bias in estimating /f is just equal

3714

J Bound et al.

to 6 To emphasize the similarity to the previous case, note that 6 is just the regression coefficient fivy.
Each of the above results applies to cross-section analysis, and to panel data by substituting AX* for X*, etc But when one uses Ay and AX as one's dependent and independent variables, respectively, another aspect of the data becomes important the correlation over time in the true values (the correlation between y at time t and at time t 1, and similarly for X) and in the measurement errors (the correlation between v at time t and at time t 1, and similarly for y) A general result is that, if the variance of a variable (say, X*) is the same in both years, the variance of AX* is equal to 2 X2 (1 rx,*,x,*,) which is greater or less than 2x as rx,*, is less than or greater than one-half A common concern, usually expressed in the context of classical measurement errors, is that true values of X will be highly correlated over time, while the measurement errors will be more or less uncorrelated In this case, a 2x, will be less than ox*, while or2 will be greater than 02, so that moving from "levels" to
"changes" intensifies the bias due to errors in measuring the independent variable(s) 9. There is one more special case worth noting Suppose that xj represents a component
of x 10, with r,, = 0, and that other variables (both y* and the other X*'s) are measured without error Take first the case where xj* represents the only explanatory variable in the model Equation (1) can now be rewritten:

y = 3 lx/ + l +

(7)

= fixj + llj + Jl

Since, by assumption, j is orthogonal to xj, the composite error in Equation (7) will be orthogonal to xj and byxj will consistently estimate /j With other variables in the equation, OLS will no longer consistently estimate P3 Rewriting Equation (1) in this case we have:

y= P, lx + jl + Zy+

(8)

= 3jxj +zy + lpj + el

While tj is orthogonal to xj, we do not expect /yj to be orthogonal to Z Thus, in this case the exclusion of j from our estimating equation represents a specification error, and both ax, z and/z x will be biased If the signs of the partial correlations

9 See Griliches and Hausman (1986) for an illuminating discussion of these issues. 10 This variance component framework fits many different kinds of contexts Thus, for example, we might imagine that xj represents schooling, with xj representing the observed quantity of schooling obtained and pj representing the unobserved quality of this schooling (here one might question the orthogonality of pj and xj) Alternatively, xj might represent cell means of xj' (we use industry specific injury rates as proxies for job specific injury rates) Here yj and xj are orthogonal by construction More detailed discussions of this latter case can be found in Dickens and Ross (1984) and Geronimus, Bound and Neidert (1996).

Ch 59: Measurement Error in Survey Data

3715

between yj and Z are the same as signs of the partial correlations between xj and Z, then using xj as a proxy for x* will only partially control for the confounding effect of Z on /3 as an estimate of /3, 13,x z will be still be biased in the same direction as is /3 ' I

2.2 General results linear model

Having highlighted some special cases in which the consequences of measurement error can be summarized succinctly, we turn to a more general model With and v potentially correlated with X* and y*, the least squares regression coefficient can be rewritten as

Ax = (X'X)-lX'(X'/ /3+ + )

( 9)

= /3 + (X'X)-'X'(-,3 + v + E).

Therefore, the bias of the least squares estimator of is

#3x = (x'x)-x'(-up/3 + vV+ )

(10)

It is useful to collect the measurement errors and their coefficients Define

y

,

o llvl El.

Then Equation (10) can be rewritten as
/ayX -/3 = (X'X)-IX'wY7 = Ay.
If there are k separate variables in the independent-variable matrix X, then A is k by k + 2 It can be rewritten in a more intuitive form as
A = lltxji/vxj/Exl,
where the jth column of flx consists of the coefficients from regressing Pj on X, and /3vx and /3 x represent the set of coefficients from regressing v and on X.
If there is measurement error in only one independent variable X* and if this error is uncorrelated with , only one column of A will be nonzero, and Ajj = j Xj, as claimed in our discussion of special cases If v = y + v* = 6X/3 + be + v*, and v* is uncorrelated with the other variables of the model, and the independent variables

1 The direction of this bias is easy to work out If, for example, the partial correlations between each element of Z and xj are positive, then yxj > y and 8y,1 'Z < ,fI

3716

J Bound et al.

are measured without error, then /Ax and fIx are a matrix and vector of zeros, and
ivx = 6/i Thus, the proportional bias for each coefficient equals 6. As the above expression makes clear, with measurement error in more that one
explanatory variable, the bias on any particular coefficient will involve multiple terms, and is hard to characterize What should be clear is that without some knowledge of the distribution of the errors ( and v), the situation is hopeless the data put no restrictions on possible values of f.
Even with classical assumptions, measurement error in more than one explanatory variable does not necessarily attenuate the coefficients on the variables measured with error Theil (1961) derives a useful approximation to the bias in the context of where two variables are measured with error He imagines we are interested in estimating the relationship:

y = Pix* + 2X2 * + ,

(11)

but observe only error ridden proxies for the x*'s, xl (xl = x + l) and x2 (X2 = X2* + 2) The errors (the 's) are assumed to be independent of each other, the x's and c and the x*'s are scaled to have unit variance Theil shows that when the errors are small

PI/a1

1f 2 X2P

2X :x 1 -p 2 1 _p2 '
where p represents the correlation between the x*'s, and the A's represent the error to total variance ratios for the two variables (A _ o 2/~2) Thus, in the multivariate case, the bias on a particular coefficient depends on factors that, as long as p is positive, tend to offset each other In fact, it should be clear that in the two variable case, the bias on the estimated coefficient on the variable measured with less error can be positive 12
2.3 Differential measurement error an example
In many cases, assuming that measurement error is classical is a simple (and potentially dangerous) expedient when we have little a priori reason to believe that any other particular assumption would be more plausible In other situations, however, we have good reason to believe that the errors are differential, and the basis for this belief can help us write down relatively detailed but still manageable models The growing

12 When more than one variable is measurement with error, not only is it no longer true that the coefficients on these variables are necessarily attenuated but it is also no longer true that the inclusion of one of the error ridden variables will necessarily reduce the bias on coefficients on accurately measured variables See Garber and Klepper (1980) for a succinct discussion of these issues.

Ch 59: Measurement Error in Survey Data

3717

literature on labor supply of older workers provides a useful example, both because it is relevant for our discussion of survey measures of health and because doing so will allow us to highlight the potential importance of differential measurement error13.
A large fraction of the men and women who leave the workforce before the age of 62 report health as the reason they do so Though health is, no doubt, an important determinant of the age at which men and women retire, there are a variety of reasons not to take these self-reports at face value It seems plausible that men and, to a lesser extent women, rationalize retirement in terms of health even when they retire primarily for other reasons 14 Myers (1982) has gone so far as to argue that there is no useful information in self-evaluated health At the same time, for want of alternative measures, econometric analyses of the labor supply decisions of older men and women have generally used respondents' self-assessment of their health There remain important questions about the validity of self-reported measures of health and therefore of the inferences that can be drawn from studies that use them.
The most common health measures used in retirement research have been global questions such as, "Does health limit the amount or kind of work you can perform?" or "How would you rate your health? Is it excellent, very good, good, fair or poor?" There are a number of reasons to be suspicious of such survey measures lParsons (1982), Anderson and Burkhauser (1984, 1985), Bound (1991), Waidmann et al (1995)l First, respondents are being asked for subjective judgments and there is no reason to expect that these judgments will be entirely comparable across respondents Second, responses may not be independent of the labor market outcomes we may wish to use them to explain Third, since health may represent one of the few "legitimate" reasons for a working aged man to be out of work, men out of the labor force may mention health limitations to rationalize their behavior Lastly, since early retirement benefits are often available only for those deemed incapable of work, men and women will have a financial incentive to identify themselves as disabled, an incentive that will be particularly high for those for whom the relative rewards from continuing to work are low.
Each of these problems will lead to a different kind of bias The lack of comparability across individuals represents measurement error that is likely to lead to our underestimating the impact of health on labor force participation, while the endogeneity of self-reported health is likely to lead to our exaggerating its impact. Biases in our estimation of health's impact on outcomes will also induce biases on coefficients of any variables correlated with health Finally the dependence of selfreported health on the economic environment will induce a bias on estimates of the impact of economic variables on participation, regardless of whether we correctly measure the impact of health itself.

13 The discussion here follows Bound (1991) closely. 14 Plausibly, this rationalization is not entirely conscious.

3718

J Bound et al.

As an alternative to using global self-reported health measures, a variety of authors have argued for the use of what have been perceived to be more objective indicators of health: responses to questions about specific health conditions or limitations 15, doctors' reports or information on subsequent mortality 16 Such proxies are presumed to be more objective than self-reported health measures, though this does not mean that reports of specific conditions are completely reliable (see Section 6 8 2) Moreover, even with perfectly accurate measures of health conditions or mortality, it is not clear that their use as proxies for health give us an accurate indication of the impact of health on labor supply Part of the problem with "objective" measures is that they measure health rather than work capacity As long as these health proxies are not perfectly correlated with work capacity the aspects of health that affect an individual's capacity of work they will suffer from errors in variables problems With self-reported health measures we have biases working in opposite directions and, as such, they will have a tendency to cancel each other out With objective measures there is only one bias, and, as long as the correlation between the proxy and actual health isn't close to perfect, the bias will be quite substantial.
The issues here are important for our understanding not only of the importance of health, but also of the impact of economic variables on early retirement Both subjective and objective health indicators are correlated with such things as education, race, pre-retirement earnings, and pre-retirement occupation These factors are also important indicators of early labor market withdrawal One interpretation of these correlations is that it is those in poor health who leave the workforce before normal retirement age Alternatively these correlations could be interpreted as reflecting the fact that poor labor market prospects induce men to leave the labor force, but that they then rationalize this behavior by identifying themselves as limited in their ability to work.
The literature that has compared results using a variety of different health measures has tended to find that health seems to play a smaller role and economic variables a greater one when the more objective proxies are used Most authors have interpreted these results as an indication of the biases inherent in using self-reported measures lParsons (1982), Anderson and Burkhauser (1984, 1985), Chirikos and Nestel (1981), Lambrinos (1981)l These authors have typically either ignored the possible biases inherent in the use of a proxy, or have assumed that these biases are small in comparison to the ones introduced by the use of self-reported measures.
Others have argued in favor of using self-reported information lBurtless (1987), Sickles and Taubman (1986)l These authors emphasize the flaws inherent in most

15 While responses to questions about specific health conditions or limitations still represent self-
reports, the presumption has been that such measures are less susceptible to measurement and endogeneity problems since the questions are narrower and more concrete and, unlike questions about work limitations, are not linked to employment behavior. '6 For areview of the literature on the effects of health on labor supply decisions see Currie and Madrian
(1999).

Ch 59: Measurement Error in Survey Data

3719

objective measures of health while pointing to the clinically oriented research supporting the reliability and predictive validity of self-reported health measures lIdler and Benyamini (1997), Nagi (1969), Maddox and Douglas (1973), LaRue et al (1979), Ferraro (1980), Mossey and Shapiro (1982), Manning et al (1982)l These authors ignore the fact that even if self-reported health is a reliable indicator of actual health, this may not be enough to guarantee that it will give sensible results when used as a proxy for health in retirement equations At issue is whether self-reported health measures are systematically biased, with those out of work being substantially more likely to report health problems than those working Were this the case, the use of selfreported measures might give misleading information on the reasons why men retire early even if these measures were highly correlated with actual health.
To make these comments precise, we consider a simple model for the labor supply of older men or women The choice of hours of work, y, depends on the relative rewards of doing so; w, exogenous income (which for simplicity we ignore); unobserved health status, ir; and other random components 17, E:

y = jw+ A i +e

( 13)

We are interested in consistently estimating 31 and A We expect 1 to be positive. Since tris unobserved, the sign of A1 is arbitrary, but if larger values of rl are associated with better health then we would expect that Al should be positive as well.
We also have an indicator of n/, self-reported health h h depends on health status tr, but also on the economic rewards for continuing to work, w, and, again on other random components pi,

h=fl 2w+A2 ? l I

( 14)

We expect both fi2 and A2 to be positive. We assume that rl is orthogonal to both and libut, as long as there are common
unobserved components that affect both h and y, as there will be if the two are definitionally related or if health limitations act as a rationalization for retirement, and li will be positively correlated.
As long as il and Ware positively correlated, ignoring r in estimating Equation (13) will lead to overestimates of the importance of economic incentives in determining labor force participation The obvious alternative would be to use h as a proxy for tr but there are a variety of econometric problems with doing so The correlation between c and pl introduces a simultaneity bias while variance in Pl introduces errors-
in-variables biases on AI Errors in estimates of AI translate into errors in estimates of

17 The notational conventions we use in this section are somewhat different than the conventions we use elsewhere To focus attention on the impact of differential measurement error in our health measure, we are abstracting from potential measurement error in other variables Thus, the reader should think of y as representing well-measured hours and W as well-measured compensation On the other hand, h and d represent error ridden measures of health, t/.

3720

J Bound et al.

il, while the dependence of h on W introduces an additional bias on Al In particular, treating y and h as if they were observable, letting r, , represent the correlation
between r1and w, and p the correlation between e and Ml and normalizing A2 to equal 1, it is easy to show that:

Aa 2( 1 r2 w)+ aa,,p

a 2(1 2 W+

'

,3il =fi + (Al -Al) ¶'L -A1 / 2

As long as p > 0, this correlation will impart an upward bias on Al, while a2, will
impart the standard errors-in-variables downward bias on A1 Which one dominates depends on the relative strength of these two forces The bias on /l will depend both on the bias on Al and on /2 Thus, even if the errors-in-variables and the simultaneity biases on Al were to cancel, we might still tend to underestimate i31.
The above expressions make clear that the biases on Al and il may be quite substantial even when h is a reliable measure of 1 (i e , even when a 2, is quite small). They also make clear that the magnitude and even the direction of the bias depends on the magnitude of several different correlations Even if self-reported health is highly correlated with actual health estimates using it as a proxy for health may not give reliable results Likewise, even if self-reported health often represents rationalization, the use of self-reports may not necessarily exaggerate the role of health in retirement. Beliefs about the kinds of bias involved using self-reported health as a proxy for actual health implicitly reflect judgments about all quantities involved in the above expressions.
Now consider a somewhat more complete model where we have added an equation to make explicit the correlation between W and i7 and have some more objective indicator of health status, d, which for concreteness sake we will imagine to be subsequent mortality We have

y = Ai 7 +flw+,

( 15)

h = 2 +W/32 +Yul,

(16)

d = A3v + 2,

( 17)

w=,4 T+,

( 18)

r/= v+

(19)

In this model, health ir has two components v, which influences both longevity and work capacity (e g , heart problems), and , which influences only the capacity for work (e g , arthritis) The implicit assumption imbedded in the variance components formulation ( = v + ) is that, up to factors of proportionality (A 1/A 2 and A4 /A2), v and

Ch 59: MeasurementErrorin Survey Data

3721

0 enter the labor force, health and compensation equations with identical coefficients. This assumption seems a natural one as we are thinking of r as capacity for work, and h as a self-report on this capacity , tt and P2 are assumed to be uncorrelated with w, while all four errors (, the lt's, and ) are assumed to be uncorrelated with 17or its components v and /t2 is assumed to be uncorrelated with either e, lit or 5 These assumptions imply that 5 is also uncorrelated with either e or l1 Lastly, v and 5 are assumed to be uncorrelated with each other This assumption is mostly definitional 5 is the piece of r that is uncorrelated with d.
d is objective in two ways that h is not: d does not depend directly on Wnor is 12 correlated with Still, as long as the date of death is not perfectly correlated with an individual's capacity for work, using it as a proxy for health will not adequately control for health, in a regression of y on W(and d) In particular, normalizing 23 to equal 1 we have
A02(1 r2, w)
l r2(1 r w) + 2
02

As long as there are disabling conditions that are not life threatening (e g , severe back problems, mental illness), controlling for d will still leave an omitted variable bias on
,31, while as long as current capacity for work does not perfectly predict date of death
there will be errors-in-variables biases on both l and fil. To summarize, using mortality information as a health proxy will tend to
underestimate the effects of health and overestimate the effects of economic variables on the labor force participation decision In contrast, using self-reported health status can either over or underestimate the impact of either health or economic variables on such decisions.

2.4 Boundingparameterestimates
While, without some restrictions on the nature of the measurement error, the data puts no bounds on /3, there has been considerable work done putting bounds on : under the assumption that measurement error is classical The oldest, and best known of such results is due to Gini (1921) Working with the simple bivariate regression (eqs 1 and 2, p 3711) and under the assumption that the errors v and a are uncorrelated with each other, with y* and x*, and with e, it is easy to show that

IxY l 0 2 l

(20)

Thus

/3

y<<

(21)

3722

J Bound et al.

Under the assumptions of classical measurement error, 3yx and 1//fxy bound , with the
tightness of the bounds being a function of the R 2 between y* and x* More generally, if we allow r*, M O but maintain the other assumptions, it is possible to show that as long as the correlation between x and x* is positive, f/y3 will be correctly signed lWeinberg, Umbach and Greenland (1994)l.
Under the assumption that only one of the explanatory variables is measured with error, it is easy to generalize Gini's result to regressions with multiple explanatory variables On the other hand, in the context in which multiple explanatory variables are all measured with error, the situation is more complex Klepper and Leamer (1984) derive results under the assumption that the errors are independent of each other and of the unobserved correctly measured variables Is
We start by illustrating Klepper and Leamer's result within the context of a model with two explanatory variables,

y* = SlX* + 132x + E

(22)

For ease of discussion, we will assume that x* and x2* have been normalized in such a way that /31 and /32 are both are non-negative We can imagine several possible "estimates" of 3I1 and /32 The estimates from the direct regression

X = xl X2, 12)0= Pyxl X2, the estimates from the reverse regression of xl on y and x 2,

B:= 1
x y x2

1_

xlx 2 Y 3 xl y X2

and the estimates from the regression of x2 on y and xl,

/32 Xy '

a X y 'X

l

2

1

p 2 y XNI

These three estimates of f, and /32 represent three points on a two dimensional plane. Klepper and Leamer's results imply that if all three sets of estimates are non-negative, /3l and /2 must lie within the triangle defined by these three points and, as a result, minlP/ll < /3,1 maxl 31i and minl 2l1 < f/2 < maxl 2l If, on the other hand, one or more of these estimates is negative, then the first and second moments of the data put no bounds on possible values of /3 and /32 19 Klepper and Learner show that in

18 Some of the results developed by Klepper and Leamer had been developed previously by Koopmans (1937), Reiersol (1945), Dhondt (1960), and Patefield (1981), however Klepper and Leamer's treatment of these issues is both the clearest and the most complete. 19 Klepper and Leamer show that, if all the variables involved are normal, the bounds they derive are tight and that every point within these bounds represents a maximum likelihood estimate of the regression parameters.

Ch 59: Measurement Error in Survey Data

3723

the two variable case all possible reverse regression coefficients will be positive if and only if rlr2 > p, where rl and r2 represent the simple correlations between the two measured explanatory variables and y, and p represents the correlation between the two measured explanatory variables Thus, the higher is the simple correlation between the two explanatory variables and the dependent variable and the lower is the correlation between explanatory variables, the more likely it is that the data will put bounds on the regression parameters.
More generally, in the context where one has k potentially mismeasured explanatory variables, imagine the set of all possible k reverse regressions, one with each of the k potentially mismeasured variables treated as the dependent variable, as well as the usual direct regression Put these reverse regressions into a common normalized form with the dependent variable on the left-hand side One now has k + 1 vectors of regression estimates for the k mismeasured variables Klepper and Leamer show that if these k + 1 regressions are all positive 20, then their convex hull bounds the true parameters 21.
Krasker and Pratt (1986) take a different approach In the context of multiple regression where only one of the variables is measured with error, they ask how highly correlated must the error ridden proxy, xj, be to the unobserved correctly measured variable j* to guarantee that zZxwj ill be of the coitrect sign No assumptions are made about possible correlations between the error (j) and either y* or any of the elements of X* Krasker and Pratt show that as long as

), xrx* > R?Z + (1 Rx, 7

(23)

y z will have the correct sign For the two variable case (where only one is measured
with error) they also derive results for fiyZ j Here, correlations often have to be quite
high to guarantee that estimates will be correctly signed.

2.5 Contaminatedand corrupteddata
The measurement error represented in the typical text book and that has received the most treatment in the statistics literature represents "chronic errors" that affect every observation (the error distributions have no mass point at 0) On the other hand, there are situations in which it may be natural to assume that, while in general a variable is well measured, occasional observations are afflicted with potentially gross errors 2 2.

20 Recall that we have normalized X* in such a way that/3 Z>O More generally, the condition that Klepper and Leamer (1984) derive implies that the data puts bounds on fi only if the coefficients from all k possible reverse regressions (regressions of xj on y and all the other x's) have the pattern of signs as does the original regression ofy on X. 21 Klepper and Leamer also show that, if all the variables involved are normal, every vector of parameter estimates within the convex hull represents a maximum likelihood estimate of the model parameters. 22 To mention some trivial examples, interviewer errors such as recording that a person was paid 10 dollars per year, rather than per hour, or that person has roughly 10 000, rather than 10 dollars in the bank can lead to occasional gross errors Imputations for missing data when the researcher is not told which observations include the imputations would be another.

3724

J Bound et al.

While, formally speaking, our treatment of measurement error in the proceeding sections encompasses this case, intermittent errors are worth some attention on their own.
If one has some notion as to the probability that intermittent errors occur, it is often possible to put bounds on the distribution of the variable of interest Horowitz and Manski (1995) formalize some quite intuitive ideas They study the situation in which the researcher is interested in making inference about the marginal distribution of a variable, yl However, the researcher does not observe yl, but rather a random variable y,
Y =ylz+yo(l -z),
where z represents a random variable that takes on the value of 1 with probability p, 0 with probability 1 p; and yo a random variable whose distribution is unknown. Horowitz and Mansky refer to the case in which z is independent of y as "contaminated sampling", while the case in which this is not true is referred to as "corrupted sampling"2 3 .
To see how it is possible to put bounds on the distribution of yl, imagine we are interested in estimating the median of yl, m, and suppose we know that p < O 1 It is intuitively clear that, under "contaminated sampling" that m must lie within the closed interval between the 45th and the 55th percentiles of they distribution (i e , between the medians of the bottom and top 90 % of the y distribution) Under "corrupted sampling", where the missing part of the yl distribution could be anything, the bounds are looser. Here, m must lie in the closed interval between the 40th and 60th percentiles of the y distribution.
Horowitz and Manski focus estimating parameters of the marginal distribution of a random variable It is, however, difficult to apply similar ideas within even the simplest regression context2 4 Thus, for example, if the explanatory variables are potentially "contaminated" in no more than 10% of the sample, one could imagine bounding parameter estimates by throwing out every possible 10% combination of observations. However, with even moderate sample sizes, this procedure would exceed the capacity of current computers.

2.6 Measurement errorin categoricalvariables
While, strictly speaking, the analysis presented in the previous sections applies to both continuous and categorical variables, errors in categorical variables are more

23 As Horowitz and Manski note, their discussion relates quite closely to discussions within this statistics literature of estimators that are designed to minimize the impact of "contaminated" or "corrupted" data on parameter estimates lHuber (1981), Hampel, Ronchetti, Rousseeuw and Stahel (1986)l. 24 It is possible to see how similar techniques could be used to put bounds on regression coefficients in the context in which the dependent variable suffers from "contaminated" or "corrupted sampling" lHotz, Mullin and Sanders (1997)l It is not clear there are practical ways to apply similar ideas in the context in which the items that are "contaminated" or "corrupted" are explanatory variables.

Ch 59: Measurement Error in Survey Data

3725

naturally thought of as classification errors Thus, for example, if x* is a dichotomous,
0/1 variable, it seems natural to think in terms of the probabilities of false positives
(j O prob(x = 1 I x* = 0)) and false negatives (ro01 = prob(x = O x* = 1)) In this context, measurement error cannot be classical If x* = 1, then x x* < 0, while if x* = 0, x x* > 0, so it must be the case that a, , < O Thus, errors in binary variables must be mean reverting More generally, if x* has a limited range, as is often the case with the constructs we deal with (e g , educational attainment) there will be a tendency for ox*,,, < O since when x* is at the maximum (minimum) of its range, reporting errors can only be negative (positive)2 5 .
Nondifferential measurement error in this context implies that, conditional on the truth, reporting errors are independent of y In particular,

Pr(x = zj Ix* =zk,y) = Pr(x = zj Ix* = Zk),

( 24)

where zi E 0, 1 This is a strong and often implausible assumption Suppose, for example, that x represents a chronic health condition x* = 1 if a person suffers from the chronic condition and is O otherwise It seems plausible that the severity of a person's condition will have an effect on the probability that a person recognizes that they suffer from the condition as well as on outcomes In this case Pr(x = 1 Ix* = l,y) will be a function of y, and the random error assumption is violated.
At any rate, under the nondifferential measurement error assumption Aigner (1973) shows that

fx=/l 1 Pr(x* = x = 0)-Pr(x* = O x= 1)l

l

Jr01I r

_

Jr1(o(l-)

10

(25)

=3 L10zo + (1 ir,o)(

) o(l r(I

01)j r l

where r represents the true fraction of 's in the population ( = Pr(x* = 1)) and the second line is derived using Bayes rule2 6 Since all the war's lie between O and 1, the expression in parenthesis must be less than 1 and /3y will be biased towards 0. In fact, for sufficiently high mis-classification rates (i e , if Tol + Jrlo > 1), /,x can be
wrong signed Bollinger (1996) has worked out bounds for yx in this model Under
the assumption that rOl + rlo < 1 and the normalization that 3 > 0, Bollinger shows that

fyx <13 < max (lf 3xyx + x(1 x)l, l xyx +/fxy ( ltx)l) ,

where

Pr(x = 1) Bollinger also shows how these bounds can be tightened when

prior information exists about 0To1 and Jrlo.

25 As far as we know Siegal and Hodge (1968) were the first to make this point.
26 If the two kinds of classification error are of the same magnitude (i e , if ft0J1 r = oO(11 Jr)), then the expression in square brackets in Equation (25) simplifies considerably to 1 r 10 zrOl.

3726

J Bound et al.

Classification error in a dependent variable will also typically bias estimates Take the case where y* is a dichotomous, 0/1 variable, and we are interested in estimating Pr(y* = 1 I x*) We have accurate measures of x* (x = x*) but y suffers from classification error that is independent of x*, with l1o0 Pr(y = 1 I y* = 0) and 0ro 1 = Pr(y = O I y* = 1) Since, in this context, the measurement error in the dependent variable is negatively correlated with the accurately measured variable, it should come as no surprise that classification error in a dichotomous dependent variable will tend to bias downward estimates of the effect of y* on x* In fact, it is easy to see that

0 Pr(y = Ix)

a Pr(y* = 1 Ix*)

l1x =(lo + Ut01)l

( 26)

More generally, random misclassification of the dependent variable in a discrete-

response setting will bias downwards estimated response functions lHausman, Abre-

vaya and Scott-Morton (1998), Abrevaya and Hausman (1997)l.

Categorical variables are often thought of as the discrete indicators of continuous latent variables Thus, we might imagine that y* = 1 if 5 > O and O otherwise We are

interested in estimating Prob(y* = 1 Ix*), but do not observe y* Instead we observe y, where y = 1 if 5 + v > O and O otherwise We assume that v represents normally

distributed random "measurement error" in 5 (i e , v is assumed to be independent of both 5 and x*) The probability of classification error in this model depends not just

on y*, but also on 5 and thus on x* To keep things simple, we assume that

= /x* + E,

( 27)

where is a normally distributed, mean 0, random variable We also assume that x* is well measured (x = x*) Were we to directly observe y*, we could consistently estimate
f/a6 As it is, however, we can consistently estimate only fl/(V,2 + ,2) Retrieving //a requires estimated knowledge of o 2.
Alternatively, imagine that we have a categorical indicator of a latent continuous right hand side variable Here we imagine the underlying model in terms of the latent variables

y* =/ + e

(28)

We have a reliable indicator of y*, y (y = y*), but observe only a categorical indicator of 7r, x, where x = 1 if tI > O and O otherwise In this case, E(y I x = 1) = f/E(l I > 0), while E(y Ix = 0) = /3E(/1 n< 0) Thus, byx consistently estimates
/flE(n I1 > 0) E(7j l ? < 0)l Now suppose x only imperfectly indicates whether rj > O In particular, we assume that x = 1 if ri+ p > 0, where p represents random measurement error In this case

A3 =flE(nI + > 0)-E(n I <+0)l < lE(nI > O)-E( Il 0)l. (29)
Thus, once again, the use of a noisy explanatory variable tends to lead to an
underestimation of the magnitude of the parameter of interest.

Ch 59: Measurement Errorin Survey Data

3727

2 7 Nonlinear models

While there is growing literature on the impact of measurement error on parameter estimates within the context of non-linear models, discussions universally occur within the context of specific models For this reason, it is not possible to summarize results in quite the same way as we were when talking about the linear model Broadly speaking, the results that do exist suggest that (i) results based on linear models are often approximately true within the context of the non-linear models that have been explicitly studied, and (ii) if anything, non-linearities tend exacerbate biases introduced by measurement error.
We have seen that with multiple covariates measured with error, even in the context of the linear model, the effects of measurement error are not easily summarized On the other hand, in the context of classical measurement error in one variable the bias is always in the form of attenuation With multiple variables measured with error or if measurement error is not classical, attenuation may not hold.
Weinberg, Umbach and Greenland (1994) study the effect of non-differential measurement error in an explanatory variable within the context of a simple bivariate model, f(y* x*), where the "dose-response" is monotonic (i e , E(y* Ix*) monotonicaly increases (decreases) with x*) Recall that non-differential measurement error in x* implies thatf(y* I x*,x) =f(y* Ix*) Weinberg, Umbach and Greenland show that as long as E(x Ix*) increases monotonicaly with x*, acryx and oy*,x must have the same sign To paraphrase Weinberg, Umbach and Greenland, as long as the measurement of x* is good enough that the population mean of measured "exposure" goes up when true "exposure" does, trend reversal can not occur.
While Weinberg, Umabach and Greenland's results suggest that in simple models non-differential measurement error of the kind they describe can not cause trend reversal, monotonicity is not necessarily maintained Hwang and Stefanski (1994) show that even within the context of classical measurement error, it is possible to find situations where the regression of y* on x*, E(y* I x*), is monotonically increasing (decreasing) in x*, but that the regression of y* on x, E(y* Ix) is not.
There is also evidence within the context of specific models that non-linearities tend to exacerbate the magnitude of the bias introduced by measurement error Griliches and Ringstad (1970) analyzed the situation where y* is a quadratic function of x*

y* = Po +I IX*+ X2 *2 + e

(30)

y* is assumed to be well measured (y = y*), but x* is not (x = x* + ) Under the assumption that both x* and y are normally distributed and that p is uncorrelated with either x* or e, Griliches and Ringstad showed that

A) iyx x 2 = (I -A), iyx2 = 32( 1_ 2,

(31)

where, as before, A = a2/qx2 Thus, the coefficient on the quadratic term is more severely biased than is the coefficient on the linear term.

3728

J Bound et al.

Yatchew and Griliches (1985) derive results for the probit model with one mismeasured explanatory variable Once again, assuming all variables are distributed normally and that measurement error is classical, they show that simply using x in place of x* produces estimates that converge to

a3*x20+/ ( )

( 32)

As is evident from Equation (32), the usual bias towards zero that is present in the linear model is compounded by the term appearing after the plus sign in the denominator.
In the linear model, biases due to measurement error do not depend on whether that error is normal or homoskedastic However, in non-linear models, this is potentially important, and can induce biases that run counter to our intuitions in the linear case. Consider, for example, a Tobit model

y* = x*/5 + e, Y*

> otherwise.

Our explanatory variable x* is measured with error, and suppose the error / is heteroskedastic Then we can re-write the model for the latent variable y* as
y* = xf + (-P + ),
where the "error term" in parentheses is heteroskedastic Given that heteroskedasticity by itself leads to inconsistent parameter estimates in Tobit models, and can in plausible cases lead to over-estimating /BlMaddala (1983, p 179)l, it seems quite possible that heteroskedastic measurement error could lead to upward-biased parameter estimates.

3 Correcting for measurement error
Under the assumption that measurement error is classical, statisticians and econometricians have developed a number of methods to deal with the biases introduced into our estimators when measurement error is present In particular, under such assumptions, knowing the marginal distribution of the uj's is sufficient to allow the researcher to undo the biases introduced by measurement error Alternatively, if one has exogenous determinants of the error ridden explanatory variables or, in some cases, multiple indicators of the same outcome, one can use these as instruments 2 7, 28.

27 The focus of this section is on point estimation As such, we ignore sampling variability of the various estimators we discuss In many cases, the estimators are or can be interpreted as instrumental variable estimators More generally a discussion of the distribution of these estimators can be found in Fuller (1987), Carroll, Ruppert and Stefanski (1995) and Newey and McFadden (1994). 28 The methods mentioned all involve introducing external information As long as the measurement error in X* is classical, and X*, itself, is not normally distributed, /3 is formally identified lReiersol

Ch 59: Measurement Error in Survey Data

3729

We wish to emphasize three points about such general strategies The first is that these strategies are not as distinct as they might first seem The second is that these strategies for obtaining consistent estimates of the parameters of interest work if measurement is classical, but do not, in general do so otherwise Third, even when the correction does not produce consistent estimates, it may produce a bound; and if OLS and IV are biased in different directions or IV is less biased than OLS, this additional information may be very valuable.

3.1 Instrumental variables in the bivariate linear model
To illustrate these points we will focus on the bivariate linear regression model. To further simplify things, we will also assume that all variables are measured as deviations around their respective means Thus our model becomes

y* = x* + e

(33)

We assume that we measure y* without error (y = y*) On the other hand, we have two error ridden indicators of x*, xl = x* + p11 and x2 = x* + /t 2, with pi and P2 uncorrelated with x*.
Using either xl or x 2 as proxies for x* will lead to estimates of /3 that are biased towards O One alternative would be to use the multiple measures of x to first gauge the magnitude of the errors and then to correct the bias introduced by these errors. In particular, under the assumptions that il and P12 are uncorrelated with all the other variables in the system (including each other), aX,,x 2 = 02 Define

3l a+

UX,'

( 34)

where A1 represents the signal to total variance ratio for xl Similarly,

.22al Oa+ 2 -X OXral2X22

( 35)

3yx, = 1l1 and 3x 2 = 2/3 Under the assumptions of the model, data on y, xl and x2 allow one to consistently estimate ,/3, YX 2 Al and 22 and thence P In fact, two such

(1950), Kapteyn and Wansbeek (1983)l Under the assumption that X* is not normal a number of authors have suggested instrumental variable estimators that use third or higher moments of the various variables as instruments for X lGeary (1942), Pal (1980), Cragg (1997), Dagenais and Dagenais (1997), Lewbel (1997)l However, these methods depend crucially on the assumption that E(y* I X*) is a strict linear function of X*, and, as such, estimates will be sensitive to specification error At any rate, such methods have seldom been used in practice Alternatively, Wald (1940) suggested an estimator of: that involved grouping the data However, unless one has some external information that can be used to form groups (i.e , an instrument), the resulting estimator will typically be no less biased than OLS lPakes (1982)l.

3730

J Bound et al.

estimates are available, giving us some capacity to test the underlying assumptions of the model In particular, our assumption that 1,k and l12 are uncorrelated with x* and
E implies a,,y = ar2,y, which is testable. Alternatively, one might choose to use x2 to instrument x 29

/3, a, x 2

( 36)

Notice that /3 -/3 yx2/A 2 Thus, using x2 to instrument xi is equivalent to regressing y on x 2 and then using an estimate of A2 to disattenuate the resulting estimate of 330.
Under what circumstances will il represent a consistent estimate of /? To see, we
first write out 3,,%in terms of the x*

P3 il =

/ lx 2 + ax,1$2l + (,

a loX* + gX* 2 l + gX* 1 + 1 /2

(37)

Thus, f', = /3 if ao,,2 = ox = ,y,, = In other words 3il = /3 if x2 is exogenous,
the measurement in xl, At, the measurement error in xl, is uncorrelated with x*, and the measurement errors in x and in x2 are uncorrelated with each other These are clearly strong assumptions3 1.
The assumption that , = O means that reporting errors in x 2 are unrelated to factors other than the x* affecting y There are circumstances where this assumption may be a sensible one, but others in which it is clearly not For example, if xl and x2 represent two self-reported measures of health, and y represents a measure of labor supply, we might expect that reporting (the pi's) would be correlated with the equation
error (e). The assumption that the two errors in reporting x* are uncorrelated (i e , that
t 1,,P = 0) will also often be open to question For example, if xl and x2 represent two reports on x* taken from the same individual but at different times, it seems likely that the two errors will be positively correlated Even if x, and x2 represent two reports on x* taken from different individuals it will often be possible that the errors will be positively correlated Thus, for example, two siblings' reports on their

29 Of course, instruments don't necessarily have to be alternative indicators of x* Any variable w, such
that W0, 0, ea=, 0, and a ,,/ = O represents a valid instrument for x.
30 We have been talking as if y, x, and x2 all come from the same sample, but what is often the case is that a researcher has only one measure of x* in the primary data set of interest, but has an estimate of A from some other data set which included multiple measures of x Using an estimate of Abased on one sample to correct regression estimates from another is fine as long as one can justifiably interpret the samples as representing similar samples from similar populations.
31 Fuller (1987) states these conditions somewhat differently Using x2 to instrument xl will consistently estimate if (1) o,2, = O and (2) OQr 2 ~ = O o ,,, = q1,M2 = O qd2,q = O Since ax,t = O and 71,Y 2 = Orepresent conceptually distinct conditions, we think it makes sense to distinguish the two when discussing conditions for the consistency of the IV estimator.

Ch 59: Measurement Errorin Survey Data

3731

parent's education will usually both be based on what that parent told the two If the parent exaggerates her educational attainment (e g , claims to have finished college, even though she did not), it seems likely that this exaggeration will be common to both siblings' reports as well as to the parent's Moreover, if part of the problem is not simply that individuals inaccurately report x, but that our measures do not accurately reflect our constructs (we are interested in human capital, but ask about educational attainment in years), once again it seems likely that the errors from the separate reports will be positively correlated In all these situations we expect ao,, 2 > 0.
Thus, it seems likely that in many situations reporting errors will be positively correlated with each other The good news here is that, as long as it is true that
a,2, c X = , then f3 > /3 /3,y, Thus, correcting for measurement error will tighten our bounds on the true parameter In addition, with more than two measures of x* it is possible to begin to relax some, but not all of the assumptions regarding the independence of reporting errors.
Finally, what about the assumption that ox, ,, = O? This assumption is really at the heart of classical measurement error model There are situations where this assumption seems quite reasonable Thus, for example, if x represents a sample mean and x* a population mean, then there may be good reason to believe that I = x x* is independent of x* Alternatively, if x* represents IQ and x the performance on a specific test, then again it may be natural to assume that t (testing error) is uncorrelated with the truth (here one might want to claim that this is true by construction) However, in the context of survey measurements, there does not seem to be any compelling reason to believe that measurement error is uncorrelated with the truth Moreover, there are a number of circumstances where it seems likely that reporting errors are negatively correlated with the truth oax*,, < O For example, if, as may often be the case, x represents a component of x*, it may be as natural to assume that It and x are uncorrelated as it does that y and x* are uncorrelated Of course, ax, = Oimplies that
ax*,,I < 0. As we have already mentioned, if ao, ,, < 0, then it is no longer necessarily the
case that /3yx </3 If it is still true that U 2, e = all, P2 = 0, then P/3, /3 More generally, if all we know is that ax*,, # 0, then P,, could either over or under estimate /3and exactly the same could be said for Pi/l3 Short of some clear notions regarding the nature of measurement error, it is unclear whether standard methods of correcting for biases introduced into our estimates by such errors take us any closer to the truth.
An interesting example of the situation where ax*,,, < O occurs in the situation discussed above where x* is dichotomous, and errors are therefore errors of classification Now suppose one has two indicators of x* available, xl and x2 32 We

32 There are situations in which the researcher knows or has estimates of Jro and Jrlo from external
information Thus, for example, researchers studying the impact of training programs on the employment and earnings of those trained sometimes do not have an explicit control group, but use nationally representative samples instead In this context, the control group sample will be "contaminated" with

3732

J Bound et al.

assume that, conditional on x*, the two measures are independent of each other and of y In particular this implies

Pr (xl = zj I* = Zk,y,x 2) = Pr (xi = zj I x* = Zk),

(38)

and

Pr (x2 = Zj x* =zk,y,xl) = Pr (x2 = x* = k)

(39)

In other words, we are assuming the measurement error in x* is nondifferential Here, one might be tempted to use x2 to instrument xl; however, as our discussion above will have made clear, this procedure will tend to produce estimates of 3 that are too large in magnitude In fact, it is easy to show that

1 (r 01 + :110)'
which will be greater than /3 as long as there is any measurement error in xl.
However, under the specified assumptions, it is possible to derive consistent
estimates of /3 using GMM methods lKane, Rouse and Staiger (1999) and Black,
Berger and Scott (2000) also mention this possibilityl To see the plausibility that this is the case, it is sufficient to count parameters and moments The "structural" model includes three parameters: the constant term, the slope coefficient and the error variance In addition, there are four distinct error rates as well as the probability that x* = 1, a total of eight parameters in all With data on y, xl and x2 we have 8 independent moments The cross tabulation of xl and x2 give us three, the mean of y conditional on xl and x2 gives us four more, and the variance of y gives us one eight in al133.
More generally, if one is working with a linear model that includes categorical variables and if one has multiple, error-ridden indicators of such variables where the

individuals who received training However, in these situations, the researcher will typically have reliable information on the fraction of the population that receives training, and can use this as an estimate of r01l At any rate, in this kind of situation it is reasonably straightforward to derive consistent estimators of the parameters of interest For a discussion of the case where misclassification occurs in an explanatory variable, see Aigner (1973), Freeman (1984), Heckman and Robb (1985) and Heckman, LaLonde and Smith (1999) For the case where the misclassification occurs in the dependent variable, see Poterba and Summers (1986, 1995). 33 Kane, Staiger and Rouse's work echoes earlier work of Goodman (1974a,b), Haberman (1977),
Andersen (1982) and others on what Goodman refers to as latent structural models Goodman showed that in a context in which one observed multiple independent discrete indicators of a (latent) discrete random variable it was often possible to identify the distribution of both the underlying latent variable and the transition matrices that stochastically map the latent variable into observable indicators The correspondence between latent structural models and the model proposed by Kane, Rouse and Staiger is remarkably close However, the models that Goodman and his colleagues worked with involve solely discrete variables and have been mostly ignored by economists.

Ch 59: Measurement Error in Survey Data

3733

errors are independent of either the outcome or the other explanatory variables in the system, it is possible to get consistent estimates of the parameter of the model using GMM techniques lKane, Rouse and Staiger (1999)l 34.
While the assumption that a,2 = ax*,, = oPI,,2 = O is sufficient to identify r, it is not sufficient to fully identify the model Counting sample covariances makes this clear Var(y,xl,x 2) contains a total of 6 separate terms However, even with the stated restrictions, our model includes seven distinct parameters (, ax2 , 2 , 0, 22, ax., and ai ) In particular, the conditions necessary for the consistent estimation
of f3 are not sufficient to allow us to separately identify a 2, a 2, 012, and a,,E The
IV estimator allows us to solve both the pure errors in variable and the endogeneity problems associated with the use of xl as a proxy for x*, but does not allow us to separate out these two effects If, in addition to the assumptions we have already made, we assume that /2 is uncorrelated with x* (x, t 2 = 0), or that l is uncorrelated with
(,, , = 0) then the model is fully identified. As Goldberger (1972) and Griliches (1974, 1986) have emphasized, it is often also possible to consistently estimate errors in variables models in a multi equation setting. We illustrate with an extremely simple model Suppose'

Y = llx* + el,

Y2 = 32x* + E2 ,

(41)

x = X* + /.

The error terms (the e's and y) are assumed to be uncorrelated with each other and with x* Under these assumptions, /3 can be consistently estimated by using y2 as an instrument for x in the regression of yl on x (/3i, = Cov(yl,y 2)/Cov(x,y2 )) 2 can be estimated in a similar fashion Chamberlain and Griliches (1975) used more sophisticated multi-equation models to control for "ability" when estimating the effect of education on earnings However, as Griliches has emphasized, estimates based on such models are only as good as the models themselves In this kind of setting, minor specification errors can have significant effects on parameter estimates Griliches (1986) and Aigner et al (1984) include excellent discussions of these kind ofmodels.

3.2 Multivariate linear model
The methods we have been discussing generalize to the multivariate case Suppose, for example, one is willing to assume that errors in both the outcome and the explanatory

34 It is worth noting that the discussion has been of models in which x* is, itself, categorical Such models need to be distinguished from models in which x* is conceptualized as continuous (e g , health status), but we have only categorical indicators of x* If x represents an error ridden categorical indicator of x* (i e , if x = k iff Ck I < x* + p < ck) there may be no particular reason to believe that is correlated with x* In fact, in this case, the models are linear in latent variables For this reason, the intuitions and insights obtained from work on the linear errors in variables model still holds The case where x represents a categorical indicator of an underlying continuous variable has been extensively analyzed le g , Heckman (1978), Lee (1982a,b), Muthen (1983)l.

3734

J Bound et a.

variables (v and ) are uncorrelated with both the actual (accurately measured) outcome and the explanatory variables and that one has prior knowledge of their joint distribution, then

= (SxX u, ) -l(sxy

v)

(42)

will consistently estimate r, where Sxx represents the sample variance of X, Sxy the sample covariance of X and y, 2X , a consistent estimate of the variance of the M's
and ±,,v a consistent estimate of the covariance between # and v. Alternatively, if one has as many instruments (W's) as one has as one has explanatory
variables (X's)3 5, v is uncorrelated with y*, and w, = w,v = ow, = O then the IV estimator,

Av = lW'Xl W'y,

(43)

consistently estimates ,6 Of course, if the assumptions are violated and W is correlated with u, v or c, bi, will be inconsistent One special case is worth noting Take the situation where only one element of X is measured with error (denote this variable as x) while the rest are accurately measured (denote this vector as Z*) We are interested in estimating the equation

y* = fix* +Z*'y +

(44)

We have a proxy for x*, x (x = x* + g), but accurately observe Z* (Z = Z*) We also
have available factors that help predict x*, w W is uncorrelated with M, v, or To estimate (, y) we use W = w: Z as an instrument for x: Z Under these assumptions, the IV estimator will consistently estimate fl, but will consistently estimate y only if Z is also uncorrelated with M Thus, if reporting behavior depends not just on x*, but also on Z, then the instrumental variables estimator will not consistently estimate y.
Precisely this kind of situation arises within the context of the example discussed at some length in Section 2 3 above where we were interested in estimating the effect of health and financial factors on retirement behavior Here x* represents overall health, x a self-reported indicator of overall health, and Z* represents other factors including financial ones that effect retirement behavior As discussed above, it is natural in this context to imagine that measurement error in x* will be differential poor health will be used to rationalize behavior Compared with the global measures, more detailed health indicators available in some surveys (e g , the Health and Retirement Survey) such as reports of specific chronic conditions or functional limitations may be less susceptible to measurement and endogeneity problems, since the questions are narrower and more concrete However, as long as such measures

35 Accurately measured x's can be included as elements of W

Ch 59: Measurement Error in Survey Data

3735

represent only a component of health using such measures directly in labor supply equations is, for the reasons discussed above lsee also Bound, Schoenbaum and Waidmann (1995)l, likely to lead researchers to underestimate the effect of health and overestimate the effect of financial incentives on retirement behavior As an alternative to either using the global or detailed health measures in estimating equations, some researchers lStern (1989), Bound et al (1999)l have used detailed measures as instruments However, in this context it would seem natural to worry about the possibility that the rewards for continued work would influence reporting behavior (e g , those with low rewards for continued work might be particularly likely to report themselves in poor health to justify labor force exit) x depends not just on x*, but also on Z* In this context, using some exogenous determinants of health along with Z to instrument x : Z will consistently estimate /3, but not
36

3.3 Nonlinear models
Correcting for the bias created by errors in variables is more difficult in non-linear than in linear models Typically, instrumental variable methods work well only when errors are relatively small in magnitude lAmemiya (1985, 1990)l Thus, for example, suppose one is interested in estimating the non-linear model,

y = g(x*; ) + e,

(45)

where we assume that c is independent of x*, and that O is a parameter vector We observe a proxy for x*, x, where y = x x* is independent of x* We also have available instruments, w, that are correlated with x*, but are independent of both u and We

36 Following the example of Section 2 3 in detail, with two indicators of 7 we might be tempted to use one to instrument the other, but this will not work As long as P2 ~ Ousing d* to instrument h* will purge h* of its dependence on and so will correctly estimate X1 but will tend to underestimate i1by 24i The intuition that we should be able to use d* to instrument h* arises from the similarity of this model to the classical errors-in-variables model, in which one error-prone measure can be used to instrument another. This model differs from the classical errors-in-variables model in that the endogeneity of h* causes the error in this indicator to be correlated with the other regressor in the model, w The instrumental variable procedure uses the projection of h* onto Wand d* as a proxy for i1 What we need, instead, is the projection of q on Wand d* With h* as the dependent variable, the estimated coefficient on w will reflect not only the errors in d* but also w's direct effect on h*, 32 This, in turn, will induce the downward bias on /31 of 32AI We could sort all of this out if we had a consistent estimate of 2, but this requires either knowledge of the reliability of d* as a proxy for or another indicator of i7 Thus, using mortality information to instrument self-reported disability status will correctly estimate the impact of health but tend to underestimate the impact of economic variables on such decisions In contrast, using mortality information alone to construct a health proxy will tend to underestimate the effects of health and overestimate the effects of economic variables on the labor force participation decision, while using self-reported health status can either over or underestimate the impact of either health or economic variables on such decisions lBound (1991)l.

3736

J Bound et al.

might imagine trying to estimate by non-linear instrumental variables Amemiya (1974)l However, if g is non-linear not just in parameters, but in variables, this procedure will not consistently estimate O lAmemiya (1985, 1990), Hsiao (1989)l.
For linear models there is a close tie between simultaneous equations and errors in variables models However, for non-linear models, the analogy breaks down To see why, imagine that x* is a linear function of w, x* = rw + v, with v orthogonal to w by construction For the linear model we have:

y = x* +

(4)

= zw/3 + 3v + E.

/3v is orthogonal to w, so using rw in place of x* will consistently estimate 13 For the nonlinear model we have

y=g(x*; )+

(47)

= g(:Fw; ) + lg(x*; 0) g(JTw; 0)l + E.

lg(x*; 0) g(Jrw; 0)l will not, in general, be a linear function of v and thus there is no guarantee that it will be orthogonal to g( Tw; 0)37.
In general, consistent estimation of non-linear errors-in-variables models requires the researcher to know or be able to consistently estimate the conditional distribution of x* given x,f(x* I x; b) Withf known, the mean of y conditional on x becomes

E(y Ix) = Jg(x*; )f(x* x; 6)dx*

(48)

= G(x; y),

where y = (0, 6) Substituting G(x; y) for g(x*; 0), we obtain a model in terms of observables

y = G(x; y)+ v,

(49)

where

v = +g(x*; 0) G(x; y)

(50)

By construction E(v Ix) = O In principle this model can be estimated by maximum likelihood 38 Hsiao (1989) proposed computationally simpler minimum distance and two step estimators of the model Alternatively, one can imagine using multiple

37 Amemiya (1985) and Hsiao (1989) give more formal versions of this argument. 38 Simulation techniques can greatly facilitate such estimation lLavy, Palumbo and Stem (1998), Stinebrickner (1999)l.

Ch 59: Measurement Error in Survey Data

3737

imputation techniques lRubin (1987), Little and Rubin (1987), Brownstone (1998)l to first impute estimates of x* and then use these in a second stage to estimate 0.
The availability of an instrument, w, is not sufficient to allow the researcher to estimate the distribution of x* conditional on x (or w, for that matter) We have x = x* + p = zw + v + I The regression of x on Wallows us to consistently estimate A, but not the distribution of v Thus, this first stage regression does not allow us to identify the distribution of x* conditional on w Without knowledge of the distribution of x* conditional on observables, it is not possible to consistently estimates O However, the estimator that simply uses ?rw as a proxy for x* often works well lAmemiya (1985),
Carroll and Stefanski (1990)l as an approximation 39.

3.4 The contributionof validation data
So far we have been discussing approaches to measurement error that use multiple, possibly error ridden, indicators of the key variables we are interested in, to gauge the reliability of these measures As we have seen, estimates of the reliability of key measures can be used to gauge the effect of measurement error on our estimates under the assumption that measurement error is, in one way or another, independent of the constructs that enter our models An alternative is to compare the survey estimate with other, more accurate empirical data The promise of validation studies is that they give some direct evidence on the nature of the measurement error in survey data, by allowing comparison of survey responses to "true" values if the same variables. Often, the "true" values are obtained from employer or administrative records Thus, X* will be referred to as the "record" data.
Consider first the simplest case, where the required validation data is quite modest. Suppose we wish to consistently estimate the effect of a single explanatory variable, x*, on y*, but our survey measure for x* is measured with error If the error is classical we know h/x = l 1 02/(02 + 02)l Data from a validations study, which includes both the survey response, x, and an accurate measure of x*, xr (for example, based on checking reliable administrative records) can give us estimates of 2 or a2/a2 which can be used to correct the estimate based on the original survey data Even better, we could not assume the measurement error is classical; as long as it is uncorrelated with y*, we know that x = /3(1 /3,) The validation data allows us to estimate /3, directly.
More ambitiously, validation data allows us to identify parameter estimates in the presence of arbitrary patterns of measurement error Suppose that we have error ridden data for a random (primary) sample of the population For a distinct random sample of the population we have validation data We are imagining that this validation data

39 Amemiya (1985) studies the asymptotic behavior of the nonlinear instrumental variables estimator as ao converges to 0, and finds that with standard regularity conditions, the estimator approaches consistency as qo approaches 0.

3738

, Bound et al.

contains both the error ridden and error free data We can then use the validation data to compute the distribution of y*, X* given y, X (f(y*,X* I y,X)) This conditional
distribution can then be used to impute the distribution ofy* and X* in the primary data set What is clearly crucial for such a procedure to be valid is that the distribution of y*, X* given y, X be the same in the primary and validation data set lCarroll, Ruppert
and Stefanski (1995), refer to this as transportabilityl.
To be somewhat more concrete within the context of the linear model, validation data allow us to calculate empirical analogues to flx, ,vx and flx, box, bvx and bex. Assume to begin with that one's measure of y in the primary data set is error free and that X is exogenous (x = 0) Also let /3x*,x represent the matrix of regression coefficients from the regression ofX* on X in the validation sample (/3x*,x I - 3 x)
A consistent estimate of /3 can be obtained by first using Bx*,x calculated in the validation sample to transform X in the primary sample, X = f3x*,x X, and then regressing y on X Note that under these circumstances consistent estimation of P/
requires validation data on X, but does not require validation data on y In fact, as the
expressions make clear, the validation data on X can come from a separate sample that
contains no information on y, as long as both the primary sample and the validation sample are random samples from the same population.
More generally, if /3 x Oand fix 0, then one can obtain consistent estimates
of /3 by transforming y as well as X Let ' = y l /vx + /3xlX Then

3= (X'Xl X'S^

(51)

consistently estimates 40. Lee and Sepanski (1995) generalize Equation (51) to the nonlinear context They
consider the nonlinear regression

y* = g(x*, ) +

(52)

In the primary data set, the researcher has a random sample of error-ridden versions of y* and x*, which, following our general notation, we will refer to as y and x The researcher also has available a validation data set that contains a random sample of both accurately measured and error ridden versions of y* and x*, Yv, xv, x*, Yv, where the v subscript is used to indicate the data come from the validation data.
Consider first the case where either y* is accurately measured (y = y*) or where measurement error in y is classical and so can be absorbed in the error term and where the measurement error in x* is nondifferential Lee and Sepanski (1995) propose an estimator of O that minimizes

0 min ly-x(x v, Xv)-xg(x ; 0)l 2

(53)

They show that under standard regularity assumptions, O consistently estimates O and derive its asymptotic distribution In the context where y* suffers from non-

40 These ideas are developed formally and generalized to the non-linear setting in Lee and Sepanski (1995).

Ch 59: Measurement Errorin Survey Data

3739

classical measurement error or where the measurement error in x* is differential, Equation (53) can be modified to consistently estimate O Define W = ly: xl and
=y w'(wwv)-'wv(yv -y) Then

0' m

xX(xXvxv ) Xvg(Xv; 0)l 2,

( 53 ')

will consistently estimate 0. Measurement error in key variables can be thought of as a special case of missing
data in a literal sense the researcher is missing valid data on the variables measured with error Much of the voluminous literature on handling missing data has focused on the case where data are missing for a subset of the data Within the context of measurement error this is akin to having validation data available Thus, the techniques that have been developed to deal with missing data lLittle (1992)l could be applied to estimating models with error ridden data as well 41.
In the general context, the impact of measurement error on parameter estimates is model dependent As we have seen, within the context of the linear model, the impact will depend on the association between the measurement error in the key variables and all the other variables included in a model More generally, one needs to be able to estimatef(y*,X* y, X), where y* and X* include all the variables of interest Thus, the value of validation studies is enhanced if they include not just data on the key variables being validated but also on other variables that researchers would typically use in conjunction with these variables.
Validation studies report information regarding the magnitude of the measurement error involved in survey measures typically the mean and some measure of the dispersion in the measure Correlations between the survey and validation study measures of the same variable will also often be reported and can be thought of as measures of the validity of the survey measures (the validity of a measure is the correlation between the measure and the actual underlying construct that the measure is intended to be a measure of) While information on the marginal distributions of the error is sufficient to allow researchers to use such studies to estimate the impact of measurement error on parameter estimates if measurement error is classical, our discussion should make clear that one of the real values of a validation study is to allow us to relax such assumptions Studies sometimes report not only summary statistics but also sample regressions However, even these regressions will provide information regarding the impact of measurement error on estimates only for models similar to the ones reported on in the validation study report Perhaps such tabulations should be seen as illustrative While, in general, it will not make sense or be possible to report f(y*,X* I y,X), it will often be possible to make the validation study data available to

41 See Carroll, Ruppert and Stefanski (1995) for a discussion of the link between missing data and measurement error models See Brownstone and Valletta (1996) for the implementation of these ideas within the context of an economic example.

3740

J Bound et al.

researchers, thus allowing individual researchers to study the impact of measurement error on whatever kind of model they are interested in estimating Indeed some of the most interesting results in the literature using validation studies have been done by individuals who were not originally involved in collecting the validation data but who use such data to examine the impact of measurement error on parameter estimates within the context of a specific research question.
While validation data has considerable promise, it is important to bear in mind the limitations of such data as well We have in mind two distinct issues First validation data presumably has higher validity than survey measures indeed the very value of such data depends on this presumption however this does not mean that it is completely without error Even administrative data or payroll records will include errors Equally important, validation data may not tap exactly the same construct as does the survey measure and some of the discrepancies between the survey and validation data measures may involve discrepancies between the constructs the two capture Neither the survey measure nor the validation study measure may adequately capture the construct we are interested in.
Second, validation study data collected in one context, may not generalize to another4 2 In some contexts the issues are obvious Thus, for example, data collected from a single firm may not be that informative about the nature of measurement error in nationally representative data both because of idiosyncracies regarding the firm and because the data misses any between-firm variation In other cases, issues are more subtle Existing methodological work (see Section 5) suggests that for many items the extent of measurement error will be context dependent For example, the extent of measurement error in reported earnings and employment status appears to depend on the business cycle (see Section 6 1).

4 Approaches to the assessment of measurement error
In order to use the procedures outlined in Section 3, one needs either data that include multiple indicators of variables measured with error or validation data that include both accurate and error ridden versions of the analysis variables As the above discussion should make clear, the use of multiple measures to correct for biases introduced by measurement error requires the use of strong assumptions about the nature of the
42 Carroll, Ruppert and Stefanski (1995) emphasize the value of having validation data collected on a random sub-samples of the primary data ("We cannot express too forcefully that if it is possible to construct an internal validation data set, one should strive to do so External validation can be used but one is always making an assumption when transporting such models to the primary data ") Validation data collected as a subsample of the primary data is practically nonexistent in the data typically used by economists, but such data has sometimes been collected in other contexts (see the examples discussed by Carroll, Ruppert and Stefanski).

Ch 59: Measurement Error in Survey Data

3741

measurement error involved What is nice about validation data is that it allows the researcher to relax such assumptions.
Multiple indicator or validation data is sometimes collected as part of the primary data collection effort However, more commonly, such data comes from external independent studies It should be clear that internal multiple indicator or validation data is to be preferred over external data With the use of external data one is always making an assumption about the transportability of models from the external to the primary data.
Most of the research involving validation data incorporates one of two designs: (1) obtaining external data for the individuals included in the survey, or (2) comparing external population-based parameters or estimates with those derived from the survey. We examine empirical studies that encompass four separate approaches to the assessment of the quality of household reported economic phenomena: (i) Validation studies which involve micro-level comparisons of household-reported
data with external measures of the phenomena, such as employer's records or administrative records; (ii) Micro-level comparisons of response variance which involve the comparison of individual survey respondents' reports at time t with reports obtained at time t +x, under the same essential survey conditions; (iii) Micro-level comparisons of response differences involving the comparison of the individual survey respondents' reports at time t with reports obtained at time t ± x, involving either administrative records (e g , comparison to tax returns) or the collection of survey data under different (and supposedly preferred) survey conditions; and (iv) Macro-level comparisons of estimates based on survey reports with aggregate estimates generated under different (and supposedly preferred) survey conditions or from aggregate administrative records. Each of these approaches to the assessment of data quality suffers from potential limitations; these limitations are outlined in the discussion that follows. Validation studies which permit micro-level comparisons can be classified as one of three types of studies: (1) a reverse record check, in which elements are sampled from the administrative (or validation) records and then interviewed; (2) prospective record checks in which elements are interviewed and then administrative records are checked to confirm the reported behaviors; or (3) complete record check studies, in which all elements in the population have a probability of selection into the sample and administrative records or other validation information are obtained for all sampled elements, regardless of whether the behavior of interest has been reported or not If the measure of interest is a discrete event (e g , hospitalization, industrial accident related to a particular job), reverse record check studies are quite adequate in measuring underreporting, but are often insensitive to overreports, since the administrative records may not include the complete universe of events Prospective record checks attempt to verify affirmative survey responses; thus these designs are better for assessing overreporting of discrete events but less adequate than reverse record check studies for

3742

J Bound et al.

assessing underreporting of events since it may be difficult to obtain validation data from all potential sources A complete or full record check, provided all of the relevant records can be located, provides the best means for assessing both underreporting as well as overreporting However, such studies are rare, requiring a closed universe from which one can obtain the validation information and be confident that the records include an accounting for the entire universe of behaviors.
Regardless of the design of the validation study, most empirical investigations incorporating validation data attribute differences between the respondent report and the validation data to the respondent and thus may overstate the level of response error There are two separate issues here First, various factors may contribute to measurement error, including the interviewer, the wording of a particular question, the context of the questionnaire, as well as the essential survey conditions such as the mode of data collection; however, differences between survey reports and administrative records are often discussed in terms of response error Recognizing the alternative sources of errors is a first step in modeling them properly Second, as noted above, differences between respondent reports and the validation data may reflect deficiencies in the latter Most record check studies fail to assess or even discuss the level of potential error in the records or the error introduced via the matching of survey and record reports Comparisons of survey reports with self-reported administrative records (e.g , tax records) may show discrepancies because of errors in the administrative records Finally, it is rare to see a thorough discussion of the impact of definitional differences between the two sources of information on the level of apparent error.
In contrast to most validation studies, micro-level comparisons of survey reports for discrete events occurring before time t obtained at two points in time under the same essential survey conditions focus on simple response variance over time However, the accuracy of the data at either time t or time t +x can not be assessed Empirical investigations of this type usually attribute differences in the two estimates to error in the reports obtained at time t + x (under the assumption that the quality of retrieval declines over time).
Micro-level comparisons which entail survey estimates produced as a result of different survey designs similarly tend to attribute differences in the estimates to response error for the estimates produced under the less optimal design Hence, the later comparison requires a priori knowledge of the design most likely to produce the most accurate data.
Macro-level comparisons are fraught with several potential confounding factors, including differences in the population used to generate the estimates, definitional differences, and differences in the reference period of interest Benchmark data are themselves potentially subject to various sources of errors and omissions, complicating the interpretation of differences between the two sources Finally, whereas micro-level validation can compare survey responses to external data, comparisons of survey data with aggregate benchmark data requires some assumptions about non-response, either reweighting the available responses or imputing values for non-respondents Perfectly accurate survey responses can appear to diverge from benchmark totals if the handling

Ch 59: Measurement Errorin Survey Data

3743

of non-respondents is in error; incorrect survey responses could even add to correct control totals if response error and errors in nonresponse corrections are offsetting.

5 Measurement error and memory: findings from household-based surveys
The assessment of measurement error across various substantive disciplines has provided a rich empirical foundation for understanding under what circumstances survey responses are most likely to be subject to measurement error The theoretical framework for most of these investigations draws from the disciplines of cognitive and social psychology Although these investigations have provided insight into the factors associated with measurement error, there are few fundamental principles which inform either designers of data collection efforts or analysts of survey data as to the circumstances, either individual or design-based, under which measurement error is most likely to be significant or not Those tenets which appear to be robust across substantive areas are outlined below.
5.1 Cognitive processes
Tourangeau (1984) as well as others lsee Sudman, Bradburn and Schwarz (1996) for a reviewl have categorized the survey question and answer process as a fourstep process involving comprehension of the question, retrieval of information from memory, assessment of the correspondence between the retrieved information and the requested information, and communication In addition, the encoding of information, a process outside the control of the survey interview, determines a priori whether the information of interest is available for the respondent to retrieve from long-term memory.
Much of the measurement error literature has focused on the retrieval stage of the question answering process, classifying the lack of reporting of an event as retrieval failure on the part of the respondent, comparing the characteristics of events which are reported to those which are not reported One of the general tenets from this literature concerns the length of the recall period; the greater the length of the recall period, the greater the expected bias due to respondent retrieval and reporting error This relationship has been supported by empirical data investigating the reporting of consumer expenditures and earnings lNeter and Waksberg (1964)l; the reporting of hospitalizations, visits to physicians, and health conditions le g , National Center for Health Statistics (1961, 1967), Cannell, Fisher and Bakker (1965), Woolsey (1953)l; reports of motor vehicle accidents lCash and Moss (1972)l, crime lMurphy and Cowan (1976)l; and recreation lGems, Ghosh and Hitlin (1982)l However, even within these studies the findings with respect to the impact of the length of recall period on the quality of survey estimates are not consistent For example, Dodge (1970) found that length of recall was significant in the reporting of robberies but had no effect on the reporting of various other

3744

J Bound et al.

crimes, such as assaults, burglaries, and larcenies Contrary to theoretically justified expectations, the literature also offers several examples in which the length of the recall period had no effect on the magnitude of response errors lsee for example, Mathiowetz and Duncan (1988), Schaeffer (1994)l These more recent investigations point to the importance of the complexity of the behavioral experience over time, as opposed to simply the passage of time, as the factor most indicative of measurement error.
Another tenet rising from the collaborative efforts of cognitive psychologists and survey methodologists concerns the relationship between true behavioral experience and retrieval strategies undertaken by a respondent Recent investigations suggest that the retrieval strategy undertaken by the respondent to provide a "count" of a behavior is a function of the true behavioral frequency Research by Blair and Burton (1987) and Burton and Blair (1991) indicate that respondents choose to count events or items (episodic enumeration) if the frequency of the event/item is low and they rely on estimation for more frequently occurring events The point at which respondents switch from episodic counting to estimation varies by both the characteristics of the respondent as well as characteristics of the event As Sudman et al (1996, p 201) note, "no studies have attempted to relate individual characteristics such as intelligence, education, or preference for cognitive complexity to the choice of counting or estimation, controlling for the number of events" Work by Menon (1994) suggests that it is not simply the true behavioral frequency that determines retrieval strategies, but also the degree of regularity and similarity among events According to her hypotheses, those events which are both regular and similar (brushing teeth) require the least amount of cognitive effort to report, with respondents relying on retrieval of a rate to produce a response Those events which occurred irregularly and which were dissimilar require more cognitive effort on the part of the respondent.
The impact of different retrieval strategies with respect to the magnitude and direction of measurement error is not well understood; the limited evidence suggests that errors of estimation are often unbiased, although the variance about an estimate (e.g , mean value for the population) may be large Episodic enumeration, however, appears to lead to biased estimates of the event or item of interest, with a tendency to be biased upward for short recall periods and downward for long recall periods. In part, the direction of the estimation error related to episodic enumeration is a function of the misdating of the dates of retrieved episodes of behavior, a phenomenon referred to in the literature as telescoping le g , Sudman et al (1996)l The evidence for telescoping comes from studies which have examined respondent's accuracy in reporting dates of specific events Forward telescoping refers to the phenomena in which respondents report the occurrence of an event as more recent than is true; backward telescoping refers to misdating in the opposite direction, that is, reporting the event as occurring earlier in time than is true The direction of the misdating appears to be a function of the length of the reference period Forward telescoping is most evident when the reference period is short (one or two weeks), whereas

Ch 59: Measurement Error in Survey Data

3745

backward telescoping is more common for longer (one year or more) reference periods4 3 .
The misdating of episodic information in panel data collection efforts has given rise to a particular type of response error referred to as the "seam effect" lHill (1987)l. Seam effects refer to the phenomena of a disproportionate number of changes in respondent status (e g , employment status) change at the "seam" between the end of the reference period for wave x of a study and the start of the reference period for wave x + 1 of a study For example, a respondent will report being employed at the time of the wave x interview; at wave x + 1, the respondent reports being unemployed for the entire reference period Hence his or her change in employment status occurred at the seam of the reference periods Although the seam effect may arise as a function of the misdating of the start or end of a particular status, some have speculated that the effect is a result of respondents minimizing the level of effort associated with the respondent task by projecting the current status back to the beginning of the reference period of interest.
Finally, a third tenet springing from this same literature concerns the salience or importance of the behavior to be retrieved Salience is hypothesized to affect the strength of the memory trace and subsequently the effort involved in retrieving the information from long-term memory The stronger the trace, the lower the effort needed to locate and retrieve the information In a study on the reporting of hospitalizations, Cannell, Fisher and Bakker (1965) found that hospitalizations of longer duration were subject to lower levels of errors of omission than hospitalizations of one or two days in length; Waksberg and Valliant (1978) report a similar pattern with respect to injuries Although salient information may be subject to lower levels of errors of omission, other research has indicated that salience may lead to overestimation on the part of the respondent le g , Chase and Harada (1984)l As is evident from the literature, overestimation or overreporting on the part of the respondent can result from either forward telescoping of events, that is, the misdating the event of interest counting events which occurred prior to the start of the reference period, or from misestimation, in part, due to the salience of the event of interest Unfortunately, empirical investigations of response error in which overreporting is evident have not addressed the relative importance of forward telescoping and salience as the source of the response error.

5.2 Social desirability
In addition to asking respondents to perform the difficult task of retrieving complex information from long-term memory, survey instruments often ask questions about

43 The work on telescoping has focused on the effect of telescoping on the time of individual events. However, it seems likely that when respondents are asked to retrospectively recall the timing of various events in their past, errors in the reported timing of various events are correlated, creating something of a spurious coincidence of events This is a potentially serious issue for event history analysis.

3746

J Bound et al.

socially and personally sensitive topics It is widely believed and well documented that such questions elicit patterns of underreporting (for socially undesirable behavior and attitudes) as well as overreporting (for socially desirable behaviors and attitudes) The determination of social desirability is a dynamic process, a function of the question topic, the immediate social context, and the broader social environment at the time the question is asked Some topics are deemed, by social consensus, to be too sensitive to discuss in "polite" society In the 1990 S this is a much shorter list than was true in the 1950s, but most would agree that topics such as sexual practices, impotence, and bodily functions fall within this classification Some hypothesize that questions concerning income also fall within this category le g , Tourangeau, Rips and Rasinski (2000)l Other questions may concern topics which have strong positive or negative normative responses (e g , voting, the use of pugnacious terms with respect to racial or ethnic groups) or for which there may be criminal retribution (e g , use of illicit drugs, child abuse).
The sensitivity of the behavior or attitude of interest may affect both the encoding of the information as well as the retrieval and reporting of the material; little of the survey methodological research has addressed the point at which the distortion or measurement error occurs with respect to the reporting of sensitive material The encoding of emotionally charged behaviors is hypothesized to include an encoding of the emotion associated with the event The presence of the emotion may affect further retrieval of that information Cognitive dissonance may lead the respondent to "undo" the details of the event, distorting the event in subsequent rehearsals, thereby encoding the distorted information with the behavior lLoftus (1975)l Even if the respondent is able to retrieve accurate information concerning the behavior of interest, he or she may choose to edit this information at the response formation stage as a means to reduce the costs, ranging from embarrassment to potential negative consequences beyond the interview situation, associated with revealing the information.

5.3 Essential survey conditions
The measurement process and the quality of survey data can also be affected by design features such as the mode of data collection (e g , face-to-face, telephone, selfadministered), the method of data collection (e g , paper and pencil, computer assisted interviewing), the nature of the respondent (self vs proxy response), characteristics of the interviewer (e g , gender, race, voice quality), cross section vs longitudinal design, the frequency and time interval between interviews for longitudinal data collection, as well as the data collection organization and survey sponsor Groves (1989) provides a thorough review of empirical literature related to these various sources of error While there is evidence that at times, each of these factors may affect the quality of the data, the empirical literature is inconsistent as to the direction and magnitude of the error attributable to each of these design features.

Ch 59: Measurement Error in Survey Data

3747

5.4 Applicability offindings to the measurement of economic phenomena

One of the problems in drawing inferences from other substantive fields to that of economic phenomena is the difference in the nature of the measures of interest As noted earlier, much of the assessment of the quality of household-based survey reports concerns the reporting of discrete behaviors; many of the economic measures that are the subject of survey inquiries are not necessarily discrete behaviors or even phenomena that can be linked to a discrete memory Some of the phenomena of interest could be considered trait phenomena Consider the reporting of occupation. We speculate that the cognitive process by which one formulates a response to a query concerning current occupation is different from the process related to reporting number of doctor visits during the past year.
For other economic phenomena, it is likely that individual differences in the approach to formulating a response impact the magnitude and direction of error associated with the measurement process Consider the reporting of current earnings related to employment For some respondents, the request to report current earnings requires little cognitive effort it may almost be an automatic response For these individuals, wages may be considered a characteristic of their self identity, a trait related to how they define themselves For other individuals, the request for information concerning current wages may require the retrieval of information from a discrete episode (the last paycheck), a recent rehearsal of the information (the reporting of wages in an application for a credit card), or the construction of an estimate at the time of the query based on the retrieval of information relevant to the request.
Given both the theoretical and empirical research conducted within multiple branches of psychology and survey methodology, what would we anticipate are the patterns of measurement error for various economic measures? The response to that question is a function of how the respondent's task is formulated and the very nature of the phenomena of interest For example, asking a respondent to provide an estimate of the number of weeks of unemployment during the past year is quite different from the task of asking the respondent to report the starting and stopping dates of each unemployment spell for the past year For individuals who are in a steadystate (constant employment or unemployment), neither task could be considered a difficult cognitive process For these individuals, unemployment is not a discrete event but rather may become encoded in memory as a trait which defines the respondent. However, for the individual with sporadic spells of unemployment throughout the year, the response formulation process would most likely differ for the two questions While the response formulation process for the former task permits an estimation strategy on the part of the respondent, the latter requires the retrieval of discrete periods of unemployment For the reporting of these discrete events, we would hypothesize that patterns of response error evident in the reporting of episodic behavior across other substantive fields would be observed Similar patterns of differences may be observed as a function of requesting the respondent to report current earnings as compared to directing them to think about their last paycheck and report the gross

3748

J Bound et al.

earnings With respect to social desirability, we would anticipate patterns similar to those evident in other types of behavior, overreporting of socially desirable behaviors and underreporting of socially undesirable behaviors.

6 Evidence on measurement error in survey reports of labor-related phenomena
6.1 Earnings
Empirical evaluations of household-reported earnings information include the assessment of annual earnings, usual earnings (with respect to a specific pay period), most recent earnings, and hourly wage rates Validation data are generally based on employers' or administrative records Gradually, the focus of such studies has shifted. Early studies tended to focus on whether the mean error was near zero, and so whether the survey reports were unbiased More recent studies focus on the variance of the error relative to true variation and, more generally, on the bias caused by errors when survey measures of individual earnings are used in linear models As a result, it is hard to report results from the various studies we review in a consistent fashion Ideally, we would like to report information on the distribution of errors (e g , the mean and variance of errors) together with some measure of the potential biases introduced into simple models by the error Our preferred measure of this potential bias is the slope coefficient from the regression of the record values on the survey values of the same variable As we have seen, under the assumption that the record values are valid, one minus this coefficient gives a measure of the proportional downward bias introduced by the measurement error for simple bivariate linear regression models that use the variable in question as the explanatory variable 4 4 The range of summary measures in Table 1 reflects the considerable variation in what can be computed from studies from different disciplines that are motivated by different questions.
Overall, the findings suggest that annual earnings are reported with less error than hourly wage rates or weekly earnings Mean estimates of annual earnings appear to be subject to relatively small levels of response error, whereas absolute differences indicate significant over and underreporting at the individual level We also find consistent evidence that errors are mean-reverting, but less consistent evidence that errors are correlated with standard human capital and demographic variables.
6.1 1 Annual earnings
Nine of the studies reported in Table 1, representing six different data collection efforts4 5, examine the quality of reports of annual earnings For each of these studies,

44 The measure will be valid if the employer's or administrative records are valid and error free or if the errors in such records are completely random. 45 The Panel Study of Income Dynamics (PSID) Validation study is represented three times; see Duncan and Hill (1985), Rodgers, Brown and Duncan (1993), and Bound, Brown, Duncan and Rodgers (1994); the CPS-SSA matched study is reported in Bound and Krueger (1991) and Bollinger (1998).

Ch 59: Measurement Error in Survey Data

3749

a 0)

0

x

0)s

" N~~~r~ c

l80

"' t °T r

Ea '2

i9 _

Q

P

ON U U

CC

Pa a

C-0

W E a to

N)

O a
c N) .0

OO aC· a
Ba

t t C *a

N) O

0))l

a

~L ca

aE

aa

l·-C~.U O

Ph66 Rl
*ON~o
' bE OONqU0N)0C-

0) a'

II 'a 0 5

) OG 3

in

a

o

O

3c I

to

N) a go

0.B

e

a~g 0)0

C

a00 E
0
.

o o

OC E

'

.5 3 e

OEE

a

E

0)~~~~~~~~~~~~~I

E~o QE

,O a 5aA-' 3

a~

m

CC-6

~

c~~~~~~~"~*
~~,-·~ O

*f~~~~~p~~~o~~~o

O

ca

0 ) 0)

o

CM 55

Ca) 0

0)

.2 P

ILa

ea
0

g o
0)

E

0 s-~~~~

'

Os

"x C

d r;

E

§o
;

,og

2O

2

'8 a

'

C

E

c

ii 3 e

a

~ e .w C *CcD QO " g

·

O OOC~

Ert: el Bz a
2 OXr

a e6a
O

X

C

ao,-

a

Q~~~~~C
a

4a0

o

aLOe

1 >> 34 C

0>)

a

>1 O

0

-O

C V

,R

_

aO

o 0

C0In0,

ON

ear

7Nz

0E > )

_Q

ao a.

O

o

-

00))

a_

am

'a

C a

O-N

N

aU CP o

'a

CO00)n)

0)

On

0o

3750

0

C

i0

co

·' ~;'~ @ ;

C

O =: = ~

,

C C. ~ ,'

.e

~ '~

1~~~~~~S ~c

r

C u C C) C C C)

CC)) C

.Z.

~-
~ C

v
. 0 JC
E
.
g 0I)0 3,C 0
3OC v5
,O
-0 )
oO

J Bound et al.
o ,e'o

.o_O C, Cl O C) O
-: c N

E

Ic

5o~o·o

.0 C) C)

Cii 00 I

iiO 8

0 0 0
0 -a'e
4 0
-O
R
'5
_x
C)
0IC) *O -m0 Ci
8
d
O

0

C

0

0~

C 0
i2

C)

0.~~~~~~~~~~.
a~~~~~~~~~~~~
0

-
00 ~~~~e

"x ~~~~~~~~~~~~~~~ 6 ~~~

C)~CO~~ef

O5

ii B

C

":I~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~C

a

O

Jvl

E·Sb~~~~~~~~~~~

i'
oO 00

Ch 59: Measurement Errorin Survey Data

3751

ca 0 0

0

u

3

~

O

e·

o

°O

· .

x

, c: o

NO

"D

O

NC ) -

ONN I

-

~

F~ -~

C

t Oc NO

0)

0 ' ,o, I' c·'

c 4 c6

'

tt o~ c-, t ee

oO ON ON

0o-)
I cs
I3

r 0

0,

(S f

t FA o:

fi e e = '

'fcl ONc_Cl/vcNP-ONcA- <

ei

40

4 '0

4

gs t g r

-D to

o

~ ~ 4)43 O

~ Cl

4)

4

4)

0-

O\Q

C CCC

R
00 4 4

^ U3 X

'B

))

O

4).-
ga 0 48)~ )-g 4)
r~ 4) O

.4

.5; -0O1

-0 00

0

0

4

-O
0 4)
4) 4)

U. l

00

0o

t0.w0

.4 0.

40

4

Z

q

4)

00

-X 9

-CO SIt
0 0 40
0 04

0 0 4)
r4 0
n
2-5
4O t
4) 00
-ae:
Lnn
-

3752

J Bound et al.

PO

. II
0
a

oO II
O .0
aa

a ~\cD Amn_ _ oOo OCc'
2 r'0 0)'C0' Of ' CCO>l ''-0
O 0 N ON O o OS o

) mr g t '~ o'o S't

00

N

I'

"t 0, "t m 00 m ON 00 ON Cl

) uO .9Q
Q ,t a 2

m

O 00 -

uc m r-

0_0 CNl C_l ON 0-0

Cli

N ,:

oO

'A~

o

:)

OI

0

-o a ' o 0)

a

01 l *M

II
·3

rg) -

o o

-ao O

eSv _, Wa3 E Oog

Nooo

-h

2

'- eO 4'A.0 O ;-
e 0 -f~ i E<

00-eO O

~'A '
000
.2 u

o
ev f E

~~~~ O 'AM'

oe

r 0)

to
a2

2

~3

a8 a

m oys U U i

2

°e N a M a

O '"N O O

Z

a
,o

ca

.'i

0

co,

0

0

o

V Q

_n D

0

0

0
.F 1

.2
-0
.2
D= *0O) o -0
0 OB
O
ra
0) 0) 0)

Ch 59: Measurement Error in Survey Data

bs c to
v 8°
6 C E a)
s; 2
a 2; 50 brto .

F
CO
r. a
-

xxx

u -c

0 o
e

2

a OO

0 .
Sa O E~~~~~~C
r. 0
C9 C °:E 2 E2 o
0 Q)
-o 0 Tfm
CC
2 CU
i
I
a)
0 ar))

3753

3754

^ L, = 0.
CO

0 COO

v)

r o 00 e CC

-0 CO'0 C

co _ -

0* .to 2

eO O
.2 O r
0
3 5C
.0
>t
oE c;

'0,
'n uo

~0EE": I z-B

Q

s

0
0c' 5
C'
C Y 5
0o 4
3O Wc
-
-0 0)

' r E 0

0)

=0

=

0
U

<'5 ~

0e-0,:,-0
20 -0 't
E
p ~c
-50)
0
CO 20 fQ2 O o
C 0>

iO

CO 0

0

0or

z o 0

CO

9

0a

CO
Ea
0) O

x

W 0
-E

o

C-

vs

,S

0

.

EC O

0 0) 1O
0ro cN 0000 O
0

J Bound et al.
0)

CO ,,, C O
o a CO CO

SO

o

CO Ce CO

0 O Wo O 4 E O ; .Ctt cc 2E c _

'~S

000 C. O

000·C

OC

Ch 59: Measurement Error in Survey Data

0
00 0

Cl,

ON Cfl

0x

00 C' CC O 00

M) _

'0 '0 O crM CO On OM N

0*
;;
0~0t
0)'0 .0x
Co O

.= CI
.E
00
to 00 r 0000 ,0 C-
It 0

'D O O =o O

.

I

'0 00 NC> CC O

X-00

-

rlIo o 00 O 00

0

' C "t x

r

M

C_r

I

zO

O

o @ c ws 8

et)

0x

"E~~o~Y)00 Q

'

-

Q

Chc, ,*

_ > >>

k

NO

OO

*O

d

~0 ·;

0)~ 0)E

0),

o

C.)

0

z0p

0

0

0

0

oo ooX O

>C OO

> Od

C,oS

S °

tb

.zz t:0 0'
C, 0 00 +I
d0
" o4
~ 10: R 0)

3755

.0

a

: S 0c = Ot
.e

C0,

Q

.0

0

0 0 ,N 0,

'

I

00

o~

0o 8 Y

C

00

0 0

0
0 0 0)
0)

z
o
rA
0 It a) 0 0 c-
C

3756

J Bound et al.

00,. io

o

,

"

c

SE ~II 2

R

)

0)

0,0
RQ 2 R
to 0
R
r.

0

0 p 5

01

0 OR

0.

_

0

2

0)
0g

30
e
O) 0-
a

e

_

0)

-o3

O Oe

0

0

E
0

.r-

-Ib

00j 0 00000

\

O OC

2 o ~~ l ~ ~ ~ Er

P
.O 0

Ec
2

0)
.j

00 8 en

0-

r-

0)

0)>

0

0)0)a

N'4

t O 00 O\

0

0

0) - O

0)

g

0

R

0>),E

00

o

00

-

S

0 0) 0)000)

O O *~p

'-e o 5

~00 O

. Oo 0)

*0-0

** ,

p

S )O O

g~~~~~~

O ~~.

0

0 0o

eO
O 0)

sovl

,o2~~~-

.0

S-

0) E

3

Qt

a3

.

0)eRs|

0)

Sm O

>5 ~~g~o~s~~~Co~~~~~~~s(-

m

0
SO t 0U )

.

m el

m

0· Q~~~~~~

50-&

0

5C

00 O

9r0U-

0)

,s~~o~~~ m Cm

c
a~O ~~ X
b C~~~~

,0, a "x,
500)5 9 5-UB .0 -
0) C _~ O
E a-c
-00) 0.0

Ch 59: Measurement Error in Survey Data
.0 O be .O 0
ot

71
X1
0

; 30
~m7:1

z

.Z0:

.9 °

U

U

"B

U 70

.b -

e

U br

<o,

Bm E

B

00
me
at05
g

3757

3758

J Bound et al.

comparisons are made between the survey reports and either administrative data (IRS tax forms, Social Security Administration records) or employers' records.
Miller and Paley (1958) compared 1950 Census reports and IRS data for a sample of Census respondents 46 Limiting attention to families for which each member over age 14 could be matched to an income tax report (including spouses on joint filings) 47, they found that median earnings were $3412 in the Census reports and $3570 in the IRS data Moreover, the two distributions appear quite similar (see Table 10 in the original paper) While Miller and Paley do not ask whether the errors in the Census reports are mean reverting, the similarity of the two distributions suggests they must be.
By focusing on IRS records for validation, Miller and Paley excluded those with earnings low enough that they do not file an income-tax report In contrast, Borus (1970) focused on survey responses of residents in low-income Census tracts in Fort Wayne, Indiana He experimented with two methods for collecting annual earnings from respondents, a set of two relatively broad questions concerning earnings and a detailed set of questions concerning work histories The responses from both sets of questions were compared to data obtained from the Indiana Employment Security Division for employment earnings covered by the Indiana Unemployment Insurance Act (e g , excludes agricultural employees, self-employed, and those working for relatives) The mean annual earnings among the respondents was $2500; although the mean error for the two question types was relatively small, $47 and $39 for the work history and broad questions, respectively, the standard deviation of the mean error was large ($623 and $767) Over 10% of the respondents misreported annual earnings by $1000 While these individual-level errors seem large relative to the mean values, they are similar in magnitude to more recent estimates based on nationally representative samples le g , Bound and Krueger (1991)l.
In contrast to one of Borus's conclusions, Smith (1997) finds that, among lowincome individuals eligible to participate in federal training, earnings data based on adding up earnings on individual jobs leads to significantly higher values than data based on direct questions about annual earnings In Smith's data, this difference is due to higher values for hours worked and for irregular earnings (overtime, tips, and commissions) Comparisons with administrative data for the same individuals lead Smith to conclude that the estimates based on adding up earnings across jobs leads to overreporting, rather than more complete reporting.
Carstensen and Woltman (1979) compared reports of annual earnings obtained in a special supplement to the January (1977) Current Population Survey (CPS) with

46 Of 7091 families, only 3903 were completely matched One important reason for non-matches is
income low enough that no Federal tax would be owed; except for this difference, Miller and Paley (1958) find the matched sample representative of the larger Census sample. 47 Note that for families with more than one earner, we are really comparing family rather than individual earnings.

Ch 59: Measurement Errorin Survey Data

3759

employers' reports Respondents in rotation group 7 (1/8 of the entire CPS sample)4 8 were asked to report earnings as well as report his or her employer's complete name and address While one of the major strengths of the design is the nationally-representative sample of household respondents, the effective response rate of 61 % raises questions as representativeness of the sample of matched employer-employee information 49 . The use of a mail questionnaire to obtain information from the employer suggests that comparisons between the employer and employee information must consider measurement (or reporting) error in the validation data as a potential source of the discrepancy The study includes comparisons of annual earnings, as well as hourly, weekly, and monthly rates of pay and usual hours worked With respect to annual earnings, the absolute difference in the two earnings sources was $800 (s e = $403), or about 5% of the mean annual earnings 50.
The Panel Study of Income Dynamics (PSID) Validation Study consisted of two waves of interviews with respondents sampled from a single large manufacturing firm and the corresponding record information for those respondents 51 Cooperation by the firm essentially eliminated problems of matching validation data to each respondent and allowed for the resolution of anomalies in the validation data The questionnaire used at both waves requested that the respondent provide information for the previous two calendar years At the time of the initial interview (1983), the firm's hourly workforce was fully unionized and virtually all employees, both hourly and salaried, worked full-time The workforce was considerably older and had more job tenure than was true of national sample of workers, in part due to layoffs and few new hires in the two years prior to the initial interview These deviations were offset by a sampling procedure that disproportionately sampled younger and salaried workers Comparisons between the two validation samples and data from the Panel Study of Income Dynamics for the respective years indicates that, with respect to annual and hourly earnings, the validation sample respondents have considerably higher means and lower variance than a national sample.

48 Note that each rotation group of the CPS sample is a nationally-representative sample. 49 Of the 6791 eligible persons in the CPS, 5591 (82%) provided complete employer address data. Among the employers for whom address information was provided by the CPS respondent, 4166 (75%) responded to the mail survey which included the same earnings and hours questions asked of the CPS household respondent, resulting in an effective response rate of 61 %. 50 Respondents in the Carstensen and Woltman study could report earnings in the time unit of their choice, that is, annual, weekly, monthly, or hourly The comparison of annual earnings was limited to those respondents for whom both the respondent and the employer reported the earnings as annual earnings. 51 The PSID-VS was conducted by telephone with workers at their homes, rather than administered at the workplace Similar to other household-based studies, the PSID-VS suffered from nonresponse. The initial wave of interviewing was conducted in the summer of 1983 with 418 of the 534 sampled employees (78 3 %) A second wave of interviewing was conducted in the summer of 1987 The sample consisted of respondents to the initial wave and a fresh sample of hourly workers; the response rate among the initial wave respondents was 82 4% and 74 7% among the new sample of hourly workers, resulting in an overall sample size of 492 completed interviews.

3760

J Bound et al.

Using data from the first validation study, Duncan and Hill (1985) compared reports of annual earnings for calendar year 1981 and 1982 with information obtained from the employer's records For neither year is the mean of the simple difference between the two data sources statistically significant, although the absolute differences for each year indicate significant under and overreporting The average absolute difference between the interview and record reports of earnings for 1982 was $2123, approximately 7% of mean earnings The report of earnings for 1981 was of lower quality than for 1982; the absolute difference of the two reports of earnings for 1981 was $2567, or approximately 8 5% of mean earnings The error-to-true variance ratio showed a larger difference between the two years: for calendar year 1982 annual earnings it was quite small ( 154) but significantly larger for 1981 ( 301).
While the margin of difference depends on the measure employed, by all indications previous-year's earnings are reported more accurately than those of two years prior to the interview While this is consistent with greater error for longer recall periods, it may also reflect the fact that 1981 was a year of economic disruption both for the economy and for this firm.
Comparison of measures of change in annual earnings based on the household report and the employer records indicate no difference in means Error to true variance ratios are higher for changes than for levels ( 50 vs 15- 30), even though mean absolute errors are similar for changes and levels Errors in reported changes would be higher but for the positive correlation between the errors in the two years, 43 Duncan and Hill (1985) emphasize that these changes are obtained from differencing reports for two calendar years in the same interview, not differencing reports of last year's earnings from two interviews in a longitudinal survey.
Although the findings noted above are often based on small samples drawn from either a single geographic area lBorus (1970)l or a single firm lDuncan and Hill (1985)l, the results parallel the findings from nationally representative samples Bound and Krueger (1991) created a longitudinal linked file based on the 1977 and 1978 March CPS questionnaires and earnings histories from Social Security Administration files 52 The study is restricted to those respondents classified as heads of households for whom information for March of 1978 was successfully matched to data reported in March of 1977 and the Social Security records Of the 27485 persons classified as heads of households in matchable rotation groups (50% of the CPS rotation groups), the three-way link was made for 9137 persons Other limitations (e g , private, covered employment and positive (non-imputed) CPS and SSA earnings in both years) further reduced the effective sample to approximately 3500 persons Bound and Krueger note

52 As part of a joint project of the Census Bureau and the Social Security Administration, survey responses for persons in the March (1978) CPS Annual Demographic File were linked to their respective earnings information in SSA administrative records to create the CPS-Social Security Records Exact Match File (CPS-SER) To create a longitudinal data set, the CPS-SER was matched to the (1977) March CPS Annual Demographic File, based on the respondent's unique CPS identification number, age, education, sex, and race.

Ch 59: Measurement Error in Survey Data

3761

that the matching process tends to eliminate those who misreport their Social Security number or other matching data, and so those who tend to give inaccurate responses to other questions (e g , earnings) may be under-represented Another caveat is that the Social Security earnings data refer to earnings taxable under the payroll tax, and nearly half of the males in their sample reach this limit Consequently, many of the estimates reported below are based on models that correct for this truncation, based on the assumption that In earnings are normally distributed.
Bound and Krueger (1991) examined error in annual In earnings reports separately for men and women Although the error was distributed about a near-zero mean for both men and women, the magnitude of the error was substantial For men, the error variance exceeded 10 and represented 27 6% of the total variance in CPS earnings; for women the error variance was approximately 05 and represented less than 9% of the total variance in CPS earnings for women One striking feature of the errors is that while they appear to be unimodal and symmetric, the tails are substantially thicker than one would expect with a normal distribution Indeed, for those for whom errors were directly observable (those below the Social Security earnings limit), the standard deviation of the errors was three times the interquartile range In addition the distributions show a large spike near O For those below the earnings limit, 12% of men and 14% of women report earnings that exactly match their Social Security records, while more than 40% of each gender report earnings within 2 5%.
Despite these errors, the correlation between interview and record In earnings is high in Bound and Krueger's data ( 88 for men and 96 for women) Errors are negatively related to the record value for men (- 42), and essentially uncorrelated for women (-.03) Because errors for men are mean-reverting and errors for women are small, they find that measurement error should not appreciably bias the coefficient of In earnings in linear models The regression of record on interview values gives coefficients very close to 1 ( 97 for men and 96 for women).
Because their data include two CPS waves, they can compare interview and record reports of changes in earnings as well Consistent with the conventional wisdom, differencing increases the error variance (from 1 to 12 for men, and from 05 to .09 for women), and reduces the true variance by about half Positive correlation in the errors ( 4 for men, 1 for women) limits the increase in error variance due to differencing Consequently, although the ratio of error to total variance is substantial ( 65 for men, 2 for women) the regression of record changes on interview changes ( 77 and 85) suggest that the bias due to measurement error when the change in In earnings is an explanatory variable is not overwhelming.
Bollinger (1998) extended the work of Bound and Krueger (1991), examining the measurement error associated with each of the cross-sectional samples encompassing Bound's and Krueger's panel sample, expanding the sample to include women who were not heads of households, and incorporating nonparametric estimation procedures. To a large extent, Bollinger's findings confirm those of Bound and Krueger In addition, he finds higher measurement error in the cross-section samples as compared to the panel used by Bound and Krueger, suggesting that constructing a panel from CPS

3762

J Bound et al.

lead to the selection of respondents who appear to be better reporters Bollinger also finds that the negative correlation between measurement error in reports of annual earnings and record earnings appears to be driven by a small proportion of men with low income who grossly overreport their earnings or whose earnings are largely unrecorded by Social Security Of additional interest in the work by Bollinger is the finding that although mean response error is negatively related to earnings, median response error is zero across earnings levels, suggesting median wage regression to be more robust to the effects of response error.
Coder's (1992) analysis compares reports by respondents to the Survey of Income and Program Participation and Federal tax returns The study is limited to SIPP respondents who were married couples as of March 1991, who met the following criteria: (1) valid Social Security numbers were reported for both the husband and the wife; (2) the couple could be matched to a married-joint tax return; and (3) nonzero wage and salary income amount was reported either during the SIPP interview or on the tax return Of the approximately 9200 husband-wife couples in the SIPP, 62% (or approximately 5700 couples) met the criteria Coder finds little difference between mean estimates of annual earnings and the respective validation source He reports a simple correlation between earnings reported in SIPP and IRS data as 83; the mean annual earnings based on SIPP averaged approximately 4% less than the mean based on matched tax records Coder's data has an unusually large discrepancy between the variance of interview and record data, with the former smaller; this in turn implies a very strong negative correlation between the "error" (SIPP-IRS) and the "true" (IRS) value so strong that the effects of earnings on other variables would be overstated due to (mean-reverting) errors in earnings Alternatively, it is possible that errors in the IRS data contribute to these results lRodgers and Herzog (1987, p 408)l.
Bound, Brown, Duncan and Rodgers (1994) analyze data from both 1983 and 1987 waves of the PSID Validation Study The correlation between interview reports and company-record data on In earnings is about 9 ( 92 for 1982 earnings, 89 for 1986), but the negative correlation between error and record values is weaker for 1986 (- 08 vs - 30) Consequently, the regression of record on interview value is closer to 1 0 for 1982 than for 1986 ( 96 vs 82).
The distribution of errors for the PSID validation study appear to be quite different than that found by Bound and Krueger (1991) using the matched CPS-Social Security Earnings data Since virtually all the individuals in the PSID validation study are men, it seems natural to compare PSID validation study results to those for men using the CPS-SSE matched data The two error distributions have similar means and interquartile ranges, but the PSID validation study data shows neither the spike at 0 nor the thick tails shown by the CPS-SSE matched data As a result of the thick tails in the CPS-SSE data the variance of errors is an order of magnitude larger in the CPS-SSE data than it is in the PSID validation study datal What accounts for the difference in the distribution of errors between the PSID validation study and CPSSSE data is unclear lsee Bound, Brown, Duncan and Rodgers (1994, p 357) for a further discussion of these issuesl.

Ch 59: Measurement Error in Survey Data

3763

Given that the change in In earnings computed from the PSID Validation Study covers four years rather than one, the findings for this variable should be seen as complementing rather than replicating Bound and Krueger's The general patterns are strikingly similar increased error variance, with the increase somewhat limited by the correlation in the errors over time; negative correlation between the error and the true value of the change (- 32), and regression of true change on interview reports of 77. One interesting difference is that the correlation between the errors is lower in Bound et al 's (1994) data ( 14) than in Bound and Krueger's (1991) To some extent, this might be expected if the factors that produce this error change gradually over time; on the other hand, it may also reflect the difference between economy wide and single firm samples.
Three of these studies Duncan and Hill (1985), Bound and Krueger (1991) and Bound, Brown, Duncan and Rodgers (1994) explore the implications of measurement error for earnings models Duncan and Hill's model relates the natural logarithm of annual earnings to three measures of human capital investment: education, work experience prior to current employer, and tenure with current employer, using both the error ridden self-reported measure of annual earnings and the record-based measure as the left-hand-side variable A comparison of the ordinary least squares parameter estimates based on the two dependent variables suggests that measurement error in the dependent variable has a sizeable impact on the parameter estimates For example, estimates of the effects of tenure on earnings based on interview data were 25 % lower than the effects based on record earnings data Although the correlation between error in reports of earnings and error in reports of tenure was small ( 05) and insignificant, the correlation between error in reports of earnings and actual tenure was quite strong (- 23) and highly significant, leading to attenuation in the estimated effects of tenure on earnings based on interview information.
Bound and Krueger (1991) also explore the ramifications of an error-ridden lefthand-side variable by regressing error in reports of earnings on a number of human capital and demographic variables, including education, age, race, marital status, region, and SSA Similar to Duncan and Hill (1985), the model attempts to quantify the extent to which the correlation between measurement error in the dependent variable and right-hand-side variables biases the estimates of the parameters However, in contrast to Duncan and Hill, Bound and Krueger conclude that mismeasurement of earnings leads to little bias when CPS-reported earnings are on the left-hand-side of the equation.
Bound, Brown, Duncan and Rodgers (1994) estimate separate earnings functions using both interview and record earnings for both waves of the Validation Study They find some evidence that errors in reporting In earnings are negatively related to tenure in 1982, and positively related to education in 1986 Overall, though, they find no consistent pattern Rodgers, Brown and Duncan (1993) note, however, that if annual hours are included as an explanatory variable, its coefficient is severely biased by a number of factors (e g , correlation between errors in reporting hours and earnings, in addition to problems with the reliability of hours per se, as discussed in Section 6 1 2).

3764

J Bound et al.

While there is not much evidence that errors in reported earnings are strongly related to standard explanatory variables in earnings functions, two cautions should be noted. First, the tendency for errors in reported earnings to be mean-reverting means that, if there are no other problems, coefficients of all explanatory variables are biased toward zero This bias is about 20 % of the true coefficient in both studies Second, errors in other variables may be correlated with earnings, but there is very little evidence one way or the other on this score.
The CPS-SSA matched data and the PSID validation data can also be used to shed some light on the impact of measurement error on earnings dynamics The short nature of the CPS-SSA matched data panel limits its usefulness for this purpose, but the PSID validation study includes a total of six years of data Using these data Pischke (1995) found that a relatively simple model in which measurement error in earnings stems from the under reporting of transitory earnings fluctuations together with a white noise component did a good job of explaining basic patterns in the PSID validation study data 53.
Pischke's model rationalizes a number of the stylized facts that have emerged from recent earnings validation studies In particular his model accounts for the finding that despite mean reversion, measurement error in earnings does not seem to significantly bias the coefficients on explanatory variables in earnings regressions the explanatory variables in such regressions would be expected to explain permanent, but not transitory earnings.
In terms of the estimation of earnings dynamics, Pischke's estimates imply relatively good news The negative correlation of measurement error with transitory earnings attenuates the role of the white-noise component Pischke estimates that surveyed earnings tend to exaggerate the actual fluctuation in earnings by between 20 and 45 % depending on the year, but do a reasonably good job identifying the relative importance of the permanent component to earnings changes 54.
There are a few things that are important to note about the Pischke study First, his model implies reporting errors will tend to be more severe at some points in time as against others (i e , reporting errors will tend to rise in magnitude as the transitory component of earnings rises) Second, as Pischke emphasizes, it is hard to know how to generalize his results to more representative samples Even were the PSID validation study establishment representative of establishments in the country as a whole, earnings

53 With 11 free parameters, Pischke fits 28 free covariances quite well He reports an overall chi-square statistic on the model of 23 8 (p-value: 0 124). 54 It is certainly possible to doubt the general validity of Pischke's conclusion His estimates are based on a tightly parameterized model that was estimated on data from a single firm However, Baker and Solon (1998) have recently estimated earnings dynamic patterns using administrative data that are remarkably similar to patterns other authors lBaker (1997), Haider (2001)l have found using survey data These estimates would seem to confirm Pischke's finding that measurement error does not have dramatic effects on estimated earnings dynamics.

Ch 59: Measurement Errorin Survey Data

3765

dynamics in the sample would miss the component that arises when individuals move across firms.
On balance, the validation evidence suggests little bias in estimating mean annual earnings, and this is quite consistent with the fact that survey-based estimates of earnings aggregated up to economy-wide estimates correspond quite closely to earnings as measured in the National Income and Product Accounts 55 Moreover, despite significant absolute differences between household reports and record reports of earnings as well as significant error to record variance ratios, the correlation between the various sources of data are quite high Several of the studies indicate coefficients for the regression of household reports on record reports of annual earnings near 1 0, reflecting a negative correlation between error in the household reports and the record value for annual earning Only one study addressed the deterioration of the quality of reports of annual earnings as a function of time lDuncan and Hill (1985)l; similar to empirical investigations in other fields, their findings provide support for less accurate reporting for longer reference periods The evidence with respect to the impact of error in household reports of earnings is mixed; Duncan and Hill (1985) report significant attenuation in a model examining the effects of human capital investment, whereas Bound and Krueger (1991) conclude that misreporting of earnings leads to little bias for models incorporating CPS-earnings on the left-hand-side of the equation.
What can account for the significant individual differences between household and record-reported annual earnings? The reporting of annual earnings within the context of a survey is most likely aided by the number of times the respondent has rehearsed the retrieval and reporting process for this information We contend that the memory for one's annual earnings is reinforced throughout the calendar year, for example, in the preparation of federal and state taxes or the completion of applications for credit cards and loans To the extent that these requests have motivated the respondent to determine and report an accurate figure, such information should be encoded in the respondent's memory Indeed, both CPS and PSID time their collection of annual earnings data to coincide with the time when households would have received earnings reports from employers and might have begun preparing their taxes Subsequent survey requests should therefore be "routine" in contrast to many of the types of questions posed to a survey respondent Hence we would hypothesize that response error in such situations would result from retrieval of the wrong information (e g , annual earnings for calendar year 1996 rather than 1997), social desirability issues (e g , overreports related to presentation of self to the interviewer), or privacy concerns, which may lead to either misreporting or item nonresponse.
However, several cognitive factors may affect the quality of reports of annual earnings Comprehension may impact the quality of the information; for example,

55 For example, CPS-based estimates of total wage and salary income were 97%of independent estimates based on NIPA in 1990 lU S Census Bureau (1993)l As noted earlier, such a comparison reflects several factors besides the mean level of error in the individual reports, such as the accuracy of CPS adjustments for non-response.

3766

J Bound et al.

respondents may misinterpret the request for earnings information as a request for net earnings as opposed to gross earnings In addition, the wording of most earnings questions does not stress the need for the reporting of exact earnings; hence respondents may interpret the question as one in which they are to provide estimates as opposed to precise reports of earnings Estimation on the part of the respondents, as noted by Sudman, Bradburn and Schwarz (1996), often leads to reports that are noisy at the individual level but unbiased at the population level Retrieval of earnings information for any one year may also be subject to interference with respect to stored information concerning earnings in previous years If the source of the misreporting by respondents was due to social desirability bias, we would anticipate that the direction of the error would be toward overreporting of annual earnings, especially among those with low levels of earnings and possibly, underreporting among those at the highest levels of earnings Although there is evidence of a negative correlation between response error and the true value overall, there is little evidence to support the existence of social desirability bias with respect to the reporting of annual earnings le.g , Bollinger (1998)l.

6.1 2 Monthly, weekly, and hourly earnings

In contrast to the task of reporting annual earnings, the survey request to report most recent earnings or usual earnings is more likely to be a relatively unique request and one which may involve the attempted retrieval of information that may not have been encoded by the respondent, the retrieval of information that has not been accessed by the respondent before, or the calculation of an estimate "on the spot" Hence, we would anticipate that requests for earnings in any metric apart from a well-rehearsed metric would lead to significant differences between household reports and validation data. Moreover, the extent of rehearsal is likely to differ by type of worker; for example, those paid a monthly salary are more likely to have accessed information about monthly earnings than are those paid by the hour, while the reverse is likely for earnings per hour.
While annual earnings is the most frequently studied measure of labor market compensation in validation studies, Table 1 makes it clear that significant effort has also been devoted to validating other measures Roughly speaking, we can divide these studies into two groups: those that study weekly or monthly pay, and those that study pay per hour.
Four of the earliest studies in Table 1 focus on the correlation between weekly or monthly earnings as reported by workers and their employer's reports All four (Keating, Paterson and Stone's (1950) study ofjobs held in the past year by unemployed workers in St Paul; Hardin and Hershey's (1960) study of salaried workers at an insurance company; Borus's (1966) study of average weekly earnings of trainingprogram participants; and Dreher's (1977) study of average salary of workers at an oil company) report correlations of 90 or higher Mean reports by workers are close to record values, with modest overreporting in some studies and underreporting in others.

Ch 59: Measurement Error in Survey Data

3767

Broadly speaking, these results parallel those reported above for annual earnings, except that the issues of mean reversion and accuracy of changes in panel surveys were not addressed5 6.
Carstensen and Woltman (1979) compare worker and employer reports, using a supplement to the January (1977) CPS Their survey instruments allowed both workers and employers to report earnings in whatever time unit they preferred (e g , annual, monthly, weekly, hourly) As noted earlier, comparisons are limited to those reports for which the respondent and the employer reported earnings using the same metric. Curiously, when earnings are reported by both worker and employer on a weekly basis, workers underreport their earnings by 6%; but when both report on a monthly basis, workers overreport by 10% When the various reports are converted to a common time unit (usual weekly earnings), they find workers report earning 11 7% less per week than their employers' reports Unfortunately, they do not report correlations between worker and employer reports.
Studies of hourly wages or earnings per hour are less common, in part because it is difficult to obtain validation data for salaried workers Typically, their pay is stated in weekly, monthly, or annual terms, and employers often do not have records of the weekly hours of their salaried workers (see Section 6 4).
In their study of wages, Mellow and Sider (1983) utilized the January (1977) CPS data first analyzed by Carstensen and Woltman (1979)57 Hourly wages calculated from the CPS reported earnings and hours compared to employers' records indicate a small, but significant, rate of underreporting (In hourly wage as reported by the worker lower by 048) The variance of the difference between interview and record reports is 148, which is larger than Bound and Krueger's error variances for the logarithm of annual earnings in CPS data ( 114 and 051 for men and women).
In a reanalysis of the same data used by Mellow and Sider, Angrist and Krueger (1999) report more details In their basic sample they find that the variance in the difference between interview and record values of In hourly earnings to be 24 In comparison they report the variance in the In of survey earnings to be 36 While the ratio of these two numbers suggests a signal to total variance ratio of one third, Angrist

56 Keating, Peterson, and Stone show a cross-tabulation of interview vs record reports which displays at least weak mean reversion for men However, from their grouped data, in which 70%of the 115 cases are on the diagonal, it is hard to say anything more precise. 57 In the CPS sample, validation data could be obtained only where the worker provided the name and address of the employer, and the employer provided the relevant data Mellow and Sider note that validation data could be obtained for only about two thirds of the eligible sample However, reported CPS earnings of those who refused to provide employer contact, or whose employers refused to provide validation data, were similar to earnings of those who did not refuse The EOPP was actually two large studies: a survey of approximately 5000 establishments and the other of approximately 30000 households Because of the geographic overlap between the two studies, it was possible to link a limited number (n = 3327) of worker and employer responses The representativeness of the resulting sample is unclear, and was not discussed by Mellow and Sider (1983).

3768

J Bound et al.

and Krueger's tabulations suggest very substantial mean reversion The regression of record on surveyed In earnings suggests attenuation of about 25 %.
Duncan and Hill's (1985) analysis of PSID Validation Study data investigates the accuracy of earnings per hour values calculated from workers' reports of annual earnings, weeks worked, and average hours per week Because hours data were available only for hourly workers, their analysis excludes the firm's salaried workers. On average, calculated earnings per hour are relatively accurate (underreported by about 4%) But the error to true variance ratio of 2 8 leads the authors to characterize the extent of measurement error as "enormous" the unhappy result of annual earnings being less accurately reported for hourly than for salaried workers and substantial error in reports of annual hours (see below).
Bound, Brown, Duncan and Rodgers (1994) report similarly discouraging results for the logarithm of earnings per hour error to true variance ratios of about 1 5 in both 1982 and 1986, and correlations between interview and record values of 51 and .64 Predictably, matters only get worse for the change in the logarithm of earnings per hour.
The correlations between interview and record values are strikingly lower than those for weekly or monthly earnings in company-based samples noted above The earlier company-based studies focused on salaried workers, whereas the PSID Validation Study's hourly earnings information is available only for hourly workers As it happens, these workers are unionized and the number of hours per week is relatively compressed. In a sense, the poor results for hourly pay occur not because the reporting errors are so large (the standard deviations of the errors are 11 and 16 in the two years) but because true variation is so limited (standard deviations of 09 and 13).
Rodgers, Brown and Duncan (1993), using data from the second wave of the PSID validation study, analyze the accuracy of the logarithm of reported earnings and calculated earnings per hour over three time intervals annual, most recent pay period, and "usual" 58 Their analysis is restricted to hourly workers, since record data on hours per week were unavailable for salaried workers Two generalizations are evident from Table 1: the correlation between worker and record reports declines as one moves from annual to pay period to "usual"; and for any given time interval, earnings per hour are less accurately reported than earnings.
Since wage rates were calculated from reported hours and earnings the variance in the error associated with the wage rate can be decomposed into three parts: the variance of the error in reported earnings, the variance of the error in reported hours, and the covariance of those two reports While the details vary with the time interval, in general all three of these components are important 59 .

58 Operationally, they define "usual" as the average over the preceding six two-week pay periods They report, however, that their results are not very sensitive to the precise definition. 59 Rodgers, Brown, and Duncan report these components normalized as shares of the relevant error variance For wage rates derived from reports of annual earnings and annual hours, the contribution due

Ch 59: Measurement Error in Survey Data

3769

Two studies focus on the accuracy of reports of starting wage in a particular job. Branden and Pergamit (1994) evaluated the consistency of respondents' reports of starting wages in the National Longitudinal Study by comparing responses reported at time t to those reported one year later Only 42% of those studied reported the same starting wage for a particular job across the two years 60 Consistency varied as a function of the time unit used for reporting, with higher rates of consistency among those reporting their starting wage as an hourly or daily rate (47% and 52% consistent, respectively) as compared to a consistency rate of approximately 13% for those reporting a biweekly wage rate In contrast, Barron, Berger and Black (1997)61 find a high correlation between employers' and employees' reports of starting wages ( 974) Differences in the length of the recall period (one year vs at most four weeks) most likely contributes to the differences in the findings from the two studies Unfortunately, given these relatively short recall periods, neither study gives much evidence on the question of recall accuracy for starting wages of those who have been employed for longer periods (e g , typical of information collected as part of a retrospective event-history question sequence).
On the whole, the evidence suggests that reporting of ;eekly or monthly earnings are highly correlated with employer reports Available evidence on earnings per hour is much less reassuring Unfortunately, the cautions from the various PSID Validation Studies are as their authors indicate likely to be overly dramatic because the true variance of hourly earnings is considerably smaller in one firm than in a broader sample.
As was true for annual earnings, a few of the studies in Table 1 attempt to assess the importance of measurement errors in frequently-estimated linear models Mellow and Sider (1983) examined the impact of measurement error in wage equations; they concluded that the structure of the wage determination process model was unaffected by the use of respondent or employer-based information, although the overall fit of the

to error in annual earnings and annual hours are about equal ( 93 and 80) The errors are positively correlated (r = 43) and so the covariance is negative (- 74) For wage rates based on the most recent pay period, errors in reported earnings are about twice as important as errors in reported hours (1 36 and 62, respectively); the covariance is again negative (- 98) Based on usual pay, the contribution due to error in reports of earnings is 1 26, from error in reports of hours is 32, and the covariance is - 58. 60 Only those who reported their pay in the same time unit in both interviews are included. 61 The study reported by Barron, Berger, and Black was based on a sample of establishments with 100 or more employees, screened to determine whether they were hiring at the time of the initial interview The data collection encompassed three interviews with the firm and three with the newly hired employee of the firm Of the 5000 establishments originally sampled, no attempt was made to contact 1603 establishments due to budgetary restrictions Of the 1554 establishments classified as eligible and for whom interviews were attempted, complete information was obtained from 258 (16 6%) employer-employee pairs The low response rate, coupled with the lack of information for over 32% of the originally sampled establishments, raises serious concerns with the inferential limitations of the study The authors report that the sample for which they could obtain information was similar to the original 5000 establishments in size and industry, but completions were more likely to come from rural areas and the Mountain and Pacific regions.

3770

J Bound et al.

model was somewhat higher with employer-reported wage information Bound, Brown, Duncan and Rodgers (1994) report estimates of simple "labor supply" equations (In hours regressed on In earnings per hour and demographic controls) Here, a number of potential biases are at work due to the unreliability of hours reported as well as errors in hourly earnings and their impact depends on the true supply elasticity In the end, their results suggest such estimates may be badly biased, though the direction of the bias and the contribution of errors in measuring earnings per hour are less clear 62.
The studies reported in Table 1 provide conflicting indications of the relative accuracy of survey reports of monthly or weekly earnings, with some relatively old studies showing quite high correlations with record values The calculation of hourly earnings appears to be most prone to error; the correlations between interview and record values are significantly lower for hourly earnings than for weekly, monthly, or annual earnings In most of the studies, however, hourly earnings are calculated from separate reports of earnings and hours rather than based on direct reports of hourly earnings by respondents The error in hourly earnings is therefore a function not only of misreporting of earnings (annual, weekly, or monthly) but also a function of the reporting of hours worked, the later being subject to high levels of response error (see Section 6 4) An empirical investigation that has not been reported to date is the comparison of the accuracy of direct reports of hourly earnings by household respondents with the hourly earnings reports calculated from reports of earnings and hours.

6.2 Transferprogram income
Transfer program income can be categorized broadly as falling within one of two categories: relatively consistent recipiency status and income levels once eligibility has been established, and highly volatile recipiency status as well as income As with most other episodic events, we expect that relatively stable behavioral experiences will be reported relatively accurately whereas complex behavioral experience (e g , month to month changes in the receipt of AFDC transfer income) would be subject to high levels of response error Respondents experiencing complex patterns of on/off recipiency status will most likely err on the side of failing to recall exceptions to the rule (e g , the two months out of the year in which they were not covered by a particular program).

62 French (1998) uses the PSID-VS data to correct estimates of the inter-temporal labor supply elasticity for measurement error Within the context of his model, the covariance of the change in hours and the once lagged change in wages scaled by the variance in the transitory component of wages should give an estimate of the inter-temporal labor supply elasticity The covariance terms involve covariances between current and twice lagged hours and wages French allows for individuals to under-report the transitory component of wages and the transitory component of hours caused by the transitory component of wages to be under-reported, and for errors in wages and hours to be correlated, but otherwise that measurement error is classical With these assumptions, French is able to use the PSID-VS to correct for measurement error His results suggest that measurement error can not explain the failure of inter-temporal labor supply effects to explain short term movements in hours.

Ch 59: Measurement Errorin Survey Data

3771

Depending upon the usual status quo for these respondents (receipt or nonreceipt), both under and overreporting may be evident In addition, for some transfer program income subject to social desirability bias, we would hypothesize that respondents would err on the side of underreporting receipt Finally, misunderstanding as to the exact type of transfer program income received by the respondent may lead to the misidentification of recipiency, leading to underreporting of one type of income receipt and a corresponding overreport of another type of income receipt.
For most surveys, the reporting of transfer program income is a two-stage process in which respondents first report recipiency (or not) of a particular form of income and then, among those who report recipiency, the amount of the income One of the shortcomings of many studies which assess response error associated with transfer program income is the design of the study, in which the sample for the study is drawn from those known to be participants in the program Responses elicited from respondents are then verified with administrative data As noted earlier, retrospective or reverse record check studies limit the assessment of response error, with respect to recipiency, to determining the rate of underreporting; prospective or forward record check studies which only verify positive recipiency responses are similarly flawed since by design they limit the assessment of response error only to overreports In contrast, a "full" design permits the verification of both positive and negative recipiency responses and includes in the sample a full array of respondents Validation studies which sample from the general population and link all respondents, regardless of response, to the administrative record of interest, represent full study designs These would include the studies by Bancroft (1940), Oberheu and Ono (1975), Halsey (1978), Hoaglin (1978), and the more recent studies by Marquis and Moore (1990), Grondin and Michaud (1994), Dibbs, Hale, Loverock and Michaud (1995), Moore, Marquis and Bogen (1996), and Yen and Nelson (1996) The findings from the other studies cited in Table 2, many of which indicate a preponderance for underreporting by respondents with respect to receipt of a particular type of income, are to some extent an artifact of the study design Rather than interpret the findings from these studies as indicative of a consistent underreporting bias on the part of the respondents, a more conservative conclusion may be to view the findings as illustrative of the types and magnitude of errors recipients can make with respect to program receipt.
There are several different ways of summarizing the frequency of reporting errors, which can give very different impressions of the accuracy of the data One is the fraction of cases for which interview and record data disagree Another is the difference between the fraction reporting receipt in the interview data and the corresponding proportion according to the records, which is the extent of net under or overreporting. A third is the pair of conditional probabilities, rOe = Prob (interview = no I record = yes) and r 0 = Prob (interview = yes I record = no) that determines the extent of bias when recipiency is used as a variable in a regression (Section 2 5).
These three measures are related: the probability of disagreement = JroI + (1 Jr) r10, and net underreporting = 0=r1 (1 r)r110 The probability of disagreement tends to be lower for programs with low true participation rates as long as zr01 > r1o;

3772
0
p0
o
E 0 . 0
n v O a)
E
a)

0o rI~I ,a0m

0b:e

cO

a

B

--a~

0

*Oc

._

rc

a)

o

, ' a)o
11 C 1 C

C

C

a5,,)5

a

o
U '22
o0
a) C)
0Ci, , p.
be 0
01M c0
U
o
.2
0
.

-0

'2

U 0

0 Q

CO

._

CO

.5

¢

ea

00

kO

&

V

a) a) II

e

N

o WXCO

£O aC

°
o
o \° beg')- g -

0

VN 0)

C110 C 4N O ~;

£O

O

N5

-0

I be

J Bound et al.
a)
I, :e C
csaorO)Z-
0z 0i a)

00
O'~ O
E°

~t

~ 02 iig 2
v ae ) a O :c

~ _ Oo
~0

*O C)

.=

._
¢.Q5

¢

A Iz

0

U

c)

Q

U c

0

.

C0.

Eo C

7° Q

(,5

F: J

C

£

c

.o

'0

ON ON

'0

.

.0

5be

c

Ch 59: Measurement Error in Survey Data

3773

I

CD P

.E
Ia
U
I3I 05 s00 .

0

0

r.4)0

eID

0)

0 CO

P 0

a0)

0 0

I

E

0

0)

. o 0

0

c

.o0

CcO

=

,0

o03 0

ce 00 0)

o

OE

Q OCOa 0

oo

Ca~ O

^ 11

1i0i 1

I
-

0)

C~O u

> a 11 *O 0)
1111 CL

0

0Q0

EOQ o0-a) .0

o

O ux

q

5

c

(

0 0)

0

O=

Eo

)0)a)°0a°OC-

o) ~
· Ea~

. U 0)

II

I 0

0)
g." b
o>j

"0 Ca ) O O

4_ 0)0)

CO) )0 ., ,b

0)0

.g
IL

4=V O-

P.CE,

I

a

r:E i

v,

ga

u ,·
c
2o

,Ca))

0

~ 0, 005

o

E -.

0) '

Oo

_

Ce

0
~3 XC- CCa-

0

OC

0

a·

0

9m

0)

<· ,

OC d

4

0E

Cl

O

~O B

¢1~r
.5

.5

0O
~ 20 O

S:~

E 0) i ,,
40)
40) CO
o 00

a

CO

0)-.

Co

0)0

cCO

S

gCO

CO

0) 00))

ra 0Q
0)
.5
0) cn vO
co
0)
M ~ a
CO to MZ

E
0

L

45-

cc~

0)a

C

. o) 00 O C,

-
ox
S
0U

3774

0)0

0)

aO

00

" 00 O

a

0.0,

a

a~ 0

-C~aO

I

*

a

J Bound et at.

o~ -a

,~

*c o '

'' i' f'

°¥

a a5zc.
so

I 0)o ·B
0)CO 0)
.O

Ir ~J

0)P

Oa a

Ct

c

a -a

0a

0

0

-0

g

oO

a,·e

> 'O

>C

S

0)

-

>S D E W v < DLo::

o

0)
0
a
S0

nO

0)0

C0

0)uu

0I
Qo
0
0
C 00 2 '1 04

C aa

0C) 4O

.

U

m~~~~~~

%:-.
c-

O E

OC _t

a

w oN O
F4 "

i

o

O O OO

O~E

g) C

_

O

0,
g

~~~~~E~~BI

~

~~

g~~~ E

Ch 59: Measurement Errorin Survey Data

a
O ,
aa

a
C2 P o -a

x3 a

a) C
a

a

0

0,

aa

ea8

8

ao aa

aa

C-(

a) 004 ~a)

~0 '#

af

-

100 f'#2 O

oa S ;-Ca

a,

a

Qa)

ma) a)

C-~

t:

B0

o

*O O

E

Oaa~~~a
a

~

aa I

M0 0) O

a)

a

0

oao C-)

aO a)
6)Ea
~0 m
*O a
aC) C C
a~
a) C

"B o "-

a::
Ca)
aa
9." .0 a
aC)
F- CT
,c
aVr.

-p

a

0a) 11

a

E

i=

8a

x

a a)

l 91

a
. aa
Ca
.

3775

Ca

a ,0
a)
a
o

0
P

ac)

a)

ov
~ a
U a. aO
.E a)
a
r~. a
a) a)
a_

C

a

a0)

-a ) O a)

a

cq C
a-D

Ct

a
y

1a4 a a 2

a)

E aa-a.

C4 ) ,a-c eu a)-g
a a*

a
F
a aoo

U
a
io
a8a 1
a

3776

oo"
00 o oO
0000 0 Ii II
rOI eI2O
00

i_,c

X00 t
'c 0

.S 0

e

0 0

0

,.

'0 g:

0

0

0

0 9

"O

Wo

0,

0, 0

0

0

0

-e-.

0,

i
000 00) 0o0
0

0

0,

0

_O

P,

0,
a0

m

M

0U

00

I

g
-0o

R

J Bound et al.

Ch 59: Measurement Error in Survey Data

3777

relatively high values of both Jr01 and JroOcan lead to near-zero net underreporting but imply significant biases in a regression context.
Focusing our attention first on reporting of receipt of a particular transfer program, among the full design studies, there does appear to be a tendency for respondents to underreport receipt, although there are also examples of overreporting recipiency status For example, Oberheu and Ono (1975) report a low correspondence between administrative records and household report for receipt of AFDC (monthly and annual) and Food Stamps (lo O 2, -0r1 3), but relatively low net rates of under and overreporting 6 3 In the study reported by Marquis and Moore (1990), respondents were asked to report recipiency status for eight months (in two successive waves of SIPP interviews) Although Marquis and Moore report a low error rate of approximately 1 % to 2% (not shown in table), the error rate among true recipients is significant, in the direction of underreporting For example, among those receiving AFDC, respondents failed to report receipt in 49% of the person-months Underreporting rates were lowest among OASDI beneficiaries, for which approximately 5% of the person-months of recipiency were not reported by the household respondents The mean rates of participation based on the two sources suggest little difference; absolute differences between the two sources differed by less than one percentage point for all income types. However, the rareness of some of these programs means that small absolute biases mask high rates of relative bias among true participants, ranging from +1% for OASDI recipiency to almost 40% for AFDC recipiency In a follow-up study, Moore, Marquis and Bogen (1996) compared underreporting rates of known recipients to overreporting rates for known non-recipients and found underreporting rates to be much higher than the rate of false positives by non-recipients They also note that underreporting on the part of known recipients tends to be due to failure to ever report receipt of a particular type of income rather than failure to report specific months of receipt.
In contrast, Yen and Nelson (1996) found a slight tendency among AFDC recipients to overreport receipt in any given month, such that estimates based on survey reports exceeded estimates based on records by approximately I percentage point Oberheu and Ono (1975) also note a net overreporting for AFDC (annual) and Food Stamp recipiency (annual), 8% and 6%, respectively.
The studies vary in their conclusions with respect to the direction and magnitude of response error concerning the amount of the transfer, among those who report receiving it Several studies report a significant underreporting of assistance amount le.g , Livingston (1969), Oberheu and Ono (1975), Halsey (1978)l or significant differences between the survey and record reports lGrondin and Michaud (1994)l. Other studies report little to no difference in the amount based on the survey and record

63 Oberheu and Ono's sample is restricted to low-income households This is likely to lead to a larger value of Jrol than would be obtained in samples with the full range of household incomes For example,
Jro would be increased by mis-reporting other transfers, and these would be more common in low-income households.

3778

J Bound et al.

reports Hoaglin (1978) finds no difference in median estimates for welfare amounts and only small negative differences in the median estimates for monthly Social Security income Goodreau, Oberheu and Vaughan (1984) found that 65% of the respondents accurately report the amount of AFDC support; the survey report accounted for 96% of the actual amount of support Although Halsey (1978) reported a net bias in the reporting of Unemployment Insurance amount of -50%, Dibbs, Hale, Loverock and Michaud (1995) conclude that the average household report of unemployment benefits differed from the average true value by approximately 5% ($300 on a base of $5600).
In general, studies that assess the accuracy of transfer data from household surveys do not provide analyses of how such errors affect the parameters of behavioral models. An exception is Bollinger and David (1997), who estimate a parsimonious model of response error from validation data and then combine this information into a model of Food Stamp participation using a broader sample They find that estimated effects of wealth and predicted earnings are increased by such corrections, though they note that these results depend on the model of response error based on a relatively small validation sample (N = 2685, but with only 181 participants) They also note that low income households are much more likely to mis-report Food Stamp receipt because they confuse Food Stamps with other transfers they receive; high-income respondents do not have other transfer programs to confuse Food Stamps with Thus, while many examples of differential measurement error in survey reports of transfers are due to deliberate under-reporting, Bollinger and David's example shows that differential errors may also occur inadvertantly.
Studies of receipt of transfer payments are often interested not only in which groups are receiving transfers and how much they receive at one point in time, but also in the duration of receipt, and so in the transitions into and out of recipiency Marquis and Moore (1990) matched data from SIPP interviews to administrative records for major transfer programs They find that the number of transitions (those starting to receive benefits, and those whose benefits end) are overstated by interview respondents for some benefit programs and understated for others A more consistent pattern is that such transitions are over-stated when one compares the last month of the reference period of one interview with the first month of the next the so-called "seam" and understated when one compares reports for two months collected in the same interview 64.
Comparing the findings for transfers with those for earnings suggests several broad conclusions First, there is evidence of under-reporting of transfers, in contrast to the approximately zero-mean errors we found for earnings, and such underreporting seems more important for AFDC and other public assistance than for Social Security This is quite consistent with comparisons of aggregate estimates based on survey reports to

64 The finding of more transitions at the "seam" than at other points in a retrospective history pieced together from a series of interviews has been documented repeatedly lMoore and Kasprzyk (1984), Burkhead and Coder (1985), Hill (1987)l.

Ch 59: Measurement Error in Survey Data

3779

independent estimates of aggregate amounts received 6 5 Second, both non-reporting
and underreporting by those who report receiving positive transfer benefits contribute to this underreporting, though it is hard to draw firm conclusions about the relative importance of these two sources of error Third, accuracy of reports for individual transfers is reduced by mis-classification; i e , respondents who report receiving a transfer, and may even report the amount correctly, but incorrectly identify the program that provided the benefit Fourth, the focus on extent of underreporting in most studies leaves us with very little evidence on the likely effects of errors in reporting transfers when benefits from individual programs are used as either dependent or explanatory variables in behavioral models 66.

6.3 Assets
The literature on accuracy of reports of individual assets (and so, implicitly, of net worth) is similar in important ways to the literature on transfer income Comparisons of aggregate values based on survey reports to independent estimates of these aggregates suggests that underreporting is likely to be a problem lCurtin, Juster and Morgan (1989)l 67 The literature has therefore focused on the extent of such underreporting, rather than on the variance of the error relative to the variance of the true (record) value, or the correlation between errors and true values.
A limited number of studies have focused on the assessment of measurement error related to the reporting of assets and only one of these, the study by Grondin

65 In 1990, CPS totals amounted to 97%of independently-estimated levels of Social Security and railroad retirement benefits, and 89 % of Supplemental Security Income payments In comparison, CPS captured only 72% of AFDC and 86%of other public assistance lU S Census Bureau (1993, Table C-l)l. 66 Since benefits received depend in part on choices made by the recipient, analysts often use some sort of instrumental variable procedure to account for this endogeneity; for example, the level of AFDC benefits available in a state might be used as an instrument for the reported benefit level While one might hope that instrumenting would undo the bias from measurement error as well, we have stressed that this hope depends on the reporting error being "classical" Given that benefits are bounded (at zero) and zero benefits are in fact common, we suspect errors are likely to be mean-reverting Particularly for programs such as AFDC where reporting seems least accurate, the effect of reporting error on the consistency of IV estimates deserves explicit discussion. 67 Curtin, Juster and Morgan report that the 1983 Survey of Consumer Finances produces aggregate net worth estimates that are close to those based on external (flow-of-funds) sources This "adding up", however, reflects a balance between substantial discrepancies on particular wealth components (e g , SCF shows "too little" liquid assets but "too much" housing), and a close look at these discrepancies suggests that the external totals are often not very accurate benchmarks for the survey data (e g , because of difficulties in the flow-of-funds accounts in separating household and business asset holdings) However, alternative wealth surveys show substantially lower levels of net worth than does SCF (PSID and SIPP being roughly 80 and 60% of SCF, respectively) Juster, Smith and Stafford (1999) report that wealth surveys conducted in the 1960S typically found about two thirds of the net wealth found in the external sources CPS reports of interest and dividend income were 51 and 33% of NIPA totals lU S Census Bureau (1993)l Thus, comparisons with external totals suggest that under-reporting is likely to be the norm, although failure to sample the wealthiest households also contributes to these discrepancies.

3780

J Bound et al.

and Michaud (1994), focuses specifically on interest and dividend income generated from asset ownership Several studies conducted during the 1960S examine the extent to which respondents accurately reported savings account and stock ownership, comparing survey reports with financial institution reports for a sample of respondents known to own the particular asset of interest As noted above, reverse record check studies by design limit the detection of response error to underreports Hence, one should be cautious in drawing conclusions concerning the direction of response error based on these studies As noted in Table 3, between 5% and almost 50% of respondents fail to report existence of a savings account; 30% of those who own stock failed to report ownership The high rate of underreporting is also evident in the full design validation study reported by Grondin and Michaud (1994).
Among those who report ownership of a savings account or stocks, the findings are mixed with respect to the accuracy of account amounts Maynes (1965) and Ferber, Forsythe, Guthrie and Maynes (1969a) report a small amount of net bias for reports of savings account amounts (-5% and 0 1%, respectively), while Ferber, Forsythe, Guthrie and Maynes (1969b) report that 80% of respondents are accurate in their reports of stock holdings In contrast, Ferber et al (1969a) indicate that there is a large degree of response error, with only 40% of respondents reporting the account amount within 10% of the true value Similarly, Lansing, Ginsburg and Braaten (1961) indicate an absolute discrepancy of almost 50% between financial records and household survey respondents' reports of saving account amounts, a discrepancy similar to that reported by Grondin and Michaud (1994).
A few studies attempt to validate survey responses to questions about the value of owner-occupied housing, a very important component of wealth for most households. Kish and Lansing (1954) find that owners' estimates are close to appraisers' on average (mean discrepancy = 4%) but the two estimates differ by 30% or more in a quarter of the cases Scrutinizing cases with the largest discrepancies which a typical survey, without validation data, could not do they find that the largest discrepancies were due to coding errors (e g , omitting a zero or misreading a lead digit in moving from the interview form to the data record) Rodgers and Herzog (1987) find that differences between household estimates of assessed value and property-tax records of assessed value are positively related to the record value This contrasts with the negative correlation they find for other variables, and which is typically found in other
studies. Related perhaps to respondents' difficulty in providing accurate responses to
questions about asset holdings is the substantial level of item non-response it is not uncommon for 30% of those who report owning an asset to either refuse to provide or claim to not know the value of the asset lJuster and Smith (1997)l In response, surveys have increasingly used "unfolding brackets": questions of the form "would it be more or less than X", where a "yes" ("no") to the first such followup leads to a second with a higher (lower) value of X Thus, respondents unwilling or unable to provide a dollar amount are induced to specify a range in which they believe the value of their asset holding lies Since those who are initially unwilling or unable to give a dollar

Ch 59: Measurement Error in Survey Data

3781

.o
\
o
C

o
o0-' o v?
II 0 4.1
.91 E
t QQ

o
t Eo o o E: E '
11 (

ou

Pb'~

."1
gte 08
W8) C r-9,

o

o

0

+

11, _ 1

O gm 0

0.,> o

I

D 1 -7;O

dU

. O 11

··' Y

o-o'

8O

VEc c XE r

·t~o 1t1 . II

O~

Xo o ~ ~-,,

8

) ID

>

o ()r- ,{> 1

8= f

4,.~

ij

z
t

8 PE

"o

o
ds~~~~9%~95 s~ w,~~t

O ae,R E

0

E

z

I e Q rn~
9E

._
0
._

o

c

Og Id

ao 9

UcE

¢

=8 e

Me

r0.

E'j

t-

9

ZL-,

c

,= E~

Ic.

a)

0V

·c- I 9

Ji m _E

s

c
v.I)

0 .N 9 c r -8
-e
.9 c
.i
-VC:

*VI

990

00 cX .0

U

Um

c

r

C,

V r.

r. 2

7c9

.C CO

c\

I
o\ W.

3782
0
r0q 0
0
0
uIU
Lo 0
0'0
04 10
't
i

6,
U o. cU 4l~
P oO oOo -
·,,LO2E
vQ
P
0 0 6 c >sO a c
*_ rte-o
19 c>

0

zZ:

0

CQa

,e

.2

.o_

dc

RM

.E.

rU
o
cCa .c

UO a,
C-
~2 r I .0- o 1L Id

.E
*oE t
,-
*c
U
, 04 aI -o0.o
O 1
0 *-Ca
U~ O CO
a
.0r ,\
c
0,.Ca) .0

J Bound et al.
U U
0
o 0e
0 x, -Ca Ca
DII
v
II* '

Uo

*O 0 U
U
0 o 11 U
o o
o

0

s

c

r-
o0oc

ca o* 0

Ch 59: Measurement Error in Survey Data

.

5-

;

dd

E

o 5S

C,

a
Co
c
.0
oo

ig

6C) o~ Co

B i asB

II O

~ E )

66

UO

._

O

P,

ez

cQ

3

J

s

C

O

a

'

=;

m

e

o

C

O~~ z

rl

0

Co
H 0r

p

t)

r

)

~~ -E:

B

~ o

))

0I

5 B

Co

U

6)

Sa
4)
C-
._ .<

4 Co
,c
6)

._

,

e9

= oa

.Ct

a~ A\a

p0,~

0.P
E °8

0a.

a

6)

,

_t

t

m

3783

3784

J Bound et a.

value for the asset tend to be those with higher true values 68, brackets help to reduce the underreporting typically found by comparing asset levels as reported in household surveys to external (aggregate) values For example, Juster and Smith (1997, Table 8) report that bracket-based imputations produce 6-12% higher estimates of mean net worth than imputations not based on bracket information.
However, experiments in which the bracket boundaries are varied randomly find that the distribution of amounts that comes out of the brackets depends on the bracket boundaries themselves For example, in one study the fraction of cases with savings accounts less than $10000 was 49% with the first bracket question set X equal to $1000 but only 37% when the first bracket question set X = $20000 This, in turn, has led to several attempts to obtain "corrected" estimates by jointly modeling the determinants of the asset value and the effect of the (randomized) bracket boundaries le.g , Hurd et al (1998), Hurd and Rodgers (1998)l Both studies find responses are pulled toward the boundary in the first bracket question Setting bracket boundaries with an eye toward maximizing the fraction of the variance in the asset that can be accounted for by the categorical responses will tend to place the first bracket boundary toward the middle of the distribution of the asset in question lHeeringa, Hill and Howell (1995)l Consequently, it is likely that the error induced by "anchoring" effects is likely to be mean-reverting in most applications Lacking validation data, however, it is hard to say much about the effects of using bracket-based imputed values in regressions that use wealth as either dependent or explanatory variable.

6.4 Hours worked
Obtaining validation data for workers' reports of how many hours they work per week has proved more difficult than obtaining earnings data In general, the administrative records income tax, unemployment insurance, and Social Security payroll tax used in many of the studies in Table 1 include no comparable data on hours worked. The largest Federal establishment survey of payroll and hours collects hours only for production workers in manufacturing and non-supervisory workers in other industries. A Bureau of Labor Statistics study that considered obtaining hours information for all workers noted "Hours data are less available than total payroll for most categories of workers" lU S Bureau of Labor Statistics (1983, p 22)l.
While the number of empirical investigations concerning the quality of household reports of hours worked is limited, one finding consistently emerges Regardless of whether the measure of interest is hours worked last week, annual work hours, usual hours worked, or hours associated with the previous or usual pay period, comparisons between company records and respondents' reports indicate that interview responses overestimate the number of hours worked The findings from seven studies in which

68 Hurst, Luoh and Stafford (1998) attribute to Donald Trump the observation that those who know how much their assets are worth can't be worth very much.

Ch 59: Measurement Errorin Survey Data

3785

household reports of hours worked are compared to employer's records are reported in Table 4; all of these studies were also represented in Table 1 Findings from three studies in which the quality of the reports of hours worked is compared to time-use diary estimates are also reported in Table 4.
Carstensen and Woltman (1979) compared reports of "usual" hours worked per week They found that compared to company reports, estimates of the mean usual hours worked were significantly overreported by household respondents, 38 4 hours vs 37 1 hours, respectively, a difference on average of 1 33 hours, or 3 6% of the usual hours worked Similarly, Mellow and Sider (1983) report that the mean difference between the natural logarithm of worker reported hours and the natural logarithm of employer reported hours was 039 They also report that the measurement error has a non-trivial variance ( 064) but do not compare that variance to that of either the interview or the record hours variable.
In their reanalysis of this same data, Angrist and Krueger (1999) report a variance of the difference in In hours of 083 This compares to the variance in In survey hours of 195 or a signal to total variance ratio of roughly 8 Again, mean reversion will tend to reduce the implied attenuation to less than the 2 this number suggests.
Duncan and Hill (1985) find that worker reports of hours worked in the previous year (from the first wave of the PSID Validation Study) exceed company reports by 90 hours per year, nearly 6% of mean hours The average absolute error was 157 hours Recall of hours worked two years ago were less accurate, as expected, with a mean absolute error of 211 hours More readily related to the discussion of biases in Section 2 is their finding that the ratio of error to record variance is 37. Bound, Brown, Duncan and Rodgers (1989) also find hours are overreported in the second wave of the Validation Study, though the mean error for In (annual hours) is only 012, which is not statistically significant However, the variance of the error is about 6 of the variance of record In hours Once again, there is evidence of significant mean reversion (correlation between error and true hours of- 37) Rodgers, Brown and Duncan (1993) consider various time intervals hours worked in the previous year, hours worked in the previous pay period, and "usual" hours worked. They find the correlation between interview reports and company records is 61 to 66 for all three measures; and, for all three measures, the correlation between error and company records is - 31 to - 37 It is worth recalling that the PSID Validation Study obtained data from one manufacturing firm with few part-time workers and therefore, limited variation in hours per week, but (at least at the first wave) less than full-year employment for many workers Moreover, hours data were unavailable for salaried workers Barron, Berger and Black (1997) report a correlation between employers' records and respondents' reports of hours last week, 769 ; but this correlation falls to .61 for In (hours).
One might wonder whether, in the case of hours, the company reported values should be treated as "true" For those who are paid by the hour, accurate recording of hours is essential for correctly paying the worker, and for those who "punch a clock" the company presumably has at least accurate records of the worker's coming and going.

3786

J Bound et al.

*^ ,\

~ o i

e

3i

C,

CO O

se

*aO t

00

"

m

%

a.E
0 CO O

0

-0)~OS~

"i

g0 Y EG O

2S > CO° °
e~EI

O COu

C 0 i.

tO 0)Q X ;c C

S a0)

O

O_d~ oo8i O

o

;D

S a S Pl
U AQ N

o

CO

)0 Lo3
20

ce
o 0

0 ._ 0

II

E

¢

v

;n

C0)

2O O~ '
o
0. ~Ot3d
00 .p
;0 Ifi

0
0
UE

03

C

0

C

*O

0

U

00)

r

0)

C

. r-

U-

0

10 Z

-

DO C/ 0)
a
oE~
0

q
Ci
2O
A o

I~
^~~f oC
~"ea

'
a Z II a
7

O

'ifB O

~~ ~~'~~ I c

W 2p 11 O

0) C

0: CO E>E

oO

~o

~ 0) 80

~

a) e 2 0) O ,

~ o
20)

O

2

C II O

O O

-a~-g

OO

. ~m~ 02) a 00
o
a
0
U

0)
0o)
0\
2
8 mO
0)

Ch 59: Measurement Errorin Survey Data

3787

o v
I

D\ i Fl

o

o v
5.

o3

_
II

U

.

?U

>U

UU
UU
0.0,

00 .~

C C *CC 00

.00

.

0. .-

-Z zD

o Q 0 Q

5a 0

0

V

cn 0
U 0

U
.9
r.

0

el .

0Q I

u

4

.0

i

'0 '0

0

i

0t,-d

c

\

~'0

a

~C B S z Fp

o

O °V

'4

O

'0 Q

"'0

6o o

,

·O

CO

QUOI

0i

-0

3

eJi

Ei -~

O \ O\
77
r~c 11

~B00t S

c°cv

E'0

OO

0}

E r3
9

4-ep O '

I'

o~P

o

c

£

'0

7j
'0
EE
=0C O rO,.
U
OO
e i; r' t 3c }*5 =

00

m
0O O Q
U0 x0

U0.

0

0U

a

m

00.

U

9U

c

c

U '0 A

3788

J Bound et al.

BEE=Y E

.

t

a Q o °

Mo C
SO

S

a

an

00

rao r>r

O O O Oo O e M

X¢

Uai

-,

O

Bo S In-z

~

Q<Ug>A Ie

4

v, 9

0r. r

oz

4

o~ ~

nl

't

134 ~~eo

2

40

lu

9 ON

't-

J.

0
30a, O

ot S'
CY

Ch 59: Measurement Errorin Survey Data

3789

0

O

.0 ~~
o
0 u' : ,qe O
.
e
0)
2

$ °e~ OO 0
%
-o

0~

i

o 8 ,-

O
U
O
1 r5 o

.

0

u

0

0* S

0

0 I

g) ) )

0
.2 > > a

0)- - -

O

0~0)~)~

~

~O " 1 ~~~

e~25g

)Si

S
39

~~~~~~~~~~.

E 0)

0

0 0) IO
5

.0
~
0)~~~~~~~~·

~~~g 0.0
0)v0 E
O~-
VS5 0)

0

0

e

op

At 5 ~~~~~~~~~~~~~~~e

3790

J Bound et al.

For other workers, the link between hours worked and pay is much less tight, and as noted above some employers may not even keep records of their hours.
Three of the studies represented in Table 4 take a different approach to assessing the worker's report of hours worked In addition to CPS-like questions on hours worked per week, the time use studies obtained time diaries from respondents These diaries involved detailed reporting of activities at each time in the previous day While only a few days' time diaries were collected from each respondent, when aggregated across respondents, work hours reported in the time diaries should add up to those reported in CPS-like questions All three studies in Table 4 that used time use data lStafford and Duncan (1980), Hamermesh (1990), Robinson and Bostrom (1994)l report that CPS-style questions lead to higher estimates of work time than are obtained from the time diaries The discrepancies are, if anything, larger than those between worker and employer reports, and the gap between CPS-like questions and the time-diary based estimates is growing over time.
Evidence on the importance of measurement error in interview-based measures of change in hours is available in the studies based on the PSID-VS Duncan and Hill (1985) find that constructing the change in annual hours by differencing reports for two previous years asked in a single interview (the first PSID-VS wave) leads to a relatively noisy measure, with an error to true variance ratio of 8 While sizeable errors in changes calculated in this way are likely to be reduced by a positive correlation between the errors in the two years lRodgers, Brown and Duncan (1993) report that correlation as 36 in the second PSID-VSl Bound, Brown, Duncan and Rodgers (1989) calculate the change in In hours as one would in a longitudinal survey, as the difference between the logarithm of 1986 hours (reported in 1987) and 1982 hours (reported in 1983) Whether measured by the error to true variance ratio, the correlation between interview and record values, or the regression of record value on interview, the change in hours data are slightly more reliable than the levels data.
Examination of a model with earnings as the left-hand-side variable and hours worked as one of the predictor variables indicates that the high correlation between the errors in reports of earnings and hours (ranging from 36 for annual measures to .54 for last pay period) seriously biases parameter estimates For example, regressions of reported and company record In annual earnings on record or reported In hours, age, education, and tenure with the company provide a useful illustration of the consequences of measurement error Based on respondent reports of earnings and hours, the coefficient for In hours is less than 60% of the coefficient based on company records while the coefficient for age is 50% larger in the model based on respondent reports In addition, the fit of the model based on respondent reports is less than half that of the fit based on company records (R2 of 352 vs 780).
The small number of studies validating worker reports of work hours against employer reports provide little guidance on the relationship between errors in reporting hours and other variables Mellow and Sider's (1983) regression explaining the difference between the two sources indicates that professional and managerial workers were more likely to overestimate their hours, as were respondents with higher levels

Ch 59: MeasurementErrorin Survey Data

3791

of education and nonwhite respondents In contrast, female respondents tended to underreport usual hours worked.
In contrast to the findings with respect to annual earnings, we see both a bias in the population estimates as well as bias in the individual reports of hours worked in the direction of overreporting This finding persists across different approaches to measuring hours worked, regardless if the respondent is asked to report on hours worked last week (CPS) or account for the weeks worked last year, which are then converted to total hours worked during the year (PSID) The consistent direction of misreporting coupled with what appears to be a trend toward increasing discrepancy over time suggests that (1) respondents misinterpret the question (monthly CPS); (2) incorrectly account for weeks worked (March CPS supplement and PSID); or (3) overreport as a result of social desirability bias in the direction of wanting to appear to be working more than is true The monthly CPS questions concerning hours worked ask the respondent to report the total number of hours worked, not hours spent at the employer's site or hours of paid work One potential source of error may be a difference in the underlying concept of interest, with users of the CPS data examining hours of paid employment and respondents indicating total number of hours, regardless of location or pay The approach used in the March CPS and PSID to obtaining hours worked requires that the respondent report the number of weeks worked in the previous year The March CPS question even includes the word "about" suggesting that the respondent can provide a rough estimate of the number of weeks worked Here we would speculate that once again, the bias is in the direction of errors of omission related to exceptions to the rule That is, if the respondent has been fully employed during the previous year, short spell deviations will not be reported Either approach to the collection of hours worked are subject to social desirability bias, if respondent's perceive the reporting of more hours as socially desirable.

6.5 Unemployment
Concern about the reliability of survey reports relating to unemployment focuses on a number of distinct but related issues One question is how accurate are reports of current labor force status, in which individuals are classified as employed, unemployed, or not in the labor force A related issue is how errors in reporting labor force status in one month affect estimates of various labor force transitions (e g , leaving unemployment by finding a job or leaving the labor force), and estimates of the duration of spells of unemployment that are calculated from such transitions Other studies have focused on the accuracy of retrospective reports, including the number of spells of unemployment, the duration of such spells (including on-going spells) and the total length of time unemployed in a particular period Unlike the variables considered in previous sections, there are no employer or administrative records that allow one to verify whether non-working individuals are unemployed or not in the labor force.

3792

J Bound et al.

6.5 1 Current laborforce status, and transitions to andfrom unemployment The most widely used data on current employment status come from the Current Population Survey, which asks a series of questions each month and on the basis of the responses classifies individuals as employed, unemployed (roughly, looking for work), or not in the labor force (not working and not seeking work)69 Correctly classifying individuals involves taking proper according to official definitions account of
complications such as wanting to work but believing none is available, search for a new job while on paid vacation from another job, school teachers on summer vacation, etc Concerned with the accuracy of these responses, CPS regularly re-interviews a subsample of its respondents, re-asking the standard questions (about the reference week covered by the original interview) and attempting to reconcile any differences that the re-interview uncovers.
Several of the studies in Table 5 report estimates of the probability that an individual initially classified as unemployed (or employed, or not in the labor force) will be judged as unemployed following the re-interview process A consistent finding of these studies lPoterba and Summers (1984, 1986), Abowd and Zellner (1985), Chua and Fuller (1987)l is that 11-16% of those classified as unemployed are likely to be misclassified, with most of the re-classifications being to not in the labor force rather than to employed 70.
A distinct but related problem with the classification of labor market status is that those in households that are interviewed by CPS for the first time are more likely to be classified as unemployed than they are in later months There is also a weaker tendency for fewer of those in their sixth and seventh months to be counted as unemployed 7T.

69 The CPS is collected each month from a probability sample of approximately 50000 households;
interviews are conducted during the week of the month containing the 19th day of the month and respondents are questioned concerning labor force status for the previous week, Sunday through Saturday, which includes the 12th of the month In this way, the data are considered the respondent's current employment status, with a fixed reference period for all respondents, regardless of which day of the week they are interviewed The design is a rotating panel design in which households selected for participation are interviewed for four consecutive months, followed by eight months of no interviews, and then interviewed for the same four months one year later In any one month, 1/8 of the sample is being interviewed for the first time, 1/8 for the second time, etc. 70 Poterba and Summers, and Abowd and Zellner take the reconciled status from the re-interview
as the "true" status Chua and Fuller note that initial reports on the re-interview survey are more consistent with the initial CPS interview for the fraction of the sample where reconciliation is carried out than on the fraction where it is not This suggests that, contrary to instructions, those conducting the re-interviews are aware of the initial CPS response before the respondent has answered the initial re-interview status Poterba and Summers speculate that knowing the initial report leads re-interviewers to minimize discrepancies (and hence the work required to reconcile them) This would imply the reconciled responses are biased toward the original reports, and so taking them as true leads to underestimate the extent of error in the regular CPS. 71 Bailar (1975) reports that in 1968-69, the number counted as unemployed was 20%higher for those in their first month than the average regardless of month This fell to 9% in 1970-72 lBailar (1975)l and 8% in 1974-83 lSolon (1986)l Over these same time periods, the number counted as unemployed is 5-7 %lower in month 7 than overall, and 3-4%lower in month 6.

Ch 59: MeasurementErrorin Survey Data

z

*O

0

.0

30

_e S

c

Is

0Q0 E i_

.5
0) C

i;~

O

"I It0)-

'0
m- ,;
N N=

¢0

a8g

0 U

m'

09 Af V

E

o

~ o otc
0)
0

0

0)
0 2

0

a3 3^

EE 8E

_o

i Ei

c

0

I

z m 0)

0

0

0

2-

0

0

~O d

0 0

0) 0).

-8 05

) Ooa

.r

2i

t9

0)

z 0)

0

r

D
E

c-
0 00 t 0Z

c

e

oi

c
C-

0z
Z,-
I0I.z-) .,-
Q

030 E
~~ 0)O0

E
Ovk,

E '4 CE=O

0 c)

20

.0)II~

4.o a c

z

00 0)

0c

~ p

*> E

22 OE 0O) )

ao 000 .0

0) 00

vo

C

" .0 00)

" B 0x)

0Z Us

1 sO

3793

3794

J Bound et al.

4o 0 A 0

0c

.

c

4)

0

.45 UO

0a
2 .1 A
a 4u) c 04 e
A
0

.cE 4)

r~~ON o O

4)

.2 ~~o-o$ ~

Co .2

~~P"~ "~

.2

O o,:

)

0

C-

0,

Oo

4)

H
0 0a s~
a-

,g

$

oo1oo ,0 ~·

Z:: 00z0 U4)

-4)

\mm

,A
Wg Un-a

P

ei Oegb

C(

B'

~~)

d

,r Com C

0:

OC

4o0.

A

E-

C04 .O

o

0

00

S

.Q~~Q2a

2 gM

o

aE

S0

C(

40 -SA o

S \ \\

o

C 'L 8 40

o6

e~~~

e

O ocO .110

2o

a;

4) 40

4)8

82

v2

.O

gO o

~· 0 4)
4) OCo

2

e

4) 43

48 .^, ,
4)_ Ceo CC

H

,20

84)0 O 4)-

20 05

00
~B Vr
ao
Er
½·

~o~J~N~ 0. U i3 _ ,v

o f

_

c 94 '

4 4) OC'

gs

900

0 .4
zP O a 2

g)0 0

Eo_~0

B0

00

a

2

.c

r,CoN v 4)~

0o etx

21
0 4)
Co

~g >.,,'O 5 40 O 0t-.t '=-° " c :H
_)
C6
U0
ic O;a
o_
w :8
4)

4) 0.
s
co
cO4)- Q c ON
v=ac M>
04) P4)
C,D -

4)0

U

cx 40

I~~

e~42)

Co?O 4) 40

Ch 59: Measurement Error in Survey Data

.

,

E0"0QEm g,x

r

E E d412c

O,

OE

o

c"

2

)00

c

I o o1 o o O )

-=

2

O

O

o

oe

.

-i

z

0 F-
Vt
C 0
0

2 aO

'Vi)
i

-a

0 C

ar

a

oo

c O

aC00C,).
C)1

3795

3796

U
0a

_ F~'
C00l

~ee>8

oo1

,, 2 oo

' '~ I 00

· e t·o

~ ~ CO O U

.;g

C)COO

· s··~~~UO

0-Eh

m

$COqBa ~g

.0
0a
U
to r5:i
0 -0

.° el 8
8 '2 g

82

;5

. CO, °

0 U

0

o

0; O

0 Q dO,

=

mo~5 a~g,

tm gEe

a

O

z

~z
IU O

0

Q

c01

0

o

0

0C .

m

U

g
00 O ' OU
0g

'S 8

n

el

UI

a)

c

0m
a) r I Q) .t z0
:5 0 , 0 -I CO

r-.)
a
U C00l
lao
Er w (7

I
U 00

0

0i

U

c0CO

U

U

VU CI) n
11COCO
m
10 U O V2 t6
U 00
2 C_

J Bound et al.

Ch 59: Measurement Error in Survey Data

C/)
v, :a

11

-

.

II

C> C1 Oe

0

0

aO

r6 ON

2a

6)}

'O

EO

0.2

0
an
E 6a

O

B

.2 t a a O 6 *

I as a'

.O O

to
.2 '0
a a
kK 0 U) C) 6).
0
.o _
'2
a
0
>

a.

E16 6)O

U Z B%sg

G

m

g3

Yo

6)

r

C "°~,:a

)
2a w

'a~
)
o Ca C~B 8 < 5S

.)

8,

UU Q0., a
z
cF
wi

o
a
_ l_0 a
0 %< 5
0 0
6)
ce b 6) w
26
a5 "
'a
6)-0 5"
_
00

a,
ral
I0z -~o
0 o :O s
86'
0a

C
am 0',

.5 o

,

0a X_ 2

0o D ~.2'
Z
sa

O )~'a

.2

9

0

0O

-

.)

'5a9 N oOoNx

O gx

3797

3798

Co
0
a) 0
iA 9O
er.0 cJ
03 g o, C
C-O
,~

0u

o S: 0
za)
.FCat0--)O 0
3

Ca-
-oE8m0
0
C.)a

P.

0

UECi)l

0 w

Co

-0

aO

E

0 a),

a)w

CC-

6u

a C-a

.2

a)

0
a) I a)
A
0
E.o 0 0

00

.0

C~Aa

B Q

0

0o

I

a)

0

P a)

Z.

0

o 0

a

o
a
Eq

z
kO

PX

32
,

Eo

ao

aN
.0)
~2 w o oN
0 11
P-
*gO. Q tQa
,
05 3W ;
C v>-

J Bound et al.

Ch 59: Measurement Error in Survey Data

3799

This pattern of "rotation group bias" is also present in the re-interview data lBailar (1975)l, which serves as a reminder that the re-interview data should not be regarded as error-free.
If those who are mis-classified in one month are correctly classified (or misclassified in a different way) in the next month, the number of transitions from one state to another will be exaggerated For example, some of those who appear to move from unemployed to not in the labor force will in fact have been out of the labor force in both months The extent to which classification error in one month biases estimates of transitions between statuses depends on whether the errors are persistent or independent from one month to the next Lacking direct evidence on this score, analysts assume that the errors in one month are unrelated to errors in the next On this assumption, a significant fraction of the apparent transitions in particular, 10- 18 of the roughly 5 probability of leaving unemployment from one month to the next appear to be due to errors in classifying workers in each of the months; transitions from unemployment to not in the labor force are exaggerated more than are transitions from unemployment to employment.
While there has been significant effort devoted to gauging the likely effects of errors in measuring labor force status on transition rates, there is much less evidence on how such errors might affect analyses of the effects of various factors on such transitions Poterba and Summers (1995) explore the consequences of errors in reporting employment status for estimates of the effects of unemployment insurance and welfare receipt on the probability of leaving unemployment Initially, they model the reporting errors as fixed probabilities, independent of the explanatory variables Correcting for reporting errors based on re-interview evidence has little effect on the estimated effects of unemployment insurance, but substantially increases the effect of welfare receipt on labor force withdrawal They note, however, that previous work suggests reporting errors in one month are higher for those who were unemployed in the previous month They present alternative estimates intended to capture this intuition, albeit informally If these alternative estimates of the probability of classification error are correct, effects of unemployment insurance and welfare receipt on transitions out of unemployment are significantly underestimated due to such error.

6.5 2 Retrospective unemployment reports

A substantial number of studies have examined directly the quality of unemployment reports These studies, reported in Table 5, encompass a variety of unemployment measures including annual number of person years of unemployment, weekly unemployment rate, occurrence and duration of specific unemployment spells, and total annual unemployment hours Only one study reported in the literature, the PSID validation study lDuncan and Hill (1985), Mathiowetz (1986), Mathiowetz and Duncan (1988)l, compares respondents' reports with validation data; the majority of the studies reported in Table 5 rely on comparisons of estimates based on alternative

3800

J Bound et al.

study designs or examine the consistency in reports of unemployment duration across rounds of data collection In general, the findings suggest that retrospective reports of unemployment by household respondents underestimate unemployment, regardless of the unemployment measure of interest.
Several of the studies reported in Table 5 compare unemployment statistics based on reports to the monthly Current Population Survey (CPS) to those obtained from the Work Experience Survey (WES), a set of questions included in the March Supplement to the CPS The studies by Morgenstern and Barrett (1974), Horvath (1982), and Levine (1993) compare the contemporaneous rate of unemployment as produced by the monthly CPS to the rate resulting from retrospective reporting of unemployment during the previous calendar year The measures of interest vary from study to study; Morgenstern and Barrett focus on annual number of person years of unemployment, Horvath on average estimates of weekly unemployment, and Levine on the unemployment rate Regardless of the measure of interest, the empirical findings from the three studies indicate that when compared to the contemporaneous measure, retrospective reports of labor force status result in an underestimate of the unemployment rate The rate of underreporting, depending upon both the measure of interest, the population, and the year, ranged from as low as 3% to as high as 25% The discrepancy between the retrospective WES and the contemporaneous reports is generally taken as evidence of recall error Note, however, that the monthly status reports are based on a complex algorithm that combines answers to a series of questions, while the WES allows the respondent greater freedom in selfclassifying.
Across the three studies, the underreporting rate is significant and appears to be related to demographic characteristics of the individual For example, Morgenstern and Barrett (1974) report discrepancy rates of 3 to 24%, with the highest discrepancy rates among women (22% for black women; 24% for white women) Levine compared the contemporaneous and retrospective reports by age, race, and gender He found the contemporaneous rates to be substantially higher relative to the retrospective reports for teenagers, regardless of race or sex, and for women Across all of the years of the study, 1970-1988, the retrospective reports for white males, ages 20 to 59, were almost identical to the contemporaneous reports.
One of the strengths of these three studies is the ability to examine the underreporting rates across many years of data and the impact of economic cycle on the quality of the retrospective reports of unemployment The findings suggest a relationship between economic cycle and the quality of retrospective reports; Morgenstern and Barrett's (1974) analyses indicate that in years of high unemployment, retrospective reports of unemployment from the WES overstate the amount of unemployment Horvath (1982) found that in periods of increasing unemployment, discrepancies between estimates of the average weekly unemployment rate based on concurrent and retrospective reports were smaller than during other economic periods Levine's (1993) findings were similar to those of Horvath; he found that underreporting declined during recessionary periods and increased during expansionary periods.

Ch 59: Measurement Errorin Survey Data

3801

In contrast to the findings comparing the estimates of unemployment from CPS and the WES, Duncan and Hill (1985) found that the overall estimate of mean number of hours unemployed one and two years prior to the survey based on employee reports and company records did not differ significantly However, micro-level discrepancies, reported as the average absolute difference between the two sources, were large relative to the average amount of unemployment in each year.
In addition to studies which examine rates of unemployment, person-years of unemployment, or annual hours of unemployment, several empirical investigations have focused on spell-level information, examining reports of the specific spell and duration of the spell Using the same data as presented in Duncan and Hill (1985), Mathiowetz and Duncan (1988) found that at the spell level, respondents failed to report over 60% of the individual spells Levine (1993) found that between 35% and 60% of persons failed to report an unemployment spell one year after the event In both studies, failure to report a spell of unemployment was related, in part, to the length of the unemployment spell; short spells of unemployment were subject to higher rates of underreporting.
With respect to reporting the duration of a spell of unemployment, there is some evidence that the direction and magnitude of response error is a function of the length of the unemployment spell For continuous spells of unemployment (that is, those that had begun in month x and which were ongoing at month x + 1) Bowers and Horvath (1984) compared reports of spell duration to the actual amount of time that had elapsed between the two interviews They found, on average, that the increase in the reported duration of the unemployment spell exceeded the actual elapsed time between interviews Torelli and Trivellato (1989) used a similar approach for a quarterly survey and found that approximately 40% of the reported spell durations were consistent with the actual elapsed time and that the magnitude of response error was a function of the actual length of the spell Specifically, they found that the longer the duration of unemployment, the greater the propensity to underreport the duration Approximately one-third of the inconsistent reports was attributed to rounding by the authors Poterba and Summers (1984) also find that the increase in spell length between interviews is smaller for those with longer durations of unemployment.
The findings suggest that, similar to other types of discrete behaviors and events, the reporting of unemployment is subject to deterioration over time The passage of time alone however may not be the fundamental factor affecting the quality of the reports Some evidence suggests that the complexity of the behavioral experience is a significant factor affecting the quality of retrospective reports Both the microlevel comparisons as well as the comparisons of population estimates suggest that behavioral complexity interferes with the respondent's ability to accurately report unemployment for distant recall periods Hence we see greater underreporting among population subgroups who traditionally have looser ties to the labor force (teenagers, women) Although longer spells of unemployment were subject to lower levels of errors of omission, a finding that supports other empirical research with respect to the effects of salience, at least one study found that errors in reports of duration were

3802

J Bound et al.

negatively associated with the length of the spell Whether this is indicative of an error in cognition or an indication of reluctance to report extremely long spells of unemployment (social desirability) is unresolved.

6.6 Industry and occupation
The measures discussed thus far are ones in which discrepancies between the gold standard, whether administrative records or reports obtained from preferred designs, have been attributed to the response process In that process, the respondent, the interviewer, and the question wording as well as the content of the questionnaire can all contribute to that which is often labeled "response" error Evaluation of error associated with the measurement of industry and occupation must consider yet another factor which could contribute to the overall quality of a measure, the error potentially introduced through the coding process The literature on response error, however, contains little discussion of the extent to which coding (as well as other post data collection processing) contributes to the overall error associated with a particular measure, or specifically with the classification of industry and occupation Therefore, in the discussion that follows, the reader is cautioned that although disagreement between household reported industry and occupation and administrative records is often classified as response error, coding/classification errors most likely contribute to the overall level of discrepancy.
Based on the small set of studies which have examined the quality of industry and occupation reports, the findings presented in Table 6 indicate that, in general, industry is reported more accurately than occupation For both industry and occupation, not surprisingly, the agreement rate between employees' and employers' reports classified according to a single-digit coding scheme are higher than the resulting reports categorized according to the more detailed three-digit classification Mellow and Sider (1983) report agreement rates between 84% and 92% for industry classification and between 58% and 81% for the classification of occupation (three-digit and onedigit classification schemes, respectively) in their Current Population Survey sample. Agreement rates are lower in the EOPP data, but Mellow and Sider indicate there is reason here to doubt the accuracy of the record report Brown and Medoff (1996) compared industry classification of workers' reports to the SIC codes for the employer, as listed by Dun and Bradstreet Using fourteen industry groups, their comparison yielded an agreement rate of 79% The findings from Mathiowetz (1992) are similar to those of Mellow and Sider, with occupational agreement rates of 52 % to 76%, for three-digit and one-digit classifications, respectively In the study by Mathiowetz, two sets of coders independently coded the reports of the employers and the employees while a third set of coders examined the two reports jointly to determine if the occupation could be considered the same occupation, that is, result in the same three-digit code The direct comparison yielded an agreement rate of over 87%, suggesting that a significant proportion of the inconsistency in three-digit classification may be due to very subtle effects related to specific words used by the

Ch 59: Measurement Errorin Survey Data

3803

ll
0o 0.
0) to

o

0

O

A0)

C-

t-

0)

a

.2 -g O

.

O

c.0

r

·

0Zc 0)

}

u U Ca

O

t ~~^~n~r-i

di °

3

UB

~S .R oO

0

o ',x O00C)Od e
~ CC 4 O C" OONO

0
P

~3tihj

O ¢I¢ 4 e

O

O CC

~~~b CO

C

O O to l

0) 0 C-
a

.0

E

y:

C

Ca

O

9

O

C

0-

09

0

0

^

c

o

to

c-

.P

0

0)
a

0 0O

C°

1S= z-'

oa

I C-

-2o

O

a

00

O

I

C

_0.

tg

0

0.

0 _ 0

G O

0

0 ~~~~

O~

0) 0
.C

·~

CCaO

~

CO~0~)~ CC :

a
,E 'I)

O>
:l

,a

·

Y OB

0)a O

a OCa

CO

Ia

ooWB a , o ,

O

-
E
30
I~~;~-~F~

u~ 00

Wo

~o'~Xo~mm '~, s

0O CO

a
.4

~'

Q

0)

0 0

S-A

0)

~n oo O a

O
^
ceoo

W~

xO O CO

OO C

00

C

~^N~ o~~~~

5crz
ON

E3 a:

3

3804

J Bound et al.

respondent to describe his or her occupation or used by the coder to classify the occupation.
For variables like industry or occupation with multiple classifications, the effect of measurement error on estimated parameters depends critically on the details of the discrepancies For example, if those in high-wage industries misreport themselves to be in other high-wage industries, the bias in estimating industry wage effects will be less than if the misreporters are spread randomly across the remaining categories. Angrist and Krueger (1999, Table 11) calculate wage-weighted industry and occupation indices, based alternatively on worker and employer data, from Mellow and Sider's CPS sample In univariate regressions, the effect of the industry index is biased downward by 8%, and occupation by 16%; controlling for standard covariates like education, potential experience, race, and sex leads to estimated biases of 10 and 25%, respectively Hence, the general finding that occupation is measured "less accurately" than industry does seem to translate into larger biases, at least when the relative size of the coefficients associated with the various categories are constrained in this way.
With respect to the reporting of occupations, the evidence of the deleterious effect associated with longer recall periods is mixed Weiss et al (1961) report a decline in the agreement rate of occupational classification by employee's and employer's from 70% for the current occupation to 60% for occupations held more than four years prior to the date of the interview Mathiowetz (1992) found no effect on length of recall period in the agreement between household and employer reports of occupation. Agreement rates between the two data sources for occupations held one year prior to the interview were 49% (3 digit) and 74% (1 digit) compared to 52% and 76%, respectively 72.
Given the difficulties in obtaining accurate measures of industry and occupation at one point in time, and the tendency of most workers to change industry and occupation only infrequently, there is general concern that measurement error will exaggerate the occurrence of changes in industry and occupation when estimates of such changes are obtained by comparing reports of industry and occupation obtained at two points in time The extent of such exaggeration depends on the extent to which the measurement errors are independent (for a given individual) over time Biases induced when change in industry or occupation is an explanatory variable will depend as well on the pattern of mis-classification (e g , are those who in a high-wage industry but are mis-classified assigned to another high-wage industry) We have no direct evidence on the independence of such errors over time Krueger and Summers (1988) assume an error rate for one-digit industries half as large as reported by Mellow and Sider (1983) (but with the same pattern of mis-classification as Mellow and Sider found),

72 Because the respondents in the study by Mathiowetz were older, with more tenure, than a nationally representative sample, these estimates should be seen as conservative estimates of the decline in the quality of reporting occupation associated with an increase in the length of the recall period.

Ch 59: Measurement Errorin Survey Data

3805

and assume such errors are independent over time 73 They find such a correction has
a more important effect on estimated industry wage differentials estimated from two successive years of CPS data (in which true changes are relatively infrequent, and so the fraction due to classification errors is probably high) than in data from the Displaced Worker Survey (where true changes are more common, and so the fraction due to classification errors is lower)74 The CPS results point clearly to the value of
evidence on pattern of errors in measuring changes in industry and occupation.

6.7 Tenure, benefits, union coverage, size of establishment, and training
In addition to questions concerning earnings, hours employed or unemployed, and industry and occupation, many labor-related studies query the respondent as to their employment tenure, union membership, establishment or firm size, and the nature of various employment-related benefits Few studies have investigated the quality of these various measures; Table 7 provides a summary of available findings The lack of replication with respect to most of the measures of interests suggests that we err on the side of being conservative when drawing inferences from these studies.
We could locate only two studies of tenure with employer in which workers' reports are compared to employer records, and these are studies of individual firms Agreement on starting date for current employer ranged from 71% lWeiss et al (1961)l to over 90% in the the first wave of the PSID-VS lDuncan and Mathiowetz (1985)l; however, agreement in the former study was defined as a reported start date within one month of the company records and in the later study, as within one year of the actual start date Bound et al (1994) report that, in both PSID-VS waves, the correlation between interview and record data was 99 75 In contrast, Brown and Light (1992) find that tenure reports in longitudinal surveys are often inconsistent indeed, it is difficult to infer which survey years a worker was employed by the same employer from the tenure data alone They consider a number of ways of resolving these inconsistencies (in tenure reports) and ambiguities (about when a worker has begun working for a new employer) Their main finding is that recoding the tenure values (so that tenure increases by the elapsed time between surveys if one infers that the worker has remained with the same employer) is important in applications where there are fixed effects for each worker or for each spell with a particular employer.

73 Their taking half of Mellow and Sider's rate is intended as a rough correction for the fact that the employer reports in Mellow and Sider's include some errors, and for the fact that errors for an individual are probably not independent over time. 74 For example, the wage difference between workers in manufacturing and otherwise similar workers in retail and wholesale trade is 07 in the CPS before correcting for measurement error, and 23 after correcting For displaced workers, the difference changes from 11 to 13. 75 Estimates of returns to tenure are about 002 higher (on a base of 01) in cross-section regressions when record rather than interview data are used However, this difference is due to a correlation between tenure and errors in reporting earnings lDuncan and Hill (1985)l.

3806

J Bound et al.

3
0 .JD z 0
a
z U m
0
E
m

C)f

3 t

C)

. CO

0c

0

03

0
a800
,L
C)

o 0 5f

0

3,

0.
E

v

4

C)

o

o

o

0o

m

.0. O

· CO

0_

C)m_dm

o

-0

_t

0

rz)

0

g'

CO

O °C)

o 0.4 M

2CO OO

'

-E 8 II r,

00

§
B

8
O

Ce

C)O

I

O C"

o );

C)

z Ui

O

-
v3 °

S>.

0

00
COi

H

t
0.

0

E r- E

E

C)

Cc)

0.

.

a

E0

)O
la &

E

a
a
3

c

C"

D

D

o

v

8C
C) a
AS
s

E

Om

.8 .0

OJ O

O~

O

3, t

B

D y BD X

ra

CC") z

C4)
C

*~ as

O

O

S

'-

B

a YO' t

'

" o

O o

C)0

eC

O

CC

0

VO 2 -o
~E

'0

'0

0

0

)

C)

eO

O

r3Wc

I
3r

"O O00e

3o
0

2IL)

0 c C)

a

C)
¢

on 0 400 0

')

Q

D4,O

'b
.
-ow
m
QO> O
I6o 06-SE§ E

5
,g

a Sa

C C 2:

a · 5
Uom C)0

2s~

88
-o C) 0}
S
oo
C)

2

z
:32)

*'aO

Coo)

>)

CO

a0

r_

CO'-'

vlCO£'0

aj E Q

CO 0_'

0

Wn 00 _
=

In
ree
00 _
_

W
ro
00
_ _

a0

'0

O

a3C)

3C

9

0

O

O

Ch 59: Measurement Errorin Survey Data

3807

a)
a

o

_o

v

'0 x

c

O a 6

o

_

.ea, 3a c ae D C 1

a) -

0, 0.e~

CO

6

.E
0
ac
1O 0 i *x
90c aa 'V ^O ~
C) '0
Po2 OO 6 a),.
Qa)

a c'0II

Yc

a)

Ca

2

~c c)

O

c ig

aDm C 5a _CO D -O a)*S Ca

~0 O N C eCC

oa

N

d3
o 1)
a
6s

o~ a

o -a r

-a

c a) t

a

a)

t mt

oc3

~a c 5

o-dC B C

o

; a)a Vo

C
t V

a 0

-0 a

Ia)

20

0.

a)

00

C) r

O

t

.r I

0a0

U 2 o a

0

-

='Cto~:@ d

r-

a -0

0

~i 4I 2o, ,+Po O E2
a

U Ca

7z

a0

a 90 O m)

-

U 0 Ea

a)

_2p a

0
4

O

O

0E :

Wa w

o

0.
ra.

S

a 0
-09

.9 .2 .) 2 x a
_ C
CO

0
a)

9rc

_ 'IV-

~a)

r8

V 6

N

V

-a
Cc
c

a^

a^

a)

a)

ax

8Y t; c

CCg

a)

3 9c

o o O O
o ma mm Sa

0 et a

C;O

-

-a

c~

Ic

a

g

a)

a

m_

m_

a)

C,

O

aa)

= 914 a

_m

m

o 00.
a)
09) a2 w
0E a *., O o
9
a^ P.r
m
a
-a m
a
o N^
md

0
o
a a) 0
.5
-ma
Cc 0
0
.,
,U O
m ;.
m_a,
WA-

3808

J Bound et al.

00

II

0

3 0o

00

00

Lno OUOO> P

co n

t'-

.O to

O

-

a^ v

O.

°x

cA

to -C 0

U
ON -~

-, 00
00 ON

O >

O

00N ON

zC) u

~ON
O

a;

z

D

zU

U

B

00

~

0

0

0

P
.D-)

.0 0)
.0 )0

t

OO 5

ON

0)

C

t

O

' e O

o

o'

O

.0

0 0
8 ~~~~~~~~~ as,~ O

mO

~~~vl
Sa~~~~~~~~~~~~

m

0)

$"x~~~~~~~~~~C

,

.2

0

U)

0c

0
C)5 00 .0

-0 0) C). C)1

E
C OD 00·

A

3

O

~CO

O

O

O) C
0)O%

9el

s~

~ _03 0)

C)

O

E

, ~ O00

00

SO

O

Ch 59: Measurement Error in Survey Data

3809

Several of the studies indicate that employees' reports of coverage under a union contract, union membership, insurance benefits, and vacation and sick leave are accurate With respect to coverage under a union contract, Mellow and Sider (1983) report discrepancy rates of approximately 7% (CPS, national sample) and 15% (EOPP, national sample), and Barron, Berger and Black's (1997) estimate is 6% This compares to a 1% disagreement rate reported by Duncan and Hill (1985) in their unionized single-employer sample The EOPP disagreement rates are, however, inflated by the fact that the employer report is coded as covered or not depending on whenever a majority of the workers are covered Freeman (1984) and Card (1996), using the Mellow-Sider CPS data but different sample definitions, find employers and workers disagreeing 3 5 and 5% of the time (respectively); like Mellow and Sider, they find the discrepancies about evenly divided between workers but not employers reporting coverage and the reverse 76.
In a simple bivariate regression of wages on union coverage, random zero-mean errors in measuring coverage would lead to an estimate whose proportional bias is equal to the sum of the two mis-classification rates (Prob(x = 0 x* = 1) + Prob(x = 1 I x* = 0)) This bias is 19 and 31 in Melfow's CPS and EOPP data, respectively; 10 in Freeman's and 12 in Card's sample of Mellow and Sider's CPS data Freeman stresses the extent to which this bias is inflated in longitudinal analyses. If measurement errors are independent over time, and the misclassification rates sum to 10, the bias becomes 29% in a fixed-effect model if 19% of the sample reports changing union status (as is true over 1970-79 in PSID); with smaller fractions of the sample changing coverage status (as would be true in studying one-year changes) the bias would be larger still Of course, if the errors are positively correlated over time, the bias due to measurement error in a fixed-effect model would be smaller than under independence 77.
Card argues that, instead of treating the employer reports as "true", one should treat both employer and worker reports as subject to measurement error He finds that the estimated impact of union status on wages is very similar using either worker or employer report, whereas the latter should have a larger effect if only the worker reports were subject to error Indeed, he argues that both the wage equations and the patterns of agreement across industry are consistent with the hypothesis that both worker and employer reports are equally prone to error, with error rates (independent of true union status) of 2 5 to 3 0% His model makes the common assumption that the error in reporting union status is uncorrelated with the error term in the wage equation This rules out a number of plausible scenarios; for example workers who are not aware of

76 Freeman also finds that, in two supplements to the May 1979 CPS (in which union coverage was asked in each), the responses given by workers are inconsistent 32% of the time The inconsistencies were about equally distributed between those who said they were covered only on the first supplement and only on the second. 77 Indeed, Freeman reports that misclassification rates summing to 10 would predict more changes of
reported union status due to error alone than one observes in his 1974-1975 CPS panel.

3810

J Bound et a.

being covered by a union contract being those in weak unions which fail to deliver high wages.
There appears to be considerable disagreement on the accuracy of employee reports of various fringe benefits Duncan and Hill (1985) also report high levels of agreement for reports of health insurance (less than 1% disagreement), dental benefits (5% disagreement, all underreporting by the respondent), life insurance (10%, all in the form of underreporting by the respondent), number of vacation days (less than 1%), and number of sick days (9%, split between over and underreporting) In contrast, Barron, Berger and Black (1997) report disagreement rates of 35% and 25% (with respect to initial benefits) and 19% and 13 % (with respect to benefits after two years) for sick pay and life insurance, respectively. Berger, Black and Scott (1998) compare March CPS reports of employer-provided coverage to reports one or two months later in special CPS supplements They find 11% of the reports are inconsistent, with lower overall coverage rates in the March surveys Comparing employer and worker reports, they find that three fourths of the disagreements are workers who report they are eligible but whose employer reports them ineligible.
The focus of Mitchell's (1988) research was the respondent's knowledge of pension plan provisions Using a match sample of household respondents and pension providers identified as part of the 1983 Survey of Consumer Finances, Mitchell finds pension misinformation as well as respondent's inability to answer questions concerning pension benefits to be quite widespread The highest rates of inaccuracy by household respondents concerned knowledge of early retirement provisions; one third of the respondents could not answer the questions and among those who did respond, less than one third understood (or more specifically, could accurately report) the requirements for early retirement benefits.
These errors are likely to be particularly damaging in structural models that relate retirement decisions to pension incentives As Gustman and Steinmeier (1999) note, workers with defined benefit pension plans do much better if they leave the firm at the early retirement age rather than even one year earlier Thus, mis-reporting the age of early retirement eligibility by even one year can make it look like an individual is retiring at precisely the age at which economic incentives suggest retirement should not occur, and lead researchers to severely underestimate the importance of pension incentives Gustman and Steinmeier also note that workers may in fact base their behavior on their perceptions rather than "true" incentives; for such workers, survey responses may be a better approximation for the variable that motivates behavior than is the "true" variable as calculated from the pension plans.
Using Dun and Bradstreet data as the record for comparison, Brown and Medoff (1996) examined the quality of household reports of establishment and company size as well as age of firm (i e , how long the firm had been in business) Correlations ranged from 56 (correlation between worker report and D&B report of age of firm) to 82 (for In establishment size) and 86 (In company size) The authors note in their findings that potential inaccuracies in the Dun and Bradstreet records "probably understate the

Ch 59: Measurement Error in Survey Data

3811

correlation between the worker reports and perfectly accurate measures of employer size".
Only one study reported in Table 7 examines the accuracy of respondents' reports of training hours Barron, Berger and Black (1997) compared workers' and employers' reports of hours of training for several different types of training: formal training, training by co-workers, and training related to others performing the job The correlation between the two reports was highest for off-site, formal training ( 457) and for total number of hours of training ( 457) and lowest for informal training by managers ( 176).
The empirical research concerning the quality of respondent's reports of benefits, tenure, and industry characteristics is limited; in many cases we have only a single study to inform us as to the error properties of these measures Although the findings suggest that the reporting of tenure and union coverage is highly correlated with administrative records, caution should be taken in drawing any conclusions from this limited literature With respect to the reporting of fringe benefits, the findings are mixed Based on the PSID-V, it appears that employees are well informed as to the characteristics of benefits whereas the studies by Barron, Berger and Black (1997) as well as Mitchell (1988) suggest high rates of inaccurate reporting.

6.8 Measurement errorin household reports of health-relatedvariables
While the examples discussed so far tend to be drawn from surveys that are most often used by economists, the empirical literature in several other substantive areas is rich with examples of the misreporting of autobiographical information An important example is health, where work typically done by those in other fields provides evidence on the validity of health-related measures often used by economists and other social scientists.
6.8 1 Health care utilization, health insurance, and expenditures
As previously noted, much of the early work with respect to the assessment of the quality of retrospective reporting by survey respondents focused on the reporting of health care utilization, usually as reverse record check studies in which respondents were sampled from those with known hospitalizations or visits to physician offices The design of these studies makes them well suited for investigating errors of omissions; however, many of these studies are uninformative with respect to overreporting errors.
Table 8 presents the findings from a selection of studies assessing either the reporting of health care utilization, characteristics of health insurance, or health care expenditures Once again, we find evidence that response errors appear to be a function of the nature of the response task facing the individual, the length of the recall period, and the salience of the information to be retrieved.
Two of the studies reported in Table 8 assess the quality of reports of hospitalizations Cannell, Fisher and Bakker (1965) describe a reverse record check

3812

B

O

4

CO 9~0 ~~E ~

i

Or r

CO

o4

O

4) 4'

4)

O

I M
0
C)
00 .cO W0. .0 N
CT 4) 00 O
Q
e
0 CO
Lo eC
80
8
4) O cr 40)
4') C P
P
E.004
4) 8)
r.

~o
4) OC" C

~~

o

O

t~~" ~ cco B ,'~~_o, ~ ~'Co' l0 t B O,'"° o 4

0rO

d

C O CO

C.

$ 0'

C

, 00

~ ~~~o CO 4) g

04)

O

OO O O

OC

"C

C,'

Y

~ Wjt 8 On~~~~~~~~~C
CC C-0
~~~~ O

iC O

)r 4

NV

C O
O

0

C-

4)

O

4)

4

C

C

CO

o

S

0r= .0

gw

N

'Ct

o

O C<~-

4U) 4)L
*O 0==

C 04

3
0

CO C-

4)

4)

J Bound et al.

Ch 59: Measurement Errorin Survey Data

4
*3

.P

::s

-

=

ID I I

,

\o O f C

CO.C
mE

·OOC~

SfC

09 0.~
>

o0 *Q

'

a'r

',

5 ) Ca

E

Caa<=

;

a 0I OxE O~

a

oa)r

=~.Q E

ro

Y

Nm O

'Z

a I
0

a

o

.002
0a0)

Ca'

c

O

0= C

Cg '
._

3813

so q

3814
.
.ae
a§~~
ce bl)

J Bound et al. Ua~~~
8C

a .2
0
:3 z
~,z
U O
a 9.0 0 - 0.
.4

ao
c.- o~~~~~t
am

x

00 C"

aEECg)

O

~0 '

B

·

NS

O
ti r a

E

a

H O O C )c C) a a

"

2g ~

~

a~~ ~~ ~ ~

~aa~a~2~~~~ ~~~~~~~e

iH

o

Qx

00 c

a~~~~~~~~'

a

a

I

a

a~~~~~~~~

O

.-C

,chO

"O ao

N-

C)

0
C)
art
C)N-
EU "O C
04

Ch 59: Measurement Error in Survey Data

3815

8

a
a_

._
,

=~.

x~~~~

Oo

C ·

om
O C

-a o N

Oa

OO

N

-

= aa

~% 0 C >O

0)

a9

C: gSm

E8 o~~~

=o

m oc
9 t N3

m ncso

6

S £ m' f S

0 O N)It-InInm-Ar

t

_ 5"I N O

.o
a

°.

O

'-D

_l

N me

h

'E0

u

N^ N 6

0) W)

sO o)

~Ee,>~ oc-e ~~
<= = 8 =" =a c

n

=

=)

,

0) 0)
a >-~

O
a

0 ) 'var

aa aa

aS~ E E> a 5aS OO

a

a

5a

;~
;a

aa" a C a0, a

0 SCOY Vl C: CO C )

a
'Z

10

0)

.aa0) 0)

-a

C.

r0.

8 R0

r

0

0)

aa a

lu
a

Q.

C.

E

0

XU010)

0

aD

O

0)

~C0

az
a,

U

0 z

a
Ma I

Q
r.

a
a

p

0

0

3816

J Bound et al.

study 78 in which approximately 1500 respondents were asked to report on hospitalizations occurring during the previous 12 months Overall, approximately 13% of hospitalizations were not reported Response error, as measured by the percent of hospitalizations not reported by the respondent, increased as a function of the length of time between the date of the hospitalization and the date of the interview For example, for hospitalizations occurring within 10 weeks of the interview, the underreporting rate was 3 % whereas among hospitalizations occurring a year prior to the interview, 40% were unreported The duration of the hospitalization was related to the rate of underreporting; 5% of longer hospital stays (e g , those lasting 30 or more days) were unreported by the household respondent as compared to 26% of one-day stays.
Other studies have examined the quality of the reports related to utilization of office-based physician services For example, Cannell and Fowler (1963) found that a significant proportion of office-based physician visits were unreported by the household respondent, even for recall periods as short as one week (15% unreported) and that the underreporting rate increased sharply with an increase in the reference period to two weeks (30% underreporting rate).
The Medical Economics Survey reported by Yaffe and Shapiro (1979) was designed to test the feasibility and effectiveness of several different survey design features to obtain information concerning health care utilization, expenditures, and health insurance coverage The study included an assessment of face-to-face vs telephone mode, as well as monthly vs bimonthly interviews over a six month data collection period In addition to the monthly or bimonthly interview, respondents were asked to maintain a diary (after the initial interview) to serve as a record-keeping system and memory aid for subsequent interviews Prior to each follow-up interview and at the end of the study period, a cumulative summary of previously reported information was mailed to each household Respondents were asked to review the report and to make any necessary additions or corrections, including entries about bills received since the time of the last interview All medical care providers identified by the respondent as having provided care for anyone in the family during the study period as well as providers identified as the usual source of care, were contacted after the household data collection.
Several of the design features, specifically, the multiple rounds of data collection, coupled with the relatively short reference period, the use of a household diary, and the use of a summary were all included so as to minimize response error These design features may account, in part, for the higher levels of agreement reported in Table 8 for this study as compared to other studies In addition, Yaffe and Shapiro only report agreement rates for population estimates, that is, (Yhh/Ymed)* 100, where Yhh represents the population estimate based on the household report and Ymed represents the population estimate based on the medical records The estimates are provided for

78 The sample consisted of persons selected from hospital records as well as a supplementary sample of persons without hospitalizations, so as to blind the interviewers as to the purpose of the study.

Ch 59: Measurement Errorin Survey Data

3817

the two distinct geographical areas studied As can be seen from the table, agreement rates for utilization are quite high for the most salient events (and less frequent) such as hospitalizations and emergency room visits, with agreement rates in excess of 90 % Agreement rates were lowest for clinic visits, 39 to 54 % With respect to expenditures, we once again see a high level of agreement between the two data sources for hospitalizations (87 to 99%) and the lowest agreement rates for hospital clinic visits (31 to 38%).
Cohen and Carlson (1994), using data from the National Medical Expenditure Survey, also examined the quality of household reports of medical expenditures The entries in Table 8 present the mean household estimate, the mean medical record estimate, the mean of the simple difference and the mean of the absolute difference between household and medical record reports of total expenditures for each of four categories of utilization The sample sizes provided in the table represent the number of events on which the estimates are made; the percent indicates what proportion of all household events of that type are included in the analysis Due to the design of the NMES (which included a medical record component for a sample of all households) as well as provider nonresponse and inability to match events reported by the household with events abstracted from medical records, not all events reported by the household respondent were included in the analyses In addition, the analysis is limited to those events for which there was expenditure data from both the household and medical record files The comparison of the two data sources indicate that although the simple differences tend not to be statistically significant, the absolute differences clearly indicate significant disagreement between the two data sources.
Very few studies have examined the ability of household respondents to report detailed information concerning features of their health insurance Knowledge of the existence of out-of-pocket payments and sources of premium payments was quite high (78% and 74%, respectively), but quite low with respect to amounts of out-ofpocket payments and amount of insurance premiums paid by others (less than 30% for each) lWalden, Horgan and Cafferata (1982)l As we would expect, the majority of respondents were able to accurately report the standard major categories of coverage (hospital room, physician in-patient surgery, other in-patient physician services, and dental services) Knowledge of coverage associated with richer benefit plans was much lower, however, with less than one-third of the respondents correctly identifying whether or not their insurance covered outpatient mental health, in-patient mental health or nursing home services.

6.8 2 Health conditions and health/functionalstatus

Measurement error in health surveys is not limited to the reporting of utilization, expenditures, and health insurance characteristics, but is also evident in the reporting of medical conditions as well as the reporting of health and functional status Findings from a sampling of the literature which addresses the validity and reliability of self reports of health conditions and functional status are presented in Table 9.

3818

1 Bound et al.

Vl to
°c ~8,O

c) z3

"O EJ 0)
5 ?o

*O C) O

v05
05

9 m I -pa

0) ,.

-o

c

c

cQ o
1e

V N Oo
55om

0

a .92

to

m -0

CO .0 =cc

0Z

0 0 C

0

00

c

0

0E L;

5r

.0c

0

Oa o Uo o
"O
e055

C ) Zm

CZ r.-

0 .0
E 0o 0

0

C-)

0r.

0

O c 0

Ul

a
0
i
c C

02

U-

00

0)

C)

050

zc_ 0505

c

05

o

.2

iC
0c5

U

0o

~ - -
0

.- ^m o

3

o2

IO `

tO-ot

O On

00 o

o

z.

'

o

Q

Q

o: c

O

°o
t
C O'C

oo
o05

s

~ S 9 :

o

V c~ A

0
0o Yg 0o8 r,
0l O C E hs > d

==
aO^ i
;:

E.2 "OE o"E 23o ¢

0
CU)
C) 05
0
0
L000)
.U
a
0.0 -' ., Zo Z,-_

cc

9,

9

a
'O
" 298
CC O

"O
m0

U

v

lN -

3O b UO-

0 I 9~

o--y0

85

Ch 59: Measurement Errorin Survey Data

0
a a .

20 ,

.Ea_,

0o a,

0
~O -0 o~a ~

,@ N

oo

2 j t;

q 2~"E
a t aa

_t

a

00
.5 oa "

L-2

So a 5

a

ca

.oE0Oaa

o'2 ' '5 D Zf

Xo

.oEal 2
lz
~0 O m,
a5 a aN a2 o

_*,'S 0 a~a ci t B

O
2
O~
,s O *IO O
O

r
oO

~nM C
.t a 5 t,0
P 'OE

:

oZ 0
0)

Q .O

.F0n-,

0 o

a

n
9

0 O O I

.2 0-

P

.0_a

QP-tao

tME
t

0

a

n0

O

0 -

0 a

0

C,

aO

N

Mh

.U_ o

zo =XO

r. .0

aQ) a.00

P

xc

11)

a a a n:-r
a e~ 2
~~ 0)
;_
E
0

3819

3820

ON00400

0000 \

OO

m C-m

C CD

tM w

,-.a

,)

'3 aO

,Zrz

~U
CO

.

0

ti

r)

00

ON

uE

z

O rR,0

xO

.Y l R C7,

0
0U O
0 o

-c

C

p

8 2

c

0m)O ·e

.) 0c

COt
0 ~U~e 0 ~\

0) 0O0N .E'
Q

r

0
aeO

J Bound et al.

Ch 59: Measurement Errorin Survey Data

3821

In two reverse record check studies lNational Center for Health Statistics (1961, 1967)l, respondents were asked to report on the prevalence of chronic conditions The second study also included an experiment designed to address the difference in the quality of data obtained from free recall as opposed to recognition from a checklist of conditions The findings from these studies suggest that underreporting is a function not only of the length of the recall period (measured as the time since the last physician visit related to the condition), but also of the response task Questions which frame the task as one of recognition as opposed to free recall resulted in lower rates of underreporting However, for both response tasks, the underreporting rate was quite high, ranging from 32 % underreporting for the recognition task related to the events occurring within the previous two weeks to an underreporting rate of 84% for free recall of events occurring four or more months prior to the interview The improved reporting related to the recognition task is predictable; the presence of a cue provides both additional context for the respondent to understand the goal of the questions and an additional means for accessing the associated network of memory The study by Madow (1973) is a complete record check design, limited to respondents in a specific health plan As can be seen from the table, almost half of the conditions recorded in the medical records were not reported by the household respondent whereas over 40% of the conditions reported in the household interview were not identified in the medical record.
As part of the National Medical Care Expenditure Survey (NMES), Johnson and Sanchez (1993) examined the congruence between medical conditions as reported by the household respondent and medical conditions as reported by the medical care provider These data are based on the same matched sample of household reported events and provider reported events used by Cohen and Carlson (1994) in their analyses of the quality of household reports of health care expenditures. Household reports reflect conditions associated with hospitalizations, visits to emergency rooms, outpatient departments, as well as office based physician visits. Household reported conditions, which reflect a mix of self and proxy collected information, were coded to three-digit level of detail by experienced coders using the International Classification of Diseases, Version 9 (ICD-9) ICD-9 condition codes were abstracted from the medical records, independent of the knowledge of the condition described by the respondent Household reports of utilization were linked to the medical record abstracted records via a probabilistic match function. One of the variables used in the probabilistic match was a one-digit collapsed classification of the condition related to the utilization As a result, the agreement rates which indicate the percent of medical events reported by the household respondent for which the two condition codes (household based and medical record based) agree are likely to be optimistic At the three-digit level of detail, there is agreement between the condition codes as reported by the household and the medical condition recorded in the medical records for less than half of the medical events As we would expect, grosser levels of aggregation result in higher rates of agreement.

3822

J Bound et al.

While the lack of congruence between survey data and medical records is disturbing, we want to emphasize that this information alone tells us very little about the effect of this measurement error on parameters estimates First, it seems plausible that reporting errors decline with the severity of the condition (severe arthritis is more likely to be reported than is mild arthritis) Second, in many cases researchers will be interested in modeling jointly effects of various conditions on outcomes In such cases, it is hard to say much about either the magnitude or the direction of the bias on a single coefficient, since the coefficient on any one condition will be biased not only by the under and overreporting of that condition, but also by the under and over reporting of other conditions (see the discussion in Section 2 2).
Table 9 also examines the reliability, and to the extent possible, the validity of several measures of health and functional status The measures examined include the Index of Activities of Daily Living lKatz, Ford, Moskowitz, Jacobsen and Jaffe (1963)l, the Sickness Impact Profile lBergner, Bobbitt, Kressel, Pollard, Gilson and Morris (1976)l, and the SF-36 lWare, Snow, Kosinski and Gandek (1993)l In contrast to the validation studies presented earlier, no external measure of validity exists for the majority of the measures related to health or functional status Rather, as with most psychometric scales, the interests lies in the reliability of the measure (that is, test-retest reliability or internal consistency) or the validity of the index, measured as the correlation or consistency with other subjective scales.
Despite its broad use, there has been little published with respect to the assessment of the validity or reliability of the Index of Activities of Daily Living, especially within the general population Katz, Downs, Cash and Grotz (1970) applied the Index of AD Ls as well as other indexes to a sample of patients discharged from hospitals for the chronically ill and report a correlation between the index and a mobility scale and a confinement measure of 50 and 39, respectively Most assessments of the Index of ADL have examined the predictive validity of the index with respect to independent living le g , Katz and Akpom (1976)l or length of hospitalization and discharge to home or death le g , Ashberg (1987)l These studies indicate relatively high levels of predictive validity.
Despite these findings, there is a growing body of literature that suggest that the measurement of functional limitations via the use of ADL scales is subject to substantial amounts of measurement error and that measurement error is a significant factor in the apparent improvement or decline in functional health observed in longitudinal data For example, Mathiowetz and Lair (1994) found that conditions of the interview, characteristics of the interviewer, and type of respondent (self or proxy) were predictive of improvement in functional status over the 18 months of interest whereas the individual's demographic characteristics and health status were indicative of decline in functional status Rodgers and Miller (1997) examined the consistency with which respondents reported functional limitations, using alternative sets of question wording Consistent with other findings in the literature, they found that minor differences in the wording of questions resulted in significant variation in the proportion of respondents identified as being limited in one or more functional

Ch 59: MeasurementErrorin Survey Data

3823

activities, ranging from a low of 6% (based on a single question) to more than 25% of the respondents 79 (based on a set of six to nine ADL questions).
The Sickness Impact Profile (SIP) measures health status by assessing the way sickness changes daily activities and behavior and consists of 136 statements grouped into twelve categories of activities The profile focuses on actual performance as opposed to capacity Bergner, Bobbitt, Carter and Gilson (1981) report on the reliability of the profile for both interviewer administered questionnaires and self-administered forms, with reliability higher for the interviewer administered form ( 97) than for the self-administered form ( 87) Internal consistency, as measured by Cronbach's alpha 80 was similarly lower for the self-administered form ( 81) than for the intervieweradministered form ( 94).
The SF-36 is a generic health status measure, one that is not specific to age, disease, or treatment, that focuses on health-related quality of life outcomes The index covers eight areas of health: physical functioning, role limitations due to physical health problems, bodily pain, general health, vitality, social functioning, role limitations due to emotional problems, and mental health The measure is designed for both interviewer administration as well as self-administration and both modes of data collection have been assessed with respect to validity and reliability Reliability of the SF-36 has been assessed in numerous studies lsee Ware et al (1993) for summary of these studiesl; across the various scales of the SF-36 and across the various studies, the median of the reliability coefficients equals or exceeds 80 (Cronbach's alpha) The findings from two of the more recent studies examining the SF-36 are reported in Table 9. McHorney, Ware, Lu and Sherbourne (1994) examined the internal consistency of the SF-36 among approximately 3500 patients with one or more chronic conditions; as can be seen from the table the coefficients range from 78 for general health to 90 for mental health A self-administered version of the questionnaire study conducted among a nationally representative sample of noninstitutionalized adults found similarly high measures of internal consistency lMcHorney, Kosinski and Ware (1994)l.

6.9 Education
Despite the importance of schooling as both an outcome and as an explanatory variable in economic models, relatively little effort has been devoted to assessing the accuracy of survey reports of years of schooling or similar measures of educational attainment.

79 Rodgers and Miller's study is based on the respondents to the first wave of the AHEAD study. 80 Cronbach's alpha provides an estimate of internal-consistency reliability based on the average inter-
item correlation and the number of items in the scale, expressed as k r/lI +(k I)rl where k equals the number of items inthe scale and r is the average correlation between items The coefficient alpha will be higher (1)the more questions asked about the topic, and (2)the higher the average correlation between the scores for all possible combinations of the entire set of questions Inmost applied studies, the lowest acceptable level of internal consistency reliability is 70 for group data and 90 for individual-level analysis lNunnally and Bernstein (1994)l.

3824

J Bound et al.

The literature which is available, however, illustrates a number of interesting issues that are potentially relevant for other variables as well.
Typically, these studies (summarized in Table 10) have two interview-based measures of education, each of which is plausibly measured with error In assessing what we can learn from such data, recall that the OLS bias in estimating , in the model y =/x* + e when instead of x* we use xl = x* + u 1depends on 1 A = 1 (, x,/x2 ) If we have another measure of x*, x 2 = x* + 2 then Al = ox,x2/ 2, as long as p2 is uncorrelated with x* and with 1 In other words, as long as the error in measuring x2 is "classical" whether x2 is itself a particularly reliable indicator of x* is unimportant. If, in contrast, l and #12 are positively correlated, the covariance between the two measures of x* will overstate i),and holding that correlation constant, the larger the
measurement error in x 2 the worse the overstatement will be. An early study of the reliability of reported years of schooling is Siegal and Hodge's
(1968) analysis of 1960 Census data Validation data came from the Post-Enumeration Survey (PES), a re-interview conducted to assess the accuracy of the original Census reports They found that the Census reports and PES data on individual years of schooling are highly correlated They also noted, however, that the variance of the Census report is slightly smaller than that of the PES education variable, which is inconsistent with the usual assumption that the Census report is equal to the true (PES) variable plus an uncorrelated measurement error The discrepancy between the two reports was in fact negatively related to the PES value (r = - 20) They argued that one should expect errors to be negatively related to true values for bounded variables, since for those with the highest (lowest) true level of education, errors must be negative (positive) Given that the variances of the Census and PES variable are essentially equal, the b Es, Census = 93, so the bias due to errors in measuring education as an explanatory variable is small (as long as other explanatory variables are not highly
correlated with education). Siegal and Hodge (1968) recognized the possibility that the PES measure of
education is also measured with error and considered several relatively elaborate models in which both years of schooling and income are mis-measured These relied on rather arbitrary identifying assumptions, and Siegal and Hodge concluded "we have not been able to devise an entirely plausible solution".
Bishop (1974) presents a comprehensive summary of the reliability of Census and CPS reports of education Estimates of the correlation between Census and other measures of education center on 9, as do the alternative estimates of Al Bishop notes that mean reversion would tend to reduce the bias caused by measurement error, while positive correlation in the errors would lead the values of A to be too high.
Bielby, Hauser and Featherman (1977) compare Current Population Survey reports to subsequent interviews and re-interviews of the same households approximately six to seven months later as part of the Occupational Change in a Generation (OCG) study. Focusing on the sample of non-black males that participated in both the OCG interview and re-interviews, they find inter-correlations among the three measures of years of schooling of 80- 92 The OCG shows both lower correlation with the other two

Ch 59: Measurement Error in Survey Data

3825

C) 0

0 z

' ,c O CI O

~z0

rO

cNq

C)Z 0z

Q

c oo

3

O

Oo O

c

OOh ie-S

C

so

-C0

cW

3,,

aC 0 U aO

r
EC a0

0

0
0~

.

C)

C)

C)
0
1 00g
C)
Cra.

C
C) oo
>E
mo
~ .O D
C
o~ O

Ux £ o 00

UU ^U

m om

i:

cao

OCa O

~0

C) O ,,

0.; Q

ae

~ r C)0u0 C)~

O Ca

g~d

0 J a"~O~O~go

0U

e~

Q\ C)~~~~~

St~t

_t

N

·g

\

.o oo 'o 'F

0

00 00 C

00 '
_O C 11 11

o

O

001 o °

C) C) o _o

a
Bvl a
o

'
0
C)

E

cC

o
% o°. 0
m
C)E

.s::
os8 o
.00
C)
oU

3
g.
g~o

0<
Ca

c F-

_

CO

*O _
-

C) 0 C)

r.SC

C)

0s

-Ca

-v
CN C)-
mCQC) C) a

3826

+ O' t
0) 00 _ V
o o

'0 'k C' (N

c c 00 r'

0"x0

ci l

Im x

o 4 =D

N a)

0, *r~ O 00 a
. "' (m 00 'i : i

It 2 ",

N (N

~ eeE O 0
0,ZO o
a _ C
1P_ 01)z
ZO
$z

ca a a

c3O

aa >P )rr

O;

0

F.0-

{} 0 a

0C) .) 0

04

Fr-.
0)
+00e)o .0=_r-oC,
0bSz O C ,O U_
. 5l
cO'ap
'MoOO -I

0 to 0)
0 'CaO x

0

"U Xc~ cv

pC0) )
0)

04; O O

a

= o7o
,2 I

0 p
-
0)
o
00
0)i .r'0 V,
0)0
2 Al
~g. Mr
-00 o
2Id
2 nv >'CO \

0
e I.
o ZO Fa 0) 0D
.-
a ._
9. A a,-
a)0
. a a.

J Bound et al.

Ch 59: Measurement Error in Survey Data

3827

measures and higher variance, suggesting it is the least reliable of the three measures. A rather complicated measurement model which allows errors to be correlated with true values for OCG and OCG-R but not CP5 81, and assumes errors in the three measures are uncorrelated produces reliability estimates of 89, 70, and 96 for CPS, OCG, and OCG-R, respectively The lower reliability of OCG is perhaps attributable to it being a mailback survey, while the others were telephone or personal interviews.
If we take the estimates of the first three studies in Table 10 at face value, their implication is that biases in estimating the effect of education on other variables due to errors in measuring years of schooling are not likely to be large There are, however, two important qualifications: (i) taking these estimates at face value means assuming that the errors in the alternative reports are (at least roughly) uncorrelated, (ii) as noted in Section 2, biases due to measurement error become more important if other (wellmeasured) explanatory variables are correlated with years of schooling.
A relatively extreme context for illustrating the latter point are recent "twin" studies that relate wage or earnings differences between twins to differences in their schooling. In effect, this strategy for estimating returns to education adds a set of dummy variables, one for each pair of twins, to a standard wage or earnings equation Such between-twin differencing has much the same effect as the first-differencing in panel data most of the variation in schooling is between rather than within twin pairs, and if reporting errors are not highly correlated the reliability of differences in education within twin pairs is likely to be lower than the reliability of reports of education in general.
Ashenfelter and Krueger (1994) obtained the usual information on wages and schooling in a sample of twins, and each sample member's report of the years of schooling completed by his or her twin This report of one's twin's schooling is highly correlated with the twin's own report (r = 9); assuming (as Ashenfelter and Krueger do) that errors in their own and twin reports are uncorrelated, this correlation is consistent with the reliability estimates in the earlier literature However the correlation between twin I's report of own schooling minus twin 2's report of own schooling and twin 2's report of l's schooling minus twin l's report of 2's schooling is only 57 in their sample of MZ (monozygotic, or "identical" twins) and 74 in a small sample of DZ (dizygotic, or "fraternal" twins) This suggests, for the MZ twins, that estimates of returns to schooling based on differencing wages and schooling between twins are likely to underestimate the true returns by over 40% IV estimates, using the difference in reports of twin's schooling as an instrument for one's own reports, are consistent with this calculation8 2.

81 Bielby et al argue that with true scores unobserved, the units of the "true" variable are arbitrary and regard the unit coefficient on the CPS measure as a normalization Their estimates suggest a slight positive correlation between error and true value for the two OCG measures. 82 The IV estimate reproduces this calculation if the maintained assumption that the covariance between the difference in wages and the difference in years of schooling is the same using either measure of the

3828

J Bound et al.

The assumption that reporting errors are uncorrelated with each other is subject to challenge on a number of grounds First, one might anticipate that the error made, for example, by twin 1 in reporting own schooling would be positively related with the error in twin 2's report of l's schooling 8 3, so that errors in the own and crossreports of the difference in schooling would be positively related This would lead the covariance between differences in years of schooling based on own reports and on twin reports to be greater than the variance of the true difference, and the bias due to measurement error understated by the classical model A second possibility is that errors in one twin's report of own and twin's schooling are positively related This would imply that twin l's report of own schooling would be more highly correlated with his/her report of 2's schooling than with 2's report of own schooling, and the data support this conjecture Ignoring such a correlation would lead the standard correction for the bias due to measurement error to be too large.
A solution to the second problem is to use one twin's report of the difference in schooling as an instrument for the other's report This leads to a downward revision, as expected, in the estimated return to schooling Behrman and Rosenzweig (1999), in contrast, find no evidence in their sample from the Minnesota Twin registry that errors in reports of own and twin's schooling are correlated, and so find estimated returns to schooling are unaffected by allowing for such a correlation.
A subsequent paper by Rouse (1999), using four waves of twin surveys rather than the first wave used by Ashenfelter and Krueger, found somewhat different substantive results 8S4 but quite similar conclusions as regards the importance of measurement error in the schooling variable 85 .
Miller, Mulvey and Martin (1995) conducted a similar analysis using a larger sample of Australian twins Their findings differ from the U S twin studies in two respects. First, the correlation between the difference in own reports and the difference in twin reports of education is substantially lower, at least for MZ twins Second, the variance of schooling using twin reports is lower than using own reports This suggests that the twin reports are more accurate or the errors are more mean-reverting, neither of which seem likely on a priori grounds.

difference in years of schooling As Ashenfelter and Krueger note, this is approximately true in their data. 83 While we lack a firm understanding of the situations which lead to errors in reporting schooling, it
seems reasonable that there would be certain situations in which errors are particularly frequent, and if there is an error it is particularly likely to go in one direction For example, if one ends one's schooling after a not-particularly-successful sophomore year of college, "true" years of schooling might be 17, with the most likely error reporting 18 instead If twin 1 is in this situation, both twin 1 and twin 2 would be more likely to over-report schooling (by one year) than to make some other error. 84 Unlike other twin studies, Ashenfelter and Krueger (1994) found that a first-differenced specification (not corrected for measurement error) leads to larger estimates ofthe returns to schooling than is obtained without fixed (twin) effects; Rouse's larger sample reaffirms the conventional wisdom in this regard. 85 Ashenfelter and Rouse (1998) use the first three waves of the twin survey; their correlations between own and twin reports are very similar to those from Rouse's study which uses four.

Ch 59: Measurement Error in Survey Data

3829

Kane, Rouse and Staiger (1999) return to the "standard" framework for estimating wage equations, simple cross-sections with no (identifiable) twins They focus instead on the assumption that the error in reporting years of schooling is unrelated to the true value As noted above, for binary variables (e g , has graduated from college vs has not graduated), any error must be negatively related to the true value The same sort of negative correlation is likely (though not inevitable) for bounded variables such as
schooling. Kane, Rouse and Staiger (1999) analyze schooling as reported by respondents in the
National Longitudinal Study of the Class of 1972, virtually all of whom graduate from high school Their focus is on reports of education beyond high school, as reported by NL572 respondents and as recorded in transcripts of all post-secondary schools they reported attending (which were collected as part of the NL572 study) While one might be tempted to take the latter as an indicator of "true" schooling, internal evidence suggests this is unlikely: holding constant BA receipt or non-receipt according to the transcript data, those who self-report having one earn higher wages than those who do not (and, less surprisingly, holding constant self-reported BA status, those who have a BA according to the transcript data earn higher wages than those who do not).
This provides the basis for a method-of-moments estimation strategy that does not rely on the standard IV assumption that measurement errors are uncorrelated with true values Kane, Rouse and Staiger (1999) do, however, maintain the standard assumption that errors in reporting schooling are uncorrelated with wages, with each other, and (in models with covariates) with the covariates In the simplest case, with schooling a binary variable and no covariates, there are seven unknowns: the intercept and BApremium in the In-wage equation, the true probability of having a BA, and four parameters of the "measurement" model (which has each measure of schooling as a linear function lwith interceptl of true schooling) There are also seven observable means or sample proportions: if we define a two-by-two table for combinations of selfand transcript-reported BA status, there is one mean In wage in each of these cells and four (but only three independent) sample proportions This equivalence provides the basis for jointly estimating wage equations and the measurement model by GMM. Kane, Rouse, and Staiger show how this intuition can be extended to many educational categories, and to include covariates (which lead to the model being over-identified).
Substantively, they find that most differences between self-reports and transcript data and most of the error, according to their GMM estimate occur where one or the other of the reports claims some college, but less than a BA degree This means that the extent to which OLS under-estimates and traditional IV overstates the return to schooling is largest as a proportion of the true value for those reporting some college. According to their estimates, OLS is less than the GMM estimate of returns to some college and a BA by about 02 (on a base of 125 and 308, respectively) while IV over-estimates each return by about the same amount lKane, Rouse and Staiger (1999,
Table 6)l. On balance, the studies in Table 10 support four general conclusions First, evidence
on the reliability of survey reports of educational attainment rely more on multiple

3830

J Bound et al.

measures, each of which is likely to contain non-negligible error, and less on direct validation evidence than is true for most of the other variables considered in this paper Second, unless there is substantial positive correlation of the errors in these multiple measures, the bias due to errors in measuring years of schooling in traditional applications such as cross-sectional earnings functions is unlikely to be large Third, while it is generally assumed that the errors are uncorrelated with each other and with the dependent variable (typically, In wage or In earnings), there is no direct evidence on this score Most discussions in the literature treat positive correlations as the most likely alternative; if positive is more likely than negative, there is every reason to fear that positive is more likely than zero Fourth, here as elsewhere, differencing (in this case, differences within twin pairs) greatly exacerbates the bias due to errors in measuring schooling, but the availability of reports of one's twin's schooling as well as one's own provides some leverage for undoing such bias.

7 Conclusions
Empirical research in economics has increasingly used individual or household-level data derived from surveys Unlike aggregate data based on surveys where one might hope that the errors would "cancel out", the move to micro data requires a continuous concern about measurement error as a likely source of bias 86 Some variables (transfer income, wealth holdings, medical care utilization and expenditures) are sufficiently difficult to measure that such concerns would arise even in estimating simple bivariate regressions; others (union coverage, schooling, and perhaps earnings) that seem to be reported with reasonable accuracy become candidates for concern when panel data are used in ways that effectively difference out much of the true variation while increasing the noise.
The impact of measurement error on parameter estimates depends on the magnitude of the error relative to the true variation, but more generally on the joint distribution of the measurement errors and the true variables If we are going to use data on X and y in order to study the impact of X* on y*, in principle we need to know the entire data-generating mechanism; that is , f(y,X,y*,X*) Standard methods for "correcting" for measurement error such as instrumental variables procedures typically

86 Our comments should not be taken to suggest we think aggregate data is without significant error. While response errors are presumably less important in aggregate data than they are in individual or household-level survey data, there are certainly other important sources of error Many aggregate series (e.g , unemployment rates) are based on survey data and, as such, are subject to sampling error More fundamentally, much aggregate data is constructed using procedures that are likely to introduce systematic error into data series Thus, for example the Department of Commerce's Bureau of Economic Analysis (BEA) uses procedures to construct value added lPeterson (1987)l that, outside of manufacturing and a few other industries are likely to underestimate the growth in output and thus productivity lGriliches (1994)l and to create spurious correlations between growth and productivity lWaldmann (1991)l Any discussion of such issues is well beyond the scope of this chapter.

Ch 59: Measurement Error in Survey Data

3831

involve strong assumptions regarding the nature of the data-generating mechanism (i.e , that errors are classical) that are rarely discussed or defended Short of detailed knowledge of the data-generating mechanism, the theoretical literature suggests that when the correlations between our measures and our constructs is high and when our models are simple, we can be reasonably confident regarding the robustness, in qualitative terms, of our inferences This is the situation where standard methods for correcting for measurement error have little effect on our estimates In contrast to this, in situations where we have reason to believe that measurement error on key variables is sufficiently large as to have qualitative effects on our estimates, serious sensitivity analysis is in order.
Validation data has provided considerable evidence on the magnitude of measurement error Gradually, the focus has shifted from the extent of under or overreporting (i.e , on the mean error) to the ratio of the variance of the reporting error to the variance of the true value, and more recently to consideration of whether errors are, as is so often assumed, uncorrelated with true values Such evidence as we have suggests that errors are often negatively related to true values and, indeed, this must be so for binary variables Fewer studies focus on the correlation between errors in measuring one variable and either measured or true values of other variables The very limited evidence we have suggests that such correlations do not lead to appreciable or predictable biases except in contexts where variables are definitionally related (e g , hours worked per week and earnings per hour defined as weekly earnings/weekly hours).
Despite the effort that has gone into validating various survey measures, it is striking to us how little is known about the accuracy of much of the data that is routinely collected in household surveys To take a simple example, there is no hard evidence on how reliably hourly earnings are reported for men and women paid by the hour. Nor is there much data on the accuracy with which individuals report wealth or consumption expenditures In other contexts, such as for health conditions, we know something about the accuracy of such reports, but virtually nothing about the impact that misreporting has on parameter estimates Similarly, there are many studies of the accuracy of retrospective reporting of events, but few clues as to how the (often important) errors found in such studies will bias parameter estimates of event-history studies.
Increasing use of panel data has been accompanied with a heightened awareness of the tendency of such estimation to increase the importance of measurement error The panel-data literature has benefitted from simple, intuitive results that alert analysts to situations where such errors are likely to be most harmful Unfortunately, even the most rudimentary corrections for measurement error in such contexts depend on knowing the correlation between errors3/4for an individual's wage over time, for twins' reports of their education, etc and there is almost no direct evidence on such correlations. Obtaining validation data sufficient to calculate such correlations requires at least two rounds of survey data and either two rounds of validation data (e g , the PSID Validation Study) or the good fortune to be able to obtain validation of two rounds of

3832

J Bound et al.

survey data in a single step (e g , the matched CPS-SSA data, and matches of transfer program records to SIPP data) Hopefully, in the future, it will be possible to merge administrative data to existing panel data.
As with panel data, there is good reason to fear that parameter estimates in nonlinear models are likely to be more sensitive to measurement error than those in simple (linear) models Unfortunately, the analysis of non-linear models has proceeded on a case-by-case basis, and it has not highlighted any key feature of the error distribution for validation studies to assess Thus, analysts must often choose between less ambitious linear models for which the consequences of measurement error is better understood and more elaborate models which may well be more vulnerable to such errors At a minimum, assessment of the relative benefits of the two approaches needs to put greater weight on this vulnerability.
One reason for remaining gaps in our knowledge about the inaccuracies of survey data is that users of the data are rarely involved in the validation studies 87 As a result, it is natural for them to focus on the accuracy of the reports rather than the effect of inaccuracies on parameter estimates Since different researchers are interested in different parameters, researchers conducting validation studies will never be able to satisfy all audiences However, researchers can sometimes make their data publically available It is interesting to note that both the CPS-SSA data by Bound and Krueger and the PSID-V data have been put to very good use by researchers outside the teams that originally developed the two data sets le g , Bollinger (1998), Pischke (1995), French (1998), Brownstone and Valletta (1996)l In addition, there are clear payoffs to greater involvement of users in the design of validation studies.
While in general we believe that more effort devoted to collecting and analyzing validation data would significantly enhance the value of survey data, it is important to recognize the limitations of such initiatives Those collecting validation data usually begin with the intention of obtaining "true" values against which the errors of survey reports can be assessed; more often than not we end up with the realization that the validation data are also imperfect While much can still be learned from such data, particularly if one is confident the errors in the validation data are uncorrelated with those in the survey reports, this means replacing one assumption (e g , errors are uncorrelated with true values) with another (e g , errors in survey reports uncorrelated with errors in validation data).
Many of the validation studies reported in this chapter are based on small convenience samples (workers in a firm which cooperates by providing payroll records, households with accounts at cooperating financial institutions) The use of small samples means the reliability of the data is itself assessed with considerable sampling error Moreover, the distribution of the variables of interest may well differ in the smaller validation sample and the large sample about which one wishes to make

87 These comments echo somewhat similar comments often made by Griliches (e g , 1986, 1994) that economists should become more involved in the generation of the data they use.

Ch 59: Measurement Errorin Survey Data

3833

inferences (e g , true wage variation will be smaller within one firm than in the economy) Even when validation data is provided for a sizeable share of a larger survey, concerns about representativeness are hard to dismiss (are those who underreport transfers less likely to cooperate in validating their responses?).
A final limitation of validation studies is that, even if the validation corresponds exactly to the "correct" answer to the survey question, it may not correspond to the "true" value of the variable in question On the one hand, the construct we wish to test may be more subtle than questions that our surveys can ask For example, earnings presumably depend on the interaction of years of schooling, school quality, and student effort that produce "education" or "learning"; the gap between "education" and "years of schooling" will remain no matter how successful we are in inducing individuals to accurately report their years of schooling On the other hand, in some cases it may be the respondent's perception of a variable rather than the "true" value of the variable that motivates behavior Thus, for example, savings behavior of smokers may depend on their own estimate of their life-expectancy, not the Surgeon General's.
It is widely recognized that survey data and, indeed, other types of data are often imperfect Analyzing such data requires an understanding of their most significant shortcomings Validation data are often imperfect, too But they give important clues about these shortcomings clues that would otherwise be unavailable and suggest strategies for dealing with them As econometricians create more complicated tools, understanding the effects of imperfect data on the performance of these tools becomes more important Validation studies are an essential part of that enterprise.

References
Abowd, J M , and D Card (1987), "Intertemporal labor supply and long-term employment contracts", American Economic Review 77:50-68.
Abowd, J M , and D Card (1989), "On the covariance structure of earnings and hours changes", Econometrica 57:411-445.
Abowd, J M , and A Zellner (1985), "Estimating gross labor-force flows", Journal of Business and Economic Statistics 3:254-283.
Abrevaya, J , and J A Hausman (1997), "Semiparametric estimation with mismeasured dependent variables: an application to panel data on unemployment spells", Mimeo (University of Chicago, Graduate School of Business; MIT Department of Economics).
Aigner, D J (1973), "Regression with a binary independent variable subject to errors of observation", Journal of Econometrics 1:49-59.
Aigner, D J , C Hsiao, A Kapteyn and T Wansbeek (1984), "Latent variable models in econometrics", in Z Griliches and M D Intriligator, eds , Handbook of Econometrics, Vol II (North-Holland, Amsterdam) 1323 1393.
Akerlof, G , and J Yellen (1985), "Unemployment through the filter of memory", Quarterly Journal of Economics 100:747-783.
Amemiya, T (1974), "The nonlinear two-stage least-squares estimator", Journal of Econometrics 2:105-110.
Amemiya, Y (1985), "Instrumental variable estimator for the nonlinear errors-in-variables model", Journal of Econometrics 28:273-289.

3834

J Bound et al.

Amemiya, Y (1990), "Two-stage instrumental variable estimators for the nonlinear errors-in-variables model", Journal of Econometrics 44:311-332.
Andersen, E B (1982), "Latent structure analysis: a survey", Scandinavian Journal of Statistics", 9:1-12. Anderson, K H , and R V Burkhauser (1984), "The importance of the measure of health in empirical
estimates of the labor supply of older men", Economics Letters 16:375-380. Anderson, K H , and R V Burkhauser (1985), "The retirement-health nexus: a new measure of an old
puzzle", Journal of Human Resources 20:315-330. Angrist, J , and A Krueger (1999), "Empirical strategies in labor economics", in: O Ashenfelter and
D Card, eds , Handbook of Labor Economics, Vol 3A (North-Holland, Amsterdam) 1277-1366. Ashberg, K (1987), "Disability as a predictor of outcome for the elderly in a department of internal
medicine", Scandinavian Journal of Social Medicine 15:26-265. Ashenfelter, O , and A Krueger (1994), "Estimates of the economic return to schooling from a new
sample of twins", American Economic Review 84:1157-1173. Ashenfelter, O , and C E Rouse (1998), "Income, schooling, and ability: evidence from a new sample
of identical twins", Quarterly Journal of Economics 113:253-284. Bailar, B A (1975), "The effects of rotation group bias on estimates from panel surveys", Journal of
the American Statistical Association 70:23-30. Baker, M (1997), "Growth-rate heterogeneity and the covariance structure oflife-cycle earnings", Journal
of Labor Economics 15:338-375. Baker, M , and G Solon (1998), "Earnings dynamics and inequality among Canadian men, 1976-1992:
evidence from longitudinal income tax records", Unpublished manuscript (University of Michigan). Bancroft, G (1940), "Consistency of information from records and interviews", Journal ofthe American
Statistical Association 35:377-381. Barron, J M , M C Berger and D A Black (1997), On the Job Training (W E Upjohn Institute for
Employment Research, Kalamazoo, MI). Behrman, J R , and M R Rosenzweig (1999), "Ability" biases in schooling returns and twins: a test and
new estimates", Economics of Education Review, 18:159-167. Berger, M C , D A Black and EA Scott (1998), "How well do we measure employer-provided health
insurance coverage?" Contemporary Economic Policy 16:356-367. Bergner, M , R Bobbitt, S Kressel, W Pollard, B Gilson and J Morris (1976), "The sickness impact
profile: conceptual formulation and methodology for the development of a health status measure", International Journal of Health Services 6:393-415. Bergner, M , R Bobbitt, W Carter and B Gilson (1981), "The sickness impact profile: development and final revision of a health status measure", Medical Care 19:787-805. Bielby, W T, R M Hauser and D L Featherman (1977), "Response errors of non-black males in models of the stratification process", in: D J Aigner and A S Goldberger, eds , Latent Variables in Socio-Economic Models (North-Holland, Amsterdam) 227-251. Bishop, J H (1974), "Biases in measurement of the productivity benefits of human capital investments", Discussion Paper 223-74 (Institute for Research on Poverty, University of Wisconsin). Black, D , M Berger and E Scott (2000), "Bounding parameter estimates with mismeasured data", Journal of the American Statistical Association 95:739-748. Blair, E , and S Burton (1987), "Cognitive processes used by survey respondents to answer behavioral frequency questions", Journal of Consumer Research 14:280-288. Bollinger, C R (1996), "Bounding mean regressions when a binary regressor is mismeasured", Journal of Econometrics 73:387-399. Bollinger, C R (1998), "Measurement error in the current population survey: a nonparametric look", Journal of Labor Economics 16:576-594. Bollinger, C R , and M H David (1997), "Measuring discrete choice with response error: food stamp participation", Journal of the American Statistical Association 92:827-835. Borus, M (1966), "Response error in survey reports of earnings information", Journal of the American Statistical Association 61:729-738.

Ch 59: Measurement Errorin Survey Data

3835

Borus, M (1970), "Response error and questioning technique in surveys of earnings information", Journal of the American Statistical Association 65:566-575.
Bound, J (1991), "Self-reported vs Objective measures of health in retirement models", Journal of Human Resources 26:106-138.
Bound, J , and A Krueger (1991), "The extent of measurement error in longitudinal earnings data: do two wrongs make a right?" Journal of Labor Economics 12:345-368.
Bound, J, C Brown, G J Duncan and W L Rodgers (1989), "Measurement error in cross-sectional and longitudinal labor market surveys: results from two validation studies", Working Paper 2884 (National Bureau of Economic Research).
Bound, J , C Brown, G J Duncan and WL Rodgers (1994), "Evidence on the validity of cross-sectional and longitudinal labor market data", Journal of Labor Economics 12:345-368.
Bound, J , M Schoenbaum and T Waidmann (1995), "Race and education differences in disability status and labor force attachment in the health and retirement survey", The Journal of Human Resources 30:5227-5267.
Bound, J , M Schoenbaum, T R Stinebrickner and T Waidmann (1999), "The dynamic effects of health on the labor force transitions of older workers", Labour Economics 6:179-202.
Bowers, N , and E Horvath (1984), "Keeping time: an analysis of errors in the measurement of unemployment duration", Journal of Business and Economic Statistics 2:140-149.
Branden, L , and M Pergamit (1994), "Response error in reporting starting wages", Paper presented at the Annual Meetings of the American Association for Public Opinion Research.
Brown, C , and J Medoff( 1996), "Employer characteristics and work environment", Annales D'Economie et de Statistique 41:275-298.
Brown, J N , and A Light (1992), "Interpreting panel data on job tenure", Journal of Labor Economics 10:219-257.
Brownstone, D ( 1998), "Multiple imputation methodology for missing data, non-random response and panel attrition", in: T Garling, T Laitila and K Westin, eds , Theoretical Foundations of Travel Choice Modeling (Elsevier, Amsterdam).
Brownstone, D , and R Valletta (1996), "Modeling earnings measurement error: a multiple imputation approach", Review of Economics and Statistics 78:705-717.
Burkhead, D , and J Coder (1985), "Gross changes in income recipiency from the survey of income and program participation", Proceedings of the Section on Social Statistics (American Statistical Association, Alexandria, VA) 351-356.
Burtless, G (1987), "Occupational effects of the health and work capacity of older men", in: G Burtless, ed., Work, Health and Income Among the Elderly (Brookings Institution, Washington, DC).
Burton, S , and E Blair (1991), "Task conditions, response formulation processes, and response accuracy for behavioral frequency questions in surveys", Public Opinion Quarterly 55:50-79.
Cannell, C , and F Fowler (1963), A Study of Reporting of Visits to Doctors in the National Health Survey (Survey Research Center, Ann Arbor, MI).
Cannell, C , G Fisher and T Bakker (1965), "Reporting of hospitalizations in the health interview survey", Vital and Health Statistics, Series 2, Number 6 (Public Health Service, Washington).
Card, D (1996), "The effect of unions on the structure of wages: a longitudinal analysis", Econometrica 64:957-979.
Carroll, R , and L A Stefanski (1990), "Approximate quasi-likelihood estimation in models with surrogate predictors", Journal of the American Statistical Association 85:652-663.
Carroll, R , J Ruppert and L A Stefanski (1995), Measurement Error in Nonlinear Models (Chapman and Hall, London).
Carstensen, L , and H Woltman (1979), "Comparing earning data from the CPS and employer's records", Proceedings of the Social Statistics Section (American Statistical Association, Alexandria, VA) 168 173.
Cash, WS , and A J Moss (1972), "Optimum recall period for the reporting of persons injured in

3836

J Bound et a.

motor vehicle accidents", Vital and Health Statistics, Series 2, Number 5 (U S Public Health Service,
Washington). Chamberlain, G , and Z Griliches (1975), "Unobservables with a variance components structure: ability,
schooling and the economics success of brothers", International Economic Review 16:422-49. Chase, D R , and M Harada (1984), "Response error in self-reported recreation participation", Journal
of Leisure Research 16:322-329. Chirikos, T N , and G Nestel (1981), "Impairment and labor market outcomes: a cross-sectional and
longitudinal analysis", in: H Parnes, ed , Work and Retirement: A Longitudinal Study of Men (MIT
Press, Cambridge, MA) 93-131. Chua, TC , and W Y Fuller (1987), "A model for multinomial response error applied to labor flows",
Journal of the American Statistical Association 82:46-51. Coder, J (1992), "Using administrative record information to evaluate the quality of the income data
collected in the survey of income and program participation", Proceedings of Statistics Canada Symposium 92, Design and Analysis of Longitudinal Surveys (Statistics Canada, Ottawa) 295-306. Cohen, S, and B Carlson (1994), "A comparison of household and medical provider reported expenditures in the 1987 NMES", Journal of Official Statistics 10:3-29. Cragg, J G (1997), "Using higher moments to estimate the simple errors-in-variables model", RAND
Journal of Economics 28:571-91. Currie, J, and B C Madrian (1999), "Health, health insurance and the labor market", in:O Ashenfelter
and D Card, eds , Handbook of Labor Economics, Vol 3 C (North-Holland, Amsterdam) 3309-3416. Curtin, R E, ET Juster and J Morgan (1989), "Survey estimates of wealth: an assessment of quality",
in: R E Lipsey and H E Tice, eds , The Measurement of Saving, Investment, and Wealth (University
of Chicago Press, Chicago). Dagenais, M G , and DL Dagenais (1997), "Higher moment estimators for linear regression models
with errors in the variables", Journal of Econometrics 76:193-221. David, M (1962), "The validity of income reported by a sample of families who received welfare
assistance during 1959", Journal of The American Statistical Association 57:680-685. Dhondt, A (1960), "Sur une gnr6alisation d'un theorme de R Frisch en analyse de confluence",
Cahiers du Centre d'Etudes de Recherche Operationnelle 2:37-46. Dibbs, R , A Hale, R Loverock and S Michaud (1995), "Some effects of computer assisted interviewing
on the data quality of the survey of labour and income dynamics", SLID Research Paper, Series
No 95-07 (Statistics Canada, Ottawa). Dickens, W T , and B A Ross (1984), "Consistent estimation using data from more than one sample",
Technical Working Paper 33 (NBER). Dodge, R W (1970), "Victim recall pretest", Unpublished memorandum (U S Bureau of the Census,
Washington, DC). Dreher, G (1977), "Nonrespondent characteristics and respondent accuracy in salary research", Journal
of Applied Psychology 62:773-776. Duncan, G , and D Hill (1985), "An investigation of the extent and consequences of measurement error
in labor economic survey data", Journal of Labor Economics 3:508-522. Duncan, G , and N Mathiowetz (1985), A Validation Study of Economic Survey Data (Survey Research
Center, University of Michigan, Ann Arbor). Ferber, R (1966), The Reliability of Consumer Reports of Financial Assets and Debts (Bureau of
Economic and Business Research, University of Illinois, Urbana, IL). Ferber, R , J Forsythe, H Guthrie and E Maynes (1969a), "Validation of a national survey of financial
characteristics: savings accounts", Review of Economics and Statistics 51:436-444. Ferber, R , J Forsythe, H Guthrie andE Maynes (1969b), "Validation ofconsumer financial characteristics:
common stock", Journal of the American Statistical Association 64:415-432. Ferraro, K E (1980), "Self-ratings of health among the old and old-old", Journal of Health and Social
Behavior 21:377-383.

Ch 59: Measurement Error in Survey Data

3837

Freeman, R B (1984), "Longitudinal analyses ofthe effects of trade unions", Journal of Labor Economics 2:1-26.
French, E (1998), "The labor supply response to (measured but) predictable wage changes", Unpublished manuscript (Department of Economics, University of Wisconsin).
Fuller, W (1987), Measurement Error Models (Wiley, New York). Garber, S , and S Klepper (1980), "Extending the classical normal errors-in-variables model",
Econometrica 48:1541-1546. Geary, R C (1942), "Inherent relationships between random variables", Proceedings of the Royal Irish
Academy Section A 47:63-76. Gems, B , D Ghosh and R Hitlin (1982), "A recall experiment: impact of time on recall of
recreational fishing trips", Proceedings of the Section on Survey Research Methods (American Statistical Association, Alexandria, VA) 168-173. Geronimus, A T , J Bound and L J Neidert (1996), "On the validity ofusing census geocode characteristics to proxy individual socioeconomic characteristics", Journal of the American Statistical Association 91:529-537. Gini, C (1921), "Sull'interpolazione di una retta quando i valori della variabile indipendente sono affetti da errori accidntali", Metron 1:63-82. Goldberger, A S (1972), "Structural equation methods in the social sciences", Econometrica 40: 979-1001. Goodman, L A (1974a), "The analysis of systems of qualitative variables when some of the variables are unobservable, Part I, A modified latent structure approach", American Journal of Sociology 79:1179-1259. Goodman, L A (1974b), "Explanatory latent structure analysis using both identifiable and unidentifiable models", Biometrika 61:215-231. Goodreau, K , H Oberheu and D Vaughan (1984), "An assessment of the quality of survey reports of income from the aid to families with dependent children (AFDC) program", Journal of Business and Economic Statistics 2:179-186. Greenberg, D , and H Halsey (1983), "Systematic misreporting and effects of income maintenance experiments on work effort: evidence from the Seattle-Denver experiment", Journal ofLabor Economics 1:380-407. Griliches, Z (1974), "Errors in variables and other unobservables", Econometrica 42:971-998. Griliches, Z (1986), "Economic data issues", in: Z Griliches and M D Intriligator, eds , Handbook of Econometrics, Vol 3 (North-Holland, Amsterdam) 1466-1514. Griliches, Z (1994), "Productivity, R&D, and the data constraint", American Economic Review 84:1-23. Griliches, Z , and J A Hausman (1986), "Errors in variables in panel data", Journal of Econometrics 31:93-118. Griliches, Z , and V Ringstad (1970), "Error in the variables bias in nonlinear contexts", Econometrica 38:368-370. Grondin, C , and S Michaud (1994), "Data quality of income data using computer-assisted interview: the experience of the Canadian survey of labour and income dynamics", Proceedings of the Survey Research Methods Section (American Statistical Association, Alexandria, VA) 830-835. Groves, R M (1989), Survey Errors and Survey Costs (Wiley, New York). Gustman, A L , and T L Steinmeier (1999), "What people don't know about their pensions and social security: an analysis using linked data from the health and retirement study", Working Paper 7368 (NBER). Haber, L (1966), "Evaluating response error in the reporting of the income of the aged: benefit income", Proceedings of the Social Statistics Section (American Statistical Association, Alexandria, VA) 412-419. Haberman, S J (1977), "Product models for frequency tables involving indirect observation", Annals of Statistics 5:1124-1147.

3838

J Bound et al.

Haider, S (2001), "Earnings instability and earnings inequality of males in the United States: 1967-1991", Journal of Labor Economics, forthcoming.
Hall, R E , and ES Mishkin (1982), "Sensitivity of consumption to transitory income: estimates from panel data on households", Econometrica 50:461-481.
Halsey, H (1978), "Validating income data: lessons from the Seattle and Denver income maintenance experiment", Proceedings of the Survey of Income and Program Participation Workshop, Survey Research Issues in Income Measurement: Field Techniques, Questionnaire Design, and Income Validation (U S Department of Health, Education, and Welfare, Washington, DC).
Hamermesh, D S (1990), "Shirking or productive schmoozing: wages and the allocation of time at work", Industrial and Labor Relations Review 43:1215-1335.
Hampel, F, E Ronchetti, P Rousseeuw and W Stahel (1986), Robust Statistics (Wiley, New York). Hardin, E , and G Hershey (1960), "Accuracy of employee reports on changes in pay", Journal of
Applied Psychology 44:269-275. Hausman, J A , J Abrevaya and E Scott-Morton (1998), "Misclassification of the dependent variable in
a discrete response setting", Journal of Econometrics 87:239-269. Heckman, J J (1978), "Dummy endogenous variables in a simultaneous equation system", Econometrica
46:931-959. Heckman, J J , and R Robb Jr (1985), "Alternative methods for evaluating the impact of interventions", in:
J.J Heckman and B Singer, eds , Longitudinal Analysis of Labor Market Data (Cambridge University
Press, Cambridge) 156-246. Heckman, J J , R J La Londe and J A Smith (1999), "The economics and econometrics of active labor
market programs", in:O Ashenfelter and D Card, eds , Handbook of Labor Economics, Vol 3A
(North-Holland, Amsterdam) 1865-2097. Heeringa, S G , D H Hill and DA Howell (1995), "Unfolding brackets for reducing item nonresponse in
economic surveys", Health and Retirement Study Working Paper 94-027 (Institute for Social Research,
Ann Arbor, MI). Hill, D (1987), "Response errors around the seam: analysis of change in a panel with overlapping
reference periods", Proceedings of the Section on Survey Research Methods (American Statistical
Association, Alexandria, VA) 210-215. Hoaglin, D (1978), "Household income and income reporting error in the housing allowance demand
experiment", Proceedings of the Survey of Income and Program Participation Workshop, Survey Research Issues in Income Measurement: Field Techniques, Questionnaire Design, and Income Validation (U S Department of Health, Education, and Welfare, Washington, DC). Horowitz, J L, and C E Manski (1995), "Identification and robustness with contaminated and corrupted
data", Econometrica 63:281-302. Horvath, F (1982), "Forgotten unemployment: recall bias in retrospective data", Monthly Labor Review
105:40-43. Hotz, VJ, C Mullin and S Sanders (1997), "Bounding causal effects using data from a contaminated
natural experiment: analyzing the effects of teenage childbearing", Review of Economic Studies
64:575-603. Hsiao, C (1989), "Consistent estimation for some nonlinear errors-in-variables models", Journal of
Econometrics 41:159-185. Hu, T (1971), "The validity of income and welfare information reported by a sample of welfare
families", Proceedings of the Social Statistics Section (American Statistical Association, Alexandria,
VA) 311-313. Huber, P (1981), Robust Statistics (Wiley, New York). Hurd, M D , and W Rodgers (1998), "The effects of bracketing and anchoring on measurement in the
health and retirement study" (Institute for Social Research, Ann Arbor, MI). Hurd, M D , D McFadden, H Chand, L Gan, A Merill and M Roberts (1998), "Consumption and
savings balances of the elderly: experimental evidence on survey response bias", in: D Wise, ed , Frontiers in the Economics of Aging (University of Chicago Press, Chicago) 353-387.

Ch 59: Measurement Error in Survey Data

3839

Hurst, E , M C Luoh and EP Stafford (1998), "The wealth dynamics of American families, 1984-94", Brookings Papers on Economic Activity 1998:267-337.
Hwang, G T , and L A Stefanski (1994), "Monotonicity ofregression functions in structural measurement error models", Statistics and Probability Letters 20:113-116.
Idler, E I , and Y Benyamini (1997), "Self-rated health and mortality: a review of twenty-seven community studies", Journal of Health and Social Behavior 39:21-37.
Johnson, A , and M E Sanchez (1993), "Household and medical provider reports on medical conditions: national medical expenditure survey, 1987", Journal of Economic and Social Measurement 19: 199-223.
Juster, ET , and J P Smith (1997), "Improving the quality of economic data: lessons from the HRS and AHEAD", Journal of the American Statistical Association 92:1268-1277.
Juster, ET , J P Smith and EP Stafford (1999), "The measurement and structure of household wealth", Labour Economics 6:253-273.
Kaestner, R , T Joyce and H Wehbeh (1996), "The effect of maternal drug use on birth weight: measurement error in binary variables", Economic Inquiry 34:617-629.
Kane, T J , C E Rouse and D Staiger (1999), "Estimating the returns to schooling when schooling is misreported", Working Paper 7235 (NBER).
Kapteyn, A ,and T Wansbeek (1983), "Identification in the linear errors in variables model" Econometrica 51:1847-49.
Katz, S , and C Akpom (1976), "Index of ADL", Medical Care 14:116-118. Katz, S , A Ford, R Moskowitz, B Jacobsen and M Jaffe (1963), "Studies of illness in the aged:
the index of ADL: a standardized measure of biological and psychosocial function", Journal of the American Medical Association 185:914-919. Katz, S , T Downs, H Cash and R Grotz (1970), "Progress in development of the index of ADL", Gerontologist 10:20-30. Keating, E , D Paterson and C Stone (1950), "Validity of work histories obtained by interview", Journal of Applied Psychology 34:6-11. Kish, L , and J B Lansing (1954), "Response errors in estimating the value of homes", Journal of the American Statistical Association 49:520-538. Klein, B , and D Vaughan (1980), "Validity of AFDC reporting among list frame recipients", in: J Olson, ed., Reports from the Site Research Test (U S Department of Health and Human Services, Washington, DC) ch 11. Klepper, S , and E E Leamer (1984), "Consistent sets of estimates for regressions with errors in all variables", Econometrica 52:163-184. Koopmans, T C (1937), Linear Regression Analysis of Economic Time Series (Netherlands Econometric Institute, de Erven E Bohn N V, Haarlem). Krasker, W, and J Pratt (1986), "Bounding the effects of proxy variable on regression coefficients", Econometrica 54:641-656. Krueger, A B , and L H Summers (1988), "Efficiency wages and the inter-industry wage structure", Econometrica 56:259-293. Lambrinos, J (1981), "Health: a source of bias in labor supply models", Review of Economics and Statistics 63:206-212. Lansing, J B , G Ginsburg and K Braaten (1961), An Investigation of Response Error (Bureau of Economic and Business Research, University of Illinois, Urbana IL). LaRue, A , L Bank, L Jarvic and M Hewtland (1979), "Health in old age: how physicians' rating and self-ratings compare", Journal of Gerontology 34:687-691. Lavy, V, M Palumbo and S Stern (1998), "Simulation ofmultinomial probit probabilities and imputation", in: T Fomby and R Hill, eds , Advances in Econometrics (JAI Press, Greenwich CT). Lee, L E (1982a), "Health and wage: a simultaneous equation model with multiple discrete indicators", International Economic Review 23:199-221.

3840

J Bound et al.

Lee, L E (1982 b), "Simultaneous equations models with discrete and censored variables", in: C Manski and D McFadden, eds , Structural Analysis of Discrete Data with Econometric Applications (MIT Press, Cambridge, MA).
Lee, L E, and J Sepanski (1995), "Estimation of linear and nonlinear errors-in-variables models using validation data", Journal of the American Statistical Association 90:130-140.
Levi, M D (1973), "Errors in the variables bias in the presence of correctly measured variables", Econometrica 41:985-986.
Levine, P (1993), "CPS contemporaneous and retrospective unemployment compared", Monthly Labor Review 116:33-39.
Lewbel, A (1997), "Constructing instruments for regressions with measurement error when no additional data are available, with an application to patents and R&D", Econometrica 65:1201-1213.
Little, R J (1992), "Regression with missing X's: a review", Journal of the American Statistical Association 87:1227-1237.
Little, R J , and D B Rubin (1987), Statistical Analysis with Missing Data (Wiley, New York). Livingston, R (1969), "Evaluation of the reporting of public assistance income in the special census
of Dane County, Wisconsin: May 15, 1968 ", Proceedings of the Ninth Workshop on Public Welfare Research and Statistics, 59-72. Loeb, S , and J Bound (1996), "The effect of measured school inputs on academic achievement: evidence from the 1920s, 1930S and 1940S birth cohorts", Review of Economics and Statistics LXXVIII:653-664. Loftus, EF (1975), "Leading questions and the eyewitness report", Cognitive Psychology 7:560-572. MaCurdy, T E (1982), "The use of time series processes to model the error structure of earnings in a longitudinal data analysis", Journal of Econometrics 18:83-114. Maddala, G S (1983), Limited-dependent and Qualitative Variables in Econometrics (Cambridge University Press, Cambridge). Maddox, G , and E Douglas (1973), "Self-assessment ofhealth: a longitudinal study ofelderly subjects", Journal of Health and Social Behavior 14:87-93. Madow, W (1973), "Net differences in interview data on chronic conditions and information derived from medical records", Vital and Health Statistics, Series 2, No 23 (U S Government Printing Office, Washington, DC). Manning Jr, WG , J P Newhouse and J E Ware Jr (1982), "The status of health in demand estimation, or beyond excellent, good, fair and poor", in: VR Fuchs, ed , Economic Aspects of Health (University of Chicago Press, Chicago). Marquis, K H , and J C Moore (1990), "Measurement errors in survey ofincome and program participation (SIPP) program reports", Proceedings of the Sixth Annual Research Conference (U S Bureau of the Census, Washington, DC) 721 745. Mathiowetz, N (1986), "The problem of omissions and telescoping error: new evidence from a study of unemployment", Proceedings of the Section on Survey Research Methods (American Statistical Association, Alexandria, VA). Mathiowetz, N (1992), "Errors in reports of occupation", Public Opinion Quarterly 56:352-355. Mathiowetz, N , and G Duncan (1988), "Out of work, out of mind: response errors in retrospective reports of unemployment", Journal of Business and Economic Statistics 6:221-229. Mathiowetz, N , and T Lair (1994), "Getting better? Change or error in the measurement of functional limitations", Journal of Economic and Social Measurement 20:237-262. Maynes, E (1965), "The anatomy of response errors: consumer saving " Journal of Marketing Research 2:378-387. McCallum, B T (1972), "Relative asymptotic bias from errors of omission and measurement", Econometrica 40:757-758. McHorney, C , J Ware, J Lu and C Sherbourne (1994), "The MOS 36-item short-form health survey (SF-36), III Test of data quality, scaling assumptions, and reliability across diverse patient groups", Medical Care 32:40-66.

Ch 59: Measurement Error in Survey Data

3841

McHorney, C , M Kosinski and J Ware (1994), "Comparison of the costs and quality of norms collected by mail versus telephone interview: results from a national study", Medical Care 32:551-567.
Mellow, W , and H Sider (1983), "Accuracy of response in labor market surveys: evidence and implications", Journal of Labor Economics 1:331-344.
Menon, G (1994), "Judgements of behavioral frequencies: memory search and retrieval strategies", in: N Schwarz and S Sudman, eds , Autobiographical Memory and the Validity of Retrospective Reports (Springer, New York) 161-172.
Miller, H , and L Paley (1958), "Income reported in the 1950 census and on income tax returns", An Appraisal of the 1950 Census Income Data (Princeton University Press, Princeton NJ) 179-201.
Miller, P, C Mulvey and N Martin (1995), "What do twin studies reveal about the economic returns to education? A comparison of Australian and U S findings", American Economic Review 85:586-599.
Mitchell, O (1988), "Workerknowledge ofpension provisions", Journal ofLabor Economics 6(1):21-39. Moore, J C , and D Kasprzyk (1984), "Month-to-month recipiency turnover in the ISDP", Proceedings
of the Section on Survey Research Methods (American Statistical Association, Alexandria, VA) 210-215. Moore, J C , K H Marquis and K Bogen (1996), "The SIPP cognitive research evaluation experiment: basic results and documentation", Unpublished report (U S Bureau of the Census). Moore, J C , L Stinson and E Welniak (2000), "Income measurement error in surveys: a review", Journal of Official Statistics 16(4):331-361. Morgenstern, R , and N Barrett (1974), "The retrospective bias in unemployment reporting by sex, race, and age", Journal of the American Statistical Association 69:355-357. Mossey, J M , and E Shapiro (1982), "Self-rated health: a predictor of mortality among the elderly", American Journal of Public Health 72:800-808. Murphy, L R , and C D Cowan (1976), "Effects of bounding on telescoping in the national crime survey", Proceedings of the Social Statistics Section (American Statistical Association, Alexandria, VA) 633-638. Muthen, B (1983), "Latent variable structural equation modeling with categorical data", Journal of Econometrics 22:43-65. Myers, R J (1982), "Why do people retire from work early?" Aging and Work 5:83-91. Nagi, S Z (1969), "Congruency in medical and self-assessment of disability", Industrial Medicine 38:74-83. National Center for Health Statistics (1961), "Health interview responses compared with medical records", Vital and Health Statistics, Series D, No 5 (U S Government Printing Office, Washington, DC). National Center for Health Statistics (1967), "Interview data on chronic conditions compared with information derived from medical records", Vital and Health Statistics, PHS Pub No 1000, Series 2, No 23 (U S Government Printing Office, Washington, DC). Neter, J , and J Waksberg (1964), "A study of response errors in expenditures data from household interviews", Journal of the American Statistical Association 59:18-55. Newey, WK , and D McFadden (1994), "Large sample estimation and hypothesis testing", in: R E Engle and D L McFadden, eds , Handbook of Econometrics, Vol 4 (North-Holland, Amsterdam) 21112245. Nunnally, J , and I Bernstein (1994), Psychometric Theory (McGraw-Hill, New York). Oberheu, H , and M Ono (1975), "Findings from a pilot study of current and potential public assistance recipients included in the current population survey", Proceedings of the Social Statistics Section (American Statistical Association, Alexandria, VA) 576-579. Pakes, A (1982), "On the asymptotic bias of Wald-type estimators of a straight line when both variables are subject to error", International Economic Review 23:491-497. Pal, M (1980), "Consistent moment estimators of regression coefficients in the presence of errors in variables", Journal of Econometrics 14:349-364. Parsons, D O (1982), "The male labor force participation decision: health, reported health, and economic incentives", Economica 49:81-91.

3842

J Bound et al.

Patefield, W M (1981), "Multivariate linear relationships: maximum likelihood estimation and regression bounds", Journal of the Royal Statistical Society B 43:342-352.
Peterson, M O (1987), "Gross product by industry, 1986", Survey of Current Business 67:25-27. Pischke, J S (1995), "Measurement error and earnings dynamics: some estimates from the PSID validation
study", Journal of Business and Economic Statistics 13:305-314. Poterba, J M , and L S Summers (1984), "Response variation in the CPS: caveats for the unemployment
analyst", Monthly Labor Review 107:37-42. Poterba, J M , and L S Summers (1986), "Reporting errors and labor market dynamics", Econometrica
54:1319-1338. Poterba, J M , and L S Summers (1995), "Unemployment benefits and labor market transitions: a
multinomial logit model with errors in classification", Review of Economics and Statistics 77:207-216. Reiersol, O (1945), "Confluence analysis by means of instrumental sets of variables", Arkiv for
Mathematik, Astronomi och Fysik 32:1-119. Reiersol, O (1950), "Identifiability of a linear relation between variables which are subject to error",
Econometrica 18:375-389. Robinson, J , and A Bostrom (1994), "The overestimated workweek? What time-diary measures suggest",
Monthly Labor Review 117:11-23. Rodgers, W , and B Miller (1997), "A comparative analysis of ADL questions in surveys of older
people", The Journals of Gerontology 52B:21-36. Rodgers, W , C Brown and G Duncan (1993), "Errors in survey reports of earnings, hours worked, and
hourly wages", Journal of the American Statistical Association 88:1208-1218. Rodgers, WL , and A R Herzog (1987), "Covariances of measurement errors in survey responses",
Journal of Official Statistics 3:403-418. Rouse, C E (1999), "Further estimates of the economic return to schooling from a new sample oftwins",
Economics of Education Review 18:149-157. Rubin, D B (1987), Multiple Imputation for Nonresponse in Survey (Wiley, New York). Schaeffer, N C (1994), "Errors of experience: response error in reports about child support and their
implications for questionnaire design", in: N Schwartz and S Sudman, eds , Autobiographical Memory and the Validity of Retrospective Reports (Springer, New York). Shapiro, M D (1982), "A note on tests of the permanent income hypothesis in panel data", Unpublished manuscript (University of Michigan). Sickles, R C , and P Taubman (1986), "An analysis of the health and retirement status of the elderly", Econometrica 54:1339-1356. Siegal, P ,and R Hodge (1968), "A causal approach to the study of measurement error", in: H M Blalock and A B Blalock, eds , Methodology in Social Research (McGraw-Hill, New York) 28-59. Smith, J (1997), "Measuring earnings levels among the poor: evidence from two samples of JTPA eligibles", Unpublished paper (University of Western Ontario, Canada). Solon, G (1986), "Effects of rotation group bias on estimation of unemployment", Journal of Business and Economic Statistics 4:105-109. Stafford, EP , and G Duncan (1980), "The use of time and technology by households in the United States", in: R Ehrenberg, ed , Research in Labor Economics, Vol 3 (JAI Press, Greenwich CT). Stem, S (1989), "Measuring the effect of disability on labor force participation", Journal of Human Resources 24:361-395. Stinebrickner, T R (1999), "Estimation of a duration model in the presence of missing data", Review of Economics and Statistics 81:529-542. Sudman, S , N Bradburn and N Schwarz (1996), Thinking about Answers: The Application of Cognitive Processes to Survey Methodology (Jossey-Bass, San Fransisco). Theil, H (1961), Economic Forecasts and Policy, 2nd revised edition (North-Holland, Amsterdam). Torelli, N , and U Trivellato (1989), "Youth unemployment duration from the Italian labor force survey", European Economic Review 33:407-415.

Ch 59: Measurement Errorin Survey Data

3843

Tourangeau, R (1984), "Cognitive sciences and survey methods", in: T Jabine, E Loftus, M Straf, J Tanur and R Tourangeau, eds , Cognitive Aspects of Survey Methodology: Building a Bridge Between Disciplines (National Academy Press, Washington, DC).
Tourangeau, R , L Rips and K Rasinski (2000), The Psychology of Survey Response (Cambridge University Press, Cambridge).
U.S Bureau of Labor Statistics (1983), Employer Records Analysis Survey of 1981 (Bureau of Labor Statistics, Washington).
U.S Census Bureau (1993), "Poverty in the United States: 1992 ", Current Population Reports, Series P-60-185 (U S Census Bureau).
Vaughan, D (1978), "Errors in reporting supplemental security income recipiency in a piolot household survey", Proceedings of the Section on Survey Research Methods (American Statistical Association, Alexandria, VA) 288-293.
Vaughan, D , and R Yuskavage (1976), "Investigating discrepancies between social security administration and current population survey benefit data for 1972 ", Proceedings of the Social Statistics Section (American Statistical Association, Alexandria, VA) 824-829.
Waidmann, T , J Bound and M Schoenbaum (1995), "The illusion of failure: trends in the self-reported health of the U S elderly", Milbank Quarterly 73:253-287.
Waksberg, J , and R Valliant (1978), Final Report on the Evaluation and Calibration of NEISS (Westat, Inc for Consumer Products Safety Commission).
Wald, A (1940), "The fitting of straight lines if both variables are subject to error", Annals of Mathematical Statistics 11:284 300.
Walden, D , C Horgan and G Cafferata (1982), "Consumer knowledge of health insurance coverage", in: C Cannell and R Groves, eds , Health Survey Research Methods (National Center for Health Services Research, Washington, DC).
Waldmann, R J (1991), "Implausible results or implausible data? Anomalies in the construction of value-added data and implications for estimates of price-cost markups", Journal of Political Economy 99:1315-1328.
Ware, J , K Snow, M Kosinski and B Gandek (1993), SF-36 Health Survey: Manual and Interpretation Guide (The Health Institute, New England Medical Center, Boston).
Weinberg, C R , D M Umbach and S Greenland (1994), "When will nondifferential misclassification of an exposure preserve the direction of a trend?" American Journal of Epidemiology 140:565-571.
Weiss, D J , R V Dawis, G W England and L H Lofquist (1961), Validity of Work Histories Obtained by Interview (Industrial Relations Center, University of Minnesota).
Wickens, M R (1972), "A note on the use of proxy variables", Econometrica 40:759-761. Woolsey, T D (1953), "Results ofthe sick-leave memory test ofOctober, 1952 ",Unpublished memorandum
(Department of Health Education and Welfare). Yaffe, R , and S Shapiro (1979), "Medical economics survey-methods study: cost-effectiveness of
alternative survey strategies", in: S Sudman, ed , Health Survey Research Methods (National Center for Health Services Research, Washington). Yatchew, A , and Z Griliches (1985), "Specification error in probit models", Review of Economics and Statistics 67:134-139. Yen, W, and H Nelson (1996), "Testing the validity of public assistance surveys with administrative records: a validation study of welfare survey data", Paper presented at the Annual Conference of the American Association for Public Opinion Research.

