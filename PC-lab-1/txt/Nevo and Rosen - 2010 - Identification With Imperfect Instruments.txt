IDENTIFICATION WITH IMPERFECT INSTRUMENTS
Aviv Nevo and Adam M. Rosen*
Abstract—Dealing with endogenous regressors is a central challenge of
applied research. The standard solution is to use instrumental variables that
are assumed to be uncorrelated with unobservables. We instead allow the
instrumental variable to be correlated with the error term, but we assume
the correlation between the instrumental variable and the error term has
the same sign as the correlation between the endogenous regressor and the
error term and that the instrumental variable is less correlated with the
error term than is the endogenous regressor. Using these assumptions,
we derive analytic bounds for the parameters. We demonstrate that the
method can generate useful (set) estimates by using it to estimate demand
for differentiated products.

I.

Introduction

E

NDOGENEITY is a central issue in nonexperimental
studies. A common method for dealing with it is to use
an instrumental variable (IV). In linear models, an IV has to
be correlated with the endogenous covariate and uncorrelated
with the econometric unobservable. The former condition is
known as relevance, or strength of the IV, and the latter as
exogeneity, or validity. Unfortunately, even when great care
is taken, the validity of the IV often relies on what might seem
like arbitrary assumptions, and empirical findings are often
called into question as a result of debate over this assumption.
In this paper, we ask what, if anything, can be learned
about the parameters of interest if the validity assumption
fails. We provide (set) identification results for the parameters
of a single regression equation with endogenous regressors
and an IV that fails to satisfy the usual exogeneity condition.
For a broad class of parametric models, we provide a set
of inequalities that fully characterize the identified set, and
for an often used special case—the linear model—we show
that these inequalities can be characterized analytically using
well-known estimators.
In place of the usual exogeneity assumption, we assume
that some of the instruments are imperfect (they are imperfect instrumental variables, IIV) in the sense that they may be
correlated with the error term. Without further assumptions
or conditions on the data, these variables do not help in narrowing the possible values of the parameters. Indeed, they do
not even identify the direction of bias of OLS estimates.
Received for publication April 30, 2009. Revision accepted for publication
October 27, 2010.
∗
Nevo: Northwestern University and NBER; Rosen: UCL, IFS, and
CEMMAP
We thank Joel Horowitz, Chuck Manski, Rob Porter, Elie Tamer, the editor, three anonymous referees, and seminar participants at Northwestern
University, University College London, SITE, University of Paris I, University of Pennsylvania, University of Toronto, Yale, University of Naples
Federico II, and the UK Competition Commission for comments and suggestions. This paper is a revised version of Chapter 3 of Adam Rosen’s 2006
Northwestern Ph.D. dissertation, subsequently CEMMAP working paper
no. CWP16/08. A.R. gratefully acknowledges financial support from the
Center for the Study of Industrial Organization, the Eisner Memorial Fellowship at Northwestern University, and the Economic and Social Research
Council through the ESRC Centre for Microdata Methods and Practice grant
RES-589-28-0001. We are solely responsible for any and all errors.

If the value of the correlation between the IIV and the error
term were known, then the IIV could be used to form a valid
moment condition. It is not clear, however, how a researcher
can learn and justify a particular value of this correlation.
An alternative is to assume that the correlation is bounded
between two values, for example, between −0.1 and 0.1,
and use this information to bound the parameters of interest. While in principle this can help check the sensitivity of
results to the validity assumption, it is not clear how to come
up with reasonable values for bounding the correlation. For
example, is the range of −0.1 to 0.1 reasonable? Is it too wide
or not wide enough? It is not clear to us how to answer these
questions in a systematic, non–ad hoc way.
Instead we consider an alternative. We first assume that the
sign of the correlation between the IIV and the error term is
(weakly) the same sign as the correlation between the endogenous variable and the error term. This assumption nests the
standard IV assumption, since the sign of the correlation is
weakly the same. Although this does not bound the value of
the correlation between the IIV and the error term, we show
that if the IIV and the endogenous variable are negatively
correlated, the parameters can be bounded from both above
and below.1
There is a sense in which the above requirements parallel
the standard assumptions for IV. The standard assumptions
require zero correlation between the IV and the error term
and nonzero correlation between the IV and the endogenous
variables, with no restrictions on the sign of this correlation. We relax the exogeneity assumption, instead requiring
a weak inequality. As a result, however, we need to make
stronger restrictions on the correlation of the observables if
we are to obtain two-sided bounds. Hence we are substituting a weaker assumption on the unobservables for a stronger
assumption on the observables. The advantage, of course, is
that the assumption on the observables can be verified.
Next, we add an assumption that the correlation between
the IIV and the error term is less than the correlation between
the endogenous variable and the error term. That is, the IIV is
thought to be correlated with the unobservable in the equation
of interest, but less so than the endogenous regressor. This
assumption seems intuitive: the IIV is not perfect, but it is
better than the assumption justifying OLS (in the sense that
the correlation with the error term is lower). This assumption
allows us to bound the degree of correlation of the IIV and the
error term between 0 and the correlation of the endogenous
regressor and the error term. We show that this assumption
allows us to tighten the bounds on the parameters of interest.
1 Requiring that the correlation between the IIV and the error term have
the same sign as the correlation between the endogenous variable and the
error term can be viewed as a normalization. We could, of course, satisfy it
by multiplying the IIV by −1 if it were not initially satisfied, but then the
sign of the correlation between the IIV and the endogenous variable would
flip, and the IIV would not provide two-sided bounds.

The Review of Economics and Statistics, August 2012, 94(3): 659–671
© 2012 by the President and Fellows of Harvard College and the Massachusetts Institute of Technology

660

THE REVIEW OF ECONOMICS AND STATISTICS

We extend our results beyond the simple linear model to
allow additional regressors and several IIVs. The case of multiple IIVs is of particular interest if none of these variables
provides two-sided bounds on its own. We show how differencing the variables to create a new IIV can generate more
informative two-sided bounds.
Our approach provides the range of values of the parameter
of interest consistent with the data and the modeling assumptions. If the bounds are tight, the researcher may be able to
draw conclusions using the weaker assumptions justifying
the imperfect IV. If the bounds are too wide to allow definite
conclusions, then one might want to use the stronger assumptions justifying standard IV methods. However, in this case,
the justification of the instrument validity restriction is essential for the credibility of the results. Either way, our approach
clarifies the relative role of data and assumptions. In section
V, we demonstrate our method in an application to estimation of the demand for differentiated products and show that
the approach can generate (what we believe to be) useful
bounds.2 While our motivation lies in IO applications such
as these, we believe the method is more generally applicable
in all fields of economics.
Like us, several papers provide bounds when the standard
IV assumption fails (Frisch, 1934; Leamer, 1981; Klepper
& Leamer, 1984; Hotz, Mullin, & Sanders, 1997; Altonji,
Elder, & Taber, 2005; Bontemps, Magnac, & Maurin, 2006).
Manski and Pepper (2000) characterize the identification
region for model parameters when, instead of the usual exogeneity condition, the expectation of the outcome variable
conditional on the instrument is assumed to be monotone for
any given value of the endogenous covariate. Their analysis applies to nonparametric models, while we focus on a
linear (parametric) model.3 Because we focus on the linear
model, we can employ weaker restrictions on correlations
rather than assumptions on conditional means. The benefit of
our assumptions is that we derive analytic bounds, which take
on a very simple form and are easy to compute with standard
regression software. (For a more complete comparison of our
results to Manski & Pepper, 2000, see Nevo & Rosen, 2008.)
A different related literature provides sensitivity analysis in
the context of estimation of treatment effects. (See, for example, Angrist, Imbens, & Rubin, 1996; Imbens, 2003; Small,
2007; Rosenbaum & Small, 2008. For a detailed overview and
additional examples, see Rosenbaum, 2002.) For research on
the implications of instrument invalidity in the linear model,
outside the study of treatment effects, see, for example, Ashley (2009), Hahn and Hausman (2003), Berkowitz, Caner, and
Fang (2008), Conley, Hansen, and Rossi (2006), and Kraay
(2008).
In section II, we lay out the general setup and develop
conditions that define the identified set. In section III, we
first focus attention on the special case of a simple linear

regression with one imperfect instrument and characterize
analytically the identification region for the slope parameter
β. We then extend the results to the multiple regression model
as well as the case of several imperfect IVs and provide an
analytic characterization for the bounds on all parameters.
Section IV then discusses estimation and inference. Estimation is straightforward, and for inference, we illustrate how
the method of Chernozhukov et al. (2009) can be used to compute confidence intervals for each of the model parameters
individually. Section V provides the empirical illustration,
and section VI concludes.

2 An additional application to production function estimation is available
in Nevo & Rosen (2008).
3 See Manski and Pepper (1998) for an application to a linear model.

4 For simplicity we present the results in this section for a scalar X. The
basic ideas can be extended to a multivariate variable, as we show in the
next section for the linear model.

II.

The Model

A. The Setup

The researcher is interested in identifying the parameters
of a regression with at least one endogenous variable and an
arbitrary number of exogenous variables. For each observation, the outcome variable Y is a function of an endogenous
covariate X, a 1 × kw vector of additional covariates W , and
U, an additively separable mean zero error unobserved by the
researcher. We assume a parametric specification,
Y = m(X, W , θ) + U,
where θ is a vector of parameters and m(X, W , θ) is twice
continuously differentiable in θ.4
We assume that there exists an observable kz -dimensional
random vector Z of imperfect instruments—in the sense
formally defined in our assumptions 3 and 4 below. These
assumptions restrict the relationship between observables X
and Z by imposing that X and components of Z have the
same direction of correlation with the error and that the correlation between any component of Z and the error is less
than that between X and the error. The key distinguishing
feature of covariates W relative to X is that no such assumptions are made regarding Z and W . In addition, we assume
the existence of a 1 × kw vector of valid instruments Z w ,
which may include elements of W if some of the regressors
are themselves exogenous. If the number of valid instruments
exceeded the dimension of W , then model parameters would
be locally point-identified under the usual rank condition, and
they could be consistently estimated by standard instrumental
variable methods such as GMM. For this reason, we restrict
the number of valid instruments to be equal to the dimension
of W .
We assume the econometrician observes a size n sample
of realizations of (Y , X, W , Z, Z w ) satisfying the following
assumptions. We use the subscript i to denote individual
observations, and subscript j to denote individual elements
of these vectors:

IDENTIFICATION WITH IMPERFECT INSTRUMENTS

Assumption 1 (sampling process). The observations
(yi , xi , wi , zi , ziw ) , i = 1, . . . , n are stationary and weakly
dependent.
Assumption 1 is a standard assumption, commonly used to
guarantee consistency of parameter estimates in conventional
cases with sufficiently many instruments for point identification. Here, it similarly serves to guarantee consistency
of our estimated bounds. Note that this assumption allows
heteroskedasticity and serial correlation. In assumption 2,
we further assume that variables Z w are exogenous, in the
sense that each component of Z w is uncorrelated with the
unobservable U:
Assumption 2 (Z w exogenous). E(Z w U) = 0.
The variable X may be correlated with U, in which case
identification and estimation of the model parameters θ typically rely on the use of a vector of instrumental variables. The
assumptions justifying the IVs are often called into question
in empirical work, and in some cases they may be untestable.
We assume instead that the econometrician has observations
of some imperfect instruments, Z, that are also correlated
with the unobservable U, but less so than the endogenous
regressor X, which we formalize below in assumptions 3 and
4. We assume that kz , the number of imperfect instruments,
is fixed.
Formally, the assumptions we impose on our imperfect
instruments (IIV) are as follows. We use the notations σab
and ρab throughout to denote the covariance and correlation,
respectively, between any two random variables A, B, and σa
to denote the standard deviation of a random variable A.
Assumption 3 (same direction of correlation).
ρxu ρzj u ≥ 0, j = 1, . . . , kz .
Assumption 3 asserts that the endogenous regressor X and
the IIV have the same direction of correlation with the error
term. Since we require a weak inequality, assumption 3 is
a weakening of the usual assumption that ρzj u = 0. Like
the classic validity assumption, this assumption is also about
unobserved variables and will not always be satisfied. We
provide an application in section V where we believe this
assumption is satisfied (see Nevo & Rosen, 2008, for an
additional application).
Assumption 4 (instruments less endogenous than x).
|ρxu | ≥ |ρzj u |, j = 1, . . . , kz .
Assumption 4 adds the condition that the IIV is less correlated with the error term than is the endogenous regressor.
To us, this seems like an intuitive assumption for numerous
applications where one may believe that the instrument Z is
not necessarily exogenous but is “better” or “less endogenous” than the endogenous regressor. For example, in the

661

context of demand estimation in our application in section
V, the market demand equation contains an unobservable
market-level component. We assume that the unobservable
component of demand in any given market is less correlated
with the product’s price in other markets than the own-market
price. As we will see below, this assumption will help us
tighten the bounds on the parameters.
We also make use of the standard rank conditions needed
for the probability limits of the OLS and 2SLS estimators to
be well-defined in the linear model.
Assumption 5 (rank and order). Rank(E[(Z, Z w ) (Z, Z w )]) =
kz + kw , rank(E[(X, Z w ) (X, Z w )]) = kw + 1, and
rank(E[(Z, Z w ) (X, W )]) = kw + 1, kz ≥ 1.
B. Identification

The above assumptions yield a system of moment equalities and inequalities that restrict the feasible values of model
parameters θ. In general, these restrictions will not be sufficient for point identification but may still provide information
regarding the value of θ.
A useful construct for the analysis is the ratio of correlations of the instrument Zj and regressor X with the
econometric error term. Denote this ratio as
λ∗j ≡ ρzj u /ρxu ,

(1)

and when ρxu = ρzu = 0, we adopt the convention that λ∗j =
0. By definition,

 
E σx Zj − λ∗j σzj X U = σx σzj u − λ∗j σzj σxu = 0,
when assumptions 3 and 4 hold. Therefore, if λ∗j were known,
it could be used to construct a weighted average of Zj and X
that is uncorrelated with the error term.
Of course, λ∗j is unknown, but our assumptions bound its
value. That is, assumptions 3 and 4 together imply that λ∗j ∈
[0, 1]. Our hope is to use the bounds on λ∗j to bound the
parameters of interest, θ. To do this, define the function Vj (·)
as
Vj (λ) ≡ σx Zj − λσzj X.

(2)

Note that when evaluated at λ∗j the function generates a variable, Vj (λ∗j ), that is uncorrelated with U and satisfies the
moment condition E[(Y − m(X, W , θ)) × Vj (λ∗j )] = 0. In
other words, the function evaluated at λ∗j yields a valid instrumental variable. We do not know the value λ∗j , but given our
assumptions, we know that λ∗j ∈ [0, 1]. Hence, the identified
set is computed by evaluating the moment condition for the
full range of 0 ≤ λj ≤ 1. As we show in the next section, a
much simpler characterization holds in the linear model.

662

THE REVIEW OF ECONOMICS AND STATISTICS

Formally, the implied restrictions of assumptions 2 to 4
are:


E Zjw (Y − m(X, W , θ)) = 0,
(3a)

 ∗ 
E (Y − m(X, W , θ)) × Vj λj = 0, j = 1, . . . , kz , (3b)
λ∗j ∈ [0, 1], j = 1, . . . , kz ,
(3c)
The model parameters must satisfy the kw + kz moment conditions (3a) and (3b). If Λ∗ ≡ (λ∗1 , · · · , λ∗kz ) were known and
the standard rank conditions were satisfied, these moment
conditions would identify θ locally (globally, if the model is
linear). However, since Λ∗ is known only to belong to the
unit cube in Rkz , θ will generally not be point-identified.
The identified set for θ is by definition the set of parameter values that satisfy restrictions (3a) to (3c). The identified
set can be computed numerically by iterating over all the
possible values of Λ∗ and computing the implied value of the
parameters. Estimation and inference can be performed using
this characterization and by any of a variety of methods (see,
for example, Chernozhukov et al., 2007, and the references
therein).
III.

The Linear Model

Conditions (3a) to (3c) fully characterize the identified
set, but they do not provide an easy way to compute the set,
nor do they tell us when the set is bounded. In this section,
in order to obtain an analytic characterization of the identified set, we restrict attention to the linear model. We show
that in the linear model, our modeling restrictions lead to a
straightforward characterization of the identified set that can
be exploited to perform (set) estimation with standard linear
regression methods. We start with the simple linear model
and then generalize the results to multiple IIVs as well as
additional regressors.
A. The Simple Linear Model with One Imperfect Instrument

Consider the simple linear model,
Y = α + Xβ + U,
where E[U] = 0. Define βOLS and βIV
z to be the probability limits of the standard OLS and IV estimators for β,
respectively:
σxy
σxu
βOLS ≡ 2 = β + 2
(4)
σx
σx
and
βIV
z

σzy
σzu
≡
=β+
.
σxz
σxz

(5)


βOLS and β̂IV
z are taken to be their corresponding estimators. Applying equation (5) to the case where V (1) is the
instrument defines
σx σzy − σz σxy
βIV
.
(6)
v(1) ≡
σx (σxz − σz σx )

This is the probability limit of the traditional IV (2SLS) estimator for β when V (1) is used as an instrument for X, where
V (·) is as defined in equation (2), that is, V (1) ≡ σx Z − σz X.
The true value of the parameter, β, can be bounded when
assumptions 1 to 3 are imposed.
Lemma 1. Let assumptions 1 to 3 hold. If σxz < 0, then
β is between βOLS and βIV
z and we have a two-sided bound
OLS
OLS
(βIV
≤
β
≤
β
if
σ
≤ β ≤ βIV
xu , σzu ≥ 0, and β
z
z
if σxu , σzu ≤ 0). If instead, σxz > 0, then we have a onesided bound given by β ≤ min{βOLS , βIV
z } if σxu , σzu ≥ 0 and
β ≥ max{βOLS , βIV
}
if
σ
,
σ
≤
0.
xu
zu
z
Lemma 1 gives a simple characterization of the identified
set for β, which we denote as B∗ . Given assumptions 1 to 3,
βOLS and βIV
z provide either two-sided or one-sided bounds,
depending on the correlation between X and Z, which can be
consistently estimated from the data. Note that when σxz < 0,
an assumption on the sign of σxu is not needed for two-sided
bounds. When instead σxz > 0, there is only a one-sided
bound, and a sign assumption for σxu and σzu is needed to
determine whether this is an upper or a lower bound. When
σxz = 0, βIV
z is either positive or negative infinity, depending
on the sign of σzu , so that the corresponding bound is uninformative. More generally, if σxz is “small,” then the bound
given from βIV
z is large, which is a direct manifestation of the
problem of weak instruments.
If σxz < 0, assumption 3 can provide finite, and, we hope,
economically helpful, bounds on the parameter of interest.
Moreover, inspection of these bounds reveals that when σxz <
0 or ρxz > λ∗ , the bias of βOLS has the same sign as βOLS −βIV
z .
In general, however, an IIV will not even identify the direction
of the bias or necessarily correct the OLS estimate in the
“right” direction. A common intuition—that even if the IV
is invalid, the IV estimate corrects the OLS estimate in the
right direction—probably comes from the case when λ∗ is
small. Recall that λ∗ = 0 is the valid IV case. So λ∗ close to
0 means the IV is “almost” valid and then ρxz > λ∗ is likely
to hold. But if neither σxz < 0 nor ρxz > λ∗ holds, then an
IIV will not even identify the direction of the bias of βOLS .
Up to this point we have not imposed assumption 4. We
now ask what we get from imposing it. As the following result
shows, by bounding λ∗ between 0 and 1, as the assumption
implies, we obtain sharper identification results:
Proposition 1. Let assumptions 1 to 4 hold. If σxz < 0,
IV
then β is between βIV
v(1) and βz , and we have a two-sided
IV
IV
IV
bound (βIV
z ≤ β ≤ βv(1) if σxu , σzu ≥ 0 and βv(1) ≤ β ≤ βz
if σxu , σzu ≤ 0). If instead σxz > 0, then we have a oneIV
sided bound given by β ≤ min{βIV
v(1) , βz } if σxu , σzu ≥ 0 or
IV
β ≥ max{βIV
v(1) , βz } if σxu , σzu ≤ 0. These bounds are sharp.

In cases where σxz > 0, proposition 1 shows that imposing
assumption 4 improves on the bounds of lemma 1 but that the
bounds remain one-sided. When instead σxz < 0, proposition
1 improves on the two-sided bounds given in lemma 1. So

IDENTIFICATION WITH IMPERFECT INSTRUMENTS

while assumptions 3 and 4 jointly bound λ∗ between 0 and
1, they do not in general provide two-sided bounds for the
parameter of interest, β. To see why, note that
βIV
v(λ) =

σx σzy − λσz σxy
σy (ρzy − λρxy )
.
=
σx σxz − λσz σx2
σx (ρxz − λ)

(7)

∗
If λ = ρxz , then βIV
v(λ) is not defined, so even though λ is
bounded, β might not be bounded. If σxz > 0, we cannot rule
out that λ = ρxz . If σxz < 0, then for all 0 ≤ λ ≤ 1, λ = ρxz ,
and therefore β is bounded from above and below.
Thus, while assumption 4 does not give us two-sided
bounds where they did not already exist, it does tighten
the bounds. Corollary 1 applies to the case where σxz < 0
and where proposition 1 achieves two-sided bounds for β.
This corollary characterizes the degree to which use of βIV
v(1)
improves on the bounds provided by lemma 1, which are just
βOLS and βIV
z . The implication is that the greater the magnitude of the correlation between X and Z, the tighter the bound
OLS
achieved using βIV
, with maximal improvev(1) instead of β
ment obtained when ρxz = −1, in which case the size of the
bounds is halved.

Corollary 1. If σxz < 0, then
βIV
v(1)

−

βIV
z



as long as E[(X, W ) Z w ] had full rank, θ = (β, δ ) would be
point-identified and consistently estimable by the usual IV
estimation procedures. Thus, we restrict attention to the case
where Z w has the same dimension as W .
In principle, the analysis is the same as before. As shown
in section IIB, assumptions 3 and 4 are equivalent to the
assertion that V (λ) = σx Z − λσz X is a valid instrument for
X, for some unknown value of λ ∈ [0, 1], which we denote
λ∗ . Thus, the identified set can be computed by computing
θ(λ) over all λ ∈ [0, 1] with θ(λ) given by the usual IV
formula:
θ(λ) = E[(V (λ), Z w ) (X, W )]−1 E[(V (λ), Z w ) Y ].

Bounds on β. We follow a standard way of deriving results for multivariate regressions by netting out the effects of
W . The residuals of an IV regression of X and Y on W using
Z w as the instruments are given by
−1

Ỹ ≡ Y − W E[Z W ] E[Z Y ].
w

Notice that if E[ZU]  = 0, it is possible for βOLS to be
closer to β than βIV
z , even in the case when the instrument Z
is less correlated with U than is the endogenous regressor X
and σxz < 0 (the IV estimate identifies the sign of the OLS
bias). Basically, it is possible that βIV
z overcorrects, so that it
may not be the case that the instrumental variables estimator
offers an improvement over βOLS . This result accords with
the finding of Hahn and Hausman (2003).
B. Additional Regressors

This section generalizes beyond the simple linear model,
allowing the presence of additional regressors, as well as valid
instruments, in addition to the IIV. The regression of interest
is
(8)

where X is univariate, W is a 1 × kw vector of additional
regressors (possibly including a constant), and E[U] = 0.
Z is a univariate IIV that satisfies assumptions 3 and 4 with
respect to the endogenous regressor X. The additional regressors W may include exogenous and endogenous components,
but we assume that assumption 2 holds, so that there is a
1 × kw vector of valid instruments Z w such that E[Z w W ] is
nonsingular and E[Z w U] = 0. If any components of W are
exogenous, then those will also be included as components
of Z w . Note that if the dimension of Z w exceeded that of W ,
there would be more valid instruments than regressors. Then,

(9)

The remainder of this section first generalizes our results
from the simple linear model to derive analytic bounds on
β. We then construct the identification interval for each
individual component of δ.

X̃ ≡ X − W E[Z w W ]−1 E[Z w X],


IV

1
βOLS − βz .
=
1 − ρxz

Y = Xβ + W δ + U,

663

w

(10a)
(10b)

We show in the appendix that
Ỹ = βX̃ + U.

(11)

The result of running an IV regression of Ỹ on X̃ with
V (λ) as instrument consistently estimates the first component of θ in the IV regression above given by βIV
V (λ) ≡
E[V (λ)X̃]−1 E[V (λ)Ỹ ]. Applying our analysis of the simple
linear model to this regression then delivers the following
bounds for β, where σzỹ denotes the covariance of Z and Ỹ ,
σzx̃ that between Z and X̃, and so on.
Proposition 2. Let assumptions 1 to 5 hold. If (σx̃x σz −
IV
σx σx̃z )σx̃z < 0, then β is between βIV
v(1) and βz and we have a
IV
IV
two-sided bound (βIV
z ≤ β ≤ βv(1) if σxu σx̃z < 0 and βv(1) ≤
IV
β ≤ βz if σxu σx̃z ≥ 0). If instead (σx̃x σz − σx σx̃z )σx̃z > 0, then
IV
we have a one-sided bound given by β ≥ max{βIV
z , βv(1) } if
IV
IV
σxu σx̃z < 0 or β ≤ min{βz , βv(1) } if σxu σx̃z ≥ 0. These bounds
are sharp.
The statement of proposition 2 follows closely that of
proposition 1, but the conditions differ because we need to
account for the partialing-out of exogenous variables in the
first stage. Proposition 2 relies on the original statement of
assumptions 3 and 4, which is in terms of sign restrictions
on unconditional correlations. When Z w = W , a sufficient
condition for the required inequality is σx̃z < 0. An alternative approach would be to impose assumptions 3 and 4 on
conditional correlations, with ρx̃u and ρz̃u replacing ρxu and

664

THE REVIEW OF ECONOMICS AND STATISTICS

ρzu . This would lead to the condition σx̃z < 0 for two-sided
IV
bounds, but the bounds would differ from βIV
z and βv(1) .

all of the intervals Br∗ , and the identified set for each δj is the
∗
intersection over r = 1, . . . , kz of the intervals Dj,r
.

Bounds on other coefficients. In this section we shift
focus from β to other regression coefficients and show that
these coefficients are also interval identified. Whether their
identification regions are one- or two-sided corresponds to
whether the identification region for β is one- or two-sided.
To facilitate the analysis, define Y ∗ ≡ Y − Xβ, so that
∗
Y = W δ + U. Given the assumption that the instruments Z w
are valid, it follows that δ = E[Z w W ]−1 E[Z w Y ∗ ]. Then the
jth component of δ is given by

Proposition 4. Assume assumptions 1 to 5. Then the identification region for β is B∗ = [maxr βl,r , minr βu,r ], and the
identification region for δj , each j = 1, . . . , kw is Dj∗ =
j
j
[maxr δl,r , minr δu,r ]. These bounds are sharp.


−1 

δj = E Zjw W̃j E Zjw Ỹ ∗ ,

(12)

where
 w
−1  w 
W−j E Z−j
X ,
W̃j ≡ Wj − W−j E Z−j




−1
w
w ∗
W−j E Z−j
Y ,
Ỹ ∗ ≡ Y ∗ − W−j E Z−j
and subscript −j denotes a vector with its jth component
removed. That is, W̃j and Ỹ ∗ correspond to the residuals of
w
IV regressions of Wj and Y ∗ on W−j employing Z−j
as instruments. The latter regression is infeasible as β, and therefore
Y ∗ are unknown. However, β is interval-identified, and the
identification region for δj can be obtained by tracing out the
implied values of δj over the identified set for β.
Proposition 3. Assume assumptions 1 to 5. Then the identification region for any δj , j = 1, . . . , kw is given by the interval
ranging from δj0 to δj1 where



−1 

−1 
δj0 ≡ E Zjw W̃j E Zjw Ỹ − E Zjw W̃j E Zjw X̃ βL ,



−1 

−1 
δj1 ≡ E Zjw W̃j E Zjw Ỹ − E Zjw W̃j E Zjw X̃ βU ,
and where βL and βU are the extreme points of the identification region for β.
C. Multiple Imperfect Instruments

Up to this point we have assumed that we have a single
imperfect IV. We now ask what the researcher gains from
multiple imperfect IVs for the endogenous regressor X. We
show that this can help tighten the identification region for β
and with additional assumptions can be used to obtain twosided bounds where they were previously only one-sided.
When there are multiple imperfect instruments that satisfy
assumptions 3 and 4, that is, kz > 1 and Z = (Z1 , . . . , Zkz ),
then proposition 2 can be used to derive bounds on β (oneor two-sided, depending on the sign of σxzr ) for each Zr ,
r = 1, . . . , kz . For each r, denote the bounds implied by
proposition 2 as Br∗ = [βl,r , βu,r ] (where one of the two is
j
j
∗
= [δl,r , δu,r ] denote the
possibly ±∞). In addition, let Dj,r
bounds on δj for each j = 1, . . . , kw given by proposition 3.
It follows that the identified set for β is the intersection of

This proposition is a result of applying propositions 2 and
3 to each of the instruments Zj , j = 1, . . . , J. Furthermore,
this exploits all the identifying power of the multiple IIVs, in
the sense that there is no additional identifying power from
imposing assumptions 3 and 4 jointly with respect to multiple
instruments. This is because for every value of β ∈ B∗ , there
is an admissible data generation process that satisfies all of
our modeling assumptions. The sharpness of the bounds for
each element of δ is a direct result of their characterization
in proposition 3 as functions of β. Note that in principle, B∗
and the intervals Dj∗ could be empty, which can be used to
serve as the basis for a specification test, as we discuss in the
following section.
A potential drawback is that when (σxx̃ σzj −σx̃zj σx )σx̃zj ≥ 0
for each IIV Zj , proposition 4 may provide only a one-sided
bound. In some cases, the researcher may be willing to assert
that one instrument is better than another in the sense that
it is both more relevant and more valid. In particular, in the
case where the bounds of proposition 4 are one-sided, such
an assumption can be used to generate an IIV that provides
two-sided bounds by constructing a weighted difference of
the original IIVs. The intuition is that by subtracting the more
relevant IIV from the less relevant one, one can generate a
new IIV that is negatively correlated with X. This can be used
to obtain two-sided bounds by the application of proposition
2 as long as the differencing does not flip the direction of
the new IIVs’ correlation with the error term, relative to the
original ones.
Formally, let there be two instruments, Z1 and Z2 , each
satisfying assumption 3, and (σxx̃ σzj − σx̃zj σx )σx̃zj ≥ 0, for
j = 1, 2. Define the following weighted average of Z1 and
Z2 :
ω(γ) = γZ2 − (1 − γ)Z1 ,
where γ ∈ (0, 1).
Proposition 5. Assume assumptions 1, 2, and 5, and let
assumption 3 hold for both Z1 and Z2 . Suppose that σzj u ≥
0 and (σxx̃ σzj − σx̃zj σx )σx̃zj ≥ 0 for j = 1, 2. Assume that
for some known γ∗ ∈ (0, 1), σω(γ∗ )u ≥ 0 and (σxx̃ σω(γ∗ ) −
σω(γ∗ )x̃ σx )σω(γ∗ )x̃ < 0. This yields the following bounds for β:
 IV IV OLS 
βIV
.
ω(γ∗ ) ≤ β ≤ min βz1 , βz2 , β
If, in addition, assumption 4 holds for both Z1 and Z2 , then

 IV IV IV
IV
IV
βIV
ω(γ∗ ) ≤ β ≤ min βz1 , βz2 , βv1 (1) , βv2 (1) , βv∗ (1) ,

IDENTIFICATION WITH IMPERFECT INSTRUMENTS
IV
IV
IV
where βIV
v1 (1) , βv2 (1) , βω(γ∗ ) , and βv∗ (1) are defined by using
∗
∗
V1 (1), V2 (1), ω(γ ), and V (1) ≡ σx ω(γ∗ ) − σω(γ∗ ) X as
instruments in the definition given in equation (5).

The first set of bounds given by the proposition simply says
that if there exists a γ∗ such that the conditions on ω(γ∗ ) are
met, then we can apply lemma 1 to obtain a two-sided bound.
If assumption 4 holds as well, then the bounds of proposition 2 also apply with Z1 , Z2 , and ω(γ∗ ) as IIVs, yielding
sharper bounds. Note that the quantities βIV
vj (1) , j = 1, 2, correspond to the probability limits of IV estimators that employ
IV
Vj (1) ≡ σx Zj − σzj X as an instrument, and βIV
ω(γ∗ ) and βv∗ (1)
∗
∗
to those employing ω(γ ) and V (1) as instruments, and are
thus easily estimated via linear IV regression. The following lemma provides more basic conditions that guarantee the
existence of such a γ∗ and that are testable in the case where
the additional regressors W are exogenous.
Lemma 2. Assume assumptions 1, 2, and 5, and let assumption 3 hold for both Z1 and Z2 . Suppose that σzj u > 0 and
(σxx̃ σzj − σx̃zj σx )σx̃zj > 0 for j = 1, 2, and that W = Z w .
Then the following statements are equivalent: (1) there exists
γ∗ ∈ (0, 1) such that σω(γ∗ )u ≥ 0 and σω(γ∗ )x̃ < 0; (2) there
σ
σz1 u
γ∗
; and (3)
exists γ∗ ∈ (0, 1), such that σx̃zx̃z1 > 1−γ
∗ > σ
z2 u
2
σz1 ỹ σx̃z2 < σz2 ỹ σx̃z1 . Furthermore, a sufficient condition for
the inequality (σxx̃ σω(γ∗ ) − σω(γ∗ )x̃ σx )σω(γ∗ )x̃ < 0 is that the
partial correlation between X and ω(γ∗ ) controlling for W
is negative.
The lemma shows several things. Part 1 of the lemma
restates the conditions required, on the weighted average
ω(γ∗ ), to satisfy both assumption 3 and the conditions in
proposition 1. Part 2 states a condition on the correlations
of the two IIVs, Z1 and Z2 . It says that the ratio of the IIVs’
correlations with X̃ must exceed the ratio of their correlations
with the error term. Finally, part 3 of the lemma states a condition on observable quantities that allows us to test whether
such a γ∗ exists.
Note that while proposition 5 provides two-sided bounds,
it relies on knowing γ∗ . Lemma 2 shows that by checking
if σz1 ỹ σx̃z2 < σz2 ỹ σx̃z1 holds, we can test if there exists some
value of γ∗ such that the required conditions hold. However,
it does not reveal for which values of γ∗ this holds; it reveals
only that a set of such values exists. To exploit the results
of the proposition, we need to assume a value for γ∗ . For
example, assuming γ∗ = 0.5 implies σxz1 > σxz2 and σz1 u <
σz2 u , so the more relevant variable is also weakly better in
terms of validity.
D. Multiple Endogenous X

In this section we consider the case of kx > 1 endogenous
regressors with exactly one IIV for each of them. For notational simplicity, assume there are no exogenous regressors
except for the intercept term. The model is

Y = β0 + Xβ + U.

665

(13)

Define
λ∗j ≡

ρzj u
ρxj u

,

j = 1, . . . , kx ,

where, as before, we define λ∗j = 0 if ρzj u = ρxj u = 0.
Assumptions 3 and 4 together correspond to λ∗j ∈ [0, 1],
j = 1, 2. Since E[U] = 0, we can write the model as
Y = Xβ + U,
where, for any random variable W , W ≡ W − E[W ]. By definition of λ∗j it follows that E[V j (λ∗j )U] = 0, j ∈ {1, . . . kx },
where
V j (λj ) ≡ σxj Z j − λj σzj X j .
Following our usual notation, define V (Λ) ≡ (V 1 (λ1 ), . . . ,
V kx (λkx )). The IV estimand using V (Λ) as the IV is given by
βIV
= E[V (Λ) X]−1 E[V (Λ) Ȳ ].
V (Λ)
The identified set for β is unbounded if and only if the inverse
E[V (Λ) X]−1 does not exist or, equivalently, if and only if the
determinant of E[V (Λ) X] can take the value 0 over feasible
values of Λ ≡ (λ1 , . . . , λJ ). For kx = 2, a sufficient condition
for the determinant not to equal 0 for all feasible values of Λ
is that (ρx2 z1 ρx1 z2 − ρx1 z1 ρx2 z2 ) < 0, (ρx1 z1 − ρx2 z1 ρx1 x2 ) < 0,
and (ρx2 z2 − ρx1 z2 ρx2 x1 ) < 0.
IV.

Estimation and Inference

So far we have focused solely on identification. However,
these identification results are constructive, naturally leading
to consistent estimators since the derived bounds are probability limits of OLS and IV estimators under assumptions
1, 2, and 5. Consistent estimators of our bounds can thus be
computed using standard regression software.
Regarding statistical inference, a variety of methods from
the literature are applicable, including Pakes et al. (2005),
Chernozhukov et al. (2007), and Andrews and Guggenberger
(2009). In section V, we employ a variant of the inferential procedure proposed by Chernozhukov et al. (2009). The
method is particularly well suited for settings where the
identified set is the intersection of many intervals.
Specifically, we use a sample analog estimator for
the identified set of the form of [Ln , Un ], where Ln∗ ≡
max{Ln1 , . . . , LnR }, and Un∗ ≡ min{Un1 , . . . , UnS }, and where
each Lnr , Uns is a consistent estimator of all the lower and
upper bounds on the parameter of interest, respectively. To
construct confidence intervals, we first construct confidence
bands for each of the estimated bounds and then take the intersection of these. Intuitively, this adjusts each of the estimates
by an amount that depends on the precision with which it is

666

THE REVIEW OF ECONOMICS AND STATISTICS

estimated. Those estimates with high standard errors require
a larger adjustment than those with lower standard errors. The
precise procedure is as follows:
1. Compute Jl∗ = { j : Lnj ≥ Ln∗ − 2σ̄l log n} and Ju∗ =
{ j : Unj ≤ Un∗ + 2σ̄u log n} where
σ̄l = max ŝlj ,
j=1,...,R

σ̄u = max ŝuj ,
j=1,...,S

and where ŝlj and ŝuj are the standard errors of the
estimates Lnj , Unj , respectively.
2. Define Δn ≡ |Un∗ −Ln∗ |+ and pn ≡ 1−Φ(log n×Δn )α.
Let Ω̂l and Ω̂u be consistent estimators for the variance
covariance of {Lnj : j ∈ Jl∗ } and {Unj : j ∈ Ju∗ },
respectively. Such estimates may be obtained either by
analytic calculation of asymptotic variance formulas or
by bootstrapping. Let Z l and Z u denote |Jl∗ | and |Ju∗ |
mean-zero multivariate normal random variables with
variances Ω̂l and Ω̂u , respectively.
3. Compute the pn quantiles of max{Z l } and max{Z u },
denoted ql (pn ) and qu (pn ), respectively. In the case
where |Jl∗ | or |Ju∗ | equals 1, this can be done by inverting the normal CDF. Otherwise these may be computed
via multivariate normal simulation.
4. A 1−α confidence interval for the parameter of interest
is then given by CI1−α = [L1−α , U1−α ], where
L1−α ≡ max∗ {Lnj − ŝlj ql (pn )},

0.05 level. However, such a test does not provide information
regarding the source of misspecification.5
V.

In this section we provide an application of our method to
the estimation of demand for differentiated products, which
has played a central role in industrial organization as well
other fields over the past few years. The working paper version of this paper presents an additional application to the
estimation of a Cobb-Douglas production function.
Assume that the indirect utility consumer i gets from
product j in market t is given by
uijt = pjt β + wjt Γ + ξjt + ijt ,
where wjt , pjt , and ξjt are observable characteristics, price,
and unobservable characteristics of product j in market t. ijt
is an unobservable stochastic term that captures the idiosyncratic portion of consumer i’s taste for product j in market
t. We assume that when making purchases, each consumer
chooses exactly one good and also has the option to choose
an “outside” good, that is, not to buy any of the products. We
normalize the mean value of the outside good to be 0 so that
ui0t = i0t . Furthermore, ijt is assumed to be a distributed iid
extreme value, from which it follows that each product j has
market share sjt in market t, where
sjt =

j∈Jl

U1−α ≡ min∗ {Unj + ŝuj qu (pn )}.
j∈Ju

The confidence set CI1−α provides an asymptotic confidence interval for the bounded parameter of interest, which
is uniformly valid over points in the identified set. The first
step estimates the set of lower and upper bounds that are
sufficiently close to binding to affect the asymptotic distribution of the maximum and minimum boundary estimators.
This step may be skipped and the full set of boundary estimates used instead of the subsets Jl∗ and Ju∗ , in which case
the confidence set is valid but in general conservative. One
may also adapt this procedure to provide either a 1 − α
confidence interval for the entire identified set, by setting
pn = 1 − α/2, or a pointwise (but not uniformly valid) 1 − α
confidence interval for the parameter of interest by setting
pn = 1−α. In our application, we report the confidence interval for pn = 0.975 for inference on the identified set. Taking
pn = 1−Φ(log n×Δn )α as above with α = 0.05 provides an
intermediate value between 0.95 and 0.975 that depends on
the size of the estimated identified set so as to achieve uniformity, in similar spirit to Imbens and Manski (2004) and Stoye
(2009). (For further details, refer to Chernozhukov et al.,
2009). A by-product is that this also provides a specification
test: if the lower and upper bounds of the confidence set computed with pn = 0.975 cross, then the model is rejected at the

An Application

exp(pjt β + wjt Γ + ξjt )
1+

J
k=1

exp(pkt β + wkt Γ + ξkt )

,

and
log(sjt ) − log(s0t ) = pjt β + wjt Γ + ξjt .

(14)

If price pjt and market characteristics wjt were uncorrelated
with the random unobservable ξjt , the parameters of this equation, β and Γ, could be estimated by ordinary least squares.
However, it is commonly thought in these markets that any
given product’s price is correlated with unobservable shifters.
In general, the error term may include unobserved product quality or promotional activities, and both are likely to
be correlated with price. In this application, we control for
unobserved product characteristics that are fixed over time
by using product fixed effects. Thus, the error term includes
mainly unobserved promotional activities.
We employ scanner data from the ready-to-eat cereal
industry at the brand-quarter-MSA (metropolitan statistical
area) level, obtained from the IRI Infoscan Data Base at the
University of Connecticut. We have observations from twenty
quarters, and for this application, we focus attention on the top
25 brands (in terms of market share) and the San Francisco
5 Crossing of the boundary estimates would reflect that, given the maintained linear specification, the IIV assumptions that have been imposed
are not mutually consistent. This is analogous to overidentification tests for
GMM as in Hansen (1982). Indeed, assumptions 3 and 4 nest the possibility
that the IIVs are valid instruments.

IDENTIFICATION WITH IMPERFECT INSTRUMENTS

667

Table 1.—Summary Statistics
Variable

Mean

Median

Standard
Deviation

Minimum

Maximum

Brand
Variation

City
Variation

Quarter
Variation

Price (¢ per serving)
Advertising (Mil.$ per quarter)
% share within Cereal Market

20.5
3.6
2.2

20.0
3.0
1.7

4.9
2.0
1.4

8.5
0.0
0.3

40.9
9.8
7.9

88.5%
65.9
90.3

6.3%
NA
0.1

1.8%
1.8
0.0

Source: IRI Infoscan Data Base, University of Connecticut, Food Marketing Center.

Table 2.—Logit Demand Estimates
(1)

(2)

(3)

(4)

(5)
IIV

Price
Advertising/10
First-stage F-statistic

OLS

IV

2SLS

Only A3

A3 and A4

−2.21
(0.72)
0.31
(0.01)

−4.08
(0.89)
0.30
(0.06)
1,780

−4.47
(0.89)
0.30
(0.06)
930

[−8.69, −4.08]
(−11.44, −2.32)
[0.28, 0.30]
(0.16, 0.41)
380

[−8.69, −5.99]
(−11.44, −4.04)
[0.28, 0.29]
(0.16, 0.41)
1,116

The dependent variable in all columns is log(sjt ) − log(s0t ). The sample includes 990 observation: 25 brands in two cities, Boston and San Francisco, over twenty quarters (one of the brands was introduced after
five quarters). The regressions also include brand fixed effects, a dummy variable for San Francisco, and twenty quarterly time dummy variables. Column 2 reports results using the average price in the region as an IV.
Column 3 reports two-stage least-squares results using price in the region and the average price in the other city as IVs. Column 4 reports results using the difference between the average price in the other city and the
average price in the region as an IIV. Column 5 imposes assumption 4 in addition to assumption 3 to sharpen the bounds. Standard errors are reported in parentheses. In columns 4 and 5 we report 95% confidence
intervals for the identified set using the method described in section IV. Finally, the first-stage F-statistic tests the exclusion of the IVs from the (first-stage) regression of price on the instruments and all the exogenous
variables.

and Boston markets. The key variables observed for each
product, market, and quarter combination are quantity sold,
total revenue, and brand-level advertising. We define price
as the revenue divided by quantity. (For additional information on the data source and the details of the ready-to-eat
cereal industry, see Nevo, 2000, 2001.) Table 1 provides a
descriptive summary of the data.
The standard approach for dealing with the endogeneity of
price in this setting is to use prices of the product in other markets as an instrumental variable (Hausman, Leonard, & Zona,
1994; Hausman, 1997; Nevo, 2001). The idea is that the IV is
correlated with price through common marginal cost shocks.
Assuming that the errors in demand are independent across
markets, these instruments are valid. This latter assumption
has been challenged (for example, the discussion of Hausman, 1997, by Bresnahan, 1997). The demand shocks could
be correlated across cities for several reasons. For example,
advertising could be at the regional or national levels. Alternatively, the brand preferences could change over time. For
instance, if in the middle of the sample, fiber-rich cereals
are found to be healthy, the preferences for these cereals
could change. Any of these stories would render the IV, and
the implied estimates, invalid. There is evidence that despite
these theoretical concerns, the IV are valid (Nevo, 2001);
nevertheless, some concerns linger over the validity of the
estimates.
We use prices in other cities as IIVs. The typical concern
in demand estimation is that price, the endogenous variable,
is positively correlated with the error term. In order to satisfy assumption 3, we require that prices in other markets,
the IIVs, be positively correlated with the error. The examples suggest that usually we worry about positive association
between demand errors in different markets. Thus, it is natural

to assume that the correlation of prices in other cities with
the error term is positive. Thus, assumption 3 is likely satisfied. Unfortunately, in our data, it is also the case that prices
in other markets are positively correlated with price. Therefore, these IIV will yield only one-sided bounds. However,
we can exploit the fact that we have multiple cities to generate a valid IIV, using the results in section IIIC. For each
of our markets, Boston and San Francisco, we use two IIVs.
Denote by Z1 the average price in the other markets in the
region—New England for Boston and northern California
for San Francisco—and by Z2 the average price in the other
city. In Nevo & Rosen (2008), we provide a model that justifies the required assumptions. The intuitive idea is as follows.
The average price in the region, Z1 , is assumed to be more
correlated with price because marginal cost shocks are common. It is also assumed to be less correlated with demand
because the composition of demand is assumed to be more
similar between Boston and San Francisco than with their
surrounding (less urban) regions.
In the sample, the partial correlations, ρpz1 = 0.81 and
ρpz2 = 0.48 satisfy the first of these assumptions. Furthermore, lemma 2 allows us to verify the second assumption.
Indeed, we find that σỹz1 ρx̃z2 < 0 < σỹz2 ρx̃z1 , so by the lemma,
there exists a range of γ such that ω(γ) = γZ2 − (1 − γ)Z1
satisfies the conditions required to get a two-sided bound.
The results in table 2 assume γ = 0.5. We also explored
γ = σz1 /(σz1 + σz2 ) and found almost identical results. For
both values of γ we can verify that the correlation between
price and ω(γ) = γZ2 − (1 − γ)Z1 is negative.
In some of the results, we also use assumption 4 on the
differenced IV. In the context of the demand application,
assumption 4 is quite intuitive. It implies that the price in
another market, say Z1 , is less correlated with the error term

668

THE REVIEW OF ECONOMICS AND STATISTICS

than is the price in the same market. In Nevo & Rosen
(2008) we provide a model that formalizes this intuition. If
we assume that assumptions 3 and 4 hold for both Z1 and
Z2 , then assumption 4 will also hold for the weighted difference, and the second set of bounds from proposition 5
applies.
The results are presented in table 2. The dependent variable in all columns is log(sjt ) − log(s0t ). The first column
presents results from regressing this variable on price, brand,
and quarter dummy variables and a city of San Francisco
dummy variable. The estimated price coefficient is negative,
and the advertising coefficient is positive, as expected. However, the own price elasticities are less than 1 in absolute
value. Once we use the average regional price as an IV, the
price coefficient becomes more negative, as expected. The
same is true when we use both the average regional price and
the price in the other city jointly.
The next two columns use weighted differences between
the average regional price and the price in the other city as IIV.
The results in column 4 are from only imposing assumption
3 on the differenced IV, while in column 5, we present results
when we additionally impose assumption 4.
The results yield a fairly consistent picture. If we do not
impose assumption 4, then the price coefficient is between
−8.7 and −4 (with a confidence interval of −11.4 and −2.3).
If we impose assumption 4, the price coefficient is between
−8.7 and −6 (with a confidence interval of −11.4 and −4).6
In all cases, the OLS point estimate is outside the confidence
interval. When we impose assumption 4, the IV estimate
is very close to the boundary of the confidence interval.
Note that in all cases, the excluded variables are highly
significant in the first stage, as indicated by the reported
F-statistics.
In the logit model price elasticities are proportional to the
price coefficient. So going from column 1 to 2 doubles the
price elasticities by roughly a factor of two. Further moving
to the lower bound of the identified set increases the price
elasticities by another factor of two. Generally the results
suggest that the IV price elasticities are too low in absolute
value.
There are two common uses for demand elasticities in
the IO literature. Often the elasticities are used in a firstorder condition, typically from a Bertrand pricing game, in
order to compute price cost margins (PCM). PCM computed
in this way are used to test among different supply models (Nevo, 2001). Our results suggest that the estimates of
PCM using the standard IV assumption might be too high.
Another use of demand estimates is for simulation of the
effects of mergers (Hausman et al., 1994, and Nevo, 2000).
The results in table 2 suggest that estimates using the standard IV assumption would tend to underestimate the effects
6 The confidence intervals reported in the table are for the identified set.
We also computed the confidence interval for the estimated parameters,
which are essentially identical and therefore not reported. For example, for
column 4, the confidence interval for the parameter was [−11, −2.6].

of a merger, because they will tend to underestimate the
substitution among products.

VI.

Conclusion

In this paper we study identification of the parameters of
a single regression equation with endogenous regressors and
instruments that fail to satisfy the usual exogeneity condition. Instead, we consider cases where the instruments are
assumed to have the same direction of correlation with the
error as the endogenous regressor, but where the instruments
are less correlated with the error term than is the endogenous
regressor.
Under our assumptions, we first derive an abstract characterization of the identified set for all parameters in a general
class of models and then focus primarily on set identification
of model parameters with a linear specification. Consistent
estimates of these bounds can be computed by standard OLS
and linear 2SLS regressions under the usual rank conditions.
We found that the bounds obtained, and in particular whether
they form an open or closed interval depends on the correlation between the endogenous regressor and the instrument,
which is point-identified. Furthermore, depending on both
the sign of σxz and its magnitude relative to σxu and σzu , β
may be closer to either βOLS or βIV
z even if Z is less endogenous than X, in the sense that our assumptions 3 and 4 are
satisfied.
Relative to conventional instrumental variable assumptions, the cost of our approach is that the weaker assumptions
we impose generally yield partial identification rather than
point identification of model parameters. The benefit, however, is that inferences made are robust to a lack of instrument
exogeneity and thus may be more credible in some circumstances. Additionally, for cases in which the applied
researcher wishes to impose instrument exogeneity, our
approach provides one answer to the question of how much
this assumption drives their results.
Our focus has been entirely on parametric models, with
specialized results for linear models. While much empirical work relies on such models, an interesting extension
would be to perform a similar analysis in a nonparametric
model. However, with a nonparametric functional form, it is
doubtful that our assumptions on the correlations of endogenous regressors and imperfect instruments with econometric
errors would prove anywhere near as fruitful. More promising would be an extension of our assumptions to conditional
expectation analogs. Indeed, the identifying power of MIV
assumptions was examined in a nonparametric context by
Manski and Pepper (2000). Their MIV assumption is a
conditional expectation analog of our assumption that the
instrument is positively correlated with the error. One could
also posit a conditional mean version of our assumption that
the instrument is less correlated with the latent variate than
is the endogenous regressor. In light of the positive results of
Manski and Pepper, it would seem that such an assumption

IDENTIFICATION WITH IMPERFECT INSTRUMENTS

could have significant identifying power in a nonparametric
model.
In the linear case, our focus was a model with a fixed
parameter. The heterogeneous effects model has attracted
much interest lately. For example, Angrist et al. (1996) show
that the standard IV estimate can be interpreted as a local
average treatment effect (LATE) under a standard exclusion
restriction and a monotonicity condition on the effect of the
IV on the endogenous variable. Angrist et al. (1996) show the
bias in the estimate if the exclusion restriction is violated. It
would be interesting to extend our analysis to this setup.

REFERENCES
Altonji, J. G., T. E. Elder, and C. R. Taber, “Selection on Observed
and Unobserved Variables: Assessing the Effectiveness of Catholic
Schools,” Journal of Political Economy 113 (2005), 151–184.
Andrews, D. W. K., and P. Guggenberger, “Validity of Subsampling and
Plug-In Asymptotic Inference for Parameters Defined by Moment
Inequalities,” Econometric Theory 25 (2009), 669–709.
Angrist, J., G. Imbens, and D. B. Rubin, “Identification of Causal Effects
Using Instrumental Variables,” Journal of the American Statistical
Association 91 (1996), 444–455.
Ashley, R., “Assessing the Credibility of Instrumental Variables Inference
with Imperfect Instruments via Sensitivity Analysis,” Journal of
Applied Econometrics 24 (2009), 325–337.
Berkowitz, D., M. Caner, and Y. Fang, “Are ‘Nearly Exogenous’ Instruments Reliable?” Economics Letters 101 (2008), 20–23.
Bontemps, C., T. Magnac, and E. Maurin, “Set Identified Linear Models,”
IDEI, working paper (2006).
Bresnahan, T. F., “Comment on Valuation of New Goods under Perfect and
Imperfect Competition” (pp. 237–247), in T. F. Bresnahan and R. J.
Gordon (Eds.), The Economics of New Goods (Chicago: University
of Chicago Press, 1997).
Chernozhukov, V., H. Hong, and E. Tamer, “Estimation and Confidence
Regions for Parameter Sets in Econometric Models,” Econometrica,
75 (2007), 1243–1284.
Chernozhukov, V., S. Lee, and A. Rosen, “Intersection Bounds, Estimation
and Inference,” CEMMAP working paper no. CWP19/09 (2009).
Conley, T., C. Hansen, and P. E. Rossi, “Plausibly Exogenous,” Chicago
Graduate School of Business, working paper (2006).
Frisch, R., Statistical Confluence Analysis by Means of Complete Regression
Systems (Oslo, Norway: University Institute for Economics, 1934).
Hahn, J., and J. Hausman, “IV Estimation with Valid and Invalid Instruments,” MIT working paper (2003).
Hansen, L. P., “Large Sample Properties of Generalized Method of Moment
Estimators,” Econometrica 50 (1982), 1029–1054.
Hausman, J. A. “Valuation of New Goods under Perfect and Imperfect
Competition” (pp. 209–237), in T. F. Bresnahan and R. J. Gordon (Eds.), The Economics of New Goods (Chicago: University of
Chicago Press, 1997).
Hausman, J. A., G. K. Leonard, and J. D. Zona, “Competitive Analysis with
Differentiated Products,” Annales D’Économie et de Statistique 34
(1994), 159–180.
Hotz, V. J., C. H. Mullin, and S. G. Sanders, “Bounding Causal Effects
Using Data from a Contaminated Natural Experiment: Analysing
the Effects of Teenage Child Bearing,” Review of Economic Studies
64 (1997), 575–603.
Imbens, G., “Sensitivity to Exogeneity Assumptions in Program Evaluation,” American Economic Review 93 (2003), 126–132.
Imbens, G., and C. F. Manski, “Confidence Intervals for Partially Identified
Parameters,” Econometrica 72 (2004), 1845–1857.
Klepper, S., and E. E. Leamer, “Consistent Sets of Estimates for Regressions
with Errors in All Variables,” Econometrica 52 (1984), 163–184.
Kraay, A., “Instrumental Variables Regressions with Honestly Uncertain
Exclusion Restrictions,” World Bank working paper (2008).
Leamer, E. E., “Is It a Demand Curve, or Is It a Supply Curve? Partial Identification through Inequality Constraints,” this review 63 (1981),
319–327.

669

Manski, C. F., and J. Pepper, “Monotone Instrumental Variables: With an
Application to the Returns to Schooling,” NBER working paper
(1998).
——— “Monotone Instrumental Variables: With an Application to the
Returns to Schooling,” Econometrica 68 (2000), 997–1010.
Nevo, A., “Mergers with Differentiated Products: The Case of the Readyto-Eat Cereal Industry,” Rand Journal of Economics 31 (2000), 395–
421.
——— “Measuring Market Power in the Ready-to-Eat Cereal Industry,”
Econometrica 69 (2001), 307–342.
Nevo, A., and A. Rosen, “Identification with Imperfect Instruments,”
CEMMAP working paper no. 16/08 (2008).
Pakes, A., J. Porter, K. Ho, and J. Ishii, “The Method of Moments with
Inequality Constraints,” Harvard University, working paper (2005).
Rosenbaum, P. R., Observational Studies (New York: Springer, 2002).
Rosenbaum, P., and D. S. Small, “War and Wages: The Strength of
Instrumental Variables and Their Sensitivity to Unobserved Biases,”
Journal of the American Statistical Association 103 (2008), 925–
933.
Small, D. S., “Sensitivity Analysis for Instrumental Variables Regression with Overidentifying Restrictions,” Journal of the American
Statistical Association 102 (2007), 1049–1058.
Stoye, J., “More on Confidence Regions for Partially Identified Parameters,”
Econometrica 77 (2009), 1299–1315.

APPENDIX A
Proofs
Lemma 1
Proof. The result follows directly from inspection of the expressions for
βOLS and βIV
z given by equations (4) and (5), respectively.
Proposition 1
Proof.

We note that if σxu , σzu ≥ 0, then assumption 4 gives

ρxu ≥ ρzu ≥ 0 ⇔ σz σxu ≥ σx σzu
⇔ σz (σxy − σx2 β) ≥ σx (σzy − σxz β) ⇔ βIV
v(1) ≥ β.
If instead σxu , σzu ≤ 0, then σz σxu ≤ σx σzu and βIV
v(1) ≤ β. Notice that
OLS
+ (1 − γ)βIV
βIV
z , where γ ≡ σz σx /(σz σx − σxz ) = 1/(1 − ρxz ).
v(1) = γβ
First consider the case where σxz < 0. Then γ > 0 and 1 − γ > 0,
OLS
implying that βIV
and βIV
z . If σxu ≥ 0, lemma 1 implies
v(1) lies between β
OLS
]. Since in this case, we also have that βIV
that β ∈ [βIV
z ,β
v(1) ≥ β, and
OLS
, it follows that βIV
βIV
v(1) ≤ β
v(1) provides a smaller upper bound for β:
IV
IV
IV
β ∈ [βIV
z , βv(1) ]. If instead σxu < 0, then similar logic leads to β ∈ [βv(1) , βz ].
IV
Now suppose σxz > 0. Then if σxu ≥ 0, βv(1) ≥ β, and lemma 1 gives β ≤
IV
OLS
, βIV
min{βOLS , βIV
z }. An immediate implication is that β ≤ min{β
z , βv(1) },
IV
OLS
OLS
IV
is redundant in that min{β , βz , βv(1) } =
but it turns out that β
IV
IV
OLS
OLS
< βIV
,
min{βIV
z , βv(1) }. This is because if β
z , and then βv(1) ≤ β
OLS
IV
IV
,
then
min{β
,
β
}
=
β
.
The
claim
while clearly if instead βOLS ≥ βIV
z
z
z
OLS
that βOLS < βIV
⇒ βIV
holds because σxz > 0 implies that
z
v(1) ≤ β
1 − γ = −σxz /(σz σx − σxz ) < 0, so that
OLS
OLS
βIV
+ (1 − γ)βIV
+ (1 − γ)βOLS = βOLS .
v(1) = γβ
z ≤ γβ

Symmetric reasoning applied to the case where σxz > 0 and σxu < 0
IV
gives that β ≥ max{βIV
z , βv(1) }. The sharpness of the bounds follows as an
implication of proposition 4, which covers the case of multiple imperfect
instruments and is proven below.
Corollary 1
Proof.

Using the above notation,

IV
OLS
IV
OLS
βIV
+ (1 − γ)βIV
− βIV
v(1) − βz = γβ
z − βz = γ(β
z ).

670

THE REVIEW OF ECONOMICS AND STATISTICS
implying that λ∗ (b) is monotone in the direction of σx̃x σỹz − σx̃z σxỹ .
First, suppose (σx̃x σz − σx σx̃z )σx̃z < 0. Then by proposition 2, b
IV
∗
lies between βIV
z and βv(1) . These values correspond to values of λ (b) of 0
and 1, respectively, and by monotonicity of λ∗ (b), it follows that λ∗ ∈ [0, 1].
Now suppose instead that (σx̃x σz −σx σx̃z )σx̃z ≥ 0. We consider two subcases
corresponding to the sign of σx̃z :

Proposition 2
Proof.

Assumptions 3 and 4 and ρxu > 0 give

ρxu ≥ ρzu ≥ 0 ⇔ σxu σz ≥ σzu σx ≥ 0
⇔ σxỹ σz − σxx̃ σz β ≥ σzỹ σx − σzx̃ σx β ≥ 0,
(1)

(2)

where the third line uses Ỹ = βX̃ + U, which is shown in lemma 3 below.
Inequality 1 provides an upper bound on β if σzx̃ σx − σxx̃ σz is negative, and
a lower bound if this expression is positive. Inequality 2 provides an upper
bound if σzx̃ is positive and a lower bound if σzx̃ is negative. Combining
these inequalities and a symmetrical derivation for the case ρxu < 0 gives
the conclusion of the proposition.
Let the conditions of proposition 2 hold. Then Ỹ = βX̃ + U.

Lemma 3.
Proof.
gives

Subtracting WE[Z w W ]−1 E[Z w Y ] from both sides of equation (8)

Ỹ = Xβ + W δ − WE[Z w W ]−1 E[Z w Y ] + U
= Xβ + W δ − WE[Z w W ]−1 E[Z w (Xβ + W δ + U)] + U
= Xβ + W δ − WE[Z w W ]−1 E[Z w X]β − WE[Z w W ]−1 E[Z w W ]δ + U
= X̃β + U.

Proof. Starting with the definition of Ỹ ∗ , and making use of Y ∗ = Y −Xβ,
we have that
 w
−1  w ∗ 
Ỹ ∗ = Y ∗ − W−j E Z−j
W−j E Z−j
Y
 w
−1  w 
= Y − Xβ − W−j E Z−j W−j E Z−j Y
−1  w 
 w
W−j E Z−j
X β = Ỹ − X̃β,
+ W−j E Z−j
w
w
W−j ]−1 E[Z−j
Y ]. Now plugging this into equation
where Ỹ = Y − W−j E[Z−j
(12) gives
−1 


δj = E Zjw W̃j E Zjw Ỹ ∗



−1 
−1 

= E Zjw W̃j E Zjw Ỹ − E Zjw W̃j E Zjw X̃ β,

so that δj is linear in β, which delivers the conclusion of the proposition,
since all other components of the above expression are point-identified.
Proposition 4
∗

Proof. That the true population parameter β belongs to B as defined in
the statement of the proposition follows immediately from proposition 2.
This is because proposition 2 can be applied to each Zj individually, yielding
that β must fall in the intersection of each of the bounds obtained with each
Zj individually.
It remains to show that these bounds are sharp—that any value of b ∈ B∗
is feasible. Choose an arbitrary b ∈ B∗ . To prove sharpness, it must be
shown that there exists a random variable Ũ such that the joint distribution
of (Y , X, W , Z, Z w , U) with U = Ũ satisfies all of our assumptions if β = b.
Define Ũ ≡ Ỹ − X̃b, where Ỹ and X̃ are as defined in equations (10a) and
(10b). By definition E[Z w Ũ] = 0. Next, adopt the shorthand Z = Zj for
any j and define
ρzũ
σx σỹz − bσx σx̃z
=
.
ρxũ
σz σxỹ − bσz σx̃x

Proof. We assume that condition 1 holds and show it is equivalent to 2.
Condition 1 holds if and only if there exists γ∗ ∈ [0, 1] such that γ∗ σz2 u −
(1 − γ∗ )σz1 u ≥ 0 and γ∗ σx̃z2 − (1 − γ∗ )σx̃z1 < 0, or, equivalently,
γ∗ ≥

σz1 u
≥0
σz1 u + σz2 u

(A2)

σx̃z1
≤ 1,
σx̃z1 + σx̃z2

(A3)

and
γ∗ <

from which it follows that
σx̃z1
σz1 u
−
≥ 0.
σx̃z1 + σx̃z2
σz1 u + σz2 u
Substituting σzj u = σzj ỹ − σx̃zj β for j = 1, 2 and collecting terms gives
σz1 ỹ σx̃z2 < σz2 ỹ σx̃z1 , condition 3. From the inequalities σzj u ≥ 0 and σx̃zj > 0
(implied by (σxx̃ σzj − σx̃zj σx )σx̃zj > 0) it also follows that condition 3 ⇒
condition 1. The equivalence of conditions
1 and 2 follows since equation
σ
γ∗
(A2) holds if and only if σx̃zx̃z1 > 1−γ
∗ , and equation (A3) holds if and only
∗

σ

2

z1 u
γ
if 1−γ
. That the inequality delivering two-sided bounds is implied
∗ > σ
z2 u
by the partial covariance between X and ω(γ∗ ) being negative (which is
part of condition 1) follows from first noting that this partial covariance
is equal to σx̃ω(γ∗ ) , and then by using the fact that σxx̃ > 0. This implies
that σω(γ∗ )x̃ < 0 ⇒ (σω(γ∗ )x̃ σx − σxx̃ σω(γ∗ ) ) < 0, and consequently that
(σω(γ∗ )x̃ σx − σxx̃ σω(γ∗ ) )σω(γ∗ )x̃ > 0.

Proposition 5
(A1)

To complete the proof of sharpness, we now show that λ∗ (b) ∈ [0, 1],
for arbitrary choice of j, which implies that assumptions 3 and 4 are both
satisfied. Note that the derivative of λ∗ (b) is
dλ∗ (b)
σx̃x σỹz − σx̃z σxỹ
= σx σz
,
db
(σz σxỹ − bσz σx̃x )2

IV
Case 2. σzx̃ > 0. Then b ∈ (−∞, min{βIV
z , βv(1) }] and σzx̃ σx − σxx̃ σz ≤ 0.
IV
Following the same logic as when σzx̃ < 0, we have that when βIV
z < βv(1) ,
ρx̃z
dλ∗ (b)
∗
< 0, and λ (b) as a function of b takes values on the interval [0, ρx̃x ).
dβ
 ρx̃z 
∗
≥ βIV
, 1 . In both cases, ρρx̃xx̃z ∈ [0, 1]
When instead βIV
z
v(1) , λ (b) ∈
ρx̃x
follows from the inequalities σzx̃ σx − σxx̃ σz ≤ 0 and σzx̃ > 0.

Lemma 2

Proposition 3

λ∗ (b) ≡

IV
Case 1. σzx̃ < 0. Then b ∈ [max{βIV
z , βv(1) }, ∞) and σzx̃ σx − σxx̃ σz ≥ 0.
IV
>
β
,
then
it
follows
that
σ
σ
−
σzx̃ σxỹ < 0, b ∈ [βIV
If βIV
zỹ xx̃
z
v(1)
v(1) , ∞), and
dλ∗ (b)
∗
<
0.
Thus,
the
upper
bound
on
λ
(b)
is
1,
achieved
when
b = βIV
v(1) .
db
Using L’Hôpital’s rule, if follows that the limit of λ∗ (b) as b → ∞ is
λ∗ (b) = σσxz σσx̃xx̃z = ρρx̃xx̃z , which is ≥ 0 from the inequalities σzx̃ σx − σxx̃ σz ≥ 0
IV
IV
(since (σx̃x σz − σx σx̃z )σx̃z ≥ 0) and
 σzx̃ <∗ 0. If instead βv(1) ≤ βz , then
σ
σzỹ σxx̃ − σzx̃ σxỹ ≥ 0, b ∈ σzx̃zỹ , ∞ , and dλdb(b) ≥ 0. Thus, the lower bound
∗
on λ∗ (b) is 0, achieved when b = βIV
z . The upper bound on λ (b) is the
limit of expression (A1) as b → ∞, which is λ∗ (b) = ρρx̃xx̃z ≤ 1, again since
σzx̃ σx − σxx̃ σz ≥ 0.

Proof. The proof follows by application of lemma 1 and proposition 4
with ω(γ∗ ) as an IIV for X. All that needs to be shown for the latter set of
bounds is that if assumption 4 holds for both Z1 and Z2 , then it also holds for
ω(γ∗ ), ρxu ≥ ρωu , or, equivalently, σxu σω ≥ σωu σx . By definition we have
σx σωu = γσx σz2 u − (1 − γ)σx σz1 u .

IDENTIFICATION WITH IMPERFECT INSTRUMENTS
Note that by the Cauchy-Schwarz inequality,
var(ω) = γ2 σz22 + (1 − γ)2 σz21 − 2γ(1 − γ)σz1 z2
≥ γ2 σz22 + (1 − γ)2 σz21 − 2γ(1 − γ)σz1 σz2
= (γσz2 − (1 − γ)σz1 )2 ,
which implies that σω ≥ |γσz2 − (1 − γ)σz1 |. If γσz2 − (1 − γ)σz1 > 0, we
have that
σxu σω ≥ σxu (γσz2 − (1 − γ)σz1 ) ≥ γσxu σz2 ,

671

since σxu ≥ 0, while if γσz2 − (1 − γ)σz1 < 0, we have that
σxu σω ≥ σxu ((1 − γ)σz1 − γσz2 ) ≥ (1 − γ)σxu σz1 > γσxu σz2 .
So in both cases,
σxu σω ≥ γσxu σz2 ≥ γσx σz2 u ≥ γσx σz2 u − (1 − γ)σx σz1 u = σx σωu ,
where the second inequality follows by assumption 4 for Z2 , the third since
σz1 u ≥ 0, and the equality by definition of ω.

This article has been cited by:
1. Yi Lu, Travis Ng. 2012. Do Imports Spur Incremental Innovation in the South?. China Economic Review 23:4, 819-832. [CrossRef]

