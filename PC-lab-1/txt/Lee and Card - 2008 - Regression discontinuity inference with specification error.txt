ARTICLE IN PRESS

Journal of Econometrics 142 (2008) 655–674
www.elsevier.com/locate/jeconom

Regression discontinuity inference with speciﬁcation error
David S. Leea,, David Cardb
a

Princeton University and NBER, USA
b
UC Berkeley and NBER, USA
Available online 24 May 2007

Abstract
A regression discontinuity (RD) research design is appropriate for program evaluation problems in which treatment
status (or the probability of treatment) depends on whether an observed covariate exceeds a ﬁxed threshold. In many
applications the treatment-determining covariate is discrete. This makes it impossible to compare outcomes for
observations ‘‘just above’’ and ‘‘just below’’ the treatment threshold, and requires the researcher to choose a functional
form for the relationship between the treatment variable and the outcomes of interest. We propose a simple econometric
procedure to account for uncertainty in the choice of functional form for RD designs with discrete support. In particular,
we model deviations of the true regression function from a given approximating function—the speciﬁcation errors—as
random. Conventional standard errors ignore the group structure induced by speciﬁcation errors and tend to overstate the
precision of the estimated program impacts. The proposed inference procedure that allows for speciﬁcation error also has a
natural interpretation within a Bayesian framework.
r 2007 Elsevier B.V. All rights reserved.
JEL classification: C21; C14; C51; C11
Keywords: Regression discontinuity; Speciﬁcation error; Random effects; Functional from; Bayesian estimation

1. Introduction
In the classic regression-discontinuity (RD) design (Thistlethwaite and Campbell, 1960) the treatment status
of an observation is determined by whether an observed covariate is above or below a known threshold. If the
covariate is predetermined it may be plausible to think that treatment status is ‘‘as good as randomly
assigned’’ among the subsample of observations that fall just above and just below the threshold.1 As in a true
experiment, no functional form assumptions are necessary to estimate program impacts when the treatmentdetermining covariate is continuous: one simply compares average outcomes in small neighborhoods on either
side of the threshold. The width of these neighborhoods can be made arbitrarily small as the sample size
Corresponding author. Tel.: +1 609 258 9548; fax: +1 609 258 4041.

E-mail address: davidlee@princeton.edu (D.S. Lee).
This assumption may or may not be plausible, depending upon the context. In particular, if the treatment is under perfect control of
individuals, and there are incentives to ‘‘sort’’ around the threshold, the RD design may be invalid. On the other hand, even when
individuals have partial control over the covariate, as long as there is a stochastic component that has continuous density, the treatment
variable is as good as (locally) randomly assigned. See Lee (2006) for details.
1

0304-4076/$ - see front matter r 2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.jeconom.2007.05.003

ARTICLE IN PRESS
656

D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

grows, ensuring that observed and unobserved characteristics of observations in the treatment and control
groups are identical in the limit. This idea underlies the approach of Hahn et al. (2001) and Porter (2003), who
describe non-parametric and semi-parametric estimators of RD gaps.
In many applications where the RD design seems compelling, however, the covariate that determines
treatment is inherently discrete or is only reported in coarse intervals. For example, government programs like
Medicare and Medicaid have sharp age-related eligibility rules that lend themselves to an RD framework, but
in most data sets age is only recorded in months or years. In the discrete case it is no longer possible to
compute averages within arbitrarily small neighborhoods of the cutoff point, even with an inﬁnite amount of
data. Instead, researchers have to choose a particular functional form for the model relating the outcomes of
interest to the treatment-determining variable. Indeed, with an irreducible gap between the ‘‘control’’
observations just below the threshold and the ‘‘treatment’’ observations just above, the causal effect of the
program is not even identiﬁed in the absence of a parametric assumption about this function.
In this paper we propose a simple procedure for inference in RD designs in which the treatment-determining
covariate is discrete. The basic idea is to model the deviation between the expected value of the outcome and
the predicted value from a given functional form as a random speciﬁcation error. Modeling potential
speciﬁcation error in this way has a number of immediate implications. Most importantly, it introduces a
common component of variance for all the observations at any given value of the treatment-determining
covariate. This creates a problem similar to the one analyzed by Moulton (1990) for multi-level models in
which some of the covariates are only measured at a higher level of aggregation (e.g., micro models with statelevel covariates). Random speciﬁcation errors can be easily incorporated in inference by constructing sampling
errors that include a grouped error component for different values of the treatment-determining covariate.
The use of ‘‘clustered’’ standard errors will generally lead to wider conﬁdence intervals that reﬂect the
imperfect ﬁt of the parametric function away from the discontinuity point.
More subtly, inference in an RD design involves extrapolation from observations below the threshold to
construct a counterfactual for observations above the threshold. As in a classic out-of-sample forecasting
problem, the sampling error of the counterfactual prediction for the point of support just beyond the threshold
includes a term reﬂecting the expected contribution of the speciﬁcation error at that point. Since the estimated
(local) treatment effect is just the difference between the mean outcome for these observations and the
counterfactual prediction, the precision of the estimated treatment effect depends on whether one assumes that
the same speciﬁcation error would prevail in the counterfactual world. If so, this error component vanishes. If
not, the conﬁdence interval for the local treatment effect has to be widened even further.
The paper is organized as follows. Section 2 describes the RD framework and why discreteness in the
treatment-determining covariate implies that the treatment effect is not identiﬁed without assuming a
parametric functional form. Section 3 describes the proposed inference procedure under a model where
speciﬁcation errors are considered random. Section 4 describes a modiﬁed procedure under less restrictive
assumptions about the speciﬁcation errors. Section 5 proposes an alternative, efﬁcient estimator for the
treatment effect, and Section 6 relates this estimator to a Bayesian approach. Section 7 concludes.

2. The RD design with discrete support
2.1. The problem of discreteness
To illustrate how discreteness causes problems for identiﬁcation in an RD framework, consider the
following potential outcomes formulation.2 There is a binary indicator D of treatment status which is
determined by whether an observed covariate X is above or below a known threshold x0 : D ¼ 1½X Xx0 .
Let Y 1 represent the potential outcome if an observation receives treatment and let Y 0 represent the potential
outcome if not. The goal is to estimate E½Y 1  Y 0 jX ¼ x0 ; the average treatment effect at the threshold.
As usual, Y 1 and Y 0 are not simultaneously observed for any individual. Instead, we observe
Y ¼ DY 1 þ ð1  DÞY 0 .
2

For an overview of the potential outcomes framework for program evaluation problems see, for example, Angrist and Krueger (1999).

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

657

When the support of X is continuous and certain smoothness assumptions are satisﬁed, E½Y 1  Y 0 jX ¼ x0 
is identiﬁed by the discontinuity in the regression function for the observed outcome Y at x0 . More speciﬁcally,
if E½Y 1 jX ¼ x and E½Y 0 jX ¼ x are both continuous in x at x0 , then
E½Y jX ¼ x0   limþ E½Y jX ¼ x0  e
e!0

¼ E½Y 1 jX ¼ x0   limþ E½Y 0 jX ¼ x0  e
e!0

¼ E½Y 1  Y 0 jX ¼ x0 .
This idea is illustrated in Fig. 1. The data identify E½Y 1 jX ¼ x when xXx0 ; and E½Y 0 jX ¼ x when xox0 ,
as indicated by the solid lines. Because of the discontinuous rule that determines treatment status, the data do
not identify the dashed lines, or the counterfactual mean E½Y 0 jX ¼ x0  (the open circle). What the data do
yield is E½Y 0 jX ¼ x0  e, which can be an arbitrarily good approximation to E½Y 0 jX ¼ x0 , with e sufﬁciently
small. In this setting, non-parametric and semi-parametric procedures for estimation are appropriate (Hahn
et al., 2001; Porter, 2003), particularly when the sample size is large, in which case one can precisely estimate
local averages just above and below x0 .
This limiting argument, however, does not work when the support of X is discrete. Suppose X can take on J
distinct values (x1 ; . . . ; xJ ) and let xk ¼ 0 be the value of the covariate at the discontinuity threshold. Fig. 2 is a
discrete analog to Fig. 1. As before, the counterfactual mean E½Y 0 jX ¼ 0 is unobservable. Here, the discrete
analog to E½Y jX ¼ x0   lime!0þ E½Y jX ¼ x0  e is E½Y jX ¼ 0  E½Y jX ¼ xk1 , which substantially overestimates the true effect E½Y 1  Y 0 jX ¼ 0.
Unlike the continuous case, even if the population quantities E½Y jX ¼ xj  (j ¼ 1; . . . ; J) are known,
E½Y 1  Y 0 jX ¼ 0 remains unidentiﬁed. Identiﬁcation can be achieved by assuming that the regression
function can be expressed as
E½Y jX ¼ xj  ¼ Dj b0 þ hðxj Þ,

(1)

where hðÞ is a continuous function, Dj ¼ 1½xj X0, and hð0Þ ¼ E½Y 0 jX ¼ 0. With this speciﬁcation b0 (equal to
E½Y 1  Y 0 jX ¼ 0) is the parameter of interest. Eq. (1) is equivalently expressed as a model for the micro-data
Y ij ¼ Dj b0 þ hðxj Þ þ eij ,

(2)

where Y ij is the outcome for the ith individual with the jth value of X, and eij  Y ij  E½Y ij jX ¼ xj , with
conditional variance s2ej .
It is important to note that b0 is only identiﬁed when hðÞ is determined by a limited number of parameters.
With only J distinct values of X, if hðÞ contains J or more parameters, there is no way for the data to

E[Y|X=x]

E[Y1|X=x]

E[Y0|X=x]
x0-e

x0
X

Fig. 1. Regression discontinuity, continuous covariate.

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

E[Y|X=x]

658

E[Y1|X=x]
E[Y1|X=xk]
E[Y0|X=xk]
E[Y0|X=xk-1]

E[Y0|X=x]
xk

xk-1
X

Fig. 2. Regression discontinuity, discrete covariate.

distinguish between a discontinuity in the regression function, and a continuous function that connects
E½Y jX ¼ xk1  and E½Y jX ¼ 0.
In addition, the asymptotic arguments used to justify non-parametric estimation of b0 (as in Hahn et al.,
2001) cannot be applied here. Even with an inﬁnite amount of data, there are no data in a region in an
‘‘arbitrarily’’ small neighborhood below 0. For example, a one-sided kernel (or local linear) estimator will, in
the limit, place no weight on observations for which X pxk1 , and all of the weight on observations slightly
below 0 (but above xk1 ). But because of the discrete support there are no data in this neighborhood.
2.2. Parametric estimation and inference
It is common practice for researchers to estimate RD designs by regressing Y on a low-order polynomial in
xj , and the treatment indicator Dj (e.g., Card and Shore-Sheppard, 2004; Kane, 2003; DiNardo and Lee, 2004;
Lee, 2006). If the polynomial function is the correct form for hðÞ, then conventional least squares inference is
appropriate.
When the covariate is discrete, a simple goodness-of-ﬁt statistic for the polynomial functional form can be
calculated as
G

ðESS R  ESS UR Þ=ðJ  KÞ
,
ESS UR =ðN  JÞ

(3)

where ESS R is the (restricted) error sum of squares from estimating (2) with a polynomial in xj for hðxj Þ, and
ESS UR is the (unrestricted) sum of squares from regressing Y ij on a full set of dummy variables for the J
values of X. Under normality (and homoskedasticity) of eij , this statistic is distributed as F ðJ  K; N  JÞ,
where K is the number of parameters estimated in (2) and N is the number of observations.3 If the statistic
exceeds the critical value, it suggests that the polynomial function is too restrictive.
A rejection of the polynomial, however, need not imply that the least squares estimate b^ is inconsistent for
b0 . Following White (1980) and Chamberlain (1994), b^ is consistent for b , the discontinuity in the function
3
Under non-normal (homoskedastic) eij , ðJ  KÞ  G will be asymptotically distributed as w2 ðJ  KÞ. Letting W j be the vector of
regressors (the polynomial and dummy variable), under heteroskedastic eij , one can compute the statistic as

G~ 

nj
nj
J X
J X
X
X
1
1
^ 2
ðY ij  W j yÞ
ðY ij  Y j Þ2
2
^ ej
^ 2ej
j¼1 i¼1 s
j¼1 i¼1 s

P Pnj
Pnj
which is a version of ESSR  ESS UR , weighted by the reciprocal of s^ 2ej ¼ ðn1j i¼1
ðY ij  Y j Þ2 . Equivalently, G~ ¼ ½ Jj¼1 i¼1
^ 2   N, or G~ ¼ PJ ðnj =s^ 2 ÞðY j  W j yÞ
^ 2 . It can be shown that G~ is distributed asymptotically as w2 ðJ  KÞ.
ð1=s^ 2ej ÞðY ij  W j yÞ
ej
j¼1

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

659

that is the least squares approximation to the true function in Eq. (1).4 The difference between b and b0 is
unknown, but may be small (or could even be zero), even if the goodness-of-ﬁt statistic leads one to reject the
polynomial speciﬁcation.
Despite this possibility, it seems natural for a researcher to be relatively more ‘‘skeptical’’ of b^ as an estimate
of b0 when the goodness-of-ﬁt statistic rejects the model, and relatively more ‘‘conﬁdent’’ in b^ when the
F-statistic is relatively close to 1. The inference procedures proposed below formalizes this notion. We propose
to inﬂate conventional standard errors to reﬂect ‘‘modeling uncertainty’’. As we show below, the degree of
inﬂation is directly related to the goodness-of-ﬁt statistic G.

3. Random speciﬁcation error
Suppose a polynomial is chosen to approximate hðÞ. The regression in Eq. (2) can be re-written as
Y ij ¼ a0 þ Dj b0 þ X j g0 þ aj þ eij ,

(4)

where X j is a row vector of polynomial terms in xj (with the normalization xk ¼ 0), and aj  hðxj Þ  X j g0 is
speciﬁcation error—the degree to which the true function hðÞ deviates from the polynomial function.5
Throughout the paper, we focus on the case of no other individual-level covariates, but it will be clear that the
analysis can be extended to include such covariates. Moreover, if the RD design is valid, they can be excluded
in the same way that baseline covariates can be excluded in an analysis of a randomized experiment (see, for
example, the discussion in Lee, 2006). We also focus on the case of the ‘‘sharp’’ RD design – in which the
treatment is a deterministic function of X. It will be clear, however, that these ideas also extend to ‘‘fuzzy’’ RD
designs—in which there is imperfect compliance of the treatment.6 The Appendix describes how to apply the
inference procedures described below to the ‘‘fuzzy’’ design.
Our ﬁrst proposed inference procedure stems from treating this modeling error as random and orthogonal
to X (or, alternatively, E½aj jX ¼ xj  ¼ 0, j ¼ 1; . . . ; J). This assumption implies that the least squares estimate
b^ will be consistent for b0 . More importantly, it implies that the conventional heteroskedasticity-consistent
^ This is because the randomness in
variance estimators will generally be inconsistent for the true variance of b.
aj has induced a within-group correlation (at the j level) in the error. Essentially, the speciﬁcation error here is
a random effect, and it is well known that standard error estimates that ignore this within-group correlation
will under-state the true variability of the least squares estimates (Moulton, 1990).
Thus, our ﬁrst observation is that if the polynomial function is viewed as an approximation that nonetheless
gives unbiased estimates of the discontinuity, and speciﬁcation errors are considered to be random, then
conventional standard error formulas understate the variability of the least squares estimate of the
discontinuity gap.
Letting y0  ða0 ; b0 ; g0 Þ, and y^ be the least squares
in the regression of Y ij on W j  ð1; Dj ; X j Þ, a
pﬃﬃﬃﬃestimator
ﬃ
consistent estimator for the asymptotic variance of N ðy^  y0 Þ is given by
! n
!!
!1  
nj
nj
j
J X
J
X
X
1 X
J 1X
0
0
^
^
W jW j
W j ðY ij  W j yÞ
W j ðY ij  W j yÞ
N j¼1 i¼1
N J j¼1 i¼1
i¼1
!1
nj
J X
1 X
0

W jW j
ð5Þ
N j¼1 i¼1
When this interpretation of b^ is adopted, the conventional heteroskedasticity-consistent standard errors are appropriate for inferences
about b . Chamberlain (1994) derives the asymptotic distribution of minimum distance estimators under mis-speciﬁcation, and shows the
equivalence of the variance to the heteroskedasticity-consistent variance in a least squares regression.
5
X j may include interactions between the polynomial terms and the treatment indicator. This allows the regression function to have
different derivatives (up to the order of the interaction terms) on either side of the threshold.
6
Discussion of the distinction between the ‘‘sharp’’ and ‘‘fuzzy’’ designs can be found in Hahn et al. (2001).
4

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

660

with nj ﬁnite as J ! 1. The computation of this variance is available as a standard option in today’s typical
statistical analysis software.7
The assumption that aj is orthogonal to X may seem restrictive, but it should be noted that conventional
inference using parametric functional forms (like polynomial functions) implicitly imposes the strictly more
restrictive assumption of no speciﬁcation error, aj ¼ 0.
3.1. Clustered standard errors and the goodness-of-fit statistic
There is a connection between the goodness-of-ﬁt statistic given in (3), and the difference between the nonclustered and clustered variance estimators.
To see this, ﬁrst note that (5) can be re-written as
!1
!

J
J 
nj
nj 2 0
1X
1X
2
0
^
^
W jW j
VC 
W j W j ðY j  W j yÞ
J j¼1 N=J
J j¼1 N=J
!1
J
nj
1X
0

W jW j
,
ð6Þ
J j¼1 N=J
Pnj
Y ij ; note that this estimator has been re-normalized to be consistent for the asymptotic
where Y j ¼ ð1=nj Þ i¼1
pﬃﬃﬃ
pﬃﬃﬃﬃﬃ
^
variance for J ðy  y0 Þ, rather than for N ðy^  y0 Þ. This shows that the clustered standard error formula in
the micro-level regression is equivalent to using the conventional heteroskedasticity-consistent standard error
in a ‘‘cell-level’’ regression of Y j on W j , weighting each cell by the weight nj =ðN=JÞ.8
Consider the simpliﬁed case where nj ¼ n0 for all cells, so the weight becomes 1, and that aj and eij have
constant variance s2a and s2e across all J cells. In this case, we have


p
s2
V^ C ! E½W 0j W j 1 s2a þ e
n0
p
while the non-clustered variance estimator V^ NC ! E½W 0j W j 1 ðs2a þ s2e Þð1=n0 Þ.9 It follows that the ratio of the
clustered to the non-clustered estimated variance will converge in probability to
n0

s2a þ s2e =n0
.
s2a þ s2e

(7)

This quantity represents the extent to which the non-clustered variance must be ‘‘inﬂated’’.
This ratio can be estimated by a Lagrange Multiplier version of the goodness-of-ﬁt statistic in G in (3),
which is given by
1
1=ðJ  KÞðESS R  ESS UR Þ
LM ¼
J K
ð1=NÞESS R
P
^ 2
ð1=ðJ  KÞÞ Jj¼1 ðY j  W j yÞ
¼ n0
P P0
^ 2
ð1=NÞ Jj¼1 ni¼1
ðY ij  W j yÞ
which, with n0 ﬁxed and J ! 1, can be shown to converge in probability to the ratio in (7).
4. Mis-speciﬁcation of counterfactual functions
In this section, we show that the special structure of an RD design implies that in some circumstances, the
^ If the speciﬁcation error is random, then it is
clustered standard errors may still understate the variability of b.
7

For example, in STATA, this variance can be computed by regressing Y ij on W j , and using the ‘‘cluster’’ option, where the groups are
deﬁned by the discrete values of X.
8
The sum of these weights across the J cells is equal to J.
pﬃﬃﬃ
pﬃﬃﬃﬃﬃ
9
ð1=n0 Þ is added because this is the estimator for the asymptotic variance for J ðy^  y0 Þ, rather than for N ðy^  y0 Þ.

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

661

necessary to decide how the error in estimating E½Y 1 jX ¼ xk  is related to the speciﬁcation error in estimating
E½Y 0 jX ¼ xk . As shown below, if the errors are assumed to be identical, then the approach described above is
appropriate. If the errors are independent, then the standard errors for b^ must be inﬂated even further.
Before describing these two cases in detail, we provide some intuition for the difference between the two
cases. As we have argued above, in the case of discrete X, non-parametric identiﬁcation of the RD design is
impossible. Since it is necessary to impose some functional form, estimating the ‘‘discontinuity gap’’ amounts
to using data away from the discontinuity threshold to estimate the average outcome at the threshold.
Consider Fig. 3A, which abstracts from sampling error (i.e., suppose there is an inﬁnite amount of data
per value of X). The solid dots represent E½Y jX ¼ xj  away from the discontinuity. Essentially, we are
using data from the right, as well as an approximating function, to estimate the true E½Y 1 jX ¼ xk . In the
ﬁgure, the approximating function (the solid line) is not perfect, and the true E½Y 1 jX ¼ xk  is larger than that
predicted by the functional form. Similarly, the extrapolation of E½Y 0 jX ¼ xk  from data on the left also
under-predicts the truth. Assuming ‘‘identical’’ speciﬁcation errors means that we are assuming that the error
in our ‘‘forecast’’ of E½Y 1 jX ¼ xk  is of the same sign and magnitude as our forecast error of E½Y 0 jX ¼ xk , in
repeated draws of the random effect error. One realization of this process is illustrated in Fig. 3A.
Fig. 3B, by contrast, depicts a single realization from a process that allows the prediction error for
E½Y 1 jX ¼ xk  to be independent of the error for E½Y 0 jX ¼ xk . In the ﬁgure, the parametric functional form
over-predicts E½Y 0 jX ¼ xk  and under-predicts E½Y 1 jX ¼ xk .

E[Y|X=x]

E[Y1|X=xk]

E[Y0|X=xk]

X

E[Y|X=x]

E[Y1|X=xk]

E[Y0|X=xk]

X
Fig. 3. (A) Counterfactual speciﬁcation, identical errors; (B) Counterfactual speciﬁcation, independent errors.

ARTICLE IN PRESS
662

D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

4.1. Identical specification errors
Suppose we approximate the following two counterfactual functions by the following polynomial functions
E½Y 1 jX ¼ xj  ¼ a0 þ X j g0 þ b0 þ a1j ,
E½Y 0 jX ¼ xj  ¼ a0 þ X j g0 þ a0j ,

ð8Þ

where a1j and a0j are the random speciﬁcation errors in the approximations for E½Y 1 jX ¼ xj  and
E½Y 0 jX ¼ xj , respectively. The approximation for E½Y 1 jX ¼ xj  is parallel to the approximation for
E½Y 0 jX ¼ xj , and different by exactly b0 for each value of X.
If we assume that a1j ¼ a0j , and we use the fact that Y ¼ DY 1 þ ð1  DÞY 0 , then we obtain
E½Y jX ¼ xj  ¼ a0 þ X j g0 þ Dj b0 þ aj ,
where aj  Dj a1j þ ð1  Dj Þa0j . This expression leads to the same regression speciﬁcation given in (4). As
before, b0 (or, E½Y 1  Y 0 jX ¼ xk ) is the causal parameter of interest, and the clustered standard error formula
is appropriate for inference.
The assumption of identical speciﬁcation errors is equivalent to assuming that the same approximation error
would arise whether the cell at the discontinuity point assigned to treatment or not. Equivalently, this assumption
implies that the treatment effect at the discontinuity is deterministic, that is, E½Y 1  Y 0 jX ¼ xk  ¼ b0 .
One case where this assumption may be valid is when the researcher believes that the source of the
approximation error is independent of treatment status. For example Card and Shore-Sheppard (2004) use a
regression discontinuity design to examine the impact of the Medicaid expansions on health insurance. The
family income eligibility limits for Medicaid were relaxed for children born after a certain date, and Card and
Shore-Sheppard (2004) examine the relationship between Medicaid enrollment and quarter of birth. It is
possible that there are small health differences by season of birth, implying that demand for Medicaid
coverage varies by quarter of birth; here, aj would reﬂect those seasonal differences. Arguably, the same
seasonal differences would be present irrespective of treatment status.
Note that the speciﬁcation errors a1j and a0j could be identical even when the counterfactual functions are
not strictly parallel. To see this, consider the speciﬁcation
E½Y 1 jX ¼ xj  ¼ a0 þ X j g1 þ b0 þ a1j ,
E½Y 0 jX ¼ xj  ¼ a0 þ X j g0 þ a0j .
Here, the coefﬁcients on the polynomial terms are allowed to be different. We now have
E½Y jX ¼ xj  ¼ a0 þ X j g0 þ X j Dj ðg1  g0 Þ þ Dj b0 þ aj ,
where again, aj  Dj a1j þ ð1  Dj Þa0j . This, too, leads to the ‘‘random-effects’’ regression equation given in (4),
except that interactions between Dj and the polynomial terms are included. In this fully-interacted model the
treatment effect function
E½Y 1  Y 0 jX ¼ xj  ¼ X j ðg1  g0 Þ þ b0

(9)

is itself a polynomial in X. Therefore, in order to use this speciﬁcation, it is necessary to assume that even if
polynomials provide only an approximation to each counterfactual function separately, there is no approximation
error in describing the difference in the counterfactual functions as a polynomial in X (at least at X ¼ xk ).
4.2. Independent specification errors
Alternatively, one can allow a1j aa0j . When this is true, the treatment effect of interest is no longer equal to
b0 . Instead, we have, using (8),
E½Y 1  Y 0 jX ¼ xk  ¼ b0 þ a1k  a0k .

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

663

b^ will be consistent for b0 , but not for the parameter of interest, E½Y 1  Y 0 jX ¼ xk . Formally, with nonidentical a1j , a0j , we have
b^  E½Y 1  Y 0 jX ¼ xk  ¼ ðb^  b0 Þ  ða1k  a0k Þ,

(10)

where the ﬁrst term converges in probability to 0 as J ! 1, while the second term does not. No matter how
much data are available, there is still uncertainty in the average treatment effect, induced by uncertainty about
the realizations of a1k , a0k .
Inference about E½Y 1  Y 0 jX ¼ xk  requires accounting for this uncertainty. In particular, it is necessary to
assume that the speciﬁcation errors are drawn from some parametric distribution. A natural choice is to
assume that a1j and a0j are jointly and mutually independent, for each j. Independence implies that the forecast
error for E½Y 1 jX ¼ xk  is independent of the forecast error for E½Y 0 jX ¼ xk .
In the Appendix, it is shown that, assuming that a1j and a0j have equal variance s2a across all j values,
b^  E½Y 1  Y 0 jX ¼ xk  d
qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
! Nð0; 1Þ,
d
2
^
VðbÞ þ 2s^ a

(11)

d
^  V^ C =J is the standard cluster-consistent variance estimator.10 s^ 2 is a consistent estimator of s2 , given by
where VðbÞ
a
a
s^ 2a 

nj
J
J
X
1 X
1 X
^ 2 1
nj ðY j  W j yÞ
ðY ij  Y j Þ2 .
N j¼1
N j¼1 nj  1 i¼1

(12)

The ﬁrst term is the weighted variance of the mean residual from the regression. With nj ﬁxed, and as J ! 1,
P
it converges in probability to s2a þ limJ!1 ðJ=NÞð1=JÞ Jj¼1 s2ej . It contains the variance in the speciﬁcation
error aj , as well as sampling error in estimating the Y j ’s. The second term is an estimate of
P
limJ!1 ðJ=NÞð1=JÞ Jj¼1 s2ej , the average sampling variance.11
This implies that the interval
qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ

d
d
^b  1:96 Vð
^bÞ þ 2s^ 2 ; b^ þ 1:96 Vð
^ þ 2s^ 2
bÞ
(13)
a
a
will contain E½Y 1  Y 0 jX ¼ xk  with approximately 0:95 probability. The interpretation of this conﬁdence
interval is similar to conventional conﬁdence intervals, except that here the parameter E½Y 1  Y 0 jX ¼ xk  is
itself random, due to the randomness of the speciﬁcation errors. Thus, the correct statement of inference is
that the interval contains E½Y 1  Y 0 jX ¼ xk  about 95% of the time in repeated draws of both eij and the
(random) speciﬁcation errors a1k and a0k .12
The interval in (13) strictly contains the usual conﬁdence interval, and therefore leads to more conservative
inferences. A wider interval is an intuitive result, since uncertainty regarding the extrapolation errors should
yield less precise inferences. Another intuitive aspect of the interval in (13) is that it collapses to the
conventional one when the chosen parametric form is exactly correct and s2a is known to be zero.
There is a close connection between s^ 2a and the goodness-of-ﬁt statistic G. Consider the case of a constant
sampling error variance s2e across all j cells. In this case, an alternative consistent estimator for s2a could be
10
It may appear that the homoskedasticity and normality of a1j and a0j is restrictive, but it is important to remember that it is less
restrictive than assuming that there is no speciﬁcation error at all (i.e., s2a ¼ 0).
11
Under heteroskedasticity of eij across the J groups, a consistent estimator is given by
!
2
J
J
X
X
nj
nj s^ ej
1
^ 2P 1
ðY

W
yÞ
s^ 2a  PJ
,
j
j
J
^ 2ej Þ j¼1 s^ 2ej
^ 2ej Þ j¼1 s^ 2ej nj
j¼1 ðnj =s
j¼1 ðnj =s
Pnj
ðY ij  Y j Þ2 .
where s^ 2ej ¼ ð1=nj Þ i¼1
12
(13) has been called an ‘‘Empirical Bayes’’ Conﬁdence Interval. See Morris (1983).

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

664

given by
s~ 2a 



 X
nj
J X
J
1 J
1 X
^ 2J
nj ðY j  W j yÞ
ðY ij  Y j Þ2 .
J  K N j¼1
N N  J j¼1 i¼1

The probability limits of the ﬁrst and second terms are s2a þ limJ!1 ðJ=NÞs2e and limJ!1 ðJ=NÞs2e ,
respectively. It is also true that s~ 2a ¼ ðG  1ÞðESS UR =N  JÞðJ=NÞ. Thus, the more that G exceeds 1—evidence
that the parametric approximation is too restrictive—the wider the conﬁdence interval (13). Obtaining a
negative value for s~ 2a simply implies that a goodness-of-ﬁt statistic would be less than 1.
Finally, we draw attention to a technical point that leads to two complications. First, under conventional
pﬃﬃﬃ
asymptotics, (11) only holds when s2a 40. When s2a ¼ 0,
J ðb^  E½Y 1  Y 0 jX ¼ xk Þ converges in
d
^ þ 2J s^ 2 does not converge to V C : the ﬁrst term
distribution to Nð0; V C Þ (where V C ¼ p limðV^ C Þ). But J VðbÞ
a
converges to V C , but the second term does not vanish. Secondly, under conventional asymptotics, even when
s2a 40, b^  E½Y 1  Y 0 jX ¼ xk  converges in distribution to Nð0; 2s2a Þ, because the variance in the estimator of b0
vanishes as the number of cells increases. Thus, with any ﬁxed sample, the usual asymptotic approximation leads
2
2
to an unintuitive result that the variance is V C =J when s2a ¼ 0, but jumps to 2s
paﬃﬃﬃfor sa 40 but arbitrarily small.
The source of these problems is that the estimation error b^  b0 is Op ð1= J Þ, while the speciﬁcation error
a1k  a0k is Op ð1Þ. In the Appendix, we propose a sequence for the data that allows the variance of X to shrinks
as the number of cells J grows. Intuitively, although the increase in the number of cells tends to decrease the
variability in the least squares estimator, the shrinking variance in the regressors offsets this
tendency, leading to an estimation error that is of the same stochastic order as the speciﬁcation error. The
expression in Eq. (11) will then be valid whether or not s2a ¼ 0, and the asymptotic variance in the overall error
b^  E½Y 1  Y 0 jX ¼ xk  will be continuous at s2a ¼ 0:
5. Efﬁcient estimation
When the speciﬁcation errors a1j and a0j are assumed to be different, there is an estimator for E½Y 1  Y 0 jX ¼ 0
^ This is because the least squares estimate of b amounts to the
that is more efﬁcient than the OLS estimator b.
0
difference between the prediction for E½Y 1 jX ¼ 0 and the prediction for E½Y 0 jX ¼ 0, using data away from the
discontinuity threshold. While it is necessary to make such an extrapolation for E½Y 0 jX ¼ 0 (since this quantitity is
unobservable), information on E½Y 1 jX ¼ 0 is available from the sample mean Y k . Use of this information can
lead to a more efﬁcient estimator of the treatment effect.
Fig. 3B illustrates the point. In the ﬁgure, b^ estimates the discontinuity in the function represented by the
solid lines. In this particular realization of the data, the treatment effect at X ¼ 0 is the difference between the
solid circle, which is above the parametric function, and the open circle, which is below. The deviation of the
open circle from the parametric line is unobservable, but the cell mean provides information on E½Y 1 jX ¼ 0.
Indeed, as the number of observations per cell tends to inﬁnity, we can estimate E½Y 1 jX ¼ 0 perfectly.
More formally, assume that Eq. (4) is valid, with the normalization that xk ¼ 0. Let a^ þ b^ be the least
squares estimate of E½Y 1 jX ¼ 0 that leaves out the kth cell in the estimation.13 Now consider the combination
estimator
^
b ¼ b^ þ lðY k  ð^a þ bÞÞ

(14)

which is the least squares estimator of the discontinuity adjusted by the kth cell mean’s deviation from the least
squares prediction. The error in the estimator is given by
^
b  E½Y 1  Y 0 jX ¼ 0 ¼ ðb^  b0 Þ  ða1k  a0k Þ þ lða0 þ b0 þ a1k þ ek  ð^a þ bÞÞ
¼ ðb^  b Þ  ða1k  a0k Þ þ lða1k þ ek  ð^a þ b^  ða0 þ b ÞÞÞ
0

which will be centered around zero.
13

Note that this estimator is asymptotically equivalent to one that includes the kth cell.

0

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

665

The variance of this error is
^ þ 2s2 þ l2 V ða1k þ ek  ð^a þ bÞÞ
^ þ 2lCððb^  ða1k  a0k Þ; a1k þ ek  ð^a þ bÞÞ
^
V ðbÞ
a


2
^ þ 2s2 þ l2 s2 þ sk þ V ð^a þ bÞ
^  2lðCðb;
^ ð^a þ bÞÞ
^ þ s2 Þ,
¼ V ðbÞ
a
a
a
nk
where the equality holds because the least squares estimators a^ and b^ do not include data from the kth cell.
The optimal l can be found by differentiating this variance with respect to l and solving for the ﬁrst order
condition, yielding
l¼

^ ð^a þ bÞÞ
^
s2a þ Cðb;
.
^ þ s2 =nk
s2a þ V ð^a þ bÞ
k

(15)

The intuition behind this formula is illustrated by considering the case in which two separate parametric forms
are used to model the function to the left and the right of the discontinuity threshold; that is, when the terms of
the parametric function are completely interacted with the treatment dummy variable. Use the identity
^ a^ þ bÞ
^ ¼ V ð^a þ bÞ
^  Cð^a; a^ þ bÞ,
^ and note that Cð^a; a^ þ bÞ
^ ¼ 0 here, because in a completely interacted
Cðb;
^ The
model, only data to the left are used to estimate a^ and only data to the right are used to estimate a^ þ b.
optimal value of l then becomes
l¼

^
s2a þ V ðxk g^ þ bÞ
.
^ þ s2 =nk
s2a þ V ðxk g^ þ bÞ
k

(16)

When the parametric function is ‘‘good’’, s2a will be relatively small compared to the cell-level sampling error
s2ek =nk : l will thus tend to 0, and the linear combination estimator will be closer to the original parametric
^ On the other hand, if the parametric form is ‘‘bad’’, s2 will be relatively large. As a result, l will
estimator b.
a
tend towards 1, and the combination estimator will converge towards Y k  a^ , which is the difference between
the cell mean and the prediction of E½Y 0 jX ¼ xk  using data on the left side of the discontinuity threshold. The
combination estimator thus provides a simple way to optimally combine two alternative estimators of
E½Y 1  Y 0 jX ¼ 0—b^ and Y k  a^ . Note that the usual OLS estimator that includes the kth cell can also be
written in the same form as (14), using the recursive residual formula of Brown et al. (1975). The implied
weight by the OLS will in general not be equal to the weight given by (14).14
Whether or not the model is fully interacted, the optimal l can be substituted into the expression above to
yield the variance of this combination estimator:


s2ek

2
2
2
^
^
V ðb Þ ¼ ðV ðbÞ þ 2sa Þ  l sa þ V ð^a þ bÞ þ
.
(17)
nk
Note that the ﬁrst set of parentheses is the error variance as discussed in the previous section, while the second
term is non-negative. Thus, the variance of the combination estimator will be weakly smaller than the variance
^
of the estimator b.
To make this estimator feasible, it is necessary to obtain sample analogs to the population variances and
covariances in either (15) or (16). s2a can be estimated by s^ 2a as deﬁned in the previous section. The estimator
^ is simply the ‘‘standard error of the prediction’’ at X ¼ 0, which is a standard option in most
for V ð^a þ bÞ
^ a^ þ bÞ
^ ¼ V ðbÞ
^ þ Cð^a; bÞ
^ can be estimated using the estimated variance of b^ and
statistical packages. Cðb;
^
covariance between b and (as long as the threshold is normalized to be zero) the estimated intercept a^ ; these
quantities are usually computed in most statistical packages. Finally, the usual variance estimator of Y k can be
^ which can be used to
used as the sample analog to s2ek =nk . Together, these quantities imply an estimator l,


construct b^ , a feasible version of b .
14

Using the recursive residual formula, the OLS coefﬁcient using all observations can be written as

y^ ¼ y^ k þ ðW 0 W Þ1 W 0k ðY k  y^ k Þ,
where k denotes leaving out the kth cell, and W k denotes the kth row of W.

ARTICLE IN PRESS
666

D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

In the Appendix, we provide conditions under which
b^  E½Y 1  Y 0 jX ¼ xk  d
qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
! Nð0; 1Þ,
d
Vðb^ Þ
d
where Vðb^ Þ is deﬁned by (17), with population quantities replaced by their sample analogs.
The usual asymptotic arguments lead to the same complications described in the previous section.
Therefore, we continue to adopt the ‘‘shrinking variance’’ sequence in computing the asymptotic distribution,
and providing a consistent variance estimator. In addition, as shown in the Appendix, in order to consistently
^ it is necessary to assume that the number
estimate s2k , while maintaining that s2k =nk has the same order as b,
of observations and the variance of  in the kth cell both grow as the number of cells increase. Without
^ nor the V ðb^ Þ.
increasing the number of observations in the kth cell, one can neither consistently estimate l;
2
Without further requiring that sk grows with the number of observations in the cell, the term s2k =nk will
vanish in the expressions for l and V ðb Þ.
6. Relation to Bayesian estimation
There is a close connection to the proposed estimator b^ and a Bayesian approach to the problem.
Speciﬁcally, the conﬁdence intervals proposed above can be interpreted as Bayesian posterior intervals.
For example, note that (14) can be re-written as
^  a^ .
b ¼ ½lY k þ ð1  lÞð^a þ bÞ
The expression in brackets can be viewed as an estimate of E½Y 1 jX ¼ 0—a l-weighted average of the kth cell
mean and the predicted value from the regression—and the term a^ as an estimate of E½Y 0 jX ¼ 0.
Consider a simple Bayesian approach to estimating E½Y 1 jX ¼ xk   E½Y 0 jX ¼ xk . A likelihood for the
observed data would be speciﬁed; for example, Y ik NðE½Y 1 jX ¼ 0; s2 Þ; assume here that s2 is known. Now
consider a prior distribution for ðE½Y 1 jX ¼ xk ; E½Y 0 jX ¼ xk Þ given by
!!
s21 0
N ðE 1 ; E 0 Þ
.
0 s20
In this simple setup, given the observed data, the posterior distribution for the quantity E½Y 1 jX ¼ xk  would
be given by
NðlY k þ ð1  lÞE 1 ; ð1  lÞs21 Þ
with l ¼ s21 =ðs2 =nk þ s21 Þ. Since at X ¼ 0, there are no data for the outcome in the untreated regime, the
posterior for E½Y 0 jX ¼ xk  is the same the prior, NðE 0 ; s20 Þ. With some re-arrangement, the resulting posterior
distribution for E½Y 1  Y 0 jX ¼ 0 is

 2

s
N ½lY k þ ð1  lÞE 1   E 0 ; s21 þ s20  l2
þ s21
.
nk
Note that under an uninformative (diffuse) prior on E½Y 0 jX ¼ 0, the posterior for the treatment effect will
also be uninformative. In the case where only data on the kth cell are provided, this is intuitive: without any
outside information, one should not be able to provide an informative estimate of the treatment effect.
What are reasonable choices for the components of the prior distribution E 1 , E 0 , s21 , and s20 ? One possibility
is to use the data away from the discontinuity threshold to generate values for these parameters. For example,
^ the predicted value of E½Y 1 jX ¼ 0 using all data to the right of the kth cell in a parametric regression
a^ þ b,
d^
þ s^ 2 , is a reasonable
could be viewed as a reasonable value for E 1 . The variance of that prediction, Vð^a þ bÞ
a

d
value for s21 . Similarly, a regression using all data to the left of the kth cell could generate a^ and Vð^
aÞ þ s^ 2a ,
which could be used as values for E 0 and s20 , yielding the prior distribution for E½Y 0 jX ¼ xk . Using these

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

667

values—and substituting s^ 2 for s2 —yields a posterior distribution for E½Y 1  Y 0 jX ¼ 0 given by
d
Nðb^ ; Vðb^ ÞÞ.15 It is important to note that a hierarchical Bayesian approach could be used for this problem.
Rather than choosing values E 1 , E 0 , s21 , and s20 , a prior distribution could be speciﬁed for the hyperparameters
of the model a0 , b0 , g0 , s2a , and s2j .
7. Summary
This paper draws attention to functional form issues in the estimation of RD designs when the index variable
determining treatment, X, has discrete support. In the discrete case, the conditions for non-parametric or semiparametric methods are not satisﬁed; indeed, the treatment effect is not non-parametrically identiﬁed. Our goal is
to formally incorporate uncertainty in the necessary parametric modeling of the underlying RD function.
We have proposed a procedure for inference that explicitly acknowledges errors in whatever parametric
functional form is chosen. Instead of assuming that the chosen functional form ‘‘correctly’’ describes the
underlying regression function, we model the deviations of the true conditional means from the parametric
function as random speciﬁcation errors with an unknown variance. Viewing these deviations as random errors
requires—at a minimum—the use of cluster-consistent standard errors (clustered on the distinct values of X),
rather than conventional heteroskedasticity-consistent standard errors. An even more ﬂexible model of the RD
counterfactual functions requires further adjustment; the resulting conﬁdence intervals can also be viewed as
Bayesian posterior intervals, when the prior distribution is based on data away from the discontinuity threshold.
The inference procedure proposed in this paper can be summarized as follows:
1. Normalize the X variable so the threshold is at 0, so the intercept in the regression can be interpreted as the
estimate of E½Y 0 jX ¼ 0. Choose the parametric form for the approximation. Run the regression on the
micro-data, computing both heteroskedasticity- and cluster-consistent (clustering on the individual values
of X) standard errors.
2. Consider whether or not the counterfactual functions can be modeled so that speciﬁcation errors in
E½Y 1 jX ¼ xk  and E½Y 0 jX ¼ xk  are the same. If so, then the clustered standard errors can be used for
inference.
3. If not, collapse the data to the cell level, retaining information on the means, variances, and number of
observations in each cell. Run the (cell size-weighted) regression using the cell-data.16 Use mean squared
error from the regression and cell variances to compute s^ 2a as in (12). Adjust the sampling variance by 2s^ 2a
according to (13).
4. If a more efﬁcient estimator is desired, use the estimated variances and covariances of the discontinuity coefﬁcients
d
^ and use this estimator for computing b^ and Vð
and intercept, as well as the kth cell variance, compute l,
b^ Þ.
Althouh our proposed procedure allows for speciﬁcation error, there remains the issue of how to choose the
functional form for the systematic part of the functional form (e.g., the order of the polynomial in X).
Nevertheless, we believe our approach is better than simply assuming the parametric form is correct.
Moreover, our proposed procedures can be easily implemented using the variances and covariances provided
by regression routines in standard statistical packages.
Acknowledgments
We are grateful to Guido Imbens and Thomas Lemieux for helpful suggestions, and to Michael Jansson,
James Powell, Keisuke Hirano, Bill Evans, and participants in the 2003 Banff International Research Station
Regression Discontinuity Conference for helpful discussions and suggestions.
15
Here we are referring to the combination estimator for the model that completely interacts the treatment indicator with the
polynomial. This notion of improving upon the estimate for the kth cell, by using information from other cells, is what underlies the
^ a þ bÞ
^ of E½Y 1 jX ¼ xk  is a type of ‘‘shrinkage’’/Stein
^ k þ ð1  lÞð^
parametric Empirical Bayes approach. Indeed, the estimator ½lY
estimator (see Morris, 1983). Thus, the conﬁdence intervals provided here could also be viewed as Empirical Bayes conﬁdence intervals.
16
At this point, it is useful to verify that the point estimate is identical to that computed in step 1, and that the heteroskedasticityconsistent standard error is identical to the cluster-consistent standard error in step 1 (except for a possible ﬁnite-sample correction factor).

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

668

Appendix A. Proofs
A.1. Notation
Consider the regression in matrix form
y ¼ Db þ X g þ e,
where y (J  1) is a vector of cell means for the outcome, the two columns of D (J  2) are the intercept and
treatment indicator variable, the columns of X (J  K) are the K polynomial terms in the treatmentdetermining covariate, and each element of e (J  1) is the composite error term aj þ j . b and g are the
corresponding coefﬁcient vectors. The proofs below are for an unweighted least squares estimate, but they also
hold for weighted (by the number of observations per cell) least squares estimates, by ﬁrst pre-multiplying the
regression equation by the square root of an appropriate weighting matrix. Let yj ; Dj , X j , ej be the jth row of
the corresponding matrices (vectors).
A.2. Assumptions
The main assumption is that X has a shrinking variance—after partialling out the intercept and the
pﬃﬃﬃ
treatment dummy—as the number of cells increases. That is, we assume that X  E½X  jD þ ð1= J Þ
ðX   E½X  jDÞ, where X  is a J  K random matrix. For the proofs below, note that this deﬁnition is
pﬃﬃﬃ
equivalent to X  DE½D0j Dj 1 E½D0j X j  þ ð1= J Þ ðX   DE½D0j Dj 1 E½D0j X j Þ, where X j is the jth row of X  .
By adopting this sequence, the estimated discontinuity—which amounts to the difference between two linear
forecasts at the discontinuity threshold—will not become more precise as J increases. Instead the discontinuity
estimator will converge to a normal distribution with ﬁnite variance.
Further assume that E½ðX j  Dj E½D0j Dj 1 E½D0j X j Þ0 ðX j  Dj E½D0j Dj 1 E½D0j X j Þ ¼ C, a positive deﬁnite
 2
matrix, and that E½D0j Dj e2j , E½D0j X j e2j , and E½X 0
j X j ej  are ﬁnite matrices.
A.3. Asymptotic distribution of b^ as J ! 1
It can be shown that the least squares estimator for b can be written as
b^ ¼ ðD0 DÞ1 D0 y  ðD0 DÞ1 D0 X ðX 0 MX Þ1 X 0 My,
where M  I  DðD0 DÞ1 D0 . It follows that
b^  b ¼ ðD0 DÞ1 D0 e  ðD0 DÞ1 D0 X  ðX 0 MX Þ1 X 0 Me.
0

1

0

The ﬁrst term is op ð1Þ. ðD DÞ D X
X 0 MX ¼

p

! E½D0j Dj 1

E½D0j X j .

(18)
0

p

X MX ! C, because

1 
ðX  DE½D0j Dj 1 E½D0j X j Þ0 ðX   DE½D0j Dj 1 E½D0j X j Þ
J
1
 ððD0 DÞ1 D0 X   E½D0j Dj 1 E½D0j X j Þ0 ðD0 X   D0 DE½D0j Dj 1 E½D0j X j Þ
J
1
1 0 
1 0
1
0
0
0
0 
 ðX 0 D  E½X 0
j Dj E½Dj Dj  D DÞððD DÞ D X  E½Dj Dj  E½Dj X j Þ
J
1
ððD0 DÞ1 D0 X   E½D0j Dj 1 E½D0j X j Þ0 D0 DððD0 DÞ1 D0 X   E½D0j Dj 1 E½D0j X j Þ
J

where the ﬁrst line converges to C, and the second, third, and fourth lines are op ð1Þ.
Finally, we have
1
J
1
¼ pﬃﬃﬃ ðX   DE½D0j Dj 1 E½D0j X j Þ0 e þ op ð1Þ.
J

1
J

X 0 Me ¼ pﬃﬃﬃ ðX   DE½D0j Dj 1 E½D0j X j Þ0 e  ððD0 DÞ1 D0 X   E½D0j Dj 1 E½D0j X j Þ0 pﬃﬃﬃ D0 e

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

669

Thus, we have
d
b^  b ! Nð0; E½D0j Dj 1 E½D0j X j COCE½D0j X j 0 E½D0j Dj 1 Þ

where O  E½ðX j  Dj E½D0j Dj 1 E½D0j X j Þ0 ðX j  Dj E½D0j Dj 1 E½D0j X j Þe2j .
This is the asymptotic distribution of the ﬁrst term Eq. (10). The second term in (10), consisting of the
speciﬁcation errors, is by assumption a difference of the two independent normals with equal variances. The
asymptotic covariance between the two terms in (10) is zero, so Eq. (11) follows, given the proofs in A.4, A.5,
and A.6 below.
g^
A.4. Proof of consistency of VðbÞ
(variance estimator using true b)
The expression in (18) can be used to construct a natural consistent variance estimator assuming a known b.
Using (18), consider
!
J
X
g^
1
0
0
2
VðbÞ  ðD DÞ
Dj Dj ej ðD0 DÞ1
j¼1

þB

J
X

!

ðX j  Dj ðD0 DÞ1 D0 X Þ0 Dj e2j ðD0 DÞ1

j¼1

1

þ ðD0 DÞ

J
X

!
D0j ðX j  Dj ðD0 DÞ D0 X Þe2j B0
1

j¼1

þB

J
X

!
0

1

0

0

0

1

ðX j  Dj ðD DÞ D X Þ ðX j  Dj ðD DÞ D

0

X Þe2j

B0 ,

ð19Þ

j¼1

where B  ðD0 DÞ1 D0 X ðX 0 MX Þ1 . We ﬁrst show that this is a consistent estimator for the variance given
above, and then show that it is numerically identical to the conventional least squares clustered variance
estimator (with known b).
The ﬁrst three terms in (19) will be shown to be op ð1Þ, and the ﬁnal term will converge to the desired
asymptotic variance. The ﬁrst term is op ð1Þ. The second term in (19) can be equivalently written as
!
J
X
0
1
0  0
2
B
ðX j  Dj E½Dj Dj  E½Dj X j Þ Dj ej ðD0 DÞ1
j¼1

þ

BðE½D0j Dj 1 E½D0j X j 

0

1

0

 ðD DÞ D X Þ

0

J
X

!
D0j Dj e2j

ðD0 DÞ1

j¼1

!
J
X
¼B
ðX j  Dj E½D0j Dj 1 E½D0j X j Þ0 Dj e2j ðD0 DÞ1 þ op ð1Þ
j¼1

!
J
1 X
1

0
0  0
2
¼ B pﬃﬃﬃ
ðX j  Dj E½Dj Dj  E½Dj X j Þ Dj ej ðD0 DÞ1 þ op ð1Þ
J j¼1
¼ op ð1Þ þ op ð1Þ,
p

where the ﬁrst equality follows because ðD0 DÞ1 D0 X is consistent for E½D0j Dj 1 E½D0j X j  and X 0 MX ! C,
which implies that B is Op ð1Þ, the second equality follows by the deﬁnition of X j , and the third equality follows
because ðD0 DÞ1 is Op ð1=JÞ. The third term in (19) is similarly op ð1Þ.

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

670

The fourth term in (19) can be re-written as
!
J
X
1
1
0
0  0
0
0 
2
B
ðX j  Dj E½Dj Dj  E½Dj X j Þ ðX j  Dj E½Dj Dj  E½Dj X j Þej B0
j¼1

þ

BðE½D0j Dj 1 E½D0j X j 

1

0

0

 ðD DÞ D X Þ

0

J
X

!
D0j Dj e2j

j¼1

ðE½D0j Dj 1 E½D0j X j 


J
X

1

 ðD DÞ D X ÞB þ BðE½D0j Dj 1 E½D0j X j   ðD0 DÞ1 D0 X Þ0
!
0

0

0

D0j ðX j  Dj E½D0j Dj 1 E½D0j X j Þe2j B0

j¼1

þB

J
X

!
ðX j 

Dj E½D0j Dj 1 E½D0j X j Þ0 Dj e2j

j¼1

ðE½D0j Dj 1 E½D0j X j   ðD0 DÞ1 D0 X ÞB0
which is equal to
!
J
1X
1
1

0
0  0

0
0 
2
B
ðX  Dj E½Dj Dj  E½Dj X j Þ ðX j  Dj E½Dj Dj  E½Dj X j Þej B0
J j¼1 j
 
 
1
1
þ Op ð1Þ  Op
 Op ðJÞ  Op
 Op ð1Þ
J
J
 
pﬃﬃﬃ
1
þ Op ð1Þ  Op
 Op ð J Þ  Op ð1Þ
J
 
pﬃﬃﬃ
1
þ Op ð1Þ  Op ð J Þ  Op
 Op ð1Þ
J
pﬃﬃﬃ
P
because E½D0j Dj 1 E½D0j X j   ðD0 DÞ1 D0 X is Op ð1=JÞ, and ð Jj¼1 D0j ðX j  Dj E½D0j Dj 1 E½D0j X j Þe2j Þ is Op ð J Þ,
which can be seen by noting that X is, by deﬁnition, shrinking towards the predicted means. The ﬁrst line also
follows by the deﬁnition of X. Thus the fourth term in (19) converges in probability to E½D0j Dj 1
E½D0j X j COCE½D0j X j 0 E ½D0j Dj 1 .
Next, (19) can be shown to be numerically identical to the conventional least squares clustered variance
estimator (with b known), after some re-arrangement of terms. Speciﬁcally, after expanding the middle two
terms, (19) becomes
0

ðD DÞ

1

J
X

!
D0j Dj e2j

0

ðD DÞ

j¼1

 ðD0 DÞ1

J
X
j¼1

þB

J
X

1

0

 BX DðD DÞ

þB

j¼1

1

J
X

!
D0j Dj e2j

ðD0 DÞ1

j¼1

!
D0j Dj e2j ðD0 DÞ1 D0 XB0
!

X 0j Dj e2j ðD0 DÞ

1

þ ðD0 DÞ

j¼1
J
X

0

1

J
X

!
D0j X j e2j B0

j¼1
0

1

0

0

!
0

1

ðX j  Dj ðD DÞ D X Þ ðX j  Dj ðD DÞ D

0

X Þe2j

B0 .

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

671

PJ
PJ
PJ
0
0
0
2
2
2
After
the last term and collecting terms with
j¼1 Dj Dj ej ,
j¼1 X j Dj ej ,
j¼1 Dj X j ej , and
PJ expanding
0
2
j¼1 X j X j ej , we obtain
!
!
!
!
J
J
J
J
X
X
X
X
0
2
0
2
0
2
0
0
2
A
Dj Dj ej A þ B
X j D j ej A þ A
D j X j ej B þ B
X j X j ej B0 ,
j¼1

j¼1
1

j¼1

0

0

1

0

1

j¼1

where A  ðD DÞ  BX DðD DÞ ¼ ðD DÞ þ ðD DÞ D X ðX MX Þ1 X 0 DðD0 DÞ1 , and B  ðD0 DÞ1
D0 X ðX 0 MX Þ1 . This is exactly the expression that would be obtained by using the partitioned inverse formula
^
for the conventional least squares clustered variance estimator (with b known) for b.
0

0

1

0

0

d^
g^
A.5. Proof that VðbÞ
 VðbÞ
is op ð1Þ
d^
g^
Let VðbÞ
be the conventional clustered variance estimator (with unknown b); it is deﬁned as VðbÞ
except after
^
replacing ej with e^j  Y j  Dj b  X j g^ . It follows that
e^j ¼ ej  Dj ðb^  bÞ  X j ð^g  gÞ
¼ ej  Dj ðD0 DÞ1 D0 e þ Dj ðD0 DÞ1 D0 X ð^g  gÞ  X j ð^g  gÞ
¼ ej  Dj ðD0 DÞ1 D0 e þ Dj ððD0 DÞ1 D0 X  E½D0j Dj 1 E½D0j X j Þð^g  gÞ
 ðX j  Dj E½D0j Dj 1 E½D0j X j Þð^g  gÞ
 
 
1
1
¼ ej  Dj  Op pﬃﬃﬃ þ Dj  Op
 Op ð1Þ
J
J
1
 pﬃﬃﬃ ðX j  Dj E½D0j Dj 1 E½D0j X j Þ  Op ð1Þ.
J
The second and third equalities follow from re-arranging terms. The ﬁnal equality follows from noting that
ðD0 DÞ1 D0 X  E½D0j Dj 1 E½D0j X j  is Op ðJ1Þ and ð^g  gÞ is Op ð1Þ, as shown in the proof of asymptotic normality.
Squaring the above residual yields
  
 
 
 
1
1
1
1
e^2j  e2j ¼ ej Dj Op
þ Op pﬃﬃﬃ  Op pﬃﬃﬃ
 ej X j Op pﬃﬃﬃ
J
J
J
J
  
 
 0
  
 
 
1
1
1
1
1
1
þ Op
D0j Dj Op
þ Op pﬃﬃﬃ  Op pﬃﬃﬃ
þ Op pﬃﬃﬃ  Op pﬃﬃﬃ
J
J
J
J
J
J
  
 
 0
 
1
1
1
1
 Op
D0j X j Op pﬃﬃﬃ
þ Op pﬃﬃﬃ  Op pﬃﬃﬃ
J
J
J
J
 0
 
1
1

þ Op pﬃﬃﬃ X 0
j X j Op pﬃﬃﬃ .
J
J

ð20Þ

d^
g^
Note that each of the above terms is a summation of scalars. To see that VðbÞ
 VðbÞ
is op ð1Þ, substitute each
of these scalars for ‘‘e2j ’’ in (19). The ﬁrst three terms will be op ð1Þ as argued in the proof for the consistency of
g^
VðbÞ.
In addition, the fourth term will also be op ð1Þ because each of these scalars is a product that includes a
Op ðÞ term in (20).
p

A.6. Proof that s^ 2a ! s2a
P
P
P
First, note the deﬁnition s^ 2a  ð1=JÞ j e^2j  ð1=JnÞ j ð1=ðn  1ÞÞ i ðY ij  yj Þ2 . Next, summing over (20), it
P
P
p
follows that ð1=JÞ j e^2j !ð1=JÞ j e2j , which converges to s2a þ s2 =n. Finally, the second term is a consistent
estimator for s2 =n, as J ! 1.

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

672

A.7. Proof of asymptotic distribution of shrinkage estimator
In addition to the assumptions above, normalize so that xk , the point of the threshold, is zero, and let
b ¼ ða; bÞ, so that a is the intercept and b is the discontinuity gap. Also assume that nk ¼ Jnk , nk a ﬁnite
pﬃﬃﬃﬃﬃ
2
constant, and eik ¼ nk eik , so that s2ek ¼ nk s2
ek , sek a ﬁnite constant.
We will show that
b^  E½Y 1  Y 0 j X ¼ 0 d
qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
! Nð0; 1Þ
d

^
Vðb Þ
d
d
by ﬁrst showing that b^  E½Y 1  Y 0 jX ¼ 0 ! Nð0; V ðb ÞÞ, and then showing that Vðb^ Þ is consistent for

V ðb Þ.
pﬃﬃﬃ
pﬃﬃﬃ
^ k  ð^a þ bÞÞÞ.
^
Deﬁne
First, re-write ð1= J Þðb^  E½Y 1  Y 0 jX ¼ 0Þ as ð1= J Þðb^  E½Y 1  Y 0 jX ¼ 0þ lðY
pﬃﬃﬃ
pﬃﬃﬃ
p
ﬃﬃﬃ
0

^
^
^
^
cJ as the vector ðð1= J Þðb  E½Y 1  Y 0 jX ¼ 0Þ; ð1= J ÞðY k  ð^a þ bÞÞ; lÞ , so that ð1= J Þðb  E½Y 1  Y 0 j
X ¼ 0Þ ¼ f ðcJ Þ, noting that f ðÞ is a continuous function.
pﬃﬃﬃ
We need to show cJ has probability limit c ¼ ð0; 0; lÞ, and that J ðcJ  cÞ converges in distribution to
p
ﬃﬃﬃ
Nð0; V  Þ. If true, then J ðf ðcJ Þ  f ðcÞÞ will converge in distribution to Nð0; ð1; l; 0Þ0 V   ð1; l; 0ÞÞ, by the delta
method. The zero in the last element of the gradient vector implies that the resulting asymptotic variance does
^ or its covariance with any other element of bJ . As a result, it will be true that
not include the variance of l,
d
b^  E½Y 1  Y 0 jX ¼ 0 ! Nð0; V ðb ÞÞ.
pﬃﬃﬃ
p
To show cJ ! c  ð0; 0; lÞ, recall from above that b^  E½Y 1  Y 0 jX ¼ 0 is Op ð1Þ; multiplying by 1= J
^ ¼ ð^a  aÞ þ ðb  bÞ
^ þ ak þ ek is also Op ð1Þ, because ð1=nk ÞPnk eik ¼
yields op ð1Þ. Similarly, Y k  ð^a þ bÞ
i¼1
pﬃﬃﬃ
pﬃﬃﬃ  Pnk 
ð1= J nk Þ i¼1 eik ; multiplying by 1= J yields op ð1Þ. l^ is consistent for l, because the sample analogs to each
^ a^ þ bÞ
^ and V ðbÞ
^ are
of its parts are consistent. For example, as shown above, the standard estimators for Cðb;
2
consistent, as is s^ a . Also,
nk
nk
nk
nk
1X
1X
2X
1X
2
2
ðY

Y
Þ
¼

þ

ðE½Y


Y
Þ
þ
ðE½Y ik   Y k Þ2
ik
k
ik
ik
k
n2k i¼1
n2k i¼1 ik n2k i¼1
n2k i¼1
pﬃﬃﬃﬃﬃ
nk
nk
X
nk
1X
1
¼
e2
þ
ðE½Y


Y
Þ
eik þ ðE½Y ik   Y k Þ2
ik
k
nk i¼1 ik
n
n2k
k
i¼1
p
ﬃﬃﬃ




n
k
J
1X
1
¼
e2 þ O
Op ð1Þ,
Op ð1Þop ðJÞ þ O
nk i¼1 ik
J
J2

where the ﬁrst and second equalities hold after some re-arrangement, and the third equality holds because
E½Y ik   Y kpisﬃﬃﬃOp ð1Þ:
d
To show J ðcJ  cÞ ! Nð0; V  Þ, we decompose the vector as
1
1 0 1 0
ak1  ak0
0
b^  b
pﬃﬃﬃ
B C B
C
B
^ C
J ðcJ  cÞ ¼ @ ða  a^ Þ þ ðb  bÞ
A þ @ ek A þ @ ak1 A.
pﬃﬃﬃ
0
0
J ðl^  lÞ
0

pﬃﬃﬃﬃﬃ P k 
Pk
The element in the second vector is ð1=nk Þ ni¼1
eik ¼ ð1= nk Þ ni¼1
eik , which converges to a normal. The third
vector is normal, by assumption. The ﬁrst two elements converge to a normal as in the proof of the asymptotic
pﬃﬃﬃ
^ as shown above. Finally, J ðl^  lÞ can also be expressed as a summation in the form
normality of b,

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

673

pﬃﬃﬃ P
of ð1= J Þ Jj¼1 zj .
0
pﬃﬃﬃ
J@

1
^d
^
^ a^ þ bÞ
^
a^ þ bÞ
s2a þ Cðb;
s^ 2a þ Cðb;
A

2 þ V ð^
^ þ s2 =nk
d^
2
2
s
a
þ
bÞ
a
ek
s^ a þ Vð^a þ bÞ þ s^ ek =nk

converges in probability to
0
1
^d
^  Cðb;
^ a^ þ bÞ
^
pﬃﬃﬃ s^ 2a  s2a þ Cðb;
^
a
þ
bÞ
A.
J@
^ þ s2 =n
s2a þ V ð^a þ bÞ
k
k
pﬃﬃﬃ P
The numerator can be shown to be a summation in the form of ð1= J Þ Jj¼1 zj þ op ð1Þ. The central limit
theorem applies.
We have shown that each of the parts that make up l^ is consistent. Those same terms are used to construct
d
Vðb^ Þ , which is therefore consistent for V ðb Þ.
Appendix B. Extension to ‘‘fuzzy’’ RD designs
Many interesting applications of the RD research design involve ‘‘imperfect compliance’’: the relation
between the treatment of interest is not a deterministic function of X. Instead the conditional expectation of
the treatment is a discontinuous function of X. Angrist and Lavy (1998), for example, use discontinuities in the
mapping from the number of students in a grade to average class size to identify the effect of class size on test
scores. The rule, while not perfectly followed, nevertheless generates a discontinuity in the expected class size.
A very simple version of this setup consists of two equations:
Y 1ij ¼ Dj d0 þ X j g1 þ uij ,
Y 2ij ¼ Y 1ij b0 þ X j g2 þ vij ,
where ðY 1ij ; Y 2ij Þ is a pair of observed outcomes for the ith individual in the jth cell, X j and Dj are as
previously deﬁned, d0 is the discontinuity in Y 1 at X ¼ 0, b0 is the causal effect of Y 1 on Y 2 , and ðuij ; vij Þ is a
pair of potentially correlated errors. Correlation between uij and vij implies that b0 cannot be estimated
consistently by a simple OLS procedure. b0 can be estimated, however, by instrumental variables method
using Dj as an instrument for Y 1ij . The maintained assumptions are that program status Dj has no direct effect
on Y 2 , controlling for Y 1 . Note that the resulting IV estimator is equivalent to estimating two regression
discontinuities—for the two outcomes Y 1 and Y 2 —and computing the ratio of the discontinuity gaps.
A natural extension of our framework is to assume that the data generating process for the observed
outcomes is
Y 1ij ¼ Dj d0 þ X j g1 þ a1j þ uij ,
Y 2ij ¼ Y 1ij b0 þ X j g2 þ a2j þ vij ,
where ða1j ; a2j Þ represents an i.i.d. vector of mean zero random speciﬁcation errors. IV will still yield an
asymptotically unbiased estimate of b0 , but the conventional IV sampling errors, as in the ‘‘sharp’’ design,
ignore the group structure of the residuals and may overstate the precision of the IV estimator (See ShoreSheppard, 1996 for a discussion of grouped error structures in an IV setting similar to Moulton, 1990). The use
of clustered standard errors is again a simple remedy in this situation.
Note that the above speciﬁcation implicitly assumes the structure of ‘‘identical’’ speciﬁcation errors in the
counterfactual functions, as described in Section 4.1. If it is more desirable to assume ‘‘independent’’ errors, as
in Section 4.2, then it is necessary to account for the variance in the forecast errors a1j and a2j . One way to
proceed would be to apply the procedure in Section 4.2, separately for both ‘‘outcomes’’ Y 1 and Y 2 . This

ARTICLE IN PRESS
D.S. Lee, D. Card / Journal of Econometrics 142 (2008) 655–674

674

would give us, for example, least squares estimate b^ and p^ for the parameters E½Y 11  Y 01 jX ¼ 0 and E½Y 12 
Y 02 jX ¼ 0 (where the superscripts denote potential outcomes). The error in these estimators include both
estimation error and the forecast error, as in Section 4.2. It is possible to analogously compute the covariance
in the estimation error in b^ and p^ as well as the covariance between the speciﬁcation errors for each outcome.
Following an analogous argument as in Section 4.2, it would then follow that
1

^
ðb^  E½Y 11  Y 01 jX ¼ 0; p^  E½Y 12  Y 02 jX ¼ 0Þ0 S
ðb^  E½Y 1  Y 0 jX ¼ 0; p^  E½Y 1  Y 0 jX ¼ 0Þ
1

1

2

2

(where S^ is the corresponding consistent estimator of the variance–covariance matrix for the error vector)
converges in distribution to w2 ð2Þ. One can invert this test statistic to generate, for example, a 95% joint
conﬁdence set for E½Y 11  Y 01 jX ¼ 0 and E½Y 12  Y 02 jX ¼ 0, and from this generate the conﬁdence set for the
ratio E½Y 12  Y 02 jX ¼ 0=E½Y 11  Y 01 jX ¼ 0.
References
Angrist, J., Krueger, A., 1999. Empirical strategies in labor economics. In: Ashenfelter, O., Card, D. (Eds.), Handbook of Labor
Economics, vol. 3A. North-Holland, Amsterdam, pp. 1278–1284.
Angrist, J., Lavy, V., 1998. Using Maimonides’ rule to estimate the effect of class size on scholastic achievement. Quarterly Journal
of Economics 114, 533–575.
Brown, R.L., Durbin, J., Evans, J.M., 1975. Techniques for testing for the constancy of regression relationships over time (with
discussion). Journal of the Royal Statistical Society B 37, 149–192.
Card, D., Shore-Sheppard, L., 2004. Using discontinuous eligibility rules to identify the effects of the federal medicaid expansions on low
income children. Review of Economics and Statistics 86, 752–766.
Chamberlain, G., 1994. Quantile regression, censoring, and the structure of wages. In: Sims, C.A. (Ed.), Advances in Econometrics, Sixth
World Congress, vol. 1. Cambridge University Press, Cambridge.
DiNardo, J., Lee, D.S., 2004. Economic impacts of new unionization on private sector employers: 1984–2001. Quarterly Journal of
Economics 119, 1383–1442.
Hahn, J., van der Klaauw, W., Todd, P., 2001. Identiﬁcation and estimation of treatment effects with a regression–discontinuity design.
Econometrica 69 (1), 201–209.
Kane, T.J., 2003. A quasi-experimental estimate of the impact of ﬁnancial aid on college-going. Working Paper, National Bureau of
Economic Research.
Lee, D.S., 2006. Randomized experiments from non-random selection in U.S. house elections. Journal of Econometrics, forthcoming.
Morris, C.N., 1983. Parametric empirical bayes inference: theory and applications. Journal of the American Statistical Association 78,
47–55.
Moulton, B., 1990. An illustration of a pitfall in estimating the effects of aggregate variables on micro units. Review of Economics and
Statistics 57, 334–338.
Porter, J., 2003. Estimation in the regression discontinuity model. Working Paper, Harvard University, Cambridge, MA.
Shore-Sheppard, L., 1996. The precision of instrumental variables estimates with grouped data. Working Paper 374, Industrial Relations
Section, Princeton University, Princeton.
Thistlethwaite, D., Campbell, D., 1960. Regression-discontinuity analysis: an alternative to the ex post facto experiment. Journal of
Educational Psychology 51, 309–317.
White, H., 1980. Using least squares to approximate unknown regression functions. International Economic Review 21, 149–170.

