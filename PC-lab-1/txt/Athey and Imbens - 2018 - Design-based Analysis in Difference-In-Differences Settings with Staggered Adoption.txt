arXiv:1808.05293v3 [econ.EM] 1 Sep 2018

Design-based Analysis in
Difference-In-Differences Settings with
Staggered Adoption∗
Susan Athey†

Guido W. Imbens‡

Current version September 2018

Abstract
In this paper we study estimation of and inference for average treatment effects in a
setting with panel data. We focus on the setting where units, e.g., individuals, firms, or
states, adopt the policy or treatment of interest at a particular point in time, and then
remain exposed to this treatment at all times afterwards. We take a design perspective
where we investigate the properties of estimators and procedures given assumptions on
the assignment process. We show that under random assignment of the adoption date
the standard Difference-In-Differences estimator is is an unbiased estimator of a particular
weighted average causal effect. We characterize the properties of this estimand, and show
that the standard variance estimator is conservative.

Keywords: Staggered Adoption Design, Difference-In-Differences, Fixed Effects, Randomization Distribution

∗

We are grateful for comments by participations in the conference in honor of Gary Chamberlain
at Harvard in May 2018, and in particular by Gary Chamberlain. Gary’s insights over the years
have greatly affected our thinking on these problems. We also wish to thank Sylvia Kloskin and
Michael Pollmann for superb research assistance. This research was generously supported by ONR
grant N00014-17-1-2131.
†
Professor of Economics, Graduate School of Business, Stanford University, and NBER,
athey@stanford.edu.
‡
Professor of Economics, Graduate School of Business, Stanford University, SIEPR, and NBER,
imbens@stanford.edu.

1

Introduction

In this paper we study estimation of and inference for average treatment effects in a setting with
panel data. We focus on the setting where units, e.g., individuals, firms, or states, adopt the policy or treatment of interest at a particular point in time, and then remain exposed to this treatment at all times afterwards. The adoption date at which units are first exposed to the policy
may, but need not, vary by unit. We refer to this as a staggered adoption design (SAD), such designs are sometimes also referred to as event study designs. An early example is Athey and Stern
[1998] where adoption of an enhanced 911 technology by counties occurs over time, with the
adoption date varying by county. This setting is a special case of the general Difference-InDifferences (DID) set up (e.g., Card [1990], Meyer et al. [1995], Angrist and Pischke [2008],
Angrist and Krueger [2000], Abadie et al. [2010], Borusyak and Jaravel [2016], Athey and Imbens
[2006], Card and Krueger [1994], Freyaldenhoven et al. [2018], de Chaisemartin and D’Haultfœuille
[2018], Abadie [2005]) where, at least in principle, units can switch back and forth between being exposed or not to the treatment. In this SAD setting we are concerned with identification
issues as well as estimation and inference. In contrast to most of the DID literature, e.g.,
Bertrand et al. [2004], Shah et al. [1977], Conley and Taber [2011], Donald and Lang [2007],
Stock and Watson [2008], Arellano [1987, 2003], Abraham and Sun [2018], Wooldridge [2010],
de Chaisemartin and D’Haultfœuille [2017, 2018], we take a design-based perspective where the
stochastic nature and properties of the estimators arises from the stochastic nature of the assignment of the treatments, rather than a sampling-based perspective where the uncertainty arises
from the random sampling of units from a large population. Such a design perspective is common
in the analysis of randomized experiments, e.g., Neyman [1923/1990], Rosenbaum [2002, 2017].
See also Aronow and Samii [2016], Abadie et al. [2016, 2017] for this approach in cross-section
regression settings. This perspective is particularly attractive in the current setting when the
sample comprises the entire population, e.g., all states of the US, or all countries of the world.
Our critical assumptions involve restrictions on the assignment process as well as exclusion
restrictions, but in general do not involve functional form assumptions. Commonly made common trend assumptions (de Chaisemartin and D’Haultfœuille [2018], Abraham and Sun [2018])
follow from some of our assumptions, but are not the starting point.
As in Abraham and Sun [2018] we set up the problem with the adoption date, rather than the
actual exposure to the intervention, as the basic treatment defining the potential outcomes. We
1

consider assumptions under which this discrete multivalued treatment (the adoption date) can
be reduced to a binary one, defined as the indicator whether or not the treatment has already
been adopted. We then investigate the interpretation of the standard DID estimator under
assumptions about the assignment of the adoption date and under various exclusion restrictions.
We show that under a random adoption date assumption, the standard DID estimator can be
interpreted as the weighted average of several types of causal effects; within our framework,
these concern the impact of different types of changes in the adoption date of the units. We
also consider design-based inference for this estimand. We derive the exact variance of the
DID estimator in this setting. We show that under a random adoption date assumption the
standard Liang-Zeger (LZ) variance estimator (Liang and Zeger [1986], Bertrand et al. [2004]),
or the clustered bootstrap, are conservative. For this case we propose an improved (but still
conservative) variance estimator.
Our paper is most closely relateds to a very interesting set of recent papers on DID methods that explicitly focus on issues with heterogenous treatment effects (Abraham and Sun [2018],
de Chaisemartin and D’Haultfœuille [2018], Han [2018], Goodman-Bacon [2017], Callaway and Sant’Anna
[2018], Hull [2018], Strezhnev [2018], Imai et al. [2018], Hazlett and Xu [2018], and Borusyak and Jaravel
[2016]). Among other things these papers derive interpretations of the DID estimator as weighted
averages of causal effects and bias terms under various assumptions. In many cases they find that
these interpretations involve weighted averages of basic average causal effects with potentially
negative weights and propose alternative estimators that do not involve negative weights.

2

Set Up

Using the potential outcome framework for causal inference, we consider a setting with a
population of N units. Each of these N units are characterized by a set of potential outcomes in T periods for T + 1 treatment levels, Yit (a). Here i ∈ {1, . . . , N} indexes the units,
t ∈ T = {1, . . . , T } indexes the time periods, and the argument of the potential outcome function Yit (·), a ∈ A = T ∪ {∞} = {1, . . . , T, ∞} indexes the discrete treatment, the date that the
binary policy was first adopted by a unit. Units can adopt the policy at any of the time periods
1, . . . , T , or not adopt the policy at all during the period of observation, in which case we code
the adoption date as ∞. Once a unit adopts the treatment, it remains exposed to the treatment

2

for all periods afterwards. This set up is like that in Abraham and Sun [2018], Hazlett and Xu
[2018], and in contrast to most of the DID literature where the binary indicator whether a unit is
exposed to the treatment in the current period indexes the potential outcomes. We observe for
each unit in the population the adoption date Ai ∈ A and the sequence of T realized outcomes,
Yit , for t ∈ T, where
Yit ≡ Yit (Ai ),
is the realized outcome for unit i at time t. We may also observe pre-treatment characteristics,
denoted by the K-component vector Xi , although for most of the discussion we abstract from
their presence. Let Y , A, and X denote the N × T , N × 1, and N × K matrices with typical
elements Yit , Ai , and Xik respectively. Implicitly we have already made a sutva-type assumption
(Rubin [1978], Imbens and Rubin [2015]) that units are not affected by the treatments (adoption dates) for other units. Our design-based analysis views the potential outcomes Yit (a) as
deterministic, and only the adoption dates Ai , as well as functions thereof such as the realized
outcomes as stochastic. Distributions of estimators will be fully determined by the adoption date
distribution, with the number of units N and the number of time periods T fixed, unless explicitly
stated otherwise. Following the literature we refer to this as a randomization, or designed-based,
distribution (Rosenbaum [2017], Imbens and Rubin [2015], Abadie et al. [2017]), as opposed to
a sampling-based distribution.
In many cases the units themselves are clusters of units of a lower level of aggregation.
For example, the units may be states, and the outcomes could be averages of outcomes for
individuals in that state, possibly of samples drawn from subpopulations from these states. In
such cases N and T may be as small as 2, although in many of the cases we consider N will
be at least moderately large. This distinction between cases where Yit is itself an average over
basic units or not, affects some, but not all, of the formal statistical analyses. It may make some
of the assumptions more plausible, and it may affect the inference, especially if individual level
outcomes and covariates are available.
Define W (a, t) = 1a≤t to be the binary indicator for the adoption date a preceeding t, and
define Wit to be the indicator for the the policy having been adopted by unit i prior to, or at,

3

time t:
Wit ≡ W (Ai , t) = 1Ai ≤t ,
so that the N × T matrix W with typical element Wit has the form:


WN ×T

Let Na ≡

0 0 0 0 ... 0









=








0 0 0 0 ... 1
0 0 0 0 ... 1
0 0 1 1 ... 1
0
..
.

0
..
.

1
..
.

1 ... 1
.. . . ..
. .
.

0 1 1 1 ... 1

PN

(never adopter)





(late adopter) 








(medium adopter) 




(early adopter)

1Ai =a be the number of units in the sample with adoption date a, and define
P
πa ≡ Na /N, for a ∈ A, as the fraction of units with adoption date equal to a, and Πt ≡ ts=1 πs ,
i=1

for t ∈ T, as the fraction of units with an adoption date on or prior to t.

Also define Y t (a) to be the population average of the potential outcome in period t for
adoption date a:
N
1 X
Yit (a),
Y t (a) ≡
N i=1

for t ∈ T, a ∈ A.

Define the average causal effect of adoption date a′ relative to a, on the outcome in period t, as

τt,aa′

N
o
1 Xn
≡ Y t (a ) − Y t (a) =
Yit (a′ ) − Yit (a) .
N i=1
′

Abraham and Sun [2018] focus on slighlty different building blocks, what they call CAT Ta,t ,
P
which, for 0 ≤ t ≤ T − a, are the super-population equivalent of (1/Na ) i|Ai=a {Yia+t (a) −
Yia+t (∞)}. The average causal effects τt,aa′ are the building blocks of many of the estimands we

4

consider later. A particularly interesting average effect is

τt,∞1

N

1 X
=
Yit (1) − Yit (∞) ,
N i=1

the average effect of switching the entire population from never adopting the policy (a = ∞),
to adopting the policy in the first period (a = 1). Formally there is nothing special about the
particular average effect τt,∞1 relative to any other τt,aa′ , but τt,∞1 will be useful as a benchmark.
Part of the reason is that for all t and i the comparison Yit (1) − Yit (∞) is between potential
outcomes for adoption prior to or at time t (namely adoption date a = 1) and potential outcomes
for adoption later than t (namely, never adopting, a = ∞). In contrast, any other average effect
τt,aa′ will for some t involve comparing potential outcomes neither of which correspond to having
adopted the treatment yet, or comparing potential outcomes both of which correspond to having
adopted the treatment already. Therefore, τt,∞1 reflects more on the effect of having adopted
the policy than any other τt,aa′ .

3

Assumptions

We consider three sets of assumptions. The first set, containing only a single assumption, is
about the design, that is, the assignment of the treatment, here the adoption date, conditional
on the potential outcomes and possibly pretreatment variables. We refer to this as a design
assumption because it can be guaranteed by design. The second set of assumptions is about
the potential outcomes, and rules out the presence of certain treatment effects. These exclusion
restrictions are substantive assumptions, and they cannot be guaranteed by design. The third
set of assumptions consists of four auxiliary assumptions, two about homogeneneity of certain
causal effects, one about sampling from a large population, and one about an outcome model
in a large population. The nature of these three sets of assumptions, and their plausibility, is
very different, and it is in our view useful to carefully distinguish between them. The current
literature often combines various parts of these assumptions implicitly in the notation used and
in assumptions about the statistical models for the realized outcomes.

5

3.1

The Design Assumption

The first assumption is about the assignment process for the adoption date Ai . Our starting
point is to assume that the adoption date is completely random:
Assumption 1. (Random Adoption Date) For some set of positive integers Na , for a ∈ A,
pr(A = a) =



N!
Q
a∈A Na !

−1

,

for all N-vectors a such that for all a ∈ A,

PN

i=1

1ai =a = Na .

This assumption is obviously very strong. However, without additional assumptions that
restrict either the potential outcomes, or expand what we observe, for example by including
pre-treatment variables or covariates, this assumption has no testable implications in a setting
with exchangeable units.
Lemma 1. (No Testable Restrictions) Suppose all units are exchangeable. Then Assumption 1 has no testable implications for the joint distribution of (Y , A).
All proofs are given in the Appendix.
Hence, if we wish to relax the assumptions, we need to bring in additional information. Such
additional information can come in the form of pretreatment variables, that is, variables that
are known not to be affected by the treatment. In that case we can relax the assumption by
requiring only that the adoption date is completely random within subpopulations with the
same values for the pre-treatment variables. Additional information can also come in the form
of limits on the treatment effects. The implications of such restrictions on the ability to relax
the random adoption assumption is more complex, as discussed in more detail in Section 3.2.
Under Assumption 1 the marginal distribution of the adoption dates is fixed, and so also
the fraction πa is fixed in the repated sampling thought experiment. This part of the set up is
similar in spirit to fixing the number of treated units in the sample in a completely randomized
experiment. It is convenient for obtaining finite sample results. Note that it implies that the
adoption dates for units i and j are not independent. Note also that in the standard framework
where the uncertainty arises solely from random sampling, this fraction does not remain constant
in the repeated sampling thought experiment.
6

An important role is played by what we label the adjusted treatment, adjusted for unit and
time period averages:
Ẇit ≡ Wit − W ·t − W i· + W ,
where W ·t , W i· , and W are averages over units, time periods, and both, respectively:
N
N
N
N
X 1 X
X
1 X
1 XX
1 X
Wit =
1Ai ≤t =
1Ai =s =
1Ai =s =
πs ,
W ·t ≡
N i=1
N i=1
N i=1 s≤t
N i=1
s≤t
s≤t
T
T + 1 − Ai
1X
Wit = 1Ai ≤T
,
W i· ≡
T t=1
T

and
T
T
T
1X
1X
1 XX
πs =
(T + 1 − t)πt ,
W ≡
W ·t =
T t=1
T t=1 s≤t
T t=1

where, with some minor abuse of notation, we adopt the convention that a1a≤T is zero if a = ∞.
Note that under Assumption 1, ow·t and W are non-stochastic. Using these representations we
can write the adjusted treatment indicator as
Ẇit = g(t, Ai ),
where
g(t, a) ≡

1a≤t −

X
s≤t

πs

!

+

1
T

a1a≤T −

T
X
s=1

sπs

!

+

T +1
(1a=∞ − π∞ ) .
T

Because the marginal distribution of Ai is fixed under Assumption 1, the sum

(3.1)

P

i,t

Ẇit2 is non-

stochastic under this assumption, even though Ẇit and thus Ẇit2 are stochastic. This fact enables
us to derive exact finite sample results for the standard DID estimator as discussed in Section 4.
This is similar in spirit to the derivation of the exact variance for the estimator for the average
treatment effect in completely randomized experiments when we fix the number of treated and
controls.
7

3.2

Exclusion Restrictions

The next two assumptions concern the potential outcomes. Their formulation does not involve
the assignment mechanism, that is, the distribution of the adoption date. In essence these
are exclusion restrictions, assuming that particular causal effects are absent. Collectively these
two assumptions imply that we can think of the treatment as a binary one, the only relevant
component of the adoption date being whether a unit is exposed to the treatment at the time we
measure the outcome. Versions of such assumptions are also considered in Borusyak and Jaravel
[2016], de Chaisemartin and D’Haultfœuille [2018], Abraham and Sun [2018], Hazlett and Xu
[2018] and Imai and Kim [2016], where in the latter a graphical approach is taken in the spirit
of the work by Pearl [2000].
The first of the two assumptions, and likely the more plausible of the two in practice, rules
out effects of future adoption dates on current outcomes. More precisely, it assumes that if the
policy has not been adopted yet, the exact future date of the adoption has no causal effect on
potential outcomes for the current period.
Assumption 2. (No Anticipation) For all units i, all time periods t, and for all adoption
dates a, such that a > t,
Yit (a) = Yit (∞).
We can also write this assumption as requiring that for all (i, t, a),
Yit (a) = 1a≤t Yit (a) + 1a>t Yit (∞),





or 1a>t Yit (a) − Yit (∞) = 0,

with the last representation showing most clearly how the assumption rules out certain causal
effects. Note that this assumption does not involve the adoption date, and so does not restrict
the distribution of the adoption dates. Violations of this assumption may arise if the policy is
anticipated prior to its implementation.
The next assumption is arguably much stronger. It asserts that for potential outcomes in
period t it does not matter how long the unit has been exposed to the treatment, only whether
the unit is exposed at time t.
Assumption 3. (Invariance to History) For all units i, all time periods t, and for all
8

adoption dates a, such that a ≤ t,
Yit (a) = Yit (1).
This assumption can also be written as
Yit (a) = 1a≤t Yit (1) + 1a>t Yit (a),



or 1a≤t Yit (a) − Yit (1) = 0,

with again the last version of the assumption illustrating the exclusion restriction in this assumption. Again, the assumption does not rule out any correlation between the potential outcomes
and the adoption date, only that there is no causal effect of an early adoption versus a later
adoption on the outcome in period t, as long as adoption occurred before or on period t.
In general, this assumption is very strong. However, there are important cases where it may
be more plausible. Suppose the units are clusters of individuals, where in each period we observe
different sets of individuals. To be specific, suppose the the units are states, the time periods
are years, and outcome is the employment rate for twenty-five year olds, and the treatment is
the presence or absence of some regulation, say a subsidy for college tuition. In that case it may
well be reasonable to assume that the educational choices for students graduating high school
in a particular state depends on what the prevailing subsidy is, but much less on the presence
of subsidies in previous years.
If both the exclusion restrictions, that is, both Assumptions 2 and 3, hold, then the potential
outcome Yit (a) can be indexed by the binary indicator W (a, t) = 1a≤t :
Lemma 2. (Binary Treatment) Suppose Assumptions 2 and 3 hold. Then for all units i,
all time periods t and adoption dates a > a′ , (i)


Yit (a ) − Yit (a) = 1a′ ≤t<a Yit (1) − Yit (∞) ,
′

so that,

Yit (a) = Yit (∞) + 1a≤t




 Y (∞)
it
Yit (1) − Yit (∞) =
 Y (1)


it

9

if a ≤ t
otherwise,

and, for all time periods t, and adoption dates a > a′ , (ii)

τt,aa′ = τt,∞1 1a′ ≤t<a


 τ
t,∞1
=
 0

if a′ ≤ t < a,
otherwise.

If these two assumptions hold, we can therefore simplify the notation for the potential outcomes and focus on Yit (1) and Yit (∞).
Note that these two assumptions are substantive, and cannot be guaranteed by design. This
in contrast to the Assumption 1, which can be guaranteed by randomization of the adoption
date. It is also important to note that in many empirical studies Assumptions 2 and 3 are
made, often implicitly by writing a model for realized outcome Yit that depends solely on the
contemporaneous treatment exposure Wit , and not on the actual adoption date Ai or treatment
exposure Wit′ in other periods t′ . In the current discussion we want to be explicit about the fact
that this restriction is an assumption, and that it does not automatically hold. Note that the
assumption does not restrict the time series dependence between the potential outcomes.
It is trivial to see that without additional information, the exclusion restrictions in Assumptions 2 and 3 have no testable implications because they impose restrictions on pairs of potential
outcomes that cannot be observed together. However, in combination with random assignment,
2 and 3, there are testable implications as long as T ≥ 2 and there is some variation in the
adoption date.
Lemma 3. (Testable Restrictions from the Exclusion Restrictions) (i) Assumptions 2 and 3 jointly have no testable implications for the joint distribution of (Y , W ).
(ii) Suppose T ≥ 2, and π2 , π∞ > 0. Then the combination of Assumptions 1–3 impose testable
restrictions on the joint distribution of (Y , W ).

3.3

Auxiliary Assumptions

In this section we consider four auxiliary assumptions that are convenient for some analyses,
and in particular can have implications for the variance of specific estimators, but that are
not essential in many cases. These assumptions are often made in empirical analyses without
researchers explicitly discussing them.
The first of these assumptions assumes that the effect of adoption date a′ , relative to adoption
10

date a, on the outcome in period t, is the same for all units.
Assumption 4. (Constant Treatment Effect Over Units) For all units i, j and for
all time periods t and all adoption dates a and a′
Yit (a) − Yit (a′ ) = Yjt(a) − Yjt (a′ ).
The second assumption restricts the heterogeneity of the treatment effects over time.
Assumption 5. (Constant Treatment Effect over Time) For all units i and all time
periods t and t′
Yit (1) − Yit (∞) = Yit′ (1) − Yit′ (∞).
We only restrict the time variation for comparisons of the adoption dates 1 and ∞ because
we typically use this assumption in combination with Assumptions 2 and 3. In that case we
obtain a constant binary treatment effect set up, as summarized in the following Lemma.
Lemma 4. (Binary Treatment and Constant Treatment Effects) Suppose Assumptions 2-5 hold. Then for all t and a′ < a
Yit (a′ ) − Yit (a) = 1a′ ≤t<a τ1∞ .
The final assumption allows us to view the potential outcomes as random by postulating a
large population from which the sample is drawn.
Assumption 6. (Random Sampling) The sample can be viewed as a random sampling from
an infinitely large population, with joint distribution for (Ai , Yit(a), a ∈ A, t ∈ T) denoted by
f (a, y1 (1), . . . , yT (∞)).
Under this assumption we can put additional structure on average potential outcomes.
Assumption 7. (Additivity)
E [Yit (∞)] = αi + βt .

11

4

Difference-In-Differences Estimators: Interpretation and
Inference

In this section we consider the standard DID set up (e.g., Meyer et al. [1995], Bertrand et al.
[2004], Angrist and Pischke [2008], Donald and Lang [2007], de Chaisemartin and D’Haultfœuille
[2018]). In the simplest setting with N units and T time periods, without additional covariates,
the realized outcome in period t for unit i is modeled as
Yit = αi + βt + τ Wit + εit .

(4.1)

In this model there are unit effects αi and time effects βt , but both are additive with interactions
between them ruled out. The effect of the treatment is implicitly assumed to be additive and
constant across units and time periods.
We interpret the DID estimand under the randomized adoption date assumption, leading to a different setting from that considered in de Chaisemartin and D’Haultfœuille [2018],
Abraham and Sun [2018], Goodman-Bacon [2017]. We also derive its variance and show that
in general it is lower than the standard random-sampling based variance. Finally we propose a
variance estimator that is is smaller than the regular variance estimators such as the Liang-Zeger
and clustered bootstrap variance estimators.

4.1

Difference-In-Differences Estimators

Consider the least squares estimator for τ based on the specification in (4.1):


N
T
τ̂did , {α̂i }i=2 , {β̂t }t=1 = arg

min

T
τ,{αi }N
i=2 ,{βt }t=1

N X
T
X

(Yit − αi − βt − τ Wit )2 .

i=1 t=1

It is convenient to write τ̂did in terms of the adjusted treatment indicator Ẇit as
P

i,t

τ̂did = P

Ẇit Yit

2
i,t Ẇit

.

12

The primary question of interest in this section concerns the properties of the estimator τ̂did .
This includes the interpretation of its expectation under various sets of assumptions, and its
variance. Mostly we focus on exact properties in finite samples.
In order to interpret the expected value of τ̂did we consider some intermediate objects. Define,
for all adoption dates a ∈ A, and all time periods t ∈ T the average of the outcome in period t
for units with adoption date a:

Y t,a =




1
Na

 0

P

i:Ai =a

Yit

if Na > 0,
otherwise.

Under Assumption 1 the stochastic properties of these averages are well-defined because the Na
are fixed over the randomization distribution. The averages are stochastic because the realized
outcomes depend on the adoption date. Define also the following two difference between outcome
averages:
τ̂t,aa′ = Y t,a′ − Y t,a .
In general these differences do not have a causal interpretation. Such an interpretation requires
some assumptions, for example, on random assignment of the adoption date.
Example: To facilitate the interpretation of some of the results it is useful to consider a
special case where the results from completely randomized experiments directly apply. Suppose
T = {1, 2}, and A = {2, ∞}, with a fraction π = π2 = 1 − π∞ adopting the policy in the second
period. Suppose also that Yi1 (a) = 0 for all i and a. Then the DID estimator is
τ̂did = τ̂2,2∞ = Y 2,2 − Y 2,∞ =

1 X
1 X
Yi2 −
Yi2 ,
N2 i:A =2
N∞ i:A =∞
i

i

the simple difference in means for the second period outcomes for adopters and non-adopters.
Under Assumption 1, the standard results for the variance of the difference in means for a
randomized experiments apply (e.g., Neyman [1923/1990], Imbens and Rubin [2015]), and the

13

exact variance of τ̂did is,
N

X
1
V(τ̂did ) =
Yi2 (2) − Y 2 (2)
N2 (N − 1) i=1

2

N

X
1
+
Yi2 (∞) − Y 2 (∞)
N∞ (N − 1) i=1

N

X


1
−
Yi2 (2) − Y 2 (2) − Yi2 (∞) − Y 2 (∞)
N(N − 1) i=1

2

2

.

The standard Neyman estimator for this variance ignores the third term, and uses unbiased
estimators for the first two terms, leading to:
V̂(τ̂did ) =

X 
1
Yi2 − Y 2,2
N2 (N2 − 1) i:A =2

2

+

i

X 
1
Yi2 − Y 2,∞
N∞ (N∞ − 1) i:A =∞

2

.

i



4.2

The Interpretation of Difference-In-Differences Estimators

The following weights play an important role in the interpretation of the DID estimand:
π g(t, a)
Pa
,
′ ′ 2
t′ ∈T
a′ ∈A πa′ g(t , a )

γt,a ≡ P

γt,+ ≡

X

γt,a ,

and γt,− ≡

X

γt,a ,

(4.2)

a>t

a≤t

with g(a, t) as defined in (3.1). Note that these weights are non-stochastic, that is, fixed over
the randomization distribution.
Example (ctd): Continuing the example with two periods and adoption in the second period
or never, we have in that case

γt,a




0






0




 −1
=


1






1




 −1

if (t, a) = (1, 1),
if (t, a) = (2, 1),
if (t, a) = (1, 2),
if (t, a) = (2, 2),
if (t, a) = (1, ∞),

γt,+


 0 if t = 1,
=
 1 if t = 2,

if (t, a) = (2, ∞),

14

and γt,−


 0
if t = 1,
=
 −1 if t = 2.


The weights γt,a have some important properties,
X

γt,+ = 1

t∈T

X

γt,− = −1,

and

T X
X

γt,a =

t=1 a∈A

t∈T

X

γt,+ +

t∈T

X

γt,− = 0.

t∈T

Now we can state the first main result of the paper.
Lemma 5. We can write τ̂did as
τ̂did =

XX
t∈T a∈A

γt,a Y t,a =

X
t∈T

γt,+ τ̂t,∞1 +

XX
t∈T a>t

γt,a τ̂t,∞a −

XX

γt,a τ̂t,a1 .

(4.3)

t∈T a≤t

Comment 1. Alternative characterizations of the DID estimator or estimand as a weighted av-

erage of potentially causal comparisons are presented in Abraham and Sun [2018], de Chaisemartin and D’Ha
[2018], Han [2018], Goodman-Bacon [2017], and Borusyak and Jaravel [2016]). The characterizations differ in terms of the building blocks that are used in the representation and the assumptions made. Like our representation, the representation in Abraham and Sun [2018] is
in terms of average causal effects of different adoption dates, but it imposes no-anticipation.
Goodman-Bacon [2017] presents the DID estimator in terms of basic two-group DID estimators. Like our representation, the Goodman-Bacon [2017] is mechanical and does not rely on
any assumptions. To endow the building blocks and the representation itself with a causal
interpretation requires some assumption on, for example, the assignment mechanism. 
Comment 2. The lemma implies that the DID estimator has an interpretation as a weighted
average of simple estimators for the causal effect of changes in adoption dates, the τ̂t,aa′ . Moreover, the estimator can be written as the sum of three averages of these τ̂t,aa′ . The first is a
weighted average of the τ̂t,∞1 , which are all averages of switching from never adopting to adopting in the first period, meaning that these are averages of changes in adoption dates that involve
switching from not being treated at time t to being treated at time t. The sum of the weights
for these averages is one, although not all the weights are necessarily non-negative. The second
sum is a weighted sum of τ̂t,∞a , for a > t, so that the causal effect always involves changing the
adoption date from never adopting to adopting some time after t, meaning that the comparison
is between potential outcomes neither of which involves being treated at the time. The sum of
the weights for these averages is one again. The third sum is a weighted sum of τ̂t,a1 , for a ≤ t,
15

so that the causal effect always involves changing the adoption date from adopting prior to,
or at time, t relative to adopting at the initial time, meaning that the comparison is between
potential outcomes both of which involves being treated at the time. These weights sum to
minus one. 
If we are willing to make the random adoption date assumption we can give this representation a causal interpretation:
Theorem 1. Suppose Assumption 1 holds. Then (i):
E [τ̂t,aa′ ] = τt,aa′ ,
and (ii)
E [τ̂did ] =

X

γt,+ τt,∞1 +

XX

γt,a τt,∞a −

t∈T a>t

t∈T

XX

γt,a τt,a1 .

t∈T a≤t

Suppose also Assumption 2 holds. Then (iii):
E [τ̂did ] =

XX

γt,a τt,∞a .

t∈T a≤t

Suppose also Assumption 3 holds. Then (iv):

E [τ̂did ] =

T
X

γt,+ τt,∞1 .

t=1

Suppose also Assumption 5 holds. Then (v):
E [τ̂did ] = τ∞1 .
Part (iii) of the theorem where we make the no-anticipation assumption is closely related to
one of the results in Abraham and Sun [2018], who make a super-population common trend assumption that, in the super-population context, weakens our random adoption date assumption.
Part (iv) of the theorem, where we assume both the exclusion restrictions so that the treatment
is effectively a binary one, is related to the results in de Chaisemartin and D’Haultfœuille [2018],
16

although unlike those authors we do not restrict the trends in the potential outcomes.
Without either Assumptions 2 or 3, the estimand τdid has a causal interpretation, but it
is not clear it is a very interesting one concerning the receipt of the treatment. With the noanticipation assumption (Assumption 2), the interpretation, as given in part (iii) of the theorem,
is substantially more interesting. Now the estimand is a weighted average of τt,∞a for a ≤ t,
with weights summing to one. These τt,∞a are the average causal effect of changing the adoption
date from never adopting to some adoption date prior to, or equal to, time t, so that the average
always involves switching from not being exposed to the treatment to being exposed to the
treatment.

4.3

The Randomization Variance of the Difference-In-Differences Estimators

In this section we derive the randomization variance for τ̂did under the randomized adoption
date assumption. We do not rely on other assumptions here, although they may be required for
making the estimand a substantively interesting one. The starting point is the representation
P
τ̂did = t,a γt,a Y t,a . Because under Assumption 1 the weights γt,a are fixed, the variance is
V(τ̂did ) =

X

2
γt,a
V(Y t,a ) +

t,a

X

γt,a γt′ ,a′ C(Y t,a , Y t′ ,a′ ).

(t,a)6=(t′ ,a′ )

Note that the γt,a are known. Working out the variance V(Y t,a ), and finding an unbiased estimator for it, is straightforward. It is more challenging to infer the covariance terms C(Y t,a , Y t′ ,a′ ),
and even more difficult to estimate them. In general that is not possible. Note that for a
sampling-based variance the γt,a are not fixed, because in different samples the fractions with
a particular adoption date will be stochastic. This in general leads to a larger variance, as we
verify in the simulations.
Define
Yi (a) =

T
X
t=1

γt,a Yit (a),

Y (a) =

T
X

γt,a Y t (a)

t=1

and Y a =

T
X
t=1

17

γt,a Y t,a .

Now we can write τ̂ did as
τ̂ did =

XX

γt,a Y t,a =

a∈A t∈T

X

Y a.

a∈A

Define also
N

Sa2

2
1 X
=
Yi (a) − Y (a) ,
N − 1 i=1

and
N

2
Va,a
′



1 X
Yi (a) − Y (a) + Yi (a′ ) − Y (a′ )
=
N − 1 i=1

2

.

Theorem 2. Suppose Assumptions 1 holds. Then the exact variance of τ̂did over the randomization distribution is
V (τ̂did ) =



X

Sa2

X

Sa2 /Na .

a∈A

T −1
1
+
Na
N



−

X

X

a∈A a′ ∈A,a′ >a

2
Va,a
′
,
N

with
V (τ̂did ) ≤

a∈A

Comment (ctd): In our two period example with some units adopting in the second period
and the others not at all, and Yi1 (a) = 0, we have


γ1 = 

0
0



,



γ2 = 

−1
1



,



and γ∞ = 

S12 = 0,
N
N
1 X
1 X
2
Yi2 (2) −
Yj2 (2)
S,2 =
N − 1 i=1
N j=1

!2

,

18

1
−1



.

2
S∞

N
N
1 X
1 X
=
Yi2 (∞) −
Yj2(∞)
N − 1 i=1
N j=1

2
V1,2
= 0,

,

2
S1,∞
= 0,
N

2
V2,∞

!2

1 X
=
N − 1 i=1

N
1 X
Yi2 (2) −
Yi2 (2)
N j=1

!

−

N
1 X
Yi2 (∞) −
Yi2 (∞)
N j=1

!!2

,

so that in this special
N
N
X
1 X
1
Yi2 (2) −
Yi2 (2)
V(τ̂did ) =
N2 (N − 1) i=1
N j=1

!2

N
N
X
1 X
1
Yi2 (∞) −
Yi2 (∞)
+
N∞ (N − 1) i=1
N j=1
N

X
1
−
N(N − 1) i=1

N
1 X
Yi2 (2) −
Yi2 (2)
N j=1

!

!2
−

N
1 X
Yi2 (∞) −
Yi2 (∞)
N j=1

!!2

,

which agrees with the Neyman variance for a completely randomized experiment. 

4.4

Estimating the Randomization Variance of the Difference-InDifferences Estimators

In this section we discuss estimating the variance of the DID estimator. In general there is
no unbiased estimator for V (τ̂did ). This is not surprising, because there is no such estimator
for the simple difference in means estimator in a completely randomized experiment, and this
corresponds to the special case with T = 1. However, it turns out that just like in the simpled
randomized experiment case, there is a conservative variance estimator. In the current case
it is based on using unbiased estimators for the terms involving Sγ2a ,a , and ignoring the terms
involving Vγ2a ,a,γa′ ,a′ . Because the latter are non-negative, and enter with a minus sign, ignoring
them leads to an upwardly biased variance estimator. One difference with the simple randomized
experiment case is that there is no simple case with constant treatment effects such that the
variance estimator is unbiased.

19

Next, define the estimated variance of this by adoption date:
s2a ≡

X
2
1
Yi − Y a .
Na − 1 i:A =a
i

Now we can characterize the proposed variance estimator as
b did ≡
V

X s2
a
.
N
a
a∈A

Theorem 3. Suppose Assumption 1 holds. Then
h
i
b did ≥ V(τ̂did ),
E V

b did is a conservative variance estimator for τ̂did .
so that V

There are two important issues regarding this variance estimator. The first is its relation to

the standard variance estimator for DID estimators. The second is whether one can improve on
this variance estimator given that in general it is conservative.
The relevant variance estimators are the Liang-Zeger clustered variance estimator and the
clustered bootstrap (Bertrand et al. [2004], Liang and Zeger [1986]). Both have large sample
justifications under random sampling from a large population, so they are in general not equal
to the variance estimator here. In large samples both the Liang-Zeger and bootstrap variance
will be more conservative than V̂did because they also take into account variation in the weights
γt,a . These weights are kept fixed under the randomization scheme, because that keeps fixed
the marginal distribution of the adoption dates. In contrast, under the Liang-Zeger calculations
and the clustered bootstrap, the fraction of units with a particular adoption date varies, and
that introduces additional uncertainty.
The second issue is whether we can improve on the conservative variance estimator V̂did . In
general there is only a limited ability to do so. Note, for example, that in the two period example
this variance reduces to the Neyman variance in randomized experiments. In that case we know
we can improve on this variance a little bit exploiting heteroskedasticity, e.g., Aronow et al.
[2014], but in general those gains are modest.

20

5

Some Simulations

The goal is to compare the exact variance, and the corresponding estimator in the paper to
the two leading alternatives, the Liang-Zeger (stata) clustered standard errors and the clustered
bootstrap. We want to confirm settings where the proposed variance estimator differs from
the Liang-Zeger clustered variance, and settings where it is the same. We have N units, observed for T time periods. We focus primarily on the case with T = 3. The adoption date is
randomly assigned, with πI = (π1 , π2 , π3 , π∞ ) = (0, 0.67, 0, 0.33), and πII = (π1 , π2 , π3 , π∞ ) =
(0, 0.5, 0.4, 0.1).
We consider two designs for the potential outcome distributions in the population, the Yi (a)
for a ∈ {1, 2, 3, ∞}. In design A the potential outcomes, are generated as
























Yi1 (2)
Yi1 (3)
Yi1 (∞)
Yi2 (2)
Yi2 (3)
Yi2 (∞)
Yi3 (2)
Yi3 (3)
Yi3 (∞)














∼N



































0
0
0
4
3
3
2
2
1

























 2
,σ 





















1 0 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0 0
0 0 1 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0
0 0 0 0 1 0 0 0 0
0 0 0 0 0 1 0 0 0
0 0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 0 1














 .











In this design the treatment effect is constant, and depends only on whether the adoption
date preceeds the potential outcome date, or
Yit (a) = 1a≤t + εit ,
where the εit are correlated over time.
In design B the potential outcomes are generated as

21

























Yi1 (2)
Yi1 (3)
Yi1 (∞)
Yi2 (2)
Yi2 (3)
Yi2 (∞)
Yi3 (2)
Yi3 (3)
Yi3 (∞)














∼N



































0
0
0
2
1
1
2
11
1

























 2
,σ 





















1

0

0 0 0 0 0 0 0

0 10 0 0 0 0 0 0 0
0

0

1 0 0 0 0 0 0

0

0

0 1 0 0 0 0 0

0

0

0 0 1 0 0 0 0

0

0

0 0 0 1 0 0 0

0

0

0 0 0 0 1 0 0

0

0

0 0 0 0 0 1 0

0

0

0 0 0 0 0 0 1














 .











Here the treatment effects depend on the treatment having been adopted, but the effect
differs by the adoption date.
In design C the potential outcomes are generated with positive correlations between the
potential outcomes as
























Yi1 (2)
Yi1 (3)
Yi1 (∞)
Yi2 (2)
Yi2 (3)
Yi2 (∞)
Yi3 (2)
Yi3 (3)
Yi3 (∞)














∼N



































0
0
0
2
1
1
2
11
1

























 2
,σ 





















1
0.9

0.9 0.9
1

0.9 0.9

0.9
1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0





0 


0
0
0
0
0
0 


1 0.9 0.9 0
0
0 


0.9 1 0.9 0
0
0  .


0.9 0.9 1
0
0
0 


0
0
0
1 0.9 0.9 


0
0
0 0.9 1 0.9 

0
0
0 0.9 0.9 1

In design D the potential outcomes are generated with negative correlations between the
potential outcomes as

22

























Yi1 (2)
Yi1 (3)
Yi1 (∞)
Yi2 (2)
Yi2 (3)
Yi2 (∞)
Yi3 (2)
Yi3 (3)
Yi3 (∞)














∼N



































0
0
0
2
1
1
2
11
1







1
−0.4 −0.4
0
0
0
0
0
0







 −0.4
1
−0.4
0
0
0
0
0
0 







 −0.4 −0.4
1
0
0
0
0
0
0 







 0
0
0
1
−0.4 −0.4
0
0
0 




 2
,σ  0
0
0
−0.4
1
−0.4
0
0
0  .







 0
0
0
−0.4 −0.4
1
0
0
0 







 0
0
0
0
0
0
1
−0.4 −0.4 







 0
0
0
0
0
0
−0.4
1
−0.4 



0
0
0
0
0
0
−0.4 −0.4
1

For a particular design, eg (A, 2) draw the four sets of three-component vectors of potential
outcomes for each unit (the three components corresponding to the three time periods), one set
for each of the values of a ∈ {1, 2, 3, ∞}. We keep these sets of potential outcomes fixed across
all simulations for a given design. Then for each simulation draw the adoption date according
to the distribution for that design, keeping the fraction of units with a particular adoption date
fixed.
We want to look at variances and the corresponding confidence intervals based on four
methods for estimating the variance for the DID estimator. The confidence intervals are Normaldistribution based, simply equal to the point estimates plus and minus 1.96 times the square
root of the variances. We can write τ̂did as a regression estimator with NT observations, and
N + T regressors. Let with j = 1, . . . , NT . For observation j, Tj ∈ {1, . . . , T } denotes the time
period the observation is from, and Nj ∈ {1, . . . , N} denotes the unit is corresponds to. Now
let Yj = YNj ,Tj and Wj = WNj ,Tj , so that the regression function can be written as

Yj = µ +

N
−1
X
n=1

αn 1Nj =n +

T −1
X

βt 1Tj =t + τ Wj + εj = Yj = Xj⊤ θ + εj ,

t=1

where Xj = (1, 1Nj =1 , . . . , 1Nj =N −1 , , 1Tj =1 , . . . , 1Tj =T −1 , Wj ), and θ = (µ, α1 , . . . , αN −1 , β1 , . . . , βT −1 , τ ).

23

We compare five variances. The first is exact randomization-based variance,
Vdid = V (τ̂ ) =

X Sγ2

a ,a

a∈A

Na

−

X
a∈A

X

Vγ2a ,a,γa′ ,a′

a′ ∈A,a′ >a

N

.

The other four are estimators of the variance.
b did .
First, the feasible conservative variance estimator V

Second, the standard Liang-Zeger clustered variance. Start with the representation Yj =
Xj⊤ θ + εj . Let ε̂j = Yj − Xj⊤ θ̂ be the residual from this regression. Calculate the variance as

b LZ =
V

J
X

Xj Xj⊤

j=1

!−1




⊤ 
!−1
N
J
X
X
X
X



Xj ε̂j  
Xj ε̂j  
Xj Xj⊤
,

n=1

j:Nj =n

j:Nj =n

j=1

and get the corresponding variance estimator for τ̂did .
b B1 . Draw bootstrap samples based on drawing units, with
Third, the clustered bootstrap, V

all time periods for each unit drawn. Note that this explicitly changes from bootstrap sample
to bootstrap sample the fraction of units with a particular adoption date.
b B2 , where we fix the fraction of units
Fourth, a modification of the clustered bootstrap, V

with each value for the adoption date.

In Table 1 we report the results. For each of the five variances we report the average of

variance, and the coverage rate for the 95% confidence interval.
b B1 ) substantially overWe see that the standard Liang-Zeger and the clustered bootstrap (V
b B2 ) and the proposed
estimate the variance in Design B. The fixed adoption date bootstrap (V
b did ) have the appropriate coverage.
variance estimator (V

6

Conclusion

We develop a design-based approach to Difference-In-Differences estimation in a setting with
staggered adoption. We characterize what the standard DID estimator is estimating under a
random adoption date assumption, and what the variance of the standard estimator is. We show
that the standard DID estimatand is a weighted average of different types of causal effects,
for example, the effect of changing from never adopting to adopting in the first period, or
24

Table 1: : Simulations
Design
A
B
C
D
A
B
C
D
A
B
C
D
A
B
C
D

π
I
I
I
I
II
II
II
II
I
I
I
I
II
II
II
II

N
30
30
30
30
30
30
30
30
150
150
150
150
150
150
150
150

Vdid
0.144
0.111
0.201
0.064
0.112
0.085
0.184
0.081
0.027
0.022
0.035
0.019
0.020
0.021
0.034
0.016

Cov
0.951
0.947
0.953
0.949
0.946
0.947
0.949
0.950
0.953
0.955
0.956
0.950
0.952
0.945
0.952
0.950

V̂did
0.239
0.187
0.217
0.265
0.165
0.139
0.191
0.164
0.047
0.041
0.038
0.044
0.033
0.036
0.035
0.028

Cov
0.979
0.986
0.947
1.000
0.972
0.973
0.939
0.992
0.991
0.994
0.960
0.997
0.989
0.985
0.953
0.990

V̂LZ
0.214
0.163
0.181
0.230
0.146
0.268
0.279
0.285
0.045
0.039
0.036
0.044
0.033
0.053
0.051
0.044

Cov
0.974
0.978
0.925
0.999
0.966
0.999
0.983
1.000
0.989
0.992
0.956
0.997
0.989
0.997
0.985
0.998

V̂B1
0.232
0.182
0.211
0.257
0.158
0.269
0.285
0.280
0.047
0.041
0.037
0.044
0.033
0.052
0.052
0.044

Cov
0.975
0.982
0.942
1.000
0.969
0.999
0.981
0.999
0.989
0.992
0.955
0.996
0.987
0.997
0.983
0.998

V̂B2
0.219
0.172
0.200
0.244
0.142
0.119
0.162
0.142
0.046
0.041
0.037
0.043
0.032
0.035
0.034
0.028

Cov
0.973
0.978
0.932
0.999
0.956
0.962
0.920
0.987
0.989
0.992
0.954
0.995
0.987
0.984
0.947
0.987

changing from never adopting to adopting later. In this approach the standard Liang-Zeger
and clustered bootstrap variance estimators are unnecessarily conservative, and we propose an
improved variance estimator.

25

Appendix
Proof of Lemma 1: Let Y p denote the N × (T · (T + 1)) dimensional matrix with all the potential
outcomes. Because the units are exchangeable we can write the joint distribution of the potential
outcomes and A as
p

f (Y , A) =

N
Y

f (Yip , Ai ).

i=1

Now we shall construct a distribution f (Yip , Ai ) that satisfies two conditions. First, Ai is independent of
all the potential outcomes and second, the implied distribution for the adoption date and the realized
outcome is consistent with the actual distribution. To do so we assume independence of the sets
potential outcomes Yi1 (a), . . . , fiT (a) for different a, and assume that
f (Yi1 (a), . . . , fiT (a)) = f (Yi1 (a), . . . , fiT (a)|Ai = a) = f (Yi1 , . . . , fiT |Ai = a).

Proof of Lemma 2: By Assumption 2 we have
Yit (a) = 1a≤t Yit (a) + 1a>t Yit (∞),
and by Assumption 3 we have
Yit (a) = 1a≤t Yit (1) + 1a>t Yit (a).
Combining the two assumptions implies
Yit (a) = 1a≤t Yit (1) + 1a>t Yit (∞).
Hence
Yit (a′ ) − Yit (a) = 1a′ ≤t Yit (1) + 1a′ >t Yit (∞) − (1a≤t Yit (1) + 1a>t Yit (∞))
= 1a′ ≤t<t (Yit (1) − Yit (∞)) ,
which proves part (i).

26

For part (ii)

τt,aa′ =

N

1 X
Yit (a′ ) − Yit (a)
N
i=1

=

N
1 X
1a′ ≤t<t (Yit (1) − Yit (∞))
N
i=1

=1

a′ ≤t<t

N
1 X
(Yit (1) − Yit (∞)) = 1a≤t<a′ τt,∞1 .
N
i=1


Proof of Lemma 3: Part (i) follows directly from the fact that the exclusion restrictions place
restrictions only on potential outcomes that cannot be observed together.
Let us turn to part (ii). By assumption
Yit (a) ⊥⊥ Ai ,
which as a special case includes
Yi1 (∞) ⊥⊥ Ai .
Hence
Yi1 (∞) ⊥⊥ Ai

Ai ≥ 2

which implies
Yi1 ⊥⊥ Ai

Ai ≥ 2

and thus
Yi1 ⊥⊥ Ai

Ai ∈ {2, ∞},

which is a testable restriction. 

27

Proof of Lemma 4: By Assumptions 2 and 3 we have


Yit (a) − Yit (∞) = 1a≤t Yit (1) − Yit (∞) .
By Assumptions 4 and 5, Yit (1) − Yit (∞) = τ1∞ , so that
Yit (a) − Yit (∞) = 1a≤t τ1∞ .

Proof of Lemma 5: Using the definition for g(t, a), we can write τ̂did as
τ̂did =

P

i,t Ẇit Yit
P
2
i,t Ẇit

P

P

P
P
P P
P
g(a, t)Yit
a∈A
i:Ai =a Ẇit Yit
t∈T
a∈A
P P
P P i:Ai =a
=
=
2
N t∈T a∈A πa g(a, t)
N t∈T a∈A πa g(a, t)2
t∈T

P
P
g(a, t)Na Y t,a
a∈A
P Pi:Ai =a
=
N t∈T a∈A πa g(a, t)2
P P
X
t∈T
a∈A g(a, t)πa Y t,a
P
=
γt,a Y t,a ,
= P
2
t∈T
a∈A πa g(a, t)
t,a
t∈T

where γt,a is as given in (4.2). 

Proof of Theorem 1: First consider part (i). We will show that
E[Y ta ] = Y t (a),
which in turn implies the result in (i). We can write
#
"
#
N
N
1 X
1 X
E[Y ta ] = E
1Ai =a Yit = E
1Ai =a Yit (a) .
Na
Na
"

i=1

i=1

By Assumption 1 this is equal to
N
N
N
1 X
1 X Na
1 X
E [1Ai =a ] Yit (a) =
Yit (a) =
Yit (a) = Y t (a),
Na
Na
N
N
i=1

i=1

i=1

which is the desired result.

28

Next consider part (ii). By Lemma 5,
τ̂did =

X

γt,+ τ̂t,∞1 +

XX

γt,a τ̂t,∞a −

t∈T a>t

t∈T

XX

γt,a τ̂t,a1 ,

t∈T a≤t

so that


E [τ̂did ] = E 

X

γt,+ τ̂t,∞1 +

XX

γt,a τ̂t,∞a −

t∈T a>t

t∈T

XX
t∈T a≤t



γt,a τ̂t,a1  ,

which by Assumption 1 is equal to
X

γt,+ E [τ̂t,∞1 ] +

XX

γt,a E [τ̂t,∞a ] −

t∈T a>t

t∈T

XX

γt,a E [τ̂t,a1 ] .

t∈T a≤t

This in turn, by part (i), is equal to
X

γt,+ τt,∞1 +

XX

γt,a τt,∞a −

t∈T a>t

t∈T

XX

γt,a τt,a1 ,

t∈T a≤t

which finishes the proof of part (ii).
Next consider part (iii). If Assumption 2 holds, then for all a > t, τt,∞a = 0, so that
E [τ̂did ] =

X

γt,+ τt,∞1 −

γt,a τt,a1

t∈T a≤t

t∈T

=

XX

XX

γt,a τt,∞a .

t∈T a≤t

Next consider part (iv). If also Assumption 3 holds, then also for all a ≤ t, τt,a1 = 0, so that
E [τ̂did ] =

X

γt,+ τt,∞1 +

t∈T

=

X

XX

γt,a τt,∞a −

t∈T a>t

XX

γt,a τt,a1

t∈T a≤t

γt,+ τt,∞1 .

t∈T

Finally, consider part (v). This follows directly from part (iv) in combination with the constant
treatment effect assumption (Assumption 5). 
Next we give a preliminary result.

29

Lemma A.1. Suppose that Assumption 1 holds. Then (i) the variance of Y a is
V(Y a ) =

Sa2
Na



1−

Na
N



,

(ii), the covariance of Y a and Y a′ is
C(Y a , Y a′ ) = −



1
1
2
2
=
Sa2 + Sa2′ − Saa
Sa2 + Sa2′ − Vaa
′
′ ,
2N
2N

(iii), the variance of the sum of the Y a is

V

X

Ya

a∈A

!

=

!

≤

X

a∈A

Sa2



1
T −1
+
Na
N



−

1
2N

X

2
Vaa
′,

a,a′ :a6=a′

and (iv),

V

X

a∈A

Ya

X S2
a
.
Na

a∈A

Proof of Lemma A.1: Part (i) follows directly from the variance of a sample average with random
sampling from a finite population.
Next consider part (ii). Define
2
Saa
′ =

N


1 X
Yi (a′ ) − Y (a′ ) − Yi (a) − Y (a) .
N −1
i=1

Recall that the variance of the difference between Y a′ and Y a is
V(Y a′ − Y a ) =

S2 ′
S 2′
Sa2
+ a − aa ,
Na Na′
N

from the results in Neyman [1923/1990], Imbens and Rubin [2015] for completely randomized experiments with a binary treatment. In general it is also true that
V(Y a′ − Y a ) = V(Y a ) + V(Y a′ ) − 2C(Y a , Y a′ ).
Combining these two characterizations of the variance of the standard estimator for the average treat-

30

ment effect, it follows that the covariance is equal to
1
V(Y a ) + V(Y a′ ) − V(Y a′ − Y a )
2

C(Y a , Y a′ ) =
1
=
2



Sa2
Na



  2

2 
Saa
Sa2′
Sa2′
Sa
Na
Na′
′
−
+
1−
+
−
1−
N
Na′
N
Na Na′
N

1  2
2
Sa + Sa2′ − Saa
′
2N
1  2
2
2
2
Sa + Sa2′ + Vaa
=−
′ − 2Sa − 2Sa′
2N
1  2
2
=
Sa + Sa2′ − Vaa
.
′
2N

=−

Next, consider part (iii). Using the result in part (ii),
X

V

Ya

a∈A

!

=

X

V(Y a ) +

X

a∈A


X S2 
Na
1
a
1−
+
=
Na
N
2N
a∈A

=

X

Sa2

X

Sa2

a∈A

=

a∈A

C(Y a , Y a′ )

a,a′ :a6=a′

X



1
2N

X

a,a′ :a6=a′



1
T
1
−
+
Na N
N



−



T −1
1
+
Na
N



−

1
2N

2
Sa2 + Sa2′ − Vaa
′

2
Vaa
′

a,a′ :a6=a′

X

2
Vaa
′.

a,a′ :a6=a′

2 terms is not directly estimable. Because it
Finally, consider part (iv). The third term, the sum of Vaa
′

has a negative sign, we need to find a lower bound on this sum. A trivial lower bound is zero, but we
can do better. We will show that
1
2N

X

2
Vaa
′ ≥

a,a′ :a6=a′

X

a∈A

Sa2

T −1
.
N

(A.1)

This in turn implies
−

1
2N

X

a,a′ :a6=a′

2
Vaa
′ ≤ −

X

a∈A

Sa2

T −1
,
N

31

and thus
X

V

Ya

a∈A

≤

!

X

=

Sa2

a∈A

Sa2

a∈A

=

X





1
T −1
+
Na
N

1
T −1
+
Na
N



−



X

−

a6=a

Sa2

a∈A

1 X 2
Vaa′
2N
′
T −1
N

X S2
a
.
Na

a∈A

The last inequality to prove is (A.1). First,
N

2
Vaa
′

1 X
=
N −1
i=1


2
Yi (a′ ) − Y (a′ ) + Yi (a) − Y (a)

N
2
2

2 o
1 Xn
Yi (a′ ) − Y (a′ ) + Yi (a) − Y (a) + 2 Yi (a′ ) − Y (a′ ) Yi (a) − Y (a)
=
N −1
i=1

=
Hence


1
Sa2 + Sa2′ + 2C(Yi (a), Yi (a′ )) .
N

1 X 2
1
Vaa′ =
2N
2N
′
a6=a

=

X

a∈A

Sa2

X

a,a′ :a6=a′

 2
Sa + Sa2′ + 2C(Yi (a), Yi (a′ ))

1 X
T
C(Yi (a), Yi (a′ )).
+
N
N
′

(A.2)

a6=a

Next,

0≤V

X

a∈A

!

Yi (a)

=

X

V(Yi (a)) +

X

C(Yi (a), Yi (a′ )).

a,a′ :a6=a′

a∈A

Therefore
X

a,a′ :a6=a′

C(Yi (a), Yi (a′ )) ≥ −

X

a∈A

V(Yi (a)) = −

X

a∈A

32

Sa2 .

(A.3)

Combining (A.2) and (A.3) we get the bound
1
2N

X

2
Vaa
′ =

a,a′ :a6=a′

≥

X

X

Sa2

a∈A

T
1
+
N
N

X

C(Yi (a), Yi (a′ ))

a,a′ :a6=a′

X
X T −1
T
−
,
Sa2 =
Sa2
N
N

Sa2

a∈A

a∈A

a∈A

which proves (A.1). 
Proof of Theorem 2: This follows directly from the results in Lemma A.1. 
Proof of Theorem 3: By Assumption 1 it follows that


E s2γa ,a = Sγ2a ,a .
This implies that
h

i

E V̂did = E

"

X

a∈A

#

s2γa ,a /Na =

X

Sγ2a ,a /Na ≥ V(τ̂did ),

a∈A

where the inequality is by Theorem 2. 

33

References
Alberto Abadie. Semiparametric difference-in-differences estimators. The Review of Economic Studies,
72(1):1–19, 2005.
Alberto Abadie, Alexis Diamond, and Jens Hainmueller. Synthetic control methods for comparative
case studies: Estimating the effect of California’s tobacco control program. Journal of the American
Statistical Association, 105(490):493–505, 2010.
Alberto Abadie, Susan Athey, Guido Imbens, and Jeffrey Wooldrige. Clustering as a design problem.
2016.
Alberto Abadie, Susan Athey, Guido W Imbens, and Jeffrey M Wooldridge. Sampling-based vs. designbased uncertainty in regression analysis. arXiv preprint arXiv:1706.01778, 2017.
Sarah Abraham and Liyang Sun. Estimating dynamic treatment effects in event studies with heterogeneous treatment effects. 2018.
Joshua Angrist and Alan Krueger. Empirical strategies in labor economics. Handbook of Labor
Economics, 3, 2000.
Joshua Angrist and Steve Pischke. Mostly Harmless Econometrics: An Empiricists’ Companion. Princeton University Press, 2008.
Manuel Arellano. Computing robust standard errors for within group estimators. Oxford bulletin of
Economics and Statistics, 49(4):431–434, 1987.
Manuel Arellano. Panel data econometrics. Oxford university press, 2003.
P. Aronow, D. Green, and D. Lee. Sharp bounds on the variance in randomized experiments. Annals
of Statistics, 42(3):850–871, 2014.
Peter M. Aronow and Cyrus Samii. Does regression produce representative estimates of causal effects?
American Journal of Political Science, 60(1):250–267, 2016.
Susan Athey and Guido Imbens. Identification and inference in nonlinear difference-in-differences
models. Econometrica, 74(2):431–497, 2006.

34

Susan Athey and Scott Stern. An empirical framework for testing theories about complimentarity in
organizational design. Technical report, National Bureau of Economic Research, 1998.
Marianne Bertrand, Esther Duflo, and Sendhil Mullainathan. How much should we trust differencesin-differences estimates? The Quarterly Journal of Economics, 119(1):249–275, 2004.
Kirill Borusyak and Xavier Jaravel. Revisiting event study designs. 2016.
Brantly Callaway and Pedro HC Sant’Anna. Difference-in-differences with multiple time periods and
an application on the minimum wage and employment. arXiv preprint arXiv:1803.09015, 2018.
David Card. The impact of the mariel boatlift on the miami labor market. Industrial and Labor
Relation, 43(2):245–257, 1990.
David Card and Alan Krueger. Minimum wages and employment: Case study of the fast-food industry
in new jersey and pennsylvania. American Economic Review, 84(4):772–793, 1994.
Timothy G Conley and Christopher R Taber. Inference with difference in differences with a small
number of policy changes. The Review of Economics and Statistics, 93(1):113–125, 2011.
Clément de Chaisemartin and Xavier D’Haultfœuille. Fuzzy differences-in-differences. The Review of
Economic Studies, 85(2):999–1028, 2017.
Clément de Chaisemartin and Xavier D’Haultfœuille. Two-way fixed effects estimators with heterogeneous treatment effects. 2018.
Stephen G Donald and Kevin Lang. Inference with difference-in-differences and other panel data. The
review of Economics and Statistics, 89(2):221–233, 2007.
Simon Freyaldenhoven, Christian Hansen, and Jesse Shapiro. Pre-event trends in the panel event-study
design. Technical report, Brown University Working Paper, 2018.
Andrew Goodman-Bacon. Difference-in-differences with variation in treatment timing. Technical report, Working Paper, 2017.
Sukjin Han. Identification in nonparametric models for dynamic treatment effects. 2018.

35

Chad Hazlett and Yiqing Xu. Trajectory balancing: A general reweighting approach to causal inference
with time-series cross-sectional data. 2018.
Peter Hull. Estimating treatment effects in mover designs. arXiv preprint arXiv:1804.06721, 2018.
Kosuke Imai and In Song Kim. When Should We Use Linear Fixed Effects Regression Models for Causal
Inference with Longitudinal Data? PhD thesis, Working paper, Princeton University, Princeton,
NJ, 2016.
Kosuke Imai, In Song Kim, and Erik Wang. Matching methods for causal inference with time-series
cross-section data. 2018.
Guido W Imbens and Donald B Rubin. Causal Inference in Statistics, Social, and Biomedical Sciences.
Cambridge University Press, 2015.
Kung-Yee Liang and Scott L Zeger.

Longitudinal data analysis using generalized linear models.

Biometrika, 73(1):13–22, 1986.
Bruce D Meyer, W Kip Viscusi, and David L Durbin. Workers’ compensation and injury duration:
evidence from a natural experiment. The American Economic Review, pages 322–340, 1995.
Jerzey Neyman. On the application of probability theory to agricultural experiments. essay on principles. section 9. Statistical Science, 5(4):465–472, 1923/1990.
Judea Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press, New York,
NY, USA, 2000. ISBN 0-521-77362-8.
Paul R Rosenbaum. Observational studies. In Observational Studies. Springer, 2002.
Paul R Rosenbaum. Observation and Experiment: An Introduction to Causal Inference. Harvard
University Press, 2017.
Donald B Rubin. Bayesian inference for causal effects: The role of randomization. The Annals of
statistics, pages 34–58, 1978.
Bbabubhai V Shah, Mary Margaret Holt, and Ralph E Folsom. Inference about regression models from
sample survey data. Bulletin of the International Statistical Institute, 47(3):43–57, 1977.

36

James H Stock and Mark W Watson. Heteroskedasticity-robust standard errors for fixed effects panel
data regression. Econometrica, 76(1):155–174, 2008.
Anton Strezhnev. Semiparametric weighting estimators for multi-period difference-in-differences designs. 2018.
Jeffrey M Wooldridge. Econometric analysis of cross section and panel data. MIT press, 2010.

37

