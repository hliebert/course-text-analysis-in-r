Comment: Performance of Double-Robust Estimators When "Inverse Probability" Weights
Are Highly Variable
Author(s): James Robins, Mariela Sued, Quanhong Lei-Gomez and Andrea Rotnitzky
Source: Statistical Science, Vol. 22, No. 4 (Nov., 2007), pp. 544-559
Published by: Institute of Mathematical Statistics
Stable URL: https://www.jstor.org/stable/27645860
Accessed: 21-10-2019 14:59 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve and
extend access to Statistical Science

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

Statistical Science
2007, Vol. 22, No. 4, 544-559

DOI: 10.1214/07-STS227D

Main article DOI: 10.1214/07-STS227
? Institute of Mathematical Statistics, 2007

Comment: Performance of Double-Robust
Estimators When "Inverse Probability"
Weights Are Highly Variable
James Robins, Mariela Sued, Quanhong Lei-Gomez and Andrea Rotnitzky
1. GENERAL CONSIDERATIONS
We thank the editor Ed George for the opportunity to
discuss the paper by Kang and Schaeffer.

The authors' paper provides a review of double
robust (equivalently, double-protected) estimators of
(i) the mean ?jl ? E(Y) of a response Y when Y is miss
ing at random (MAR) (but not completely at random)
and of (ii) the average treatment effect in an observa
tional study under the assumption of strong ignorabil
ity. In our discussion we will depart from the notation
in Kang and Schaeffer (throughout, K&S) and use cap
ital letters to denote random variables and lowercase
letter to denote their possible values.

In the missing-data setting (i), one observes n i.i.d.

copies of O = (T,X,TY), where X is a vector of al
ways observed covariates and T is the indicator that the

response Y is observed. An estimator of ?i is double
robust (throughout, DR) if it remains consistent and

asymptotically normal (throughout, CAN) when ei
ther (but not necessarily both) a model for the propen

sity score tc(X) = P(T = l\X) = P{T = 1|X, Y) or

all candidate estimators that depend on a linear logistic
maximum likelihood estimate of the propensity score,
including all the DR estimators considered by the au
thors.

Near the end of their Section 1, the authors state
that their simulation example "appears to be precisely
the type of situation for which the DR estimators of
Robins et al. were developed." They then suggest that
their simulation results imply that the cited quotation

from Bang and Robins (2005) is incorrect or, at the
very least, misguided. We disagree with both the au
thors' statement and suggestion. First, the cited quote
neither claims nor implies that when a linear logistic
model for the propensity score and a linear model for
the mean of Y given X are moderately misspecified,
DR estimators always outperform estimators?such as
regression, maximum likelihood, or parametric (multi
ple) imputation estimators?that do not depend on the
estimated propensity score. Indeed, Robins and Wang
(2000) in their paper "Inference for Imputation Estima
tors" stated the following:

If nonresponse is ignorable, a locally semi

a model for the conditional mean m(X) = E(Y\X) ?
E(Y\X, T ? 1) is correctly specified, where the equal
ities follow from the MAR assumption. The authors

parametric efficient estimator is doubly pro
tected; i.e., it is consistent if either a model

for nonresponse or a parametric model for

demonstrate, via simulation, that when a linear logis
tic model for the propensity score and a linear model
for the mean of Y given X are both moderately mis
specified, there exists a joint distribution under which
the OLS regression estimator ?oLS of /x outperforms

the complete data can be correctly spec
ified. On the other hand, consistency of
a parametric multiple imputation estimator
requires correct specification of a paramet
ric model for the complete data. However,

in cases in which the variance of the 'in

James Robins is Professor, Department of Epidemiology,

verse probability' weights is very large, the
sampling distribution of a locally semipara
metric efficient (augmented inverse proba
bility of response weighted) estimator can
be markedly skew and highly variable, and
a parametric imputation estimator may be
preferred.

Harvard School of Public Health, Boston, Massachusetts
02115, USA (e-mail: akaris@hsph.harvard.edu). Mariela
Sued is Assistant Professor, Facultad de Ciencias Exactas y
Naturales, Universidad de Buenos Aires and CONICET,
Argentina. Quanhong Lei-Gomez is a Graduate Student,
Department of Bio statistic s, Harvard School of Public

Health, Boston, Massachusetts 02115, USA. Andrea
Rotnitzky is Professor, Department of Economics, Di Telia
University, Buenos Aires, Argentina.

The just-quoted cautionary message of Robins and
Wang (2000) is not far from K&S's take-home mes

544
This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

COMMENT 545
sage. In Section 5 we show that, in the authors' simu

which Y is observed only when T ? 1, such optimiza

lation example, the variance of the estimated "inverse
probability" weights is very large and the sampling dis
tribution of their candidate DR estimators is skewed

well on the data ((1 - T)Y, T, X) in which Y is ob

and highly variable. It follows that their example is
far from the settings Bang and Robins had in mind
when recommending the "routine use of DR estima

on data ((1 - T)Y, T, X) rather than data (TY, 7\ X),

tors." Rather, their example falls squarely into the class

tion would not guarantee that ?Iols would also perform
served only when T = 0. Based on this insight, in Sec
tion 5, we repeat K&S's simulation study, except based

and show that, indeed, fioLS is now outperformed by
all candidate DR estimators in terms of both bias and

for which Robins and Wang (2000) cautioned that a

MSE.

parametric imputation estimator may be preferable to

nitzky and colleagues had published extensive warn

In the analysis of real, as opposed to simulated data,
we do not know a priori whether the features of the
joint distribution of (Y, T, X) do or do not favor pioLS>
Furthermore, with highly variable "inverse probabil

ings about, and simulation studies of, the hazards of
highly variable "inverse probability" weights (Robins,

ity" weights, we generally cannot learn the answer
from the data, owing to poor power. This suggests

DR estimators.

Even prior to Robins and Wang (2000), Robins, Rot

Rotnitzky and Zhao, 1995, pages 113-115; Scharf
stein, Rotnitzky and Robins, 1999, pages 1108-1113),
although not specifically for DR estimators. Due to the
fact that the problem of highly variable weights was
not the focus of their paper and had already been dis
cussed extensively in earlier papers by Robins and col
leagues, Bang and Robins (2005) did not repeat Robins
and Wang's (2000) cautionary message. In retrospect,

had they done so or had the authors been aware of

that, with highly variable weights, a single estimator,
whether (iols or a single DR estimator of the mean ?x is

never adequate even with MAR data; rather an analyst
should either "not attempt to make inference about the
mean" or else provide a sensitivity analysis (in which
models for both the propensity score and the regression
of Y on X and estimators of ?jl are varied). In Section 6,
we sketch a possible approach to sensitivity analysis.
In this discussion we ask the following question: can

the Robins and Wang article, a misunderstanding could
perhaps have been averted.

we find DR estimators that, under the authors' cho

Whenever the "inverse probability" weights are
highly variable, as in K&S's simulation experiment,

most as well as ?Iols applied to data (TY, T, X) and
yet perform better than ?Iols when applied to data
((1 ? T)Y, T, X). In Section 4 we describe the princi
ples we used to search among the set of possible DR
estimators and discuss the expected performance of
various candidates. We define a general class of DR

a small subset of the sample will have extremely large
weights relative to the remainder of the sample. In this
setting, no estimator of the marginal mean ?i ? E(Y)
can be guaranteed to perform well. That is why, in such
settings, some "argue that inference about the mean
E(Y) in the full population should not be attempted,"

to quote from the authors' discussion. Yet, surpris
ingly, in the authors' simulation experiment, the regres
sion estimator ?Iols performed very well with a mean

sen joint distribution for (Y, T, X), both perform al

estimators, which we refer to as "bounded," that con
tains the DR estimators that perform best in the setting

of highly variable "inverse probability" weights. We
further subdivide the class of bounded DR estimators

into two subclasses?bounded Horvitz-Thompson DR

squared error (MSE) less than any of their candidate
DR estimators, all of which estimated the propensity
score by maximum likelihood under a linear logistic
model. The explanation is that, whether due to unusual

perform particularly poorly in settings with highly vari

luck or to "cherry-picking," the chosen data-generating
distribution was as if optimized to have ?Iols perform

able "inverse probability" weights. The performance
of our estimators is examined in the simulations re

sen distribution and show that it possesses a number

ported in Section 5, which both mimics the simula
tions in S&K and also repeats it but now using data

well. Indeed, in Section 5, we "deconstruct" the cho
of specific, some rather unusual, features that together
served to insure ?Iols would perform well even under

K&S's misspecified models.
Now, even were the chosen joint distribution of
(7, 7\ X) optimized to have ?Iols perform extremely

well as an estimator of E(Y) on data (TY, T, X) in

estimators and regression DR estimators. We then de
scribe various scenarios which favor one subclass over
the other. We also explain why certain DR estimators

?1-T)Y,T,X).

A major point emphasized by K&S was that, in

their simulations, the regression estimator ?Iols out
performed any DR estimator when both their model for

the propensity score and for the regression of Y on X
(from now on referred to as the "outcome model") were

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

546 J. ROBINS, M. SUED, Q, LEI-GOMEZ AND A. ROTNITZKY
misspecified. However, they restricted attention to lin
ear logistic propensity score models. In Section 3, we
show that ?Iols is CAN for ?i when either (but not nec
essarily both) a linear model for the inverse propensity

score, \/tt{X) ? X7a, or a linear model XT? for the
conditional mean E(Y\X) is correctly specified. That
is, by definition, ?Iols itself is a DR estimator of \x
when the inverse linear model tt(X) = \/(XTa) for

Most of the DR estimators of \x discussed by K&S
are of the general form

pLDR(?,M)=Fn{rn(X)} + Fn
or

(D

XT? and the model n(X) = l/(Xra) are both mis
specified. Yet, under their scenario, ?Iols did not "out
perform any DR estimator that is CAN when either the

regression model XT? or the model t?(x) = \/(xTa)
is correctly specified," precisely because ?Iols is one

such DR estimator! Of course, the model n(X) =

\/(XTa) would rarely, if ever, be used in practice as
the model does not naturally constrain n(X) to lie in
[0, 1]. Nonetheless, understanding that ?Iols is a DR
estimator provides important insight into the meaning
and theory of double-robustness.

2. GENERAL FORM OF DOUBLE-ROBUST

ESTIMATORS

The authors note that many different DR estimators

exist and give a number of explicit examples. The au
thors restrict attention to MAR data with missing re

sponse. In this setting Robins (2000), Robins (2002),
Tan (2006) and van der Laan and Robins (2003) had
previously proposed a rather wide variety of DR es
timators, in addition to the DR estimators of Robins

and colleagues considered by the authors. Moreover,
Scharf stein et al. (1999) and van der Laan and Robins
(2003) provided general methods for the construction

of DR estimators in models with MAR or coarsened
at random (CAR) data. Robins and Rotnitzky (2001)
described a general approach to the construction of DR
estimators (when they exist) in a very large model class
that includes all MAR and CAR models as well as cer

tain nonignorable (i.e., non-CAR) missing data mod
els. Recently, van der Laan and Rubin (2006) have de
veloped a general approach called "targeted maximum
likelihood" that has overlap with methods in Scharf

stein et al. (1999), Robins (2000, 2002) and Bang and
Robins (2005) in the setting of missing response data.

We will use the general methods of Robins and Rot
nitzky (2001) to find a candidate set of DR estimators
among which we then search for ones that perform in
simulations as well as or better than those discussed by

S&K.

MX)

[Y-rn(X)}

?B-DR(n,m) = f)n{m(X)}

the propensity score is substituted for K&S's linear lo

gistic model!
In K&S's simulation experiment, the linear model

T

?n[T/7c(X){Y-m(X)}]
?n{T/(n(X))}

where throughout, ?n(A) is a shortcut for n~l
X^=1A;. Robins, Sued, Lei-Gomez and Rotnitzky

(2007) show that these estimators are solutions to
particular augmented inverse probability weighted
(AIPW) estimating equations. The AIPW estimating
equations are obtained by applying the general meth

ods of Robins and Rotnitzky (2001) to the simple
missing-data model considered by K&S.
Quite generally, to construct m and ft we specify
(i) a "working" parametric submodel for the propen
sity score n(X) = Pr(7 = 1|X) of the form

(2) jr(.)e{n(.;a):aeRq},
where n(x\a) is a known function, for example,
it(x\ a) = {1 + exp(?xTa)}~1 as in S&K and, (ii) a

working parametric model for m(X) = E(Y\X) of the

form

(3) m(.)e{m(-,?):?e

where m(x\ ?) is a known function, for example,

m(x; ?) = xT? as in S&K. We then obtain estim

tors a and ? which converge at rate n1^2 to some con
stant vectors a* and /3*, which are, respectively, equa
to the true value of a and/or ? when the correspond
ing working model is correctly specified, and define

rh(x) =m(x\ ?) and n(x) = tt(x; a). [In fact, unde

mild additional regularity conditions, the rate n1//2 ca
be relaxed to n^, ? > 1/4, a fact which is critical when

the dimensions p and q of ? and a are allowed to i
crease with n as np, p < 1/2.]
Under regularity conditions, if either (but not nec

essarily both) (2) or (3) is correct, ?iDR(?, ) an

??B-DR(?, <) are consistent and asymptotically normal
(CAN) estimators of ?x.

In the special case in which (a) 7t(x;a) = {1
exp(?xTa)}~1 and m(x\ ?) ? <b(xT?) where O is

known canonical inverse link function, and (b) ?

the MLE of a and ? is the iteratively reweighted least
squares estimator of ? among respondents (throughout
denoted as J?reg) satisfying

(4) Fn[TX{Y-<S>(XT?REG)}] = 0,

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

COMMENT 547
we shall denote m with yyireg and the resulting DR esti
mators as \xdr(tt, rriREG) and ?B-DR(n, wreg)- When
<3> is the identity, ?REG is thus the OLS estimator of ?.

In such case, Pldr(^^reg) is the estimator denoted
??C-OLS in S&K and jIb-dr?^, ^reg) is the estimator
in the display following (8) in S&K.

3. ?IOLS AS A DR ESTIMATOR UNDER A LINEAR

INVERSE PROPENSITY MODEL

As anticipated in Section 1, in this section we will
argue that the regression estimator ?Iols is indeed a
DR estimator with respect to specific working models.
Suppose that we postulate the linear inverse propensity

model, that is, in (2) we take n(x; a) = \/(ctTx). It
follows from (4) that for any a e Q,

(5)

n(X\ a)

{Y-mREG(X)}

the last display is a convex combination of the ob
served F-values and thus always lies in the interval
ITmin, ?max] with endpoints the minimum and maxi
mum observed Y-values. But, [Ym{n, YmSLX] is included
in the parameter space for ?jl because ?jl is the popula
tion mean of Y.

Note that division by Fn{T/ft(X)} is essential to
ensure that (6) is in [Fmin, rmax]. In particular, the

Horvitz-Thompson estimator {?ht = 'Pn{YT/n(X)}

does not satisfy this property. For example, if Y is
Bernoulli, (6) lies in [0, 1] but ?Iht may lie outside
[0, 1]. For instance, this will be the case if in the sample

there exists a unit with T ? 1, ?(X) < \/n and Y = 1
since then ?Iht will be greater than 1. Indeed, when
we carried out 1000 Monte Carlo replications of Kang
and Schaeffer's simulation experiment for sample size

= 0.

Thus, the regression estimator {Iols is indeed equal

to jlDR(i?(-;a),mREG) for any a and therefore DR
with respect to the linear inverse propensity model
^sub,inv and the outcome model <&(xT?) = xT?.
To estimate a in model ?PSub,inv we may use ei

n = 1000 using their misspecified analysis model for
7t(x), we found in one particularly anomalous replica
tion, a simulated unit with T ? 1 but with the unusually

small estimated propensity ft(X) < 1/17,000. Thus,

had we simulated Y from a Bernoulli rather than from
a normal distribution, we would have had ?Iht > 17 for
this anomalous replication!

The desire that an estimator falls in the interval

ther the estimator ainv or the estimator ?inv that, re

[^rnin, ^max] is in conflict with the desire that it be

spectively, minimize the log-likelihood Fn[T log{Ti(X;

unbiased, as we now show. Suppose the propensity
score function n(x) were known. The set of exactly
unbiased estimators of /x (that are invariant to per
mutations of the index / labeling the units) are con

a)} + {1 ? J}log{l ? n(X',a)}] or squared norm
Wn[{n(x.a) - Ifflll2 both subject to the constraints
n(Xi\ ot) > 0, / = 1,..., N. Under regularity condi

tions, ainv and ?inv converge in probability to quan
tities a*nv and a**w with the property that when model
^sub,inv is correctly specified, n(X; afm) and it(X\ afn* )

are equal to the propensity score P(T ? l\X).

4. DOUBLE-ROBUST ESTIMATORS WITH

DESIRABLE PROPERTIES

4.1 Boundedness
We would like to have DR estimators of \i ? E(Y)
with the "boundedness" property that, when the sam
ple space of Y is finite, they fall in the parameter space
for ?jl with probability 1. Neither ?jldr(?,mREG) nor

?B-DR(n,inREG) has this property. We consider two
separate ways to guarantee the "boundedness" prop
erty.

First, suppose that we found DR estimators that

could be written in the IPW form

(6) Fn{YT/?(X)}/?n{T/?(X)}
for some nonnegative ?(-). Then the property would
hold for such estimators. Specifically, the quantity in

tained in the set {Fn[T{Y - q(X)}/n(X) + q(X)]}

as q(X) varies. It follows that no unbiased estimator
of \x exists for Y Bernoulli that is guaranteed to fall

in |Tmin> imaxL Taking q(X) identically zero, we ob
tain ?Iht = Fn{YT/jr(X)}. Suppose that in an actual
study of 1000 subjects, a rare fluctuation had occurred
and there was a subject with T = 1 whose propensity
score rc(X) was less than 1/17,000 so ?Iht > 17. We
doubt any scientist could be convinced to publish the
logically impossible estimate ?Iht for the mean of a
Bernoulli F, with the argument that only then would
his estimator of the mean be exactly unbiased over hy
pothetical repetitions of the study that, of course, nei
ther have occurred nor will occur. Exactly analogous
difficulties arise for any other choice of q(X). With
highly variable weights, "boundedness" trumps unbi

asedness.

Second, the boundedness property also holds for DR
estimators that can be written in the regression form

(7) P,{m(X)}
with m(x) = <&(xT? + h(x)Ty) for some specified
function h(-) and an inverse link function O satisfying

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

548 J. ROBINS, M. SUED, Q. LEI-GOMEZ AND A. ROTNITZKY
inf Y < ?>(w) < sup Y for all w, where Y is the sample

space of Y. This follows because (i) Fn{fh(X)} falls
in the interval [mmin, mmax], with mm[n and mmax the

minimum and maximum values of m(X) among the n
sample units and, (ii) the above choice of <&(*) guar
antees that [mmjn, mmax] is contained in the parameter
space for \x.

Neither the estimator ^dr(^^reg) nor the estima
tor ??-DRi?.mREG) of Section 2 satisfies the "bound
edness" property. Note, however, that ?B-DR(u,fh)
satisfies \??-DR(n, w)| < max/=i,...>n |F? ? m(X/)| +

maxf^i,...^ |m(X/)|. Thus when F is Bernoulli and
m(X) = <I>(Xr?) for O any inverse link with range in
[0,1], we have that \?jlb-dr{u, rh)\ < 2, so it is within
a factor of 2 of lying in the parameter space. In con

trast, when Y is Bernoulli, ?1dr(?, m), like {?ht, can
be extremely large.
In the next sections, we describe general approaches
to constructing DR estimators that can be written in the
form (6) or the form (7). Thus it is important to deter
mine whether DR estimators that satisfy (6) perform

dents who have both very small values of ft(X) and
large residuals Y ? m(X).

4.1.1 Regression double-robust estimators. We re
fer to DR estimators satisfying (7) as regression DR
estimators. They are obtained by replacing mreg m
?DR(?,mREG) with rh(X) satisfying

(8)

T -{Y-m(X)}

Ltt(X)

0.

Here we describe three such estimators, though others

exist (Robins et al, 2007).

The first one, proposed in Scharf stein et al. (1999)

and discussed further in Bang and Robins (2005), is
the estimator in K&S's Table 8. To compute this es
timator one considers an extended outcome model of

the form $>(XT? + cpft(X)~l) adding the covariate
ft (X)~l (i.e., the inverse of the fitted propensity score).

One then jointly estimates (?,<p) with (?,<p) satisfy

ing wn[T{Y - ?(xT? + <pjz(xr1)} [?iYl}] = ?

The first row of this last equation is precisely (8)

better or worse than those satisfying (7) when mod

with rh(X) replaced with the fitted regression function

els for both m(-) and n{>) are wrong. Unfortunately,
no general recommendation can be given because the
answer will depend on the specific data generating
process and models used to estimate m( ) and ix{>). For
example, suppose that as in Kang and Schaeffer's sim
ulation experiment, Y is continuous, var(F|X) = a2
does not depend on X, i> is the identity link and we
estimate the model XT? for m(X) = E(Y\X) by OLS.
When (i) a2/Var(F) is near zero and (ii) there exist
a number of nonrespondent units j (i.e., units j with

ffiEXT-REG(X) = <P(XT? + $fi(X)~l). Consequently,
?DR(u, niEXT-REG) = ^n{mEXT~REG(X)}' This estima
tor is CAN provided either the model Tt(x;a) for
the propensity score it(x) or the model <P(xT?) for

Tj = 0) whose values xj of X lie far outside the con
vex hull of the set of values of X for the subsample
of respondents, then y? and m(xj) will be close to
one another but not to mreg?xj) except if, by luck,

the model E{Y\X) ? XT? is so close to being cor

rect that the fit of the model to the subsample of re
spondents allows successful linear extrapolation to X's
far from those fitted. As we shall see, it is precisely

such "luck" that explains the good performance of
?OLS in the authors' simulation experiment. Without

such luck, the estimator Pn{m/??o(X)} may perform

E(Y\X = x) is correct. In fact, it is CAN even if model

<i>(xT?) is incorrect provided the model <P(XT? +
<p{7t(X; a*)}-1) is correct, where a* is the probability
limit of the estimator a of a. In particular, as indicated
in the previous subsection, if Y is Bernoulli and 3> is

the inverse logit link, {idr(? ^ext-reg) is always in

[0,1].

Nonetheless, when Y is continuous and # is the

identity, \?jldr(?,mEXT-REG)\ can be disastrously large

when the estimated inverse probability weights ?
(X)~l are highly variable. Specifically, when ft(X)~l
is highly variable, it could very well happen that in
most repeated samples the largest value of ft~~~l among

nonrespondents is manyfold greater than the largest

value among the respondent subsample. [E.g., a typ
ical Monte Carlo replication of Kang and Schaeffer

poorly compared to Fn{YT/7t(X)}/?n{T/n(X)}, ow

under the wrong propensity score model had a largest
ft (X)~~l of 80 in the respondent subsample but a largest

ing to unsuccessful linear extrapolation. On the other

ft(X)~l of 1800 in the nonrespondent subsample.] In

hand, when cr2/Var(F) is close to 1 and very few

such cases, enormously greater extrapolation would be

vex hull of the set of X's in the respondents subsam
ple, Fn{tftREG(X)} will generally perform better than

?n{YT/n(X)}/Wn{T/Tt (X)},as the latter may be dom

model ?(XT?) to obtain fitted values for Y in the non
respondent subsample, clearly a problem if the extrap
olation model <&{XT? -\-(pft(X)~~1} is also wrong. This

inated by the large weights \/n(X) assigned to respon

phenomenon explains the disastrous performance of

units with T = 0 have values of X far outside the con

required with model <P{XT? + <pfi(X)~1} than with

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

COMMENT 549
??dr(u,wext-reg) observed in K&S's Table 8 when
both the model for the propensity score and the out
come model are wrong.
A second DR estimator with the regression form (7)
is immediately obtained by estimating the parameter

? of the model E(Y\X) = ?(XT?) with the weighted
least squares estimator ?wLS that uses weights \/ft (X).

By definition, the estimator ?wLS satisfies

T

7t(X)

{Y-<$>(XT?WLS)}X

= 0

model <i>(XT?) by adding the covariate ft(X) (rather
than its inverse) to obtain <&{XT? + cpft(X)} and then
jointly estimate (?, cp) with the estimator (?, cp) satis

fying

MX)

[y_0(X7 ? + yft(X)))

'n(XY = 0.
X

Because we have assumed the vector X has one com
ponent equal to the constant 1, (8) is satisfied with
rh(X) equal to mDR.IPW-NR(X) = ?{XT? + (pft(X)}.
Thus, ??DR(?,rnDR-iPW-NR) = Fh^dr-ipw-nr)- Fur

thermore, since by construction, ?n[T{Y ?

and consequently (8) is immediately true for rh(X)
?dr-ipw-nr(X)}] = 0, then ?mDr(t?,rhDR-IPW-NR) is

equal to rhwLs(X) = <?>(XT?wLs) when, as we
al equal to ?n{TY + (1 ? T)rriDR-ipw-NR(X)}. Be
also

ways assume in this discussion, the first component
cause ft(X) is bounded between 0 and 1, adding
of X is the constant 1. It therefore follows that when
the covariate ft(X) to model <&(XT?), in contrast to
model <&(XT?) has an intercept, ?jldr{? ,mwLs)
? ft(X)~x, does not induce model extrapolation
adding
^n( >WLs)- The estimator ?jldr(u, mwLs) is called
problems like the ones discussed above for ?1dr(^,
?WLS ?n K&S.
wext-reg)- We speculate that Pldr?^^dr-ipw-nr)
With highly variable fc(X)~l and incorrect mod
will behave much better than ?1dr(^, wext-reg) and

els for both tt(X) and E(Y\X), we would expect
possibly similarly to ?1dr(?,mwLs) when ?(X)~] has

?1dr(tc, fhWLS) to outperform ?1dr(u^ext-reg)
be variance. Indeed, we have observed this behavior
high
cause it does not have the severe extrapolation problem
in the simulation study of Section 5; however, due to
of ?jldr(? , wext-reg)' This expectation is dramatically
space limitations, results for ?jldr(^^ext-reg) were
borne out in K&S's simulations.
not reported as they were qualitatively similar to those
reported
in K&S.
Some years ago, Marshall Joffe pointed out to
us

the estimator ?1dr(^, wext-reg) with O the
that ?1dr(^', mwLs) was double-robust and asked us Finally,
if
identity
link
is also an example of a DR targeted max
it had advantages compared to ?Idr(?^ext-reg)- At
imum
likelihood
estimator of the marginal mean ?jl in
the time we had not realized that ?1dr(^,wext-reg)
the
sense
of
van
der Laan and Rubin (2006). We thus
would perform so very poorly in settings with highly
conclude
from the above discussion that with highly
variable 7r(X)-1, so we told him that it probably
of

variable ft(X)~l and incorrect parametric models for
fered no particular advantage. Based on our bad advice,

Joffe never published a paper on ?Idr?^, ?-wls)n(X)
as aand E(Y\X), certain targeted maximum likeli

hood estimators can perform much worse than the ad
DR estimator. To our knowledge, Kang and Schaeffer
hoc estimator ?jldr^^wls)
are the first to do so. We note that Kang and Schaeffer
do not consider ?1dr{^ , mwls) to be an AIPW DR esti
4.1.2 Bounded Horvitz-Thompson double-robust
mator. However, the above derivation shows otherwise.
estimators. We refer to DR estimators satisfying (6)
Even jIdr(A, m wls) may not perform well in some
as bounded Horvitz-Thompson DR estimators. They
are obtained by replacing ? in ?1b-dr(^^reg) with
instances. For example, if Var(F|X) = a2 is constant,
ftExT
satisfying
a21 Var(F) is near 1 and a number of nonrespondents

have X lying far outside the convex hull of the re
(9) P? {rhREG(X) - ?Lreg) (-7TT7 - 1
spondents' X values, then Pldr(?, ?wls) may perform
\7TeXT(X)

= 0

poorly. This is because the subjects who have the great

where pi reg ? ^nl^REG(X)]. We can obtain such a
est ft(X)~l in the respondents' subsample will have
kext(') by considering the extended logistic model
enormous leverage which can force their residual to

xext(X) ? expit{arX + <ph(X)} with h(X) a user

be nearly zero, which is a problem particularly when
supplied function and estimating cp with ?prop-greed

or2/Var(F) is near 1 and the model <&(XT?) is mis

solving

specified, as then extrapolation to the X's far from the
convex hull will be poor.

The third DR regression type estimator is an exten
sion of the estimator fapw-NR in Kang and Schaeffer.

To compute this estimator we extend the regression

T

1
nl\expit(?TX+ cph(X))
{rhREG(X) - ?Iols)

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

= 0

550 J. ROBINS, M. SUED, Q. LEI-GOMEZ AND A. ROTNITZKY

where ? is the MLE of a in the model n(X) =

expit(arX). Then tcext(X) = expit{arX +

(fPROP-GREEDh(X)} satisfies (9) and consequently
??b-dr{Uext,wireg) is of the form (6). A default
choice for h(X) would be itireg?^) ~ ??LS
Interestingly, the OLS estimator ?oLS can be viewed
not only as a DR estimator, as seen in Section 3, but

also as a bounded Horvitz-Thompson DR estimator!
Specifically, suppose that ?invis used to estimate a in
the propensity model 7t(X; a) as in Section 3, except
that without imposing the constraints, so that indeed,

<?mv solves 0 - PJt^^f) - 1}X]. Then
^Tt(X;?im)

iH?REGiX)- ?OLs)

response given the covariates (the latter referred to
throughout as the outcome model).
The estimators reported in rows 1 and 9, rows 3
and 11, rows 4, 12, 17 and 22 and rows 5, 13, 18 and
23 are, respectively, the estimators ?oLS, ?iPW-POP,

?BC-OLS and ??wls investigated by K&S. Through
out we use the notational conventions of Sections

2-4, and thus we rename ?jlbc-ols and fiwis with
??DR(n,rhREG) and ?DR(n,mwLs)> respectively. The
estimator ?jlht is the Horvitz-Thompson type estimator

f>n{TY/ft(X)}. All remaining estimators are DR esti
mators of ?i and are defined in Sections 2 and 4.

= 0

and ?oLS is equal to the inverse probability weighted
estimator

When both working models are correct, theory
indicates that all DR estimators are CAN, asymptot
ically equivalent, and efficient in the class of esti
mators that are CAN even if the outcome model is
incorrect. We were not surprised then to find that all

DR estimators reported in rows 4-8 of Table 1 per

7r(X;ainv) >' ^n(X;aim)

formed identically and were more efficient than the in

efficient IPW estimators ?ipw-POP and ?jlht- However,

Robins (2001) and van der Laan and Rubin (2006)
describe particular bounded Horvitz-Thompson DR
estimators /?/??) that are obtained by iterating to
convergence a sequence ?1^ of estimators that are
not themselves bounded Horvitz-Thompson estima

?OLS caught our attention. The estimator ?Iols is the
maximum likelihood estimator of /x, and hence effi

tors. However, the Robins (2001) estimator performed
poorly in our simulations (results not shown) and no

covariates. Thus, we would have expected it to have

simulation study of the van der Laan and Rubin (2006)

estimator has been published to our knowledge with
highly variable inverse probability weights. In fact, van

der Laan and Rubin (2006) describe an estimator /?(??)

that is simultaneously a bounded Horvitz-Thompson
and a regression DR estimator that is obtained by it
erating to convergence a sequence jx^ of estimators
without this dual property. Again we do not know of a
simulation study showing that the estimator generally
performs well in practice with highly variable inverse
probability weights.

5. SIMULATION STUDIES

the near-identical behavior of the regression estimator

cient, in a semiparametric model that assumes a para
metric form for the conditional mean of Y given the
smaller variance than that of the DR estimators of /x,

because when both the propensity score model and
the regression model are correct, the latter attains the
semiparametric variance bound in the less restrictive

(nonparametric) model that does not impose restric
tions on the conditional mean of Y. A closer exam

ination of the data generating process used by K&S
explains this unusual behavior. Under S&K data gen
erating process Y[ ? 210 + 13.7Z* + e\, where Z* =

2Zi/ + Yfj=2^ji ' with Zji, j = 1,..., 4, and ?/ mutu

ally independent iV(0, 1) random variables. But under

this process Z*, and hence Z? = (Zu, Zu, Z3;, Z4/),
is an essentially perfect predictor of F?: the residual

To investigate the nature of the surprisingly good
performance of the regression estimator ?Iols in the
simulation study of K&S and to evaluate the perfor

variance var(Y? \Zf) is equal to var(F/)/195. This strik

mance of the additional estimators described in Sec

versus the predicted values from the fit of the correct

tion 4, we replicated the simulation study of K&S.
Table 1 reports the Monte Carlo bias, variance and
mean squared error for twelve different estimators of

outcome model to the respondents in a random sample
of n = 200 units. Dark dots correspond to data points
of respondents. White dots correspond to the simulated

/x ? 210, sample sizes n = 200 and 1000 and the

missing outcomes F; of the nonrespondents plotted

four possible combinations of model specifications for
the propensity score and the conditional mean of the

against the predicted values Z\?. The white dots follow
nearly perfectly a straight line through the origin and

ing feature of K&S data generating process is illus
trated in Figure 1. The figure shows a scatterplot of Y

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

COMMENT
Table 1
Results for simulation study as in K&S

Row

Bias

Estimator

Sample size 200
Var

Both models right

1 pL0LS 0.13
2 ?jlht -0.08

5.97
148.92

3 ?lPW-POP -0.06

14.12

4 P>DR(fi,mREG) ?-13 5.96
5 ?DR(n,mWLS) 0.13 5.97

5.97
6 l?DR(?,tnDR-?pw-NR) 0.13

7 ??B-DR(?,mREG) 0.13
8 ?^B-DR^fiEXT^REG) ?-13

5.96
5.97

Both models wrong

9 ?OLS -0.39
10 ?Iht 16.87
11 ?iPW-POP 1-67
12 ??DR(?,mREG) -4.90
13 PDR(fi,mWLS) ~2m
14 ?DR(n,moR-ipw-NR) -1.76

10.91

4110.86
73.39

15 ??B-DR(?,mREG) ~3-82

16 ??-DR^EXT^REG) -2.25
7T-model right, outcome model wrong

17 ?>DR(fi,mREG) 0.55
18 ?DR(x,mWLs) 0.65
19 ?DR(n,mDR-ipW-NR) 0.06
20 piB-DR(?,mREG) 0.56
21 ?B-DR(nEXT,tnREG) 0.53

7T-model wrong, outcome model right

22 ?DR(n,mREG) 0.14
23 ?DR(n,mWLS) 0.13
24 ?iDR(?,mDR-IPW-NR) 0.13
25 ?B-DR(fi>>hREG) ?-13
26 ??B-DR(?EXT,mREG) 0.13

with slope 1 : the predicted values are essentially per
fect predictors of the missing outcomes! When the out
come and propensity score models are correctly spec
ified, the asymptotic variance of the DR estimator is

equal to var(Y) + var[7i(Z){l - n(Z)}-[ var(F|Z)].

When Z is a perfect predictor of Y, this variance re
duces to var(F), the variance of the standardized dis

145.93
10.70

11.82
40.07

11.77

MSE
5.98
148.92
14.13
5.98
5.98
5.98
5.98
5.98

-0.03
0.17

11.06
4395.39

-0.83
38.97

14.90
54.65
16.82

-13.91
-2.98
-2.49
-8.03
-3.33

76.17
169.91
14.74

11.82
8.82

12.12

11.51

11.83

5.95
5.97
5.97
5.96
5.96

5.97
5.98
5.98
5.97
5.98

7.39
9.41

Bias

9.24
7.40
9.69

-0.03

-0.03
-0.03
-0.03
-0.03
-0.03

4.81

0.07
0.16
-0.10
0.08
0.11

-0.03

-0.03

-0.03

-0.02

-0.02

Sample size 1000
Var
MSE
1.41

26.46
3.43

1.41

26.49
3.43
1.41
1.41
1.41

1.41
1.41
1.41
1.41
1.41

2.19
39933
108.86
6853.68
2.20
1.81
128.61
3.44

1.41

1.41

2.88
41452
131.95
7047.12
11.08

8.02

193.13

14.54

2.81
1.90
1.58
2.79
2.08

2.82
1.93
1.59

1.77

1.77
1.41

2.80

2.09

1.41
1.41
1.43
1.42

of the infeasible estimator ?Ifull- In our study we had
simulated the outcomes of the nonrespondents. Thus,

we were indeed able to compute ??full and its Monte
Carlo variance. As expected, the Monte Carlo variance
of ?FULL was essentially the same as that of ?iols for

both sample sizes.

Theory also indicates that the IPW estimators

tribution of ?FULL, the sample mean of Y of respon
dents and nonrespondents. This is not surprising be
cause it is well known that, when the outcome model

?ww-POP and ??ht of rows 2 and 3 should be CAN.
However, in our simulations, these estimators were
nearly unbiased but their sampling distribution was

is correctly specified, a DR estimator asymptotically
extracts all the information available in Z to predict
Y. Since the regression estimator ?iols cannot be more

skewed to the right and had very large variance. Fig
ure 2 shows smooth density estimators for these sam

efficient than ?Ifull, we conclude that ?Iols and the
DR estimators should have nearly identical variance

1000. The skewness and large variance of the IPW esti
mators were caused by few samples which had respon

when Z is an almost perfect predictor of Y and indeed

dents with large values of Y and very large weights

this variance should be also almost the same as that

pling distributions for sample sizes n ? 200 and n ?

I/ft. Specifically, in most samples, the true it values of

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

1.41

1.43
1.42

552

J. ROBINS, M. SUED, Q. LEI-GOMEZ AND A. ROTNITZKY

o

o
CO

o

LO

CN

O
O

>
O

o

o

100 150 200

250

300

predicted

o
m

o
o
co

o

o

CN

FlG. 1. K&S simulation experiment. Outcomes vs predicted values. Sample size 200. Top: correct y model. Bottom: wrong y model. Dashed
line is the line Y ? X. Dark dots: respondents. White dots: nonrespondents.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

COMMENT 553
the respondents were not too small, and consequently
the weights \/ft not too large, precisely because by
the very definition of n, having a respondent with a
small Tt is a rare event. In the data generating process
of K&S, Jt(Z) is negatively correlated with Y\ the cor

relation is roughly equal to ?0.6. Thus, in most sam
ples, the I/ft -weighted mean of the Y values of the

the sum of 7?7r?~ (F; ? m(Z?)) is almost zero regar
less of the model under which ? was computed. C

sequently, all DR estimators must be nearly the sam
as the infeasible full data sample mean ft full
Finally, turn to the case in which both propensi
score and the outcome models are wrong. The perfo

mance of the IPW estimators is disastrous as well

respondents tended to be smaller than ?. However, in a

that of the DR estimator in row 12 and, to a lesser

few samples, some anomalous respondent had a small
value of it. In the computation of ?m-, this anomalous
respondent carried an unusually large weight I/ft and
because his Y value tended to be larger than the mean

tent, that of the estimator in row 15. Figure 3 show
smooth density estimators of the sampling distri
tion of these four estimators when the sample size

/x, the estimator ??ht in those rare samples tended to be

substantially larger than ?. The skewness lessens as the

1000. The estimators [jlht and ?Iipw-pop have d
tributions heavily skewed to the right while the
timators ??DR(u,rnREG) and ?1b-dr(? ,rhREG) ha
distributions heavily skewed to the left. The sk

sample size increases because with large sample sizes,
the number of samples which have respondents with
small values of it also increases. The skewness is also

ness is far more dramatic for the estimators ?Xht a

substantially less severe for ?Iipw-pop compared to that

and ?JiB-DR(?,mREG), reflecting the fact that jlipw-P

of ?HT also as expected since, as discussed in Sec
tion 4.1, in any given sample, \?1ipw-pop\ is bounded
by the largest observed |F| value.
Although the Monte Carlo sampling distribution of
the IPW estimators gives a rough idea of the shape of
the true sampling distribution of these estimators, nei
ther the Monte Carlo bias nor the Monte Carlo variance

should be trusted. One thousand replications are not
enough to capture the tail behavior of highly skewed
sampling distributions, and as such cannot produce re
liable Monte Carlo estimates of bias, much less of vari
ance.

?jldr(u, reg) than for their counterparts ?ipw-P
and ?JLB-DR(?,mREG) are bounded in the sense

scribed in Section 4.1 while ?Xht and fXoR(ft,rriRE

are unbounded. [Indeed, to avoid distortions, in c

structing the density plots of ?jlht and ?Xor?tc, m r

we have omitted the extreme values of 5873 a

?2213, respectively, from one simulation replication
Rows 12 and 14 of Table 1 report that the Monte Ca
bias and variance indeed are even larger for n = 1
than for n ? 200. The extreme distribution skewnes

and the increase in bias and variance with sample siz
are explained as follows. As noted earlier, even wh
the tt's are estimated from a correct model, the dist

bution of ?Iht and ?ipw-POP will tend to be skew

Turn now to the case in which the propensity score
to the right when l/n is positively correlated with
model is correct but the outcome model is incorrect.
because of the presence of a few unusual samples wi
Theory indicates that the DR estimators of rows 17 to
anomalous respondents with large Y values and smal
21 of Table 1 should be CAN. However, in our simula
71 values. Now, because of the nature of the wrong a
tions nearly all the DR estimators were slightly
biased
alytic
propensity score model used in the simulation
upward. Nevertheless, all DR estimators performed
as
the estimated
? 's corresponding to the anomalous un
well as or better, in terms of MSE, than the OLS esti
in the unusual samples were many times smaller th
mator of row 9.
the true 7r's. As a consequence the, usually large, v
Consider now the case in which the propensity
uesscore
of Y of the anomalous units essentially determin
model is incorrect but the outcome model is correct.
the values of ?Xht and fiipw-POP in the unusual samp
Once again, the almost identical performance ofand
all consequently,
DR
exacerbated even more the ske
estimators in rows 22-26 of Table 1 with that of the
ness of the Monte Carlo sampling distribution of th
OLS estimator of row 1 is no surprise after recalling
IPW estimators. The larger bias and variance wh
that Z is a perfect predictor of Y. Specifically, the
n ?fact
1000 than when n ? 200 were due to two re
that Z* is a nearly perfect predictor of 7/ implies
that with sample size 1000 in which the values
cations
rh(Zi) is almost identical to the outcome Y? regardless
the estimators were extreme [specifically, ?Xht ? 1
of whether unit / is a respondent or a nonrespondent
and 2884, and iXDR(n ,mREG) = -2213 and -17
and regardless of whether m(Z[) was fit by ordinary
These outlying values were caused by one anomalo
least squares or by weighted least squares. Thus,
the
nonrespondent
in each sample with large values o
average of ra(Z?) is essentially the same as ?xfull
andsecond largest Y values in one sample and t
(the

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

J. ROBINS, M. SUED, Q. LEI-GOMEZ AND A. ROTNITZKY

Sample size 200 Sample size 1000

200 210 220 230

200 250 300
?uHT correct

fiHT correct

o.oo H
200

210
A

220 230

^IPW-POPcorrect

205

210

215

^IPW-POPcorrect

FIG. 2. Distributions of ?^T and friPW-POP under correct propensity score models.

largest in the other). For these units, the \/it values

were 38.7 and 50.9 but \/ft were 17,068 and 399, re
spectively. When the two samples with these anom
alous units were removed, the variance of the estima

tors ?Iht and ?DR(?,mREG) decreased to 6729 and
890, respectively. The paradoxical increase in Monte
Carlo variance with sample size is but another proof
that the Monte Carlo variance in simulations with 1000

replications is not a reliable estimator of the true vari
ance for estimators with highly skewed distributions.

The different directionality of the skewness of the IPW
and DR estimators is explained as follows. In the com

putation of ?DR(ft,mREG) and ?Xb-dr^t,rhREG) we
inverse probability weight the values of (v?ireg ? Y).

Consequently since, as indicated below, under K&S's
wrong analytic outcome model, ttireg was reasonably
bounded; thus, in the few unusual samples, the anom
alous units with small 7r's had large and negative val
ues of (rriREG ? Y) and produced extremely small val
ues of the DR estimators.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

COMMENT

555

0.10

0.08

0.02 H

0.00 H

TgtfiCMiOu uu uu?O ggi ti a

250

500 1000

300

/?Hr incorrect
One estimator with value 587

/U.niM,n?n
lIPW-POP incorrect

_J_L_

_l_L_

0.06

jfr 0.04 c

0

?
0.02

0.00

100 150 200

-300 -200 -100

1

100 200

?x incorrect
/Wincorrect
B-DR ? One estimator with value -2213 deleted

FIG. 3. Distributions of fr, ht > ?lPW-POP^ ?DR^ft > mRE?) and ??-DR(n, m reg) under incorrect propensity score and outcome models.

The performance of the remaining DR estimators in

rows 13, 14 and 16 is heterogeneous. Some, though
still biased, have bias and variance orders of mag
nitude smaller than the variance of the estimators
?XDR(JT,?iREG) and ?XB-dr(u^reg)
In a second simulation experiment described below,

correct we cannot expect to find a single clear winner.
The relative performance of the estimators will very

much depend on the data generating process and the
nature of the model misspecifications.

To understand why the regression estimator jXols

the relative performance of the DR estimators was

performed so remarkably well when both models were
wrong, we first note that because the outcome model

somewhat different than in this simulation study and,

was a linear regression model with an intercept fitted

as we explain later, better than that of the regression es
timator jXoLS- This attests to the obvious fact that when

by ordinary least squares in the respondent subsam
ple, the sum of the predicted values X'? and the sum

the propensity score and outcome models are both in

of F in the respondent subsample are the same. Thus,

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

556

J. ROBINS, M. SUED, Q. LEI-GOMEZ AND A. ROTNITZKY

oo % /
o

m
CM

150 200 250 300 350 400

450

predicted
Fig. 4. Y vs predicted values in one sample of size 1000 generated under K&S experiment. Dashed line is the line Y ? X. Dark dots:
respondents. White dots: nonrespondents.

frpLS = (n0bs/n)Yobs + (?miss/n) (X'/3)miss, where
(X'?)miss is the average of the predicted values for
the missing outcomes. The bias of ?jlols therefore de
pends on the bias of (Xf?)miss as an estimator of the
mean of Y in the nonrespondent subpopulation. If, due

either to good luck or "cherry picking," the predic
tion function xf? from a misspecified regression model

x'? successfully extrapolates to the covariates of non

respondents, even when these are far from the con
vex hull of covariates in the respondent subsample,
(Xf?)miss ? Fmiss will be roughly centered around 0,

and consequently ?Iols will be a nearly unbiased esti
mator of the mean of Y. We now show this phenom
enon explains the excellent performance of ?oLS in
Kang & Schaeffer's simulation. In Figure 4 we plot

see that the predicted values of the nonrespondents are
reasonably centered around the straight line even for
those points with predicted values far from the pre
dicted values of the respondents. In this sample, ?Xols
was 205.78, a far more reasonable value than those ob
tained for the IPW and just-mentioned DR estimators.

To demonstrate that ?Xols can have a substantially
worse performance than the DR estimators, we con
ducted a second simulation experiment. This second
experiment, like our first, redid K&S's simulation by
generating the data (F, T, X) from K&S's chosen dis
tributions. However, in our second experiment we ana
lyzed the data ((1 ? T)Y, T, X) in which F is observed
only when 7 = 0, rather than the data (7T, T, X) that
was analyzed by us in our first experiment and by

ted the outcomes Y versus the predicted values X'? in

K&S in their paper. [To do so, since the data ((1 ?
T)Y, T, X) can be recoded as ((1 - T)Y, 1 - T, X),

the previously mentioned unusual sample of size 1000

we simply recompute each of the estimators reported

with both the propensity and outcome models mis
specified, where ?m(u,mREG), ?B-DR(ftt?reg) and
the IPW estimators did disastrously due to the pres
ence of one anomalous unit with extremely small ft.
The dark dots correspond to the observed data values
of the respondents. White dots correspond to the ac
tual simulated missing outcomes Y of the nonrespon
dents plotted against the predicted values X'?. We can

in Table 1 except now we everywhere replace ? and
T by 1 ? Ti and I ? T.] The results are displayed in
Table 2. We observe that, with both models wrong, the

bias and MSE of ?Xols now exceed those of any DR
estimator!
As in our first experiment, due to the extreme vari
ability in the estimated "inverse probability" weights,
the DR estimators appear to have considerable finite

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

557

COMMENT
Table 2
T reversed
Results for simulation study as in K&S but with the roles of T and
1

Row

Estimator

Both models right

2

Bias
0.12

1 ?0LS

?m

3 ?lPW-POP

4 P>DR(?,mREG)
5 ?DR(n,mWLS)
6 ??R(n, ?iDR-IPW-NR)

7 ?B-DR(n,mREG)

8 ??-DR^EXT^REG)
Both models wrong

9 ?oES

10 ?HT

11 ?lPW-POP
12 ?DR(a,mREG)

-0.46
0.45
0.12
0.12
0.12

0.12
0.12

4.97
0.55
3.92
3.33

13 ?DR(n,mWLS)

3.17

15 ?B-DR(n,mREG)

3.32

14 ??Ri? ,mDR-IPW-NR)

16 ??-DR(fiEXT, mREG)
7i -model right, outcome model wrong

17 P>DR(fi,mREG)
18 ?DR(x,mWLS)

19 ?DR(n, ^dr-ipw-nr)
20 ??-DR(jt,mREG)

21 ??-DR(XEXT, mREG)
it -model wrong, outcome model right

22 ?DR(jt,mREG)
23 ?DR(u,mWLS)
24 ??R(n, rnDR-IPW-NR)

25 ?B-DR(n,mREG)

26 ??-DRiUEXT, mREG)

3.11
3.30

Sample size 200

MSE

Bias

5.96
49.14
14.76
5.96
5.96
5.96
5.96
5.96

5.98
49.36
14.96
5.98
5.97
5.97
5.97
5.97

-0.03
-0.24
0.05
-0.02

7.97

32.68
40.57
25.03
19.90
18.24
17.90
19.69
19.55

4.97
0.39
3.68
3.07
2.81
2.64
3.04
3.01

13.11

9.02

0.14
0.23

2.96
1.92

11.76

0.14

2.76

40.27

9.67
8.79
8.21
8.21

8.70
8.68

0.71
0.99
0.71
0.75
0.86

12.60
8.04
7.26
11.21
10.38

11.12

0.12

5.96
5.96
5.96
5.96
5.96

5.97
5.97
5.97
5.97
5.97

0.12

0.12

0.12

0.12

sample bias, especially at the smaller sample size of
200, when the propensity model is correct but the out
come model is wrong. In fact, this bias is larger than
it was in the first simulation experiment, which was to

be expected as the variability in the estimated "inverse
probability" weights was greater in the second than the

first experiment (data not shown).

6. SENSITIVITY ANALYSIS
Consider again the missing-data setting with the
mean ? of Y as the parameter of interest. When the
covariate vector X is high dimensional, one cannot be
certain, owing to lack of power, that a chosen model for

the propensity score is nearly correct, even if it passes

standard goodness-of-fit tests. Therefore a large num
ber of models for the propensity score with different

Sample size 1000
Var
MSE

Var

7.76

-0.02

-0.02

-0.02

-0.02

0.18

1.41
8.45

3.11

1.41
1.41
1.40
1.41
1.40
1.91

6.27

2.22
2.12

1.97
1.97

2.10
2.10

1.72

0.18

2.71

-0.02

1.40

-0.02

1.40
1.40
1.40

-0.02

-0.02

-0.02

1.40

subsets of the covariates, different orders of interac
tions and different dimensions of the parameter vec
tor should be fit to the data. Similarly, many different
outcome models should be fit. This raises the question:
once fit, how should these many candidate models be
used in the estimation of the mean of F?

One approach is to use modern techniques of model

selection to choose a single propensity and outcome
model. Specifically, there has been a recent outpouring

of work on model selection in regression. This work
has shown that one can use cross-validation and/or pe

nalization to empirically choose, from among a large
number of candidates, a model whose predictive risk
for the response variable in the regression is close
to that of the best candidate model. In fact, van der
Laan (2005) has proposed that fc-fold cross-validation
should be routinely employed to select the model for

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

1.41

8.51
3.12

1.41
1.41
1.41
1.41

1.41

26.62
6.43
15.79
11.53
9.84
8.94

11.34

11.16
2.98
1.97
1.75
2.78
2.74
1.41
1.41
1.41
1.41
1.41

558 J. ROBINS, M. SUED, Q. LEI-GOMEZ AND A. ROTNITZKY
the propensity score and for the outcome regression

that are to be used in the construction of a DR esti
mator.

An alternative approach which we are currently
studying is the following. Suppose one has fit Jp
propensity score models and J0 outcome models. For
a favorite DR estimator /x, define ?ij as the DR esti
mator that uses the fitted values from the /th propen

sity model and the jth outcome model. Now, if the
/th propensity model is correct, all J0 estimators in

the set 8pj = {?ij; j = 1,..., J0} will be CAN es

timators of ?. Thus, an a -level test of the homo

geneity hypothesis Hpi : EA(?n) = EA(?ij) for all
j e {2,..., J0} [where EA(>) stands for large sample
mean, i.e., the probability limit of ] is also an a-level
goodness-of-fit test for the propensity model that is di
rectly relevant to its use in a DR estimator of ?. Sim

ilarly if the jth outcome model is correct, all Jp es
timators in the set 80j = {?ij', i = 1,..., Jp] will be
CAN for ? and a test of the homogeneity hypothesis

H0j : EA(?}j) = EA(?ij) for all /e{2.Jp] is a
test of fit for the outcome model. This suggests that
one could choose as a final estimator of ? the DR esti

mator ?i*j*, where /* is the / for which the test of the

hypothesis Hp? gave the largest p-value and j* is the j
for which the test of the hypothesis H0j gave the largest

??-value. However, this method of selecting /* and j*
is nonoptimal for two reasons. First, it could easily se
lect a misspecified propensity model / for which the
power of the test of the hypothesis Hp? is particularly
poor and similarly for the outcome regression. This re
mark implies that some measure of the spread of the

elements of 8pj and 80j should also contribute to
the selection of /* and j*. Second, the method does
not exploit the fact that if /* and j* are correct, then

EA(?lij*) ? EA(?li*j) for all / and j, suggesting that
an optimal method should select /* and j* jointly. Al

ternative approaches for selecting /* and j* will be
reported elsewhere. In any case, the very fact that input

to the selection algorithm requires the matrix ?ij pro
vides an informal sensitivity analysis; we directly ob
serve the sensitivity of our DR estimator to the choice
of propensity and outcome regression model.
The approach just described could also be combined

of the particular DR estimator might be included by
using a number of different DR estimators and select
ing among or averaging over DR estimators that give
similar estimates /i/*y*.

van der Laan (2005) has proposed some new ap

proaches to model selection for DR estimation that
go beyond his above-mentioned approach, which we
do not discuss here due to space limitations. Finally,
Wang, Petersen, Bangsberg and van der Laan (2006)
have proposed using the parametric bootstrap to study
the sensitivity of DR estimates to highly variable "in
verse probability" weights.

7. FURTHER CONSIDERATIONS
Estimation of Causal Effects
K&S briefly touch on the problem of estimating the
difference of the outcome means corresponding to two

treatments in an observational study under ignorabil
ity. This difference is often referred to as the average

causal effect (ACE). K&S view the problem of esti
mating ACE essentially as two missing-data problems,
each one regarding the outcomes of subjects that do not
follow the treatment of concern as missing. The differ
ence of the DR estimators of the separate means serves
as an estimator of the mean difference ACE. However,
the difference of the two DR estimators will have poor

small sample behavior if there is incomplete overlap
of the estimated propensity scores in the treated and
untreated. In fact, in the presence of incomplete over
lap, most investigators argue against trying to estimate

ACE and in favor of estimating the causal effect in
the subpopulation of subjects with overlapping propen
sity scores. However, assuming the ACE parameter is
of some substantive interest, Robins et al. (2007) sug
gest an alternative to reporting the difference of two

DR estimators of the separate means. Their approach
is based on fitting a linear semiparametric regression
model for the unknown conditional effect function en
coding the dependence of the conditional treatment ef
fect on the baseline covariates X. Their model has the

with the model selection approach. Specifically, one

property that it is guaranteed to be correctly specified
under the null hypothesis that the conditional effect
function is the zero function. Robins et al. (2007) show

Jp and J0 propensity and outcome models (the ones
with the Jp and J0 lowest cross-validated risk esti

that this strategy results in estimators of the ACE that
greatly outperform any estimator based on the differ
ence of double-robust estimators, whenever the model

first uses cross-validation to choose not one but rather

mates) out of a much larger number of candidate mod
els and next, one uses these Jp +J0 models as input for
the approach described above. Sensitivity to the choice

for the conditional effect function is correctly speci
fied; in particular, when the aforementioned null hy
pothesis is true.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

COMMENT 559

REFERENCES

Multiple Robustness
Consider again the MAR missing-data model with X
very high dimensional (say 20-100 continuous covari
ates) so we cannot possibly hope to model the propen
sity score or the outcome regression nonparametrically.
Double-robust estimators of the mean ? of Y are nx/2

consistent if either one of two parametric models is
correct but inconsistent if both models are misspeci
fied. This property of DR estimators seems unsatisfac
tory, as it means that one does very, very well if one of

Bang, H. and Robins, J. M. (2005). Doubly robust estimation in
missing data and causal inference models. Biometrics 61 962

972. MR2216189

ROBINS, J. M. (2000). Robust estimation in .sequentially ignor
able missing data and casual inference models. Proc. Amer. Sta
tist. Assoc. Section on Bayesian Statistical Science 1999 6-10.
Robins, J. M. (2002). Commentary on "Using inverse weighting
and predictive inference to estimate the effects of time-varying
treatments on the discrete-time hazard", by Dawson. and Lavori.

Statistics in Medicine 21 1663-1680.

the two models is correct but can do very, very poorly
when both are incorrect. Might we do better?
Define an estimator to be m-robust for ? at rate na
if the estimator is na -consistent for ? when any one of
m parametric models is correct, but inconsistent if all

Robins, J. M. and Rotnitzky, A. (2001). Comment on "Infer
ence for semiparametric models: Some questions and an an

m models are misspecified. A DR estimator is then a
2-robust estimator with a = 1/2. Our view is that an

Robins, J. M., Rotnitzky, A. and Zhao L.-P. (1995). Analysis

m-robust estimator with m large, even though this may

require a to be much smaller than 1/2 and so entail
a much slower rate of convergence, would usually be
preferable to a DR estimator for the following two rea
sons. First, if one uses an m-robust rather than a DR
estimator, one is more likely to be using a consistent
estimator of ? (as it is always more likely that at least
one of m, rather than one of two, models is correct).
Second, the slower rate of convergence (under the as
sumption one of the m models is correct) will result
in wider nominal confidence intervals than the usual

nominal intervals of length l/n1^2 associated with a

DR estimator. Such a wide interval seems to us a more

appropriate measure of the actual uncertainty about /x,
more accurately reflecting the fact that our estimator

could even be inconsistent if all m models are incor
rect.

These observations raise the following questions.
Do m-robust estimators exist for arbitrarily large m
if we are willing to sacrifice n1^2-consistency for na

consistency with a perhaps much smaller than 1/2?
What is the maximum value of a we can achieve for
a given m? If m-robust estimators exist for m > 2,
how do we construct them? Answers to these ques
tions can be found in Robins, Li, Tchetgen and van
der Vaart (2007), where it is shown that, under weak
assumptions, (i) m-robust estimators exist for all m,

(ii) m-robust estimators are (m ? 1) dimensional U

swer," by P. J. Bickel and J. Kwon. Statist. Sinica 11 920-936.

MR1867326

Robins, J. M. and Wang, N. (2000). Inference for imputation
estimators. Biometrika 87 113-124. MR1766832
of semiparametric regression models for repeated outcomes in
the presence of missing data. J. Amer. Statist. Assoc. 90 106

121.MR1325118
Robins, J. M., Li, L., Tchetgen, F. and van der Vaart,

A. W. (2007). Higher order influence functions and minimax
estimation of nonlinear functionals. In IMS Lecture Notes
Monograph Series Probability and Statistics Models: Essays in
Honor of David A. Freedman 2 335-421.

Robins, J. M., Sued, M., Lei-Gomez, Q. and Rotnitzky, A.
(2007). Double-robustness with improved efficiency in missing
and causal inference models. Technical report, Harvard School
of Public Health.

ROSENBAUM, P. R. (2002). Observational Studies, 2nd ed.
Springer, New York. MR1899138

Scharfstein, D. O., Rotnitzky, A. and Robins, J. M.
(1999). Adjusting for nonignorable drop-out using semipara
metric non-response models (with discussion). /. Amer. Statist.

Assoc. 94 1096-1146. MR1731478

Tan, Z. (2006). A distributional approach for causal inference us
ing propensity scores. /. Amer. Statist. Assoc. 101 1619-1637.

MR2279484

van der Laan, M. J. and Robins, J. M. (2003). Unified Meth
ods for Censored Longitudinal Data and Causality. Springer,
New York. MR 195 8123

van der Laan, M. J. and Rubin, D. (2006). Targeted max
imum likelihood learning. U.C. Berkeley Division of Biosta
tistics Working Paper Series. Available at http://www.bepress.
com/ucbbiostat/paper213/.

van DER Laan, M. (2005). Statistical inference for variable
importance. U.C. Berkeley Division of Biostatistics Working
Paper Series. Available at http://www.bepress.com/ucbbiostat/
paper 188/.

Wang, Y., Petersen, M., Bangsberg, D. and van der

statistics, for which explicit closed-form expressions

Laan, M. (2006). Diagnosing bias in the inverse probability of

ten less than 1/2 and sometimes much less. How
ever, the finite sample properties of m-robust esti
mators have yet to be studied even by simulation.
Thus we will have to wait to see if they are as use
ful in practice as theory would indicate they should

mental treatment assignment. U.C. Berkeley Division of Biosta

are given, and (iii) the maximal possible a is of

treatment weighted estimator resulting from violation of experi

tistics Working Paper Series. Available at http://www.bepress.
com/ucbbiostat/paper211/.

be.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:59:18 UTC
All use subject to https://about.jstor.org/terms

