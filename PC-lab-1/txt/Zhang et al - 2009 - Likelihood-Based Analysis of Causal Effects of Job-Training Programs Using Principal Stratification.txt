Journal of the American Statistical Association

ISSN: 0162-1459 (Print) 1537-274X (Online) Journal homepage: https://www.tandfonline.com/loi/uasa20

Likelihood-Based Analysis of Causal Effects of JobTraining Programs Using Principal Stratification
Junni L. Zhang, Donald B. Rubin & Fabrizia Mealli
To cite this article: Junni L. Zhang, Donald B. Rubin & Fabrizia Mealli (2009) Likelihood-Based
Analysis of Causal Effects of Job-Training Programs Using Principal Stratification, Journal of the
American Statistical Association, 104:485, 166-176, DOI: 10.1198/jasa.2009.0012
To link to this article: https://doi.org/10.1198/jasa.2009.0012

Published online: 01 Jan 2012.

Submit your article to this journal

Article views: 501

Citing articles: 34 View citing articles

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=uasa20

Likelihood-Based Analysis of Causal Effects of
Job-Training Programs Using Principal Stratification
Junni L. ZHANG, Donald B. RUBIN, and Fabrizia MEALLI
Government-sponsored job-training programs must be subject to evaluation to assess whether their effectiveness justifies their cost to the
public. The evaluation usually focuses on employment and total earnings, although the effect on wages is also of interest, because this effect
reflects the increase in human capital due to the training program, whereas the effect on total earnings may be simply reflecting the increased
likelihood of employment without any effect on wage rates. Estimating the effects of training programs on wages is complicated by the fact
that, even in a randomized experiment, wages are ‘‘truncated’’ (or less accurately ‘‘censored’’) by nonemployment, that is, they are only
observed and well-defined for individuals who are employed. In this article, we develop a likelihood-based approach to estimate the wage
effect of the US federally-funded Job Corps training program using ‘‘Principal Stratification’’. Our estimands are formulated in terms of: (1)
the effect of the training program on wages for those who would be employed whether they were trained or not, also called the survivor
average causal effect (SACE), and the proportion of people in this category; (2) the wages when trained for those who would be employed
only when trained, and the proportion of people in this category; (3) the wages when not trained for those who would be employed only when
not trained, and the proportion of people in this category; (4) the proportion of people who would be not employed whether trained or not.
We conduct likelihood-based analysis using the EM algorithm, and investigate the plausibility of important submodels with scaled loglikelihood ratio statistics. We also conduct a sensitivity analysis with respect to specific parametric assumptions. Our results suggest that all
four types of people [(1)–(4) previously] exist, which is impossible under the usual monotonicity assumptions made in traditional
econometric evaluation methods.
KEY WORDS: Monotonicity assumption; Principal stratification; Rubin Causal Model; Treatment effect on wages.

1. INTRODUCTION AND BACKGROUND
We evaluate the effects of a randomized job-training program, an issue that has generated a large literature bridging
statistics and economics (e.g., Heckman and Robb 1985;
Heckman and Hotz 1989; Angrist, Imbens, and Rubin 1996;
Heckman, Ichimura, Smith, and Todd 1998; Dehejia and
Wahba 1999; Abadie, Angrist, and Imbens 2002). To garner a
comprehensive understanding of the effects of a job training
program, we need to estimate its effects, not only on employment and income, but also on wages, which provides useful
information to policy makers because it allows them to
undertake a more complete cost-benefit analysis. Also, it helps
them understand whether any earning gains due to the program
are obtained by raising individual human capital, and thus
wage rates, or by increasing total hours of work. Disentangling
these effects is crucial to understanding how a program works
to change and improve future job training programs.
Complications arise because, for those who are not employed,
wages are neither observed nor well-defined. Here, we show a
principled way to deal with ‘‘truncation due to death,’’ meaning
no wages are defined for those who are not employed, which is a
problem often encountered in causal inference, for example
when evaluating the effects of a therapy on the quality of life of
survivors. There are other complicating issues that deserve
consideration when evaluating social experiments, namely,

Junni L. Zhang is Associate Professor, Department of Business Statistics and
Econometrics, Guanghua School of Management, Peking University, Beijing
100871, P. R. China (E-mail: zjn@gsm.pku.edu.cn). Donald B. Rubin is John L.
Loeb Professor, Department of Statistics, Harvard University, 1 Oxford Street,
Cambridge, MA 02138 (E-mail: rubin@stat.harvard.edu). Fabrizia Mealli is
Professor, Department of Statistics, University of Florence, Viale Morgagni 59,
Florence 50134, Italy (E-mail: mealli@ds.unifi.it). Junni L. Zhang’s research is
sponsored by Chinese NSF grant 10401003 and NIH 1 R03 TW007197-01A2.
Donald B. Rubin’s work was partially supported by a US NSF grant
SES-05-50887 and NIH grant R01 DA023879-01. Fabrizia Mealli’s research
was partially supported by an ESF-CNR and a MIUR-COFIN grant
2005131989_003.

missing outcome data and noncompliance with assigned treatment. Although a truly satisfactory substantive analysis would
address all issues simultaneously, to do so is quite complicated
and obscures the advantages of the principled way to deal with
‘‘truncation due to death.’’ Even though treatment is randomized, employed treated participants and employed controls are
not fully comparable because those two groups are formed by
conditioning on employment status, which is a posttreatment
measurement (Rosenbaum 1984). As noted also by Lalonde
(1995) in the context of training programs, the observed and
unobserved characteristics of those who are employed in the
treatment and control groups are likely to differ, and thus a
simple comparison of the employed groups is misleading for
inference about treatment effects on wages.
Here, we use an approach based on the framework of the
Rubin Causal Model (Rubin 1974; Holland 1986), where the
causal effects are defined by comparisons of potential outcomes for a common set of units (Rubin 1974, 1978, 2005). We
treat the wages for those who are not employed as being
‘‘truncated by death’’ (Zhang and Rubin 2003; Zhang, Rubin,
and Mealli 2008), and apply principal stratification (Frangakis
and Rubin 2002) to evaluate the Job Corps training program.
Job Corps stands out as the nation’s largest, most comprehensive education and job training program for disadvantaged
youth between the ages of 16 and 24. The program provides a
wide range of services: basic education, vocational skills training, health care, education, and counseling. Each year, Job Corps
serves more than 60,000 new participants in approximately 120
centers nationwide, at a cost of about USD 1.5 billion (Burghardt
et al. 2001; Burghardt, McConnell, and Schochet 2003). We use
data from the National Job Corps Study, conducted by Mathematica Policy Research, Inc. for the U.S. Department of Labor,
to provide information for Congress and program managers

166

 2009 American Statistical Association
Journal of the American Statistical Association
March 2009, Vol. 104, No. 485, Applications and Case Studies
DOI 10.1198/jasa.2009.0012

Zhang, Rubin, and Mealli: Likelihood Analysis of Causal Effects of Training Programs

to assess how well Job Corps achieves its goal of helping
participants become more responsible, employable, and productive citizens. The study is based on a national random sample
of all eligible applicants in late 1994 and 1995. Sampled youth
were assigned randomly to a program group or a control group.
Consistent with the program’s aim, key outcomes of interest are:
employment status, total earnings, and wages. In the empirical
analysis, we focus on the effect of the program on wages,
although the effect on employment is also a relevant and automatic output of our analysis.
Following Frangakis and Rubin (2002), we classify the individuals into four principal strata according to the joint values of
the potential outcomes of employment status when assigned to be
trained and when not assigned to be trained. For an estimand to be
a causal effect it must compare outcomes under treatment and
control on a common set of units (Rubin 1974; Holland 1986;
Frangakis and Rubin 2002; Rubin 2005). Thus causal effects of
assignment to training can be obtained by comparing outcomes
when assigned training and outcomes when assigned control for
people belonging to the same principal stratum. Because wages
are only well-defined for those who are employed, we can only
estimate effects of the program on wages for those who would be
employed whether they were assigned to be trained or not. For
people who would be employed only when assigned to be trained
or only when assigned not to be trained, we can only estimate the
wages or labor earnings under one treatment arm. For people who
would not be employed whether assigned to be trained or not,
there are no associated wages. The fact that proper causal effects
can only be defined and estimated for one latent subgroup of units
is a limitation created by the truncation mechanism, rather than a
drawback of the framework of principal stratification.
A related approach is used in Lee (2005) to derive bounds on
the average treatment effect on wages for the specific principal
stratum of the always employed, also called the ‘‘survivor
average causal effect’’ (SACE) in Rubin (1998, 2000), where
the term ‘‘survivor’’ arises from the medical version of this
problem, where the ‘‘always employed’’ group comprises those
who would survive under either treatment condition, and Y
measures quality of life (Rubin 2006). Lee’s bounds, however,
are a special case of those derived in Zhang and Rubin (2003)
when the monotonicity assumption is made, which excludes
the existence of people who would be employed if not assigned
to be trained but not employed if assigned to be trained.
In the econometric literature, ‘‘truncation by death’’ is often
known as sample selection (Heckman 1974), and sample
selection models are often used to address this complication
(Heckman 1979; Vella 1998). A standard parametric selection
model can be specified as follows. For individual i, let Zi be the
indicator of treatment assignment; let Si be the observed
employment indicator; and let Yi be the individual’s wage,
which is only observed if Si ¼ 1. The selection model assumes
that there exists an underlying regression relationship
logðY i Þ ¼ b0 þ b1 Z i þ X 1i b þ u1i ;
where the dependent variable Yi is observed only if Si ¼ 1, and
Si is governed by the selection equations:
Si ¼ 1 if Si $ 0;
Si ¼ 0 if Si < 0;

167

where Si ¼ g0 þ g1 Z i þ X2i g þ u2i is a never observed continuous latent variable underlying the observed employment
indicator; X1i and X2i are two possibly overlapping sets of
covariates; and u1i and u2i are variables assumed to have some
parametric joint distribution (e.g., normal with mean 0 and
covariance matrix S). Extensions of this typical selection
model include semiparametric models (Ahn and Powell 1993;
Vella 1998; Das, Newey, and Vella 2003), models with heterogeneous treatment effects, and in particular, models with two
versions of the Si ; Si, and log(Yi) corresponding to the
‘‘potential outcomes’’ associated with the two treatment levels
Zi ¼ 0 and Zi ¼ 1 ([ Si ð0Þ; Si(0), log(Yi(0))] and [ Si ð1Þ; Si(1),
log(Yi(1))]), which are defined shortly.
If joint normality is assumed for log(Yi) and Si ; identification
is driven by this assumption, and even in cases where normality
holds, identification is usually weak, and estimates can be very
sensitive to the inclusion/exclusion of covariates and their
interactions (see e.g., Little 1985; Copas and Li 1997). Consequently, in practice identification of selection models typically relies on specifying covariates in X2 that are
‘‘instruments’’ in the sense that they determine the employment
status but do not affect wages given covariates X1 in the wage
equation (Wooldridge 2002). However, finding realistic instruments is not an easy task, and in many examples the required
‘‘exclusion restrictions’’ have very little justification. In fact,
background variables that are typically collected are plausibly
related to both employment and wage rates. In addition,
monotonicity, which rules out the existence of the subgroup of
people for whom training is not beneficial in terms of employment, is almost always assumed.
For the effects of the program based on the subset of data
used by Lee (2005), our results show that the data strongly
support the existence of all four latent groups, meaning that
there is a group of individuals, about 8%, for whom assignment
to training is harmful in terms of employment. The size of the
group for whom the program is beneficial in terms of
employment is about 7%; the effect on wages for the always
employed group, whose size is about 51%, is negligible.
Around 4 years after participation in the program, earnings
gains appear to be due to an increasing number of hours of
work rather than to an increase in wages.
This article proceeds as follows. In Section 2 we review the
principal stratification approach, as well as identification issues
underlying the differences between the principal stratification
approach and traditional selection models. In Section 3 we
present the empirical evaluation of the effect of the program
studied here, and discuss sensitivity of the results to certain
parametric assumptions. In Section 4 we discuss generalizations of the results and conclude.
2. THE PRINCIPAL STRATIFICATION APPROACH
2.1 Principal Strata and Observed Groups
Let N denote the total number of individuals in the experiment. For individual i, let zi denote the indicator of treatment
assignment, where z denotes the vector of zi for all N individuals. For individual i, let Si(z) denote the indicator of employment given assignment z, and let Yi(z) denote the wage given
assignment z; Si(z) and Yi(z) are called potential outcomes,

168

Journal of the American Statistical Association, March 2009

because only one value, that corresponds to the observed z, can
be observed.
The terminology of ‘‘potential outcomes’’ is due to Neyman’s
use of ‘‘potential yields’’ in a randomized agricultural trial
(Neyman 1923) for randomization-based inference.
Assumption 1 (Stable Unit Treatment Value Assumption,
SUTVA). If zi ¼ z0 i ; then Si(z) ¼ Si(z9) and Yi(z) ¼ Yi(z9), no
matter how z and z9 are chosen, and this holds for all i ¼ 1, . . ., N.
SUTVA (Rubin 1980) implies, first, that potential outcomes
for individual i are unaffected by the treatment assignments of
other individuals, i.e., that there is no interference between
units. If N is small relative to the total number of people who
are eligible for the training program, the no interference part of
SUTVA is plausible because the potential outcomes for individual i would depend more on the whole job market and not on
the other individuals’ assignments in the experiment. If N is
large relative to the total number of eligible people, however,
SUTVA may fail because, e.g., of the possible displacement
effects of the training program. SUTVA also implies that there
are no hidden versions of the treatments that would result in
different outcomes than represented by the Si(z) and Yi(z), such
as effective and ineffective training programs, both available to
person i, but not distinguished in our notation.
Throughout this article, we assume SUTVA, which allows us
to write Si(z) and Yi(z) unambiguously as Si(zi) and Yi(zi)
respectively. Therefore, for individual i, Si(1) is the employment indicator under treatment, Si(0) is the employment indicator under control, Yi(1) is the wage under treatment, and Yi(0)
is the wage under control. For those who are not employed, the
wages are not defined on Rþ (the set of positive real numbers),
so we treat the wages for those who are not employed as
‘‘truncated’’ by nonemployment following Zhang and Rubin
(2003), and define them to be *, using the extended sample
space {Rþ, *} for wages: Yi(1) ¼ * if Si(1) ¼ 0 and Yi(0) ¼ * if
Si(0) ¼ 0.
A direct application of principal stratification implies that
the individuals can be classified into four principal strata
according to the joint values of the two potential employment
indicators:
d

d

d

d

EE ¼ {i|Si(1) ¼ Si(0) ¼ 1}, those who would be employed
regardless of treatment assignment, for whom Yi(1) 2 Rþ
and Yi(0) 2 Rþ; suppose the proportion of people in EE is
pEE;
EN ¼ {i|Si(1) ¼ 1, Si(0) ¼ 0}, those who would be
employed under treatment but not employed under control, for whom Yi(1) 2 Rþ and Yi(0) ¼ *; suppose the
proportion of people in EN is pEN;
NE ¼ {i|Si(1) ¼ 0, Si(0) ¼ 1}, those who would not be
employed under treatment but employed under control,
for whom Yi(1) ¼ * and Yi(0) 2 Rþ; suppose the proportion of people in NE is pNE;
NN ¼ {i|Si(1) ¼ Si(0) ¼ 0}, those who would not be
employed regardless of treatment assignment, for whom
Yi(1) ¼ Yi(0) ¼ *; suppose the proportion of people in NN
is pNN.

Because we cannot observe both Si(1) and Si(0), we generally cannot observe the principal stratum for individual i. The

treatment effect on wages for individual i is equal to Yi(1) 
Yi(0), which is defined on R (the set of real numbers) only for
the EE group, and is not defined on R for the other groups.
Thus, the average treatment effect that is of primary interest is
YEE ð1Þ  YEE ð0Þ; the difference between the average Yi(1) and
the average Yi(0) for the EE group.
Whether the latent group EE is of substantial interest will
depend on the context, on its characteristics, and on its relative
size. Some labor economists might argue that wages for individuals who are not employed can indeed be defined, but
cannot be observed, because they are lower than their ‘‘reservation wage’’ (the lowest wage rate at which a worker would be
willing to accept a particular type of job), so that it could be
meaningful to talk about treatment effects on wages also for
individuals who are not employed (e.g., offered but refused
wages). Here we do not argue this point, but emphasize that, at
least in this experiment, individuals in the EN group are never
observed as employed when not in the program (and so their
wages are never observed when not in the program) and individuals in the NE group are never observed as employed when
in the program (and so their wages are never observed when in
the program), so only by adding assumptions about quantities
that are never observed in this experiment would it be possible
to use the observed data to estimate an effect of the program on
wages for the NE and EN groups.
We prefer to avoid a priori defining the problem in terms of
these assumptions; therefore for us, the most meaningful
inferences about the treatment effect on wages can be drawn
only for the EE group, because this is the only group for which
wages can be observed both under treatment and control.
However, our inferences about the other strata can also provide
interesting insights about the program, and the relative sizes of
the groups.
For individual i, let Zi be the indicator of observed treatment
assignment; the observed employment indicator and observed
wages are Sobs
¼ Si ðZ i Þ and Y obs
¼ Y i ðZ i Þ respectively; note
i
i
obs
that Si is related to Si in the selection model of Section 1.
Because we cannot observe both Si(1) and Si(0), we cannot
usually observe the principal stratum Gi for individual i. What
we can observe are the following four groups:
d

d

d

d

O(1, 1) ¼ {i|Zi ¼ 1, Sobs
¼ 1}, those who are assigned to
i
treatment and employed; suppose the proportion of people
observed in O(1, 1) is P11;
O(1, 0) ¼ {i|Zi ¼ 1, Sobs
¼ 0}, those who are assigned to
i
treatment and not employed; the proportion of people
observed in O(1, 0) is 1  P11;
O(0, 1) ¼ {i|Zi ¼ 0, Sobs
¼ 1}, those who are assigned to
i
control and employed; suppose the proportion of people
observed in O(0, 1) is P01;
O(0, 0) ¼ {i|Zi ¼ 0, Sobs
¼ 0}, those who are assigned to
i
control and not employed; the proportion of people
observed in O(0, 0) is 1  P01.

We assume either full compliance with treatment assignment
or, in the presence of noncompliance, focus on the effect of
treatment assignment, i.e., the Intention To Treat effect (ITT),
so that each individual is observed to fall into one of these four
groups, and also belongs to one latent group. Specifically, those
in O(1, 1) can be either in EE or EN; those in O(1, 0) can be

Zhang, Rubin, and Mealli: Likelihood Analysis of Causal Effects of Training Programs

either in NE or NN; those in O(0, 1) can be either in EE or NE;
and those in O(0, 0) can be either in EN or NN.

pEE þ pEN ¼
pNE þ pNN ¼

2.2 Identification of SACE
Without making any distributional assumptions, large sample bounds for SACE can be obtained, as in Zhang and Rubin
(2003), which also showed that other explicit assumptions can
be formulated to sharpen inferences about SACE. One such
assumption, monotonicity, states that the treatment is not
harming anyone in the sense that no individual would be
employed under control but not employed under treatment,
implying there is no NE group (see also Lee 2005). This
assumption is less plausible in the job training context than the
analogous monotonicity assumption typically made in instrumental variables (IV) analysis, e.g., with noncompliance to
assigned treatment (see Angrist, Imbens, and Rubin 1996),
because here monotonicity rules out, a priori, the possibility of
a negative treatment effect on employment, whereas in the IV
context the assumption rules out defiers, those who would do
the opposite of their assignment. It is plausible in practice that
there are individuals who would be employed under control but
not employed under treatment. For example, some people may
take any job that is available without training, but, after being
trained, choose to wait for a better job, and thus choose to be
not employed. Note that the standard selection model of Section 1 implicitly assumes monotonicity (i.e., no NE or no EN
group), depending on the sign of g 1.
Another assumption, considered in Zhang and Rubin (2003)
that can be used to sharpen bounds is ‘‘stochastic dominance.’’
Under this assumption, the wage distribution for the EE group
when trained is stochastically larger than the wage distribution
for the EN group when trained, and the wage distribution for
the EE group when not trained is stochastically larger than the
wage distribution for the NE group when not trained. Note that
our stochastic dominance assumption is related to, but different
from, both the perfect positive rank correlation (Heckman,
Smith, and Clements 1997) and the stochastic dominance
assumption in Manski (1995). Perfect positive rank correlation
is an assumption about the dependence between potential
outcomes across the treatment and control states, whereas our
stochastic dominance is an assumption about the distributions
of a potential outcome across two principal strata, but within
either the treatment or the control group.
To sharpen inferences with real data and finite samples, and to
derive unique maximum likelihood point estimates of the causal
parameters of interest, additional assumptions can be useful.
One possibility is to specify a parametric model and exploit
standard mixture model analysis (e.g., see Titterington, Smith,
and Makov 1985) for identification. For any principal stratum g
2 {EE, EN, NE, NN} and z ¼ 0, 1, let Yg(z) denote the wage
under treatment assignment z for a random member of g. We
now convey some intuition on why SACE ¼ YEE ð1Þ  YEE ð0Þ
can be consistently estimated by maximum likelihood when no
covariates are observed and parametric assumptions about
YEE(1), YEE(0), YEN(1), and YNE(0), such as log-normality, are
imposed. Because the treatment assignment is random, in large
samples, we have

pEE þ pNE ¼
pEN þ pNN ¼

169

P
Z Sobs
Pi i [ P11
Zi
P
Z i ð1  Sobs
i Þ
P
¼ 1  P11
Zi
P
ð1  Z i ÞSobs
i
P
[ P01
ð1  Z i Þ
P
ð1  Z i Þð1  Sobs
i Þ
P
¼ 1  P01 :
ð1  Z i Þ

ð1Þ

Suppose that all latent wage distributions are lognormal: then
the observed log(Yi(1)) for the O(1, 1) group follows a mixture of
two normal distributions, one for log(YEE(1)) and the other for
log(YEN(1)). Using standard normal mixture model analysis
(e.g., see also Aitkin and Rubin 1985; McLachlan and Peel
2000), we can estimate the proportions of the two components,
and therefore estimate pEE /pEN. Similarly, the observed
log(Yi(0)) for the O(0, 1) group follows a mixture of two normal
distributions, one for log(YEE(0)) and the other for log(YNE(0)),
and so we can estimate the ratio of pEE/pNE and its reciprocal.
Combining these two estimated ratios with the equations in (1),
we can uniquely estimate the p‘s. Except in the very special case
when pEE ¼ pEN or pEE ¼ pNE, we can uniquely estimate
YEE ð1Þ from the component with mixture proportion pEE/(pEE
þ pEN) in the distribution of the observed Yi(1) for the O(1, 1)
group, and YEE ð0Þ from the component with mixture proportion
pEE/(pEE þ pNE) in the distribution of the observed Yi(0) for the
O(0, 1) group.
The role and the nature of our parametric assumptions are
different from those in standard selection models: our assumptions are related to variables observed on meaningful
subgroups of individuals, rather than to error terms whose
meaning strongly depends upon, and varies with, functional
form details of the model specification. Within a fully parametric setting, we only need to specify the conditional distribution of principal strata given covariates and the distributions
of the outcome variables conditional on both the principal
strata and the covariates. For identification, no instrument is
required.
Covariates can be helpful for several reasons. First, they
generally improve the precision of parameter estimates because
they improve the prediction of the missing potential outcomes
(Y and S). Second, covariates generally make assumptions more
plausible, because they are conditional rather than marginal; in
addition, the use of covariates allows more plausible generalization to a population that differs in some ways from the one
under study, as will be discussed in Section 4.

2.3 Specific Parametric Models
The probabilities of the four principal strata can often be
usefully modeled using a multinomial logit:
exp ðbTg Xi Þ
PðGi ¼ gÞ ¼ P
; g 2 fEE; EN; NE; NNg;
T
g0 exp ðbg0 X i Þ
where the EE group is taken as the baseline group (bEE ¼ 0). A
probit model or its t-based extensions (Liu 2004) could also be
used. Under monotonicity, P(Gi ¼ NE) [ 0.

170

Journal of the American Statistical Association, March 2009

The log potential wages are often modeled using normal
linear regressions:
if Gi ¼ EE; log½Y i ð1Þ ; NðhTEE;1 X i ; s2EE;1 Þ; s2EE;1 > 0;
log½Y i ð0Þ ; NðhTEE;0 X i ; s2EE;0 Þ; s2EE;0 > 0;
if Gi ¼ EN; log½Y i ð1Þ ; NðhTEN;1 X i ; s2EN;1 Þ; s2EN;1 > 0;
if Gi ¼ NE; log½Y i ð0Þ ; NðhTNE;0 X i ; s2NE;0 Þ; s2NE;0 > 0:
The family of t-distribution-based linear regressions with
heavier tails could also be used (Liu and Rubin 1998). Under
stochastic dominance, restrictions are generated on the h‘s and
the s2’s (Zhang, Rubin, and Mealli 2008). The coefficients
other than the intercept in hEE,1 are constrained to be equal to
those in hEN,1, whereas the intercept in hEE,1 is constrained to
be no less than that in hEN,1; also s2EE;1 is constrained to be
equal to s2EE;1 : Similar constraints need to be imposed on hEE,0,
hNE,0, s2EE;0 ; and s2NE;0 :
Let u ¼ ðbEN ; bNE ; bNN ; hEE;1 ; s2EE;1 ; hEE;0 ; s2EE;0 ; hEN;1 ;
obs
2
sEN;1 ; hNE;0 ; s2NE;0 Þ. Let Sobs ¼ fSobs
¼
i ; i ¼ 1;    ; Ng; Y
obs
fY i ; i ¼ 1;    ; Ng; and X ¼ fXi; i ¼ 1;    ; Ng: The likelihood function is
Y
½pEE:i N i ðhTEE;1 Xi ; s2EE;1 Þ
LðujZ; Sobs ; Yobs ; XÞ}
i2Oð1;1Þ

þ
3

pEN:i N i ðhTEN;1 Xi ; s2EN;1 Þ3
Y

Y

ðpNE:i þ pNN:i Þ

i2Oð1;0Þ

½pEE:i N i ðhTEE;0 X i ; s2EE;0 Þ þ pNE:i

i2Oð0;1Þ

3 N i ðhTNE;0 X i ; s2NE;0 Þ

Y

ðpEN:i þ pNN:i Þ;

i2Oð0;0Þ

where pg:i ¼ P(Gi ¼ g|Xi, u) for g 2 {EE, EN, NE, NN}, and
Ni(m, t 2) denotes the probability density function of a normal
distribution with mean m and variance t 2 evaluated at
logðY obs
i Þ:
3. APPLICATION TO THE JOB CORPS STUDY
3.1 The Job Corps Job Training Program and Simple
Descriptive Analyses
Since 1993, Mathematica has conducted the National Job
Corps Study for the U.S. Department of Labor. Sampled youth
were assigned randomly to a program group or a control group.
Program group members could enroll in Job Corps; control
group members could not, although they could enroll in other
education and training programs in their communities. Impacts
on key outcomes have been estimated by comparing the
experiences of the program and control groups, for the full
sample and for key student subgroups. Program benefits,
measured in dollars, have also been compared with program
costs to assess the program’s cost effectiveness.
Previous Mathematica reports (Burghardt et al. 2001; Burghardt, McConnell, and Schochet 2003) presented findings based
on data from periodic surveys conducted over a 4-year interval
after random assignment. These reports stated that Job Corps
produced beneficial, statistically significant impacts on key outcomes: 12% earnings gains were reported during the last 2 years
of the survey period. On the basis of forecasts that these earnings
impacts would persist, Job Corps was found to be cost-effective.

As stated in the introduction, in this, as well as in many other
evaluation studies, there are usually three kinds of issues that
would require the use of principal stratification. Two of these
issues are missing outcome data and noncompliance with
assigned treatment, both of which generally require the use of
principal stratification, even if interest focuses only on the ITT
effect of the assignment (i.e., of the offer to be trained), as
pointed out in Frangakis and Rubin (1999). A third issue is
‘‘truncation’’ by nonemployment, meaning wages are undefined for those who are not employed. Although a truly satisfactory substantive analysis would address all three issues
simultaneously, to do so is quite complicated and obscures the
message of the principled way to deal with any one of them.
For examples of principled analyses that account for more than
one posttreatment complication, see Barnard, Frangakis, Hill,
and Rubin (2003) and Mattei and Mealli (2007). Consequently,
we will focus on just one issue here, ‘‘truncation’’ by nonemployment, and partially accept the methods used by Lee
(2005) to deal with the other two issues. A future effort of ours
will deal with all three problems simultaneously in a principled
manner. As does Lee (2005), we ignore noncompliance and
focus on ITT effects, that is, on effects of being offered
enrollment in Job Corps rather than participating in the program. We also focus on 10,542 participants who had observed
values for earnings and working hours for week 208. Table A.1
in the appendix presents descriptive statistics for the data. For
the treatment group and the control group, for baseline as well
as postassignment variables, it reports the proportion of participants with observed values for the specified variable, the
group mean and the group standard deviation. It also reports the
differences in the group means and associated standard errors.
None of the baseline covariates shows a substantial difference
between the program and control groups. In contrast, marginally, labor market outcomes in week 208 show substantial
differences between the treatment and the control groups—the
treatment group has higher weekly hours, higher earnings, and
a higher employment rate at week 208. We will investigate
whether the treatment improves employment rate and hourly
wage after controlling for covariates.
Unlike Lee (2005), who imputed the mean for missing values
of the baseline covariates, we multiply imputed missing covariate values using the multiple imputation (MI) procedure in
SAS (2004), which assumes that the covariates follow a multivariate normal distribution. For two of the baseline covariates,
‘‘earnings in previous year’’ and ‘‘usual weekly earnings,’’ we
used the logarithm transformation log(x þ 1). The imputed
values were then rounded to appropriate digits. The fractions of
missing information are very small, and there is essentially zero
variance between the results across the three imputed datasets;
thus, we describe results as if there were no missing data.
3.2 Principled Analysis Based on Principal Stratification
Based on the principal stratification model specified in
Section 2.3, we use the EM algorithm (Dempster, Laird, and
Rubin 1977) to find the maximum likelihood estimates (MLEs)
^ (details in the Appendix). As expected in
of parameters u
mixture models, we find that the likelihood function has multiple modes, and thus it cannot be approximated well by the

Zhang, Rubin, and Mealli: Likelihood Analysis of Causal Effects of Training Programs

171

Table 1. Values of the scaled log-likelihood ratio statistic for the general model versus various restrictions

2 log(L)/d.f.
d.f.

No EN
Group

No NE
Group

Stochastic
Dominance

AteE ¼ 0

SACE ¼ 0

AteE ¼ 0 and
SACE ¼ 0

22.8
59

13.1
59

12.9
58

0.9
29

1.2
30

1.1
59

The degrees of freedom are calculated as follows. Under the restriction that there is no EN group, bEN, hEN, 1 and s2EN;1 are eliminated, and therefore the number of parameters in u is 59
( ¼ 2 3 29 þ 1) fewer than that in the general model. Similarly, the number of parameters in u under the restriction that there is no NE group is 59 fewer than that in the general model.
Under the stochastic dominance restriction, there are 58 fewer parameters than in the general model, because there is one set of common values for the nonintercept coefficients in hEE,1
and hEN,1, or hEE,0 and hNE,0, and one common value for s2EE;1 and s2EN;1 ; or s2EE;0 and s2NE;0 : Under the restriction that AteE ¼ 0, there are 29 fewer parameters than in the general model,
because there is one set of common values for bEN and bNE. Under the restriction that SACE ¼ 0, there are 30 fewer parameters than in the general model, because there is one set of
common values for hEE,1 and hEE,0, and one common value for s2EE;1 and s2EE;0 : Under the combined restriction that AteE ¼ 0 and SACE ¼ 0, there are 59 ( ¼ 29 þ 30) fewer parameters
than in the general model.

standard asymptotic normal distribution. Confidence intervals
using bootstrap sampling (Efron and Tibshirani 1993) fail for
the same reason. Therefore, we prefer to focus on comparisons
of the maximized likelihood under the general model and under
various meaningful restrictions, and investigate whether there
is evidence that some restrictions implying more parsimonious
models might hold. Using direct likelihood inference and the
scaled log-likelihood ratio, we investigate whether the comparison of likelihood values would suggest the plausibility of
those more parsimonious models. This approach is in the spirit
of the direct likelihood approach advocated by Fisher (1921),
Barnard, Jenkins, and Winsten (1962), Barnard (1965), Hacking
(1965), Edwards (1972), Royall (1997), and recently discussed
in Boyles (2008). Indeed, we agree with Boyles (2008) that
‘‘with or without LL [‘‘law of likelihood’’ due to Fisher (1921)],
likelihood methods are often the only solutions for complex realworld applications,’’ except if the problem is attacked by a full
Bayesian approach, which brings more attendant complications.
Design weights need to be taken into consideration; if the
subjects are randomized only based on the observed covariates,
then the design weights can be ignored when conducting likelihood inference about u (Rubin 1976) (note that inference by
weighting each observation is usually inefficient as illustrated by
Basu’s well-known example (Basu 1971)). However, Schochet
et al. (2003) indicated that the design weights also depend on
whether the applicant ‘‘lived in one of the 57 areas sending the
largest number of nonresidential students to Job Corps’’ as well
as ‘‘the predictions made by Job Corps outreach and admissions
staff about whether each applicant was likely to be assigned to a
residential or nonresidential program slot.’’ The residential status of the applicants is not included in the list of covariates in
Table A.1, so the design weights cannot be ignored and are
therefore used as a covariate. We tried three forms—raw
weights, log weights, and inverse weights—and found that there
is little difference among results. We therefore only investigate
whether raw design weights should be included. The dimension
of u for the model including design weights is 207, including
7 3 29 parameters for the regression coefficients (bEN, bNE,
bNN, hEE,1, hEE,0, hEN,1, and hNE,0, each vector consisting of 27
coefficients for the covariates plus an intercept plus one coefficient 
for the design weight) and four parameters for the variances s2EE;1 ; s2EE;0 ; s2EN;1 ; and s2NE;0 : The parameters u for
the model without design weights exclude seven regression
coefficients. The scaled log-likelihood ratio statistic (which
under regularity conditions, which do not hold in our example,
has expectation one) that compares the model with raw design
weights to that without design weights is greater than six,

thereby suggesting that the design weights should be included.
We will only focus on the results using raw design weights as a
covariate.
The restrictions that we deem of important policy relevance
are as follows: (1) there is no EN group (one version of the
monotonicity assumption); (2) there is no NE group (the other
version of the monotonicity assumption); (3) stochastic dominance; (4) the average treatment effect on employment, denoted as AteE, is zero (and thus bEN ¼ bNE); (5) SACE ¼ 0 (and
thus hEE,1 ¼ hEE,0 and s2EE;1 ¼ s2EE;0 ); (6) AteE ¼ 0 and
SACE ¼ 0.
^ to estimate the quantities of
Now we discuss how to use u
interest in the population
from which the sample was drawn.

^ for g 2 {EE, EN, NE, NN}. The
Let p
^ g:i ¼ PðGi ¼ gX i ; uÞ
proportions
P of the four
P principal strata are estimated as
p
^ g ¼ f Ni¼1 W i p
^ g:i g=f Ni¼1 W i g for g 2 {EE, EN, NE, NN},
where Wi is the design weight for observation i. The average treatment effect on employment is estimated as
d ¼p
AteE
^ EN  p
^ NE : The average wage for the EE group under
treatment is estimated as


PN
T
2
^
W
p
^
exp
h
X
þ
0:5

s
^
i
EE:i
i
EE;1
EE;1
i¼1
d
AyeEEðTÞ
¼
:
PN
^ EE:i
i¼1 W i p
The average wage for the EE group under control (AyeEE(C)),
for the EN group under treatment (AyeEN(T)), and for the NE
group under control (AyeNE(C)) are estimated analogously.
The average treatment effect on wage for the EE group is
d
d
d ¼ AyeEEðTÞ
estimated as SACE
 AyeEEðCÞ:
Table 1 presents values of the scaled log-likelihood ratio
statistic for the general model versus models with policy-relevant restrictions. More specifically, it presents values of 2
log(L)/df, where L is the ratio of the maximized likelihood
under the general model and under a model with a specific
restriction, and df is equal to the difference of the number of
parameters in the models. Strong deviations from one of this
quantity provide evidence that the corresponding restrictions
are not supported by the data. Our findings suggest that
monotonicity (in both versions) and stochastic dominance are
restrictions that are not supported by the data, with corresponding values of the scaled log-likelihood ratio statistic
equal to 22.8, 13.7, and 12.9 respectively.
The restrictions of an average treatment effect on employment equal to 0 and of an average treatment effect on wages for
the EE group equal to 0 both appear to be plausible, and estimates of policy-relevant quantities under the general model,

172

Journal of the American Statistical Association, March 2009

Table 2. Maximum likelihood estimates under the general model
Estimands

ML Estimates

pEE
pEN
pNE
pNN
AteE
AyeEE(T)
AyeEE(C)
AyeEN(T)
AyeNE(C)
SACE

0.51
0.07
0.08
0.34
0.01
7.77
7.77
8.98
10.74
0.00

reported in Table 2, and under these restrictions were essentially the same. These estimates suggest that there is a positive
proportion ðp
^ EN  7%Þ of participants who benefited from the
assignment to the Job Corps training program in terms of
employment, and a positive proportion ðp
^ NE  8%Þ of participants who might have raised their reservation wages as a
consequence of the training, and refuse job offers that would
otherwise be accepted under control; this is consistent with the
finding that the NE group has a higher average hourly salary (of
approximately 10 USD) than both the EE and EN groups. As a
consequence, the effect of the training program on employment
appears to be negligible. There is also a large proportion
^ NN  34%Þ of individuals who would not be employed
ðp
irrespective of their treatment assignment. Most people
^ EE  51%Þ; however, would be employed irrespective of
ðp
their treatment assignment, but the average treatment effect on
wages for them appears to be zero. Note that this treatment
effect is the intention-to-treat effect, and it is possibly diluted
by noncompliance to treatment assignment. The average
training program’s effect on wages for the compliers might be
different, which is a subject for future investigation.

3.3 Sensitivity to the Logarithmic Transformation
to Normality
As explained in Section 2.2, parametric assumptions are
crucial to point-identify the SACE; consequently, we now
examine how sensitive our results are to the parametric
assumptions in Section 2.3, by considering Box-Cox transformations of wage other than the logarithmic transformation
used so far. Figure 1 plots the maximum log-likelihood against
the parameter l in the Box-Cox transformation, for l ranging
from 1 to 1 at incremental steps of 0.1, where l ¼ 0 corresponds to the logarithmic transformation. The log-likelihood
curve is rather flat between l ¼ 0.7 and l ¼ 0.4, with a
maximum obtained at l ¼ 0.4. For l values ranging from
0.7 to 0.4 and different from 0, Table 3 reports the scaled loglikelihood ratio statistics for the general model versus models
with various restrictions and maximum likelihood estimates of
AteE and SACE under the general model. The results are quite
similar to those obtained under l ¼ 0, and are thus robust with
respect to deviations from the log-normality assumption. The
monotonicity and stochastic dominance restrictions are not
supported by the data, but it is plausible that AteE ¼ 0 and
SACE ¼ 0. So our parametric specification seems not to be
contradicted by the data.
4. DISCUSSION
In this article, we applied a novel framework to estimate the
effects of job training on wages. Principal stratification allowed
us to define important and meaningful subpopulations of program participants, to express explicit behavioral assumptions
about them, and to analyze the data in more detail than is possible using traditional selection models. The causal effect of
training on wages is sought only for those who would be
employed under both treatment assignments, because only for
this subpopulation of units can wages be observed both when

Figure 1. Log-likelihood values for various Box-Cox transformation of the wage for 208.

Zhang, Rubin, and Mealli: Likelihood Analysis of Causal Effects of Training Programs

173

Table 3. Values of the scaled log-likelihood ratio statistic for the general model versus various submodels and estimates of AteE and SACE under
the general model for different values of l
2 log(L)/d.f.
l
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.1
0.2
0.3
0.4

No EN Group

No NE Group

Stochastic
Dominance

AteE ¼ 0

SACE ¼ 0

AteE ¼ 0 and
SACE ¼ 0

88.3
72.4
59.0
47.9
38.9
31.9
26.5
20.5
19.5
19.5
20.3

48.3
39.9
32.8
26.8
22.0
18.1
15.1
11.9
11.5
11.6
12.2

74.5
92.9
38.9
56.8
45.0
14.5
12.7
14.7
27.1
26.9
28.1

0.7
0.7
0.7
0.7
0.8
1.0
1.0
1.0
0.9
0.9
1.0

1.5
1.5
1.5
1.5
1.5
1.4
1.3
1.1
1.1
1.1
1.1

1.1
1.1
1.1
1.1
1.2
1.3
1.1
1.1
1.0
1.0
1.1

trained and when not trained, at least in the experiment under
study.
Principal stratification also allows conclusions from an
experiment to be more generalizable. In the Job Corps experiment, the participants are randomly drawn from the population
of eligible applicants, so here the experimental results can be
rather easily generalized to the target population. It is, however,
often the case that the composition of the participants in an
experiment is different from that in the target population. In
particular, the proportions of the four principal strata are likely to
differ in the experimental group and the target population. If we
assume that the conditional distributions of outcomes given both
the covariates and the principal strata are the same in the
experiment and the target population, then we can generalize the
conclusions from an experiment to a wider population with
different distributions of the covariates and of the principal strata
given the covariates. For example, the treatment effect on wages
for the EE group (i.e., SACE) may be generalizable to the EE
group in a population. Analogously, within cells defined by
covariates, inferences about SACE, the wages under treatment
for the EE group, the wages under control for the EE group, the
wages under treatment for the EN group, and the wages under
control for the NE group are more likely to generalize to other
populations.
The same principal stratification framework can be used in
other ‘‘truncation by death’’ situations, for example, when

AteE
0.00
0.00
0.01
0.01
0.01
0.01
0.02
0.01
0.01
0.01
0.01

SACE
0.00
0.09
0.10
0.11
0.11
0.09
0.07
0.01
0.03
0.03
0.01

evaluating the effects of hormone replacement therapy on
5-year cancer-free survival, or the effects of high school educational programs on final test scores. Some traditional biostatistical analyses in the context of medical studies are based
on the concept of ‘‘competing risks from different causes of
death,’’ and make similar structural assumptions as traditional
selection model analyses.
A possible contention from the research community
regarding our approach is that, in general, we cannot identify
which participant belongs to which principal stratum, and thus
we cannot draw unambiguous inferences about an individual
person’s causal effects. This contention has also characterized
the Instrumental Variable literature, where, under certain
assumptions, only the effect on the (principal) subpopulation of
compliers can be identified (Angrist, Imbens, and Rubin 1996).
Generally, we have no way to identify uniquely from the data
the principal stratum for any individual participant, but we can
still get information about the distribution of the principal
strata and about the causal effects defined for these strata, and
we can sharpen inferences by borrowing strength from other
participants having similar pretreatment covariates. As more
covariates are collected, we can get more precise predictions of
each individual’s principal stratum. The fact that proper causal
effects can only be defined and estimated for latent subgroups
of units is a limitation created by the truncation mechanism,
rather than a drawback of our approach.

174

Journal of the American Statistical Association, March 2009

APPENDIX A. SUMMARY STATISTICS OF THE NATIONAL JOB CORPS STUDY DATA
Table A.1. Summary statistics of the National Job Corps study data by treatment status
Treatment
Variable
Female
Age at Baseline
White, NonHispanic
Black, NonHispanic
Hispanic
Other Race/Ethnicity
Never Married
Married
Living Together
Separated
Has Child
Number of Children
Education
Mother’s Education
Father’s Education
Ever Arrested

Prop. obs.

Mean

Control
Std. dev.

Prop. obs.

Mean

Difference
Std. dev.

Diff.

Std. Err.

1.00
1.00
1.00
1.00
1.00
1.00
0.98
0.98
0.98
0.98
0.99
0.99
0.98
0.81
0.61
0.99

0.44
18.86
0.27
0.49
0.17
0.07
0.92
0.02
0.04
0.02
0.18
0.26
10.09
11.49
11.42
0.25

0.50
2.18
0.44
0.50
0.37
0.26
0.28
0.14
0.20
0.15
0.39
0.64
1.55
2.56
2.86
0.44

1.00
1.00
1.00
1.00
1.00
1.00
0.98
0.98
0.98
0.98
0.99
0.99
0.98
0.80
0.60
0.98

0.44
18.79
0.27
0.48
0.17
0.07
0.92
0.02
0.04
0.02
0.19
0.26
10.08
11.51
11.54
0.26

0.50
2.16
0.44
0.50
0.38
0.26
0.28
0.15
0.20
0.15
0.39
0.63
1.53
2.59
2.84
0.44

0.00
0.08
0.00
0.01
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.01
0.02
0.12
0.00

0.01
0.04
0.01
0.01
0.01
0.01
0.01
0.00
0.00
0.00
0.01
0.01
0.03
0.06
0.07
0.01

Household Inc.:
<3,000
3,000–6,000
6,000–9,000
9,000–18,000
>18,000

0.62
0.62
0.62
0.62
0.62

0.25
0.20
0.12
0.24
0.18

0.44
0.40
0.32
0.43
0.39

0.64
0.64
0.64
0.64
0.64

0.26
0.21
0.11
0.24
0.18

0.44
0.40
0.32
0.43
0.38

0.01
0.00
0.00
0.00
0.01

0.01
0.01
0.01
0.01
0.01

Personal Inc.:
< 3,000
3,000–6,000
6,000–9,000
>9,000

0.92
0.92
0.92
0.92

0.79
0.13
0.05
0.03

0.41
0.34
0.22
0.17

0.92
0.92
0.92
0.92

0.79
0.13
0.04
0.03

0.40
0.33
0.21
0.18

0.01
0.00
0.01
0.00

0.01
0.01
0.00
0.00

At Baseline:
Have Job
Had Job, Prev. Yr.
Months Employed, Prev. Yr.
Earnings, Prev. Yr.
Usual Hours/Week
Usual Weekly Earnings

0.97
0.98
0.94
0.92
0.96
0.95

0.21
0.65
3.80
2,876.72
22.56
111.11

0.41
0.48
4.28
4,319.19
20.90
121.02

0.97
0.98
0.94
0.92
0.96
0.95

0.21
0.64
3.80
2,834.87
22.12
109.38

0.41
0.48
4.32
4,395.94
20.74
116.61

0.00
0.01
0.01
41.86
0.44
1.72

0.01
0.01
0.09
92.46
0.43
2.46

After Random Assignment:
Week 208 Weekly Hours
Week 208 Weekly Earnings
Week 208 Being Employed
Number of Observations

1.00
1.00
1.00
4,163

27.71
227.43
0.61

26.02
249.35
0.49

1.00
1.00
1.00
6,379

25.85
202.67
0.57

26.26
230.03
0.50

1.87
24.76
0.04

0.53
4.83
0.01

NOTE: N ¼ 10,542. All means are weighted by the original sample design weights.

Zhang, Rubin, and Mealli: Likelihood Analysis of Causal Effects of Training Programs

APPENDIX B. THE EM ALGORITHM FOR FINDING
THE MLE

for i 2 Oð0; 1Þ; P½t ðGi ¼ EEÞ
½t

We will discuss the EM algorithm for the general model
without restrictions when the logarithmic transformation is
applied to wages. Let G denote the vector of Gi for all N
individuals. Treating G as the missing data, the complete-data
log-likelihood function is
obs

lðujZ; S

;Y

obs

; GÞ ¼

X

i2Oð1;1Þ

"


logðY obs
1
i Þ  hEN;1 X i
3 logðpEN:i Þ  logðs2EN;1 Þ 
2
2s2EN;1
X
W i IðGi ¼ NEÞ logðpNE:i Þ
þ

2½t

½tT

½tT

2½t

2½t

pNE:i N i ðhNE;0 Xi ; sNE;0 Þ
½t

½tT

;

½t

2½t

pEE:i N i ðhEE;0 Xi ; sEE;0 Þ þ pNE:i N i ðhNE;0 Xi ; sNE;0 Þ

;

P½t ðGi ¼ ENÞ ¼ P½t ðGi ¼ NNÞ ¼ 0;
pEN:i
½t
pEN:i

½t

þ pNN:i

;

pNN:i
½t

½t

pEN:i þ pNN:i

;

Determine u[tþ1] by maximizing Q(u|u[t]) with respect to u.
We can determine b½tþ1
ðg 2 fEN; NE; NNgÞ by maximizing
g
X

W i IðGi ¼ EEÞ

W i P½t ðGi ¼ EEÞ logðpEE:i Þ

i2Oð1;1Þ


2 #
logðY obs
1
i Þ  hEE;0 X i
2
3 logðpEE:i Þ  logðsEE;0 Þ 
2
2s2EE;0
X
W i IðGi ¼ NEÞ
þ

þ

X

W i P½t ðGi ¼ ENÞ logðpEN:i Þ

i2Oð1;1Þ

þ

i2Oð0;1Þ

X

W i P½t ðGi ¼ NEÞ logðpNE:i Þ

i2Oð1;0Þ


2 #
logðY obs
1
i Þ  hNE;0 X i
2
3 logðpNE:i Þ  logðsNE;0 Þ 
2
2s2NE;0
X
W i IðGi ¼ ENÞ logðpEN:i Þ
þ

þ

X

W i P½t ðGi ¼ NNÞ logðpNN:i Þ

i2Oð1;0Þ

þ

X

W i P½t ðGi ¼ EEÞ logðpEE:i Þ

i2Oð0;1Þ

i2Oð0;0Þ

W i IðGi ¼ NNÞ logðpNN:i Þ;

þ

i2Oð0;0Þ

where I is the general indicator function.
The EM algorithm starts with an initial value u[0]. Let u[t] be
the estimate of u at the t’th iteration, and iteration t þ 1 of EM
proceeds as follows:
E Step.

Find Q(u|u[t]), the conditional expectation of complete-data
log-likelihood given u[t] and the observed data. From (B.1), we
can see that this reduces to finding the conditional probabilities
of the principal strata:
for i 2 Oð1; 1Þ; P½t ðGi ¼ EEÞ
½t

¼

½tT

2½t

pEE:i N i ðhEE;1 Xi ; sEE;1 Þ
½t

½tT

½t

2½t

½tT

2½t

pEE:i N i ðhEE;1 X i ; sEE;1 Þ þ pEN:i N i ðhEN;1 X i ; sEN;1 Þ
½t

P½t ðGi ¼ ENÞ ¼

X

W i P½t ðGi ¼ NEÞ logðpNE:i Þ

i2Oð0;1Þ

ðB:1Þ

½t

½tT

M-step.

W i IðGi ¼ NNÞ logðpNN:i Þ

X

½t

2½t

P½t ðGi ¼ EEÞP½t ðGi ¼ NEÞ ¼ 0:

"

þ

½tT

2 #

i2Oð0;1Þ

"

½t

½t

i2Oð1;0Þ

X

2½t

pEE:i N i ðhEE;0 Xi ; sEE;0 Þ þ pNE:i N i ðhNE;0 Xi ; sNE;0 Þ
½t

P½t ðGi ¼ NEÞ ¼

P½t ðGi ¼ NNÞ ¼

i2Oð1;0Þ

þ

½tT

pEE:i N i ðhEE;0 Xi ; sEE;0 Þ

for i 2 Oð0; 0Þ; P½t ðGi ¼ ENÞ ¼


2 

logðY obs
1
i Þ  hEE;1 X i
3 logðpEE:i Þ  logðs2EE;1 Þ 
2
2s2EE;1
X
þ
W i IðGi ¼ ENÞ

X

¼

½t

W i IðGi ¼ EEÞ

i2Oð1;1Þ

þ

175

½tT

2½t

pEN:i N i ðhEN;1 Xi ; sEN;1 Þ
½t
½tT
2½t
pEE:i N i ðhEE;1 X i ; sEE;1 Þ

þ

½t
½tT
2½t
pEN:i N i ðhEN;1 Xi ; sEN;1 Þ

½t

P ðGi ¼ NEÞ ¼ P ðGi ¼ NNÞ ¼ 0;
½t

for i 2 Oð1; 0Þ; P½t ðGi ¼ NEÞ ¼

pNE:i
½t

pNN:i
½t

½t

pNE:i þ pNN:i

½t

pNE:i þ pNN:i

½t

P½t ðGi ¼ NNÞ ¼

;

P½t ðGi ¼ EEÞ ¼ P½t ðGi ¼ ENÞ ¼ 0;

;

;

þ

X

W i P½t ðGi ¼ ENÞ logðpEN:i Þ

i2Oð0;0Þ

þ

X

W i P½t ðGi ¼ NNÞ logðpNN:i Þ

i2Oð0;0Þ

using weighted multinomial logit regression. For example, for
each observation i in the O(1, 1) group, we could create two
observations to be used in the weighted multinomial logit
regression, one belonging to the EE group with weight
WiP[t](Gi ¼ EE), and the other belonging to the EN group with
weight WiP[t](Gi ¼ EN).
For (g, z) 2 {(EE, 1), (EE, 0), (EN, 1), (NE, 0)}, we can
½tþ1
2½tþ1
determine hg;z and sg;z using weighted linear regression.
For example, for each observation i in the O(1, 1) group, we
could create one observation with weight WiP[t](Gi ¼ EE) to be
½tþ1
2½tþ1
used in the weighted linear regression for hEE;1 and sEE;1 :
[Received April 2005. Revised June 2008.]

;

REFERENCES
Abadie, A., Angrist, J., and Imbens, G. (2002), ‘‘Instrumental Variables Estimates of the Effects of Subsidized Training on the Quantiles of Trainee
Earnings,’’ Econometrica, 70, 91–117.
Ahn, H., and Powell, J. (1993), ‘‘Semiparametric Estimation of Censored
Selection Models with a Nonparametric Selection Mechanism,’’ Journal of
Econometrics, 58, 3–29.
Aitkin, M., and Rubin, D. B. (1985), ‘‘Estimation and Hypothesis Testing in
Finite Mixture Models,’’ Journal of the Royal Statistical Society, Ser. B, 47,
67–75.

176
Angrist, J., Imbens, G., and Rubin, D. B. (1996), ‘‘Identification of Causal
Effects Using Instrumental Variables,’’ Journal of the American Statistical
Association, 91, 444–455.
Barnard, G. A. (1965), ‘‘The Use of the Likelihood Function in Statistical
Practice,’’ Proceedings of the Fifth Berkeley Symposium, 1, 27–40.
Barnard, G. A., Jenkins, G. M., and Winsten, C. B. (1962), ‘‘Likelihood
Inference and Time Series,’’ Journal of the Royal Statistical Society, Ser. A,
125, 321–372.
Barnard, J., Frangakis, C., Hill, J., and Rubin, D. (2003), ‘‘A Principal Stratification Approach to Broken Randomized Experiments: A Case Study of
School Choice Vouchers in New York City,’’ Journal of the American Statistical Association, 98, 299–323 (with discussion).
Basu, D. (1971), ‘‘An Essay on the Logical Foundations of Survey Sampling,
Part One,’’ in Foundations of Statistical Inference, eds. V.P. Godambe, and
D.A. Sprott, Toronto: Holt, Rinehart and Winston.
Boyles, R. A. (2008), ‘‘The Role of Likelihood in Interval Estimation,’’ The
American Statistician, 62, 22–26.
Burghardt, J., McConnell, S., and Schochet, P. (2003), National Job Corps Study:
Findings Using Administrative Earnings Records Data. Final Report. Document No. PR03-92., Princeton, NJ: Mathematica Policy Research, Inc.
Burghardt, J., McConnell, S., Schochet, P., Johnson, T., Gritz, M., Glazerman,
S., Homrighausen, J., and Jackson, R. (2001), Does Job Corps Work?
Summary of the National Job Corps Study. Document No. PR01-50.,
Princeton, NJ: Mathematica Policy Research, Inc.
Copas, J. B., and Li, H. G. (1997), ‘‘Inference for Non-random Samples (with
discussion),’’ Journal of the Royal Statistical Society, Ser. B, 59, 55–95.
Das, M., Newey, W., and Vella, F. (2003), ‘‘Nonparametric Estimation of
Sample Selection Models,’’ The Review of Economic Studies, 52, 33–58.
Dehejia, R., and Wahba, S. (1999), ‘‘Causal Effects in Non-experimental
Studies: Re-evaluating the Evaluation of Training Programs,’’ Journal of the
American Statistical Association, 94, 1053–1062.
Dempster, A. P., Laird, N., and Rubin, D. B. (1977), ‘‘Maximum Likelihood
Estimation From Incomplete Data Using the EM Algorithm (with discussion),’’ Journal of the Royal Statistical Society, Ser. B, 39, 1–38.
Edwards, A. W. F. (1972), Likelihood, Cambridge, UK: Cambridge University
Press.
Efron, B., and Tibshirani, R. J. (1993), An Introduction to the Bootstrap, New
York, NY: Chapman and Hall.
Fisher, R. A. (1921), ‘‘On the ‘‘Probable Error’’ of a Coefficient of Correlation
Deduced From a Small Sample,’’ Metron, 1, 3–32.
Frangakis, C. E., and Rubin, D. B. (1999), ‘‘Addressing Complications of
Intention-to-Treat Analysis in the Combined Presence of All-or-None
Treatment-Noncomplianze and Subsequent Missing Outcomes,’’ Biometrika, 86, 365–379.
——— (2002), ‘‘The Defining Role of ‘Principal Stratification and Effects’ for
Comparing Treatments Adjusted for Posttreatment Variables: From Treatment Noncompliance to Surrogate endpoints,’’ Biometrics, 58, 191–199.
Hacking, I. (1965), Logic of Statistical Inference, New York: Cambridge
University Press.
Heckman, J. J. (1974), ‘‘Shadow Prices, Market Wages, and Labor Supply,’’
Econometrica, 42, 679–694.
——— (1979), ‘‘Sample Selection Bias as a Specification Error,’’ Econometrica, 47, 153–162.
Heckman, J. J., and Hotz, V. J. (1989), ‘‘Choosing Among Alternative Nonexperimental Methods for Estimating the Impact of Social Programs: The Case
of Manpower Training,’’ Journal of the American Statistical Association, 84,
862–880.
Heckman, J. J., Ichimura, H., Smith, J., and Todd, P. (1998), ‘‘Characterizing Selection Bias Using Experimental Data,’’ Econometrica, 66, 1017–
1098.
Heckman, J. J., and Robb, R. (1985), ‘‘Alternative Methods for Evaluating
the Impact of Interventions: An Overview,’’ Journal of Econometrics, 30,
239–267.
Heckman, J. J., Smith, J., and Clements, N. (1997), ‘‘Making the Most out of
Programme Evaluations and Social Experiments: Accounting for Heterogeneity
in Programme Impacts,’’ The Review of Economic Studies, 64, 487–535.
Holland, P. (1986), ‘‘Statistics and Causal Inference,’’ Journal of the American
Statistical Association, 81, 945–960.

Journal of the American Statistical Association, March 2009
Lalonde, R. J. (1995), ‘‘The Promise of Public Sector-Sponsored Training
Programs,’’ The Journal of Economic Perspectives, 9, 149–168.
Lee, D. S. (2005), ‘‘Training, Wages, and Sample Selection: Estimating Sharp
Bounds on Treatment Effects,’’ NBER Working Paper, 11721.
Little, R. J. A. (1985), ‘‘A Note About Models for Selectivity Bias,’’ Econometrica, 53, 1469–1474.
Liu, C. (2004), ‘‘Robit Regression: A Robust Alternative to Logit and Probit,’’
in Missing Data and Bayesian Methods in Practice: Contributions by
Donald Rubin’s Statistical Family, eds. A. Gelman and X. L. Meng, New
York: Wiley.
Liu, C., and Rubin, D. B. (1998), ‘‘Ellipsoidally Symmetric Extensions of the
General Location Model for Mixed Categorical and Continuous Data,’’
Biometrika, 85, 673–688.
Manski, C. F. (1995), Identification Problems in the Social Sciences, Cambridge, MA: Harvard University Press.
Mattei, A., and Mealli, F. (2007), ‘‘Application of the Principal Stratification
Approach to the Faenza Randomized Experiment on Breast Self-Examination,’’ Biometrics, 63, 437–446.
McLachlan, G., and Peel, D. (2000), Finite Mixture Models, New York: John
Wiley and Sons.
Neyman, J. (1923), ‘‘On the Application of Probability Theory to Agricultural
Experiments: Essay on Principles,’’ Translated in Statistical Science, 5, 465–
480.
Rosenbaum, P. (1984), ‘‘The Consequences of Adjustment for a Concomitant
Variable That has Been Affected by the Treatment,’’ Journal of the Royal
Statistical Society, Ser. A, 147, 656–666.
Royall, R. M. (1997), Statistical Evidence, London: Chapman and Hall.
Rubin, D. B. (1974), ‘‘Estimating Causal Effects of Treatments in Randomized
and Nonrandomized Studies,’’ Journal of Educational Psychology, 66, 688–
701.
——— (1976), ‘‘Inference and Missing Data,’’ Biometrika, 63, 581–592.
——— (1978), ‘‘Bayesian Inference for Causal Effects,’’ The Annals of Statistics, 6, 34–58.
——— (1980), ‘‘Discussion of ‘‘Randomization Analysis of Experimental
Data: The Fisher Randomization Test’’ by D. Basu,’’ Journal of the American Statistical Association, 75, 591–593.
——— (1998), ‘‘More Powerful Randomization-Based p-values in DoubleBlind Trials with Non-compliance (with Discussion by D. R. Cox),’’ Statistics in Medicine, 17, 371–389.
——— (2000), ‘‘The Utility of Counterfactuals for Causal Inference—Discussion of ‘‘Causal Inference Without Counterfactuals’’ by
A. P. Dawid,’’ Journal of the American Statistical Association, 95, 435–
438.
——— (2005), ‘‘Causal Inference Using Potential Outcomes: Design, Modeling, Decisions,’’ Journal of the American Statistical Association, 100,
322–331.
——— (2006), ‘‘Causal Inference Through Potential Outcomes and Principal
Stratification: Application to Studies with Censoring Due to Death,’’ Statistical Science, 21, 299–321.
SAS Institute, Inc. (2004), SAS/Stat 9.1 User’s Guide, Cary, NC.
Schochet, P. Z., Bellotti, J., Cao, R. J., Glazerman, S., Grady, A., Gritz, M.,
McConnell, S., Johnson, T., and Burghardt, T. (2003), ‘‘National Job Corps
Study: Data Documentation and Public Use Files: Volume I,’’ Mathematica
Policy Research, Inc.
Titterington, D., Smith, A., and Makov, U. (1985), Statistical Analysis of Finite
Mixture Distributions, New York: John Wiley and Sons.
Vella, F. (1998), ‘‘Estimating Models with Sample Selection Bias: A Survey,’’
The Journal of Human Resources, 33, 127–169.
Wooldridge, J. (2002), Econometric Analysis of Cross Section and Panel Data,
Cambridge, MA: MIT Press.
Zhang, J. L., and Rubin, D. B. (2003), ‘‘Estimation of Causal Effects via
Principal Stratification When Some Outcomes are Truncated by ‘Death’,’’
Journal of Educational and Behavioral Statistics, 28, 353–368.
Zhang, J. L., Rubin, D. B., and Mealli, F. (2008), ‘‘Evaluating The Effects of
Job Training Programs on Wages through Principal Stratification,’’ in Volume
21 of Advances in Econometrics: Modeling and Evaluating Treatment Effects
in Econometrics, eds. D. Millimet, J. Smith, and E. Vytlacil, Oxford, UK:
JAI Press.

