Identification and Robustness with Contaminated and Corrupted Data
Author(s): Joel L. Horowitz and Charles F. Manski
Source: Econometrica, Vol. 63, No. 2 (Mar., 1995), pp. 281-302
Published by: The Econometric Society
Stable URL: https://www.jstor.org/stable/2951627
Accessed: 11-03-2019 19:31 UTC
REFERENCES
Linked references are available on JSTOR for this article:
https://www.jstor.org/stable/2951627?seq=1&cid=pdf-reference#references_tab_contents
You may need to log in to JSTOR to access the linked references.
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

The Econometric Society is collaborating with JSTOR to digitize, preserve and extend access
to Econometrica

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

Econometrica, Vol. 63, No. 2 (March, 1995), 281-302

IDENTIFICATION AND ROBUSTNESS WITH CONTAMINATED
AND CORRUPTED DATA

BY JOEL L. HOROWITZ AND CHARLES F. MANSKI

Robust estimation aims at developing point estimators that are not highly sensitive to
errors in the data. However, the population parameters of interest are not identified
under the assumptions of robust estimation, so the rationale for point estimation is not
apparent. This paper shows that under error models used in robust estimation, unidentified population parameters can often be bounded. The bounds provide information that is
not available in robust estimation. For example, it is possible to obtain finite bounds on
the population mean under contaminated sampling. A method for estimating the bounds
is given and illustrated with an application. It is argued that when the data may be
contaminated or corrupted, estimating the bounds is more natural than attempting point
estimation of unidentified parameters.

KEYWORDS: Robust estimation, contaminated sampling, corrupted sampling, identification.

1. INTRODUCTION

INFERENCE IN THE PRESENCE OF ERRORS in the data is problematic because the
sampling process does not identify the probability distribution of interest. As
with other identification problems, it is natural to analyze problems with data
errors in two stages: first determine which features of the relevant population
are identified given the available information about the sampling process, and
then develop methods for estimating the identified features.
One of the main approaches to inference in the presence of data errors,
robust estimation, follows a different analytical strategy. Studies of robustness
aim at characterizing how point estimators of population parameters behave
when data errors are generated in specified ways. The main objective is to find
point estimators that are not greatly affected by errors. There is no attempt to
undertake the separate though related task of determining what information
about the parameters is available from a sampling process that produces data
errors and how that information can be extracted. See Huber (1981) and
Hampel, Ronchetti, Rousseeuw, and Stahel (1986), referred to hereinafter as
HRRS, for general treatments of robust estimation.
In this paper, we address the identification problem directly. Our aim is to
learn what can be inferred about parameters of interest when the sampling
process generates erroneous observations. We show that under error models

regularly used in robust estimation, population parameters often can be bounded
even though they are not identified. The bounds are sharp; that is, they exhaust
the information about the parameters that is available from the sampling

1 We thank Roger Koenker, Marianthi Markatou, Franco Peracchi, three anonymous ref
and the co-editor for comments. The research of Joel L. Horowitz was supported in part by NSF
Grants SES-8922460 and DMS-9208820. The research of Charles F. Manski was supported in part
by NSF Grants SES-8808276 and SES-9223220.
281

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

282 J. L. HOROWITZ AND C. F. MANSKI

process and the maintained assumptions. Moreover, estimating the bounds
consistently is often very easy.

Our main assumption is that the analyst can place an upper bound on the
probability of a data error. This assumption is implicit in all robust estimation.
Bounded-influence estimation assumes that the probability of a data error is
"small" (technically, it is infinitesimal), and high-breakdown estimation assumes

implicitly that the error probability is less than the breakdown point. Huber

(1964), in his development of minimax estimators of location in the presence of
gross errors, assumes explicitly that there is a known upper bound on the
probability of a data error. HRRS suggest a particular upper bound when they
state that "altogether, 1-10% gross errors in routine data seem to be more the

rule rather than the exception" (p. 28). Later, HRRS take a more ambiguous
position but still seem to argue that an analyst usually can at least estimate an
upper bound on the probability of a data error (p. 399).
In some applications, the probability of a data error can be estimated from a
validation data set. In other applications, data errors arise out of the efforts of

analysts to impute missing values; the fraction of imputed values then provides
an estimate of an upper bound on the error probability. There are, of course,
many applications in which there is no obvious way to set a firm upper bound on
the probability of a data error. In these cases, it is still of interest to determine
how inference on population parameters degrades as the error probability
increases. This can be done by varying the upper bound on the probability of a
data error over a plausible range and observing the resulting changes in the
bounds on the parameters of interest.

We analyze identification under two error models prominent in robust estimation. The "contaminated sampling" model assumes that data errors are
statistically independent of sample realizations from the population of interest.
The more general "corrupted sampling" model does not impose this assumption. The contaminated sampling model is maintained in the part of the
robustness literature concerned with bounded-influence estimation. The corrupted sampling model is used in studies of high-breakdown estimation.
Econometrics has long been concerned with a third error model. The "errorsin-variables" model assumes that erroneous observations are generated by
adding mean-zero errors to sample realizations from the population of interest.
Frisch (1934) proved that the slope parameter of a simple linear regression is

bounded under the errors-in-variables model. Klepper and Leamer (1984)
extended this finding to multiple linear regressions. Our work is in the same

spirit as these contributions but applies to different error models.
Section 2 presents the contaminated and corrupted sampling models formally
and develops basic identification results that are obtainable when no structure is
imposed on the sample space or the parameter of interest. We introduce the
concept of "identification breakdown" and relate it to the robustness concept of
breakdown. Section 3 gives further results that apply when the sample space is
the real line. We obtain sharp bounds on quantiles and on the more general
class of parameters that respect stochastic dominance. Section 4 develops an

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 283

infinitesimal identification analysis that yields an identification version of the
gross-error sensitivity. Section 5 outlines how the bounds obtained in Sections 2
and 3 can be estimated consistently. The estimation method is illustrated with
an application to data on the distribution of household incomes in the U.S.
Some of the incomes used in computing this distribution are imputations of
missing data rather than actual income observations. Our bounds determine the
potential implications of income imputation for estimation of the actual income
distribution of American households.
The findings reported in Sections 2-5 lead us in Section 6 to question the
focus on point estimation found in robustness studies. If, given the available
information, a population parameter can only be bounded, then the rationale
for point estimation is not apparent. It seems to us more natural to estimate the
bounds, a task that is often easily accomplished.
Our work also suggests that the perspective of robust estimation is more

conservative than necessary. Robust estimation views the inference problem
before the data are collected. The objective is to guard against the worst
outcomes that errors in the data could conceivably produce. But some outcomes
that are possible ex ante can be ruled out ex post, after the data have been
collected. Identification analysis characterizes the inference that can be made
given the knowledge of the empirical distribution of the data.

The problem of inferring the mean of a distribution provides a compelling
example of the difference between identification analysis and robust estimation.

It is well known that the mean is not robust under contaminated sampling, but
we obtain bounds of finite width on the mean under such sampling. These
findings are not contradictory: identification analysis and the theory of robust
estimation analyze different quantities and make different assumptions about
the information that is available. Identification analysis gives the range of
possible values of the mean of the distribution of interest subject to knowledge

of the distribution that is revealed by the data. In contrast, robust estimation
supposes that the sampled distribution is not known and, holding the distribution of interest fixed at a hypothetical value, obtains the range of feasible values
of the mean of the sampled distribution.
We illustrate key results of our analysis with numerical examples. All proofs
are in the Appendix. The formal analysis is restricted to inference on marginal
distributions, but all of the results extend immediately to inference on condi-

tional distributions (i.e., to regressions) if contamination or corruption is confined to the response variable. The, present analysis does not cover problems in

which the conditioning variables are observed with error.
2. BASIC IDENTIFICATION ANALYSIS

2.1. Statement of the Problem
To pose the problem of data errors that we investigate, suppose that one
wants to make an inference about the marginal distribution of a random

variable y1. However, one observes not y1 but a random variable y whose

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

284 J. L. HOROWITZ AND C. F. MANSKI

realized value can be that of either y1 or (with nonzero probability) another
random variable, y0, whose distribution is unknown. Since interest centers on

the distribution of y1, realizations of y corresponding to y0 are erroneous,
whereas realizations of y corresponding to y1 are error free.
Formally, let (Y, Q) be a measurable space, let (y0, y1, z) E Yx Yx {0, 1} be a
random triple distributed P, and let a random sample be drawn from P. The
objective is to make an inference about the marginal distribution of y1, but one
does not observe sample realizations of any components of (y0, y1, z). One

observes only realizations of y y0(l - z) + y1z. Since interest centers on y1,
realizations of y corresponding to z = 0 constitute data errors. Realizations of
y corresponding to z = 1 are error free.

Let 4' denote the space of all probability distributions on (Y, Q). Let

Q Q(y) denote the distribution of the observable y. Let Pi = Pi(yi) den
marginal distribution of yi (i = 0, 1). Let Pij Pij( yi Iz=) denote the dis
tion of yi conditional on the event z = 1 for i = 0, 1 and j = 0, 1. Let p _
be the marginal probability of a data error. The object of interest is P1. In

particular, one may wish to infer a parameter r(P1), where r( ) maps 4'
into 1
The inferential problem is that the sampling process does not identify P1 but
only Q. These two distributions may be decomposed as follows:

(1) P1= (1-P)P11 +PP10
and

(2) Q= (1 -P)P11 +PPo0.
In robust estimation, the unknown P1 is held fixed and Q is allowed to range

over all distributions consistent with (1) and (2). The objective is to characterize
the maximum possible difference between r(Q), which can be estimated consistently, and r(P1), which cannot be estimated consistently because it is not
identified. In identification analysis, Q is held fixed because it is identified by
the data, and P1 is allowed to range over all distributions consistent with (1)
and (2). The objective is to set bounds on the unknown quantity r(P1).
It is easily seen that in the absence of prior information, identification of Q
implies no restrictions on P1. Simply observe that Q = P00 if p = 1, in which
case Q provides no information about P1. On the other hand, restrictions on P1
may arise if suitable prior information is available.

2.2. The Contaminated and Corrupted Sampling Models
A piece of prior information that is frequently assumed to be available in
robust estimation is that the occurrence of data errors is independent of the
sample realizations from the population of interest. That is,

(3) Pi =P1,
in which case inferences about P1 are equivalent to inferences about P11. This

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 285

assumption underlies the influence function and bounded-influence estimation.
It will be seen below that tighter bounds on P1 can be established when (3)
holds than when it does not. Accordingly, this paper provides parallel treat-

ments of the problem in which (3) does and does not hold. Results when (3)

holds are formulated in terms of bounds on P1l and functionals r(P11) since
under (3), P1l and P1 are the same. Results when (3) does not hold are
formulated in terms of bounds on P1 and functionals r(P1).

Following common terminology, we refer to the case where (3) holds as the
"contaminated sampling" model (see, e.g., Huber (1981, p. 11)). We refer to the
case in which (3) does not hold as the "corrupted sampling" model. This case,
which permits arbitrary corruption of an arbitrarily selected fraction of the data,
underlies much of the literature on high-breakdown estimation. The process of
data corruption used by HRRS in their definition of the finite-sample breakdown point is a finite-sample version of our corrupted sampling model. The
same is true of the process of data corruption used by Donoho and Huber
(1983), referred to hereinafter as DH, in their definition of the breakdown poin
under c-replacement.
2.3. Implications of an Upper Bound on the Error Probability
Another useful piece of prior information is an upper bound, A, on the

probability, p, that a data point is erroneous. As was discussed in Section 1, our

analysis assumes that one knows or can estimate a A such that p < A < 1. In this
section and Sections 3-4, which are concerned with identification, we assume
that A is known a priori. In Section 5, which is concerned with estimation, we
assume only that one has a consistent estimator of A.

Knowledge that p < A combined with the fact that Q is identified implies that

P1l belongs to a set of distributions 'I1l(A), defined below, and that P1 belongs

to a larger set 'I1(A).2 As A increases, the sets 'I1l(A) and 'I1(A) expand but
remain informative in the sense that they are proper subsets of If for all A < 1.

Proposition 1 presents the resulting restrictions on P1l and P1:
PROPOSITION 1: A. Let the error probability p be known with p < 1. Then

(4) P11 E I1(P) - {(Q - p 0)/(1 P): i00 E
and

(5) P1 E F1(P) -{(1 -p)+11 +Pi10: (IP11,ipo) E 111(p) X I
These restrictions on P11 and P1 are sharp.

B. 4'11(p) c 1(P).

C. Let 8 > 0 and p + 8 < 1. Then '11(P) C I,11(p +8) and 'j1(p) C '1

D. Let it be known only that p < A < 1. Then P11 E f11(A) and P1 e If1(A).
These restrictions on P11 and P1 are sharp.

2 Both It'l(A) and t1(A) depend on Q as well as A, but we leave this fact implicit as we shall not

be varying Q.

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

286 J. L. HOROWITZ AND C. F. MANSKI

Proposition 1 implicitly characterizes the identifiabi

as P11 and P1. The proposition shows that Poo E

Po E to()- I10 - A). We use these facts in Section 4.

Tighter bounds on P1 can be established under the contaminated sampling

model than under the corrupted sampling model. This fact, which is implied by
(3) and part B of Proposition 1, is important enough to warrant statement as a
corollary to Proposition 1:

COROLLARY 1.1: Let it be known that p < A <1 and that P1 = P11. Then
P1 E '11(A). This restriction on P1 is sharp.

2.4. Identification Breakdown

Given any real-valued functional r( ) on If, let T {,r(fr): qr E If} denote the
range of r. Let TL and Tu, respectively, denote the lower and upper bounds of
T. Under the assumptions of Proposition 1D

(6a) IT(Pil) E T11(Ak)-{[(* : qf E 11i(A))
and

(6b) lr(Pi) E_ Tl(A) -{T(q): qr E_ F10))}.

Let TllL(A) and T1lu(A), respectively, denote the lower and up
T1l(A), and let TlL(A) and T1u(A) denote the lower and upper b
In robust estimation, the breakdown point of a functional r( ) can be defined
as the largest fraction of erroneous data that rT() can tolerate without being
driven to either boundary of its range (HRRS, p. 98). Following this convention,
define

A11 sup{A: TL < TllL(A) < T11U(A) < TU}
and

A1 Sup{A: TL < TlL(A) < T1U(A) < TU}
We call A1l and A1 the "identification breakdown" points of T(P1l) and T(P1).
In general, A1l and A1 depend on Q.'
When Y is a finite-dimensional real space, the identification breakdown point
under the corrupted sampling fnodel, A1, is a limiting form of the HRRS version
of the finite-sample breakdown point of robust estimation.4 To show this, let

A1n denote the HRRS finite-sample breakdown point of r( ) at a random
sample of size n drawn from Q. Then we have the following:
3 DH define the breakdown point as the smallest fraction of erroneous data that can drive r( ) to
a boundary of its range. As noted by HRRS, their definition and that of DH differ by l/n in a
sample of size n. Our analysis could be based on either definition. We adopt that of HRRS to avoid
ambiguity.

4 The e-replacement breakdown point of DH also could be used.

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 287

PROPOSITION 2: Assume that Y is a finite-dimensional real space and that
(7)

lim

|tr(F

)-,r(Gn|=O

n -- o

for any sequences of distribution functions {FF} and {Gn} s
pointwise as n -- oo. Then limn -- l n = A1 almost surely.
Note that A1 is evaluated at the observed distribution Q, whereas the
breakdown point in robust estimation is evaluated at the distribution of interest,
P1. This difference between the identification and robust-estimation breakdown

points reflects the focus of identification analysis on ex post inference, whereas
robust estimation is concerned with ex ante analysis of the behavior of estimators.

2.5. Sharp Bounds on Probabilities

We now develop the implications of the general, but abstract, Proposition 1
for identification of P11 and P1. Corollary 1.2 begins this process by obtaining
sharp bounds on P11(A) and P1(A) for all measurable sets A.

COROLLARY 1.2: Let it be known that p < A < 1. Let A E [2. Then

(8) P11(A) E jI11(A; A) [0, 1] n [{Q(A) - A}/(1 - A), Q(A)/(1 - A)],
and

(9) P1(A) E- 1F(A; A)--[0, 1] n [ Q(A) -A, Q(A) + A] .
These bounds on P11(A) and P1(A) are sharp.

An equivalent representation of the intervals If1,(A; A) and If1(A; A) can be

obtained by dividing the range of possible values of Q(A) into four regimes:

(10Oa) 1 -A < Q( A) < A 11 j( A ; A) = f( A ; A) = [0, 1] ,

(10b) Q(A) < min (1 - A, A) =rjj11(A;A) = [0,Q(A)/(1 -A)],
Vf(A; A) =[0, Q(A) +A],

(10C) Q(A) > max(l1-A, A) 11 fI(A; A) =[{Q(A) - A/(l -A), 1],
VV1(A; A) = [Q(A) -A,1],

(10d) A < Q(A) < 1 -A 11-Tj(A; A)
= [{Q(A) -A}/(1 -A), Q(A)/(1 -A)]

VI1(A;A) = [Q(A) -A,Q(A) +A].
It can be seen from (10) that the bounds on P11(A) and P1(A) are trivial if

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

288 J. L. HOROWITZ AND C. F. MANSKI

1,

1

Bounids
Observed CDFC

-4

-2

()

2

4

-4

t

-2

()

2

4

t

a. Bounds under Conitamination b. Bounds under Corruption

FIGURE 1.-Bounds on probabilities under contamination and corruption.

1 - A < Q(A) < A but are informative otherwise. Moreover, the identification
breakdown point of both P11(A) and P1(A) is min[Q(A), 1 - Q(A)].
The following example illustrates Corollary 1.2:

EXAMPLE 1: Let the observed distribution, Q, be the standard normal, and let

A = 0.1. We find bounds on the cumulative distribution function (CDF) of y1
under contamination and corruption. Let (P denote the cumulative standard

normal distribution function. Then from (8)

max [, <(l)0.9
01 P1[-o,t]<min[1,
I9
( 1
L
0.
From (9)

max[ 0, ?P(t) - 0.1] < P1[ - oo, t] < min [1, ?P(t) + 0.1]
Figure la plots the lower and upper bounds on P-c[-c, t] as well as the

observed CDF, P(t). Figure lb plots the lower and upper bounds on PJ -

as well as the observed CDF. Observe that under contamination, but not

corruption, the width of the boun,ds approaches 0 as t -> + oo. Also observe that

the lower bounds are uninformative if t < - 1.28 (?(Pz) < 0.1), and the upper
bounds are uninformative if t > 1.28 (P(z) > 0.9). This reflects the identification breakdown point of the probability function.

Corollary 1.2 shows that Q(A) E W1 (A; A) c f1(A; A) for all A. Hence, Q

belongs to both 1tl(A) and f1(A). This means that if the only available
information is a bound on p, one cannot reject the hypothesis that P1 = P1l = Q.
Moreover, P1l and P1 cannot differ from Q by too much. Equation (8) implies
This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 289

that P1l is dominated by Q (i.e., sets of zero Q measur

measure), and (9) implies that supA E=QI Pl(A) - Q(A) I <A
It is important to understand the relation between the sharp restriction

Pl E '11G(A) reported in Proposition 1 and the collection of sharp restricti
Pl1(A) E 1jj(A; A), A E Q2, found in Corollary 1.2. Every distribution fll Ee
Ijj1(A) satisfies qi1l(A) E ,1 (A; A), A E Q2. However, not every function 4: Q2
W1 satisfying +(A) E 'Tr1,(A; A), A E Qf, is a probability distribution. The sa
relation applies, of course, to the restriction on P1.

3. IDENTIFICATION WHEN Y IS THE REAL LINE

In Section 2, apart from Proposition 2, (Y, Q) was an arbitrary measurable
space. In this section, we assume that Y is the extended real line and that Q2
consists of the Lebesgue measurable sets. Section 3.1 obtains sharp bounds on

quantiles of P1l and P1. Section 3.2 does the same for parameters that respe
stochastic dominance.

3.1. Sharp Bounds on Quantiles

For a E (0, 1], the a-quantile of P1 is ql1(a) inf{t: P11[1-oo, t] > a). Th
a-quantile of P1 is ql(a) inf{t: Pj[-cc, t] > a}. Proposition 3 shows that

ql1(a) lies between two quantiles of Q and that ql(a) lies between two more
widely spaced quantiles of Q.

PROPOSITION 3: Let Ybe the extended real line and Q2 the Lebesgue measurable
sets. Let it be known that p < A < 1. For y E .1, let
(y-quantile of Q if 0 < y < 1,

r(y) =1,- oo if y < O,
cs if y > 1.
Then

(11) q11(a) E [r(a(1 -A)}, r{a(1 -A) + A)],
and

(12) q1(a) E [r(a -A), r(a? +A)].
These bounds on q1l(a) and q1(a) are sharp.
If A is fixed, r[a(1 -A)] and r[a(1 - A) + A] increase as a increases. Hence,

the bounds on ql1(a) shift to the right as a increases. If a is fixed and A
increases from 0 to 1, the set of possible values of ql1(a) widens from the
a-quantile of Q to the smallest interval enclosing the support of Q. The bound
is informative both above and below for all a E (0, 1), all Q, and all A < 1.

Therefore, the identification breakdown point of q1l(a) is always 1.
The bounds on ql(a) also shift to the right as a increases for fixed A. If a
remains fixed and A increases from 0 to 1, the set of possible values of ql(
This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

290 J. L. HOROWITZ AND C. F. MANSKI

2

/ ~~~Bounds
Observed CDF
-2

()

.5

1

Alpha

0

.5

1

Alpha

a. Bounds under Contamination b. Bounds under Corruption

FIGURE 2.-Bounds on quantiles under contamination and corruption.

widens from the a-quantile of Q to [ oo, oo]. The lower bound is informative if
A < a, and the upper bound is informative if A < 1 - a. Therefore, the identification breakdown point of q (a) is min (a, 1 - a).
The following example illustrates Proposition 3:
EXAMPLE 2: Let the observed distribution, Q, be the standard normal, and let

A = 0.1. We find bounds on the quantile function of Y1 under contamination

and corruption. Let 0 < a < 1. From (11), dlY1(0.9a) < ql1(a) < 0-1(0.9a + 0.1).

From (12), 1rP[max(0, a - 0.1)] < q1(a) < 1iP[min (a + 0.1, 1)]. Figure 2a plots
the lower and upper bounds on ql1(a) as well as the observed quantile function

i-P1(a). Figure 2b plots the lower and upper bounds on ql(a) as well as the
observed quantile function. Observe that the lower bound on ql(a) is uninformative if a < 0.1 and the upper bound is uninformative if a > 0.9. This reflects
the identification breakdown points of the quantile function under corruption.

3.2. Sharp Bounds on Parameters that Respect Stochastic Dominance

If F and G are distributions on the extended real line Y, F is said to
stochastically dominate G if F[ - ?o, t ] < G[ - ?o, t ] for all t E Y. We say
parameter r(-) respects stochastic dominance if r(F) > r(G) whenever F
stochastically dominates G. Familiar examples include quantiles and the means
of monotone functions of the random variable of interest. Proposition 4 provides sharp bounds on parameters that respect stochastic dominance.

PROPOSITION 4: Let Y be the extended real line and Q the Lebesgue measurable
sets. Let it be known that p < A < 1. Let r: V -* 1 respect stochastic domi-

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 291
nance. Define the following distributions on (Y, Q):

LA[-oo,t] =Q[-c, t]/(1 -A) if t <r(1 -A),

LA -oo, t I=1 if t>r(1 -A),
fo

if

t

<r(A),

A[ (Q[ -oo, t]-)/1A) if t > r()
Then

r(P11) E [r(LA),r(UA)].
Let S__0 and 5. be the probability measures on Y that place all their mass at - oo
and oo, respectively. Then

(Pl) E [r{(1 - A)LA + A&0}, {(1-A)UA +A5.1}]
These bounds on r(P11) and r(P1) are sharp.
Proposition 4 can be applied to obtain an alternative proof of Proposition 3.

More importantly, Proposition 4 can be used to obtain sharp bounds on the
means of bounded, increasing functions on Y. Corollary 4.1 gives the result.

COROLLARY 4.1: Let g: Y Ml be a bounded, increasing function with
Ko - limt _Og(t) and K1 - limt +Og(t) being the finite lower and upper bounds.

For qi E i, let r(q) fg(y) d be the mean of g(y) when y is distributed qf.
Then sharp bounds on r(P11) and r(P1) are

(13) r(P11) E [fg(y) dLA, g(y) dUA]
and

r(P,)E [(1 -A)fg(y) dLA +AKO, (l-A) g(y) dUA + AK1].

Observe that if fg(y) dLA and fg(y) dUA are held fixed, the range [KO, K

g(*) does not affect the bounds on r(P11). Therefore, (13) provides sh

bounds on r(Pll) even if g(Q) is unbounded. In particular, letting g(y) = y

find that for the contamination model

(14) E(y1jz = 1) E [JydLA,j ydUA]
This interval is informative whenever the mean of Q exists because fydQ > - oo
implies fydLA > - oo, and fydQ < oo implies fydUA < oo. Thus, we obtain finite
bounds on the mean under contaminated sampling.
This finding does not contradict the well-known result in the literature on

robust estimation that the mean is not robust under contaminated sampling.
Identification analysis and the theory of robust estimation analyze different

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

292 J. L. HOROWITZ AND C. F. MANSKI

quantities and make different assumptions about the information that is avail-

able to the analyst. Identification analysis gives the range of possible values of

the mean of P1l subject to the information on Q that is revealed by the
sampling process. As is shown by (14), the resulting range of values is finite if
the mean of Q is finite. In contrast, robust estimation supposes that Q is not yet

known and, holding P1l fixed, obtains the feasible values of the mean of Q for
Q E ((1 -P)P11 +pqi: qE E 1, p < A}. The range of possible values of the mean is
unbounded under this setup.
The following example illustrates Corollary 4.1:

EXAMPLE 3: Let the observed distribution, Q, be the standard normal, and let

A = 0.1. We find bounds on E(y1) under contamination. From Proposition 4

LAJ - o?, t] = min [P(t)/0.9, 1] and UA[- oo, t] = maxtO, [?P(t) - 0.1]/0.9}. Ob
serve that LA[-?o, t] = 1 if t > 1.282, and UA[-cc, t] = 0 if t < - 1.282. Let (
denote the standard normal density function. Then from Corollary 4.1

(1/0.9) 1|22
U(U) du
< E(y1) < (1/0.9) | u(u) du.
X
-1.282
Therefore, - 0.194 < E(y1) < 0.194 under contamination.

4. INFINITESIMAL IDENTIFICATION ANALYSIS FOR SMOOTH FUNCTIONALS

The results obtained thus far hold for all A < 1. Simplifications occur when A

is close to 0 and r(-) is a suitably smooth functional. These simplifications ar
central to the literature on bounded-influence estimation. Here we exploit them
to develop an infinitesimal identification analysis.

Let (Y, Q) be an arbitrary measurable space, as in Section 2. Observe that the

sets T1l(A) and 4f1(A) of possible values of P1l and P1, originally defined in
Proposition 1, can alternatively be expressed as follows:

(15) T11(A) = {Q-[ A/(1-A)]( O-Q): qj E I 0(A)}
and

(16) 'tfr1(A) = {Q-A(q,-): q Foo(A),wE f},
where too(A) is the set of possible distributions P00.
Let qi E too(A), cl E f, and 0 < /3 < A/(1 - A). When it exists, define
7 (Q, q, o) =lin.Q ( ') TQ

to be the derivative of r-() at Q in the direction -( - cl). Recall

and T1(A), defined in (6a) and (6b), denote the sets of possible values for ir(P11)
and r(P1), respectively. Then we have the following proposition:

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 293

PROPOSITION 5: Let it be known that p < A < 1. Ass
and is bounded uniformly over fi E too(A) and that

(17) lim sup IT (Q, OI,Q) - {r[Q-18(q,f3O q ?t1 to(A)

Then

(18) TII(A) = ({r(Q) + Ar'(Q, q, Q) + O(A; Q): i E- WOO(A)),
where o(A; Q) denotes a term that, for fixed Q, is o(A) uniformly over f E too(A).
Sharp bounds on r(P11) are

(19) T(Q) +A inf 7'(Q, fr,Q) +o(A;Q)
E 'too(A)

Ki-(P11) < r(Q) + A sup 7'(Q, fi, Q) + o(A; Q).
EH too(A)

Assume that -'(Q, if, w) exists and is bounded uniformly over (qf, w)
and that

(20) lim sup I '(Q', &,co) - {r[Q-P(Of-w)] -r(Q)}/4 I =0.
f3O pq ? Eoo(A)

Then

(21) T1(A) = {r(Q) + Ar'(Q, q, ) + o(A; Q): q E 00(A), c E },
where o(A; Q) here denotes a term that, for fixed Q, is o(A) uniformly over

Vi E too(A) and w E 'I. Sharp bounds on r(P1) are

(22) 7(Q) + A inf 7'(Q, f, c)) + o(A; Q)
E 'too(A)

<?i(P1) < 7(Q) +A sup r'(Q,qfc,w) +o(A;Q).
E 'too(A)

Proposition 5 is an abstract result whose implications can be investigated

most easily by imposing additional,structure on i'. Corollary 5.1 assumes
is a bounded linear functional and obtains results that are analogous to ones
appearing in the literature on bounded-influence estimation.

COROLLARY 5.1: Let the assumptions of Proposition 5 hold. Let -'(Q, q&, w)
a bounded linear functional of (i/ - w) with the integral representation

(23) r'(Q,qf,c) = ffQ(y)d(iP-oj).
This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

294 J. L. HOROWITZ AND C. F. MANSKI

Assume without loss of generality that

(24) ffQy) dQ = .
(If ffQ dQ = A Q # 0, replace fQ with fQ - ALQ.) Define
(25) Bu= supfQ(Y)
yeY

and

(26) BL= inf fQ(y).
Bounds on r(P11) are

T(Q) + ABL + o(A; Q) S T(P11) 6 T(Q) + ABu + o(A; Q).
Define B* = Bu - BL and BL =-Bu. Bounds on r(P1) are
r(Q) +AB* + o(A; Q) < r(P11) < r(Q) +AB* + o(A;Q).
In robust estimation under contaminated sampling, the unknown distribution

PH1 is held fixed. Suppose that the derivative of T( ) at P1j in the direction
('I - P1l) has the representation Jffp1dqi. Then the quantity

(27) max[ inf fpll(y) , supfpll(y)1
LyeY yy j=

is called the gross-error sensitivity of
(25) and (26) with (27), it can be seen t
error sensitivity of T('), except the derivative is evaluated at Q in the direction

of - (if - Q) instead of at P11 in the direction of (qi - P11). Thus, in identification analysis as in robust estimation, the gross-error sensitivity governs the

maximum possible value of l r(Q) - r(P11)I under the contamination model with

infinitesimal contamination probability. However, in identification analysis, the

gross error sensitivity is evaluated at the observed distribution Q, not the

unknown "correct" distribution P1l. Like the difference between the identif
tion and robust-estimation breakdown points, this reflects the focus of identification analysis on ex post inference.
5. ESTIMATION OF IDENTIFIED FEATURES WITH AN APPLICATION
TO THE INCOME DISTRIBUTION IN THE U.S.

This paper has focussed on identification. We now provide a brief discussion
of estimation and give an illustrative application. All of the restrictions on P1
and P1 reported in Sections 2-4 are functionals of the distribution Q. So an

obvious estimation approach is to estimate Q by its empirical distribution Q
and compute the restrictions on P1 and P1 under Qn. If A is not known
a priori but a consistent estimator An is available, A can be replaced by An.
For example, the bounds 1f1j(A; A) and 1I(A; A) on P1l(A) and P1(A) found
in Corollary 1.2 may be estimated consistently by

,P l A A kn_ r [0,1] n[fn AAA-An)/(' -An 8 Qn({AA /l-An)]
This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 295

and

tInl(A; An) -[0,1] n [Qn(A) -A
Similarly, if r(*) is a continuity point of Q, the bounds [r{a(l - A)),

r{a(l - A) + A)] and [r(a - A), r(a + A)] on qll(a) and q1(a), found in Pro
tion 3, may be estimated consistently by [rj{a(l - An)), rn{a(l - An) +
[rn(a - A), rn(a + An)], respectively, where rn(y) is the y-quantile of
y E (0, 1], rn(y) = - oo for y < 0, and rn(y) = oo for y > 1. The problem of
developing confidence intervals for the bounds is not treated here since our
main focus is on identification.

To illustrate estimation of the bounds, we consider data on the income
distribution in the U.S. The data are based on household interviews obtained in

the Current Population Survey (CPS) and are published by the U.S. Bureau of
the Census (the Bureau) in Series P-60 of Current Population Reports. Two
sampling problems identified by the Bureau are "interview nonresponse,"
wherein some households in the CPS, sampling frame are not interviewed, and
"item nonresponse," wherein some of those interviewed do not provide complete income responses. U.S. Bureau of the Census (1991, pp. 387-388) states
that in the March 1990 CPS, which provides data on incomes during 1989,
approximately 4.5% of the 60,000 households in the sampling frame were not
interviewed and that incomplete income data were obtained from approximately
8% of the persons in interviewed households. Faced with these nonresponse
problems, the Bureau uses available information to impute missing income data.
The Bureau mixes actual and imputed data to produce the household income
statistics reported in its Series P-60 publications.
From the perspective of this paper, y1 is the income a CPS household would
report if it were to complete the survey, y0 is the income the Bureau would

impute to the household if the household were not to complete the survey, and
z = 1 if a household completes the survey. The distribution of income reported

by those CPS households who do complete the survey is P1l. The distribution
household income found in the Series P-60 publications is Q = (1 -p)P11 +pP00
where p is the probability that a CPS household does not complete the survey
and P00 is the distribution of incomes imputed by the Bureau to those
households who do not complete the survey. The distribution of interest is

P1 = (1 -p)P1l +pP10, where P1o is the (latent) distribution of incomes th
would have been reported by CPS households who did not complete the survey,

had they done so. That is, P1 is the distribution of reported incomes if all

households in the CPS sampling frame were to report their incomes.5

The Bureau's imputation practice is valid if P1o = Poo, implying that P1 = Q.
Our concern, however, is with the worst-case situation in which one has no prior
S Our reference to P1 as the "distribution of interest" does not imply that P1 is necessarily the
distribution an applied researcher would wish to learn. Applied researchers are typically interested
in the distribution of actual income, not the distribution of reported income. The two distributions
may differ if some households misreport their incomes. Misreporting although an important
sampling problem, will not be addressed here.

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

296 J. L. HOROWITZ AND C. F. MANSKI

information about the relation between Poo and P1o. We can compute the
bound estimates given at the beginning of this section if we have consistent
estimates of Q and of an upper bound on P. Bureau publications provide both
quantities. We focus on the distribution of household income in 1989.

As has been noted, U.S. Bureau of the Census (1991) reports that 4.5% of the
CPS households were not interviewed and 8% of the persons in interviewed
households did not provide complete income responses. The Bureau's publication does not report how the latter group are spread across households but we
can be sure that no more than 7.6% (i.e., 8% x .955) of the households have

item nonresponse. So An= 12.1% consistently estimates an upper bound on
Now consider Q. U.S. Bureau of the Census (1991, Table 5, p. 17) provides
estimates for each of twenty-one income intervals (in thousands of dollars):

Qn[0, 5) = .053 Qn[35,40) = 0.066 Qn[70,75) = .018

Qn[5, 10) = .103 Qn[40,45) = 0.060 Qn[75,80) = .015
Qn[10, 15) = .097 Qn[45,50) = 0.048 Qn[80,85) = .013

Qn[15, 20) = .092 Qn[50,55) = 0.043 Qn[85,90) = .009
Qn[20, 25) = .087 Qn[55,60) = 0.032 Qn[90, 95) = .008
Qn[25, 30) = .083 Qn[60,65) = 0.028 Qn[95, 100) = .006

Qn[30, 35) = .076 Qn[65,70) = 0.023 Qn[100, + ) = .039
Let us "fill out" this estimate of Q by imposing the auxiliary assumption that
income is distributed uniformly within each interval except the last. We may

now estimate bounds on features of P1, and P1.

For example, consider the probability that household income is below $30,000.

We have Qn[0, 30) = 0.515 and An = 0.121. Hence, the estimated bounds on
P11[0, 30) are [0.448, 0.586] and the estimated bounds on P1[0, 30) are
[0.394,0.636]. Now consider median household income. The median of P1l must
lie between the 0.5(1 - A) and 0.5(1 - A) + A quantiles of Q, while the median
of P1 must lie between the 0.5 - A and 0.5 +A quantiles of Q. Replacing Q and

A by Qn and An, and invoking the auxiliary assumption that Q is uniform with

$5000 intervals, the estimated bounds on qjj(.5) are [25.482,33.026], and

estimated bounds on q1(.5) are [21.954,37.273].

6. DISCUSSION

The literature on robust estimation aims at characterizing the behavior of

point estimators of population parameters in the presence of errors in the data
and at developing point estimators that are not highly sensitive to such errors.
However, the parameters of interest in robust estimation are not identified
under the assumptions that are made, so the rationale for point estimation is
not apparent. This paper has shown that the parameters can be bounded under
the assumptions of robust estimation, and it has shown how the bounds can be
estimated. It seems to us more natural to estimate the bounds, which are

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 297

identified, than to attempt point estimation of parameters that are not identified.6

It might be argued that use of 7(Qn) as a point estimator of r(P1) is
preferable to estimation of the identification bounds given in our propositions.
A researcher reporting 7(Qn) need not take an explicit stand on the size of the
error probability. A researcher estimating identification bounds must specify at
least an upper bound on p. We do not find this argument compelling. In the
absence of an upper bound on p, one cannot assess the size of the asymptotic

bias Ir(Q) - (P1)I of the estimate (Qn) or even be sure it is finite. The
usefulness of a point estimator with unknown and, possibly unbounded asym
totic bias is not obvious. Moreover, given an upper bound on p, estimation of
r(Q) yields no information on r(P1) beyond that contained in our sharp boun
Department of Economics, University of Iowa, Iowa City, LI 52242, U.S.A.
and

Department of Economics, University of Wisconsin, Madison, WI 53706, U.S.A.
Manuscript received March, 1993; final revision received April, 1994.

APPENDIX

PROOF OF PROPOSITION 1: A. By (2), the feasible values for P,1 and Poo are

(P11, P00) E {((/11, '/00) E X X : Q = (1 -p)i11 +pfr0oo)

Hence the feasible values for P,, are given by (4) and the ones for Poo are
(Q -piroo)/(1 -p) E 'P. Knowledge of p and identification of Q convey no info
Hence, by (1), the feasible values for P, are given by (5).
B. If qi I IE-F,(p), then ('fIy, 'rlo) E w,'1(p) x if. So if,l E fl(p), by (5).

C. Let ill E tAP11(p). Let the error probability increase to p + 8. Define
(p + 8). Then 4foo, is a probability measure and (frll, 'fr^) E 'P x 'P solves
4if((1 -p - ) + fr000(p + 8). Hence ill E tI111(p + 8). That tI1(p) C tI1(p + 8)

above and from (5).

D. It follows from Part A that the feasible values for P,, and P, are Pl GEu , AtI111(p) and
P1 E U P 6 A.1(P). Part C showed that U P 6 AI11(P) = f',(A) and U P 6 A11(P) = /1(A). Q.E.D.
PROOF OF COROLLARY 1.2: Consider first the situation in which p is known. Part A of
Proposition 1 implies that

P11(A) E [0,1]n{[Q(A) -pa]/(1 -p): a E [0,1])

= [0, 1]fl [{Q(A) -p}/(1 -p), Q(A)/(1 -p)] -f'11(A; p).

This shows that P, (A) is a member of f1/ (A; p). To show that the bound is sharp, we need
prove that, for each all E t11,(A; p), there exist distributions (4ill, 4ioo) such that ill(A) = all a
Q = (1 -P)Vf' +Pfr?00.

6 Point estimation is especially pernicious if the probability limit of the point estimator need n

be in the space of feasible values of r(Pl). The estimators most commonly considered in the
robustness literature do not have this failing. In robust estimation, the functional r( ) is weak
continuous on If, and the estimator of r(PI) typically is r(Qn). In this situation, plimn oo(Qn)
7r(Q). We observed in Section 2 that Q is in the space tI,(A) of feasible values for P1. Therefor
7r(Q) is in the space of feasible values for r(Pd).

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

298 J. L. HOROWITZ AND C. F. MANSKI

To prove that such distributions exist, fix al1 E W11(A; p) and let aoo solve the equation
Q(A) = (1 -p)aj1 + paoo. Because all E t11,(A; p), it follows that aoo E [0, 11. Now choose ('111, '/oo)
as follows: For Q(A) > 0 and measurable B cA,

0jj(B;p)= [Q(B)/Q(A)]ajj; qi00(B;p)= [Q(B)/Q(A)]aoo.
For Q(A) = 0 and measurable B cA,

t,11(B; p) = A,00(B; p) = 0.
For Q(Y - A) > 0 and measurable B c Y - A,

j(B; P) 3[Q(B)/Q(Y-A)](1 - all);
f0or(B; p) [Q(B)/Q(Y-A)](l - aoo).
For Q(Y-A) = O and measurable B c Y-A,

qij(B; p) = qoo(B; p) = .

Then qif1 (A; p) = a1I and Q(B; p)= (1 - p)qil(B) + pioo(B) for all measurable B.

The above concerns P1l(A). The sampling process implies no restrictions on P1o(A). Hence th

sharp bound on P1(A) is

Pj(A) E- I{(1- p)aj, + palo: all- E F11(A; P), alo r= [O, 1]}

= {[o, 1 -p] n[Q(A) -p, Q(A)] +p[O, 1])
= [o, l]fn [Q(A) -p, Q(A) +p] =--1(A; p).
Now suppose only that p S A. Then the feasible values for P1l(A) and P1(A) are P1l(A) e
U_kAl, (A; p) and P1(A) E U p , AI1(A; p). But U p _<A,11(A; p) = 4111(A;.A) and U p 111(A; p)

=

1I(A;

A).

Q.E.D.

PROOF
OF
PROPOSIT
and
Qn
are
cumulativ
with
probability
mea
space of CDFs, and define

vw=vp) - t* f {(Q -pPoo)/(l -p): Poo E t*}Also define

(Al) YL(P)- inf r(P1),
II E'*I(p)

where P1 is given by (1'). Define yu(P) by replacing "inf' with "sup" in (Al).

Let m be the smallest integer such that p S m/n. Define Pn - m/n. For any positive integer j,
let W,* denote the set of CDFs corresponding to discrete distributions that have at most j mass

points. Let V,l n-m(P) denote the set of CDFs P1,ln-m E 1!I- such that
(A2) Qn = (1 -Pn)Pll,n-m +PnP0O,m
for some Poo m E Wm*. Define

(A3) YnP- inf r(pln)

Ln P) P , n-m E tV l , n-m(P )
Pl0, m E t'

where

(A4) Pin = (1 -Pn)Pll,n-m +PnPi0,mDefine yun(p) by replacing "inf' with "sup" in (A3).
The proof of Proposition 2 requires two preliminary lemmas.

LEMMA 1: Suppose that (A2) holds for all n and that as n -0 oo, (a) Qn Q and (b) Poo m
for some P0*0. Then there is a Pj1 such that P1l, n -m 1 P*, and (P*, P0*0) E P*1 x AP*.

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 299

PROOF:
It are
follows
from (2')
and,(A2)
that
P* =
P*j
and Po*o
nondecreasing
because
they
are limit

remains to prove that P* and PO*O are continuous
limp, oP*(y - v). Let PO*(y-) be defined analogously.

distribution function, so

(A5) Q(Y) = (1 -P)Pl*(Y) +PPoo(Y )Moreover, since P* and PO*0 are nondecreasing,

(A6) Pi*i(Y-) Pi*i(Y)
for i = 0 or 1. Therefore, by (A5) and (A6)

(A7) Q(Y) = (1 -P)Pll(y-) +PP*(Y) S (1 -P)P1*(Y) +PPoo(Y) = Q(Y).
(A6) and (A7) imply that P* (y) = P*(y) and P*0(y) = PO*0(y). Q.E.D.

LEMMA 2: Let (7) hold and Qn -- Q as n -->co. Then YLn(P) -- yL(P) and yun

PROOF: Let E > 0 be given. Let {PIIn-m, P10,mnoo m} E v ,n-m X PMX *

satisfying (A2) and such that (P1n) > YLn(P) + E for each n, where Pin is given
selection principle there is a subsequence {n(i): i = 1,2, . .. } such that Poo,m(i)

m(i) is the value of m corresponding to n(i). Call the limit function PO*0

corresponding subsequence of {PII,n-m} converges to some P*, P* and

bution functions, and (P*, PO*) E 13 x If*. Recall that m is a function of
(1 -p)P1 +pPPO1m- Since, yL(P) S r(P* ) for every n by definition of yL(P), (7

YL(P) - < [r(Plin(i)) (P*n(i))] + T(Pln(i)) <YLn(i)(P) + ?
for all sufficiently large i. Therefore, since E is arbitrary

(A8) lim inf YLn(i)(P) -> YL(P)Since (A8) holds for any convergent subsequence of {(Pl,n-m, Poo,m} and every infinite subsequence

has a convergent subsequence, there can be at most finitely many values of n for which r(P <) S
YL(P) - e. It follows that

(A9) liminf YLn(P) > YL(P)
n -X o

Now let P, be a CDF such that (1') and (2') hold and r(PI) < YL(P) + e. Let

CDFs satisfying (A4) such that Pin -- P1 as n -->co. By (7)
IYLn(P) - E < [-T(PI) -r(P1n)] + T(P1n) < YL(P) + E

for all sufficiently large n. Therefore,

(A10) lim sup 'YLn(P) < YL(P)n a:* v

YLn(P) - YL(P) follows by combining (A9) and (A10). Similar arguments ap
rYU(P)-

PROOF
applies

Q.E.D.

OF
PRO
if
break

yu(p). Note that 8 > 0. Let E be such that 0 < E < 8. By (7) and Lemma 2, yun(p) S yu(p) + E =
TH - 8 + E < TH for all sufficiently large n. It follows that for Pn defined as in (A2), p <Pn < Ai.
Therefore, p < AI implies p <Ain for all sufficiently large n, and

(A1l) AI,< liminf A1n.
Now let Ai( (i = 1,2,...) be a convergent subsequence of {AIn}. Denote the limit point by A*,
and let p <Al. There is a 8 > 0 such that for all sufficiently large i, Yun(1)(P) S TH - 8. Let E be

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

300 J. L. HOROWITZ AND C. F. MANSKI

such that 0 < e < 8. By (7) and Lemma 2, yu(p) < yuf(i)(p) + F < TH - 8 < TH for all sufficiently
large i. Therefore, yu(p) < TH, and p < A1 implies that p < A1. It follows that A* < A1. Since this is
true for every limit point of {Al,),

(A12) limsup Al, <A1.

The theorem follows from (All), (A12) and the fact that Qn -* "Q Q.E.D.
PROOF OF PROPOSITION 3: Corollary 1.2 shows that, for each t c ,

(A13) P11[-'ot] c t O E ] [O,ln{Q[-oo, t] -A}/(l -A), Q[-oo, t]/(l -A)].
Hence,

Q[ -??ot] < (1 -A)acx PIJ - oo,t] < a
and

Q[ -??ot] a (1 -A)a2 +A >Pill - oo t ] > a.
It follows that qll(a) E [r{a(l - A)), r{a(l - A) + A)]. This bound on ql1(a) is sharp because the
bound (A13) on P1I[ - oo, t I is sharp. For t >; r[a(l - A)], Q[ - oo, t > a(l -A); hence, the upper
bound in (A13) is no less than a. For t <r[a(l - A) + A], Q[- o, t] <a(l - A) + A; hence, the
lower bound in (A13) is below a. It follows that all t E [r{a(l - A)), r{a(l - A) + A)] are feasible

values for ql1(a).
Now consider q1(a). Corollary 1.2 shows that, for each t E Ml,

P1[-oo, t] E [o, l]in{Q[-oo, t] - A, Q[-oo, t] + A}.
Hence,

Q[-oo, t] <a -A P1[-oo,t] <aa
and

Q[ -??, t] > cx + A Pj - oo, t ]> ae.

It follows that ql(a) E [r(a - A), r(a + A)] and, by the same reasoning as above, tha
sharp in the absence of further information. Q.E.D.

PROOF OF PROPOSITION 4: To show that r(LA) is t

f O if t < r(l -A),

[ '-oo, t] \{Q[-oo,t] -(1 -A)}/A if r>
and observe that

Q[-oo,t] = (1-A)LA[-oo,t] +Afroo[-oo,t], Vta. 'l
This proves that LA E '1l(A); hence, T(LA) is a feasible value for r(P1l).
r(LA) is the smallest feasible value for r(P1l) because LA is stochastically dominated by every
member of W11(A). We need to show that LA[ - oo, t] > 4fj- oo, t] for all 4'l Ea k1l(A) and t E Ml. If
t>r(l-A), then

LA[ - oo, t] -11[C-, t] = 1 o-11[-oc, t] > 0.
If t < r(l - A), then

4if[ -cc, t] > LA[ -oo, t] (1 - A)4lj1[ -oo, t] > Q[ -oo, t].

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

CONTAMINATED AND CORRUPTED DATA 301

Hence (1 - A)ij11[-oo, t] + A ifoo[-oo, t] > Q[-oo, t] for al

that ill E 1,(A)

The proof that r(UA) is the sharp upper bound on r(PI

fQ[-oo, t]/A if t < r(A),

o00 -X t]-I 1 if t > r(A),
and observe that

Q[-oo,t] = (1 -A)UA[-oo, t] + Aioo[-oo, t], Vt Er 1.

Hence UA E I,11(A). Moreover, UA stochastically dominates every qifl E I,11(A). If t < r(A), the
UA -oo, t] -11[ -, t] = 0- 11[-o, t] 0.
If t > r(A), then

i 11[-x,t] < UA[-oo, t] (1 -A)ill[- oo, t] < Q[-oo,t] -A.
Hence (1 - A)qillf[-co, t] + Aioo[f - oo, t] < Q[-co, t] for all 'foo E I. This contradicts the assumption

that ill E ,(A).
Now consider the bounds on r(PI). By Proposition 1, PI1 lies in the set I/,(A) {(1 - A)qfII +

Aqilo: (f'll, qilo) etIf,,(A) x If}. We found above that LA E tI,11(A) and that LA is stochastically
dominated by all the members of tI,,(A). The distribution 8-. belongs to I and is stochastically
dominated by all the members of If. Hence, (1 - A)LA + AS_ E /,1(A) and (1 - A)LA + AS _- is
stochastically dominated by all the members of P1(A). It follows that r{(1 - A)LA + AS_J is the
smallest feasible value for r(P1). The proof for the upper bound is analogous. Q.E.D.
PROOF OF PROPOSITION 5: Conditions (17) and (20) imply the following uniform Taylor's

expansions of r{Q - [A /(1 - A)](qi - Q)} and r[Q - A(qi - c)] around r(Q):

(A14) r{Q - [A/(1 - A)](qi - Q)) = r(Q) + Ar'(Q, i, Q) + o(A; Q)
and

(A15) r[Q - A(qi -,w)] = T(Q) + Ar'(Q, qi, o) + o(A; Q).
Applying (A14) to (15) yields (18) and applying (A15) to (16) yields (21). The bounds (19) and (22)
follow

immediately.

~~~~Y

Q.E.D.

PROOF
OF
COROLLARY
5.1
the
bounds
that
result
wh
inf r'(Q, i, Q) = inf

sup r'(Q,qf,Q)= sup fQ(n),

inf r'(Q,i,c) = inf fQ(n) - sup fQ(q)'
*Et

neY

sup r'(Q,if,w)= sup fQ(q)- inf fQ(). Q.E.D.

*1

Etik

'neY

ineY

otw

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

302 J. L. HOROWITZ AND C. F. MANSKI

REFERENCES

DONOHO, D. L., AND P. J. HUBER (1983): "The Notion of a Breakdown Point," in Festschrift for
Erich L. Lehmann, ed. by P. J. Bickel, K. A. Doksum, and J. L. Hodges. Belmont, CA:
Wadsworth.

FRISCH, R. (1934): Statistical Confluence Analysis by Means of Complete Regression Systems. Oslo,
Norway: University Institute of Economics.
HAMPEL, F., E. RONCHETTI, P. ROUSSEEUW, AND W. STAHEL (1986): Robust Statistics. New York:
Wiley.
HUBER, P. (1964): "Robust Estimation of a Location Parameter," Annals of Mathematical Statistics,

35, 73-101.
(1981): Robust Statistics. New York: Wiley.
KLEPPER, S., AND E. E. LEAMER (1984): "Consistent Sets of Estimates for Regressions with Errors
in All Variables," Econometrica, 52, 163-183.
U.S. BUREAU OF THE CENSUS (1991): "Money Income of Households, Families, and Persons in the
United States: 1988 and 1989," in Current Population Reports, Series P-6-, No. 172. Washington,
D.C.: U.S. Government Printing Office.

This content downloaded from 206.253.207.235 on Mon, 11 Mar 2019 19:31:01 UTC
All use subject to https://about.jstor.org/terms

