Adjusting for Nonignorable Drop-Out Using Semiparametric Nonresponse Models:
Comment
Author(s): Peter J. Diggle
Source: Journal of the American Statistical Association, Vol. 94, No. 448 (Dec., 1999), pp.
1128-1129
Published by: Taylor & Francis, Ltd. on behalf of the American Statistical Association
Stable URL: https://www.jstor.org/stable/2669927
Accessed: 21-10-2019 14:54 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

American Statistical Association, Taylor & Francis, Ltd. are collaborating with JSTOR to
digitize, preserve and extend access to Journal of the American Statistical Association

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:30 UTC
All use subject to https://about.jstor.org/terms

Comment
Peter J. DIGGLE

I greatly admire the work embodied in this important ar-

a drop-out-free population), then I would prefer to avoid

ticle. The authors' mathematical skill provides a solution

detailed assumptions about the longitudinal variation in the

to a notoriously difficult methodological problem. Their

data, and the semiparametric approach is very attractive. If

statistical insight raises a challenge to parametric model-

I want to look in more detail at longitudinal trajectories, ei-

ers who advocate other, less robust solutions. In the fol-

ther population-averaged or especially subject-specific (e.g.,

lowing remarks I take the general point of view that in

to make clinical decisions on individual patients), and ad-

comparing the semiparametric modeling approach of the

justed for the effects of measurement error on the observed

present article with a parametric modeling approach, we

responses, then I think I am more or less forced to develop a

are comparing shades of gray-both are modeling ap-

parametric model, quite likely involving time-varying ran-

proaches, informed by a combination of scientific judg-

dom effects to describe the individual subjects' trajectories.

ment and statistical formalism, differing only in the ex-

The data from the ACTG 175 trial, which the authors very

tent to which they choose to constrain the family of

kindly passed on to me, contain much more longitudinal

models under consideration and, by the same token, to

information than the authors use to answer the simple but

admit modeling assumptions that go beyond the empirically

very relevant question: What would have been the mean response at 56 weeks in each treatment arm had there been

verifiable.

no drop-outs? Had the authors sought to address more de-

In my experience, scientists are inveterate overoptimists.
They ask questions of their data that their data cannot an-

tailed questions about longitudinal trajectories, would their

swer. Statisticians can either refuse to answer such questions, or they can explain what is needed over and above

methodology have moved closer toward a parametric modeling approach?

the data to yield an answer and be properly cautious in re-

At Lancaster, Rob Henderson and I are working on a

porting their results. Parametric models represent a formal

modeling approach to problems of this kind that is still

articulation of what I mean by "over and above the data."

semiparametric but in a weaker sense than is used in the

Sometimes the willingness to make untestable assumptions

article. We postulate a parametric linear model for a longi-

opens up new scientific insights; other times, it generates

tudinal sequences of measurements Yij: j = 1, . .. , ni; i =

a misleading answer. To find out which of these two situ-

1,...,m, where i indexes subjects, j indexes occasions

ations prevails might require independent confirmation by

within subjects, and tij denotes the time at which the m

follow-up studies. This is an integral part of the scientific
method (but perhaps sits uncomfortably alongside clinical
trial ethics). A counterpart to the authors' "It is not what

surement Yij is made. We assume that

Yij = xi (tij)'13 + WliV(tij) + (1)

you do not know that hurts you; it is the things you think
you know, but do not" is "We buy information with assumptions" (Coombs 1964).
What I like about the quotation from Coombs is its im-

where the Zij N(O, T2) are mutually independent mea-

surement errors, the Wli(.) are independent copies of a
nonstationary stochastic process, which is itself decompos-

able into a linear random-effects component and a serially

plicit invitation to the reader to consider the possibility that

correlated stationary component, and xl (tij) is a possibly

what is bought may be worth more or less than its price.

time-varying vector of covariates for Yij. For the drop-out
model, or more generally for the intensity function of an

Put another way, the extent to which information or assumptions over and above the data should be allowed to
impact on statistical inference may depend on the type of

question being asked. The more complicated the question

(in conceptual terms), the more the balance may move in

associated point process of recurrent events, we assume an
expression of the form

Ai (tij) = Ao (tij) exp{X2 (tij)' + W2i (tij)}, (2)

favor of parametric modeling. In the longitudinal setting
of the article, if I want to estimate a marginal population
mean (i.e., the average value that I would expect to see in

where A0 (.) is a nonparametrically specified baseline intensity that is modulated by a log-linear regression including both fixed and random components through the terms

x2(tij)'c/ and W2i(tij). In this model, association between

Peter J. Diggle is Director, Medical Statistical Unit, Department of Math-

the measurement and recurrent event histories of an indi-

ematics and Statistics, Lancaster University, Lancaster LA1 4YF, U.K.

The author would like to thank Ray Carroll and all of the participants in
the recent conference on Informative Missing Values held at Texas A&M
University to mark Ray's 50th birthday. The two days of discussion at
that conference helped him to clarify his thoughts on the issues raised
by dropouts in longitudinal studies (although readers of these comments
may feel, as he does that he still has some way to go). This research has
been supported in part by National Institute of Mental Health grant R01

vidual subject is induced by dependence between the pro-

cesses Wli(.) and W2i(.). There is an emerging literature

? 1999 American Statistical Association
Journal of the American Statistical Association

December 1999, Vol. 94, No. 448, Theory and Methods

MH56639.
1128

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:30 UTC
All use subject to https://about.jstor.org/terms

Diggle:

Comment

Table

1.

From a Simulation Experiment With n = 100 Subjects, and 1,000

Simulated Replicates, for Each of Several Values of ir

_r2

.01

.1

.5

1.0

100.0

Bias -.0036 -.0230 -.0594 -.0910 -.1735
SE

.0034

.0034

.0035

.0035

.0040

1129

small simulation experiment using this model. The true valEstimated
ues of the model parameters were u = 0, r = .1, CO = -.5,
and 3 = .5. Hence the drop-out mechanism is such that

the probability of drop-out increases with Y, and an analysis that treats the drop-outs as ignorable is liable to give a
negatively biased estimator for ,.

The observed covariate X was generated as X = U + Z,
on semiparametric models of this general kind (for a recent
review, see Hogan and Laird 1997).
Within the specific context of the problem that this article
does address-estimating a marginal population mean-the

core of the semiparametric method is, I think, the unnumbered equation in Section 3,

where Z N(O, T2); hence the correlation between U and

X is p =1/ 1? T2. Each experiment generates data from
n = 100 subjects, and the experiment was replicated 1,000
times for each of several values of T. Table 1 shows Monte

Carlo estimates of the estimator ,i = n-Z E2=1 Yi/iri where
the estimates of wFi = P(Yi observed) are obtained from the
incorrect drop-out model (4).

When T2 0 (so that p 1), the observed X is a near-

E[1(Y)[V = v] - 1 A (Vt = v)I(Yi) (3)

perfect surrogate for the unobserved U and the estimator

The intuitive interpretation of (3) is that an unweighted

as predicted, but this development is progressive. Provided

nv - w(v,Yi)

mean (which would give the required answer in a drop-outfree population) is modified by weighting each observation

for At is unbiased. As T2 increases, negative bias develops
that T2 is small (i.e., a good surrogate can be found for the
random effect U), the strictly incorrect analysis assuming
completely random, covariate-dependent drop-out can give

Yi inversely according to the estimated probability wF(v, Yi)
approximately correct inferences. At the opposite extreme,
that Yi is observed conditionally on its covariate value v.
The simulation studies in Section 5 of the article show that

this can give good results, both in terms of unbiased estimation and accurate estimation of a standard error, in large
samples. As the authors themselves point out, it could lead
to difficulties if the i- can get close to 0, and my guess is
that these difficulties become relatively more acute in small
samples.

I am especially intrigued by the authors' discussion in
Section 7.2.3, concerning the strategy of including additional covariates in the drop-out model. Their conclusion, if
I understand it correctly, that this does not help at all seems

counterintuitive. I wonder, therefore, whether the failure of
this strategy is a byproduct of the insistence on a fully
nonparametric formulation of the dropout mechanism. A

simple parametric counterexample would be to postulate a

when T2 is large, the observed covariate X is unrelated to

the drop-out mechanism, and adjustment for it yields no
benefit.

Whatever modeling strategy is adopted, I think there
would be general agreement on all of the following:
* When informative drop-out cannot be ruled out, sensitivity analyses are preferable to placing total faith in

a single fitted model.
* The question of plausible ranges for sensitivity anal-

ysis parameters is both important and difficult.
* The ideal outcome, that substantive inferences are robust to variation of sensitivity parameters over the
whole of their permissible ranges, may not be achieveable in practice.

model in which Y IU N(u + U, (J2) and U N(O,These
1).

The marginal mean of Y is ,u. Now suppose that logitP(Y

considerations lead me to conclude that sensitivity

parameters should, if possible, have an interpretation which

missingIU) = a + 13U. If U is unobserved, then this isisreadily
an
explainable to the scientist whose data are be-

informative drop-out model; if U is observed (without er-

ror) as a covariate, then the model becomes a completely
random drop-out covariate-dependent model (Little 1995),
and the analysis would be straightforward. Perhaps more
realistically, if in this model we observe not U itself, but
a covariate X that is correlated with U, an analysis based

on the (incorrect) assumption that drop-out is completely
random but dependent on X; for example, that

logitP(Y missingIU) = a + 3X (4)
should alleviate to some extent the problem of dealing adequately with the informative drop-out. I have carried out a

ing analyzed. This raises a (possibly tenuous), analogy with
the elicitation of prior distributions for Bayesian inference.
However, although it may be true that in practice, proponents of Bayesian inference are also naturally attracted to
parametric modeling formulations, my own view is that the
question of whether parametric modeling based on assump-

tions "over and above the data" is a good modeling strategy
is quite separate from the issues that distinguish Bayesian
from non-Bayesian inference.
ADDITIONAL REFERENCE
Coombs, C. H. (1964), A Theory of Data, New York: Wiley.

This content downloaded from 206.253.207.235 on Mon, 21 Oct 2019 14:54:30 UTC
All use subject to https://about.jstor.org/terms

