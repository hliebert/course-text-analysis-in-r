Econometric Theory, 34, 2018, 112–133.
doi:10.1017/S0266466617000056

A GENERAL DOUBLE ROBUSTNESS
RESULT FOR ESTIMATING AVERAGE
TREATMENT EFFECTS
TYMON SŁOCZY ŃSKI
Brandeis University

JEFFREY M. WOOLDRIDGE
Michigan State University

In this paper we study doubly robust estimators of various average and quantile treatment effects under unconfoundedness; we also consider an application to a setting
with an instrumental variable. We unify and extend much of the recent literature by
providing a very general identification result which covers binary and multi-valued
treatments; unnormalized and normalized weighting; and both inverse-probability
weighted (IPW) and doubly robust estimators. We also allow for subpopulationspecific average treatment effects where subpopulations can be based on covariate
values in an arbitrary way. Similar to Wooldridge (2007), we then discuss estimation
of the conditional mean using quasi-log likelihoods (QLL) from the linear exponential family.

1. INTRODUCTION
In causal inference settings, doubly robust estimators involve models for both the
propensity score and the conditional mean of the outcome, and remain consistent
if one of these models (but not both) is misspecified. In this paper, we unify and
extend some of the recent literature on doubly robust estimators by providing a
very general identification result which accounts for the majority of interesting
problems. We cover both binary and multi-valued treatments; the average treatment effect, the average treatment effect on the treated, and average treatment
effects for other subpopulations of interest; distribution, quantile, and inequality
treatment effects; local average treatment effects in a setting with an instrumental
variable; unnormalized and normalized weighting; and linear, logistic, and exponential mean functions. Inverse-probability weighting (IPW) is also easily shown
to be a special case within our approach. As far as we know, this is the first paper to
consider all these problems jointly and provide such a general identification result.
Moreover, unlike in the majority of recent studies, our parameters of interest are
We thank Peter Phillips (Editor), Arthur Lewbel (Co-Editor), and three anonymous referees for helpful comments.
Tymon Słoczyński also acknowledges financial support from the National Science Centre (grant DEC-2012/05/N/
HS4/00395) and the Foundation for Polish Science (a START scholarship). Address correspondence to Jeffrey
M. Wooldridge, Department of Economics, Michigan State University, East Lansing, MI 48824-1038, USA;
e-mail: wooldri1@msu.edu.

112

c Cambridge University Press 2017


Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

113

defined as a solution to a population optimization problem, and not to a moment
condition. This has an important advantage when the response or outcome variable has restricted range, as estimators based on moment conditions can produce
estimated means outside the range of logical values—unless one makes some
rather ad hoc adjustments. Here we extend the approach of Wooldridge (2007),
who studied weighted objective functions in a missing data setting, along several
useful dimensions. Our approach also carefully explains the anatomy of double
robustness in a very general setting.
The remainder of the paper is organized as follows. In Section 2, we review the
statistical and econometric literature on doubly robust estimators. In Section 3,
we introduce our notation as well as assumptions and estimands; we also present
our main identification result (in Section 3.2). In Section 4, we discuss several
applications of this approach. In Section 5, we discuss estimation. Further, we
summarize our main findings in Section 6. Finally, in Appendix B, we discuss
implementation of our estimation methods.
2. BACKGROUND
Augmented inverse-probability weighting (AIPW), a standard class of doubly
robust estimators, was introduced in the missing data literature by Robins,
Rotnitzky, and Zhao (1994).1 There are two equivalent ways of writing an AIPW
estimator: either as an IPW estimator, augmented with an additional term (based
on imputation), or as an imputation estimator, augmented with an additional term
(based on reweighting of prediction errors).2 Either of these adjustment terms
can be understood as a form of bias correction, but it is this second formulation which arguably provides good intuition for the additional robustness of this
estimator. When the conditional mean is correctly specified, the adjustment
term—again, based on reweighting of prediction errors—has expectation zero.
When the propensity score is correctly specified, this same term consistently
estimates the bias of imputation. The resulting estimator is asymptotically normal
and locally efficient: when both models are correctly specified, AIPW achieves
the semiparametric efficiency bound.
That this estimator is robust to misspecification of at most one of the working
models was demonstrated in later work by Scharfstein, Rotnitzky, and Robins
(1999), and the term “doubly robust” was introduced by Robins, Rotnitzky, and
van der Laan (2000). Doubly robust estimators continue to be an important topic
of research in statistics, both in causal inference and in missing data settings. For
example, Bang and Robins (2005) extended this methodology to several panel
data models and represented their estimators—which is similar to Scharfstein
et al. (1999), but otherwise not typical—as imputation estimators, with the inverse
of the propensity score included as an additional control variable. Tan (2006a)
developed an alternative AIPW estimator, which might provide either an efficiency gain—if the propensity score is correctly specified—or bias reduction—
if the propensity score is misspecified, but the conditional mean is correctly

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

114

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

specified. Early simulation studies were presented by Lunceford and Davidian
(2004) and Kang and Schafer (2007). While the former paper strongly encouraged
“routine use of [AIPW] in practice”, the latter study was somewhat pessimistic;
its results triggered a considerable debate, with comments of Ridgeway and
McCaffrey (2007), Robins, Sued, Lei-Gomez, and Rotnitzky (2007), Tan (2007),
Tsiatis and Davidian (2007), and a rejoinder.
Following this debate, further AIPW estimators—with better properties—have
been developed. In particular, Cao, Tsiatis, and Davidian (2009) and Tan (2010)
provided new estimators with increased efficiency and improved robustness
against very small values of the propensity score. An estimator with more desirable efficiency properties was also studied by Rotnitzky, Lei, Sued, and Robins
(2012). On the other hand, Hu, Follmann, and Qin (2012) proposed an estimator
with increased robustness to model misspecification: first, covariate information
is collapsed into a two-dimensional score, with one dimension for the conditional
mean of the outcome and the other for the propensity score; second, a regression of
the outcome on this score is estimated using nonparametric methods. A sufficient
condition for consistency of this estimator is that either of the two dimensions captures the “core” of the corresponding pattern. Finally, Vermeulen and Vansteelandt
(2015) focused on bias reduction, and developed an estimator which minimizes the
asymptotic bias under misspecification of both working models.
One shortcoming of the AIPW approach—which is clear from the discussion
in Kang and Schafer (2007) and Robins et al. (2007)—is that the estimated mean
functions are not only sensitive to extreme values of the propensity score estimates, but they can actually produce estimates outside the logically consistent
range when the response is bounded in some way.
In recent years, there has also been substantive interest in doubly robust estimators in the econometric literature. Hirano and Imbens (2001) provided an early
application to data on right heart catheterization; however, these authors used linear models for a binary outcome, which necessarily does not fully exploit the
double robustness result. Wooldridge (2007) developed a general framework for
missing data problems and studied doubly robust estimators of the average treatment effect (ATE), including inverse-probability weighted QML estimators with
logistic and exponential mean functions.3 An important benefit of the approach
in Wooldridge (2007) is that provided one chooses the conditional mean function
so that it coheres with the range of the response variable, estimated counterfactual means are always within the logical range. Cattaneo (2010) used “doubly
robust moment conditions” to construct efficient semiparametric estimators of
multi-valued treatment effects, also extending the scope of applications to quantile
treatment effects (QTEs). More recently, Graham, Campos de Xavier Pinto, and
Egel (2012) derived a new IPW estimator (“inverse probability tilting”), which
replaces the maximum likelihood estimate of the propensity score with a particular method of moments estimate. This new estimator shares the properties of
double robustness and local efficiency with previous methods, but it has smaller
asymptotic bias under certain conditions.4

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

115

While the majority of these previous papers used parametric models for the
conditional mean and the propensity score, and allowed one of these models to be
arbitrarily misspecified, Rothe and Firpo (2015) studied the properties of “semiparametric doubly robust estimators” in which this first stage remains fully nonparametric. In this context, misspecification is no longer an issue, but Rothe and
Firpo (2015) nevertheless demonstrated that such estimators, which exploit “doubly robust moment conditions” (as in Cattaneo, 2010), have desirable asymptotic
properties, since their special structure automatically removes most of the largest
“second order” terms. These same moment conditions were also used in recent
papers by Belloni, Chernozhukov, and Hansen (2014); Belloni, Chernozhukov,
Fernández-Val, and Hansen (2017) and Farrell (2015) for treatment evaluation
with high-dimensional data, including settings with more covariates than observations.
The discussion so far has focused on doubly robust estimators that require the
treatment variable to be unconfounded conditional on covariates. A much smaller
literature—primarily in statistics—has considered estimation of various parameters of interest in instrumental variable (IV) settings. An early contribution by
Tan (2006b) studied doubly robust estimation of the local average treatment effect
(LATE) in a model which, unlike Imbens and Angrist (1994), includes additional
covariates. The estimator of Tan (2006b) is consistent if either the instrument
propensity score is correctly specified, or both the first stage and the conditional
mean of the outcome are correctly specified. Doubly robust estimators of the
LATE were also studied by Uysal (2011) as well as in an early version of Rothe
and Firpo (2015). Finally, a recent paper by Ogburn, Rotnitzky, and Robins (2015)
studied doubly robust estimation of the dependence of the local average treatment
effect on a subset of pretreatment covariates.
Estimation of other parameters of interest has also been considered. In particular, Okui, Small, Tan, and Robins (2012) studied doubly robust estimation of
a finite-dimensional parameter indexing the dependence of the conditional mean
of the outcome on the endogenous treatment variable. Tchetgen Tchetgen and
Vansteelandt (2013) discussed a control function approach to estimating the conditional average treatment effect on the treated in an instrumental variable model;
subsequently, a similar method for estimating the unconditional ATT was developed by Liu, Miao, Sun, Robins, and Tchetgen Tchetgen (2015).
The current paper contributes to several strands of the literature on doubly
robust estimators. We build on the framework of Wooldridge (2007) and expand it
in several useful directions by focusing on treatment effects estimation. As mentioned above, we prefer the setup in Wooldridge (2007) because it leads to doubly robust estimation for important nonlinear as well as linear conditional mean
specifications, and ensures that estimates of ATEs lie within logical ranges when
the response variable is bounded in some way. A related point is that estimators
based on a weighted objective function tend to be less sensitive to lots of variation in the estimated propensity score. Wooldridge (2007) only considered estimation of the ATE over the entire population, and did not present results for doubly

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

116

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

robust estimation of ATEs for subpopulations. An important aspect of our unified
framework is the introduction of an indicator that can select out subpopulations,
thereby providing simple doubly robust estimators for a wide variety of treatment
effects. This includes not only subpopulations defined by pretreatment covariates,
or average treatment effects for different treatment groups, but it introduces new
possibilities. For example, after treatment has been assigned, some units may
exhibit observed behavior—such as getting more education—and we can estimate
average treatment effects for such populations.
To summarize, our paper shows how doubly robust estimators of various average treatment effects for the most common response variables can be studied in
a single framework. This same framework can be used to obtain doubly robust
estimators of distribution, quantile, and inequality treatment effects, as well as of
the local average treatment effect (in an instrumental variable setting). Previous
approaches are limited along one or more dimensions, either focusing only on
the ATE, using only linear conditional means, or using moment conditions that
can produce nonsensical estimates. As a technical improvement over Wooldridge
(2007) and several of the other cited papers, we demonstrate identification
using a conditional mean version of unconfoundedness, rather than full conditional independence between the treatment and potential outcomes.
3. IDENTIFICATION
We now introduce our notation and discuss the population parameters of interest.
Also, we detail the assumptions that are needed for identification of these estimands as well as outline our main identification result. To avoid confusion with
our notation, the discussion of distribution, quantile, and inequality treatment
effects—as well as of our extensions to instrumental variable models—is deferred
to Section 4. As will be explained, these applications are easily expressed within
the following framework.
3.1. Notation and Assumptions
We assume some treatment to take on G + 1 different values, labeled
{0, 1, 2, . . . , G}. For a given population, let W represent the treatment assignment.
Typically, W = 0 represents the absence of treatment, but this is not important for
what follows. The leading case is G = 1, and then W = 0 denotes control and
W = 1 denotes treatment.
For each level of treatment, g, we assume counterfactual outcomes, Yg ,
g ∈ {0, 1, 2, . . . , G}. Most of the common treatment effects are defined in terms
of the mean values of the Yg . For example, let
μg = E(Yg ), g = 0, 1, 2, . . . , G

(1)

denote the mean values of the counterfactual outcomes across the entire population. Assuming g = 0 to be the control, the average treatment effect of treatment
level g is

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

τg,at e = E(Yg − Y0 ) = μg − μ0 .

117

(2)

We may also be interested in the average treatment effect for units actually
receiving this level of treatment, namely
τg,at t = E(Yg − Y0 |W = g) = E(Yg |W = g) − E(Y0|W = g).

(3)

With more than two treatment levels, we can define similar quantities comparing
any two of them. The important point is that our goal is to estimate
E(Yg ) or E(Yg |W = h)

(4)

for treatment levels g and h.
Let X denote a vector of observed, pretreatment covariates that predict treatment and have explanatory power for the Yg . We assume that treatment is
unconfounded conditional on X. We will refine this assumption when we state
the general results; the strongest form of unconfoundedness is conditional independence between the treatment assignment and each counterfactual outcome:
W ⊥ Yg | X , g = 0, 1, 2, . . . , G,

(5)

where “⊥” means “independent of” and “|” denotes “conditional on”. If D(·|·) denotes conditional distribution, we can write unconfoundedness as D(W |Yg , X) =
D(W |X). In estimating the parameter τg,at t , we will see that we only need to
assume unconfoundedness with respect to Y0 , the counterfactual in the control
state.
In what follows, it is helpful to define binary treatment indicators as
Wg = 1[W = g], g = 0, 1, 2, . . . , G

(6)

as well as the generalized propensity score (Imbens, 2000) for treatment level g as
pg (x) = P(Wg = 1|X = x).

(7)

Under conditional independence,
pg (X) = P(Wg = 1|Yg , X).

(8)

In order to allow for a wide variety of treatment effects, we introduce a binary
variable, D, which we will also assume to be unconfounded with respect to each Yg.
In applications, D might be a deterministic function of X, in which case its
inclusion serves to isolate a subset of the population determined by pretreatment
covariates. Another important case is when D is an indicator for a different level
of treatment. Yet another possibility is when D indicates a subpopulation formed
after the treatment assignment. For example, in the evaluation of a job training
program, some individuals might choose to obtain additional education unrelated
to the job training program. If D is an indicator representing “more schooling,”

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

118

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

we would not want to include D in X, as that would generally cause unconfoundedness to be violated—see, for example, Wooldridge (2005). However, we may
want to estimate the average treatment effect of the job training program itself for
the group that subsequently sought additional schooling. Importantly, we will not
have to impose any restrictions on the dependence between W and D. As far as
we know, ours is the first framework to consider this possibility.
In what follows we let η = P(D = 1) be the unconditional probability that
D = 1 and assume that η > 0. The special case of P(D = 1) = 1 is important and
is allowed. Also, define the propensity score for D as
r (x) = P(D = 1|X = x).

(9)

If D and Yg are conditionally independent, then
r (X) = P(D = 1|Yg , X),

(10)

although this is not the version of unconfoundedness we use for our main result.
3.2. A General Result on Weighting
Our general result applies to any function of the potential outcome, Yg , and the
observed
covariates.
Let q(Yg , X) denote such a function, where we assume


E q(Yg , X) < ∞. In the following lemma—which is crucial for our main
result—we demonstrate that, for all g, we can recover E q(Yg , X)|D = 1 from
the distribution of observable variables.
LEMMA 3.2. Assume that Wg and D are each unconfounded in conditional
mean, that is,




E q(Yg , X)|Wg , X = E q(Yg , X)|X
(11)




(12)
E q(Yg , X)|D, X = E q(Yg , X)|X .
Define η = P(D = 1) > 0. Further, assume that pg (x) > 0 for all x ∈ X , where
pg (x) is defined in (7). Then,




Wg
1
·E
r (X)q(Yg , X) = E q(Yg , X)|D = 1 .
(13)
η
pg (X)
This lemma is fairly general, partly due to the inclusion of the auxiliary variable,
D, which defines our subpopulation of interest. The proof of this lemma uses
unconfoundedness in the conditional mean separately for Wg and D. Naturally, if




E q(Yg , X)|Wg , D, X = E q(Yg , X)|X ,
then (11) and (12) both hold.
A number of applications of Lemma 3.2 are covered in Section 4. The proof of
Lemma 3.2 is straightforward and can be found in Appendix A.

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

119

4. APPLICATIONS
Before considering doubly robust estimation, it is useful to see how some important special cases in the literature fit into the current framework. We are primarily
interested in showing the population moments that establish identification, but the
formulas also suggest simple estimators of our parameters of interest.
4.1. Average Treatment Effects under Unconfoundedness
Binary Treatments. Let G = 1, W0 = 1 − W1 = 1 − W , and p0 (X) = 1 − p1 (X) =
1 − p(X). Then, with q(Y, X) = Y and Y = (1 − W ) · Y0 + W · Y1 , Lemma 3.2
implies


1−W
W
(14)
Y−
Y ,
τat e = E(Y1 − Y0 ) = E
p(X)
1 − p(X)
with D = 1 in both cases. This expression leads directly to the standard IPW
estimator (Horvitz and Thompson, 1952). Similarly, we can use Lemma 3.2 to
write the average treatment effect on the treated as


1−W
1
·E W ·Y −
p(X) · Y , (15)
τat t = E(Y1 − Y0 |W = 1) =
P(W = 1)
1 − p(X)
because D = W , η = P(W = 1), and r (X) = p(X). More generally, we can write
the average treatment effect for any subpopulation of interest as


W
1−W
1
E(Y1 − Y0 |D = 1) = · E
r (X) · Y −
r (X) · Y ,
(16)
η
p(X)
1 − p(X)
as long as this subpopulation is defined by D, a binary variable which is unconfounded with respect to potential outcomes, conditional on X. A leading case is
when D is a deterministic function of X, so we are looking at a subpopulation
determined by the conditioning variables that appear in the propensity score.
Multi-valued Treatments. Let Y = W0 · Y0 + W1 · Y1 + W2 · Y2 + · · · + WG · YG .
Then, with q(Y, X) = Y , Lemma 3.2 suggests that the average gain from switching from the control group to treatment g, g ∈ {1, 2, . . . , G}, is


Wg
W0
Y−
Y .
(17)
τg,at e = E(Yg − Y0 ) = E
pg (X)
p0 (X)
Similarly, the average treatment effect on those receiving treatment g, relative to
the control group, is


1
W0
τg,at t = E(Yg − Y0 |W = g) =
· E Wg · Y −
pg (X) · Y . (18)
P(W = g)
p0 (X)

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

120

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

4.2. Distribution, Quantile, and Inequality Treatment Effects
Distribution Treatment Effects. In what follows, it is helpful to define an extended set of counterfactual outcomes, Yg (y) = 1[Yg ≤ y]. In other words, we can
create a set of binary variables, Yg (y), where y is any real number and Yg (y) = 1
whenever Yg ≤ y. Also, Y (y) = W0 · Y0 (y) + W1 · Y1 (y) + · · · + WG · YG (y). If we
let FYg denote the unconditional cdf of Yg , then, from Lemma 3.2, we can write:

Wg
FYg (y) = P(Yg ≤ y) = E Yg (y) = E
Y (y) .
pg (X)






(19)

As noted by Foresi and Peracchi (1995), when we vary the value of y, we can
provide a useful characterization of FYg . This idea was extended in a number
of recent papers (especially in Chernozhukov, Fernández-Val, and Melly, 2013),
and we will exploit this later. Now, using (19), we can identify the distribution
treatment effect (DTE) of treatment g as


Wg
W0
Y (y) −
Y (y) .
(20)
τg,dt e (y) = FYg (y) − FY0 (y) = E
pg (X)
p0 (X)
Previous studies of distribution treatment effects include Abadie (2002), Lee
(2009), Maier (2011), Chernozhukov et al. (2013), and Sant’Anna (2016). As far
as we know, however, ours is the first paper to consider doubly robust estimation
of this parameter.
Quantile Treatment Effects. There are many papers that consider identification
and estimation of quantile treatment effects (QTEs), defined as
τg,qt e (t) = Q Yg (t) − Q Y0 (t),

(21)

where Q Yg (t) is the tth quantile of Yg . Unlike early contributions, which usually
modeled the quantiles directly (see, e.g., Abadie, Angrist, and Imbens, 2002), we
first obtain FYg using (19). Then, we note that


Q Yg (t) = inf u : FYg (u) ≥ t .

(22)

What follows,




τg,qt e (t) = inf u : FYg (u) ≥ t − inf v : FY0 (v) ≥ t .

(23)

This approach to identifying quantile treatment effects was used by Cattaneo
(2010), Frandsen, Frölich, and Melly (2012), Chernozhukov et al. (2013), Frölich
and Melly (2013), Donald and Hsu (2014), and Sant’Anna (2016), among others.
However, only Cattaneo (2010) discussed doubly robust estimation of QTEs,
which we allow in Section 5. Also, our approach to estimation differs from that
in Cattaneo (2010).

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

121

Inequality Treatment Effects. A recent paper by Firpo and Pinto (2016) introduced an alternative approach to studying distributional impacts of interventions.
Namely, such effects were modeled as differences in inequality measures between
two marginal distributions of potential outcomes. Let υ : Fυ → R be an inequality
measure, say the coefficient of variation, the interquartile range, the Theil index,
or the Gini coefficient. As before, we first obtain FYg using (19). Then we note,
following Firpo and Pinto (2016), that the inequality treatment effect (ITE) can
be written as
τg,it e = υ(FYg ) − υ(FY0 ).

(24)

In the concluding section of their paper, Firpo and Pinto (2016) suggested that
studying doubly robust estimators of ITEs would be an interesting avenue for
further research. Such estimators of these parameters follow from Section 5.
4.3. Extensions to Instrumental Variable Estimation
Our general result can be applied in contexts where we require instrumental variables to provide exogenous variation in treatment assignment. In the following
discussion we need to introduce new notation. In particular, let some instrumental
variable—which satisfies the usual exclusion restriction—take on H + 1 different
values, labeled {0, 1, 2, . . . , H }. Let Z represent the instrument assignment. We
also define
Z h = 1[Z = h], h = 0, 1, 2, . . . , H.

(25)

Further, we introduce the instrument propensity score for each Z h :
sh (x) = P(Z h = 1|X = x).

(26)

If Z is unconfounded with respect to each counterfactual outcome and each counterfactual treatment, conditional on X, we can use Lemma 3.2 to separately identify the numerator and the denominator of the usual formula for the local average
treatment effect (LATE). More precisely, and similarly to Tan (2006b), we can
identify this parameter of interest as
τh,lat e =

E
E

Zh
sh (X ) Y

− s0Z(X0 ) Y

Zh
sh (X ) W

− s0Z(X0 ) W

,

(27)

where both the numerator and the denominator are simply equal to the average
effects of Z h , compared with Z 0 , on the outcome and the treatment, respectively. In other words, we identify these objects separately, using (17) in both
cases.
We leave applications to identifying other parameters via instrumental variables
to future research.

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

122

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

4.4. Unnormalized and Normalized Weights
In the previous setup, given a random sample {(Wig , Di , X i ,Yi ) : i = 1, 2, . . . ,N},
Lemma 3.2 suggests how to consistently estimate μg,1 ≡ E q(Yg , X)|D = 1 :
1
N −1
η̂

N
i=1

Wig
r (X i )q(Yi , X i ) ,
pg (X i )

(28)

p

where η̂ → η > 0. One simple, unbiased and consistent estimator of η is
η̂ = N −1

N

Di = N D /N,

(29)

i=1

where N D is the number of observations with Di = 1. The estimator of μg,1 is
then
−1
μ̂g,1,unnormalized = N D

N
i=1

Wig
r (X i )q(Yi , X i ).
pg (X i )

(30)

In special cases, several papers have discouraged empirical researchers from using
η̂ = N D /N, because it leads to a weighted average where the weights do not sum
to unity. In particular, the weight for observation i is
1 Wig
r (X i ),
N D pg (X i )

(31)

and these do not usually sum to unity across i . It is a simple adjustment to obtain
a consistent estimator whose weights are guaranteed to sum to unity. To choose
such weights, note that we can apply Lemma 3.2 to q(Yg , X) ≡ 1 to get


Wg
r (X) ,
(32)
η=E
pg (X)
and so an alternative unbiased and consistent estimator of η is
η̂ = N

−1

N
i=1

Wig
r (X i ).
pg (X i )

(33)

When we plug this estimator in (28) for η̂, we obtain
N

μ̂g,1,normalized =
i=1

Wig
r (X i )
pg (X i )

−1 N
i=1

Wig
r (X i )q(Yi , X i )
pg (X i )

(34)

and now the weights,

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

⎡
⎣

N
j =1

⎤−1
Wj g
Wig
r (X j )⎦
r (X i ),
pg (X j )
pg (X i )

123

(35)

necessarily sum to unity across i .
Many applications of inverse-probability weighted (IPW) estimators, including
those to doubly robust estimation, use normalized weights because the weights
are applied to an objective function, such as a squared residual or a quasi-log
likelihood function. For example, to estimate μg = E(Yg ), we can solve
N

min

m g ∈R

i=1

Wig
(Yi − m g )2 ,
pg (X i )

(36)

and the solution is easily seen to be the estimator with normalized weights.
5. ESTIMATION
We now develop doubly robust (DR) estimators of various average treatment
effects by considering estimation of
μg,1 ≡ E(Yg |D = 1).

(37)

As we saw in Section 4, various average treatment effects can be obtained by
appropriate choice of D, where D = 1 simply defines a subpopulation of interest.
It is helpful to divide the argument into two subsections. The first part of the
DR result is when a conditional mean function is correctly specified, and here we
need to draw on important results from the literature on quasi-MLE estimation
of correctly specified conditional means. The second part requires an application of Lemma 3.2 and a basic understanding of the linear exponential family of
distributions.
The setting is that for a counterfactual outcome Yg a parametric mean function is specified, which we write as {m g (x, θg ) : x ∈ X , θg ∈ g }. Along with the
specification of the mean function, we choose as an objective function a quasi-log
likelihood (QLL) from the linear exponential family (LEF). As discussed
in Gourieroux, Monfort, and Trognon (1984)—see also Wooldridge (2010,
Chap. 13)—the LEF has the feature that it identifies the parameters in a correctly
specified conditional mean. What is somewhat less known is that if the QLL is
chosen so that the conditional mean function represents the so-called canonical
link, then the unconditional mean is consistently estimated even if the conditional
mean function is misspecified. We use this fact in Section 5.2.
In what follows we assume regularity conditions such as smoothness of the
conditional mean functions in βg and enough finite moments so that standard
consistency and asymptotic normality results hold for quasi-maximum likelihood
estimation.

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

124

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

5.1. Part 1: The Conditional Mean is Correctly Specified
In this subsection we assume that the conditional mean is correctly specified
which means that, for some vector θgo ∈ g ,
E(Yg |X = x) = m g (x, θgo ), x ∈ X ,

(38)

where X is the support of X. As shown in Gourieroux et al. (1984), if q(Yg , X; θg )
is a QLL from a density in the LEF with mean function m g (x, θg ) then it can be
written as




q(Yg , X; θg ) = a m g (X, θg ) + b(Yg ) + Yg c m g (X, θg ) .
(39)
Gourieroux et al. (1984) use this structure to show that θgo is a solution to
max E[q(Yg , X; θg )|X]

(40)

θg ∈g

for all outcomes X, which means
E[q(Yg , X; θgo )|X] ≥ E[q(Yg , X; θg )|X].

(41)

For our purposes, another important feature of the LEF family is that it will
suffice to assume that treatment assignment Wg is unconfounded in the mean:




(42)
E Yg |Wg , X = E Yg |X ;
we do not need the stronger conditional independence assumption in (5). This is
because b(Yg ) does not depend on the parameters, and so we can drop it from
the objective function. The only other place in which Yg appears is to multiply a
function of X (and θg ), and so it will suffice to impose (42).
We use parametric models for the propensity scores, pg (x), say Fg (x; γg ). We
allow this model to be misspecified, but assume that the estimator settles down to a
p
limit: γ̂g → γg∗ , where γg∗ is sometimes called the “pseudo-true value”. Similarly,
p

P(D = 1|X = x) is modeled parametrically as J (x; ψ) with ψ̂ → ψ ∗ . In obtaining
γ̂g and ψ̂ we would almost certainly use the Bernoulli log likelihood. In other
words, we estimate standard binary response models by MLE. (More precisely,
by quasi-MLE because we allow the binary response models to be misspecified.)
The weighted objective function for estimating θgo —where Wig selects the units
in treatment group g—is
N

−1

N
i=1

Wig
J (X i ; ψ̂) · q(Yi , X i ; θg ).
Fg (X i ; γ̂g )

(43)

Using standard convergence results—for example, Newey and McFadden (1994)
and Wooldridge (2010, Chap. 12)–(43) converges in probability to
E

Wg
J (X; ψ ∗ ) · q(Yg , X; θg ) .
Fg (X; γg∗ )

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

125

An argument very similar to Lemma 3.2 shows that


Wg
pg (X)J (X; ψ ∗ )
∗
E
J (X; ψ ) · q(Yg , X; θg ) = E
E[q(Yg , X; θg )|X] . (44)
Fg (X; γg∗ )
Fg (X; γg∗ )

Now pg (X)J (X; ψ ∗ )/Fg (X; γg∗ ) ≥ 0, so
pg (X)J (X; ψ ∗ )
pg (X)J (X; ψ ∗ )
o
E[q(Y
E[q(Yg , X; θg )|X]
,
X;
θ
)|X]
≥
g
g
Fg (X; γg∗ )
Fg (X; γg∗ )

(45)

for all X. By iterated expectations, θgo is a solution to
max E

θg ∈g

Wg
J (X; ψ ∗ ) · q(Yg , X; θg )
Fg (X; γg∗ )

(46)

and, provided the mean function is well specified and the distribution of X is
sufficiently rich, θgo will be the unique solution. The conclusion is that, even if
P(Wg = 1|X) and P(D = 1|X) are misspecified, we consistently estimate the
parameters θgo in the correctly specified conditional mean,
E(Yg |X) = m g (X, θgo ).

(47)

Because D is unconfounded conditional on X,
E(Yg |X, D) = E(Yg |X)

(48)

and so
E(Yg |D = 1) = E[m g (X, θgo )|D = 1].

(49)

It follows that a consistent estimator of μg,1 = E(Yg |D = 1) is
μ̂g,1 =

−1
ND

N

Di · m g (X i , θ̂g ),

(50)

i=1

where N D is the number of observations with Di = 1.
5.2. Part 2: The Propensity Score is Correctly Specified
We are still interested in consistently estimating μg,1 = E(Yg |D = 1). Now we
assume that we have correctly specified parametric models for the propensity
scores and P(D = 1|X = x):
P(Wg = 1|X = x) = F(x, γgo )
P(D = 1|X = x) = J (x, ψ o ),

(51)
(52)

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

126

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

and we still maintain unconfoundedness with respect to Yg . In some cases we will
not estimate P(D = 1|X = x). From Lemma 3.2 and the structure of the QLL in
the LEF—see (39)—we know that because


Wg
1
·E
J (X, ψ o ) · q(Yg , X; θg ) = E q(Yg , X; θg )|D = 1
o
η
F(X, γg )

(53)



for all θg , the minimizer θg∗ of E q(Yg , X; θg )|D = 1 , which we assume is
unique, is also the minimizer of
E

Wg
J (X, ψ o ) · q(Yg , X; θg ) .
F(X, γgo )

(54)

By the convergence arguments in Section 5.1, the solution θ̂g to (43) is consistent
for θg∗ . So it remains to be shown that, for estimating μg,1 , having a consistent
estimator of θg∗ suffices.
In order to recover μg,1 from m g (X, θg∗ ), we need to know some further properties of the LEF family. As discussed in Wooldridge (2007), certain combinations
of QLLs and mean functions generate the important result
E(Yg |D = 1) = E[m g (X, θg∗ )|D = 1].

(55)

The key is that for a given LEF we choose the canonical link function to obtain
the conditional mean model. For the normal distribution, which leads to OLS
as the estimation method, the canonical link function leads to a mean linear in
parameters. It is well-known from linear regression analysis that, as long as an
intercept is included in the equation, the average of the fitted values is the same
as the average of the dependent variable. The population result also holds. Thus,
if we use a linear model m g (x, θg ) = αg + xβg , then it is always true that
E(Yg |D = 1) = E(αg∗ + Xβg∗ |D = 1).

(56)

The same is true for the Bernoulli QLL when we use a logistic function for the
mean:
m g (x, θg ) =

(αg + xβg ),

(57)

which means that if Yg is binary or fractional, then we should use the Bernoulli
QMLE with a logistic mean function. A third useful case is when Yg ≥ 0, in which
case the QLL-mean pair that delivers double robustness is the Poisson QLL and an
exponential mean function: m g (x, θg ) = exp(αg + xβg ). These cases are discussed
in more detail in Wooldridge (2007). See also Kaiser (2016) for an application of
the Poisson QMLE with an exponential mean function to decomposition problems. The new twist here is that the claims hold for any population we choose
to define via D = 1, and because D can be a treatment indicator or an indicator
based on X, we have a single double robustness result for a broad class of average

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

127

treatment effects. In addition, D can be an indicator of being in a subpopulation formed after treatment assignment, thereby allowing us to estimate treatment
effects for groups that have certain behavioral responses to treatment. This
appears to be novel.
6. SUMMARY DISCUSSION AND WIDER ISSUES
In this paper we unify the current literature on doubly robust estimators by
establishing identification of a large class of average treatment effects under
unconfoundedness. We cover binary and multi-valued treatments as well as the
average treatment effect, the average treatment effect on the treated, and average treatment effects for other subpopulations of interest (based on covariates).
We also extend this initial result to distribution, quantile, and inequality treatment effects, as well as to the local average treatment effect in a setting with an
instrumental variable. Further, we allow for both unnormalized and normalized
weighting, and cover standard inverse-probability weighted (IPW) estimators as
a special case.
Because doubly robust estimators involve models for both the conditional mean
and the propensity score, and require that at least one of these models is correctly
specified in order to remain consistent, we carefully describe each of these cases.
Similar to Wooldridge (2007), we consider estimation of the propensity score using
Bernoulli QMLE as well as estimation of the conditional mean using various QLLs
from the linear exponential family. More precisely, we consider three cases: OLS
with a linear mean function; Bernoulli QMLE with a logistic mean function; and
Poisson QMLE with an exponential mean function. These nonlinear mean functions have typically been ignored in recent work, even though they might provide
a useful alternative to a linear model for many outcome variables of interest.
Our contribution is essentially methodological, and we do not directly contribute to the philosophical underpinnings of causal inference, or to the debate on
the proper way to define causality. Nevertheless, our setup applies to several of
the causal frameworks discussed in the recent issue of this journal in honor of
Trygve Haavelmo’s contributions to structural equations and causal inference. As
was often the case in econometrics, the early giants in the field had a coherent,
deep understanding of their area of research, and Haavelmo is a leading example.
He understood that, when economists specify, say, a supply and demand system,
each has a hypothetical or counterfactual interpretation, and identification is synonymous with making assumptions about how observables are generated from the
underlying economic equations. Over the years there was slippage in the empirical application of simultaneous equations models in that researchers applied them
to settings where the underlying equations did not satisfy Ragnar Frisch’s autonomy requirement, as discussed recently by Heckman and Pinto (2015). See also
the Econometric Theory interview with Arthur Goldberger (Kiefer, 1989), who
lamented that the progress made by Frisch, Haavelmo, and others at the Cowles
Commission had eroded.

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

128

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

The papers by Heckman and Pinto (2015) and Pearl (2015) explicitly use a
counterfactual setting of the type we use here. Pearl’s do-calculus is what our
framework captures in the counterfactual outcomes Yg for different treatment
levels g. Had we used a different notation, say Y (w), where Y (w) is the random
outcome with, say, the price or policy set at w, then studying changes in Y (w)
as w changes is precisely the purpose of Pearl’s do-calculus for changing w.
Heckman and Pinto (2015, pp. 118–119) provide a very clear discussion of
Haavelmo’s hypothetical function in the context of the linear model. While we
do not consider continuous “treatment” variables W in this paper, the idea of
hypothetical or potential outcomes is paramount. Future research could study
extensions of our results in a setting that allows for multiple “treatment” variables
that can be continuous, discrete, or some mixture.
NOTES
1. However, Kang and Schafer (2007) and Long, Hsu, and Li (2012) noted that this approach to
estimation goes back at least as far as Cassel, Särndal, and Wretman (1976).
2. A non-technical introduction to AIPW estimators was provided by Glynn and Quinn (2010).
See also Kang and Schafer (2007) and Tan (2007).
3. This approach was applied to a multi-valued treatment effect framework and to a decomposition
framework by Uysal (2015) and Kaiser (2016), respectively. Both of these papers also considered an
extension to identification and estimation of the average treatment effect on the treated (ATT).
4. In a different setting, Kline (2011) demonstrated that parametric imputation—also referred to
as Oaxaca–Blinder—is also doubly robust in a particular way; namely, it has an alternative IPW representation, in which the weights are based on a linear model for the treatment odds. A similar result
had also been demonstrated by Robins et al. (2007).

REFERENCES
Abadie, A. (2002) Bootstrap tests for distributional treatment effects in instrumental variable models.
Journal of the American Statistical Association 97, 284–292.
Abadie, A., J. Angrist, & G. Imbens (2002) Instrumental variables estimates of the effect of subsidized
training on the quantiles of trainee earnings. Econometrica 70, 91–117.
Bang, H. & J.M. Robins (2005) Doubly robust estimation in missing data and causal inference models.
Biometrics 61, 962–972.
Belloni, A., V. Chernozhukov, I. Fernández-Val, & C. Hansen (2017) Program evaluation and causal
inference with high-dimensional data. Econometrica 85, 233–298.
Belloni, A., V. Chernozhukov, & C. Hansen (2014) Inference on treatment effects after selection
among high-dimensional controls. Review of Economic Studies 81, 608–650.
Cao, W., A.A. Tsiatis, & M. Davidian (2009) Improving efficiency and robustness of the doubly robust
estimator for a population mean with incomplete data. Biometrika 96, 723–734.
Cassel, C.M., C.E. Särndal, & J.H. Wretman (1976) Some results on generalized difference estimation
and generalized regression estimation for finite populations. Biometrika 63, 615–620.
Cattaneo, M.D. (2010) Efficient semiparametric estimation of multi-valued treatment effects under
ignorability. Journal of Econometrics 155, 138–154.
Cattaneo, M.D., D.M. Drukker, & A.D. Holland (2013) Estimation of multivalued treatment effects
under conditional independence. Stata Journal 13, 407–450.
Chernozhukov, V., I. Fernández-Val, & B. Melly (2013) Inference on counterfactual distributions.
Econometrica 81, 2205–2268.

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

129

Donald, S.G. & Y.C. Hsu (2014) Estimation and inference for distribution functions and quantile
functions in treatment effect models. Journal of Econometrics 178, 383–397.
Emsley, R., M. Lunt, A. Pickles, & G. Dunn (2008) Implementing double-robust estimators of causal
effects. Stata Journal 8, 334–353.
Farrell, M.H. (2015) Robust inference on average treatment effects with possibly more covariates than
observations. Journal of Econometrics 189, 1–23.
Firpo, S. & C. Pinto (2016) Identification and estimation of distributional impacts of interventions
using changes in inequality measures. Journal of Applied Econometrics 31, 457–486.
Foresi, S. & F. Peracchi (1995) The conditional distribution of excess returns: An empirical analysis.
Journal of the American Statistical Association 90, 451–466.
Frandsen, B.R., M. Frölich, & B. Melly (2012) Quantile treatment effects in the regression discontinuity design. Journal of Econometrics 168, 382–395.
Frölich, M. & B. Melly (2013) Unconditional quantile treatment effects under endogeneity. Journal
of Business & Economic Statistics 31, 346–357.
Glynn, A.N. & K.M. Quinn (2010) An introduction to the augmented inverse propensity weighted
estimator. Political Analysis 18, 36–56.
Gourieroux, C., A. Monfort, & A. Trognon (1984) Pseudo maximum likelihood methods: Theory.
Econometrica 52, 681–700.
Graham, B.S., C. Campos de Xavier Pinto, & D. Egel (2012) Inverse probability tilting for moment
condition models with missing data. Review of Economic Studies 79, 1053–1079.
Heckman, J. & R. Pinto (2015) Causal analysis after Haavelmo. Econometric Theory 31, 115–151.
Hirano, K. & G.W. Imbens (2001) Estimation of causal effects using propensity score weighting:
An application to data on right heart catheterization. Health Services & Outcomes Research Methodology 2, 259–278.
Horvitz, D.G. & D.J. Thompson (1952) A generalization of sampling without replacement from a
finite universe. Journal of the American Statistical Association 47, 663–685.
Hu, Z., D.A. Follmann, & J. Qin (2012) Semiparametric double balancing score estimation for incomplete data with ignorable missingness. Journal of the American Statistical Association 107, 247–257.
Imbens, G.W. (2000) The role of the propensity score in estimating dose-response functions.
Biometrika 87, 706–710.
Imbens, G.W. & J.D. Angrist (1994) Identification and estimation of local average treatment effects.
Econometrica 62, 467–475.
Kaiser, B. (2016) Decomposing differences in arithmetic means: A doubly robust estimation approach.
Empirical Economics 50, 873–899.
Kang, J.D.Y. & J.L. Schafer (2007) Demystifying double robustness: A comparison of alternative
strategies for estimating a population mean from incomplete data. Statistical Science 22, 523–539.
Kiefer, N.M. (1989) The ET interview: Arthur S. Goldberger. Econometric Theory 5, 133–160.
Kline, P. (2011) Oaxaca-Blinder as a reweighting estimator. American Economic Review: Papers &
Proceedings 101, 532–537.
Lee, M.-J. (2009) Non-parametric tests for distributional treatment effect for randomly censored
responses. Journal of the Royal Statistical Society: Series B 71, 243–264.
Liu, L., W. Miao, B. Sun, J. Robins, & E. Tchetgen Tchetgen (2015) Doubly robust estimation of a
marginal average effect of treatment on the treated with an instrumental variable. Unpublished.
Long, Q., C.H. Hsu, & Y. Li (2012) Doubly robust nonparametric multiple imputation for ignorable
missing data. Statistica Sinica 22, 149–172.
Lunceford, J.K. & M. Davidian (2004) Stratification and weighting via the propensity score in estimation of causal treatment effects: A comparative study. Statistics in Medicine 23, 2937–2960.
Maier, M. (2011) Tests for distributional treatment effects under unconfoundedness. Economics
Letters 110, 49–51.
Newey, W.K. & D. McFadden (1994) Large sample estimation and hypothesis testing. In R.F. Engle &
D. McFadden (eds.), Handbook of Econometrics, vol. 4, pp. 2111–2245. North Holland.
Ogburn, E.L., A. Rotnitzky, & J.M. Robins (2015) Doubly robust estimation of the local average
treatment effect curve. Journal of the Royal Statistical Society: Series B 77, 373–396.

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

130

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

Okui, R., D.S. Small, Z. Tan, & J.M. Robins (2012) Doubly robust instrumental variable regression.
Statistica Sinica 22, 173–205.
Pearl, J. (2015) Trygve Haavelmo and the emergence of causal calculus. Econometric Theory 31,
152–179.
Ridgeway, G. & D.F. McCaffrey (2007) Comment: Demystifying double robustness: A comparison
of alternative strategies for estimating a population mean from incomplete data. Statistical Science
22, 540–543.
Robins, J.M., A. Rotnitzky, & M. van der Laan (2000) Comment. Journal of the American Statistical
Association 95, 477–482.
Robins, J.M., A. Rotnitzky, & L.P. Zhao (1994) Estimation of regression coefficients when some
regressors are not always observed. Journal of the American Statistical Association 89, 846–866.
Robins, J.M., M. Sued, Q. Lei-Gomez, & A. Rotnitzky (2007) Comment: Performance of doublerobust estimators when “inverse probability” weights are highly variable. Statistical Science 22,
544–559.
Rothe, C. & S. Firpo (2015) Semiparametric two-step estimation using doubly robust moment conditions. Unpublished.
Rotnitzky, A., Q. Lei, M. Sued, & J.M. Robins (2012) Improved double-robust estimation in missing
data and causal inference models. Biometrika 99, 439–456.
Sant’Anna, P.H.C. (2016) Program evaluation with right-censored data. Unpublished.
Scharfstein, D.O., A. Rotnitzky, & J.M. Robins (1999) Rejoinder. Journal of the American Statistical
Association 94, 1135–1146.
Tan, Z. (2006a) A distributional approach for causal inference using propensity scores. Journal of the
American Statistical Association 101, 1619–1637.
Tan, Z. (2006b) Regression and weighting methods for causal inference using instrumental variables.
Journal of the American Statistical Association 101, 1607–1618.
Tan, Z. (2007) Comment: Understanding OR, PS and DR. Statistical Science 22, 560–568.
Tan, Z. (2010) Bounded, efficient and doubly robust estimation with inverse weighting. Biometrika
97, 661–682.
Tchetgen Tchetgen, E.J. & S. Vansteelandt (2013) Alternative identification and inference for the
effect of treatment on the treated with an instrumental variable. Unpublished.
Tsiatis, A.A. & M. Davidian (2007) Comment: Demystifying double robustness: A comparison of
alternative strategies for estimating a population mean from incomplete data. Statistical Science 22,
569–573.
Uysal, S.D. (2011) Doubly robust IV estimation of the local average treatment effect. Unpublished.
Uysal, S.D. (2015) Doubly robust estimation of causal effects with multivalued treatments: An application to the returns to schooling. Journal of Applied Econometrics 30, 763–786.
Vermeulen, K. & S. Vansteelandt (2015) Bias-reduced doubly robust estimation. Journal of the American Statistical Association 110, 1024–1036.
Wooldridge, J.M. (2005) Violating ignorability of treatment by controlling for too many factors.
Econometric Theory 21, 1026–1028.
Wooldridge, J.M. (2007) Inverse probability weighted estimation for general missing data problems.
Journal of Econometrics 141, 1281–1301.
Wooldridge, J.M. (2010) Econometric Analysis of Cross Section and Panel Data, 2nd ed. MIT Press.

APPENDIX A: Proofs
Proof of Lemma 3.2. The proof that




Wg
E
r (X)q(Yg , X) = E r (X)q(Yg , X)
pg (X)

(A.1)

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

131

is similar to Wooldridge (2007). However, Wooldridge assumes conditional independence
rather than the weaker conditional mean independence we use here. The current proof is
an implication of iterated expectations and unconfoundedness in mean:


 



Wg
Wg
r (X)q(Yg , X) = E E
r (X)q(Yg , X) Wg , X
E
pg (X)
pg (X)




Wg
r (X)E q(Yg , X)|Wg , X
=E
pg (X)




Wg
r (X)E q(Yg , X)|X
=E
pg (X)


Wg
(A.2)
r (X)h g (X) ,
≡E
pg (X)




where we use E q(Yg , X)|Wg , X = E q(Yg , X)|X ≡ h g (X). Now apply iterated expectations again:
 

 


Wg
Wg
r (X)h g (X) = E E
r (X)h g (X) X
E
pg (X)
pg (X)




E Wg |X
=E E
|X r (X)h g (X)
pg (X)


= E r (X)h g (X)


because E Wg |X = pg (X). Another application of iterated expectations gives the result
because







E r (X)q(Yg , X) = E r (X)E q(Yg , X)|X = E r (X)h g (X) .
Next, we show that




E r (X)q(Yg , X) = E D · q(Yg , X)

(A.3)

which again follows by iterated expectations and unconfoundedness in mean:


 


E D · q(Yg , X) = E E D · q(Yg , X) D, X



= E D · E q(Yg , X)|Wg , X


= E D · h g (X)




= E r (X)h g (X) = E D · q(Yg , X) .

(A.4)

Finally,






E D · q(Yg , X) = (1 − η) · E D · q(Yg , X)|D = 0 + η · E D · q(Yg , X)|D = 1


= η · E q(Yg , X)|D = 1 .

(A.5)

Combining the three pieces gives




Wg
E
r (X)q(Yg , X) = η · E q(Yg , X)|D = 1 ,
pg (X)
which completes the proof because η > 0 is assumed.

(A.6)


Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

132

TYMON SŁOCZYŃSKI AND JEFFREY M. WOOLDRIDGE

APPENDIX B: Implementation in Stata
We now discuss possible applications of our estimation methods in Stata, as well as
previous implementations of doubly robust estimators in this software package, such as
Emsley, Lunt, Pickles, and Dunn (2008), Cattaneo, Drukker, and Holland (2013), and the
teffects aipw and teffects ipwra commands in Stata 13.
In the first implementation that we are aware of, Emsley et al. (2008) introduced a
Stata command for the standard AIPW estimator of the ATE (dr). On the other hand,
Cattaneo et al. (2013) provided a Stata command (poparms) for estimating treatment
effects of multivalued treatments, including QTEs, but excluding, for example, the ATT.
The implemented (semiparametric) estimators are based on earlier work of Cattaneo
(2010), and hence both the conditional mean and the propensity score are estimated
using series estimators. When no polynomials are included in these models, poparms will
overlap with dr.
The standard AIPW estimator of the ATE is also implemented as teffects aipw
in Stata 13. Again, when no polynomials are included in poparms, it will overlap with
teffects aipw. Because our estimation methods are not AIPW, none of these implementations will overlap with our approach. To the best of our knowledge, the only exception is
teffects ipwra in Stata 13—which implements the estimation methods of Wooldridge
(2007) as well as some extensions of these methods which we discuss in this paper.
We provide further discussion in the following.
For simplicity, let us consider the case of a binary treatment. Let ovar and tvar be the
names of the outcome and treatment variables, respectively, and let xvars be the list of
names of control variables. We start with estimating the propensity scores.
. logit tvar xvars
. predict pscore
When the mean function is linear, we can estimate the ATE in the following way:
.
.
.
.
.
.

regress ovar xvars if tvar == 1 [pw = 1/pscore]
predict ot
regress ovar xvars if tvar == 0 [pw = 1/(1-pscore)]
predict oc
generate te = ot-oc
summarize te

An identical estimate can be obtained by typing:
. teffects ipwra (ovar xvars) (tvar xvars)
When the mean function is logistic or exponential, we can replace regress in the previous
procedure with logit or poisson, respectively. We can also obtain the same estimates by
simply typing:
. teffects ipwra (ovar xvars, logit) (tvar xvars)
. teffects ipwra (ovar xvars, poisson) (tvar xvars)
Alternatively, with a linear mean function, we can estimate the ATT in the following way:
.
.
.
.

regress
predict
regress
predict

ovar xvars if tvar == 1
ot
ovar xvars if tvar == 0 [pw = pscore/(1-pscore)]
oc

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

ESTIMATING AVERAGE TREATMENT EFFECTS

133

. generate te = ot-oc
. summarize te if tvar == 1
Again, an identical estimate can be obtained by typing:
. teffects ipwra (ovar xvars) (tvar xvars), atet
Extensions to logistic and exponential mean functions are analogous and straightforward.
On the other hand, quantile and inequality treatment effects as well as various parameters in instrumental variable models cannot be readily estimated using teffects ipwra.
A comprehensive implementation of estimators for all these cases is beyond the scope
of this paper, and we conclude this discussion with an implementation of our estimation
method for DTEs and QTEs.
Let y be the value of the outcome variable in which we are interested, that is, let it be
equal to y in τ1,dt e (y). We can then estimate the DTE in the following way:
.
.
.
.
.
.
.

generate oy = ovar<=y
logit oy xvars if tvar == 1 [pw = 1/pscore]
predict ot
logit oy xvars if tvar == 0 [pw = 1/(1-pscore)]
predict oc
generate te = ot-oc
summarize te

To obtain the QTE for a given quantile, it is sufficient to vary the value of y (y) and estimate
average values of Y1 (y) (ot) and Y0 (y) (oc) for each value. We can then estimate Q Y1 (t)
or Q Y0 (t) by finding the smallest y for which the estimated average value of Y1 (y) or
Y0 (y), respectively, is greater than or equal to t.

Downloaded from https://www.cambridge.org/core. Harvard University, on 07 Feb 2020 at 22:59:45, subject to the Cambridge Core terms of
use, available at https://www.cambridge.org/core/terms. https://doi.org/10.1017/S0266466617000056

