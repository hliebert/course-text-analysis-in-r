CHAPTER

1

Decomposition Methods in Economics
Nicole Fortin * , Thomas Lemieux ** , Sergio Firpo ***
* UBC and CIFAR
** UBC and NBER
*** EESP-FGV and IZA

Contents
1. Introduction
2. Identification: What Can We Estimate Using Decomposition Methods?
2.1. Case 1: The aggregate decomposition
2.1.1.
2.1.2.
2.1.3.
2.1.4.
2.1.5.
2.1.6.

The overall wage gap and the structural form
Four decomposition terms
Imposing identification restrictions: overlapping support
Imposing identification restrictions: ignorability
Identification of the aggregate decomposition
Why ignorability may not hold, and what to do about it

2.2. Case 2: The detailed decomposition

14
17
17
18
21
24

25

2.2.1. Nonparametric identification of structural functions
2.2.2. Functional form restrictions: decomposition of the mean
2.2.3. Functional form restrictions: more general decompositions

2.3. Decomposition terms and their relation to causality and the treatment effects literature
3. Oaxaca-Blinder—Decompositions of Mean Wages Differentials
3.1. Basics
3.2. Issues with detailed decompositions: choice of the omitted group
3.3. Alternative choices of counterfactual
3.4. Reweighted-regression decompositions
3.5. Extensions to limited dependent variable models
3.6. Statistical inference
4. Going beyond the Mean—Distributional Methods
4.1. Variance decompositions
4.2. Going beyond the variance: general framework
4.3. Residual imputation approach: JMP
4.4. Methods based on conditional quantiles
4.5. Reweighting methods
4.6. Methods based on estimating the conditional distribution
4.7. Summary
5. Detailed Decompositions for General Distributional Statistics
5.1. Methods based on the conditional distribution
5.2. RIF-regression methods
5.3. A reweighting approach
5.4. Detailed decomposition based on conditional quantiles
Handbook of Labor Economics, Volume 4a
c 2011 Elsevier B.V.

2
13
14

27
29
29

33
36
36
43
47
48
51
52
52
54
56
58
60
63
69
74
74
75
76
82
87

ISSN 0169-7218, DOI 10.1016/S0169-7218(11)00407-2
All rights reserved.

1

2

Nicole Fortin et al.

6. Extensions
6.1. Dealing with self-selection and endogeneity
6.2. Panel data
6.3. Decomposition in structural models
7. Conclusion
References

87
88
91
92
96
97

Abstract
This chapter provides a comprehensive overview of decomposition methods that have been
developed since the seminal work of Oaxaca and Blinder in the early 1970s. These methods are used
to decompose the difference in a distributional statistic between two groups, or its change over time,
into various explanatory factors. While the original work of Oaxaca and Blinder considered the case
of the mean, our main focus is on other distributional statistics besides the mean, such as quantiles,
the Gini coefficient or the variance. We discuss the assumptions required for identifying the different
elements of the decomposition, as well as various estimation methods proposed in the literature. We
also illustrate how these methods work in practice by discussing existing applications and working
through a set of empirical examples throughout the paper.
JEL classification: J31; J71; C14; C21
Keywords: Decomposition; Counterfactual distribution; Inequality; Wage structure; Wage differentials;
Discrimination

1. INTRODUCTION
What are the most important explanations accounting for pay differences between men
and women? To what extent has wage inequality increased in the United States between
1980 and 2010 because of increasing returns to skill? Which factors are behind most
of the growth in US GDP over the last 100 years? These important questions all share
a common feature. They are typically answered using decomposition methods. The
growth accounting approach pioneered by Solow (1957) and others is an early example
of a decomposition approach aimed at quantifying the contribution of labor, capital,
and unexplained factors (productivity) to US growth.1 But it is in labor economics,
starting with the seminal papers of Oaxaca (1973) and Blinder (1973), that decomposition
methods have been used the most extensively. These two papers are among the most
heavily cited in labor economics, and the Oaxaca-Blinder (OB) decomposition is now a
standard tool in the toolkit of applied economists. A large number of methodological
papers aimed at refining the OB decomposition, and expanding it to the case of
distributional parameters besides the mean, have also been written over the past three
decades.
The twin goals of this chapter are to provide a comprehensive overview of
decomposition methods that have been developed since the seminal work of Oaxaca and
1 See also Kendrick (1961), Denison (1962), and Jorgenson and Griliches (1967).

Decomposition Methods in Economics

Blinder, and to suggest a list of best practices for researchers interested in applying these
methods.2 We also illustrate how these methods work in practice by discussing existing
applications and working through a set of empirical examples throughout the chapter.
At the outset, it is important to note a number of limitations to decomposition
methods that are beyond the scope of this chapter. As the above examples show, the
goal of decomposition methods are often quite ambitious, which means that strong
assumptions typically underlie these types of exercises. In particular, decomposition
methods inherently follow a partial equilibrium approach. Take, for instance, the
question “what would happen to average wages in the absence of unions?”As H. Gregg
Lewis pointed out a long time ago (Lewis, 1963, 1986), there are many reasons to believe
that eliminating unions would change not only the wages of union workers, but also those
of non-union workers. In this setting, the observed wage structure in the non-union
sector would not represent a proper counterfactual for the wages observed in the absence
of unions. We discuss these general equilibrium considerations in more detail towards the
end of the paper, but generally follow the standard partial equilibrium approach where
observed outcomes for one group (or region/time period) can be used to construct
various counterfactual scenarios for the other group.
A second important limitation is that while decompositions are useful for quantifying
the contribution of various factors to a difference or change in outcomes in an accounting
sense, they may not necessarily deepen our understanding of the mechanisms underlying
the relationship between factors and outcomes. In that sense, decomposition methods,
just like program evaluation methods, do not seek to recover behavioral relationships
or “deep” structural parameters. By indicating which factors are quantitatively
important and which are not, however, decompositions provide useful indications of
particular hypotheses or explanations to be explored in more detail. For example, if a
decomposition indicates that differences in occupational affiliation account for a large
fraction of the gender wage gap, this suggests exploring in more detail how men and
women choose their fields of study and occupations.
Another common use of decompositions is to provide some “bottom line” numbers
showing the quantitative importance of particular empirical estimates obtained in a study.
For example, while studies after studies show large and statistically significant returns
to education, formal decompositions indicate that only a small fraction of US growth,
or cross-country differences, in GDP per capita can be accounted for by changes or
differences in educational achievement.
2 We limit our discussion to so-called “regression-based” decomposition methods, where the decomposition focuses
on explanatory factors, rather than decomposition methods that apply to additively decomposable indices, where the
decomposition pertains to population sub-groups. Bourguignon and Ferreira (2005) and Bourguignon et al. (2008) are
recent surveys discussing these methods.

3

4

Nicole Fortin et al.

Main themes and road map to the chapter
The original method proposed by Oaxaca and Blinder for decomposing changes or
differences in the mean of an outcome variable has been considerably improved and
expanded upon over the years. Arguably, the most important development has been to
extend decomposition methods to distributional parameters other than the mean. For
instance, Freeman (1980, 1984) went beyond a simple decomposition of the difference
in mean wages between the union and non-union sector to look at the difference in the
variance of wages between the two sectors.
But it is the dramatic increase in wage inequality observed in the United States and
several other countries since the late 1970s that has been the main driving force behind
the development of a new set of decomposition methods. In particular, the new methods
introduced by Juhn et al. (1993) and DiNardo et al. (1996) were directly motivated by an
attempt at better understanding the underlying factors behind inequality growth. Going
beyond the mean introduces a number of important econometric challenges and is still
an active area of research. As a result, we spend a significant portion of the chapter on
these issues.
A second important development has been to use various tools from the program
evaluation literature to (i) clarify the assumptions underneath popular decomposition
methods, (ii) propose estimators for some of the elements of the decomposition, and (iii)
obtain formal results on the statistical properties of the various decomposition terms. As
we explain below, the key connection with the treatment effects literature is that the
“unexplained” component of a Oaxaca decomposition can be interpreted as a treatment
effect. Note that, despite the interesting parallel with the program evaluation literature,
we explain in the paper that we cannot generally give a “causal” interpretation to the
decomposition results.
The chapter also covers a number of other practical issues that often arise when
working with decomposition methods. Those include the well known omitted group
problem (Oaxaca and Ransom, 1999), and how to deal with cases where we suspect the
true regression equation not to be linear.
Before getting into the details of the chapter, we provide here an overview of our
main contributions by relating them to the original OB decomposition for the difference
in mean outcomes for two groups A and B. The standard assumption used in these
decompositions is that the outcome variable Y is linearly related to the covariates, X ,
and that the error term υ is conditionally independent of X :
Ygi = βg0 +

K
X
k=1

X ik βgk + υgi ,

g = A, B,

(1)

Decomposition Methods in Economics

where E(υgi |X i ) = 0, and X is the vector of covariates (X i = [X i1 , . . . , X i K ]). As is
well known, the overall difference in average outcomes between group B and A,
bµ = Y B − Y A ,
1
O
can be written as:3

bµ =
1
O

bB0 − β
bA0 ) +
(β

K
X

X Bk

bBk − β
bAk
β

+

k=1

|

{z
b µ (Unexplained)
1
S

K
X


}


bAk
X Bk − X Ak β

|k=1
{z
}
b µ (Explained)
1
X

bg0 and β
bgk (k = 1, . . . , K ) are the estimated intercept and slope coefficients,
where β
respectively, of the regression models for groups g = A, B. The first term in the
equation is what is usually called the “unexplained” effect in Oaxaca decompositions.
Since we mostly focus on wage decompositions in this chapter, we typically refer to
µ
µ
this first element as the “wage structure” effect (1 S ). The second component, 1 X ,
is a composition effect, which is also called the “explained” effect (by differences in
covariates) in OB decompositions.
In the above decomposition, it is straightforward to compute both the overall
composition and wage structure effects, and the contribution of each covariate to
these two effects. Following the existing literature on decompositions, we refer to
µ
µ
µ
the overall decomposition (separating 1 O in its two components 1 S and 1 X ) as an
µ
aggregate decomposition. The detailed decomposition involves subdividing both 1 S , the wage
µ
structure effect, and 1 X , the composition effect, into the respective contributions of each
µ
µ
covariate, 1 S,k and 1 X,k , for k = 1, . . . , K .
The chapter is organized around the following “take away” messages:
3 The decomposition can also be written by exchanging the reference group used for the wage structure and composition
effects as follows:
) (
)
(
K
K
X
X


b µ = (β
bB0 − β
bA0 ) +
b
b
b
1
X
β
−
β
+
X
−
X
β
Ak
Bk
Ak
Bk
Ak
Bk .
O
k=1

k=1

Alternatively, the so-called three-fold
uses the same reference group
both effects, but introduces
n decomposition P
nfor
o
o

PK
b µ = (β
bB0 − β
bA0 ) + K X Ak β
bBk − β
bAk +
b
a third interaction term: 1
k=1
k=1 X Bk − X Ak β Ak +
O
nP

o
K
b
b
k=1 X Bk − X Ak β Bk − β Ak . While these various versions of the basic decomposition are used in the
literature, using one or the other does not involve any specific estimation issues. For the sake of simplicity, we thus
focus on the one decomposition introduced in the text for most of the chapter.

5

6

Nicole Fortin et al.

A. The wage structure effect can be interpreted as a treatment effect
This point is easily seen in the case where group B consists of union workers, and group
A consists of non-union workers. The raw wage gap 1µ can be decomposed as the sum
µ
of the “effect” of unions on union workers, 1 S , and the composition effect linked to
µ
differences in covariates between union and non-union workers, 1 X . We can think of
the effect of unions for each worker (Y Bi − Y Ai ) as the individual treatment effect, while
µ
1 S is the Average Treatment effect on the Treated (ATT). One difference between the
µ
program evaluation and decomposition approaches is that the composition effect 1 X
is a key component of interest in a decomposition, while it is a selection bias resulting
from a confounding factor to be controlled for in the program evaluation literature.
By construction, however, one can obtain the composition effect from the estimated
µ
µ
µ
µ
treatment effect since ATT = 1 S and 1 X = 1 O − 1 S .
Beyond semantics, there are a number of advantages associated with representing the
µ
decomposition component 1 S as a treatment effect:
• The zero conditional mean assumption (E(υ|X ) = 0) usually invoked in OB
decompositions (as above) is not required for consistently estimating the ATT (or
µ
1 S ). The mean independence assumption can be replaced by a weaker ignorability
assumption. Under ignorability, unobservables do not need to be independent (or
mean independent) of X as long as their conditional distribution given X is the same
in groups A and B. In looser terms, this “selection based on observables” assumption
allows for selection biases as long they are the same for the two groups. For example,
if unobservable ability and education are correlated, a linear regression of Y on X will
not yield consistent estimates of the structural parameters (i.e. the return to education).
But the aggregate decomposition remains valid as long as the dependence structure
between ability and education is the same in group A and B.
• A number of estimators for the ATT have been proposed in the program evaluation
literature including Inverse Probability Weighting (IPW), matching and regression
µ
methods. Under ignorability, these estimators are consistent for the ATT (or 1 S )
even if the relationship between Y and X is not linear. The statistical properties
of these non-parametric estimators are also relatively well established. For example,
Hirano et al. (2003) show that IPW estimators of the ATT are efficient. Firpo
(2007) similarly shows that IPW is efficient for estimating quantile treatment effects.
Accordingly, we can use the results from the program evaluation literature to show that
decomposition methods based on reweighting techniques are efficient for performing
decompositions.4
4 Firpo (2010) shows that for any smooth functional of the reweighted cdf, efficiency is achieved. In other words,
decomposing standard distributional statistics such as the variance, the Gini coefficient, or the interquartile range using
the reweighting method suggested by DiNardo et al. (1996) will be efficient. Note, however, that this result does
not apply to the (more complicated) case of the density considered by DiNardo et al. (1996) where non-parametric
estimation is involved.

Decomposition Methods in Economics

• When the distribution of covariates is different across groups, the ATT depends on
the characteristics of group B (unless there is no heterogeneity in the treatment effect,
µ
i.e. β Bk = β Ak for all k). The subcomponents of 1 S associated with each covariate k,
X Bk (β Bk − β Ak ), can be (loosely) interpreted as the “contribution” of the covariate k
to the ATT. This helps understand the issues linked to the well-known “omitted group
problem” in OB decompositions (see, for example Oaxaca and Ransom, 1999).

B. Going beyond the mean is a ‘‘solved’’ problem for the aggregate decomposition
As discussed above, estimation methods from the program evaluation literature can be
µ
directly applied for performing an aggregate decomposition of the gap 1 O into its two
µ
µ
components 1 S and 1 X . While most of the results in the program evaluation literature
have been obtained in the case of the mean (e.g., Hirano et al., 2003), they can also be
extended to the case of quantiles (Firpo, 2007) or more general distribution parameters
(Firpo, 2010). The IPW estimator originally proposed in the decomposition literature by
DiNardo et al. (1996) or matching methods can be used to perform the decomposition
under the assumption of ignorability. More parametric approaches such as those proposed
by Juhn et al. (1993), Donald et al. (2000) and Machado and Mata (2005) could also be
used. These methods involve, however, a number of assumptions and/or computational
difficulties that can be avoided when the sole goal of the exercise is to perform an
aggregate decomposition. By contrast, IPW methods involve no parametric assumptions
and are an efficient way of estimating the aggregate decomposition.
It may be somewhat of an overstatement to say that computing the aggregate
decomposition is a “solved” problem since there is still ongoing research on the small
sample properties of various treatment effect estimators (see, for example, Busso et al.,
2009). Nonetheless, performing an aggregate decomposition is relatively straightforward
since several easily implementable estimators with good asymptotics properties are
available.

C. Going beyond the mean is more difficult for the detailed decomposition
Until recently, no comprehensive approach was available for computing a detailed
decomposition of the effect of single covariates for a distributional statistic ν other
than the mean. One popular approach for estimating the subcomponents of 1νS is
Machado and Mata (2005)’s method, which relies on quantile regressions for each
possible quantile, combined with a simulation procedure. For the subcomponents of 1νX ,
DiNardo et al. (1996) suggest a reweighting procedure to compute the contribution
of a dummy covariate (like union status) to the aggregate composition effect 1νX .
Altonji et al. (2008) implemented a generalization of this approach to the case of
either continuous or categorical covariates. Note, however, that these latter methods
are generally path dependent, that is, the decomposition results depend on the order in

7

8

Nicole Fortin et al.

which the decomposition is performed. Later in this chapter, we show how to make the
contribution of the last single covariate path independent in the spirit of Gelbach (2009).
One comprehensive approach, very close in spirit to the original OB decomposition,
which is path independent, uses the recentered influence function (RIF) regressions
recently proposed by Firpo et al. (2009). The idea is to use the (recentered) influence
function for the distribution statistic of interest instead of the usual outcome variable Y as
the left hand side variable in a regression. In the special case of the mean, the recentered
influence function is Y , and a standard regression is estimated, as in the case of the OB
decomposition.
More generally, once the RIF regression has been estimated, the estimated coefficients can be used to perform the detailed decomposition in the same way as in the
standard OB decomposition. The downside of this approach is that RIF regression coefficients only provide a local approximation for the effect of changes in the distribution of
a covariate on the distributional statistics of interest. The question of how accurate this
approximation is depends on the application at hand.

D. The analogy between quantile and standard (mean) regressions is not
helpful
If the mean can be decomposed using standard regressions, can we also decompose
quantiles using simple quantile regressions? Unfortunately, the answer is negative. The
analogy with the case of the mean just does not apply in the case of quantile regressions.
To understand this point, it is important to recall that the coefficient β in a standard
regression has two distinct interpretations. Under the conditional mean interpretation, β
indicates the effect of X on the conditional mean E (Y |X ) in the model E (Y |X ) = Xβ.
Using the law of iterated expectations, we also have E (Y ) = E X [E (Y |X )] = E (X ) β.
This yields an unconditional mean interpretation where β can be interpreted as the effect
of increasing the mean value of X on the (unconditional) mean value of Y . It is this
particular property of regression models, and this particular interpretation of β, which is
used in OB decompositions.
By contrast, only the conditional quantile interpretation is valid in the case of quantile
regressions. As we discuss in more detail later, a quantile regression model for the τ th
conditional quantile Q τ (X ) postulates that Q τ (X ) = Xβτ . By analogy with the case
of the mean, βτ can be interpreted as the effect of X on the τ th conditional quantile
of Y given X . The law of iterated expectations does not apply in the case of quantiles,
so Q τ 6= E X [Q τ (X )] = E (X ) βτ , where Q τ is the unconditional quantile. It follows
that βτ cannot be interpreted as the effect of increasing the mean value of X on the
unconditional quantile Q τ .
This greatly limits the usefulness of quantile regressions in decomposition problems.
Machado and Mata (2005) suggest estimating quantile regressions for all τ ∈ [0, 1] as a
way of characterizing the full conditional distribution of Y given X . The estimates are

Decomposition Methods in Economics

then used to construct the different components of the aggregate decomposition using
simulation methods. Compared to other decomposition methods, one disadvantage of
this method is that it is computational intensive.
An alternative regression approach where the estimated coefficient can be interpreted
as the effect of increasing the mean value of X on the unconditional quantile Q τ (or
other distributional parameters) has recently been proposed by Firpo et al. (2009). As we
mention above, this method provides one of the few options available for computing a
detailed decomposition for distributional parameters other than the mean.

E. Decomposing proportions is easier than decomposing quantiles
A cumulative distribution provides a one-to-one mapping between (unconditional)
quantiles and the proportion of observations below this quantile. Performing a decomposition on proportions is a fairly standard problem. One can either run a linear probability model and perform a traditional OB decomposition, or do a non-linear version of
the decomposition using a logit or probit model.
Decompositions of quantiles can then be obtained by inverting back proportions into
quantiles. Firpo et al. (2007) propose doing so using a first order approximation where
the elements of the decomposition for a proportion are transformed into elements of the
decomposition for the corresponding quantile by dividing by the density (slope of the
cumulative distribution function). This can be implemented in practice by estimating
recentered influence function (RIF) regressions (see Firpo et al., 2009).
A related approach is to decompose proportions at every point of the distribution (e.g.
at each percentile) and invert back the whole fitted relationship to quantiles. This can be
implemented in practice using the distribution regression approach of Chernozhukov
et al. (2009).

F. There is no general solution to the ‘‘omitted group’’ problem
As pointed out by Jones (1983) and Oaxaca and Ransom (1999) among others, in the
µ
case of categorical covariates, the various elements of 1 S in a detailed decomposition
arbitrarily depend on the choice of the omitted group in the regression model. In fact,
this interpretation problem may arise for any covariate, including continuous covariates,
that does not have a clearly interpretable baseline value. This problem has been called
an identification problem in the literature (Oaxaca and Ransom, 1999; Yun, 2005). But
as pointed out by Gelbach (2002), it is better viewed as a conceptual problem with the
detailed part of the decomposition for the wage structure effect.
As discussed above, the effect β B0 − β A0 for the omitted group can be interpreted
as an average treatment effect among the omitted group (group for which X k = 0 for
all k = 1, . . . , K ). The decomposition then corresponds to a number of counterfactual
experiments asking “by how much the treatment effect would change if X k was switched
from its value in the omitted group (0) to its average value (X Bk )”? In cases like the

9

10

Nicole Fortin et al.

gender wage gap where the treatment effect analogy is not as clear, the same logic
applied, nonetheless. For example, one could ask instead “by how much the average
gender gap would change if actual experience (X k ) was switched from its value in the
omitted group (0) to its average value (X Bk )?”
Since the choice of the omitted group is arbitrary, the elements of the detailed
decomposition can be viewed as arbitrary as well. In cases where the omitted group has
a particular economic meaning, the elements of the detailed decomposition are more
interpretable as they correspond to interesting counterfactual exercises. In other cases the
elements of the detailed decomposition are not economically interpretable. As a result,
we argue that attempts at providing a general “solution” to the omitted group problem are
misguided. We discuss instead the importance of using economic reasoning to propose
some counterfactual exercise of interest, and suggest simple techniques to easily compute
these counterfactual exercises for any distributional statistics, and not only the mean.

Organization of the chapter
The different methods covered in the chapter, along with their key assumptions and
properties are listed in Table 1. The list includes an example of one representative study
for each method, focusing mainly on studies on the gender and racial gap (see also
Altonji and Blank, 1999), to facilitate comparison across methods. A detailed discussion
of the assumptions and properties follows in the next section. The mean decomposition
methodologies comprise the classic OB decomposition, as well as extensions that appeal
to complex counterfactuals and that apply to limited dependent variable models. The
methodologies that go beyond the mean include the classic variance decomposition,
methods based on residual imputation, methods based on conditional quantiles and
on estimating the conditional distribution, and methods based on reweighting and
RIF-regressions.
Since there are a number of econometric issues involved in decomposition exercises,
we start in Section 2 by establishing what are the parameters of interest, their interpretation, and the conditions for identification in decomposition methods. We also introduce
a general notation that we use throughout the chapter. Section 3 discusses exhaustively
the case of decomposition of differences in means, as originally introduced by Oaxaca
(1973) and Blinder (1973). This section also covers a number of ongoing issues linked
to the interpretation and estimation of these decompositions. We then discuss decompositions for distributional statistics other than the mean in Sections 4 and 5. Section 4
looks at the case of the aggregate decomposition, while Section 5 focuses on the case of
the detailed decomposition. Finally, we discuss a number of limitations and extensions
to these standard decomposition methods in Section 6. Throughout the chapter, we
illustrate the “nuts and bolts” of decomposition methods using empirical examples, and
discuss important applications of these methods in the applied literature.

Path dependent,
Detailed decomposition

Non-Linearity of E[Y |X ]

3.5 Non-linear OB: Fairlie (2005),
Bauer and Sinning (2008)

No detailed
decomposition
No detailed
decomposition
No detailed
decomposition

Linearity of V (Y |X ),
Invariance of conditional variance
Linearity of E[Y |X ],
Conditional rank preservation,
Complex counterfactualb
Linearity of Q τ (Y |X ),
Conditional rank preservation

4.1. Variance decompositions

4.3. Residual imputation
procedure: Juhn et al. (1991, 1993)

4.4. Quantile regressions methods:
Machado and Mata (2005),
Chernozhukov et al. (2009)

Going beyond the mean

Racial/Ethnic wage gaps:
Reimers (1983)

Path independent,
Detailed decomposition

Complex counterfactual,
Linearity of E[Y |X ],
Zero conditional mean

3.3. Weighted or pooled OB:
Oaxaca and Ransom (1994),
Cotton (1998)

(continued on next page)

Gender glass ceiling: Albrecht
et al. (2003)

Gender gap across countries:
Blau and Kahn (1992)

Union wage differentials:
Freeman (1980, 1984)

Racial gap in
self-employment: Fairlie
(1999)

Gender and racial wage gaps:
O’Neill and O’Neill (2006)

Representative applications

Path independent,
Detailed decomposition

Properties: limitations
and advantages

Linearity of E[Y |X ],
Zero conditional mean

Assumptionsa

3.1. Standard OB: Oaxaca
(1973)-Blinder (1973)

Mean decomposition

Methods

Table 1 Maintained assumptions and properties of major decomposition methodologies.

Decomposition Methods in Economics

11

Invariance of conditional
distribution
Invariance of conditional
distribution,
Conditional rank preservation
Invariance of conditional
distribution

4.5 Inverse propensity reweighting:
DiNardo et al. (1996)

4.6 Estimation of conditional
distribution: Chernozhukov et al.
(2009)

5.2 RIF regressions: Firpo et al.
(2007, 2009)

Path independent,
Detailed decomposition

Path dependent

Path dependent

Properties: limitations
and advantages

b In some applications, the counterfactual is an average over time periods or over countries.

a Unless otherwise indicated, the different methodologies appeal to a simple counterfactual treatment.

Assumptionsa

Methods

Table 1 (continued)

Racial wage gap: Heywood
and Parent (2009)

Racial wage gap: Melly
(2006)

Immigrant/Resident wage
differentials: Chiquiar and
Hanson (2005)

Representative applications

12
Nicole Fortin et al.

Decomposition Methods in Economics

2. IDENTIFICATION: WHAT CAN WE ESTIMATE USING DECOMPOSITION
METHODS?
As we will see in subsequent sections, a large and growing number of procedures are
available for performing decompositions of the mean or more general distributional
statistics. But despite this rich literature, it is not always clear what these procedures
seek to estimate, and what conditions need to be imposed to recover the underlying
objects of interest. The main contribution of this section is to provide a more formal
theory of decompositions where we clearly define what it is that we want to estimate
using decompositions, and what are the assumptions required to identify the population
parameters of interest. In the first part of the section, we discuss the case of the aggregate
decomposition. Since the estimation of the aggregate decomposition is closely related to
the estimation of treatment effects (see the introduction), we borrow heavily from the
identification framework used in the treatment effects literature. We then move to the
case of the detailed decomposition, where additional assumptions need to be introduced
to identify the parameters of interest. We end the section by discussing the connection
between program evaluation and decompositions, as well as the more general issue of
causality in this context.
Decompositions are often viewed as simple accounting exercises based on correlations. As such, results from decomposition exercises are believed to suffer from the
same shortcomings as OLS estimates, which cannot be interpreted as valid estimates of
some underlying causal parameters in most circumstances. The interpretation of what
decomposition results mean becomes even more complicated in the presence of general
equilibrium effects.
In this section, we argue that these interpretation problems are linked in part to the
lack of a formal identification theory for decompositions. In econometrics, the standard
approach is to first discuss identification (what we want to estimate, and what assumptions are required to interpret these estimates as sample counterparts of parameters of
interest) and then introduce estimation procedures to recover the object we want to
identify. In the decomposition literature, most papers jump directly to the estimation
issues (i.e. discuss procedures) without first addressing the identification problem.5
To simplify the exposition, we use the terminology of labor economics, where, in
most cases, the agents are workers and the outcome of interest is wages. Decomposition
methods can also be applied in a variety of other settings, such as gaps in test scores
between gender (Sohn, 2008), schools (Krieg and Storer, 2006) or countries (McEwan
and Marshall, 2004).
5 One possible explanation for the lack of discussion of identification assumptions is that they were reasonably obvious
in the case of the original OB decompositions for the mean. The situation is quite a bit more complex, however, in
the case of distributional statistics other than the mean. Note also that some recent papers have started addressing these
identification issues in more detail. See, for instance, Firpo et al. (2007), and Chernozhukov et al. (2009).

13

14

Nicole Fortin et al.

Throughout the chapter, we restrict our discussion to the case of a decomposition for
two mutually exclusive groups. This rules out decomposing wage differentials between
overlapping groups like Blacks, Whites, and Hispanics, who can be Black or White.6 In
this setting, the dummy variable method (Cain, 1986) with interactions is a more natural
way of approaching the problem. Then one can use Gelbach (2009)’s approach, which
appeals to the omitted variables bias formula, to compute a detailed decomposition.
The assumption of mutually exclusive groups is not very restrictive, however, since
most decomposition exercises fall into this category:
Assumption 1 (Mutually Exclusive Groups). The population of agents can be divided
into two mutually exclusive groups, denoted A and B. Thus, for an agent i,
D Ai + D Bi = 1, where Dgi = 1{i is in g}, g = A, B, and 1{·} is the indicator function.
We are interested in comparing features of the wage distribution for two groups
of workers: A and B. We observe wage Yi for worker i, which can be written as
Yi = Dgi Ygi , for g = A, B, where Ygi is the wage worker i would receive in group g.
Obviously, if worker i belongs to group A, for example, we only observe Y Ai .
As in the treatment effects literature, Y Ai and Y Bi can be interpreted as two potential
outcomes for worker i. While we only observe Y Ai when D Ai = 1, and Y Bi when
D Bi = 1, decompositions critically rely on counterfactual exercises such as “what
would be the distribution of Y A for workers in group B ?”. Since we do not observe
this counterfactual wage Y A|D B for these workers, some assumptions are required for
estimating this counterfactual distribution.

2.1. Case 1: The aggregate decomposition
2.1.1. The overall wage gap and the structural form
Our identification results for the aggregate decomposition are very general, and hold for
any distributional statistic.7 Accordingly, we focus on general distributional measures in
this subsection of the chapter.
Consider the case where the distributional statistic of interest is ν(FYg |D s ), where
ν: Fν → R is a real-valued functional, and where Fν is a class of distribution functions
such that FYg |D s ∈ Fν if |ν(FYg |D s )| < ∞, g, s = A, B. The distribution function
FYg |D s represents the distribution of the (potential) outcome Yg for workers in group s.
FYg |D s is an observed distribution when g = s, and a counterfactual distribution when
g 6= s.
6 Alternatively, the overlapping issue can bypassed by excluding Hispanics from the Black and White groups.
7 Many papers (DiNardo et al., 1996; Machado and Mata, 2005; Chernozhukov et al., 2009) have proposed
methodologies to estimate and decompose entire distributions (or densities) of wages, but the decomposition results
are ultimately quantified through the use of distributional statistics. Analyses of the entire distribution look at several of
these distributional statistics simultaneously.

Decomposition Methods in Economics

The overall ν-difference in wages between the two groups measured in terms of the
distributional statistic ν is


1νO = ν FY B |D B − ν FY A |D A .

(2)

The more common distributional statistics used to study wage differentials are the mean
and the median. The wage inequality literature has focused on the variance of log
wages, the Gini and Theil coefficients, and the differentials between the 90th and 10th
percentiles, the 90th and 50th percentiles, and the 50th and 10th percentiles. These latter
measures provide a simply way of distinguishing what happens at the top and bottom end
of the wage distribution. Which statistic ν is most appropriate depends on the problem
at hand.
A typical aim of decomposition methods is to divide 1νO , the ν-overall wage gap
between the two groups, into a component attributable to differences in the observed
characteristics of workers, and a component attributable to differences in wage structures. In our setting, the wage structure is what links observed characteristics, as well as
some unobserved characteristics, to wages.
The decomposition of the overall difference into these two components depends
on the construction of a meaningful counterfactual wage distribution. For example,
counterfactual states of the world can be constructed to simulate what the distribution
of wages would look like if workers had different returns to observed characteristics.
We may want to ask, for instance, what would happen if group A workers were paid
like group B workers, or if women were paid like men? When the two groups represent
different time periods, we may want to know what would happen if workers in year
2000 had the same characteristics as workers in 1980, but were still paid as in 2000. A
more specific counterfactual could keep the return to education at its 1980 level, but set
all the other components of the wage structure at their 2000 levels.
As these examples illustrate, counterfactuals used in decompositions often consist
of manipulating structural wage setting functions (i.e. the wage structure) linking the
observed and unobserved characteristics of workers to their wages for each group. We
formalize the role of the wage structure using the following assumption:
Assumption 2 (Structural Form). A worker i belonging to either group A or B is
paid according to the wage structure, m A and m B , which are functions of the worker’s
observable (X ) and unobservable (ε) characteristics:
Y Ai = m A (X i , εi )

and

Y Bi = m B (X i , εi ) ,

(3)

where εi has a conditional distribution Fε|X given X , and g = A, B.
While the wage setting functions are very general at this point, the assumption
implies that there are only three reasons why the wage distribution can differ between

15

16

Nicole Fortin et al.

group A and B. The three potential sources of differences are (i) differences between the
wage setting functions m A and m B , (ii) differences in the distribution of observable (X )
characteristics, and (iii) differences in the distribution of unobservable (ε) characteristics.
The aim of the aggregate decomposition is to separate the contribution of the first factor
(differences between m A and m B ) from the two others.
When the counterfactuals are based on the alternative wage structure (i.e. using the
observed wage structure of group A as a counterfactual for group B), decompositions
can easily be linked to the treatment effects literature. However, other counterfactuals
may be based on hypothetical states of the world, that may involve general equilibrium
effects. For example, we may want to ask what would be the distribution of wages if group
A workers were paid according to the pay structure that would prevail if there were no B
workers, for example if there were no union workers. Alternatively, we may want to ask
what would happen if women were paid according to some non-discriminatory wage
structure (which differs from what is observed for either men or women)?
We use the following assumption to restrict the analysis to the first type of counterfactuals.
Assumption 3 (Simple Counterfactual Treatment). A counterfactual wage structure, m C ,
is said to correspond to a simple counterfactual treatment when it can be assumed
that m C (·, ·) ≡ m A (·, ·) for workers in group B, or m C (·, ·) ≡ m B (·, ·) for workers in
group A.
It is helpful to represent the assumption using the potential outcomes framework
introduced earlier. Consider Yg|Ds ,where g = A, B indicates the potential outcome,
while s = A, B indicates group membership. For group A, the observed wage is Y A|D A ,
C
while Y B|D
represents the counterfactual wage. For group B, Y B|D B is the observed
A
C
. Note that we add the superscript C to
wage while the counterfactual wage is Y A|D
B
highlight counterfactual wages. For instance, consider the case where workers in group
B are unionized, while workers in group A are not unionized. The dichotomous variable
D B indicates the union status of workers. For a worker i in the union sector (D B = 1),
the observed wage under the “union” treatment is Y B|D B ,i = m B (X i , εi ), while the
C
counterfactual wage that would prevail if the worker was not unionized is Y A|D
=
B ,i
C
m (X i , εi ) = m A (X i , εi ), i ∈ B. An alternative counterfactual could ask what
C
would be the wage of a non-union worker j if this worker was unionized Y B|D
=
A, j
C
m (X j , ε j ) = m B (X j , ε j ), j ∈ A. We note that the choice of which counterfactual to
choose is analogous to the choice of reference group in standard OB decomposition.8
What Assumption 3 rules out is the existence of another counterfactual wage structure such as m ∗ (·) that represents how workers would be paid if there were no unions in
8 When we construct the counterfactual Y C , we choose g to be the reference group and s the group whose wages are
g|D
s

C
“adjusted”. Thus counterfactual women’s wages if they were paid like men would be Ym|D
, although the gender gap
f

example is more difficult to conceive in the treatment effects literature.

Decomposition Methods in Economics

the labor market. Unless there are no general equilibrium effects, we would expect that
m ∗ (·) 6= m A (·), and, thus, Assumption 3 to be violated.
2.1.2. Four decomposition terms
With this setup in mind, we can now decompose the overall difference 1νO into the four
following components of interest:
D.1 Differences associated with the return to observable characteristics under the structural m functions. For example, one may have the following counterfactual in mind:
What if everything but the return to X was the same for the two groups?
D.2 Differences associated with the return to unobservable characteristics under the
structural m functions. For example, one may have the following counterfactual in
mind: What if everything but the return to ε was the same for the two groups?
D.3 Differences in the distribution of observable characteristics. We have here the
following counterfactual in mind: What if everything but the distribution of X was
the same for the two groups?
D.4 Differences in the distribution of unobservable characteristics. We have the following counterfactual in mind: What if everything but the distribution of ε was the
same for the two groups?
Obviously, because unobservable components are involved, we can only decompose
into the four decomposition terms after imposing some assumptions on the joint
distribution of observable and unobservable characteristics. Also, unless we make additional separability assumptions on the structural forms represented by the m functions,
it is virtually impossible to separate out the contribution of returns to observables from
that of unobservables. The same problem prevails when one tries to perform a detailed
decomposition in returns, that is, provide the contribution of the return to each covariate
separately.
1νO

2.1.3. Imposing identification restrictions: overlapping support
The first assumption we make to simplify the discussion is to impose a common support
assumption on the observables and unobservables. Further, this assumption ensures that
no single value of X = x or ε = e can serve to identify membership into one of the
groups.

0
Assumption 4 (Overlapping Support). Let the support of all wage setting factors X 0 , ε0

0
be X × E . For all x 0 , e0 in X × E , 0 < Pr[D B = 1|X = x, ε = e] < 1.
Note that the overlapping support assumption rules out cases where inputs may
be different across the two wage setting functions. The case of the wage gap between

17

18

Nicole Fortin et al.

immigrant and native workers is an important example where the X vector may be
different for two groups of workers. For instance, the wage of immigrants may depend
on their country of origin and their age at arrival, two variables that are not defined for
natives. Consider also the case of changes in the wage distribution over time. If group
A consists of workers in 1980, and group B of workers in 2000, the difference in wages
over time should take into account the fact that many occupations of 2000, especially
those linked to information technologies, did not even exist in 1980. Thus, taking those
differences explicitly into account could be important for understanding the evolution
of the wage distribution over time.
The case with different inputs can be formalized as follows. Assume that for group A,
there is a d A + l A vector of observable and unobservable characteristics [X 0A , ε0A ]0 that
may include components not included in the d B + l B vector of characteristics [X 0B , ε0B ]0
for group B, where dg and l g denote the length of the X g and εg vectors, respectively.
Define the intersection of these characteristics by the d + l vector [X 0 , ε0 ]0 , which
represent characteristics common to both groups. The respective complements, which
, ε0B ]0 , such
are group-specific characteristics, are denoted by tilde as [X 0Ae, ε0Ae]0 and [X 0e
B e
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
, ε B ] ∪ [X , ε ] = [X B , ε B ]0 .
that [X Ae, ε Ae] ∪ [X , ε ] = [X A , ε A ] and [X e
B e
In that context, the overlapping support assumption could be restated by letting
the support of all wage setting factors [X 0A , ε0A ]0 ∪ [X 0B , ε0B ]0 be X × E . The overlapping support assumption would then guarantee that, for all [x 0 , e0 ]0 in X × E ,
0 < Pr[D B = 1|[X 0A , X 0B ] = x, [ε0A , ε0B ] = e] < 1. The assumption rules out the
, ε0B ].
existence of the vectors [X 0Ae, ε0Ae] and [X 0e
B e
In the decomposition of gender wage differentials, it is not uncommon to have
explanatory variables for which this condition does not hold. Black et al. (2008) and
Ñopo (2008) have proposed alternative decompositions based on matching methods to
address cases where they are severe gaps in the common support assumption (for observables). For example, Ñopo (2008) divides the gap into four additive terms. The first two
are analogous to the above composition and wage structure effects, but they are computed only over the common support of the distributions of observable characteristics,
while the other two account for differences in support.
2.1.4. Imposing identification restrictions: ignorability
We cannot separate out the decomposition terms (D.1) and (D.2) unless we impose some
separability assumptions on the functional forms of m A and m B . For highly complex
nonlinear functions of observables X and unobservables ε, there is no clear definition
of what would be the component of the m functions associated with either X or ε. For
instance, if X and ε represent years of schooling and unobserved ability, respectively, we
may expect the return to schooling to be higher for high ability workers. As a result,

Decomposition Methods in Economics

there is an interaction term between X or ε in the wage equation m(X, ε), which makes
it hard to separate the contribution of these two variables to the wage gap.
Thus, consider the decomposition term D.1* that combines (D.1) and (D.2):
D.1* Differences associated with the return to observable and unobservable characteristics in the structural m functions.
This decomposition term solely reflects differences in the m functions. We call this
decomposition term 1νS , or the “ν-wage structure effect” on the “ν-overall difference”,
1νO . The key question here is how to identify the three decomposition terms (D.1*),
(D.3) and (D.4) which, under Assumption 4, fully describe 1νO ?
We denote the decomposition terms (D.3) and (D.4) as 1νX and 1νε , respectively.
They capture the impact of differences in the distributions of X and ε between groups
B and A on the overall difference, 1νO . We can now write
1νO = 1νS + 1νX + 1νε .
Without further assumptions we still cannot identify these three terms. There are
two problems. First, we have not imposed any assumption for the identification of the m
functions, which could help in our identification quest. Second, we have not imposed
any assumption on the distribution of unobservables. Thus, even if we fix the distribution
of covariates X to be the same for the two groups, we cannot clearly separate all three
components because we do not observe what would happen to the unobservables under
this scenario.
Therefore, we need to introduce an assumption to make sure that the effect of manipulations of the distribution of observables X will not be confounded by changes in the
distribution of ε. As we now show formally, the assumption required to rule out these
confounding effects is the well-known ignorability, or unconfoundedness, assumption.
Consider a few additional concepts before stating our main assumption. For each
member of the two groups g = A, B, an outcome variable Ygi and some individual characteristics X i are observed. Yg and X have a conditional joint distribution,
FYg ,X|Dg (·, ·) : R × X → [0, 1], and X ⊂ Rk is the support of X .
The distribution of Yg |Dg is defined using the law of iterated probabilities, that is,
after we integrate over the observed characteristics we obtain
FYg |Dg (y) =

Z

FYg |X,Dg (y|X = x) · dFX |Dg (x) ,

g = A, B.

(4)

We can construct a counterfactual marginal wage distribution that mixes the conditional distribution of Y A given X and D A = 1 using the distribution of X |D B . We
denote that counterfactual distribution as FY C :X =X |D B , which is the distribution of
A

19

20

Nicole Fortin et al.

wages that would prevail for group B workers if they were paid like group A workers.
This counterfactual distribution is obtained by replacing FY B |X,D B with FY A |X,D A (or
FX |D A with FX |D B ) in Eq. (4):
Z
FY C :X =X |D B =
A

FY A |X,D A (y|X = x) · dFX |D B (x) .

(5)

These types of manipulations play a very important role in the implementation of
decomposition methods. Counterfactual decomposition methods can either rely on
manipulations of FX , as in DiNardo et al. (1996), or of FY |X , as in Albrecht et al. (2003)
and Chernozhukov et al. (2009).9
Back to our union example, FY B |X,D B (y|X = x) represents the conditional distribution of wages observed in the union sector, while FY A |X,D A (y|X = x) represents the
conditional distribution of wages observed in the non-union sector. In the case where
g = B, Eq. (4) yields, by definition, the wage distribution in the union sector where we
integrate the conditional distribution of wages given X over the marginal distribution
of X in the union sector, FX |D B (x). The counterfactual wage distribution FY C :X =X |D B
A
is obtained by integrating over the conditional distribution of wages in the non-union
sector instead (Eq. (5)). It represents the distribution of wages that would prevail if union
workers were paid like non-union workers.
The connection between these conditional distributions and the wage structure is
easier to see when we rewrite the distribution of wages for each group in terms of the
corresponding structural forms,

FYg |X,Dg (y|X = x) = Pr m g (X, ε) ≤ y|X = x, Dg = 1 ,

g = A, B.

Conditional on X , the distribution of wages only depends, therefore, on the conditional distribution of ε, and the wage structure m g (·).10 When we replace the
conditional distribution in the union sector, FY B |X,D B (y|X = x), with the conditional
distribution in the non-union sector, FY A |X,D B (y|X = x), we are replacing both the
wage structure and the conditional distribution of ε. Unless we impose some further
assumptions on the conditional distribution of ε, this type of counterfactual exercise will
not yield interpretable results as it will mix differences in the wage structure and in the
distribution of ε.
9 Chernozhukov et al. (2009) discuss the conditions under which the two types of decomposition are equivalent.
10 To see more explicitly how the conditional distribution F
Yg |X,Dg (·) depends on the distribution of ε, note that we can


−1
write FYg |X,Dg (y|X = x) = Pr ε ≤ m g (X, y) |X = x, Dg = 1 under the assumption that m(·) is monotonic
in ε (see Assumption 9 introduced below).

Decomposition Methods in Economics

To see this formally, note that unless ε has the same conditional distribution across groups,
the difference
Z
FY B |D B − FY C :X =X |D B = (Pr (Y ≤ y|X = x, D B = 1)
A

− Pr (Y ≤ y|X = x, D A = 1)) · dFX |D B (x)
Z
= (Pr (m B (X, ε) ≤ y|X = x, D B = 1)
− Pr (m A (X, ε) ≤ y|X = x, D A = 1)) · dFX |D B (x) (6)
will mix differences in m functions and differences in the conditional distributions of ε
given X .
We are ultimately interested in a functional ν (i.e. a distributional statistic)
of the wage distribution. The above result means that, in general, 1νS 6= ν(FY B |D B ) −
ν(FY C :X =X |D B ). The question is under what additional assumptions will the difference
A
between a statistic from the original distribution of wages and the counterfactual distribution, 1νS = ν(FY B |D B ) − ν(FY C :X =X |D B ), solely depend on differences in the wage
A
structure? The answer is that under a conditional independence assumption, also known
as ignorability of the treatment in the treatment effects literature, we can identify 1νS and
the remaining terms 1νX and 1νε .
Assumption 5 (Conditional Independence/Ignorability). For g = A, B, let (Dg , X, ε)
have a joint distribution. For all x in X : ε is independent of Dg given X = x or,
equivalently, Dg yε|X .
In the case of the simple counterfactual treatment, the identification restrictions from
the treatment effects literature may allow the researcher to give a causal interpretation to
the results of the decomposition methodology as discussed in Section 2.3. The ignorability assumption has become popular in empirical research following a series of papers
by Rubin and coauthors and by Heckman and coauthors.11 In the program evaluation
literature, this assumption is sometimes called unconfoundedness or selection on observables,
and allows identification of the treatment effect parameter.
2.1.5. Identification of the aggregate decomposition
We can now state our main result regarding the identification of the aggregate decomposition
Proposition 1 (Identification of the Aggregate Decomposition). Under Assumption 3
(simple counterfactual), 4 (overlapping support), and 5 (ignorability), the overall ν-gap, 1νO , can
11 See, for instance, Rosenbaum and Rubin (1983, 1984), Heckman et al. (1997a,b) and Heckman et al. (1998).

21

22

Nicole Fortin et al.

be written as
1νO = 1νS + 1νX ,
where
(i) the wage structure term 1νS = ν(FY B |D B ) − ν(FY C :X =X |D B ) solely reflects the difference
A
between the structural functions m B (·, ·) and m A (·, ·)
(ii) the composition effect term 1νX = ν(FY C :X =X |D B ) − ν(FY A |D A ) solely reflects the effect of
A
differences in the distribution of characteristics ( X and ε) between the two groups.
This important result means that, under the ignorability and overlapping assumptions,
we can give a structural interpretation to the aggregate decomposition that is formally
linked to the underlying wage setting models, Y A = m A (X, ε) and Y B = m B (X, ε).
Note also that the wage structure (1νS ) and composition effect (1νX ) terms represent
algebraically what we have informally defined by terms D.1* and D.3.
As can be seen from Eq. (6), the only source of difference between FY B |D B and
FY C :X =X |D B is the difference between the structural functions m B (·) and m A (·). Now
A
note that under Assumptions 4 and 5, we have that 1νO = 1νS + ν(FY C :X =X |D B ) −
A
ν(FY A |D A ), where
FY C :X =X |D B − FY A |D A
A
Z

= Pr (Y ≤ y|X = x, D A = 1) · dFX |D B (x) − dFX |D A (x) .
Thus, ν(FY C :X =X |D B ) − ν(FY A |D A ) reflects only changes or differences in the distribuA
tion of observed covariates. As a result, under Assumptions 4 and 5, we identify 1νX by
ν(FY C :X =X |D B ) − ν(FY A |D A ) and set 1νε = 0. This normalization makes sense as a result
A
of the conditional independence assumption: no difference in wages will be systematically attributed to differences in distributions of ε once we fix these distributions to be
the same given X . Thus, all remaining differences beyond 1νS are due to differences in
the distribution of covariates captured by 1νX .
Combining these two results, we get
h
i h
i
1νO = ν(FY B |D B ) − ν(FY C :X =X |D B ) + ν(FY C :X =X |D B ) − ν(FY A |D A )
= 1νS + 1νX

A

A

(7)

which is the main result in Proposition 1.
When the Assumption 3 (simple counterfactual) and 5 (ignorability) are satisfied,
the conditional distribution of Y given X remains invariant under manipulations of the

Decomposition Methods in Economics

marginal distribution of X . It follows that Eq. (5) represents a valid counterfactual for
the distribution of Y that would prevail if workers in group B were paid according to
the wage structure m A (·). The intuition for this result is simple. Since Y A = m A (X, ε),
manipulations of the distribution of X can only affect the conditional distribution of
Y A given X if they either (i) change the wage setting function m A (·), or (ii) change the
distribution of ε given X . The first change is ruled out by the assumption of a simple
counterfactual treatment (i.e. no general equilibrium effects), while the second effect is
ruled out by the ignorability assumption.
In the inequality literature, the invariance of the conditional distribution is often
introduced as the key assumption required for FY C :X =X |D B to represent a valid counterA
factual (e.g. DiNardo et al., 1996; Chernozhukov et al., 2009).
Assumption 6 (Invariance of Conditional Distributions). The construction of the counterfactual wage distribution for workers of group B that would have prevailed if they
were paid like group A workers (described in Eq. (5)), assumes that the conditional wage
distribution FY A |X,D A (y|X = x) applies or can be extrapolated for x ∈ X , that is, it
remains valid when the marginal distribution FX |D B replaces FX |D A .
One useful contribution of this chapter is to show the economics underneath this
assumption, i.e. that the invariance assumption holds provided that there are no general
equilibrium effects (ruled out by Assumption 3) and no selection based on unobservables
(ruled out by Assumption 5).
Assumption 6 is also invoked by Chernozhukov et al. (2009) to perform the aggregate
decomposition using the following alternative counterfactual that uses group B as the
reference group. Let FY C :X =X |D A be the distribution of wages that would prevail for
B
group A workers under the conditional distribution of wages of group B workers. In
our union example, this would represent the distribution of wages of non-union workers
that would prevail if they were paid like union workers. Relative to Eq. (7), the terms of
the decomposition equation are now inverted:
h
i h
i
1νO = ν(FY B |D B ) − ν(FY C :X =X |D A ) + ν(FY C :X =X |D A ) − ν(FY A |D A )
=

1νX

+ 1νS .

B

B

Now the first term 1νX is the composition effect and the second term 1νS the wage
structure effect.
Whether the assumption of the invariance of the conditional distribution is likely to
be satisfied in practice depends on the economic context. If group A were workers in
2005 and group B were workers in 2007, perhaps Assumption 6 would be more likely
to hold than if group A were workers in 2007 and group B were workers in 2009 in the
presence of the 2009 recession. Thus it is important to provide an economic rationale

23

24

Nicole Fortin et al.

to justify Assumption 6 in the same way the choice of instruments has to be justified in
terms of the economic context when using an instrumental variable strategy.
2.1.6. Why ignorability may not hold, and what to do about it
The conditional independence assumption is a somewhat strong assumption. We discuss
three important cases under which it may not hold:
1. Differential selection into labor market. This is the selection problem that Heckman
(1979) is concerned with in describing the wage offers for women. In the case of the
gender pay gap analysis, it is quite plausible that the decisions to participate in the labor
market are quite different for men and women. Therefore, the conditional distribution of (X, ε) |D B = 1 may be different from the distribution of (X, ε) |D B = 0. In
that case, both the observed and unobserved components may be different, reflecting
the fact that men participating in the labor market may be different in observable and
unobservable ways from women who also participate. The ignorability assumption
does not necessarily rule out the possibility that these distributions are different, but it
constrains their relationship. Ignorability implies that the joint densities of observables
and unobservables for groups A and B (men and women) have to be similar up to a
ratio of conditional probabilities:
f X,ε|D B (x, e|1) = f X,ε|D B (x, e|0) · f X |D B (x|1) / f X |D B (x|0)

 

Pr (D B = 1|X = x)
Pr (D B = 0)
= f X,ε|D B (x, e|0) ·
·
.
Pr (D B = 0|X = x)
Pr (D B = 1)
2. Self-selection into groups A and B based on unobservables. In the gender gap example
there is no selection into groups, although the consequences of differential selection
into the labor market are indeed the same. An example where self-selection based on
unobservables may occur is in the analysis of the union wage gap. The conditional
independence or ignorability assumption rules out selection into groups based on
unobservable components ε beyond X . However, the ignorability assumption does
not impose that (X, ε) yD B , so the groups may have different marginal distributions
of ε. But if selection into groups is based on unobservables, then the ratio of conditional joint densities will in general depend on the value of e being evaluated, and not
only on x, as ignorability requires:

 

f X,ε|D B (x, e|1)
Pr (D B = 1|X = x)
Pr (D B = 0)
6=
·
.
f X,ε|D B (x, e|0)
Pr (D B = 0|X = x)
Pr (D B = 1)
3. Choice of X and ε. In the previous case, the values of X and ε are not determined by
group choice, although they will be correlated and may even explain the choice of the
group. In the first example of the gender pay gap, values of X and ε such as occupation
choice and unobserved effort may also be functions of gender ‘discrimination’. Thus,

Decomposition Methods in Economics

the conditional independence assumption will not be valid if ε is a function of Dg ,
even holding X constant. The interpretation of ignorability here is that given the
choice of X , the choice of ε will be randomly determined across groups. Pursuing the
gender pay gap example, fixing X (for example education), men and women would
exert the same level of effort. The only impact of anticipated discrimination is that
they may invest differently in education.
In Section 6, we discuss several solutions to these problems that have been proposed
in the decomposition literature. Those include the use of panel data methods or standard
selection models. In case 2 above, one could also use instrumental variable methods to
deal with the fact that the choice of group is endogenous. One identification issue we
briefly address here is that IV methods would indeed yield a valid decomposition, but
only for the subpopulation of compliers.
To see this, consider the case where we have a binary instrumental variable Z , which
is independent of (ε, T ) conditional on X , where T is a categorical variable which
indicates ‘type’. There are four possible types: a, n, c and d as described below:
Assumption 7 (LATE). For g = A, B, let (Dg , X, Z , ε) have a joint distribution in
{0, 1} × X × {0, 1} × E . We define T , a random variable that may take on four values
{a, n, c, d}, and that can be constructed using D B and Z according to the following
rule: if Z = 0 and D B = 0, then T ∈ {n, c}; if Z = 0 and D B = 1, then T ∈ {a, d};
if Z = 1 and D B = 0, then T ∈ {n, d}; if Z = 1 and D B = 1, then T ∈ {a, c}.
(i) For all x in X : Z is independent of (ε, T ).
(ii) Pr (T = d|X = x) = 0.
These are the LATE assumptions from Imbens and Angrist (1994), which allow us
to identify the counterfactual distribution of Y AC |X, D B = 1, T = c. We are then able
to decompose the ν-wage gap under that less restrictive assumption, but only for the
population of compliers:
h
i
1νO|T =c = ν(FY B |D B ,T =c ) − ν(FY C :X =X |D B ,T =c )
A
h
i
+ ν(FY C :X =X |D B ,T =c ) − ν(FY A |D A ,T =c )
A

= 1νS|T =c + 1νX |T =c .

2.2. Case 2: The detailed decomposition
One convenient feature of the aggregate decomposition is that it can be performed without any assumption on the structural functional forms, m g (X, ε), while constraining the

25

26

Nicole Fortin et al.

distribution of unobserved (ε) characteristics.12 Under the assumptions of Proposition 1,
the composition effect component 1νX reflects differences in the distribution of X , while
the wage structure component 1νS reflects differences in the returns to either X or ε.
To perform a detailed decomposition, we need to separate the respective contributions of X or ε in both 1νS and 1νX , in addition to separating the individual contribution
of each element of the vector of covariates X . Thus, generally speaking, the identification of an interpretable detailed decomposition involves stronger assumptions such
as functional form restrictions and/or further restrictions on the distribution of ε, like
independence with respect to X and D.
Since these restrictions tend to be problem specific, it is not possible to present a
general identification theory as in the case of the aggregate decomposition. We discuss
instead how to identify the elements of the detailed decomposition in a number of
specific cases. Before discussing these issues in detail, it is useful to state what we seek to
recover with a detailed decomposition.
Property 1 (Detailed Decomposition). A procedure is said to provide a detailed decomposition when it can apportion the composition effect, 1νX , or the wage structure effect, 1νS , into
components attributable to each explanatory variable:
1. The contribution of each covariate X k to the composition effect, 1νX k , is the portion of 1νX
that is only
P K due νto differences between the distribution of X k in groups A and B. When
1νX = k=1
1 X k , the detailed decomposition of the composition effect is said to add up.
2. The contribution of each covariate X k to the wage structure effect, 1νSk , is the portion of
1νS that is only due to differences in the parameters associated with X k in group A and B,
i.e. to differences in the parameters of m A (·, ·) and m B (·, ·) linked to X k . Similarly, the
contribution of unobservables ε to the wage structure effect, 1νSε , is the portion of 1νS that is
only due to differences in the parameters associated with ε in m A (·, ·) and m B (·, ·).
Note that unobservables do not make any contribution to the composition effect
because of the ignorability assumption we maintain throughout most of the chapter.
As we mentioned earlier, it is also far from clear how to divide the parameters of the
functions m A (·, ·) and m B (·, ·) into those linked to a given covariate or to unobservables.
For instance, in a model with a rich set of interactions between observables and unobservables, it is not obvious which parameters should be associated with a given covariate.
As a result, computing the elements of the detailed decomposition for the wage structure
involves arbitrary choices to be made depending on the economic question of interest.
The adding-up property is automatically satisfied in linear settings like the standard
OB decomposition, or the RIF-regression procedure introduced in Section 5.2. However, it is unlikely to hold in non-linear settings when the distribution of each individual
12 Differences in the distribution of the ε are fairly constrained under the ignorability assumption. While the
unconditional distribution of ε may differ between group A and B (because of differences in the distribution of X ),
the conditional distribution of ε has to be the same for the two groups.

Decomposition Methods in Economics

covariate X k is changed while keeping the distribution of the other covariates unchanged
(e.g. in the case discussed in Section 5.3). In such a procedure “with replacement” we
would, for instance, first replace the distribution of X 1 for group A with the distribution
of X 1 for group B, then switch back to the distribution of X 1 for group A and replace
the distribution of X 2 instead, etc.
By contrast, adding up would generally be satisfied in a sequential (e.g. “without
replacement”) procedure where we first replace the distribution of X 1 for group A with
the distribution of X 1 for group B, and then do the same for each covariate until the
whole distribution of X has been replaced. The problem with this procedure is that
it would introduce some path dependence in the decomposition since the “effect” of
changing the distribution of one covariate generally depends on distribution of the other
covariates.
For example, the effect of changes in the unionization rate on inequality may depend
on the industrial structure of the economy. If unions have a particularly large effect in
the manufacturing sector, the estimated effect of the decline in unionization between,
say, 1980 and 2000 will be larger under the distribution of industrial affiliation observed
in 1980 than under the distribution observed in 2000. In other words, the order of
the decomposition matters when we use a sequential (without replacement) procedure,
which means that the property of path independence is violated. As we will show later in
the chapter, the lack of path independence in many existing detailed decomposition procedures based on a sequential approach is an important shortcoming of these approaches.
Property 2 (Path Independence). A decomposition procedure is said to be path independent
when the order in which the different elements of the detailed decomposition are computed does
not affect the results of the decomposition.
A possible solution to the problem of path dependence suggested by Shorrocks (1999)
consists of computing the marginal impact of each of the factors as they are eliminated
in succession, and then averaging these marginal effects over all the possible elimination
sequences. He calls the methodology the Shapley decomposition, because the resulting
formula is formally identical to the Shapley value in cooperative game theory. We return
to these issues later in the chapter.
2.2.1. Nonparametric identification of structural functions
One approach to the detailed decomposition is to identify the structural functions
m A (·, ·) and m B (·, ·), and then use the knowledge of these structural forms to compute various counterfactuals of interest. For example, one could look at what happens
when all the parameters of m A (·, ·) pertaining to education are switched to their values
estimated for group B, while the rest of the m A (·, ·) function remains unchanged.
For the purpose of identifying the structural functions m A (·, ·) and m B (·, ·), neither
ignorability nor LATE assumptions are very helpful. Stronger assumptions invoked in the

27

28

Nicole Fortin et al.

literature on nonparametric identification of structural functions (e.g. Matzkin, 2003;
Blundell and Powell, 2007; Imbens and Newey, 2009) have to be used instead:
Assumption 8 (Independence). For g = A, B, X yε|Dg .
Assumption 9 (Strict Monotonicity in the Random Scalar ε). For g = A, B and for all
values x in X , ε is a scalar random variable and m g (X, ε) is strictly increasing in ε.
With these two additional assumptions we can write, for g = A,B, the functions
m g (·, ·) using solely functionals of the joint distribution of Y, Dg , X . We can assume
without loss of generality that ε|Dg ∼ U [0, 1], because (i) we observe the conditional
distributions of X |Dg , and ε is a scalar random variable independent of X given Dg .
Once we have identified the functions m g (·, ·) for g = A, B, we can construct the
counterfactual distribution of FY C :X =X |D B and compute any distributional statistic of
A

interest.13
Note, however, that the monotonicity assumption is not innocuous in the context
of comparisons across groups. If there was only one group of workers, the monotonicity
assumption would be a simple normalization. With more than one group, however, it
requires that the same unobservable variable has positive returns for all groups of workers,
which in some settings may not be plausible, though this is automatically satisfied in
additively separable models.
There are various reasons why this assumption may be problematic in practice.
Empirical wage distributions exhibit many flat spots because of heaping or minimum
wage effects. For example, if group A and B corresponded to two different years or
countries with different minimum wages, the monotonicity assumption would not
be satisfied.14 The monotonicity assumption would also break down in the presence
of measurement error in wages since the wage residual would now mix measurement
error and unobserved skills. As a result, the same amount of unobserved skills would not
guarantee the same position in the conditional distribution of residuals in the two groups.
In most labor economics applications, assuming that unobservables are independent
of the covariates is a strong and unrealistic assumption. Thus, the identification of the
structural functions comes at a relatively high price. The milder assumption of ignorability allows us to identify 1νS and 1νX . With full independence, we can go back and
identify more terms. In fact, because we obtain an expression for 1νS , we can construct
detailed decompositions by fixing deterministically the values of some covariates while
letting others vary.
13 This monotonicity assumption can also be found in the works of Matzkin (2003), Altonji and Matzkin (2005), Imbens
and Newey (2009), and Athey and Imbens (2006).
14 The rank pairing of two outcome variables Y and Y will be disrupted if the rank of Y remains the same because
A
B
A
at a mass point corresponding to the minimum wage, while the rank of Y B continues to increase in the absence of
minimum wage at the rank. Heckman et al. (1997a,b) consider the case of mass points at zero, but the case of multiple
mass points is much more difficult.

Decomposition Methods in Economics

2.2.2. Functional form restrictions: decomposition of the mean
A more common approach used in the decomposition literature consists of imposing
functional form restrictions to identify the various elements of a detailed decomposition. For instance, detailed decompositions can be readily computed in the case of the
mean using the assumptions implicit in Oaxaca (1973) and Blinder (1973). The first
assumption is additive linearity of the m g (·, ·) functions. The linearity assumption is also
commonly used in quantile-based decomposition methodologies, such as Albrecht et al.
(2003), Machado and Mata (2005), and Melly (2006). The linearity assumption allows
for heteroscedasticity due, for example, to the fact that the variance of unobservables
increases as educational attainment increases.
Assumption 10 (Additive Linearity). The wage structure, m A and m B , are linear additively separable functions in the worker’s observable and unobservable characteristics:
Ygi = m g (X i , εi ) = X i βg + υig ,

g = A, B

where υig = h g (εi ).
The second assumption implicit in the OB procedure is that the conditional mean of
υig is equal to zero:
Assumption 11 (Zero Conditional Mean). E[υg |X, D B ] = 0.
Under mean independence, we have that for g = A, B, E[Yg |Dg = 1] =
E[X |Dg = 1]βg and therefore we can write the mean counterfactual µ(FY C :X =X |D B )
A
as E [X |D B = 1] β A . Therefore,
µ

1 S = E [X |D B = 1] (β B − β A )

µ

and 1 X = (E [X |D B = 1] − E [X |D B = 0]) β A .

2.2.3. Functional form restrictions: more general decompositions
Under Assumption 11, the error term conveniently drops out of the decomposition for
the mean. For more general distributional statistics such as the variance, however, we
need more assumptions about the distribution of unobservables to perform a detailed
decomposition. If we add the following assumptions on the conditional wage variance
and on the function of the unobservables υig , we can separate out the wage structure
effects of observables and unobservables.
Assumption 12 (Constant Returns to Unobservables). For g = A, B, υg = σg ε.
Assumption 13 (Homoscedasticity). For g = A, B, Var[ε|X, Dg = 1] = 1.
Under these two additional assumptions, we can identify σg , and interpret it as the
price of unobservables.15 Assumption 10 (additive linearity) then allows us to separate

29

30

Nicole Fortin et al.

out returns to observable and unobservable factors, and to separately identify the contribution of observable and unobservable factors to the wage structure effect. Note that
because of the zero conditional mean assumption, only the observable factors influence
mean wages.
More formally, consider the counterfactual wage, Y AC,1 , for group B workers where
the return to unobservables is set to be as in group A,16
Y AC,1 = Xβ B + σ A ε.

(8)

Under the Assumption 5, and 9 to 13, we can divide the wage structure effect into
a component linked to unobservables, 1νS,σ , and a component linked to observables,
1νS,β , as follows
h
i
ν(FY B |D B ) − ν(FY C,1 :X =X |D )
B
1νS = |
{z A
}
ν
1
S,σ
h
i
+|

ν(FY A C,1 :X =X |D B ) − ν(FY A C :X =X |D B )
{z
}.
1νS,β

The above assumptions correspond to those implicitly used by Juhn et al. (1991) in
their influential study on the evolution of the black-white wage gap.17 While it is useful
to work with a single “price” of unobservables σg , doing so is not essential for performing a detailed decomposition. Juhn et al. (1993) [JMP] use a weaker set of assumptions in
their influential study of wage differentials over time that we now discuss in more detail.
JMP propose a residual imputation procedure that relies on the key assumption
that the rank of worker i in the distribution of υ A is the same as in the distribution of
υ B , conditional on X . This procedure enables them to perform a decomposition even
when the function h g (·) used to define the regression error υg = h g (ε) is not linear
(non-linear skill pricing). Since the (conditional) rank of υg normalized on a [0, 1] scale
is simply the cumulative distribution Fυ B |X (·) evaluated at that point, conditional rank
preservation can be stated as follows in our context:
Assumption 14 (Conditional Rank Preservation). For all individual i, we have τ Ai (xi ) =
τ Bi (xi ), where τ Ai (xi ) = Fυ A |X (υ Ai |X = xi ) and τ Bi (xi ) = Fυ B |X (υ Bi |X = xi ) are
the rankings of υ Ai and υ Bi in their respective conditional distributions.
15 Note that it is possible to relax the homoskedasticity assumption while maintaining the assumption of a single price of
unobservables σg , as in Chay and Lee (2000). We do not follow this approach here to simplify the presentation.
16 Note that we depart somewhat from our previous notation, as Y C,1 retains some components of the structural form
A

of group B, which will disappear in Y AC,3 below.
17 See Blau and Kahn (1992, 2003) for an application of the methodology to the study of gender wage differentials across
countries.

Decomposition Methods in Economics

Under this assumption, if individual i in group A observed at rank Fυ A |X (υi A |X =
xi ) were in group B instead, he/she would remain at the same rank in the conditional
distribution of υ for that other group (and vice versa). Conditional rank preservation is a
direct consequence of the assumptions of ignorability (Assumption 5) and monotonicity
(Assumption 9). Under ignorability, the distribution of ε given X does not depend on
group membership. Since υ A = h A (ε) and υ B = h B (ε), the rank of υ A and υ A in their
respective distributions is the same as the rank of ε, provided that h A (·) and h B (·) are
monotonic.
Note that the assumption of rank preservation is substantially stronger than ignorability. For instance, consider the case where ε is a vector of two ability measures:
cognitive ability and manual ability. If cognitive ability is more valued under the wage
structure m A (·) than under the wage structure m B (·), the ranking of workers in the
A and B distributions will be different, which means that neither monotonicity nor rank
preservation will hold. But provided that the conditional distribution of cognitive and
manual ability given X is the same for groups A and B, ignorability holds, which means
that the aggregate decomposition is still identified.
We explain how to implement the JMP procedure in practice in Section 4.3.
Compared to the procedure described above to construct the counterfactual wage,
Y AC,1 = Xβ B + σ A ε, the difference is that an imputed residual from the group A
distribution is used instead of σ A ε. The idea is to replace υ Bi with rank τ Bi (xi ) in the
conditional distribution of υ B with an imputed error term
−1
υ C,2
Ai = Fυ A |X (τ Bi (x i ), x i ).

(9)

The resulting counterfactual wage for group B workers,
C,2
Y Ai
= Xβ B + υ C,2
Ai ,

(10)

can then be used to compute the following two elements of the decomposition:
1νS,σ = ν(FY B |D B ) − ν(FY C,2 :X =X |D )
B

A

and

1νS,β = ν(FY C,2 :X =X |D ) − ν(FY C :X =X |D B ).
A

B

A

One important implementation issue we discuss in Section 4.3 is how to impute
residuals conditional on X . This is an important limitation of JMP’s procedure that can
be addressed in a number of ways. One popular approach is to use conditional quantile
regressions to allow for different returns to observables that vary along the conditional
wage distribution. This approach was proposed by Machado and Mata (2005) and reexamined by Albrecht et al. (2003) and Melly (2005). It relies on the assumption that the

31

32

Nicole Fortin et al.

conditional distribution of Yg |X, Dg , is completely characterized by the collection of
regression quantiles {βg,τ ; τ ∈ (0, 1)}.
Assumption 15 (Heterogenous Returns to Observables). For g = A, B, Ygi = X i βg,τ +
h g,τ (εi ).
Assumption 16 (Complete Collection of Linear Conditional Quantiles). For g = A, B,
and ∀τ ∈ (0, 1) τ = Pr(Yg ≤ xβg,τ |X = x, Dg = 1).
The above assumptions plus ignorability allow the decomposition of 1νO into 1νS and
1νX . Note that because τ = FYg |X,Dg (xβg,τ |X = x) for all τ , we are fully parameterizing the conditional distribution of Yg |X, Dg by βg,τ using all τ ∈ (0, 1). Thus, once
one inverts the conditional quantile to obtain a conditional CDF, one can apply Eq. (4)
and (5) to compute an actual or counterfactual distribution.
Many other decomposition methods have been proposed to deal with parametric and
nonparametric identification of conditional distribution functions. We have discussed
the JMP procedure, as well as extensions to the case of conditional quantiles, as a way of
illustrating the kind of assumptions required for identifying detailed decompositions of
general distributional statistics. The general message is that more stringent assumptions
have to be imposed to perform a detailed decomposition instead of an aggregate decomposition. The same general message would apply if we had discussed the identification
of other decomposition procedures such as (to cite a few examples) Donald et al. (2000),
Fortin and Lemieux (1998), Melly (2005), Chernozhukov et al. (2009), and Rothe
(2009) instead.
Finally, it is also possible to relax some of the above assumptions provided that other
assumptions are used instead. For instance, if one fixes the prices of unobservables to
be the same across groups, say to a unit price, then 1νS,σ reflects in fact changes in the
distribution of unobservables. In that case, ignorability does not hold, but because of
linearity and zero conditional mean assumptions
we can identify the parameter β’s. The

difference between Q B,τ (X i ) − X i β B and Q A,τ (X i ) − X i β A is interpreted as
differences in the τ -quantile of the conditional distribution of ε given X across groups
B and A (Q g,τ (X ) is the τ -quantile of the conditional distribution of Y for group g).
Let us state the following normalization assumption.
Assumption 17 (Unit Price to Unobservables). For g = A, B, υg = σg ε = ε.
The overall wage gap can then be decomposed as follows
1νO = 1νS + 1νε + 1νX
h
i
ν(FY B |D B ) − ν(FY C :(X,ε)=(X,ε)|D B )
= |
{zA
}
1νS

Decomposition Methods in Economics

h
i
ν(FY C :(X,ε)=(X,ε)|D B ) − ν(FY C :X =X |D B )
A
A
+ |
{z
}
ν
1ε
h
i
ν(FY C :X =X |D B ) − ν(FY A |D A )
A
+ |
{z
}.
1νX

(11)

Because of Assumptions 10, 12 and 17, we now have Y A = Xβ A + ε and Y B = Xβ B + ε.
The first difference 1νS , corresponds to differences in β’s only; the second difference is
due to differences in
FY C :(X,ε)=(X,ε)|D B − FY C :X =X |D B ,
A

A

which are explained by differences in the conditional distribution of ε given X across
groups B and A. Thus, an easy way to obtain that difference is to construct a counterfactual
C,3
= X i β A + (Y Bi − X i β B ) ,
Y Ai

(12)

and to replace FY C :(X,ε)=(X,ε)|D B with FY C,3 :(X,ε)=(X,ε)|D given that they will be
B
A
A
equivalent under the above functional form assumptions.
Finally, the difference 1νX can be obtained as a residual difference. However, under the
maintained assumptions it shall reflect only differences in the marginal distributions of X .

2.3. Decomposition terms and their relation to causality and the treatment effects literature
We end this section by discussing more explicitly the connection between decompositions and various concepts introduced in the treatment effects literature. As it turns out,
when the counterfactuals are based on hypothetical alternative wage structures, they can
be easily linked to the treatment effects literature. For example: What if group A workers
were paid according to the wage structure of group B? What if all workers were paid
according to the wage structure of group A?
Define the overall average treatment effect (ATE) as the difference between average
wages if everybody were paid according to the wage structure of group B and average
wages if everybody were paid according to the wage structure of group A. That is:
ATE = E [Y B ] − E [Y A ] ,
where switching a worker of from “type A” to “type B” is thought to be the “treatment”.

33

34

Nicole Fortin et al.

We also define the average treatment effect on the treated (ATT) as the difference
between actual average wages of group B workers and average wages if group B workers
were paid according to the pay structure of group A. That is:
ATT = E [Y B |D B = 1] − E [Y A |D B = 1] .
These treatment effects can be generalized to other functionals or statistics of the
wage distribution. For example, define ν-TE, the ν-treatment effect, as


ν-TE = ν FY B − ν FY A ,
and its version applied to the subpopulation of “treated”, ν-TT as


ν-TT = ν FY B |D B − ν FY A |D B .
The distributions FY B , FY A and FY A |D B are not observed from data on (Y, D B , X ).18
Following the treatment effects literature, we could in principle identify these parameters if “treatment” was randomly assigned. This is hardly the case, at least for our
examples, and one needs extra identifying restrictions. In fact, we note that ignorability
and common support assumptions (which together are termed strong ignorability after
(Rosenbaum and Rubin, 1983)) are sufficient to guarantee identification of the previous
parameters. For example under strong ignorability, for g = A, B
i
h
FY g (y) = E FY |X,D g (y|X ) ,


FY A |D B (y) = E FY |X,D A (y|X ) |D B = 1 .
Under ignorability, it follows that FY A |D B ∼ FY C :X =X |D B . Then 1νS = ν-TT and
A
= ν(FY B |D B ) − ν(FY A |D A ) − (ν-TT). Reweighting methods, as discussed by
DiNardo et al. (1996), Hirano et al. (2003) and Firpo (2007, 2010) have implicitly or
explicitly assumed strong ignorability to identify specific ν-treatment effects.
It is interesting to see how the choice of the reference or base group is related to the
treatment effects literature. Consider the treatment effect parameter for the non-treated,
ν-TNT:
1νX



ν-TNT = ν FY B |D A − ν FY A |D A .
18 Only F
Y B |D B and FY A |D A are observed.

Decomposition Methods in Economics

Under strong ignorability, we have FY B |D A (·) = E[FY |X,D B (·|X ) |D B = 0] =
FY C :X =X |D A (·). Thus, in this case, 1νS = ν-TNT and 1νX = ν(FY B |D B ) − ν(FY A |D A ) −
B
(ν-TNT).
We could also consider other decompositions, such as:




ν FY B |D B − ν FY A |D A = ν-TE + ν FY B |D B − ν FY B


+ ν FY A − ν FY A |D A ,
where FY B includes the actual wages of group B workers and the counterfactual wages
of group A workers if they were are paid like group B workers, and conversely for FY A .
In this case, the wage structure effect is ν-TE, while the composition effect is the sum
(ν(FY B |D B ) − ν(FY B )) + (ν(FY A ) − ν(FY A |D A )).19
The above discussion reveals that the reference group choice problem is just a matter
of choosing a meaningful counterfactual. There will be no right answer. In fact, we see
that analogously to the treatment effects literature, where treatment effect parameters
are different from each other because they are defined over distinct subpopulations, the
many possible ways of performing decompositions will reflect the reference group that
we want to emphasize.
We conclude this section by discussing briefly the relationship between causality, structural parameters and decomposition terms. In this section, we show that the
decomposition terms do not necessarily rely on the identification of structural forms.
Whenever we can identify those structural functions linking observable and unobservable
characteristics to wages, we benefit from being able to perform counterfactual analysis
that we may not be able to do otherwise. However, that comes at the cost of having
to impose either strong independence assumptions, as in the case of nonparametric
identification, or restrictive functional form assumptions plus some milder independence
assumption (mean independence, for instance) between observables and unobservables
within each group of workers.
If we are, however, interested in the aggregate decomposition terms 1νX and 1νS ,
we saw that a less restrictive assumption is sufficient to guarantee identification of
these terms. Ignorability is the key assumption here as it allows fixing the conditional
distribution of unobservables to be the same across groups. The drawback is that we
cannot separate out the wage structure effects associated with particular observable and
unobservable characteristics.
The treatment effects literature is mainly concerned with causality. Under what
conditions can we claim that although identifiable under ignorability, 1νS may have a
causal interpretation? The conditions under which we could say that 1νS is a causal
19 We note that this last decomposition corresponds, in the OB context, to the so-called three-fold decomposition
presented in footnote 3.

35

36

Nicole Fortin et al.

parameter are very stringent and unlikely to be satisfied in general cases. There are two
main reasons for that, in our view.
First, in many cases, “treatment” is not a choice or a manipulable action. When
decomposing gender or race gaps in particular, we cannot conceive workers choosing
which group to belong to.20 They may have different labor market participation behavior, which is one case where ignorability may not hold, as discussed in Section 2.1.6.
However, workers cannot choose treatment. Thus, if we follow, for example, Holland
(1986)’s discussion of causality, we cannot claim that 1νS is a causal parameter.
A second reason for failing to assign causality to the pay structure effect is that most
of the observable variables considered as our X (or unobservables ε) are not necessarily
pre-treatment variables.21 In fact, X may assume different values as a consequence of
the treatment. In the treatment effects literature, a confounding variable X may have
different distributions across treatment groups. But that is not a direct action of the
treatment. It should only be a selection problem: People who choose to be in a group
may have a different distribution of X relative to people who choose to be in the other
group. When X is affected by treatment, we cannot say that controlling for X we will
obtain a causal parameter. In fact, what we will obtain is a partial effect parameter, netted
from the indirect effect through changes in X .

3. OAXACA-BLINDER—DECOMPOSITIONS OF MEAN WAGES DIFFERENTIALS
In this section, we review the basics of OB decompositions, discussing at length some
thorny issues related to the detailed decomposition. We also address alternative choices
of counterfactuals, including the case of the pooled regression that uses a group membership dummy to obtain a measure of the aggregate wage structure effect. We introduce
a reweighted-regression decomposition as an attractive alternative when the linearity of
the conditional mean as a function of the covariates is questionable. Finally, we briefly
discuss the extensions of OB decompositions to limited dependent variable models,
which carry some of the issues, such as path dependence, that will surface in methods
that go beyond the mean.

3.1. Basics
Despite its apparent simplicity, there are many important issues of estimation and interpretation in the classic OB decomposition. The goal of the method is to decompose
differences in mean wages, µ, across two groups. The wage setting model is assumed to
be linear and separable in observable and unobservable characteristics (Assumption 10):
Yg = Xβg + υg ,

for g = A, B

20 The union/non-union wage gaps or private/public sector wage gaps are more amenable to choice.
21 Note that some analyses (e.g. Neal and Johnson, 1996) take great care to focus on pre-market variables.

(13)

Decomposition Methods in Economics

where E[υg |X ] = 0 (Assumption 11). Letting D B = 1 be an indicator of group B
µ
membership, and taking the expectations over X , the overall mean wage gap 1 O can be
written as
µ

1 O = E[Y B |D B = 1] − E[Y A |D B = 0]
= E[E(Y B |X, D B = 1)|D B = 1] − E[E(Y A |X, D B = 0)|D B = 0]
= (E [X |D B = 1] β B + E [υ B |D B = 1]) − (E [X |D B = 0] β A + E [υ A |D B = 0])

where E [υ A |D B = 0] = E [υ B |D B = 1] = 0. Adding and subtracting the average
counterfactual wage that group B workers would have earned under the wage structure
of group A, E [X |D B = 1] β A , the expression becomes
µ

1 O = E [X |D B = 1] β B − E [X |D B = 1] β A
+ E [X |D B = 1] β A − E [X |D B = 0] β A
= E [X |D B = 1] (β B − β A ) + (E [X |D B = 1] − E [X |D B = 0]) β A
µ
µ
= 1S + 1 X .
Replacing the expected value of the covariates E [X |D B = d], for d = 0, 1, by the
sample averages X g , the decomposition is estimated as
bB − X B β
bA + X B β
bA − X A β
bA
bµ = X B β
1
O


bB − β
bA + X B − X A β
bA
= XB β
=

bµ
1
S

bµ .
+1
X

(14)
(15)
(16)

b µ , while the second term
The first term in Eq. (15) is the wage structure effect, 1
S
µ
b . Note that in cases where group membership is linked to
is the composition effect, 1
X
some immutable characteristics of the workers, such as race or gender, the wage structure
effect has also been called the “unexplained” part of the wage differentials or the part
due to “discrimination”.
The OB decomposition is very easy to use in practice. It is computed by plugging
bg in the above formula. Various good
in the sample means and the OLS estimates β
implementations of the procedure are available in existing software packages.22 Table 2
displays the various underlying elements of the decomposition in the case of the gender
wage gap featured in O’Neill and O’Neill (2006) using data from the NLSY79. The
composition effect is computed as the difference between the male and female means
reported in column (1) multiplied by the male coefficients reported in column (2).23
22 The empirical applications of the OB procedure in this chapter use Jann (2008) procedures in Stata.

37

Female
Education and skill level
<10 yrs.
10-12 yrs (no diploma or GED)
HS grad (diploma)
HS grad (GED)
Some college
BA or equiv. degree
MA or equiv. degree
Ph.D or prof. Degree
AFQT percentile score (x.10)
L.F. withdrawal due to family resp.
Lifetime work experience
Years worked civilian
Years worked military
% worked part-time

1
0.032
0.104
0.298
0.045
0.307
0.153
0.054
0.007
3.971
0.547
15.559
0.060
0.135

0
0.053
0.124
0.326
0.056
0.231
0.155
0.041
0.015
4.231
0.129
17.160
0.578
0.049

(0.003)
(0.005)
(0.099)

(0.028)
(0.042)
(0.031)
(0.037)
(0.052)
(0.077)
(0.004)
(0.025)

−0.013
0.032
0.164
0.380
0.575
0.862
0.042
−0.078
0.038
0.024
−0.749

(0.043)

−0.027
(0.029)
(0.044)
(0.030)
(0.036)
(0.046)
(0.100)
(0.004)
(0.019)
0.030 (0.002)
0.042 (0.013)
−0.197 (0.049)

−0.002
−0.012
0.101
0.282
0.399
0.763
0.041
−0.083

−0.089 (0.050)

(0.028)
(0.042)
(0.031)
(0.037)
(0.052)
(0.077)
(0.004)
(0.025)

−0.003
0.006
0.131
0.330
0.468
0.807
0.042
−0.067

(0.020)
(0.030)
(0.022)
(0.026)
(0.034)
(0.060)
(0.003)
(0.015)

−0.045 (0.033)

0.038 (0.003)
0.033 (0.002)
0.024 (0.005)
0.021 (0.004)
−0.749 (0.099) −0.346 (0.044)
(continued on next page)

−0.013
0.032
0.164
0.380
0.575
0.862
0.042
−0.078

−0.027 (0.043)

−0.092 (0.014)

Table 2 Means and OLS regression coefficients of selected variables from NLSY log wage regressions for workers ages 35-43 in 2000.
(1)
(2)
(3)
(4)
(5)
Explanatory variables
Means
Male coef.
Female coef.
Male coef.
Pooled coef.

38
Nicole Fortin et al.

0.087
0.120
0.358
0.436
2.529

2654

0.186
0.237
0.130
0.447
2.763

2655

(1)
Means

0.422

0.007
2.993

0.034
−0.059

(2)
Male coef.

(0.024)
(0.156)

(0.026)
(0.031)

0.407

0.088 (0.029)
2.865 (0.144)

0.140 (0.035)
0.065 (0.030)

(3)
Female coef.

0.422

0.066 (0.026)
2.934 (0.157)

0.059 (0.031)
0.093 (0.029)

(4)
Male coef.

0.431

0.036 (0.018)
2.949 (0.105)

0.072 (0.021)
−0.001 (0.020)

(5)
Pooled coef.

The data is an extract from the NLSY79 used in O’Neill and O’Neill (2006). Industrial sectors were added (at a lost of 89 observations) to their analysis to illustrate issues
linked to categorical variables. The other explanatory variables are age, dummies for black, hispanic, region, msa, central city. Standard errors are in parentheses.

Industrial Sectors
Primary, Constr. & Utilities
Manufacturing
Education, Health,
& Public Adm.
Other Services
Constant
Dependent Var. (Log Hourly
Wage)
Adj. R-Square
Sample size

Explanatory variables

Table 2 (continued)

Decomposition Methods in Economics

39

40

Nicole Fortin et al.

The corresponding wage structure effect is computed from the difference between the
male and female coefficients reported in columns (2) and (3). The results are reported in
column (1) of Table 3. The composition effect accounts for 0.197 (0.018) log points out
of the 0.233 (0.015) average log wage gap between men and women in 2000. When the
male wage structure is used as reference, only an insignificant 0.036 (0.019) part of the
gap (the wage structure effect) is left unexplained.
Because of the additive linearity assumption, it is easy to compute the various elements of the detailed decomposition. The wage structure and composition effects can
be written in terms of sums over the explanatory variables
bB0 − β
bA0 ) +
b µ = (β
1
S

M
X

bBk − β
bAk ),
X Bk (β

(17)

k=1

bµ =
1
X

M
X


bAk ,
X Bk − X Ak β

(18)

k=1

bB0 − β
bA0 ) represents the omitted group effect, and where X gk and β
bgk represent
where (β

b
b
b
bAk ) are
the kth element of X g and βg , respectively. X Bk − X Ak β Ak and X Bk (β Bk − β
the respective contributions of the kth covariate to the composition and wage structure
b µ can be interpreted as the contribution of the difeffect. Each element of the sum 1
S
ference in the returns to the kth covariate to the total wage structure effect, evaluated
at the mean value of X Bk . Whether or not this decomposition term is economically
meaningful depends on the choice of the omitted group, an issue we discuss in detail in
Section 3.2 below.24
Similar to O’Neill and O’Neill (2006), Table 3 reports the contribution of single
variables and groups of variables to composition (upper panel) and wage structure effects
(lower panel). Life-time work experience ‘priced’ at the male returns to experience
stands out as the factor with the most explanatory power (0.137 out of 0.197, or 69%)
for composition effects. The wage structure effects are not significant in this example,
except for the case of industrial sectors which we discuss below.
Because regression coefficients are based on partial correlations, an OB decomposition that includes all K explanatory variables of interest satisfies the property of path
independence (Property 2). Note, though, that a sequence of Oaxaca-Blinder decompositions, each including a subset of the K variables, would suffer from path dependence, as
pointed out by Gelbach (2009). Despite these attractive properties, there are some important limitations to the standard OB decomposition that we now address in more detail.
23 As is common in the gender pay gap literature, we begin with the counterfactual that use group B (males) as the
reference group. In column (3) of Table 3, we present the decomposition that corresponds to Eq. (15), that is uses
group A (females) as the reference group.
24 In particular, see the discussion of the case of scalable or categorical variables below.

Unadjusted mean log wage gap:
E[ln(wm )] − E[ln(w f )]
Composition effects attributable to
Age, race, region, etc.
Education
AFQT
L.T. withdrawal due to family
Life-time work experience
Industrial sectors
Total explained by model
0.012
−0.012
0.011
0.033
0.137
0.017
0.197

(0.003)
(0.006)
(0.003)
(0.011)
(0.011)
(0.006)
(0.018)

0.233 (0.015)

0.012
−0.012
0.011
0.033
0.137
0.017
0.197

(0.003)
(0.006)
(0.003)
(0.011)
(0.011)
(0.006)
(0.018)

0.233 (0.015)

Table 3 Gender wage gap: Oaxaca-Blinder decomposition results (NLSY, 2000).
(1)
(2)
Reference group
Using male coef. Using male coef.
from col. 4,
from col. 2,
Table 2
Table 2

0.009
−0.008
0.011
0.035
0.087
0.003
0.136

(0.003)
(0.004)
(0.003)
(0.008)
(0.010)
(0.005)
(0.014)

0.233 (0.015)

(3)
Using female
coef. from col. 3,
Table 2

0.011
−0.010
0.011
0.034
0.112
0.010
0.167

0.233 (0.015)

(5)
Using pooled
coef. from col.
5, Table 2

(0.003)
0.010 (0.003)
(0.005) −0.010 (0.005)
(0.003)
0.011 (0.003)
(0.007)
0.028 (0.007)
(0.008)
0.092 (0.007)
(0.004)
0.009 (0.004)
(0.013)
0.142 (0.012)
(continued on next page)

0.233 (0.015)

(4)
Using weighted
sum of col. 2 and
3, Table 2

Decomposition Methods in Economics

41

−0.098
0.045
0.003
0.003
0.048
−0.092
0.128
0.036
(0.234)
(0.034)
(0.023)
(0.017)
(0.062)
(0.033)
(0.213)
(0.019)

(1)
Using male coef.
from col. 2,
Table 2

−0.098
0.045
0.003
0.003
0.048
0.014
0.022
0.036
(0.234)
(0.034)
(0.023)
(0.017)
(0.062)
(0.028)
(0.212)
(0.019)

(2)
Using male coef.
from col. 4,
Table 2

−0.096
0.041
0.003
0.001
0.098
−0.077
0.193
0.097

(0.232)
(0.033)
(0.025)
(0.004)
(0.067)
(0.029)
(0.211)
(0.016)

(3)
Using female
coef. from col. 3,
Table 2

−0.097
0.043
0.003
0.002
0.073
−0.085
0.128
0.066

(0.233)
(0.034)
(0.024)
(0.011)
(0.064)
(0.031)
(0.213)
(0.015)

(4)
Using weighted
sum of col. 2 and
3, Table 2

−0.097
0.043
0.002
0.007
0.092
−0.084
0.128
0.092

(0.240)
(0.031)
(0.025)
(0.010)
(0.065)
(0.032)
(0.216)
(0.014)

(5)
Using pooled
coef. from col.
5, Table 2

The data is an extract from the NLSY79 used in O’Neill and O’Neill (2006). The other explanatory variables are age, dummies for black, hispanic, region, msa, central city.
In column (1), the omitted industrial sector is “Primary, Construction, and Utilities”. In column (2), the omitted industrial sector is “Education, Health and Public Admin”.
Standard errors are in parentheses. The means of the variables are reported in Table 2.

Wage structure effects attributable to
Age, race, region, etc.
Education
AFQT
L.T. withdrawal due to family
Life-time work experience
Industrial sectors
Constant
Total wage structure/
Unexplained log wage gap

Reference group

Table 3 (continued)

42
Nicole Fortin et al.

Decomposition Methods in Economics

3.2. Issues with detailed decompositions: choice of the omitted group
There are many relevant economic questions that can be answered with the detailed
b µ in Eq. (18). For example, what has been
decomposition of the composition effect 1
X
the contribution of the gender convergence in college enrollment to the gender convergence in average pay? There are also some important questions that are based on
b µ . For example, consider the
the detailed decomposition of the wage structure effect 1
S
related “swimming upstream” query of Blau and Kahn (1997). To what extent have the
increases in the returns to college slowed down the gender convergence in average pay?
Or, to what extent has the decline in manufacturing and differences in industry wage
premia contributed to that convergence?
Some difficulties of interpretation arise when the explanatory variables of interest
are categorical (with more than two categories, or more generally, in the case of scalable variables, such as test scores) and do not have an absolute interpretation. In OB
decompositions, categorical variables generate two problems. The first problem is that
categorical or scalable variables do not have a natural zero, thus the reference point has to
be chosen arbitrarily. The conventional practice is to omit one category which becomes
the reference point for the other groups. This generates some interpretation issues even
in the detailed decomposition of the composition effect.
Returning to our NLSY example, assume that the industry effects can captured
by four dummy variables, ind1 to ind4, for the broad sectors: (i) primary, construction, transportation & utilities, (ii) manufacturing, (iii) education and health services
& public administration, and (iv) other services. Consider the case where ind1 is the
omitted category, βg,ind1 = 0, and denote by βg,indk the coefficients from the wage
0
the coefficients of a wage
regression, as in column (2) of Table 2. Denote by βg,indk
0
regression where ind3 is the omitted category, βg,ind3 = 0, as in column (4) of Table 2,
b0
b
b
so that, for example, β
g,ind4 = βg,ind4 − βg,ind3 [0.066 = 0.007 − (−0.059)]. In
our example, given the large difference in the coefficients of manufacturing between
columns (2) and (4) of Table 2, this could mistakenly lead one to conclude that the
effect of the underrepresentation of women in the manufacturing sector has an effect
three times as large (0.237 − 0.120) × 0.093 in one case (education and health omitted)
as (0.237 − 0.120) × 0.034 in the other case (primary omitted). In the first case, the
underrepresentation of women in the manufacturing sector is ‘priced’ at the relative
returns in the manufacturing versus the education and health sector, while in the other
it is ‘priced’ at the relative returns in the manufacturing versus the primary sector.25
Note, however, that the overall effect of 0.017 (0.006) of gender differences in
industrial sectors on the gender wage gap, is the same in columns (1) and (2) of Table 3.
25 This interpretation issue also arises in other applications that use categorical variables, notably the inter-industry wage
differentials literature. In this literature, following the seminal Krueger and Summers (1988) paper on inter-industry
wage differentials, the standard practice is to express industry differentials as deviations from an employment-share
weighted mean, a well-defined average.

43

44

Nicole Fortin et al.

To simplify the exposition, consider the special case where industrial sectors are the only
explanatory factors in the wage regression. It follows that the composition effect,
bµ =
1
X

4 
X


bA,indk ,
X B,indk − X A,indk β

(19)

k=1

is unaffected by the choice of omitted category.26
The second problem with the conventional practice of omitting one category to
identify the coefficients of the remaining categories is that in the unexplained part of
the decomposition one cannot distinguish the part attributed to the group membership
(true “unexplained” captured by the difference in intercepts) from the part attributed to
differences in the coefficient of the omitted or base category.27 These difficulties with
the detailed decomposition of the unexplained part component were initially pointed by
Jones (1983) who argued that “this latter decomposition is in most applications arbitrary
and uninterpretable” (p. 126). Pursuing the example above, the effect of industry wage
differentials on the gender wage gap is given by the right-hand side sums in the following
expressions
 0
 X
bB,indk − β
bA,indk ), (20)
b µ = (β
b +β
b0
b0 + β
b0
X B,indk (β
1
)
−
(
β
)
B,ind1
A0
A,ind1 +
B0
S
k6=1

cµ 0
1
S

 X
bB0 + β
bB,ind3 ) − (β
bA0 + β
bA,ind3 ) +
b0
b0
= (β
X B,indk (β
B,indk − β A,indk ), (21)


k6=3

bg0 = β
b0 + β
b0
b0
b
b
where β
g0
g,ind1 and βg0 = βg0 + βg,ind3 , g = A, B. The overall wage
0
bµ = 1
b µ , as shown in
structure effect is the same irrespective of the omitted category 1
S
S
the last row of column (1) and (2) of Table 3. However, the overall effect of differences
in the returns to industrial sectors, given by the right hand side sums with either choice
of omitted group, −0.092 (0.033) in column (1) and 0.014 (0.028) in column (2), are
different because different parts of the effect are hidden in the intercepts [0.128 (0.213)
in column (1) and 0.022 (0.212) in column (2)].28
This invariance issue has been discussed by Oaxaca and Ransom (1999), Gardeazabal
and Ugidos (2004), and Yun (2005, 2008), who have proposed tentative solutions to it.

26 In the first regression, the composition effect is given by P
bA,indk , and in the
X B,indk − X A,indk β
 0

P
P k6=1
b
bA,indk − β
bA,ind1 ] =
second regression, k6=3 X B,indk − X A,indk β
=
X
−
X
[
β
B,indk
B,indk
k6=3

P
P A,indk
bA,indk because
X
−
X
β
X
=
1
−
X
,
g
=
A,
B.
A,indk
A,indk
g,indk
B,ind1
k6=1
k6=3
27 Actually, problems arise when they are more than two categories. Blinder (1973, footnote 13) and Oaxaca (2007)
correctly point out that in the case of a binary dummy variable, these problems do not occur.
28 This problem is different from a “true” identification problem which arises when multiple values of a parameter of
interest are consistent with a given model and population.

Decomposition Methods in Economics

These solutions impose some normalizations on the coefficients to purge the intercept
from the effect of the omitted category, either by transforming
the dummy variables
P
before the estimation, or by implementing the restriction, k βg,indk = 0, g = A, B,
via restricted least squares.29 Yun (2005) imposes the constraint that the coefficient on the
first category P
equals the unweighted averagePof the coefficients on the other categories,
K
βg,ind1 = − k6=1 βg,indk /K along with k=1
βg,indk = 0. While these restrictions
may appear to solve the problem of the omitted group, as pointed out by Yun (2008)
“some degree of arbitrariness in deriving a normalized equation is unavoidable” (p. 31).
For example, an alternative restriction
P on the coefficients, that goes back to Kennedy
(1986), could be a weighted sum, k wk βgk = 0, where the weights wk reflect the
relative frequencies of the categories in the pooled sample. The coefficients would then
reflect deviations from the overall sample mean.
The pitfall here is that the normalizations proposed by Gardeazabal and Ugidos
(2004) and Yun (2005) may actually leave the estimation and decomposition without a
simple meaningful interpretation. Moreover, these normalizations will likely be sample
specific and preclude comparisons across studies. By contrast, in the case of educational
categories, the common practice of using high school graduates as the omitted category
allows the comparison of detailed decomposition results when this omitted category is
comparable across studies.
Invariance of the detailed decomposition with respect to the choice of omitted category may appear to be a desirable property, but it is actually elusive and should not come
at the expense of interpretability. There is no quick fix to the difficult choice of the appropriate omitted category or base group, which is actually exacerbated in procedures that
go beyond the mean. To mimic the case of continuous variables, one may argue that an
education category such as less than high school that yields the smallest wage effect should
be the omitted one, but this category may vary more across studies than the high school
category. Issues of internal logic have to be balanced with comparability across studies.
Another way of reporting the results of counterfactual experiments, proposed in the
context of the gender wage gap by industry, is to report the wage structure effects for
each k category by setting X g,indk = 1 and X g,indl = 0 for l 6= k in the expression (20)
for the total wage structure effect
J
 X

b
bB0 − β
bA0 ) + β
bB,indk − β
bA,indk +
bB j − β
bA j
δgµ (indk) = (β
Xgj β
j=1

k = 1, . . . , 4,

(22)

29 As pointed by Gardeazabal and Ugidos (2004), such restrictions can have some disturbing implications. In the case
of educational categories, it rules out an outcome where group B members would earn higher returns than group A
members for all levels of education.

45

46

Nicole Fortin et al.

in a case where there are other explanatory variables, X j , j = 1, J .30 Initially, such
expressions included only the first two terms, the intercept and the effect of the category
k (Fields and Wolff, 1995). Later, Horrace and Oaxaca (2001) added the wage structure
effect associated with the other variables. This allows one to compare the effect of
wage structure on gender wage differentials by category while controlling for other
explanatory variables X j , j = 1, . . . , J in a way that is invariant to the choice of
omitted category.31 In columns (1) and (2) of Table 3, the wage structure effect associated
µ
with variables other than industrial sectors is essentially zero, and the b
δ A (indk) can be
computed as the difference between the male and female coefficients in columns (2)
and (3) of Table 2 plus the 0.128 difference in the constant, yielding values of 0.128,
0.022, 0.004, and 0.048 for industries 1 through 4, respectively. Horrace and Oaxaca
(2001) also proposed to ex-post normalize the effects of each category with respect to
the maximum categorical effect.
µ
One disadvantage of decomposition terms like b
δg (indk) relative to the usual components of the detailed decomposition is that they do not sum up to the overall wage strucµ
ture effect. As a result, just looking at the magnitude of the b
δg (indk) terms gives little
indication of their quantitative importance in the decomposition. We propose a normalization to help assess the proportion of the total wage structure effect which can be
attributed to a category k given that a proportion X g,indk of group g workers belongs to
that category, and that is also invariant to the choice of omitted category. The normalizaµ
tion uses the fact that the weighted sum of the b
δg (indk), k = 1, . . . , 4 (that is, including
the omitted category), is equal to the total wage structure effect, so that the proportional
µ
effect %b
δ S,g (indk) of category k in the total wage structure can be computed as32
µ
%b
δ S (indk) =

µ
b
δg (indk)X g,indk
bµ
1
S

because

bµ =
1
S

4
X

b
δgµ (indk)X g,indk .

(23)

k=1

In our empirical example, with group B as the reference group, this expression is comµ
puted using female averages, thus %b
δ S (indk) will tell us the proportion of the total wage
structure effect that can be attributed to industrial category k given the proportion of
women in each category. The numbers are 0.308 for primary, 0.074 for manufacturing,
0.040 for education and health, and 0.578 for other services. Despite being underrepresented in the manufacturing sector, because women’s returns to manufacturing jobs are
30 In the gender wage gap literature, when the reference wage structure is the male wage structure (group B) the means
among women X A j will be used in Eq. (22).
µ0
31 It is indeed easy to see that b
bB0 + β
bB,ind1 ) − (β
bA0 + β
bA,ind1 )] + [(β
bB,indk − β
bB,ind1 ) − (β
bA,indk −
δg (indk) = [(β
bA,ind1 )]+
β

J
P
j=1


bB j − β
bA j = b
Xgj β
δ µ (indk).

µ
32 The b
bB,indk −β
bA,indk ) =
δg (indk) for the omitted category is simply the first and last components of Eq. (22), since (β
0 for that category.

Decomposition Methods in Economics

relatively high, the share of the unexplained gap attributable to that factor turns out not
to be that large.

3.3. Alternative choices of counterfactual
On the one hand, the choice of a simple counterfactual treatment is attractive because
it allows us to use the identification results from the treatment effects literature. On the
other hand, these simple counterfactuals may not always be appropriate for answering
the economic question of interest. For instance, the male wage structure may not represent the appropriate counterfactual for the way women would be paid in the absence of
labor market discrimination. If the simple counterfactual does not represent the appropriate treatment, it may be more appropriate to posit a new wage structure. For example,
in the case of the gender pay gap, typically propositions (Reimers, 1983; Cotton, 1998;
Neumark, 1988; Oaxaca and Ransom, 1994) have used a weighted average expression
β ∗ = β A + (I − )β B , where  = I corresponds to β ∗ = β A ,  = 0 corresponds
to β ∗ = β B , and where  = ω · I could reflect a weighting corresponding to the
share of the two groups in the population. Another popular choice is the matrix ∗ =
|
|
|
(X B X B + X A X A )−1 X B X B , which captures the sample variation in the characteristics of
group A and B workers.33 The decomposition is then based on the triple differences:

 ∗ 

bµ = X B − X A β
b + XB β
bB − β
b∗ + X A β
b∗ − β
bA
1
O
bµ .
bµ + 1
=1
X

S

Table 3 shows that in the NLSY example, the gender gap decomposition is substantially different when either the female wage structure (column 3) or the weighted sum
of the male and female wage structure (column 4) is used as the reference wage structure. Typically (as in Bertrand and Hallock (2001) for example), with the female wage
structure as reference, the explained part of the decomposition (composition effect) is
smaller than with the male wage structure as reference. Indeed, evaluated at either female
‘prices’ or average of male and female ‘prices’, the total unexplained (wage structure)
effect becomes statistically significant.
An alternative measure of “unexplained” differences (see Cain, 1986) in mean wages
between group A and group B workers is given by the coefficient δ of the group membership indicator variable D B in the wage regression on the pooled sample, where the
coefficients of the observed wage determination characteristics are constrained to be the
same for both groups:
E[Yi |X, D B ] = α0 + X i β ∗∗ + δ D Bi ,
33 X and X are the matrices of covariates (of dimension N × k and N × k) for groups A and B, respectively.
A
B
A
B

(24)

47

48

Nicole Fortin et al.

where the vector of observed characteristics X i excludes the constant. It follows that,
µ

1 O = E[Yi |X, D B = 1] − E[Yi |X, D B = 0]


= α0 + E[X i |D B = 1]β ∗∗ + δ − α0 + E[X i |D B = 0]β ∗∗
µ
µ
= (E[X i |D B = 1] − E[X i |D B = 0]) β ∗∗ + δ = 1 X + 1 S ,
µ

where δ = 1 S . As noted by Fortin (2008), this “regression-compatible” approach is
preferable to the one based on a pooled regression that omits the group membership
variable (as in Neumark (1988) and Oaxaca and Ransom (1994)), because in the latter
case the estimated coefficients are biased (omitted variable bias). Note, however, that this
counterfactual corresponds to the case where the group membership dummy is thought
to be sufficient to purge the reference wage structure from any group membership effect,
an assumption that is maintained in the common practice of using the group membership
dummy in a simple regression to assess its effect. The detailed decomposition is obtained
using the above triple differences decomposition.34
The results of this decomposition, reported in column (5) of Table 3, are found to be
closest to the one using the female coefficients in column (3), but this is not necessarily
always the case. Notice that the magnitude of the total unexplained wage log wage gap
0.092 (0.014) log points corresponds to the coefficient of the female dummy in column
(5) of Table 2.

3.4. Reweighted-regression decompositions
A limitation of OB decompositions, discussed by Barsky et al. (2002), is that they may
not provide consistent estimates of the wage structure and composition effect when the
conditional mean function is non linear. Barsky et al. (2002) look at the role of earnings
and other factors in the racial wealth gap. They argue that a standard OB decomposition
is inadequate because the wealth-earnings relationship is non linear, and propose a more
flexible approach instead.
Under the linearity assumption, the average counterfactual wage that group
B workers would have earned under the wage structure of group A is equal to
bA , a term that appears in
E [X B |D B = 1] · β A , and is estimated as the product X B β
both the wage structure and composition effect in Eq. (15). However, when linearity
does not hold, the counterfactual mean wage will not be equal to this term.
One possible solution to the problem is to estimate the conditional expectation using
non-parametric methods. Another solution proposed by Barsky et al. (2002) is to use
a (non-parametric) reweighting approach as in DiNardo et al. (1996) to perform the
decomposition. One drawback of this decomposition method, discussed later in the
34 This “pooled” decomposition is easily implemented using the option “pooled” in Jann (2008) “oaxaca” procedure in
Stata 9.2.

Decomposition Methods in Economics

chapter, is that it does not provide, in general, a simple way of performing a detailed
decomposition. In the case of the mean, however, this drawback can be readily addressed
by estimating a regression in the reweighted sample.
To see this, let 9(X i ) be the reweighting function, discussed in Section 4.5, that
makes the characteristics of group A workers similar to those of group B workers. The
C
counterfactual coefficients β CA and the counterfactual mean X A , are then estimated as:35
!−1
bC =
β
A

X

b i ) · Xi ·
9(X

|
Xi

i∈A
C
XA

=

X

·

X

b i ) · Y Ai · X i
9(X

i∈A

b i ) · Xi ,
9(X

i∈A
C

where plim(X A ) = plim(X B ) = E(X |D B = 1).36 If the conditional expectation
of Y given X was linear, both the weighted and unweighted regressions would yield
bA ) = β A .
bC ) = plim(β
the same consistent estimate of β A , i.e. we would have plim(β
A
When the conditional expectation is not linear, however, the weighted and unweighted
estimates of β A generally differ since OLS minimizes specification errors over different
samples.37
bµ ,
Consider the “reweighted-regression” decomposition of the overall wage gap 1
O,R
where
b µ = (X B β
bB − X CA β
bC ) + (X CA β
bC − X A β
bA )
1
A
A
O,R
bµ + 1
bµ .
=1
S,R

X,R

b µ can be divided into a pure composition effect 1
bµ
The composition effect 1
X,R
X, p
using the wage structure of group A, and a component linked to the specification error
35 When considering covariates X , we use the subscript g to denote the group whose characteristics are “adjusted” with
reweighting.
36 We show in Section 4 that the reweighting factor 9(X ) is defined as the ratio of the marginal distributions of X for
groups B and A, 9(X ) = dFX B (X )/dFX A (X ). As a result, the reweighted distribution of X for group A should be
the same as the original distribution of X in group B. This implies that the mean value of X in the reweighted sample,
C
X A , should be the same as the mean value of X for group B, X B .
37 When the conditional expectation is non-linear, the OLS estimate of β can be interpreted as the one which minimizes
the square of the specification error E(Y |X ) − Xβ over the distribution of X . Since the expected value of the
OLS estimate of β depends on the distribution of X , differences in β over two samples may either reflect true
underlying differences in the conditional expectation (i.e. in the wage structure), or “spurious” differences linked to
the fact that the distribution of X is different in the two samples. For example, if E(Y |X ) is convex in X , the expected
value of β will tend to grow as the distribution of X shifts up, since the relationship between Y and X gets steeper as X
becomes larger.

49

50

Nicole Fortin et al.

bµ :
in the linear model, 1
X,e

h
i

bC − β
bA
b µ = X CA − X A β
bA + X CA β
1
A
X,R
bµ + 1
bµ .
=1
X, p
X,e
The wage structure effect can be written as


 
C
bB − β
bC + X B − X CA βc
bµ = X B β
1
A
A
S,R
bµ
bµ + 1
=1
S, p
S,e
b µ as the reweighting error 1
b µ goes to zero in large
and reduces to the first term 1
S, p
S,e
C
µ
b
samples (plim(X B − X A ) = 0 ⇒ plim(1 S,e ) = 0).
The reweighted-regression decomposition is similar to the usual OB decomposition
except for two small differences. The first difference is that the wage structure effect
bB and the weighted estimate β
bC instead of the
is based on a comparison between β
A
bA . As discussed in Firpo et al. (2007), this ensures that the
usual unweighted estimate β
bB − β
bC reflects true underlying differences in the wage structure for group
difference β
A
A and B, as opposed to a misspecification error linked to the fact that the underlying
conditional expectation is non-linear. Note that is also useful to check whether the
C C
b is equal to zero (or close to zero), as it should be when
reweighting error (X B − X A )β
A
b
the reweighting factor 9(X ) is consistently estimated.
The other difference relative to the OB decomposition is that the composition effects

 C
C
bA .
b −β
bA plus the specification error X CA β
consists of a standard term (X A − X A )β
A
If the model was truly linear, the specification error term would be equal to zero. Computing the specification error is important, therefore, for checking whether the linear
model is well specified, and adjusting the composition effect in the case where the linear
specification is found to be inaccurate.
In the case where the conditional expectation E(Yi |X i , D = d) is estimated nonparametrically, a whole different procedure would have to be used to separate the
wage structure into the contribution of each covariate. For instance, average derivative
methods could be used to estimate an effect akin to the β coefficients used in standard
decompositions. Unfortunately, these methods are difficult to use in practice, and would
not be helpful in dividing up the composition effect into the contribution of each
individual covariate.
On a related note, Kline (2009) points out that the standard OB decomposition can
be interpreted as a reweighting estimator where the weights have been linearized as a
function of the covariates. This suggests that the procedure may actually be more robust
to departures from linearity than what has been suggested in the existing literature. Since

Decomposition Methods in Economics

the procedure is robust to these departures and remains the method of choice when
linearity holds, Kline (2009) points out that it is “doubly robust” in the sense of Robins
et al. (1994) and Egel et al. (2009).

3.5. Extensions to limited dependent variable models
OB decompositions have been extended to cases where the outcome variable is not a
continuous variable. To mention a few examples, Gomulka and Stern (1990) study the
changes over time in labor force participation of women in the United Kingdom using
a probit model. Even and Macpherson (1990) decomposes the male-female difference
in the average probability of unionization, while Doiron and Riddell (1994) propose a
decomposition of the gender gap in unionization rate based on a first order Taylor series
approximation of the probability of unionization. Fitzenberger et al. (forthcoming) use
a probit model to decompose changes over time in the rate of unionization in West and
East Germany. Fairlie (1999, 2005) discuss the cases of the racial gaps in self-employment
and computer ownership. Bauer and Sinning (2008) discuss the more complicated
cases of a count data model, for example where the dependent variable is the number
of cigarettes smoked by men and women (Bauer et al., 2007), and of the truncated
dependent variable, where for example the outcome of interest is hours of work.
In the case of a limited dependent variable Y , the conditional expectation of Y
is typically modeled as a non-linear function in X , E(Yg |X ; βg ) = G(X ; βg ). For
example, if Y is a dichotomous outcome variable (Y = 0, 1) and Yg∗ = Xβg + υg is a
latent variable which is linear in X , it follows that E(Yg |X ; βg ) = G(Xβg ) where G(·)
is the CDF of υg . When υg follows a standard normal distribution, we have a standard
probit model and G(·) = 8(·). More generally, under various assumptions regarding
the functional form G and/or the distribution of the error terms υg , the models are
estimated by maximum likelihood.
Because E(Yg |Dg = 1) = E[E(Yg |X ; βg )|Dg = 1] = E[G(X ; βg )|Dg = 1] 6=
G(E[X |Dg = 1]; βg ), the decomposition cannot simply be computed by plugging in
the estimated β’s and the mean values of X ’s, as in the standard OB decomposition.
Counterfactual conditional expectations have to be computed instead, and averaged
across observations. For example, if group A is thought to be the reference group,
E(Y B |D A = 1) = E [G(X ; β B )|D A = 1] will be the counterfactual conditional expectation of Y B that would prevail if the coefficients of the determinants of self-employment
(for example) for group B were the same as for group A. This involves computing
predicted (i.e. expected) values based on the estimated model for group B, G(X ; β B ),
over all observations in group A, and averaging over these predicted values.
The mean gap between group B and group A is then decomposed as follows
µ

1 O = E[(Y B |D B = 1)] − E(Y A |D A = 1)
= E [G(X ; β B )|D B = 1] − E [G(X ; β A )|D A = 1]

51

52

Nicole Fortin et al.

= (E [G(X ; β B )|D B = 1] − E [G(X ; β A )|D B = 1])
+ (E [G(X ; β A )|D B = 1] − E [G(X ; β A )|D A = 1])
µ
µ
= 1S + 1 X ,
into a component that attributes differences in the mean outcome variable to differences
in the characteristics of the individuals, and a component that attributes these differences
to differences in the coefficients.
The same difficult issues in the appropriate choice of counterfactuals persist for more
general non-linear models. In addition, extra care has to be taken to verify that the
sample counterfactual conditional expectation lies within the bounds of the limited
dependent variable. For example, Fairlie (1999) checks that average self-employment for
Blacks predicted from the White coefficients is not negative.
The non-linear decomposition may perform better than the linear alternative (linear
probability model, LPM) when the gap is located in the tails of the distribution or when
there are very large differences in the explanatory variables, whose effects would remain
unbounded in a LPM. On the other hand, there are many challenges in the computation
of detailed decompositions for non-linear models. Because of non-linearity, the detailed
decomposition of the two components into the contribution of each variable, even if
the decomposition was linearized using marginal effects, would not add up to the total.
Gomulka and Stern (1990) and Fairlie (2005) have proposed alternative methodologies
based on a series of counterfactuals, where the coefficient of each variable is switched to
reference group values in sequence. In the latter cases, the decomposition will be sensitive to the order of the decomposition, that is will be path dependent. We discuss these
issues further in the context of the decompositions of entire distributions in Section 5.

3.6. Statistical inference
OB decompositions have long been presented without standard errors. More recently,
Oaxaca and Ransom (1998), followed by Greene (2003, p. 53–54), have proposed
approximate standard errors based the delta method, under the assumption that the
explanatory variables were fixed.38 A more modern approach where, as above, (Y, X )
are stochastic was suggested and implemented by Jann (2005). In cases where the
counterfactuals are not a simple treatment, or where a non-linear estimator is used,
bootstrapping the entire procedure may prove to be the practical alternative.

4. GOING BEYOND THE MEAN—DISTRIBUTIONAL METHODS
Developing new decomposition methods for distributional statistics other than the mean
has been an active research area over the last 15 years. In this section, we discuss a number
38 This corresponds to an experimental setting where, for example, regression analysis was used to assess the impact of
various soils and fertilizers (X ) on agricultural yields Y .

Decomposition Methods in Economics

of procedures that have been suggested for decomposing general distributional statistics.
We focus on the case of the aggregate decomposition, though some of the suggested
methods can be extended to the case of the detailed decomposition, which we discuss
in Section 5. We begin by looking at the simpler case of a variance decomposition. The
decomposition is obtained by extending the classic analysis of variance approach (based
on a between/within group approach) to a general case with covariates X . We then
turn to new approaches based on various “plugging in” methods such as JMP’s residual
imputation method and Machado and Mata (2005)’s conditional quantile regression
method. Finally, we discuss methods that focus on the estimation of counterfactuals
for the entire distribution. These methods are either based on reweighting or on the
estimation of the conditional distribution.
Most of this recent research was initially motivated by the dramatic growth in earnings inequality in the United States. Prior to that episode, the literature was considering
particular summary measures of inequality such as the variance of logs and the Gini
coefficient. For instance, Freeman (1980, 1984) looks at the variance of log wages in his
influential work on the effect of unions on wage dispersion. This research establishes that
unions tend to reduce wage dispersion as measured by the variance of log wages. Freeman shows that despite the inequality-enhancing effect of unions on the between-group
component of inequality, the overall effect of unions is to reduce inequality because of
the even larger effect of unions on within-group inequality.
One convenient feature of the variance is that it can be readily decomposed into
a within- and between-group component. Interestingly, related work in the inequality literature shows that other measures such as the Gini or Theil coefficient are also
decomposable into a within- and between-group component.39
Note that the between vs. within decomposition is quite different in spirit from the
aggregate or detailed OB decomposition discussed in the previous section. There are
advantages and disadvantages to this alternative approach. On the positive side, looking
at between- and within-group effects can help understand economic mechanisms, as in
the case of unions, or the sources of inequality growth (Juhn et al., 1993).
On the negative side, the most important drawback of the between vs. within
decomposition is that it does not hold in the case of many other interesting inequality
measures such as the interquartile ranges, the probability density function, etc. This is a
major shortcoming since looking at what happens where in the distribution is important for identifying the factors behind changes or differences in distributions. Another
drawback of the between vs. within approach is that it does not provide a straightforward
way of looking at the specific contribution of each covariate, i.e. to perform a detailed
decomposition. One final drawback is that with a rich enough set of covariates the
number of possible groups becomes very large, and some parametric restrictions have to
be introduced to keep the estimation problem manageable.
39 See, for instance, Bourguignon (1979), Cowell (1980), and Shorrocks (1980, 1984).

53

54

Nicole Fortin et al.

In response to these drawbacks, a new set of approaches have been proposed for performing aggregate decompositions on any distributional statistic. Some approaches such
as Juhn et al. (1993), Donald et al. (2000), and Machado and Mata (2005) can be viewed
as extensions of the variance decomposition approach where the whole conditional
distribution (instead of just the conditional variance) are estimated using parametric
approaches. Others such as DiNardo et al. (1996) completely bypass the problem of estimating conditional distributions and are, as such, closer cousins to estimators proposed
in the program evaluation literature.

4.1. Variance decompositions
Before considering more general distributional statistics, it is useful to recall the steps
used to obtain the standard OB decomposition. The first step is to assume that the
conditional expectation of Y given X is linear, i.e. E(Y |X ) = Xβ. This follows directly
from the linearity and zero conditional mean assumptions (Assumptions 10 and 11)
introduced in Section 2. Using the law of conditional expectations, it then follows that
the unconditional mean is E(Y ) = E(E(Y |X )) = E(X )β. This particular property of
the mean is then used to compute the OB decomposition.
In light of this, it is natural to think of extending this type of procedure to the case
of the variance. Using the analysis of variance formula, the unconditional variance of Y
can be written as:40
n
o
Var(Y ) = E[Var(Y |X )] + E [E(Y |X ) − E(Y )]2
n
o
= E[Var(Y |X )] + E [Xβ − E(X )β]2
= E[Var(Y |X )] + β 0 Var(X )β,
where the expectations are taken over the distribution of X . The first component of the
equation is the within-group component (also called residual variance), while the second
component is the between-group component (also called regression variance). Writing
Var(Y |X, Dg = 1) ≡ vg (X ), g = A, B, we can write the difference in variances across
groups B and A as
1VO = E [v B (X )|D B = 1] − E [v A (X )|D B = 0] + β B0 Var [X |D B = 1] β B
− β 0A Var [X |D B = 0] β A .
A few manipulations yield 1VO = 1VX + 1VS , where
1VX = {E [v A (X )|D B = 1] − E [v A (X )|D B = 0]}
+ β 0A {Var [X |D B = 1] − Var [X |D B = 0]} β A
40 See for example, Theorem B.4 in Greene (2003).

Decomposition Methods in Economics

and
1VS = {E [v B (X )|D B = 1] − E [v A (X )|D B = 1]}
+ (β B − β A )0 Var [X |D B = 1] (β B + β A ).
While it is straightforward to estimate the regression coefficients (β A and β B ) and
the covariance matrices of the covariates (Var [X |D B = 0] and Var [X |D B = 1]), the
within-group (or residual) variance terms v A (X ) and v B (X ) also have to be estimated to
compute the decomposition.
Several approaches have been used in the literature to estimate v A (X ) and v B (X ).
The simplest possible approach is to assume that the error term is homoscedastic, in
which case v A (X ) = σ A2 and v B (X ) = σ B2 , and the two relevant variance parameters
can be estimated from the sampling variance of the error terms in the regressions. The
homoscedasticity assumption is very strong, however. When errors are heteroscedastic,
differences between σ A2 and σ B2 can reflect spurious composition effects, in which case
the decomposition will attribute to the wage structure effect (1VS ) what should really be
a composition effect (1VX ). Lemieux (2006b) has shown this was a major problem when
looking at changes in residual wage inequality in the United States since the late 1980s.
A simple way of capturing at least some of the relationship between the covariates
and the conditional variance is to compute the variance of residuals for a limited number
of subgroups of “cells”. For instance, Lemieux (2006b) shows estimates for 20 different
subgroups of workers (based on education and experience), while Card (1996) divides
b
the sample into five quintiles based on predicted wages X β.
Finally, one could attempt to estimate a more general specification for the conditional variance by running a “second step” model for squared regression residual

b 2 on some specification of the covariates. For example, assuming that
b
υ2 = Y − X β
v A (X ) = X δ A , we can estimate b
δ by running a regression of b
υ 2 on X .41 We can then
write the two aggregate components of the variance decomposition as:
1VX = {(E [X |D B = 1] − E [X |D B = 0]) δ A }
+ β 0A {Var [X |D B = 1] − Var [X |D B = 0]} β A

(25)

and
1VS = {E [X |D B = 1] (δ B − δ A )} + (β B − β A )0 Var [X |D B = 1] (β B + β A ). (26)
Compared to the standard OB decomposition for the mean, which only requires
estimating a (regression) model for the conditional mean, in the case of the variance, we
41 Estimating these simple models of the conditional cross-sectional variance is a special case of the large time-series
literature on the estimation of auto-regressive conditional heteroskedasticity models (ARCH, GARCH, etc.).

55

56

Nicole Fortin et al.

also need to estimate a model for the conditional variance. While this is quite feasible
in practice, we can already see a number of challenges involved when decomposing
distributional parameters beyond the mean:
• The estimation is more involved since we need to estimate models for two, instead
of just one, conditional moment. Furthermore, little guidance is typically available
on “reasonable” specifications for the conditional variance. For instance, in the case
of wages, the Mincer equation provides a reasonably accurate and widely accepted
specification for the conditional mean, while no such standard model is available for
the conditional variance.
• Computing the detailed decomposition is more complicated since the between-group
component is a quadratic form in the β’s. This yields a number of interaction terms
that are difficult to interpret.
Since the complexity of decomposition methods already increases for a distributional
measure as simple and convenient as the variance, this suggests these problems will be
compounded in the case of other distributional measures such as quantiles. Indeed, we
show in the next subsection that for quantiles, attempts at generalizing the approach
suggested here require estimating the entire conditional distribution of Y given X . This
is a more daunting estimation challenge, and we now discuss solutions that have been
suggested in the literature.

4.2. Going beyond the variance: general framework
An important limitation of summary measures of dispersion such as the variance, the Gini
coefficient or the Theil coefficient is that they provide little information regarding what
happens where in the distribution. This is an important shortcoming in the literature on
changes in wage inequality where many important explanations of the observed changes
have specific implications for specific points of the distribution. For instance, the minimum wage explanation suggested by DiNardo et al. (1996) should only affect the bottom
end of the distribution. At the other extreme, explanations based on how top executives
are compensated should only affect the top of the distribution. Other explanations based
on de-unionization (Freeman, 1993; Card, 1992; DiNardo et al., 1996) and the computerization of “routine” jobs (Autor et al., 2003) tend to affect the middle (or “lower
middle”) of the distribution. As a result, it is imperative to go beyond summary measures
such as the variance to better understand the sources of growing wage inequality.
Going beyond summary measures is also important in many other interesting economic problems such the sources of the gender wage gap and the impact of social
programs on labor supply.42 The most common approach for achieving this goal is to
perform a decomposition for various quantiles (or differences between quantiles like the
42 See Albrecht et al. (2003), who look at whether there is a glass ceiling in female earnings, and Bitler et al. (2006), who
study the distributional effects of work incentive programs on labor supply.

Decomposition Methods in Economics

90-10 gap) of the distribution. Unfortunately, as we point out in the introduction, it is
much more difficult to decompose quantiles than the mean or even the variance. The
basic problem is that the law of iterated expectations does not hold in the case of quantiles, i.e. Q g,τ 6= E X [Q g,τ (X )], where Q g,τ , is the τ th quantile of the (unconditional)
distribution of Yg , and Q g,τ (X ) is the corresponding conditional quantile.
As it turns out, one (implicitly) needs to know the entire conditional distribution of
Yg given X given to compute Q g,τ . To see this, note that
τ = FYg (Q g,τ ) = E[FYg |X g (Q g,τ |X )] =

Z

FYg |X g (Q g,τ |X )dFX g (X ),

g = A, B,

where FYg |X g (·) is the cumulative distribution of Y conditional on X in group g. Given
τ , it is possible to implicitly use this equation to solve for Q g,τ . It is also clear that in order
to do so we need to know the conditional distribution function FYg |X g (·), as opposed
to just the conditional mean and variance, as was the case for the variance. Estimating an
entire conditional distribution function for each value of (Yg |X ) is a difficult problem.
Various decomposition methods that we discuss in detail below suggest different ways of
handling this challenge.
But before covering them in detail, we recall the basic principles underlying these
methods. As in Section 2, we focus on cumulative distributions since any standard
distribution statistic, such as a quantile, can be directly computed from the cumulative
distribution. For instance, quantiles of the counterfactual distribution can be obtained
by inverting FY C : Q CA,τ = F −1
C (τ ).
YA

A

For the sake of presentational simplicity, we introduce a simplified notation relative to
Section 2. We use FX g instead of FX |Dg to represent the marginal distribution of X , and
FYg |X g to represent FYg |X,Dg the conditional distributions, for g = A, B, introduced in
Eq. (4). We use the shorthand FY C instead of FY C :X =X |D B to represent the key counA
A
terfactual distribution of interest introduced in Eq. (5), which mixes the distribution of
characteristics of group B with the wage structure from group A:
FY C (y) =
A

Z

FY A |X A (y|X )dFX B (X ).

(27)

Three general approaches have been suggested in the decomposition literature for
estimating the counterfactual distribution FY C (y). A first general approach, initially sugA
gested by Juhn et al. (1993), replaces each value of Y B for group B with a counterfactual
value of Y AC = g(Y B , X ), where g(·, ·) is an imputation function. The idea is to replace
Y B from group B with a counterfactual value of Y AC that holds the same rank in the
conditional distribution FY A |X A (·|·) as it did in the original distribution of Y B . As we
discussed in Section 2.2.3, this is done in practice using a residual imputation procedure.

57

58

Nicole Fortin et al.

Machado and Mata (2005) and Autor et al. (2005) have later suggested other approaches,
based on conditional quantile regressions, to transform a wage observation Y B into a
counterfactual observation Y AC .
A second approach proposed by DiNardo et al. (1996) [DFL] is based on the
following manipulation of Eq. (27):
Z
FY A |X A (y|X )9(X )dFX A (X ),
(28)
FY C (y) =
A

where 9(X ) = dFX B (X )/dFX A (X ) is a reweighting factor. This makes it clear that
the counterfactual distribution FY C (·) is simply a reweighted version of the distribution
A
FY A (·). The reweighting factor is a simple function of X that can be easily estimated
using standard methods such as a logit or probit. The basic idea of the DFL approach is
to start with group A, and then replace the distribution of X of group A (FX A (·)) with
the distribution of X of group B (FX B (·)) using the reweighting factor 9(·).
The third set of approaches also works with Eq. (27) starting with group B, and
then replacing the conditional distribution FY B |X B (Y |X ) with FY A |X A (Y |X ). Doing so
is more involved, from an estimation point of view, than following the DFL approach.
The problem is that the conditional distributions depend on both X and y, while the
reweighting factor 9(X ) only depends on X .
Under this third set of approaches, one needs to directly estimate the conditional distribution FY |X (y|X ). Parametric approaches for doing so were suggested by Donald et al.
(2000) who used a hazard model approach, and Fortin and Lemieux (1998) who suggested estimating an ordered probit. More recently, Chernozhukov et al. (2009) suggest
estimating distributional regressions (e.g. a logit, for each value of y). In all cases, the idea
is to replace the conditional distribution for group B, FY B |X B (y|X ), with an estimate of
the conditional distribution FY A |X A (y|X ) obtained using one of these methods.
In the next subsections, we discuss how these various approaches can be implemented. We also present some results regarding their statistical properties, and address
computational issues linked to their implementation.

4.3. Residual imputation approach: JMP
Procedure
As we explain above, Juhn et al. (1993) propose an imputation approach where the wage
Y B from group B is replaced by a counterfactual wage Y AC where both the returns to
observables and unobservables are set to be as in group A. The implementation of this
procedure is divided in two steps. First, unobservables are replaced by counterfactual
unobservables, as in Eq. (9). Second, counterfactual returns to observables are also
imputed, as in Eq. (12).43
43 Juhn et al. (1993) actually consider multiple time periods and proposed an additional counterfactual where the returns
to observables are set to their mean across time periods, a complex counterfactual treatment.

Decomposition Methods in Economics

Under the assumption of additive linearity (Assumption 10), the original wage
equation for individual i from group B,
Y Bi = X i β B + υ Bi

where υ Bi = h B (εi )

allows the returns to unobservables to be group-specific. Under the assumption of rank
preservation (14), the first counterfactual is computed as
C,2
Y Ai
= X i β B + υ C,2
Ai ,

(29)

where
−1
υ C,2
Ai = Fυ A |X (τ Bi (x i ), x i ),

and τ Bi (xi ) is the conditional rank of υ Bi in the distribution of residuals for group
B (τ Bi (xi ) = Fυ B |X (υ Bi |X = xi )). A second counterfactual is then obtained by also
replacing the returns to observable characteristics β B with β A
C,3
Y Ai
= X i β A + υ C,2
Ai .

Under the assumptions of linearity and rank preservation, this counterfactual wage
C , the counterfactual wage obtained by replacing the wage
should be the same as Y Ai
structure m B (·) with m A (·).
In practice, it is straightforward to estimate β A and β B using OLS under the assumptions of linearity and zero conditional mean. It is much less clear, however, how to
perform the residual imputation procedure described above. Under the strong assumption that the regression residuals υg are independent of X , it follows that
−1
υ C,2
Ai = Fυ A (τ Bi ).

Under this independence assumption, one simply needs to compute the rank of the
residual υ Bi in the marginal distribution (distribution over the whole sample) of residuals
for group B, and then pick the corresponding residuals in the marginal distribution of
residuals for group A. If υ Bi is at the 70th percentile of the distribution of residuals of
group B (τ Bi = 0.7), then υ C,2
Ai will simply be the 70th percentile of the distribution
of residuals for group A. In practice, most applications of the JMP procedure use this
strong assumption of independence because there is little guidance on how a conditional
imputation procedure could be used instead.
Limitations
Since independence of regression residuals is unrealistic, a more accurate implementation of JMP would require deciding how to condition on X when performing the

59

60

Nicole Fortin et al.

imputation procedure. If X consists of a limited number of groups or “cells”, then one
could perform the imputation within each of these groups. In general, however, it is
difficult to know how to implement this ranking/imputation procedure in more general
cases. As a result, other procedures such as the quantile method of Machado and Mata
(2005) are increasingly being used as an alternative to JMP.
Another limitation of the JMP procedure is that there is no natural way of extending
it to the case of the detailed decomposition for the composition effect.
Advantages
One advantage of the two-step procedure is that it provides a way of separating the
between- and within-group components, as in a variance decomposition. This plays an
important role in the inequality literature, since JMP concluded that most of the inequality growth from the 1960s to the 1980s was linked to the residual inequality component.
It is not clear, however, what is meant by between- and within-group components in
the case of distributional measures like the 90-10 gap that are not decomposable. A better
way of justifying JMP is that Y = Xβ + υ represents a structural model where X are
observed skills, while υ represents unobserved skills. One can then perform simulation
exercises asking what happens to the distribution when one either replaces returns to
observed or unobserved skills (see also Section 2.2.3).
This economic interpretation also requires, however, some fairly strong assumptions.
The two most important assumptions are the linearity of the model (Assumption 10,
m g (X i , εi ) = X i βg + υgi ) and rank preservation (Assumption 14). While linearity can
be viewed as a useful approximation, rank preservation is much stronger since it means
that someone with the same unobserved skills would be in the exact same position,
conditional on X , in either group A or B. Just adding measurement error to the model
would result in a violation of rank preservation.
Finally, if one is willing to interpret a simple regression as a decomposition between
observed and unobserved skills, this can be combined with methods other than JMP.
For instance, DFL perform regression adjustments to illustrate the effects of supply and
demand factors on wages.44

4.4. Methods based on conditional quantiles
Procedure
Like JMP, Machado and Mata (2005, MM from hereinafter) propose a procedure based
on transforming a wage observation Y B into a counterfactual observation Y AC . The
main advantage relative to JMP is that their estimation procedure, based on quantile
regressions (Koenker and Bassett, 1978), provides an explicit way of estimating the
(inverse) conditional distribution function FY−1
(·, ·) in the imputation function
A |X A
g(Y, X ) = FY−1
(FY B |X B (Y |X ), X ). One important difference, however, is that
A |X A

44 See also Lemieux (2002).

Decomposition Methods in Economics

C , MM
instead of transforming each actual observation of Y Bi into a counterfactual Y Ai
use a simulation approach where quantiles are drawn at random.
More specifically, since

Y AC = FY−1
(FY B |X B (Y |X ), X ),
A |X A
and τ B (Y |X ) = FY B |X B (Y |X ) follows a uniform distribution, one can think of doing
the following:
1. Draw a simulated value τs from a uniform distribution s = 1, . . . , S.
2. Estimate a linear quantile regression for the τs th quantile, and use the estimated result
C .45 The reason for using quantile
to predict simulated values of both Y Bs and Y As
regressions is that:
C
= FY−1
(τs , X )
Y As
A |X A

and

Y Bs = FY−1
(τs , X ),
B |X B

where FY−1
(·, ·) and FY−1
(·, ·) are the conditional quantile functions for the
A |X A
B |X B
τs th quantile in group A and B, respectively.
C to obtain measures of the wage
3. Compare the simulated distributions of Y Bs and Y As
structure effect. The composition effect is computed as the complement to the overall
difference.
A key implementation question is how to specify the functional forms for the
conditional quantile functions. MM suggest a linear specification in the X that can be
estimated using quantile regression methods. The conditional quantile regression models
can be written as:
Q g,τ (Y |X ) = FY−1
(τ, X ) = Xβ g,τ ,
g |X g

g = A, B.

Table 4 reports in the top panel the results of the Machado-Mata procedure applied
to our gender gap example using the male wage structure as reference.46 It shows that the
median gender log wage gap in the central column gives almost the same results for the
aggregate decomposition as the OB mean gender log wage gap decomposition displayed
in column (1) of Table 3. Going across the columns to compare quantile effects shows
that gender differences in characteristics are much more important at the bottom (10th
centile) than at the top (90th centile) of the wage distribution. Indeed, some significant
wage structure effects emerge at the 90th percentile.
45 For each random draw s, MM also draw a vector of covariates X from the observed data and perform the prediction
s
for this value only. Melly (2005) discusses more efficient ways of computing distributions using this conditional quantile
regression approach.
46 The estimates were computed with Melly’s implementation “rqdeco” in Stata.

61

62

Nicole Fortin et al.

Table 4 Gender wage gap: quantile decomposition results (NLSY, 2000).
Reference group: male coef.

10th percentile

50th percentile

90th percentile

A: Raw log wage gap:

Q τ [ln(wm )] − Q τ [ln(w f )]

0.170

(0.023)

0.249

(0.019)

0.258

(0.026)

B: Decomposition method: Machado-Mata-Melly

Estimated log wage gap:
Q τ [ln(wm )] − Q τ [ln(w f )]
Total explained by
characteristics
Total wage structure

0.192

(0.015)

0.239

(0.016)

0.276

(0.026)

0.257

(0.028)

0.198

(0.027)

0.143

(0.019)

−0.065

(0.027)

0.041

(0.024)

0.133

(0.025)

C: Decomposition method: RIF regressions without reweighting

Mean RIF gap:
0.180
E[RIFτ (ln(wm ))] − E[RIFτ (ln(w f ))]
Composition effects attributable to
Age, race, region, etc.
0.015
Education
−0.011
AFQT
0.005
L.T. withdrawal due to family
0.022
Life-time work experience
0.234
Industrial sectors
0.008
Total explained by
0.274
characteristics
Wage structure effects attributable to
Age, race, region, etc.
−0.342
Education
0.023
AFQT
−0.007
L.T. withdrawal due to family −0.075
Life-time work experience
0.084
Industrial Sectors
0.015
Constant
0.208
Total wage structure
−0.094

(0.023)

0.241

(0.019)

0.260

(0.026)

(0.005)
(0.005)
(0.020)
(0.021)
(0.026)
(0.012)
(0.035)

0.013
−0.017
0.013
0.042
0.136
0.020
0.208

(0.004)
(0.006)
(0.004)
(0.014)
(0.014)
(0.008)
(0.025)

0.002
−0.005
0.013
0.039
0.039
0.047
0.136

(0.004)
(0.010)
(0.005)
(0.017)
(0.023)
(0.011)
(0.028)

(0.426)
(0.028)
(0.030)
(0.032)
(0.148)
(0.060)
(0.349)
(0.044)

0.168
−0.030
0.003
−0.005
−0.085
−0.172
0.154
0.033

(0.357)
(0.031)
(0.042)
(0.025)
(0.082)
(0.046)
(0.323)
(0.028)

0.860
0.023
0.008
0.018
−0.078
−0.054
−0.653
0.124

(0.524)
(0.045)
(0.062)
(0.032)
(0.119)
(0.052)
(0.493)
(0.036)

The data is an extract from the NLSY79 used in O’Neill and O’Neill (2006). Industrial sectors have been added to their
analysis to illustrate issues linked to categorical variables. The other explanatory variables are age, dummies for black,
hispanic, region, msa, central city. Bootstrapped standard errors are in parentheses. Means are reported in Table 2.

Limitations
This decomposition method is computationally demanding, and becomes quite cumbersome for data sets numbering more than a few thousand observations. Bootstrapping
quantile regressions for sizeable number of quantiles τ (100 would be a minimum) is
computationally tedious with large data sets. The implementation of the procedure can

Decomposition Methods in Economics

be simplified by estimating a large number of quantile regressions (say 99, one for each
percentile from 1 to 99) instead of drawing values of τs at random.47
Another limitation is that the linear specification is restrictive and finding the correct
functional form for the conditional quantile regressions can be tedious. For instance, if
there is a spike at the minimum wage in the wage distribution, this will result in flat spots
in quantile regressions that would have to be captured with spline functions with knots
that depend on X . Accurately describing a simple distribution with mass points (as is
commonly observed in wage data) can, therefore, be quite difficult to do using quantile
regressions.
As pointed out by Chernozhukov et al. (2009), it is not very natural to estimate
inverse conditional distribution functions (quantile regressions) when the main goal of
counterfactual exercises is to replace the conditional distribution function FY B |X B with
FY A |X A to obtain Eq. (27). Chernozhukov et al. (2009) suggest instead to estimate
directly distributional regression models for FY |X (·, ·), which is a more direct way of
approaching the problem.
Advantages
One advantage of the MM approach is that it provides a natural way of performing a
detailed decomposition for the wage structure component. The idea is to successively
replace the elements of β B,τ by those of β A,τ when performing the simulations, keeping
in mind that this type of detailed decomposition is path dependent. Unfortunately, the
MM approach does not provide a way of performing the detailed decomposition for the
composition effect.48 This is a major drawback since the detailed decomposition of the
composition effects is always clearly interpretable, while the detailed decomposition of
the wage structure effect arbitrarily depends on the choice of the omitted group.

4.5. Reweighting methods
Procedure
As we mention in Section 4.2, another way of estimating the counterfactual distribution
FY C (·) is to replace the marginal distribution of X for group A with the marginal distriA
bution of X for group B using a reweighting factor 9(X ). This idea was first introduced
in the decomposition literature by DiNardo, Fortin and Lemieux [DFL] (1996). While
DFL focus on the estimation of counterfactual densities in their empirical application,
the method is easily applicable to any distributional statistic.
47 See Melly (2005) for a detailed description of this alternative procedure. Gosling et al. (2000) and Autor et al.
(2005) also use a similar idea in their empirical applications to changes in the distribution of wages over time.
48 Machado and Mata (2005) (page 449-450) suggest computing the detailed decomposition for the composition effect
using an unconditional reweighting procedure. This is invalid as a way of performing the decomposition for the same
reason that a OB decomposition would be invalid if the β coefficient used for one covariate was estimated without
controlling for the other covariates. We propose a conditional reweighting procedure in the next section that deals
adequately with this issue.

63

64

Nicole Fortin et al.

In practice, the DFL reweighting method is similar to the propensity score reweighting method commonly used in the program evaluation literature (see Hirano et al.
(2003)). For instance, in DFL’s application to changes in wage inequality in the United
States, time is viewed as a state variable, or in the context of the treatment effects literature as a treatment.49 The impact of a particular factor or set of factors on changes in
the wage distribution over time is constructed by considering the counterfactual state
of the world where the distribution of this factor remained fixed in time, maintaining
the Assumption 6 of invariance of the conditional distribution. Note that in contrast
with the notation of this chapter, in DFL, time period 1 is used as reference group.50
The choice of period 0 or period 1 as the reference group is analogous to the choice of
whether the female or the male wage structure should be the reference wage structure in
the analysis of the gender wage gap and is expected to yield different results in most cases.
In DFL, manipulations of the wage distributions, computed through reweighting,
are applied to non-parametric estimates of the wage density, which can be particularly
useful when local distortions, from minimum wage effects for example, are at play. To
be consistent with the rest of this section, however, we focus our discussion on the
cumulative distribution instead of the density. The key counterfactual distribution of
interest, shown in Eq. (27) (distribution of wages that would prevail for workers in group
A if they had the distribution of characteristics of group B) is constructed, as shown in
Eq. (28), using the reweighting factor
9(X ) =

dFX B (X )
.
dFX A (X )

Although the reweighting factor is the ratio of two multivariate marginal distribution
functions (of the covariates X ), this expression can be simplified using Bayes’ rule.
Remembering that Bayes’ rule states that
X
P(Bi |A) = P(A|Bi ) · P(Bi )/
P(A|B j ) · P(B j ),
j

we have
Pr(X |D B = 1) = R

Pr(D B = 1|X )
Pr(D B = 1|X ) · dF(X )
=
Pr(D B = 1)
x Pr(D B = 1|X ) · dF(X )

and a similar expression for D B = 0. Since dFX A (X ) = Pr(X |D B = 0) and dFX B (X )
= Pr(X |D B = 1), the reweighting factor that keeps all conditioning variables as in
49 This view of course makes more sense when some policy or other change has taken place over time (see Biewen, 2001).
50 On the other hand, by analogy with the treatment effects literature, Firpo et al. (2007) use time period 0 as the reference
group.

Decomposition Methods in Economics

period 0 becomes
9(X ) =

Pr(X |D B = 1)
Pr(D B = 1|X )/ Pr(D B = 1)
=
.
Pr(X |D B = 0)
Pr(D B = 0|X )/ Pr(D B = 0)

The reweighting factor can be easily computed by estimating a probability model
b ) for
for Pr(D B = 1|X ), and using the predicted probabilities to compute a value 9(X
each observation. DFL suggest estimating a flexible logit or probit model, while Hirano,
Imbens, and Ridder propose to use a non-parametric logit model.51
The reweighting decomposition procedure can be implemented in practice as
follows:
1. Pool the data for group A and B and run a logit or probit model for the probability
of belonging to group B:
Pr(D B = 1|X ) = 1 − Pr(D B = 0|X ) = 1 − Pr(ε > −h(X )β) = 3(−h(X )α)(30)
where 3() is either a normal or logit link function, and h(X ) is a polynomial in X .
b ) for observations in group A using the
2. Estimate the reweighting factor 9(X
b B = 1|X )) and A
predicted probability of belonging to group B (Pr(D
b
b
(Pr(D B = 0|X ) = 1 − Pr(D B = 1|X )), and the sample proportions in group
b B = 1)) and A (Pr(D
b B = 0)):
B (Pr(D
b
b
b ) = Pr(D B = 1|X )/Pr(D B = 1) .
9(X
b B = 0|X )/Pr(D
b B = 0)
Pr(D
3. Compute the counterfactual statistic of interest using observations from the group A
b ).
sample reweighted using 9(X
In DFL, the main object of interest is the probability density function, which is
estimated using kernel density methods. The density for group A and the counterfactual
density can be estimated as follows using kernel density methods, where K (.) is the
kernel function:52


1 X
Yi − y
b
f Y A (y) =
K
,
h · N A i∈A
h


1 Xb
Yi − y
b
f Y C (y) =
9(X i ) · K
.
A
h · N A i∈A
h
51 The estimator suggested by Hirano et al. (2003) is a series estimator applied to the case of a logit model. The idea is to
add increasingly higher order polynomial terms in the covariates as the size of the sample increases. Importantly, they
also show that this approach yields an efficient estimate of the treatment effect.
52 The two most popular kernel functions are the Gaussian and the Epanechnikov kernel.

65

66

Nicole Fortin et al.

Consider the density function for group A, f Y A (y), and the counterfactual density
f Y C (y). The composition effect in a decomposition of densities is:
A

f (y)

1X

= f Y C (y) − f Y A (y).
A

(31)

Various statistics from the wage distribution, such as the 10th, 50th, and 90th percentile, or the variance, Gini, or Theil coefficients can be computed either from the
counterfactual density or the counterfactual distribution using the reweighting factor.
The latter procedure is easier to use as it simply involves computing (weighted) statistics
using standard computer packages. For example, the counterfactual variance can be
computed as:

2
X
c C = 1
b i ) · Yi − b
Var
9(X
µ
,
C
YA
YA
N A i∈A
where the counterfactual mean b
µY C is:
A

b
µY C =
A

1 Xb
9(X i ) · Yi .
N A i∈A

For the 90-10, 90-50, and 50-10 wage differentials, the sought-after contributions
to changes in inequality are computed as differences in the composition effects, for
example,
= [Q CA,.9 − Q A,.9 ] − [Q CA,.1 − Q A,.1 ].
190-10
X

(32)

Table 5 presents, in panel A, the results of a DFL decomposition of changes over time
in male wage inequality using large samples from combined MORG-CPS data as in Firpo
et al. (2007). In this decomposition, the counterfactual distribution of wages in 1983/85
is constructed by reweighting the characteristics of workers in 1983/85 (time period 0)
so that they look like those of 2003/05 (time period 1) workers, holding the conditional
distribution of wages in 1983/85 fixed.53 The results of the aggregate decomposition,
reported in the first three rows of Table 5, show that composition effects play a large role
in changes in overall wage inequality, as measured by the 90-10 log wage differential or
the variance of log wages. But the wage structure effects are more important when looking for increases at the top of the wage distribution, as measured by the 90-50 log wage
differential, or decreases in the bottom, as measured by the 50-10 log wage differential.
53 By contrast, in the original DiNardo et al. (1996) decomposition, workers in 1988 (time period 1) were reweighted
to look like workers in 1979 (time period 0). The counterfactual distribution of wages was asking what would the
distribution of wages look like if the workers’ characteristics had remained at 1979 levels.

0.1827 (0.0037)
0.0191 (0.0034)
0.1637 (0.0043)

0.1091 (0.0046)
0.0756 (0.0031)
0.0336 (0.0048)

0.0565 (0.0029)
−0.1301 (0.0040)

−0.0736 (0.0033)

0.1100 (0.0055)
0.0289 (0.0045)
0.0811 (0.0071)

0.1921 (0.0057)
0.0027 (0.0034)
0.1894 (0.0066)

−0.0821 (0.0044)
0.0261 (0.0040)
−0.1082 (0.0060)

0.1100 (0.0040)
0.0872 (0.0044)
0.0227 (0.0053)

0.1921 (0.0032)
0.0392 (0.0040)
0.1529 (0.0049)

0.1100 (0.0039)
0.0617 (0.0018)
0.0483 (0.0043)

0.1824 (0.0036)
0.0294 (0.0019)
0.1530 (0.0043)

−0.0724 (0.0031)
0.0323 (0.0014)
−0.1047 (0.0033)

−0.0821 (0.0030)
0.0480 (0.0018)
−0.1301 (0.0030)

0.0617 (0.0013)
0.0151 (0.0005)
0.0466 (0.0013)

0.0636 (0.0013)
0.0212 (0.0008)
0.0424 (0.0016)

0.0636 (0.0013)
0.0109 (0.0007)
0.0527 (0.0016)

0.0208 (0.0007)
0.0408 (0.0017)

0.0617 (0.0015)

Variance

0.0112 (0.0004)
−0.0038 (0.0003)
0.0150 (0.0004)

0.0118 (0.0005)
−0.0019 (0.0003)
0.0137 (0.0005)

0.0118 (0.0005)
−0.0046 (0.0003)
0.0164 (0.0006)

−0.0020 (0.0004)
0.0132 (0.0003)

0.0112 (0.0004)

Gini

The data is an extract from the Morg CPS 1983/85 (232 784 obs.) and 2003/05 (170 693 obs.) used in Firpo et al. (2007). The explanatory variables include
union status, 6 education classes (high school omitted), 9 potential experience classes (20-25 years omitted). In Panel B and C, computations were performed using
Melly’s “counterfactual” procedure. The variance and Gini coefficient were computed using 100 quantile estimates. In Panel D, the estimated change is computed as
E[RIFτ (ln(w1 ))] − E[RIFτ (ln(w0 ))]. Bootstrapped standard errors (100 reps.) are in parentheses.

Estimated change (t1 − t0 ):
Total composition effect
Total wage effect

D. Decomposition method: FFL- RIF-OLS - No reweighting

Estimated change (t1 − t0 ):
Total composition effect
Total wage effect

C. Decomposition method: CFVM - Logit - F C (Y |X ) = 3 (2003/05 X’s with 1983/85 α’s)

Estimated change (t1 − t0 ):
Total composition effect
Total wage effect

B. Decomposition method: CFVM - LPM - F C (Y |X ) = 3 (2003/05 X’s with 1983/85 α’s)

Unadjusted change
(t1 − t0 ):
Total composition effect
Total wage effect

A. Decomposition method: DFL - F(X) in 1983/85 reweighted to 2003/05

Table 5 Male wage inequality: aggregate decomposition results (CPS, 1983/85-2003/05)
Inequality measure
90-10
90-50
50-10

Decomposition Methods in Economics

67

68

Nicole Fortin et al.

Advantages
The main advantage of the reweighting approach is its simplicity. The aggregate decomposition for any distributional statistic is easily computed by running a single probability
model (logit or probit) and using standard packages to compute distributional statistics
b i ) as weight.54
with 9(X
Another more methodological advantage is that formal results from Hirano et al.
(2003) and Firpo (2007, 2010) establish the efficiency of this estimation method. Note
that although it is possible to compute analytically the standard errors of the different
elements of the decomposition obtained by reweighting, it is simpler in most cases to
conduct inference by bootstrapping.55
For these two reasons, we recommend the reweighting approach as the method of
choice for computing the aggregate decomposition. This recommendation even applies
in the simple case of the mean decomposition. As pointed out by Barsky et al. (2002), a
standard OB decomposition based on a linear regression model will yield biased estimates
of the decomposition terms when the underlying conditional expectation of Y given
X is non-linear (see Section 3.4). They suggest using a reweighting approach as an
alternative, and the results of Hirano et al. (2003) can be used to show that the resulting
decomposition is efficient.
Limitations
A first limitation of the reweighting method is that it is not straightforwardly extended
to the case of the detailed decomposition. One exception is the case of binary covariates
where it is relatively easily to compute the corresponding element of the decomposition.
For instance, in the case of the union status (a binary covariate), DFL show how to compute the component of the composition corresponding to this particular covariate. It also
relatively easy to compute the corresponding element of the wage structure effect. We
discuss in Section 5 other options that can be used in the case of non-binary covariates.
As in the program evaluation literature, reweighting can have some undesirable properties in small samples when there is a problem of common support. The problem is that
the estimated value of 9(X ) becomes very large when Pr(D B = 1|X ) gets close to 1.
While lack of common support is a problem for any decomposition procedure, Frolich
(2004) finds that reweighting estimators perform particularly poorly in this context,
though Busso et al. (2009) reach the opposite conclusion using a different simulation
experiment.56
54 In small samples, it is important to ensure that these estimated weights sum up to the number of actual observations in
the sample, though this is done automatically in packages like Stata. See Busso et al. (2009) for more detail.
55 The analytical standard errors have to take account of the fact that the logit or probit model used to construct the
reweighting factor is estimated. Firpo et al. (2007) show how to perform this adjustment. In practice, however, it is
generally simpler to bootstrap the whole estimation procedure (both the estimation of the logit/probit to construct the
weights and the computation of the various elements of the decomposition).
56 In principle, other popular methods in the program evaluation literature such as matching could be used instead of
reweighting.

Decomposition Methods in Economics

Finally, even in cases where a pure reweighting approach has some limitations, there
may be gains in combining reweighting with other approaches. For instance, we discuss
in the next section how reweighting can be used to improve a decomposition based
on the RIF-regression approach of Firpo et al. (2009). Lemieux (2002) also discusses
how an hybrid approach based on DFL reweighting and the JMP decomposition procedure can be used to compute both the between- and within-group components of the
composition and wage structure effects.

4.6. Methods based on estimating the conditional distribution
Procedure(s)
As mentioned above, when we first introduced the key counterfactual distribution of
interest in Eq. (5), an alternative approach to the construction of this counterfactual
is based on the estimation of the conditional distribution of the outcome variable,
FY A |X A (y|X ). The counterfactual distribution is then estimated by integrating this
conditional distribution over the distribution of X in group B.
Two early parametric methods based on this idea were suggested by Donald et al.
(2000), and Fortin and Lemieux (1998).57 Donald, Green and Paarsch propose estimating the conditional distribution using a hazard model. The (conditional) hazard function
is defined as
h(y|X ) =

f (y|X )
,
S(y|X )

where S(y|X ) = 1 − F(y|X ) is the survivor function. Therefore, the conditional
distribution of the outcome variable, F(y|X ), or its density, f (y|X ), is easily recovered
from the estimates of the hazard model. For instance, in the standard proportional hazard
model58
h(y|X ) = exp(X α)h 0 (y),
estimates of α and of the baseline hazard h 0 (y) can be used to recover the conditional
distribution
F(y|X ) = 1 − exp(−30 (y) exp(X α)),
where 30 (y) =

R

h 0 (u)du is the integrated baseline hazard.

57 Foresi and Peracchi (1995) proposed to use a sequence of logit models to estimate the conditional distribution of excess
returns.
58 Donald et al. (2000) use a more general specification of the proportional hazard model where α and h (y) are allowed
0
to vary for different values (segments) of y.

69

70

Nicole Fortin et al.

Fortin and Lemieux (1998) suggest estimating an ordered probit model instead of a
hazard model. They consider the following model for the outcome variable Y :
Y = 3−1 (Y ∗ ),
where 3(·) is a monotonically increasing transformation function. The latent variable
Y ∗ , interpreted as a latent “skill index” by Fortin and Lemieux, is defined as
Y ∗ = X α + ε,
where ε is assumed to follow a standard normal distribution. It follows that the conditional distribution of Y is given by
F(y|X ) = 8(−X α + 3(y)).
Fortin and Lemieux implement this in practice by discretizing the outcome variable
into a large number of small bins. Each bin j corresponds to values of Y between the
two thresholds c j−1 and c j . The conditional probability of Y being in bin j is
Prob(c j−1 ≤ Y ≤ c j |X ) = 8(−X α + 3(c j )) − 8(−X α + 3(c j−1 )).
This corresponds to an ordered probit model where the 3(c j ) parameters (for
j = 1, . . . , J ) are the usual latent variable thresholds. The estimated values of α and of
the thresholds can then be used to construct the counterfactual distribution, just as in
Donald et al. (2000).
To be more concrete, the following steps could be used to estimate the counterfactual
distribution FY C (y) at the point y = c j :
A

b A (c j ), the
1. Estimate the ordered probit for group A. This yields estimates b
α A and 3
ordered probit parameters.
bY |X (c j |X i ) = 8(−X i b
b A (c j )) for each
2. Compute the predicted probability F
αA + 3
A
A
individual i in group B.
bY |X (c j |X i ) over all
3. For each threshold c j , compute the sample average of F
A
A
observations in group B:
X
b C (c j ) = 1
b A (c j )).
8(−X i b
αA + 3
F
YA
N B i∈B
Repeating this for a large number of values of y = c j will provide an estimate of the
counterfactual distribution FY C (y).
A
In a similar spirit, Chernozhukov et al. (2009) suggest a more flexible distribution
regression approach for estimating the conditional distribution F(y|X ). Following

Decomposition Methods in Economics

Foresi and Peracchi (1995), the idea is to estimate a separate regression model for each
value of y. They consider the model F(y|X ) = 3(X α(y)), where 3(·) is a known link
function. For example, if 3(·) is a logistic function, α(y) can be estimated by creating
a dummy variable 1{Yi ≤ y} indicating whether the value of Yi is below y, where 1 {·}
is the indicator function, and running a logit regression of 1{Yi ≤ y} on X i to estimate
α(y).
Similarly, if the link function is the identity function (3(z) = z) the probability model
is a linear probability model. If the link function is the normal CDF (3(z) = 8(z)) the
probability model is a probit. Compared to Fortin and Lemieux (1998), Chernozhukov
et al. (2009) suggest estimating a separate probit for each value of y, while Fortin and
Lemieux use a more restrictive model where only the intercept (the threshold in the
ordered probit) is allowed to change for different values of y.
As above, the counterfactual distribution can be obtained by first estimating the
regression model (probit, logit, or LPM) for group A to obtain the parameter estimates
b
α A (y), computing the predicted probabilities 3(X i b
α A (y)), and averaging over these
b C (y):
predicted probabilities to get the counterfactual distribution F
Y
A

X
b C (y) = 1
F
3(X i b
α A (y)).
YA
N B i∈B
b C (y) has been estimated, counterfactual
Once the counterfactual distribution F
YA
quantiles can be obtained by inverting the estimated distribution function. Consider
QC
τ,A , the τ th quantile of the counterfactual distribution FY AC (·). The estimated counterfactual quantile is:
bC = F
b−1
Q
C (τ ).
A,τ
YA

It is useful to illustrate graphically how the estimation of the counterfactual distribub C (y) and the inversion into quantiles can be performed in practice. Figure 1 first
tion F
YA
shows the actual CDF’s for group A, FY A (·), and B, FY B (·), respectively. The squares
in between the two cumulative distributions illustrate examples of counterfactuals
computed using the one of the method discussed above.
For example, consider the case of the median wage for group B, Q B,.5 . Using the
distribution regression approach of Chernozhukov et al. (2009), one can estimate, for
example, a LPM by running a regression of 1{Yi ≤ Q B,.5 } on X i for group A. This
b C (y = Q B,.5 ).
yields an estimate of b
α A (y = Q B,.5 ) that can then be used to compute F
YA
This counterfactual proportion is represented by the square on the vertical line over
y = Q B,.5 in Fig. 1.
Figure 2 then illustrates what happens when a similar exercise is performed for a
larger number of values of y (100 in this particular figure). It now becomes clear from

71

Nicole Fortin et al.
1

Proportion (CDF, F(y))

.9

FY (y)
B

FY (y)
A

Counterfactual
proportions computed
using LP model

.5

.1
0
0

QB,.1

QB,.5

QB,.9

Y (quantiles)

Figure 1 Relationship between proportions and quantiles.

1

FY (y)
B

Proportion (CDF, F(y))

72

FY (y)
A

Counterfactual
proportions computed
using LPM

.5

0
0

QA,.5

C

QA,.5

QB,.5

Y (quantiles)

Figure 2 Inverting globally.

the figure how to numerically perform the inversion. In the case of the median, the total
gap between group A and B is Q B,.5 − Q A,.5 . The counterfactual median can then
be estimated by picking the corresponding point Q CA,.5 on the counterfactual function
defined by the set of points estimated by running a set of LPM at different values of y.
In practice, one could compute the precise value of Q CA,.5 by estimating the LPMs (or
a logit or probit) for a large number of values of y, and then “connecting the dots” (i.e.
using linear interpolations) between these different values.
Figure 2 also illustrates one of the key messages of the chapter listed in the introduction, namely that is it easier to estimate models for proportions than quantiles. In Fig. 2,
the difference in the proportion of observations under a given value of y is simply the
vertical distance between the two cumulative distributions, FY B (y) − FY A (y). Decomposing this particular gap in proportion is not a very difficult problem. As discussed in
Section 3.5, one can simply run a LPM and perform a standard OB decomposition.
An alternative also discussed in Section 3.5 is to perform a nonlinear decomposition

Decomposition Methods in Economics

using a logit or probit model. The conditional distribution methods of Fortin and
Lemieux (1998) and Chernozhukov et al. (2009) essentially amount to computing this
decomposition in the vertical dimension.
By contrast, it is not clear at first glance how to decompose the horizontal distance,
or quantile gap, between the two curves. But since the vertical and horizontal are just
two different ways of describing the same difference between the two cumulative distributions FY B (y) and FY A (y), one can perform a first decomposition either vertically
or horizontally, and then invert back to get the decomposition in the other dimension.
Since decomposing proportions (the vertical distance) is relatively easy, this suggests first
performing the decomposition on proportions at many points of the distribution, and
then inverting back to get the decomposition in the quantile dimension (the horizontal
distance).
Table 5 reports, in panels B and C, the results of the aggregate decomposition results
for male wages using the method of Chernozhukov et al. (2009). The counterfactual
wage distribution is constructed by asking what would be the distribution of wages in
1983/85 if the conditional distribution was as in 2003/05. Panel B uses the LPM to
estimate 3(X i b
α A (y)) while the logit model is used in Panel C.59 The first rows of Panel
B and C show the changes in the wage differentials based on the fitted distributions, so
that any discrepancies between these rows in the first row of Panel A shows the estimation errors. The second rows report the composition effects computed as the difference
between the fitted distribution in 1983/85 and the counterfactual distribution. Given
our relatively large sample, the differences across estimators in the different panels are
at times statistically different. However, the results from the logit estimation in Panel
C give results that are qualitatively similar to the DFL results shown in Panel A, with
composition effects being relatively more important in accounting for overall wage
inequality, as measured by the 90-10 log wage differential, and wage structure effects
playing a relatively more important role in increasing wage inequality at the top and
reducing wage inequality at the bottom.
Limitations
If one is just interested in performing an aggregate distribution, it is preferable to simply
use the reweighting methods discussed above. Like the conditional quantile methods discussed in Section 4.4, conditional distribution methods require some parametric
assumptions on the distribution regressions that may or may not be valid. Chernozhukov,
Fernandez-Val, and Melly’s distribution regression approach is more flexible than earlier
suggestions by Donald et al. (2000) and Fortin and Lemieux (1998), but it potentially
involves estimating a large number of regressions.
59 The estimation was performed using Melly’s “counterfactual” Stata procedure. The computation of the variance and
Gini coefficient were based on the estimation of 100 centiles.

73

74

Nicole Fortin et al.

Running unconstrained regressions for a large number of values of y may result,
b C (y).
however, in non-monotonicities in the estimated counterfactual distribution F
YA
Smoothing or related methods then have to be used to make sure that the counterfactual
distribution is monotonic and, thus, invertible into quantiles.60 By contrast, reweighting
methods require estimating just one flexible logit or probit regression, which is very easy
to implement in practice.
Advantages
An important advantage of distribution regression methods over reweighting is that
they can be readily generalized to the case of the detailed decomposition, although these
decomposition will be path dependent. We show in the next section how Chernozhukov,
Fernandez-Val, and Melly’s distribution regression approach, and the related RIF regression method of Firpo et al. (2009) can be used to perform a detailed decomposition very
much in the spirit of the traditional OB decomposition for the mean.

4.7. Summary
In this section we discuss most of the existing methods that have been proposed to
perform an aggregate decomposition for general distributional statistics. While all these
methods could, in principle, yield similar results, we argue that DFL reweighting is the
method of choice in this context for two main reasons. First, it is simple to implement as
it simply involves estimating a single logit or probit model for computing the reweighting factors. Counterfactual values of any distributional statistical can then be readily
computed from the reweighted sample. By contrast, methods that yield counterfactual
estimates of quantiles or the whole CDF require estimating a separate model at a large
number of points in the distribution.
The second advantage of reweighting is that there are well established results in the
program evaluation that show that the method is asymptotically efficient (Hirano et al.,
2003; Firpo, 2007).

5. DETAILED DECOMPOSITIONS FOR GENERAL DISTRIBUTIONAL
STATISTICS
In this section, we extend the methods introduced above for the aggregate decomposition to the case of the detailed decomposition. We first show that conditional distribution
methods based on distribution regressions can be used to compute both the composition
and wage structure subcomponents of the detailed decomposition. We then discuss a
related method based the RIF-regressions introduced in Firpo et al. (2009). The main
advantage of this last procedure is that it is regression based and, thus, as easy to use in
practice as the traditional OB method.
60 Chernozhukov et al. (2009) use the method of Chernozhukov et al. (2010) to ensure that the function is monotonic.

Decomposition Methods in Economics

The other methods proposed in Section 4 are not as easy to extend to the case of the
detailed decomposition. We discuss, nonetheless, which elements of the detailed decomposition can be estimated using these various methods, and under which circumstances
it is advantageous to use these methods instead of others.

5.1. Methods based on the conditional distribution
Procedure
In the case where the specification used for the distribution regression is the LPM, the
aggregate decomposition of Section 4.6 can be generalized to the detailed decomposition as follows. Since the link function for the LPM is 3(z) = z, the counterfactual
distribution used earlier becomes:
X
b C (y) = 1
α A (y).
F
Xib
α A (y) = X Bb
YA
N B i∈B
We can also write:
i
i h
h
bY (y)
b C (y) − F
bY (y) − F
b C (y) + F
bY (y) − F
bY (y) = F
F
A
B
B
A
YA
YA

= X B (b
α B (y) − b
α A (y)) + X B − X A b
α A (y),
where the first term is the familiar wage structure effect, while the second term is the
composition effect. The above equation can, therefore, be used to compute a detailed
decomposition of the difference in the proportion of workers below wage y between
groups A and B. We obtain the detailed distribution of quantiles by (i) computing the
different counterfactuals for each element of X and α sequentially, for a large number
of values of y, and (ii) inverting to get the corresponding quantiles for each detailed
counterfactual. A similar approach could also be used when the link function is a probit
or a logit by using the procedure suggested in Section 3.5.
Advantages
The main advantage of this method based on distribution regressions and the global
inversion of counterfactual CDF into counterfactual quantiles (as in Fig. 2) is that it
yields a detailed decomposition comparable to the OB decomposition of the mean.
Limitations
One limitation of this method is that it involves computing a large number of counterfactuals CDFs and quantiles, as the procedure has to be repeated for a sizable number of
values of y. This can become cumbersome because of the potential non-monotonicity
problems discussed earlier. Furthermore, the procedure suffers from the problem of path
dependence since the different counterfactual elements of the detailed decomposition

75

76

Nicole Fortin et al.

have to be computed sequentially. For these reasons, we next turn to a simpler approach
based on a local, as opposed to a global, inversion of the CDF.

5.2. RIF-regression methods
Procedure
RIF-regression methods provide a simple way of performing detailed decompositions for
any distributional statistic for which an influence function can be computed. Although
we focus below on the case of quantiles of the unconditional distribution of the outcome
variable, our empirical example includes the case of the variance and Gini. The procedure can be readily used to address glass ceiling issues in the context of the gender wage
gap, or changes in the interquartile range in the context of changes in wage inequality. It
can be used to either perform OB- type detailed decompositions, or a slightly modified
“hybrid” version of the decomposition suggested by Firpo et al. (2007) (reweighting
combined with RIF regressions, as in Section 3.4 for the mean).
A RIF-regression (Firpo et al., 2009) is similar to a standard regression, except that the
dependent variable, Y , is replaced by the (recentered) influence function of the statistic of
interest. Consider IF (y; ν), the influence function corresponding to an observed wage y
for the distributional statistic of interest, ν(FY ). The recentered influence function (RIF)
is definedR as RIF(y; ν) = ν(FY ) + IF(y; ν), so that it aggregates back to the statistics of
interest ( RIF(y; ν) · dF (y) = ν(FY )). In its simplest form, the approach assumes that
the conditional expectation of the RIF (Y ; ν) can be modeled as a linear function of the
explanatory variables,
E [RIF (Y ; ν) |X ] = X γ ,

where the parameters γ can be estimated by OLS.61
In the case of quantiles, the influence function IF (Y, Q τ ) is given by
(τ − 1{Y ≤ Q τ })/ f Y (Q τ ), where 1 {·} is an indicator function, f Y (·) is the density of the marginal distribution of Y , and Q τ is the population τ -quantile of the
unconditional distribution of Y . As a result, RIF (Y ; Q τ ) is equal to Q τ + IF (Y, Q τ ),
and can be rewritten as
RIF(y; Q τ ) = Q τ +

τ − 1 {y ≤ Q τ }
= c1,τ · 1 {y > Q τ } + c2,τ ,
f Y (Q τ )

(33)

where c1,τ = 1/ f Y (Q τ ) and c2,τ = Q τ − c1,τ · (1 − τ ). Except for the constants c1,τ
and c2,τ , the RIF for a quantile is simply an indicator variable 1 {Y ≤ Q τ } for whether
the outcome variable is smaller or equal to the quantile Q τ . Using the terminology introduced above, running a linear regression of 1 {Y ≤ Q τ } on X is a distributional regression
estimated at y = Q τ , using the link function of the linear probability model (3(z) = z).
61 Firpo et al. (2009) also propose other more flexible estimation procedures.

Decomposition Methods in Economics

Proportion (CDF, (F(y))

1

Slope of the
CDF (density)

Counterfactual
proportion

.5
Counterfactual
quantile (median)

0
0

QA,.5

QCA,.5

QB,.9

Y (quantiles)

Figure 3 RIF regressions: Inverting locally.

There is, thus, a close connection between RIF regressions and the distributional
regression approach of Chernozhukov et al. (2009). In both cases, regression models are
estimated for explaining the determinants of the proportion of workers earning less than
a certain wage. As we saw in Fig. 2, in Chernozhukov et al. (2009) estimates of models
for proportions are then globally inverted back into the space of quantiles. This provides a
way of decomposing quantiles using a series of simple regression models for proportions.
Figure 3 shows that RIF-regressions for quantiles are based on a similar idea, except
that the inversion is only performed locally. Suppose that after estimating a model for
proportions, we compute a counterfactual proportion based on changing either the
mean value of a covariate, or the return to the covariate estimated with the LPM regression. Under the assumption that the relationship between counterfactual proportions
and counterfactual quantiles is locally linear, one can then go from the counterfactual
proportion to the counterfactual quantile (both illustrated in Fig. 3) by moving along
a line with a slope given by the slope of the counterfactual distribution function. Since
the slope of a cumulative distribution is the just the probability density function, one can
easily go from proportions to quantiles by dividing the elements of the decomposition
for proportions by the density.
While the argument presented in Fig. 3 is a bit heuristic, it provides the basic intuition
for how we can get a decomposition model for quantiles by simply dividing a model for
proportions by the density. As we see in Eq. (33), in the RIF for quantiles, the indicator
variable 1 {y ≤ Q τ } is indeed divided by f Y (Q τ ) (i.e. multiplying by the constant c1,τ ).
Firpo et al. (2009) explain how to first compute the RIF, and then run regressions of
the RIF on the vector of covariates. In the case of quantiles, the RIF is first estimated by
bτ , and estimating the density at that point using kernel
computing the sample quantile Q
d i ; Q τ ), is then obtained by
methods. An estimate of the RIF of each observation, RIF(Y
b
b
b
plugging the estimates Q τ and f ( Q τ ) into Eq. (33).

77

78

Nicole Fortin et al.

Letting the coefficients of the unconditional quantile regressions for each group be
!−1
γg,τ =
b

X

Xi ·

|
Xi

·

i∈G

X

d gi ; Q g,τ ) · X i ,
RIF(Y

g = A, B

(34)

i∈G

we can write the equivalent of the OB decomposition for any unconditional quantile as


bτ = X B b
γ B,τ − b
γ A,τ + X B − X A b
γ A,τ
1
O
bτ .
bτ + 1
=1
X
S

(35)
(36)

The second term in Eq. (36) can be rewritten in terms of the sum of the contribution
of each covariate as
bτ =
1
X

K
X


X Bk − X Ak γ
bAk,τ .

k=1

That is, the detailed elements of the composition effect can be computed in the same
way as for the mean. Similarly, the detailed elements of the wage structure effects can be
computed, but as in the case of the mean, these will also be subject to the problem of the
omitted group.
Table 4 presents in its bottom panel such OB like gender wage gap decomposition
of the 10th, 50th, and 90th percentiles of the unconditional distribution of wages
corresponding to Tables 2 and 3 using the male coefficients as reference group and
without reweighting. As with the MM decomposition presented in the top panel, the
composition effects from the decomposition of the median gender pay gap reported
in the central column of Table 4 are very close to those of the decomposition of the
mean gender pay gap reported in column (1) of Table 3. As before, the wage structure
effects in the relatively small NLSY sample are generally not statistically significant, with
the exception of the industrial sectors which are, however, subject to the categorical
variables problem. The comparison of the composition effects at the 10th and 90th
percentiles shows that the impact of differences in life-time work experience is much
larger at the bottom of the distribution than at the top where it is not statistically significant. Note that the aggregate decomposition results obtained using either the MM
method or the RIF regressions do not exhibit statistically significant differences. Table 5
presents in Panel D the results of the aggregate decomposition using RIF-regressions
without reweighting. The results are qualitatively similar to those of Panels A and
C. Table 6 extends the analysis of the decomposition of male wage inequality presented in Table 5 to the detailed decomposition. For each inequality measures, the detailed
decomposition are presented both for the extension of the classic OB decomposition in

F(X ) in 1983/85
reweighted to
2003/05
No reweighting
1983/85 reference

F(X ) in 1983/85
reweighted to
2003/05

90-50

(continued on next page)

(0.0014) 0.0225 (0.0014)
(0.0053) 0.0480 (0.0059)
(0.0081) 0.0318 (0.0092)
(0.0095) −0.1688 (0.0113)
(0.0033) −0.1300 (0.0039)

(0.0006) −0.0216 (0.0006)
(0.0010) 0.0305 (0.0010)
(0.0008) 0.0233 (0.0008)
(0.0014) 0.0322 (0.0013)

(0.0031) −0.0724 (0.0031)

F(X ) in 1983/85
reweighted to
2003/05

50-10
No reweighting
1983/85 reference

Unadjusted
0.1100 (0.0039) 0.1100 (0.0039) 0.1824 (0.0036) 0.1824 (0.0036) −0.0724
change
Composition effects attributable to
Union
0.0353 (0.0008) 0.0356 (0.0008) 0.0568 (0.0009) 0.0572 (0.0009) −0.0215
Education
0.0150 (0.0012) 0.0149 (0.0012) −0.0155 (0.0010) −0.0156 (0.0010) 0.0305
Experience
0.0114 (0.0009) 0.0114 (0.0009) 0.0119 (0.0009) 0.0118 (0.0009) 0.0233
Total explained
0.0617 (0.0018) 0.0619 (0.0018) 0.0294 (0.0019) 0.0298 (0.0019) 0.0323
Wage structure effects attributable to
Union
0.0019 (0.0016) 0.0084 (0.0016) 0.0016 (0.0018) 0.0141 (0.0018) 0.0035
Education
0.1053 (0.0068) 0.1234 (0.0064) 0.0339 (0.0070) 0.0754 (0.0067) 0.0714
Experience
0.0115 (0.0127) −0.0768 (0.0138) −0.0120 (0.0110) −0.0451 (0.0116) 0.0235
Constant
−0.0705 (0.0148) −0.0211 (0.0158) 0.1326 (0.0129) 0.1477 (0.0134) −0.2031
Total wage
0.0483 (0.0043) 0.0339 (0.0042) 0.1530 (0.0043) 0.1639 (0.0043) −0.1047
structure

No reweighting
1983/85 reference

90-10

Table 6 Male wage inequality: FFL decomposition results (CPS, 1983/85-2003/05).

Inequality
measure
Reweighting

Decomposition Methods in Economics

79

No reweighting
1983/85 reference

F(X ) in 1983/85
reweighted to
2003/05

Variance

(0.0001) 0.0069 (0.0001)
(0.0001) −0.0058 (0.0001)
(0.0001) −0.0049 (0.0001)
(0.0003) −0.0037 (0.0003)
(0.0001) 0.0011 (0.0001)
(0.0007) 0.0064 (0.0007)
(0.0011) −0.0064 (0.0012)
(0.0014) 0.0129 (0.0014)
(0.0004) 0.0132 (0.0004)

0.0020
0.0070
−0.0003
0.0063
0.0150

0.0112 (0.0004)

F(X ) in 1983/85
reweighted to
2003/05

0.0069
−0.0058
−0.0049
−0.0038

0.0112 (0.0004)

No reweighting
1983/85 reference

Gini

The data is an extract from the Morg CPS 1983/85 (232 784 obs.) and 2003/05 (170 693 obs.) used in Firpo et al. (2007). The explanatory variables include union status, 6
education classes (high school omitted), 9 potential experience classes (20-25 years omitted). Bootstrapped standard errors (100 reps.) are in parentheses.

Unadjusted
0.0617 (0.0013) 0.0617 (0.0013)
change
Composition effects attributable to
Union
0.0129 (0.0002) 0.0130 (0.0002)
Education
0.0013 (0.0003) 0.0013 (0.0003)
Experience
0.0009 (0.0003) 0.0009 (0.0003)
Total explained
0.0151 (0.0005) 0.0152 (0.0005)
Wage structure effects attributable to
Union
0.0002 (0.0005) 0.0023 (0.0005)
Education
0.0483 (0.0020) 0.0419 (0.0020)
Experience
0.0033 (0.0041) −0.0177 (0.0041)
Constant
−0.0052 (0.0048) 0.0145 (0.0048)
Total wage
0.0466 (0.0013) 0.041 (0.0013)
structure

Inequality
measure
Reweighting

Table 6 (continued)

80
Nicole Fortin et al.

Decomposition Methods in Economics

Eq. (36), and for the reweighted-regression decomposition, described in the case of the
mean in Section 3.4.62 For the reweighted-regression decomposition, Table 6 reports
b τ and the detailed elements of
the detailed elements of the main composition effect 1
X, p
b τ , where
the main wage structure effect 1
S, p


b τ = X CA − X A b
1
γ A,τ
X, p

and



C
bτ = X B γ
1
b
−
γ
b
B,τ
S, p
A,τ ,

and where the group A sample is reweighted to mimic the group B sample,
C
which means
we should
have plim(X A ) = plim(X B ). The total reweighting error


b τ = X B − X CA b
γ C corresponds to the difference between the “Total explained”
1
A,τ

S,e

across the classic OB and the reweighted-regression decomposition. For example, for the
90-10 log wage differential, it is equal to 0.0617 − 0.0619 = 0.0002.63 The total specifiC −b
b τ = X CA (b
γ A,τ ), corresponds to the difference between the “Total
cation error, 1
γ A,τ
X,e
wage structure” across the classic OB and the reweighted-regression decomposition and
is found to be more important. In terms of composition effects, de-unionization is found
to be an important factor accounting for the polarization of male wage inequality. It
is also found to reduce inequality at the bottom, as measured by the 50-10 log wage
differential, and to increase inequality at the top, as measured by the 90-50 log wage
differential. In terms of wage structure effects, increases in the returns to education are
found, as in Lemieux (2006a), to be the dominant factor accounting for overall increases
in male wage inequality.
Advantages
The linearity of RIF regressions has several advantages. It is straightforward to invert the
proportion of interest by dividing by the density. Since the inversion can be performed
locally, another advantage is that we don’t need to evaluate the global impact at all points
of the distribution and worry about monotonicity. One gets a simple regression which is
easy to interpret. As a result, the resulting decomposition is path independent.
Limitations
Like many other methods, RIF regressions assume the invariance of the conditional
distribution (i.e., no general equilibrium effects). Also, a legitimate practical issue is how
good the approximation is. For relatively smooth dependent variables, such as test scores,
it may be a moot point. But in the presence of considerable heaping (usually displayed
62 Using a reweighted regression approach can be particularly important in the cases of RIF-regressions that are unlikely
to be linear for distributional statistics besides the mean.
63 The reweighting error reflects the fact that the composition effect in the reweighted-regression decomposition,


C
C , is not exactly equal to the standard composition effect X − X  b
C
XB − XA b
γ A,τ
B
B γ A,τ when the reweighted
C

mean X A is not exactly equal to X B .

81

82

Nicole Fortin et al.

in wage distribution), it may advisable to oversmooth density estimates and compare
its values around the quantile of interest. This can be formally looked at by comparing
reweighting estimates to the OB-type composition effect based on RIF regressions (the
specification error discussed earlier).

5.3. A reweighting approach
Procedure(s)
As we mention in Section 4, it is relatively straightforward to extend the DFL reweighting
method to perform a detailed decomposition in the case of binary covariates. DFL show
how to compute the composition effect corresponding to a binary covariate (union
status in their application). Likewise, DiNardo and Lemieux (1997) use yet another
reweighting technique to compute the wage structure component. We first discuss the
case where a covariate is a binary variable, and then discuss the case of categorical (with
more than 2 categories) and continuous variables.
Binary covariate
Consider the case of one binary covariate, X 1 , and a vector of other covariates, X 2 . For
instance, DiNardo et al. (1996) look at the case of unionization. They are interested in
isolating the contribution of de-unionization to the composition effect by estimating
what would have happened to the wage distribution if the distribution of unionization,
but of none of the other covariates, had changed over time.
Letting A index the base period and B the end period, consider the counterfactual
distribution F C,X 1 , which represents the period A distribution that would prevail if the
YA

conditional distribution of unionization (but of none of the other covariates X 2 ) was
as in period B.64 Note that we are performing a counterfactual experiment by changing the conditional, as opposed to the marginal, distribution of unionization. Unless
unionization is independent of other covariates (X 1 ⊥ X 2 ), the marginal distribution of
unionization, FX (X 1 ), will depend on the distribution of X 2 , FX (X 2 ). For instance, if
unionization is higher in the manufacturing sector, but the share of workers in manufacturing declines over time, the overall unionization rate will decline even if, conditional
on industrial composition, the unionization rate remains the same.
Using the language of program evaluation, we want to make sure that secular changes
in the rate of unionization are not confounded by other factors such as industrial
change. This is achieved by looking at changes in the conditional, as opposed to the
marginal distribution of unionization. Note that the main problem with the procedure
suggested by MM to compute the elements of the composition effect corresponding
to each covariate is that it fails to control this problem. MM suggest using an unconditional reweighting procedure based on the change in the marginal, as opposed to the
64 Note that in DFL, it is the opposite; group B is the 1988 time period and group A is the 1979 time period.

Decomposition Methods in Economics

conditional distribution of covariates. Unless the covariates are independent, this will
yield biased estimates of the composition effect elements of the detailed decomposition.
The counterfactual distribution F C,X 1 is formally defined as
YA

F

C,X 1

YA

(y) =

Z Z

FY A |X A (y|X 1 , X 2 ) dFX B (X 1 |X 2 ) dFX A (X 2 )

Z Z

FY A |X A (y|X 1 , X 2 ) 91 (X 1 , X 2 ) dFX A (X 1 |X 2 ) dFX A (X 2 )

Z Z

FY A |X A (y|X 1 , X 2 ) 91 (X 1 , X 2 ) dFX A (X 1 , X 2 ),

=
=

where the reweighting function is
dFX B (X 1 |X 2 )
dFX A (X 1 |X 2 )
Pr B (X 1 = 1|X 2 )
Pr B (X 1 = 0|X 2 )
= X1 ·
+ (1 − X 1 ) ·
.
Pr A (X 1 = 1|X 2 )
Pr A (X 1 = 0|X 2 )

9 X 1 (X 1 , X 2 ) ≡

(37)
(38)

Note that the conditional distribution FY A (Y A |X 1 , X 2 ) is assumed to be unaffected by
the change in the conditional distribution of unionization (assumption of invariance of
conditional distribution in Section 2). This amounts to assuming away selection into
union status based on unobservables (after controlling for the other covariates X 2 ).
The reweighting factor 91 (X 1 , X 2 ) can be computed in practice by estimating two
probit or logit models for the probability that a worker is unionized in period A and B,
respectively. The resulting estimates can then be used to compute the predicted probability of being unionized (Pr A (X 1 = 1|X 2 ) and Pr B (X 1 = 1|X 2 )) or not unionized
(Pr A (X 1 = 0|X 2 ) and Pr B [X 1 = 0|X 2 ]), and then plugging these estimates into the
above formula.
DiNardo and Lemieux (1997) use a closely related reweighting procedure to compute the wage structure component of the effect of unions on the wage distribution.
Consider the question of what would happen to the wage distribution if no workers
were unionized. The distribution of wages among non-union workers:
Z Z
FYg (y|X 1 = 0) =
FYg |X g (y|X 1 = 0, X 2 ) dFX A (X 2 |X 1 = 0),
is not a proper counterfactual since the distribution of other covariates, X 2 , may not
be the same for union and non-union workers. DiNardo and Lemieux (1997) suggest
solving this problem by reweighting non-union workers so that their distribution of X 2
is the same as for the entire workforce. The reweighting factor that accomplishes this at

83

84

Nicole Fortin et al.

time A and B are 9 A,S1 (X 2 ) and 9 B,S1 (X 2 ), respectively, where:
9g,S1 (X 2 ) =

Prg (X 1 = 0)
,
Prg (X 1 = 0|X 2 )

g = A, B.

Using these reweighting terms, we can write the counterfactual distribution of wages
that would have prevailed in the absence of unions as:
Z Z
F C,S1 (y) =
FYg |X g (y|X 1 = 0, X 2 ) 9g,S1 (X 2 ) dFX g (X 2 , X 1 = 0), g = A, B.
Yg

These various counterfactual distributions can then be used to compute the contriF(y)
bution of unions (or another binary variable x1 ) to the composition effect, 1 X 1 , and
F(y)

to the wage structure effect, 1 S1 :
F(y)

1X1

= FY A (y) − F

C,X 1

YA

(y),

(39)

and
F(y)

1 S1

= [FY A (y) − F

C,S1

YA

(y)] − [FY B (y) − F

C,S1

YB

(y)].

(40)

Although we need three different reweighting factors (9 X 1 (X 1 , X 2 ), 9 A,S1 (X 2 ),
and 9 B,S1 (X 2 )) to compute the elements of the detailed wage decomposition corresponding to X 1 , these three reweighting factors can be constructed from the estimates
of the two probability models Pr A (X 1 = 1|X 2 ) and Pr B (X 1 = 1|X 2 ). As before, once
these reweighting factors have been computed, the different counterfactual statistics are
easily obtained using standard statistical packages.
General covariates
It is difficult to generalize the approach suggested above to the case of covariates that are
not binary. In the case of the composition effect, one approach that has been followed in
the applied literature consists of sequentially adding covariates in the probability model
Pr(D B = 1|X ) used to compute 9(X ).65 For instance, start with Pr(D B = 1|X 1 ),
compute 91 (X 1 ) and the counterfactual statistics of interest by reweighting. Then do
the same thing with Pr(D B = 1|X 1 , X 2 ), etc.
One shortcoming of this approach is that the results depend on the order in which the
covariates are sequentially introduced, just like results from a sequential decomposition
65 See, for example, Butcher and DiNardo (2002) and Altonji et al. (2008).

Decomposition Methods in Economics

for the mean also depend on the order in which the covariates are introduced in the
regression. For instance, estimates of the effect of unions that fail to control for any other
covariates may be overstated if union workers tend to be concentrated in industries that
would pay high wages even in the absence of unions. As pointed out by Gelbach (2009),
the problem with sequentially introducing covariates can be thought of as an omitted
variable problem. Unless there are compelling economic reasons for first looking at
the effect of some covariates without controlling for the other covariates, sequential
decompositions will have the undesirable property of depending (strongly in some cases)
on the order of the decomposition (path dependence).66
Fortunately, there is a way around the problem of path dependence when performing
detailed decompositions using reweighting methods. The approach however still suffers
from the adding-up problem and is more appropriate when only the effect of a particular
factor is of interest. To illustrate this approach, consider a case with three covariates X 1 ,
X 2 , and X 3 . In a sequential decomposition, one would first control for X 1 only, then for
X 1 and X 2 , and finally for X 1 , X 2 , and X 3 . On the one hand, the regression coefficient
on X 1 and/or X 2 in regressions that fail to control for X 3 are biased because of the
omitted variable problem. The corresponding elements of a detailed OB decomposition
for the mean based on these estimated coefficients would, therefore, be biased too.
On the other hand, the coefficient on the last covariate to be introduced in the
regression (X 3 ) is not biased since the other covariates (X 1 and X 2 ) are also controlled
for. So although order matters in a sequential regression approach, the effect of the last
covariate to be introduced is not affected by the omitted variable bias.
The same logic applies in the case of detailed decompositions based on a reweighting approach. Intuitively, the difference in the counterfactual distribution one gets by
reweighting with X 1 and X 2 only, comparing to reweighting with X 1 , X 2 , and X 3
should yield the appropriate contribution of X 3 to the composition effect.
To see this more formally, consider the group A counterfactual distribution that
would prevail if the distribution of X 3 , conditional on X 1 , X 2 , was as in group B:
F

C,X 3

YA

(y) =

Z

FY A |X A (y|X )dFX B (X 3 |X 1 , X 2 )dFX A (X 1 , X 2 ),

Z

FY A |X A (y|X )9 X 3 |X 1 ,X 2 (X 1 , X 2 )dFX A (X 3 |X 1 , X 2 )dFX A (X 1 , X 2 ),

Z

FY A |X A (y|X )9 X 3 |X 1 ,X 2 (X 1 , X 2 )dFX A (X 1 , X 2 , X 3 ),

=
=

66 Both Butcher and DiNardo (2002) and Altonji et al. (2008) consider cases where there is indeed a good reason for
following a particular order in the decomposition. For instance, Altonji et al. (2008) argue that, when looking at various
youth outcomes, one should first control for predetermined factors like gender and race before controlling for other
factors determined later in life (AFQT score, educational achievement, etc.). In such a situation, the decomposition is
econometrically interpretable even if gender and race are introduced first without controlling for the other factors.

85

86

Nicole Fortin et al.

where the reweighting factor 9 X 3 |X 1 ,X 2 (X 1 , X 2 ) can be written as:
dFX B (X 3 |X 1 , X 2 )
dFX A (X 3 |X 1 , X 2 )
dFX B (X 1 , X 2 , X 3 )/dFX B (X 1 , X 2 )
=
dFX A (X 1 , X 2 , X 3 )/dFX A (X 1 , X 2 )
= 9(X 1 , X 2 , X 3 )/9 X 1 ,X 2 (X 1 , X 2 ).

9 X 3 |X 1 ,X 2 (X 1 , X 2 ) ≡

9(X 1 , X 2 , X 3 ) is the reweighting factor used to compute the aggregate decomposition in Section 4.5. 9 X 1 ,X 2 (X 1 , X 1 ) is a reweighting factor based on all the covariates
except the one considered for the detailed decomposition (X 3 ). As before, Bayes’ rule
can be used to show that:
9 X 3 |X 1 ,X 2 (X 1 , X 2 ) =

Pr(D B = 1|X 1 , X 2 )/ Pr(D B = 1)
Pr(X 1 , X 2 |D B = 1)
=
.
Pr(X 1 , X 2 |D B = 0)
Pr(D B = 0|X 1 , X 2 )/ Pr(D B = 0)

Once again, this new reweighting factor is easily computed by running a probit or logit
regression (with X 1 and X 2 as covariates) and using predicted probability to estimate
9 X 3 |X 1 ,X 2 (X 1 , X 2 ).
This reweighting procedure for the detailed decomposition is summarized as follows:
1. Compute the reweighting factor using all covariates, 9(X ).
2. For each individual covariate k, compute the reweighting factor using all covariates
but X k , 9 X −k (X −k ).
3. For each covariate k, compute the counterfactual statistic of interest using the ratio
of reweighting factors 9(X )9 X −k (X −k ) as weight, and compare it to the counterfactual statistic obtained using only 9(X ) as weight. The difference is the estimated
contribution of covariate k to the composition effect.
Note that while this procedure does not suffer from path dependence, the contribution of each covariates does not sum up to the total contribution of covariates
(aggregate composition effect). The difference is an interaction effect between the
different covariates which is harder to interpret.
Advantages
This reweighting procedure shares most of the advantages of the other reweighting
procedures we proposed for the aggregate decomposition. First, it is generally easy to
implement in practice. Second, by using a flexible specification for the logit/probit, it is
possible to get estimates of the various components of the decomposition that depend
minimally on functional form assumptions. Third, the procedure yields efficient
estimates.

Decomposition Methods in Economics

Limitations
With a large number of covariates, one needs to compute a sizable number of reweighting factors to compute the various elements of the detailed decomposition. This can
be tedious, although it does not require that much in terms of computations since each
probit/logit is easy to estimate. Another disadvantage of the suggested decomposition
is that although it does not suffer from the problem of path dependence, we are still left
with an interaction term which is difficult to interpret. For these reasons, we suggest to
first use a regression-based approach like the RIF-regression approach discussed above,
which is essentially as easy to compute as a standard OB decomposition. The reweighting
procedure suggested here can then be used to probe these results, and make sure they are
robust to the functional-form assumptions implicit in the RIF-regression approach.

5.4. Detailed decomposition based on conditional quantiles
As we mentioned earlier, the method of Machado and Mata (2005) can be used to
compute the wage structure sub-components of the detailed decomposition. These
components are computed by sequentially switching the coefficients of the quantile
regressions for each covariate from their estimated valued for group B to their estimated
values for group A. This sequential switching cannot be used, however, to compute
the sub-components of the composition effect of the detailed decomposition. Rather,
Machado and Mata (2005) suggest an unconditional reweighting approach to do so. This
does not provide a consistent effect since the effect of the reweighted covariate of interest
gets confounded by other covariates correlated with that same covariate. For instance,
if union workers are more concentrated in manufacturing, doing an unconditional
reweighting on unions will also change the fraction of workers in manufacturing. In this
sense the effect of unions is getting confounded by the effect of manufacturing.
This is a significant drawback since it is arguably more important to conduct a
detailed decomposition for the composition effect than for the wage structure effect.
As discussed earlier, there are always some interpretation problems with the detailed
components of the wage structure effect because of the omitted group problem.
One solution is to use the conditional reweighting procedure described above
instead. But once this type of reweighting approach is used, there is no need to estimate
(conditional) quantile regressions. Unless the quantile regressions are of interest on their
own, it is preferable to use a more consistent approach, such as the one based on the
estimation of RIF-regressions, for estimating the detailed components of both the wage
structure and composition effects.

6. EXTENSIONS
In this section, we present three extensions to the decomposition methods discussed
earlier. We first consider the case where either the ignorability or the zero conditional
mean assumptions are violated because of self-selection or endogeneity of the covariates.

87

88

Nicole Fortin et al.

We next discuss the situation where some of these problems can be addressed when
panel data are available. We conclude the section by discussing the connection between
conventional decomposition methods and structural modeling.

6.1. Dealing with self-selection and endogeneity
The various decomposition procedures discussed up to this point provide consistent
estimates of the aggregate composition and wage structure effects under the ignorability assumption. Stronger assumptions, such as conditional mean independence (for
decompositions of the mean) or straight independence, have to be invoked to perform
the detailed decomposition. In this section we discuss some alternatives for estimating
the decomposition when these assumptions fail. We mostly focus on the case of the OB
decomposition of the mean, though some of the results we present could be extended to
more general distributional statistics.
We consider three scenarios, first introduced in Section 2.1.6, under which the OB
decomposition is inconsistent because of a failure of the ignorability or conditional
independence assumption. In the first case, the problem is that individuals from groups
A and B may self-select differently into the labor market. For instance, participation
decisions of men (group B) may be different from participation decisions of women
(group A) in ways that are not captured by observable characteristics. In the second
case, we consider what happens when individuals can self-select into group A or B (for
instance union and non-union jobs) on the basis of unobservables. The third case is a
standard endogeneity problem where the covariates are correlated with the error term.
For example, education (one of the covariate) may be correlated with the error term
because more able individuals tend to get more schooling.
1. Differential self-selection within groups A and B.
One major concern when decomposing differences in wages between two groups
with very different labor force participation rates is that the probability of participation depends on unobservables ε in different ways for groups A and B. This is a well
known problem in the gender wage gap literature (Blau and Kahn, 2006; Olivetti and
Petrongolo, 2008; Mulligan and Rubinstein, 2008, etc.) and in the black-white wage
gap literature (Neal and Johnson, 1996).
Our estimates of decomposition terms may be directly affected when workers of
groups A and B self-select into the labor market differently. Thus, controlling for selection based on observables and unobservables is necessary to guarantee point identification
of the decomposition terms. If no convincing models for self-selection is available a more
agnostic approach based on bounds has also been recently proposed. Therefore, following Machado (2009), we distinguish three branches in the literature of self-selection: (i)
selection on observables; (ii) selection based on unobservables; (iii) bounds.

Decomposition Methods in Economics

Selection based on observables and, when panel data are available, on time-invariant
unobserved components can be used to impute values for the missing data on wages of
non-participants. Representative papers of this approach are Neal and Johnson (1996),
Johnson et al. (2000), Neal (2004), Blau and Kahn (2006) and Olivetti and Petrongolo
(2008). These papers are typically concerned with mean or median wages. However,
extensions to cumulative distribution functions or general ν-wage gaps could also be
considered.
When labor market participation is based on unobservables, correction procedures
for the mean wages are also available. In these procedures, a control variate is added as
a regressor in the conditional expectation function. The exclusion restriction that an
available instrument Z does not belong to the conditional expectation function also
needs to be imposed.67 Leading parametric and nonparametric examples are Heckman
(1974, 1976), Duncan and Leigh (1980), Dolton and Makepeace (1986), Vella (1998),
Mulligan and Rubinstein (2008).
In this setting, the decomposition can be performed by adding a control variate
λg (X i , Z i ) to the regression. In most applications, λg (X i , Z i ) is the usual inverse Mills’
ratio term obtained by fitting a probit model of the participation decision. Note that the
addition of this control variate slightly changes the interpretation of the decomposition.
The full decomposition for the mean is now
1µ = (β B0 − β A0 ) +
+

K
X

K
X

X Bk (β Bk − β Ak ) + λ B (σ B − σ A )

k=1



X Bk − X Ak β Ak + λ B − λ A σ A .

k=1

where σ A and σ B are the estimated coefficients on the control variates. The decomposition provides a full accounting for the wage gap that also includes differences in both
the composition of unobservables ((λ B − λ A )σ A ) and in the return to unobservables
(λ B (σ B − σ A )). This treats symmetrically the contribution of observables (the X ’s) and
unobservables in the decomposition.
A third approach uses bounds for the conditional expectation function of wages
for groups A and B. With those bounds one can come up with bounds for the wage
µ
µ
µ
structure effect, 1 S , and the composition effect, 1 X . Let 1 S = E[(E [Y B |X, D B = 1]−
E [Y A |X, D B = 1])|D B = 1]. Then, letting D S be a dummy indicating labor force participation, we can write the conditional expected wage as





E Yg |X, Dg = E Yg |X, Dg , D S = 0 + Pr D S = 1|X, Dg
67 As is well known, selection models can be identified on the basis of functional restrictions even when an excluded
instrumental variable is not available. This is no longer viewed, however, as a credible identification strategy. We,
therefore, only focus on the case where an instrumental variable is available.

89

90

Nicole Fortin et al.





× E Yg |X, Dg , D S = 1 − E Yg |X, Dg , D S = 0
and therefore
L g + Pr D S = 1|X, Dg


≤ E Yg |X, Dg






E Yg |X, Dg , D S = 1 − L g

≤ Ug + Pr D S = 1|X, Dg






E Yg |X, Dg , D S = 1 − Ug

where L g and Ug are lower and upper bounds of the distribution of Yg , for g = A, B.
Therefore,
(E [Y B |X, D B = 1, D S = 1] − E [Y A |X, D B = 1, D S = 1]) Pr (D S = 1|X, D B = 1)
+ (L B − U A ) Pr (D S = 0|X, D B = 1)
≤ E [Y B |X, D B = 1] − E [Y A |X, D B = 1]
≤ (E [Y B |X, D B = 1, D S = 1]
− E [Y A |X, D B = 1, D S = 1]) Pr (D S = 1|X, D B = 1)
+ (U B − L A ) Pr (D S = 0|X, D B = 1) .
This bounding approach to the selection problem may also use restrictions motivated
by econometric or economic theory to narrow the bounds, as in Manski (1990) and
Blundell et al. (2007).
2. Self-Selection into groups A and B
In the next case we consider, individuals have the choice to belong to either group A or
B. The leading example is the choice of the union status of workers. The traditional way
of dealing with the problem is to model the choice decision and correct for selection
biases using control function methods.68
As discussed in Section 2.1.6, it is also possible to apply instrumental variable methods more directly without explicitly modeling the selection process into groups A and B.
Imbens and Angrist (1994) show that this will identify the wage gap for the subpopulation
of compliers who are induced by the instrument to switch from one group to the other.
3. Endogeneity of the covariates
The standard assumption used in the OB decomposition is that the outcome variable
Y is linearly related to the covariates, X , and that the error term υ is conditionally
independent of X , as in Eq. (1). Now consider the case where the conditional independence assumption fails because one or several of the covariates are correlated with the
68 See for instance, the survey of Lewis (1986) who concludes that these methods yield unreliable estimates of the union
wage gap. Given these negative results and the lack of credible instruments for unionization, not much progress has
been made in this literature over the last two decades. One exception is DiNardo and Lee (2004) who use a regression
discontinuity design.

Decomposition Methods in Economics

error term. Note that while the ignorability assumption may hold even if conditional
independence fails, we consider a general case here where neither assumption holds.
As is well known, the conventional solution to the endogeneity problem is to use
instrumental variable methods. For example, if we suspect years of education (one of
the covariate) to be correlated with the error term in the wage equation, we can still
estimate the model consistently provided that we have a valid instrument for years of
education. The decomposition can then be performed by replacing the OLS estimates
of the β coefficients by their IV counterparts.
Of course, in most cases it is difficult to come up with credible instrumentation
strategies. It is important to remember, however, that even when the zero conditional
mean assumption E(υ|X ) = 0 fails, the aggregate decomposition may remain valid,
provided that ignorability holds. This would be the case, for example, when unobserved
ability is correlated with education, but the correlation (more generally the conditional
distribution of ability given education) is the same in group A and B. While we are not
able to identify the contribution of education vs. ability in this context (unless we have
an instrument), we know that there are no systematic ability differences between groups
A and B once we have controlled for education. As a result, the aggregate decomposition
remains valid.

6.2. Panel data
An arguably better way of dealing with the selection and endogeneity problems mentioned above is to use panel data. Generally speaking, panel data methods can be used
to compute consistent estimates of the β’s in each of the three cases discussed earlier.
For example, if the zero conditional mean assumption holds once we also control for a
person-specific fixed effects θi in a panel of length T (E(υit |X i1 , . . . , X i T , θi ) = 0),
we can consistently estimate β using standard panel data methods (fixed effects, first
differences, etc.). This provides an alternative way of dealing with endogeneity problems
when no instrumental variables are available.
As we also discussed earlier, panel data can be used to impute wages for years where
an individual is not participating in the labor market (e.g. Olivetti and Petrongolo, 2008).
Note that in cases where groups are mutually exclusive (e.g. men vs. women), it may still
be possible to estimate fixed effect models if the basic unit used is the firm (or related
concepts) instead (Woodcock, 2008). Care has to be exercised in those circumstances to
ensure that the firm fixed effect is the same for both female and male employees of the
same firm. Another important issue with these models is the difficulty of interpretation
of the differences in male and female intercepts which may capture the unobserved or
omitted individual and firm effects.
Panel data methods have also been used to adjust for the selection into groups in cases
where the same individual is observed in group A and B. For example, Freeman (1984)
and Card (1996) estimate the union wage gap with panel data to control for the selection

91

92

Nicole Fortin et al.

of workers into union status. Lemieux (1998) uses a more general approach where the
return to the fixed effect may be different in the union and non-union sector. He also
shows how to generalize the approach to the case of a decomposition of the variance.
Without loss of generality, assume that the return to the fixed effect for non-union
workers (group A) is 1, while it is equal to σ B for union workers. The mean decomposition adjusted for fixed effects yields:
1µ = (β B0 − β A0 ) +

K
X

X Bk (β Bk − β Ak ) + θ B (σ B − 1)

k=1

+

K
X



X Bk − X Ak β Ak + θ B − θ A .

k=1

The interpretation of the decomposition is the same as in a standard OB setting
except that (θ B − θ A ) now represents the composition effect term linked to nonrandom selection into the union sector, while the wage structure term θ B (σ B − 1)
captures a corresponding wage structure effect.
More sophisticated models with several levels of fixed effects have also been used in
practice. For instance, Abowd et al. (2008) decompose inter-industry wage differentials
into various components that include both individual- and firm-specific fixed effects.

6.3. Decomposition in structural models
In Section 2, we pointed out that decomposition methods were closely related to methods used in the program evaluation literature where it is not necessary to estimate a fully
specified structural model to estimate the main parameter of interest (the ATT). Provided
that the ignorability assumption is satisfied, we can perform an aggregate decomposition
without estimating an underlying structural model.
There are some limits, however, to what can be achieved without specifying any
structure to the underlying economic problem. As we just discussed in Section 6.1,
one problem is that the ignorability assumption may not hold. Under this scenario,
more explicit modeling may be useful for correcting biases in the decomposition due to
endogeneity, self-selection, etc.
Another problem that we now address concerns the interpretation of the wage
structure components of the detailed decomposition. Throughout this chapter, we have
proposed a number of ways of estimating these components for both the mean and
more general distributional statistics. In the case of the mean, the interpretation of the
detailed decomposition for the wage structure effect is relatively straightforward. Under
the assumption (implicit in the OB decomposition) that the wage equations are truly
linear and the errors have a zero conditional mean, we can think of the wage setting
model as a fully specified structural model. The β coefficients are the “deep” structural

Decomposition Methods in Economics

parameters of the model, and these structural parameters are used directly to perform the
decomposition.
Things become more complicated once we go beyond the mean. For instance, in
the case of the variance (Section 4.1), recall that the wage structure effect from Eq. (26)
which depends on the parameters of both the models for the conditional mean (β) and
for the variance (δ).
Take, for example, the case where one of the covariates is the union status of workers. The parameter δ captures the “compression”, or within-group, effect, while the
parameter β captures the “wage gap”, or between-group, effect. These two terms have a
distinct economic interpretation as they reflect different channels through which union
wage policies tend to impact the wage distribution.
In the case of more general distributional statistics, the wage structure effect depends
on an even larger number of underlying parameters capturing the relationship between
the covariates and higher order moments of the distribution. As a result, the wage
structure part of the detailed decomposition becomes even harder to interpret, as it
potentially depends on a large number of underlying parameters.
In some cases, this may not pose a problem from an interpretation point of view. For
instance, we may only care about the overall effect of unions, irrespective of whether
it is coming from a between- or within-group effect (or corresponding components
for higher order moments). But in other cases this type of interpretation may be unsatisfactory. Consider, for example, the effect of education on the wage structure. Like
unions, education may influence wage dispersion through a between- or within-group
channel. The between-group component is linked to the traditional return to education
(effect on conditional means), but education also has a substantial effect on within-group
dispersion (see, e.g., Lemieux, 2006b). All these effects are combined together in the
decomposition methods proposed in Section 5, which is problematic if we want to
know, for instance, the specific contribution of changes in the return to education to the
growth in wage inequality.
In these circumstances, we need to use a more structural approach to get a more economically interpretable decomposition of the wage structure effect. The decomposition
method of Juhn et al. (1993) is, in fact, an early example of a more structurally-based
decomposition. In their setting, the model for the conditional mean is interpreted as an
underlying human capital pricing equation. Likewise, changes in residual wage dispersion
(given X ) are interpreted as reflecting an increase in the return to unobservable skills.
As we discussed in Section 4.3, the fact that Juhn et al. (1993) provides a richer
interpretation of the wage structure effect by separating the within- and between-group
components is an important advantage of the method. We also mentioned, however,
that the interpretation of the decomposition was not that clear for distributional statistics
going beyond the variance, and that the procedure typically imposes substantial restrictions on the data that may or may not hold. By contrast, a method like DFL imposes very

93

94

Nicole Fortin et al.

little restrictions (provided that the probit/logit model used for reweighting is reasonably
flexible), though it is more limited in terms of the economic interpretation of the wage
structure effect.
In light of this, the challenge is to find a way of imposing a more explicit structure
on the economic problem while making sure the underlying model “fits” the data reasonably well. One possible way of achieving this goal is to go back to the structural form
introduced in Section 2 (Ygi = m g (X i , εi )), and use recent results from the literature
on nonparametric identification of structural functions to identify the functions m g (·).
As discussed in Section 2.2.1, this can be done by invoking results obtained by Matzkin
(2003), Blundell and Powell (2007) and Imbens and Newey (2009). Generally speaking,
it is possible to identify the functions m g (·) nonparametrically under the assumptions of
independence of ε (Assumption 8), and strict monotonicity of m g (·) in ε (Assumption 9).
But while it is possible, in principle, to nonparametrically identify the functions
m g (·), there is no guarantee that the resulting estimates will be economically interpretable. As a result, a more common approach used in the empirical literature is to
write down a more explicit (and parametric) structural model, but carefully look at
whether the model adequately fits the data. Once the model has been estimated, simulation methods can then be used to compute a variety of counterfactual exercises. The
counterfactuals then form the basis of a more economically interpretable decomposition
of the wage structure effect.
To take a specific example, consider the Keane and Wolpin (1997) model of career
progression of young men, where educational and occupational choices are explicitly
modeled using a dynamic programming approach. After carefully looking at whether the
estimated model is rich enough to adequately fit the distribution of wages, occupational
choices, and educational achievement, Keane and Wolpin use the estimated model to
decompose the distribution of lifetime utility (itself computed using the model). They
conclude that 90 percent of the variance of lifetime utility is due to skill endowment
heterogeneity (schooling at age 16 and unobserved type). By contrast, choices and other
developments happening after age 16 have a relatively modest impact on the variance of
lifetime utility.69 The general idea here is to combine structural estimation and simulation methods to quantify the contribution of the different parameters of interest to some
decompositions of interest. These issues are discussed in more detail in the chapter on
structural methods by Keane et al. (2011).
One last point is that the interpretation problem linked to the wage structure effect
does not apply to the detailed decomposition for the composition effect. In that case,
each component is based on a clear counterfactual exercise that does not require an
underlying structure to be interpretable. The aggregate decomposition is based on the
69 Note, however, that Hoffman (2009) finds that skill endowments have a sizably smaller impact in a richer model that
incorporates comparative advantage (across occupations), search frictions, and exogenous job displacement.

Decomposition Methods in Economics

following counterfactual exercise: what would be the distribution of outcomes for group
A if the distribution of the covariates for group A were the same as for group B? Similarly, the detailed decomposition is based on a conditional version of the counterfactual.
For example, one may want to ask what would be the distribution of outcomes for group
A if the distribution of unionization (or another covariate) for group A was the same as
for group B, conditional on the distribution of the other covariates remaining the same.
These interpretation issues aside, it may still be useful to use a more structural
approach when we are concerned about the validity of the decomposition because of
self-selection, endogeneity, etc. For instance, in Keane and Wolpin (1997), the choice
of schooling and occupation is endogenous. Using standard decomposition methods to
look, for instance, at the contribution of the changing distribution of occupations to
changes in the distribution wages would yield invalid results because occupational choice
is endogenous. In such a context, structural modeling, like the IV and selection methods
discussed in Section 6.1, can help recover the elements of the decomposition when
standard methods fail because of endogeneity or self-selection. But the problem here is
quite distinct from issues with the wage structure effect where standard decomposition
methods are limited because of an interpretation problem, and where structural modeling provides a natural way of resolving this interpretation problem. By contrast, solutions
to the problem of endogeneity or self-selection are only as a good as the instruments (or
related assumptions) used to correct for these problems. As a result, the value added of
the structural approach is much more limited in the case of the composition effect than
in the case of the wage structure effect.
This last point is very clear in the emerging literature where structural modeling is
used in conjunction with experimental data. For example, Card and Hyslop (2005) use
experimental data from the Self Sufficiency Project (SSP) to look at why individuals
offered with a generous work subsidy are less likely to receive social assistance (SA). By
definition, there is no composition effect since the treatment and control groups are
selected by random assignment. In that context, the average treatment effect precisely
corresponds to the wage structure effect (or “SA” structure effect in this context) in
a decomposition of the difference between the treatment and control group. It is still
useful, however, to go beyond this aggregate decomposition to better understand the
mechanisms behind the measured treatment effect. Card and Hyslop (2005) do so by
estimating a dynamic search model.
This provides much more insight into the “black box” of the treatment effect than
what a traditional decomposition exercise would yield. Remember that the detailed
wage structure component in a OB type decomposition is based on the difference
between the return to different characteristics in the two groups. In a pure experimental
context like the SSP project, this simply reflects some heterogeneity in the treatment
effect across different subgroups. Knowing about the importance of heterogeneity in the
treatment effect is important from the point of view of the generalizability of the results.

95

96

Nicole Fortin et al.

But unlike a structural approach, it provides relatively little insight on the mechanisms
underlying the treatment effect.

7. CONCLUSION
The development of new decomposition methods has been a fertile area of research
over the last 10-15 years. Building on the seminal work of Oaxaca (1973) and Blinder
(1973), a number of procedures that go beyond the mean have been suggested and used
extensively in practice. In this chapter, we have reviewed these methods and suggested
a number of “best practices” for researchers interested in these issues. We have also
illustrated how these methods work in practice by discussing existing applications and
working through a set of empirical examples throughout the chapter.
Another important and recent development in this literature has linked decomposition methods to the large and growing literature on program evaluation and treatment
effects. This connection is useful for several reasons. First, it helps clarify some interpretation issues with decompositions. In particular, results from the treatment effects
literature can be used to show, for example, that we can give a structural interpretation
to an aggregate decomposition under the assumption of ignorability. Another benefit of
this connection is that formal results about the statistical properties of treatment effects
estimators can also be directly applied to decomposition methods. This helps guide the
choice of decomposition methods that have good statistical properties, and conduct
inference on these various components of the estimated decomposition.
But this connection with the treatment effects literature also comes at a cost. While
no structural modeling is required to perform a decomposition or estimate a treatment
effect, these approaches leave open the question of what are the economic mechanisms
behind the various elements of the decomposition (or behind the treatment effect). Now
that the connection between decomposition methods and the treatment effects literature
has been well established, an important direction for future research will be to improve
the connection between decomposition methods and structural modeling.
The literature on inequality provides some useful hints on how this connection can
be useful and improved upon. In this literature, decomposition methods have helped
uncover the most important factors behind the large secular increase in the distribution
of wages. Those include the return to education, de-unionization, and the decline in
the minimum wage, to mention a few examples. These findings have spurred a large
number of more conceptual studies trying to provide formal economic explanations for
these important phenomena. In principle, these explanations can then be more formally
confronted to the data by writing down and estimating a structural model, and using
simulation methods to quantify the role of these explanations.
This suggest a two-step research strategy where “off-the-shelf ” decomposition
methods, like those discussed in this chapter, can first be used to uncover the main forces

Decomposition Methods in Economics

underlying an economic phenomenon of interest. More “structural” decomposition
methods could then be used to better understand the economics behind the more
standard decomposition results. We expect such a research strategy to be a fruitful area of
research in the years to come.

REFERENCES
Abowd, John M., Kramarz, Francis, Lengerman, Paul, Roux, Sebastien, 2008. Persistent inter-industry
wage differences: rent sharing and opportunity costs. Working paper.
Albrecht, James, Björklund, Anders, Vroman, Susan, 2003. Is there a glass ceiling in Sweden? Journal of
Labor Economics 21, 145–178.
Altonji, Joseph G., Blank, Rebecca, 1999. Race and gender in the labor market. In: Ashenfelter, O.,
Card., D. (Eds.), Handbook of Labor Economics, vol. 3C. Elsevier Science, Amsterdam.
Altonji, Joseph G., Matzkin, Rosa L., 2005. Cross section and panel data estimators for nonseparable models
with endogenous regressors. Econometrica 73, 1053–1102.
Altonji, Joseph G., Bharadwaj, P., Lange, Fabian, 2008, Changes in the characteristics of American youth:
Implications for adult outcomes. Working paper, Yale University.
Athey, Susan, Imbens, Guido W., 2006. Identification and inference in nonlinear difference-in-differences
models. Econometrica 74, 431–497.
Autor, David H., Levy, Frank, Murnane, Richard, 2003. The skill content of recent technological change:
an empirical exploration. Quarterly Journal of Economics 118, 1279–1333.
Autor, David H., Katz, Lawrence B., Kearney, Melissa S., 2005. Rising Wage Inequality: The Role of
Composition and Prices. NBER Working Paper No. 11628, September.
Barsky, R., Bound, John, Charles, K., Lupton, J., 2002. Accounting for the black-white wealth gap: a
nonparametric approach. Journal of the American Statistical Association 97, 663–673.
Bauer, Thomas K., Göhlmann, Silja, Sinning, Mathias, 2007. Gender differences in smoking behavior.
Health Economics 19, 895–909.
Bauer, Thomas K., Sinning, Mathias, 2008. An extension of the Blinder–Oaxaca decomposition to
nonlinear models. Advances in Statistical Analysis 92, 197–206.
Bertrand, Marianne, Hallock, Kevin F., 2001. The gender gap in top corporate jobs. Industrial and Labor
Relations Review 55, 3–21.
Biewen, Martin, 2001. Measuring the effects of socio-economic variables on the income distribution: an
application to the income distribution: an application to the East German transition process. Review of
Economics and Statistics 83, 185–190.
Bitler, Marianne P., Gelbach, Jonah B., Hoynes, Hilary W., 2006. What mean impacts miss: distributional
effects of welfare reform experiments. American Economic Review 96, 988–1012.
Black, Dan, Haviland, Amelia, Sanders, Seth, Taylor, Lowell, 2008. Gender wage disparities among the
highly educated. Journal of Human Resources 43, 630–659.
Blau, Francine D., Kahn, Lawrence M., 1992. The gender earnings gap: learning from international
comparisons. American Economic Review 82, 533–538.
Blau, Francine D., Kahn, Lawrence M., 1997. Swimming upstream: trends in the gender wage differential
in the 1980s. Journal of Labor Economics 15, 1–42.
Blau, Francine D., Kahn, Lawrence M., 2003. Understanding international differences in the gender pay
gap. Journal of Labor Economics 21, 106–144.
Blau, Francine D., Kahn, Lawrence M., 2006. The US gender pay gap in the 1990s: slowing convergence.
Industrial & Labor Relations Review 60 (1), 45–66.
Blinder, Alan, 1973. Wage discrimination: reduced form and structural estimates. Journal of Human
Resources 8, 436–455.
Blundell, Richard, Powell, James L., 2007. Censored regression quantiles with endogenous regressors.
Journal of Econometrics 141, 65–83.
Blundell, Richard, Gosling, Amanda, Ichimura, Hidehiko, Meghir, Costas, 2007. Changes in the distribution of male and female wages accounting for employment composition using bounds. Econometrica
75, 323–363.

97

98

Nicole Fortin et al.

Bourguignon, Francois, 1979. Decomposable income inequality measures. Econometrica 47, 901–920.
Bourguignon, F., Ferreira, Francisco H.G., 2005. Decomposing changes in the distribution of household
incomes: methodological aspects. In: Bourguignon, F., Ferreira, F.H.G., Lustig, N. (Eds.), The Microeconomics of Income Distribution Dynamics in East Asia and Latin America. World Bank, pp. 17–46.
Bourguignon, F., Ferreira, Francisco H.G., Leite, Philippe G., 2008. Beyond Oaxaca–Blinder: Accounting
for differences in household income distributions. Journal of Economic Inequality 6, 117–148.
Busso, Matias, DiNardo, John, McCrary, Justin, 2009. New Evidence on the Finite Sample Properties of
Propensity Score Matching and Reweighting Estimators. IZA Discussion Paper No. 3998.
Butcher, Kristin F., DiNardo, John, 2002. The Immigrant and native-born wage distributions: evidence
from United States censuses. Industrial and Labor Relations Review 56, 97–121.
Cain, Glen, 1986. The economic analysis of labor market discrimination: a survey. In: Ashenfelter, O.C.,
Layard, R. (Eds.), Handbook of Labor Economics, vol. 1. North-Holland, pp. 709–730.
Card, David, 1992. The Effects of Unions on the Distribution of Wages: Redistribution or Relabelling?
NBER Working Paper 4195. National Bureau of Economic Research, Cambridge, Mass.
Card, David, 1996. The effect of unions on the structure of wages: a longitudinal analysis. Econometrica
64, 957–979.
Card, David, Hyslop, Dean R., 2005. Estimating the effects of a time-limited earnings subsidy for
welfare-leavers. Econometrica 73, 1723–1770.
Chay, Kenneth Y., Lee, David S., 2000. Changes in relative wages in the 1980s: returns to observed and
unobserved skills and black-white wage differentials. Journal of Econometrics 99 (1), 1–38.
Chernozhukov, Victor, Fernandez-Val, Ivan, Melly, Blaise, 2009. Inference on Counterfactual Distributions.
CeMMAP working paper CWP09/09.
Chernozhukov, Victor, Fernandez-Val, Ivan, Galichon, A., 2010. Quantile and probability curves without
crossing. Econometrica 78, 1093–1126.
Chiquiar, Daniel, Hanson, Gordon H., 2005. International migration, self-selection, and the distribution of
wages: Evidence from Mexico and the United States. Journal of Political Economy 113, 239–281.
Cotton, Jeremiah, 1998. On the decomposition of wage differentials. Review of Economics and Statistics
70, 236–243.
Cowell, Frank A., 1980. On the structure of additive inequality measures. Review of Economic Studies 47,
521–531.
Denison, E.F., 1962. The sources of economic growth in the United States and the alternatives before us.
Supplementary Paper No. 13. Committee for Economic Development, New York.
DiNardo, John, Fortin, Nicole M., Lemieux, Thomas, 1996. Labor market institutions and the distribution
of wages, 1973-1992: a semiparametric approach. Econometrica 64, 1001–1044.
DiNardo, John, Lee, David S., 2004. Economic impacts of new unionization on private sector employers:
1984-2001. The Quarterly Journal of Economics 119, 1383–1441.
DiNardo, John, Lemieux, Thomas, 1997. Diverging male inequality in the United States and Canada,
1981-1988: do institutions explain the difference. Industrial and Labor Relations Review 50, 629–651.
Dolton, Peter John, Makepeace, Gerald H., 1986. Sample selection and male-female earnings differentials
in the graduate labour market. Oxford Economic Papers 38, 317–341.
Doiron, Denise J., Riddell, W. Craig, 1994. The impact of unionization on male-female earnings differences
in Canada. Journal of Human Resources 29, 504–534.
Donald, Stephen G., Green, David A., Paarsch, Harry J., 2000. Differences in wage distributions between
Canada and the United States: an application of a flexible estimator of distribution functions in the
presence of covariates source. Review of Economic Studies 67, 609–633.
Duncan, Gregory M., Leigh, Duane E., 1980. Wage determination in the union and nonunion sectors: a
sample selectivity approach. Industrial and Labor Relations Review 34, 24–34.
Egel, Daniel, Graham, Bryan, Pinto, Cristine, 2009. Efficicient estimation of data combination problems by
the method of auxiliary-to-study tilting. mimeo.
Even, William E., Macpherson, David A., 1990. Plant size and the decline of unionism. Economics Letters
32, 393–398.
Fairlie, Robert W., 1999. The absence of the African-American owned business: an analysis of the dynamics
of self–employment. Journal of Labor Economics 17, 80–108.

Decomposition Methods in Economics

Fairlie, Robert W., 2005. An extension of the Blinder-Oaxaca decomposition technique to logit and probit
models. Journal of Economic and Social Measurement 30, 305–316.
Fields, Judith, Wolff, Edward N., 1995. Interindustry wage differentials and the gender wage gap. Industrial
and Labor Relations Review 49, 105–120.
Firpo, Sergio, 2007. Efficient semiparametric estimation of quantile treatment effects. Econometrica 75,
259–276.
Firpo, Sergio, 2010. Identification and Estimation of Distributional Impacts of Interventions Using Changes
in Inequality Measures. EESP-FGV. mimeo.
Firpo, Sergio, Fortin, Nicole M., Thomas, Lemieux, 2007. Decomposing Wage Distributions using
Recentered Influence Functions Regressions. mimeo, University of British Columbia.
Firpo, Sergio, Fortin, Nicole M., Lemieux, Thomas, 2009. Unconditional quantile regressions. Econometrica 77 (3), 953–973.
Fitzenberger, Bernd, Kohn, Karsten, Wang, Qingwei, 2010. The erosion of union membership in Germany:
determinants, densities, decompositions. Journal of Population Economics (forthcoming).
Foresi, Silverio, Peracchi, Franco, 1995. The conditional distribution of excess returns: an empirical analysis.
Journal of the American Statistical Association 90, 451–466.
Fortin, Nicole M., Lemieux, Thomas, 1998. Rank regressions, wage distributions, and the gender gap.
Journal of Human Resources 33, 610–643.
Fortin, Nicole M., 2008. The gender wage gap among young adults in the United States: the importance of
money vs. people. Journal of Human Resources 43, 886–920.
Freeman, Richard B., 1980. Unionism and the dispersion of wages. Industrial and Labor Relations Review
34, 3–23.
Freeman, Richard B., 1984. Longitudinal analysis of the effect of trade unions. Journal of Labor Economics
2, 1–26.
Freeman, Richard B., 1993. How much has deunionization contributed to the rise of male earnings
inequality?. In: Danziger, Sheldon, Gottschalk, Peter (Eds.), Uneven Tides: Rising Income Inequality in
America. Russell Sage Foundation, New York, 133-63.
Frolich, Markus, 2004. Finite-sample properties of propensity-score matching and weighting estimators.
Review of Economics and Statistics 86, 77–90.
Gardeazabal, Javier, Ugidos, Arantza, 2004. More on the identification in detailed wage decompositions.
Review of Economics and Statistics 86, 1034–57.
Gelbach, Jonah B., 2002. Identified Heterogeneity in Detailed Wage Decompositions. mimeo, University
of Maryland at College Park.
Gelbach, Jonah B., 2009. When Do Covariates Matter? And Which Ones, and How Much? mimeo, Eller
College of Management, University of Arizona.
Gomulka, Joanna, Stern, Nicholas, 1990. The employment of married women in the United Kingdom,
1970–1983. Economica 57, 171–199.
Gosling, Amanda, Machin, Stephen, Meghir, Costas, 2000. The changing distribution of male wages in the
U.K,. Review of Economic Studies 67, 635–666.
Greene, William H., 2003. Econometric Analysis, 5th ed., Pearson Education, Upper Saddle River, NJ.
Heckman, James, 1974. Shadow prices, market wages and labor supply. Econometrica 42, 679–694.
Heckman, James, 1976. The common structure of statistical models of truncation, sample selection and
limited dependent variables and a simple estimator for such models. Annals of Economic and Social
Measurement 5, 475–492.
Heckman, James, 1979. Sample selection bias as a specification error. Econometrica 47, 153–163.
Heckman, James J., Smith, Jeffrey, Clements, Nancy, 1997a. Making the most out of programme evaluations
and social experiments: accounting for heterogeneity in programme impacts. Review of Economic
Studies 64 (4), 487–535.
Heckman, James J., Ichimura, Hidehiko, Todd, Petra, 1997b. Matching as an econometric evaluation estimator: evidence from evaluating a job training programme. Review of Economic Studies 64, 605–654.
Heckman, James J., Ichimura, Hidehiko, Smith, Jeffrey, Todd, Petra, 1998. Characterizing selection bias
using experimental data. Econometrica 66, 1017–1098.
Heywood, John S., Parent, Daniel, 2009. Performance Pay and the White-Black Wage Gap. mimeo, McGill
University.

99

100

Nicole Fortin et al.

Hirano, Kiesuke, Imbens, Guido W., Ridder, Geert, 2003. Efficient estimation of average treatment effects
using the estimated propensity score. Econometrica 71, 1161–1189.
Holland, Paul W., 1986. Statistics and causal inference. Journal of the American Statistical Association 81
(396), 945–960.
Hoffman, Florian, 2009. An Empirical Model of Life-Cycle Earnings and Mobility Dynamics. University
of Toronto, Department of Economics. mimeo.
Horrace, William, Oaxaca, Ronald L., 2001. Inter-industry wage differentials and the gender wage gap: an
identification problem. Industrial and Labor Relations Review 54, 611–618.
Imbens, Guido W., Angrist, Joshua, 1994. Identification and estimation of local average treatment effects.
Econometrica 62, 467–476.
Imbens, Guido W., Newey, Whitney K., 2009. Identification and estimation of triangular simultaneous
equations models without additivity. Econometrica 77 (5), 1481–1512.
Jann, Ben, 2005. Standard errors for the Blinder-Oaxaca decomposition. German Stata Users’ Group
Meetings 2005. Available from http://repec.org/dsug2005/oaxaca se handout.pdf.
Jann, Ben, 2008. The Oaxaca-Blinder decomposition for linear regression models. Stata Journal 8, 435–479.
Jones, Frank Lancaster, 1983. On decomposing the wage gap: a critical comment on blinder’s method.
Journal of Human Resources 18, 126–130.
Johnson, William, Kitamura, Yuichi, Neal, Derek, 2000. Evaluating a simple method for estimating
black-white gaps in median wages. American Economic Review 90, 339–343.
Jorgenson, D.W., Griliches, Z., 1967. The explanation of productivity change. Review of Economic Studies
34, 249–283.
Juhn, Chinhui, Murphy, Kevin M., Pierce, Brooks, 1991. Accounting for the slowdown in black-white
wage convergence. In: Kosters, M.H. (Ed.), Workers and Their Wages: Changing Patterns in the United
States. American Enterprise Institute, Washington.
Juhn, Chinhui, Murphy, Kevin M., Pierce, Brooks, 1993. Wage inequality and the rise in returns to skill.
Journal of Political Economy 101, 410–442.
Keane, Michael P., Wolpin, Kenneth I., 1997. The career decisions of young men. Journal of Political
Economy 105, 473–522.
Keane, Michael P., Todd, Petra E., Wolpin, Kenneth I., 2011. The structural estimation of behavioral
models: discrete choice dynamic programming methods and applications. In: Ashenfelter, O., Card, D.
(Eds.), Handbook of Labor Economics, vol. 4A. Elsevier Science, Amsterdam, pp. 331–461.
Kendrick, John W., 1961. Productivity Trends in the United States. Princeton University Press, Princeton.
Kennedy, Peter, 1986. Interpreting dummy variables. Review of Economics and Statistics 68, 174–175.
Kline, Pat, 2009. Blinder-Oaxaca as a Reweighting Estimator. UC Berkeley mimeo.
Koenker, Roger, Bassett, G., 1978. Regression quantiles. Econometrica 46, 33–50.
Krueger, Alan B., Summers, Lawrence H., 1988. Efficiency wages and the inter-industry wage structure.
Econometrica 56 (2), 259–293.
Krieg, John M., Storer, Paul, 2006. How much do students matter? applying the Oaxaca decomposition to
explain determinants of adequate yearly progress. Contemporary Economic Policy 24, 563–581.
Lemieux, Thomas, 1998. Estimating the effects of unions on wage inequality in a panel data model with
comparative advantage and non-random selection. Journal of Labor Economics 16, 261–291.
Lemieux, Thomas, 2002. Decomposing changes in wage distributions: a unified approach. The Canadian
Journal of Economics 35, 646–688.
Lemieux, Thomas, 2006a. Post-secondary education and increasing wage inequality. American Economic
Review 96, 195–199.
Lemieux, Thomas, 2006b. Increasing residual wage inequality: composition effects, noisy data, or rising
demand for skill?. American Economic Review 96, 461–498.
Lewis, H.Gregg, 1963. Unionism and Relative Wages in the United States. University of Chicago Press,
Chicago.
Lewis, H.Gregg, 1986. Union Relative Wage Effects: A Survey. University of Chicago Press, Chicago.
Neumark, David, 1988. Employers’ discriminatory behavior and the estimation of wage discrimination.
Journal of Human Resources 23, 279–295.
Machado, José F., Mata, José, 2005. Counterfactual decomposition of changes in wage distributions using
quantile regression. Journal of Applied Econometrics 20, 445–465.

Decomposition Methods in Economics

Machado, Cecilia, 2009. Selection, Heterogeneity and the Gender Wage Gap. Columbia University,
Economics Department. mimeo.
Manski, Charles F., 1990. Nonparametric bounds on treatment effects. American Economic Review 80 (2),
319–323.
Matzkin, Rosa L., 2003. Nonparametric estimation of nonadditive random functions. Econometrica 71 (5),
1339–1375.
McEwan, P.J., Marshall, J.H., 2004. Why does academic achievement vary across countries? Evidence from
Cuba and Mexico. Education Economics 12, 205–217.
Melly, Blaise, 2006. Estimation of counterfactual distributions using quantile regression. University of St.
Gallen, Discussion Paper.
Melly, Blaise, 2005. Decomposition of differences in distribution using quantile regression. Labour
Economics 12, 577–590.
Mulligan, Casey B., Rubinstein, Yona, 2008. Selection, investment, and women’s relative wages over time.
Quarterly Journal of Economics 123, 1061–1110.
Neal, Derek A., Johnson, W., 1996. The role of premarket factors in black-white wage differences. Journal
of Political Economy 104, 869–895.
Neal, Derek A., 2004. The measured black-white wage gap among women is too small. Journal of Political
Economy 112, S1-S28.
Ñopo, Hugo, 2008. Matching as a tool to decompose wage gaps. Review of Economics and Statistics 90,
290–299.
Oaxaca, Ronald, 1973. Male-female wage differentials in urban labor markets. International Economic
Review 14, 693–709.
Oaxaca, Ronald L., Ransom, Michael R., 1994. On discrimination and the decomposition of wage
differentials. Journal of Econometrics 61, 5–21.
Oaxaca, Ronald L., Ransom, Michael R., 1998. Calculation of approximate variances for wage decomposition differentials. Journal of Economic and Social Measurement 24, 55–61.
Oaxaca, Ronald L., Ransom, Michael R., 1999. Identification in detailed wage decompositions. Review
of Economics and Statistics 81, 154–157.
Oaxaca, Ronald L., 2007. The challenge of measuring labor market discrimination against women. Swedish
Economic Policy Review 14, 199–231.
Olivetti, Claudia, Petrongolo, Barbara, 2008. Unequal pay or unequal employment? a cross-country analysis
of gender gaps. Journal of Labor Economics 26, 621–654.
O’Neill, June, O’Neill, Dave, 2006. What do wage differentials tell us about labor market discrimination?.
In: Polachek, Soloman, Chiswich, Carmel, Rapoport, Hillel (Eds.), The Economics of Immigration and
Social Policy. Research in Labor Economics 24, 293–357.
Reimers, Cornelia W., 1983. Labor market discrimination against hispanic and black men. Review of
Economics and Statistics 65, 570–579.
Robins, James, Rotnizky, Andrea, Ping Zhao, Lue, 1994. Estimation of regression coefficients when some
regressors are not always observed. Journal of the American Statistical Association 89, 846–866.
Rosenbaum, Paul R., Rubin, Donald B., 1983. The central role of the propensity score in observational
studies for causal effects. Biometrika 70, 41–55.
Rosenbaum, Paul R., Rubin, Donald B., 1984. Reducing bias in observational studies using subclassification
on the propensity score. Journal of the American Statistical Association 79, 516–524.
Rothe, Christoph, 2009. Nonparametric estimation of distributional policy effects. Journal of Econometrics
155, 56–70.
Shorrocks, Anthony F., 1980. The class of additively decomposable inequality measures. Econometrica 48,
613–625.
Shorrocks, Anthony F., 1984. Inequality decomposition by population subgroups. Econometrica 52,
1369–1385.
Shorrocks, Anthony F. 1999. Decomposition Procedures for Distributional Analysis: A Unified Framework
Based on the Shapley Value. University of Essex, Department of Economics. mimeo.
Solow, Robert, 1957. Technical change and the aggreagate production function. Review of Economics and
Statistics 39, 312–320.
Sohn, Ritae, 2008. The Gender Math Gap: Is It Growing? mimeo, SUNY Albany.

101

102

Nicole Fortin et al.

Vella, Frank, 1998. Estimating models with sample selection bias: a survey. Journal of Human Resources 33,
127–169.
Woodcock, Simon D., 2008. Wage differentials in the presence of unobserved worker, firm, and match
heterogeneity?. Labour Economics 15, 772–794.
Yun, Myeong-Su, 2005. A simple solution to the identification problem in detailed wage decomposition.
Economic Inquiry 43, 766–772. with Erratum, Economic Inquiry (2006), 44: 198.
Yun, Myeong-Su, 2008. Identification problem and detailed oaxaca decomposition: a general solution and
inference. Journal of Economic and Social Measurement 33, 27–38.

