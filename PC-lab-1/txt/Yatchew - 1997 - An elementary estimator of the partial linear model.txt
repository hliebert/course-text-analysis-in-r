Economics Letters 57 (1997) 135–143

An elementary estimator of the partial linear model
A. Yatchew*
Department of Economics, University of Toronto, 150 St. George Street, Toronto, ON M5 S 3 G7, Canada
Received 20 May 1997; accepted 19 June 1997

Abstract
Given y 5 zb 1 f(x) 1 ´ where dim(x) # 3, we propose an elementary and asymptotically efficient estimator of b. Data are
reordered so that the x’s are ‘‘close’’, then higher order differencing is applied to remove f(x). A simple specification test of f
is included.  1997 Elsevier Science S.A.
Keywords: Partial linear model; Differencing; Specification test; Returns to scale in electricity distribution; Hedonic prices of
housing attributes
JEL classification: C14; L94; R31

1. Introduction
The idea of differencing to remove the nonparametric effect in non / semiparametric regression
models is not new. In the partial linear model it is exploited by Powell (1987) and Ahn and Powell
(1993). In a pure nonparametric regression setting it has a longer history having been used to obtain
estimates of the residual variance.1 By using results of Hall, Kay and Titterington (Hall et al., 1990),
we refine a simple differencing estimator of the partial linear model so that it achieves the same
degree of asymptotic efficiency as Robinson’s (Robinson, 1988) estimator, (which in turn achieves the
asymptotic efficiency bound). An attractive feature of our procedure is that it eliminates the need for
initial nonparametric estimation procedures. Although our procedure works only if the dimension of x
does not exceed 3, the estimator should be relevant in many applications since the curse of
dimensionality often limits the number of variables that can be modelled nonparametrically.
By way of introduction, suppose one has data ( y 1 ,z 1 ,x 1 ) . . . ( y T ,z T ,x T ) on the model y 5 zb 1 f(x) 1
´ where for simplicity all variables are assumed to be scalars. The x’s have compact support say the
unit interval. Most important, the data are rearranged so that x 1 # . . . # x T . All that is known about f
is that its first derivative is bounded by a constant, (not known to the investigator), say L. If one first
differences the data to obtain:
*Tel.: 11 416 9787128; fax: 11 416 9786713; e-mail; yatchew@chass.utoronto.ca
1
See Rice (1984), Gasser, Sroka and Jennen-Steinmetz (Gasser et al., 1986), Buckley, Fagleson and Silverman (Buckley et
¨
¨
al., 1988), Muller
and Stadtmuller
(1988), Yatchew (1988) and Hall, Kay and Titterington (Hall et al., 1990, 1991).
0165-1765 / 97 / $17.00  1997 Elsevier Science S.A. All rights reserved.
PII S0165-1765( 97 )00218-8

A. Yatchew / Economics Letters 57 (1997) 135 – 143

136

y t 2 y t21 5 (z t 2 z t 21 )b 1 ( f(x t ) 2 f(x t 21 )) 1 ´t 2 ´t21

t 5 2, . . . ,T

(1.1)

then, as sample size increases – packing the unit interval with x’s – the typical difference x t 2x t 21
shrinks at a rate close to 1 /T so that f(x t 21 ) tends to cancel f(x t ), (the bound on the first derivative
implies that u f(x t )2f(x t21 )u#Lux t 2x t21 u). As long as z is not perfectly correlated with x, then under
mild conditions the OLS estimator of b using the differenced data, i.e.,

O

( y t 2 t t21 )(z t 2 z t 21 )
bˆ diff 5 ]]]]]]]]
2
(z t 2 z t21 )

O

(1.2)

is T 1 / 2 -consistent asymptotically N ( b, 1.5 s ´2 /Ts u2 ) where s u2 is the expected conditional variance of
z given x (see Proposition 1 below). In contrast, Robinson (1988) rewrites the partial linear model
conditioning on x:
y 2 E( yux) 5 y 2 E(zux)b 2 f(x) 5 [z 2 E(zux)] b 1 ´

(1.3)

If E( yux) and E(zux) are known and substituted into (1.3), then ordinary least squares will yield an
estimate of b which is asymptotically N( b, s 2´ /Ts 2u ). Of course the regression functions E( yux) and
E(zux) are generally not even known to have particular parametric forms. Robinson then produces
nonparametric (kernel) estimators of E( yux) and E(zux) that converge sufficiently quickly so that their
substitution in the OLS estimator does not affect its asymptotic distribution. The method can be quite
onerous since separate nonparametric regressions are required for each parametric variable and for the
dependent variable. On the other hand, the first differencing estimator in (1.2), while avoiding these
preliminary nonparametric regressions, achieves only 66.7%(51 / 1.5) efficiency relative to Robinson’s estimator. The main objective of this paper is to show that this can be improved substantially
through judicious higher order differencing.

2. Estimation and inference of b
Consider the following generalization of Eq. (1.1):

O d y 5SO d z D b 1O d f(x
m

m

j

m

t2j

j t2j

j 50

j50

j

j50

Od´
m

t2j ) 1

j t 2j

t 5 m 1 1, . . . ,T

(2.1)

j 50

where m is the order of differencing. Two conditions are imposed on the differencing coefficients
d 0 , . . . ,d m :

O d 50 O d 51
m

m

2
j

j

j50

(2.2)

j 50

The first condition ensures that differencing removes the nonparametric effect in Eq. (2.1) as sample
size increases and the reordered x’s become ‘‘close’’. The second condition is a normalization
restriction which implies that the (transformed) residual in (2.1) has variance s 2´ .
The viability of the estimator depends critically on the behaviour of the average squared distances
between reordered x’s, that is on 1 /T o ix t 2x t21 i 2 where i?i denotes the usual Euclidean norm.

A. Yatchew / Economics Letters 57 (1997) 135 – 143

137

Intuition may be gleaned by examining the equi-spaced case. If x is a scalar then distances between
adjacent observations are O(T 21 ) in which case 1 /T o (x t 2x t21 )2 5O(T 22 ). On the unit square,
21 / 2
2
distances between evenly distributed observations are O(T
) in which case 1 /T o ix t 2x t 21 i 5
O(T 21 ) and for k-dimensional x, 1 /T o ix t 2x t21 i 2 5O(T 22 / k ).
With random x’s similar results hold so long as reasonable ordering rules are used. If x is a scalar,
the obvious ordering rule is x 1 # . . . #x T . If x is of higher dimension, we propose an ordering rule
based on the nearest neighbour algorithm because it is simple to compute (see Appendix A Lemma).
Assumptions. Suppose we are given data ( y 1 ,z 1 ,x 1 ) . . . ( y T ,z T ,xT ) on the model y5zb 1f(x)1 ´,
E(´ ux,z)50, Var(´ ux,z)5 s 2´ , x is a k-dimensional random variable, k#3, with density bounded away
from zero on a compact set in R k . The data have been reordered according to an ordering rule with the
property that 1 /T o ix t 2x t21 i 2 5OP (T 22( 12d ) / k ) for d positive and arbitrarily close to 0. The
p-dimensional random variable z has a nondegenerate conditional distribution given x with E(zux)5
g(x) and E(Cov(zux))5 ou . The function f and the components of the vector function g have bounded
first derivatives. j
Proposition 1. Fix the order of differencing m. Select optimal differencing weights d 0 , . . . ,d m by
minimizing d 5o mk 51 (o j d j d j 1k )2 subject to constraints (2.2). Define Dy to be the (T2m)31 vector
m
m
whose elements are [Dy] t 5o j 50 d j y t2j and DZ to be the (T2m)3p matrix with entries [DZ] ti 5o j 50
d j z t 2j,i . Then

S S

2
1 s´
A
bˆ diff 5 [DZ9DZ] 21 DZ9Dy |N b, 1 1 ] ] S 21
2m T u

1
s 2diff 5 ]
T

O (Dy 2 Dz bˆ
t

t

1
P
Sˆ u,diff 5 ] DZ9DZ → Su
T

P

diff

)2 → s 2´

j

D

D

(2.3)
(2.4)
(2.5)

Thus, by increasing the order of differencing m from 1 to 2 to 3, relative efficiency improves from
66.7% to 80% to 85.7%. By selecting m sufficiently large, the estimator approaches asymptotic
efficiency. Optimal differencing weights do not have analytic expressions but have been tabulated (up
to m510), by Hall, Kay and Titterington (Hall et al., 1990). For m51 the weights minimizing d
]
subject to (2.2) are (1, 21) /Œ2, (in this case minimization of d is redundant). For m52 they are
]
(0.8090, 20.5, 20.3090). (If one uses the ‘‘natural’’ second differencing weights (1, 22,1) /Œ6 then
relative efficiency actually declines to 51.4%.) For m53 they are (0.1942, 0.2809, 0.3832, 20.8582).
Sign reversal or order reversal maintains optimality of weights.

3. Specification test for f
Once b has been estimated using the differencing estimator, we may want to test parametric
specifications for f. Let h(x,g ) be a known function of x and an unknown parameter g. We wish to test
the null hypothesis that the regression function has the parametric form zb 1h(x,g ) against the

138

A. Yatchew / Economics Letters 57 (1997) 135 – 143

alternative that it takes the semiparametric form zb 1f(x). Let bˆ LS , gˆ LS be obtained by a parametric
2
nonlinear regression of y on x and z. Define the restricted estimator of the residual variance s res
51 /T
2
ˆ
ˆ
o ( y t 2z t bLS 2h(x t , gLS )) .
2

Proposition 2. Suppose Ho :f(x)5h(x,g ) is true where h is a known function. Define s res as above and
D
2
s diff
as in equation (2.4). Let V5(mT )1 / 2 (s 2res 2s 2diff ) /s 2diff , then V →N (0,1). j
A significance test on x is a special case of the above procedure – f is a constant function and so the
restricted model is the linear regression function g 1zb.

4. Applications
Using Ontario data, we estimate the model y5zb 1f(x)1 ´ where y is variable costs of distributing
electricity per customer and x is the scale of operation as measured by the number of customers. The
vector z includes measures of customer density, (lower density results in higher costs of delivery per
customer), remaining life of distribution assets, (older plant requires more maintenance), a proxy for
local wage rates and other variables. Fig. 1 contains estimates of a fully parametric model with a
quadratic scale effect: f(x)5g1 x1g2 x 2 . Estimates of b are also obtained using the first order and
2
optimal second order differencing estimators. Using s diff from the second order optimal differencing

Fig. 1. Returns to scale in electricity distribution.

A. Yatchew / Economics Letters 57 (1997) 135 – 143

139

procedure, the nonparametric test of the significance of scale yields a value of 3.28, indicating a
significant scale effect. A nonparametric test of specification against a quadratic null yields a value for
V of 0.056 in which case the quadratic model would appear to be adequate in this case.
Thus far our results demonstrate that by differencing, we can perform inference on b as if there
were no nonparametric component f in the model to begin with.2 But having calculated bˆ diff , we can
then proceed to apply a variety of nonparametric techniques to estimate f as if b were known. Such a
modular approach simplifies implementation because it permits the use of existing software designed
to analyze pure nonparametric models.
More specifically, suppose we construct the data ( y t 2z t bˆ diff ,x t ) t51, . . . T to which we apply
standard kernel estimation methods. Then consistency, optimal rate of convergence results and the
construction of confidence intervals for f(?) remain valid because bˆ diff converges to b sufficiently
| f(x t )1 ´t leaves
quickly so that the approximation given by y t 2z t bˆ diff 5z t ( b 2 bˆ diff )1f(x t )1 ´t 5
asymptotic arguments unaffected. Fig. 1 provides kernel and spline estimates of the nonparametric
scale effect f. (Note that even if we are ultimately interested in nonparametric estimates of f,
differencing avoids the first round of nonparametric regressions associated with Robinson’s approach.)
As a second example we use housing market data (see Fig. 2). In this case the nonparametric
variable is a 2-dimensional location effect. Parametric variables for which hedonic prices are
estimated include lot area, presence of a garage or fireplace and number of bedrooms. Again having
estimated the parametric effects, we use conventional methods to estimate the nonparametric location
effect.

Fig. 2. Hedonic prices of housing attributes.

2

This is the essence underlying (A.4) as an approximation to (A.1) in the Appendix.

A. Yatchew / Economics Letters 57 (1997) 135 – 143

140

5. Extensions and conclusions
The linear portion in the partial linear model could instead be replaced by a more general
parametric specification, i.e., y5q(z, b )1f(x)1 ´ where q is a known function. With first order
differencing one would perform a nonlinear regression of y t 2y t 21 on q(z t , b )2q(z t21 , b ). If the data
are possibly heteroscedastic we may use the results developed by White (1985) which provide
heteroscedasticity consistent standard errors. For example, using the approximation of Appendix Eq.
]
(A.4) and first order differencing coefficients [1,21] /Œ2 we have:
1
|]
Var( bˆ diff ) 5
T
1
2
] S E[(´t 2 ´t21 )2 (u t 2 u t21 )2 ] 1 ] S E[(´t 2 ´t 21 )(u t 2 u t 21 )(´t 21 2 ´t22 )(u t21 2 u t22 )]
T
T
]]]]]]]]]]]]]]]]]]]]]]]]]]]
2
1
] S E[(u t 2 u t 21 )2 ]
T

S

D

in view of which a natural estimator for the variance of bˆ diff is given by:
1
2
S (Dy t 2 Dz t bˆ diff )2 (Dz t )2 1 ] S (Dy t 2 Dz t bˆ diff )Dz t (Dy t 21 2 Dz t21 bˆ diff )Dz t 21
1 ]
T
T
] ]]]]]]]]]]]]]]]]]]]]]]]]
2
T
1
] S (Dz t )2
T

S

D

The estimator is consistent under general conditions (see White (White, 1985, Chapter 6)).3 Figs. 1
and 2 contain heteroscedasticity consistent standard errors.

Acknowledgements
The author is grateful to Don Andrews, Zvi Griliches and Angelo Melino for their thoughtful
comments.

Appendix A
Lemma. Suppose x has support the unit cube in R k with density bounded away from 0. Select d
positive and arbitrarily close to 0. Cover the unit cube with sub-cubes of volume 1 /T 12d each with
sides 1 /T ( 12d ) / k . Within each sub-cube construct a path using the nearest neighbour algorithm.
3

If Z is a vector then the heteroscedasticity consistent covariance matrix estimator becomes:

S]T1 SDz Dz9D S]T1 S(Dy 2 Dz bˆ
S]T1 SDz Dz9D
21

1
]
T

t

t

21

t

t

t

t

diff

2
)2 Dz t Dz 9t 1 ] S (Dy t 2 Dz t bˆ diff )(Dy t 21 2 Dz t 21 bˆ diff )Dz t Dz t921
T

D

A. Yatchew / Economics Letters 57 (1997) 135 – 143

141

Following this, knit the paths together by joining endpoints in contiguous sub-cubes to obtain a
reordering of all the data. Then for any d .0, 1 /T o ix t 2x t 21 i 2 5OP (T 22(12d ) / k ). j
Proof. There are T 12d sub-cubes and note that the probability of an empty sub-cube goes to zero as T
increases. The maximum segment within each sub-cube is proportional to 1 /T (12d ) / k as is the
maximum segment between points in contiguous sub-cubes from which the result follows immediately. j
| OP (T 22 / k ),
Comment. Since d may be chosen arbitrarily close to 0 we write 1 /T o t ix t 2x t 21 i 2 5
| OP (T 22 / k ).
Note also that for fixed s, 1 /T o t ix t 2x t 2s i 2 5
Proof of Proposition 1. Consider the case where the nonparametric variable x is a vector and the
parametric variable z is a scalar. Write z5g(x)1u and note that

O SO

DSO

O

O

D

m
m
m
m
1
T 1/2 ]
d j f(x t 2j ) 1 d j ´t 2j
d j g(x t2j ) 1 d j u t 2j
T t j50
j50
j 50
j 50
1/2
T ( bˆ diff 2 b ) 5 ]]]]]]]]]]]]]]]]]]]]
m
m
2
1
]
d g(x ) 1 d u
T t j50 j t 2j j50 j t2j

O SO

D

O

(A.1)

Next use the Lemma above and the Cauchy-Schwartz inequality to obtain:

O SO d f(x )D 5O (d ( f(x ) 2 f(x
m

t

2

t 2j

j

1

t

j50

t

t21

2
| OP (T 12(2 / k ))
)) 1 ? ? ? 1 d m ( f(x t ) 2 f(x t 2m ))) 5

(A.2)
In the middle expression we have substituted d 0 5 2d 1 2d 2 2 ? ? ? 2d m . Then
1
T 1/2 ]
T

UO SO

DSO d g(x )DU
1
] SO SO d f(x )D D SO SO d g(x )D D
T
m

t

m

d j f(x t 2j )

j

j50

m

# T 1/2

2

j

t

t2j

j50

t2j

m

1/2

j

t

j50

2

t2j

1/2

| OP (T ( 1 / 2 )2( 2 / k))
5

j50

which converges to 0 so long as k, the dimension of x does not exceed 3. Note also that:

S

1
Var T 1 / 2 ]
T

O u O d f(x )D 5 ]T1 s O O (d f(x
m

t

t

m

j

j 50

t 2j

2
u

t

j

t 2j

| OP (T 2( 2 / k))
))2 5

(A.3)

j 50

Results similar to (A.3) also hold for other terms in (A.1) which involve u or ´ and differenced values
of f or g. Thus applying the last two results, (A.1) may be approximated by:

O SO DSO
O SO D

D

m
m
1
]
T
d´
du
T t j50 j t2j j50 j t2j
1/2 ˆ
|
]]]]]]]]]]]
T ( bdiff 2 b ) 5
m
2
1
]
d j u t2j
T t j50
1/2

(A.4)

A. Yatchew / Economics Letters 57 (1997) 135 – 143

142

The denominator converges to s 2u . Define d 5o mk 51 (o j d j d j 1k )2 then the variance of the numerator of
(A.4) equals:

F

O SO d d D G 5 s s [1 1 2d ]
m

s 2´ s 2u 1 1 2

2

j j 1k

k 51

2
´

2
u

(A.5)

j

To minimize the variance of bˆ diff we want to minimize the value of d. Using time series techniques,
Hall, Kay and Titterington (Hall et al., 1990) demonstrate that if the d j are selected to minimize d,
then o j d j d j 1k 5 21 / 2m, k51, . . . ,m in which case d 51 / 4m and:
2
s 2´ s 2u [1 1 2d ]
1 s´
| ]]]]]
]
]
Var(T 1 / 2 ( bˆ diff 2 b )) 5
5
1
1
2m s u2
(s u2 )2

F

G

Asymptotic normality follows using finitely dependent central limit theorems. The case where z is a
vector follows by similar methods. Consistent estimation of s 2´ and o u follows from application of
laws of large numbers. . . .
Proof of Proposition 2. In large samples,

S O

T 1/2

O

D

SO D O

O

1
1
| T 1/2 ]
T 1 / 2 (s 2res 2 s 2diff ) 5
´ 2t 2 ] (d 0 ´t 1 d 1 ´t21 1 ? ? ? 1 d m ´ 2t 2m 5 2
T
T
m21
m22
2
2
2
d j d j 11 ]
´t ´t21 1
d j d j 12 ]
´t ´t22 1 ? ? ? 1 d 0 d m ] ´t ´t2m 5 1
T
T
T
j50
j50

SS O D O
S O´´

T 1/2 1
]] ]
m
T

t t 21

1
1]
T

O´´

t t 22

1
1 ? ? ? 1]
T

D

O´´ D
t t 2m

which is asymptotically N (0, s 4´ /m). To obtain the third line we use the condition o 0m d j2 51. To
obtain the fourth, we again use o j d j d j 1k 5 21 / 2m, k51, . . . ,m. j

References
Ahn, H., Powell, J., 1993. Semiparametric estimation of censored selection models with a nonparametric selection
mechanism. Journal of Econometrics 58, 2–29.
Buckley, M.J., Eagleson, G.K., Silverman, B.W., 1988. The estimation of residual variance in nonparametric regression.
Biometrika 75, 189–199.
Gasser, T., Sroka, L., Jennen-Steinmetz, C., 1986. Residual variance and residual pattern in nonlinear regression. Biometrika
73, 625–633.
Hall, P., Kay, J.W., Titterington, D.M., 1990. Asymptotically optimal difference-based estimation of variance in nonparametric regression. Biometrika 77, 521–528.
Hall, P., Kay, J.W., Titterington, D.M., 1991. On estimation of noise variance in two-dimensional signal processing.
Advances in Applied Probability 23, 476–495.
¨
¨
Muller,
H.G., Stadtmuller,
U., 1988. Detecting dependencies in smooth regression models. Biometrika 75, 639–650.
Powell, J., 1987. Semiparametric Estimation of Bivariate Latent Variable Models. Working paper 8704, Social Systems
Research Institute of Wisconsin, University of Wisconsin, Madison.
Rice, J., 1984. Bandwidth choice for nonparametric regression. Annals of Statistics 12, 1215–1230.
Robinson, P.M., 1988. Root-N consistent semiparametric regression. Econometrica 56, 931–954.

A. Yatchew / Economics Letters 57 (1997) 135 – 143

143

White, H., 1985. Asymptotic Theory for Econometricians. Academic Press, New York.
Yatchew, A.J., 1988. Some Tests of Nonparametric Regressions Models, Dynamic Econometric Modelling. In: Barnett, W.,
Berndt, E., White, H. (Eds.), Proceedings of the Third International Symposium in Economic Theory and Econometrics.
Cambridge University Press, pp. 121–135.

