Journal of the American Statistical Association

ISSN: 0162-1459 (Print) 1537-274X (Online) Journal homepage: https://www.tandfonline.com/loi/uasa20

Estimating Individualized Treatment Rules Using
Outcome Weighted Learning
Yingqi Zhao , Donglin Zeng , A. John Rush & Michael R. Kosorok
To cite this article: Yingqi Zhao , Donglin Zeng , A. John Rush & Michael R. Kosorok (2012)
Estimating Individualized Treatment Rules Using Outcome Weighted Learning, Journal of the
American Statistical Association, 107:499, 1106-1118, DOI: 10.1080/01621459.2012.695674
To link to this article: https://doi.org/10.1080/01621459.2012.695674

Accepted author version posted online: 04
Jun 2012.
Published online: 08 Oct 2012.
Submit your article to this journal

Article views: 2538

View related articles

Citing articles: 162 View citing articles

Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=uasa20

Estimating Individualized Treatment Rules Using
Outcome Weighted Learning
Yingqi ZHAO, Donglin ZENG, A. John RUSH, and Michael R. KOSOROK
There is increasing interest in discovering individualized treatment rules (ITRs) for patients who have heterogeneous responses to treatment.
In particular, one aims to find an optimal ITR that is a deterministic function of patient-specific characteristics maximizing expected clinical
outcome. In this article, we first show that estimating such an optimal treatment rule is equivalent to a classification problem where each
subject is weighted proportional to his or her clinical outcome. We then propose an outcome weighted learning approach based on the
support vector machine framework. We show that the resulting estimator of the treatment rule is consistent. We further obtain a finite sample
bound for the difference between the expected outcome using the estimated ITR and that of the optimal treatment rule. The performance of
the proposed approach is demonstrated via simulation studies and an analysis of chronic depression data.
KEY WORDS:

Bayes classifier; Cross-validation; Dynamic treatment regime; Individualized treatment rule; Risk bound; RKHS; Weighted
support vector machine.

1. INTRODUCTION
In many different diseases, patients can show significant heterogeneity in response to treatments. In some cases, a drug that
works for a majority of individuals may not work for a subset of
patients with certain characteristics. For example, molecularly
targeted cancer drugs are only effective for patients with tumors
expressing targets (GruÃànwald and Hidalgo 2003; Buzdar 2009),
and significant heterogeneity exists in responses among patients
with different levels of psychiatric symptoms (Piper et al. 1995;
Crits-Christoph et al. 1999). Thus, significant improvements in
public health could potentially result from judiciously treating
individuals based on his or her prognostic or genomic data rather
than a ‚Äúone size fits all‚Äù approach. Treatments and clinical trials
tailored for patients have enjoyed recent popularity in clinical
practice and medical research, and, in some cases, have provided
high quality recommendations accounting for individual heterogeneity (Sargent et al. 2005; Flume et al. 2007; Insel 2009).
These proposals have focused on smaller, specific, and welldefined subgroups, sought to provide guidance in clinical decision making based on individual differences, and have attempted
to achieve better risk minimization and benefit maximization.
One statistical approach for developing individual-adaptive
interventions is to classify subjects into different risk levels
estimated by a parametric or semiparametric regression model
using prognostic factors, and then to assign therapy according to
risk level (Eagle et al. 2004; Marlowe et al. 2007; Cai et al. 2010).
However, the parametric or semiparametric model assumptions
may not be valid due to the complexity of the disease mechanism and individual heterogeneity. Moreover, these approaches
require preknowledge in allocating the optimal treatment to each

Yingqi Zhao is Postdoctoral Fellow, Department of Biostatistics, University
of North Carolina at Chapel Hill, NC 27599 (E-mail: yqzhao@live.unc.edu).
Donglin Zeng is Professor, Department of Biostatistics, University of North
Carolina at Chapel Hill, NC 27599 (E-mail: dzeng@email.unc.edu). A. John
Rush is Professor and Vice-Dean, Office of Clinical Sciences, Duke-National
University of Singapore Graduate Medical School, Singapore 169857 (E-mail:
john.rush@duke-nus.edu.sg). Michael R. Kosorok is Professor and Chair, Department of Biostatistics, and Professor, Department of Statistics and Operations
Research, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599
(E-mail: kosorok@unc.edu). The first, second, and fourth authors were partially
funded by NCI Grant P01 CA142538. The authors thank the editor, associate
editor, and referees for their helpful comments.

risk category. There is also a significant literature examining discovery and development of personalized treatment relying on
predicting patient responses to optional regimens (Rosenwald
et al. 2002; van‚Äôt Veer and Bernards 2008), where the optimal
decision leads to the best predicted outcome. One recent article
by Qian and Murphy (2011) applies a two-step procedure that
first estimates a conditional mean for the response and then estimates the rule maximizing this conditional mean. A rich linear
model is used to sufficiently approximate the conditional mean,
with the estimated rule derived via l1 penalized least squares
(l1 -PLS). The method includes variable selection to facilitate
parsimony and ease of interpretation. The conditional mean approximation requires estimating a prediction model of the relationship between pretreatment prognostic variables, treatments,
and clinical outcome using a prediction model. Reduction in the
mean response is related to the excess prediction error, through
which an upper bound can be constructed for the mean reduction of the associated treatment rule. However, by inverting the
model to find the optimal treatment rule, this method emphasizes prediction accuracy of the clinical response model instead
of directly optimizing the decision rule.
In this article, we proposed a new method for solving this
problem that circumvents the need for conditional mean modeling followed by inversion by directly estimating the decision
rule that maximizes clinical response. Specifically, we demonstrate that the optimal treatment rule can be estimated within a
weighted classification framework, where the weights are determined from the clinical outcomes. We then alleviate the computational problem by substituting the 0-1 loss in the classification
with a convex surrogate loss as is done with the support vector
machine (SVM) via the hinge loss (Cortes and Vapnik 1995).
The directness of this outcome weighted learning (OWL) approach enables us to better select targeted therapy while making
full use of available information.
The remainder of the article is organized as follows. In
Section 2, we provide the mathematical concepts and framework
for individualized treatment rules (ITRs), and then formulate

1106

¬© 2012 American Statistical Association
Journal of the American Statistical Association
September 2012, Vol. 107, No. 499, Theory and Methods
DOI: 10.1080/01621459.2012.695674

Zhao et al.: Estimating Individualized Treatment Rules Using Outcome Weighted Learning

1107

the problem as OWL. The proposed weighted SVM approach
for constructing the optimal ITR is then developed in detail. In
Section 3, consistency and risk-bound results are established for
the estimated rules. Faster convergence rates can be achieved
with additional marginal assumptions on the data generating
distribution. We present simulation studies to evaluate performance of the proposed method in Section 4. The method is then
illustrated on the Nefazodone-CBASP data (Keller et al. 2000)
in Section 5. In Section 6, we discuss future work. The proofs
of theoretical results are given in the Appendix.

optimal ITR, and are likely to produce a suboptimal ITR if the
model for R given (X, A) is overfitted. As an alternative, we
propose a nonparametric approach that directly maximizes the
value function based on an OWL method.
To illustrate our approach, we first notice that searching for
the optimal ITR, D‚àó , which maximizes V(D), is equivalent to
finding D‚àó that minimizes

2. METHODOLOGY

The latter can be viewed as a weighted classification error, for
which we want to classify A using X but we also weigh each
misclassification event by R/(AœÄ + (1 ‚àí A)/2). Hence, using
the observed data, we approximate the weighted classification
error by

2.1 Individualized Treatment Rule (ITR)
We assume the data are collected from a two-arm randomized trial. That is, treatment assignments, denoted by
A ‚àà A = {‚àí1, 1}, are independent of any patient‚Äôs prognostic variables, which are denoted as a d-dimensional vector
X = (X1 , . . . , Xd )T ‚àà X . We let R be the observed clinical outcome, also called the ‚Äúreward,‚Äù and assume that R is bounded,
with larger values of R being more desirable. Thus, an ITR is
a map from the space of prognostic variables, X , to the space
of treatments, A. An optimal ITR is a rule that maximizes the
expected reward if implemented.
Mathematically, we can quantify the optimal ITR in terms
of the relationship among (X, A, R). To see this, denote the
distribution of (X, A, R) by P and expectation with respect
to the P is denoted by E. For any given ITR D, we let P D
denote the distribution of (X, A, R) given that A = D(X), that
is, the treatments are chosen according to the rule D; correspondingly, the expectation with respect to P D is denoted by E D . Then
under the assumption that P (A = a) > 0 for a = 1 and ‚àí1, it
is clear that P D is absolutely continuous with respect to P and
dP D /dP = I (a = D(x))/P (A = a), where I (¬∑) is the indicator
function. Thus, the expected reward under the ITR D is given as




I (A = D(X))
dP D
dP = E
R ,
E D (R) = RdP D = R
dP
AœÄ + (1 ‚àí A)/2
where œÄ = P (A = 1). This expectation is called the value function associated with D and is denoted by V(D). Consequently,
an optimal ITR, D‚àó , is a rule that maximizes V(D), that is,


I (A = D(X))
R .
D‚àó ‚àà argmax E
AœÄ + (1 ‚àí A)/2
D
Note that D‚àó does not change if R is replaced by R + c for any
constant c. Thus, without loss of generality, we assume that R
is nonnegative in the following.
2.2 Outcome Weighted Learning (OWL) for Estimating
Optimal ITR
Assume that we observe independent and identically distributed (iid) data (Xi , Ai , Ri ), i = 1, . . . , n from the two-arm
randomized trial described above. Previous approaches to
estimating optimal ITR first estimate E(R|X, A), using the observed data via parametric or semiparametric models, and then
estimate the optimal decision rule by comparing the predicted
value E(R|X, A = 1) versus E(R|X, A = ‚àí1) (Robins 2004;
Moodie, Platt, and Kramer 2009; Qian and Murphy 2011).
As discussed before, these approaches indirectly estimate the

E[R|A = 1] + E[R|A = ‚àí1] ‚àí V(D)


I (A = D(X))
= E
R .
AœÄ + (1 ‚àí A)/2

n‚àí1

n

i=1

Ri
I (Ai = D(Xi ))
Ai œÄ + (1 ‚àí Ai )/2

and seek to minimize this expression to estimate D‚àó . Since
D(x) can always be represented as sign(f (x)), for some decision
function f , minimizing the above expression for D‚àó is equivalent
to minimizing
n‚àí1

n

i=1

Ri
I (Ai = sign(f (Xi )))
Ai œÄ + (1 ‚àí Ai )/2

(2.1)

to obtain the optimal f ‚àó , and then setting D‚àó (x) = sign(f ‚àó (x)).
The above minimization also has the following interpretation.
That is, we intend to find a decision rule that assigns treatments
to each subject only based on their prognostic information. For
subjects observed to have large rewards, this rule is apt to recommend the same treatment assignments that the subjects have
actually received; however, for subjects with small rewards, the
rule is more likely to give the opposite treatment assignments
to what they received. In other words, if we stratify subjects
into different strata based on the rewards, we will expect that
the optimal ITR misclassifies less subjects in the high reward
stratum as compared to the low reward stratum.
In the machine learning literature, Equation (2.1) can
be viewed as a weighted summation of 0-1 loss. It is well
known that minimizing Equation (2.1) is difficult due to the
discontinuity and nonconvexity of 0-1 loss. To alleviate this
difficulty, one common approach is to find a convex surrogate
loss for the 0-1 loss in Equation (2.1) and develop a tractable
estimation procedure (Lugosi and Vayatis 2004; Zhang 2004;
Steinwart 2005). Among many choices of surrogate loss, one
of the most popular is the hinge loss used in the context of
the SVM (Cortes and Vapnik 1995), which we will adopt in
this article. Furthermore, we penalize the complexity of the
decision function to avoid overfitting. In other words, instead
of minimizing Equation (2.1), we aim to minimize
‚àí1

n

n

i=1

Ri
(1 ‚àí Ai f (Xi )))+ + Œªn f 2 ,
Ai œÄ + (1 ‚àí Ai )/2
(2.2)

where x + = max(x, 0) and f  is some norm for f . In this
way, we cast the problem of estimating the optimal ITR into a
weighted classification problem using SVM techniques.

1108

Journal of the American Statistical Association, September 2012

2.3 Linear Decision Rule for Optimal ITR
Suppose that the decision function f (x) minimizing
Equation (2.2) is a linear function of x, that is, f (x) = Œ≤, x +
Œ≤0 , where ¬∑, ¬∑ denotes the inner product in Euclidean space.
Then the corresponding ITR will assign a subject with prognostic value X into treatment 1 if Œ≤, X + Œ≤0 > 0 and ‚Äì1 otherwise.
In Equation (2.2), we define f  as the Euclidean norm of Œ≤.
Following the usual SVM, we introduce a slack variable Œæi for
subject i to allow a small portion of wrong classification. Denote
C > 0 as the classifier margin. Then minimizing Equation (2.2)
can be rewritten as
C subject to Ai (Œ≤, Xi  + Œ≤0 )

max

Œ≤,Œ≤0 ,Œ≤=1

‚â• C(1 ‚àí Œæi ), Œæi ‚â• 0,

 Ri
œÄi

Œæi < s,

where œÄi = œÄ I (Ai = 1) + (1 ‚àí œÄ )I (Ai = ‚àí1) and s is a constant depending on Œªn . This is equivalent to
1
min Œ≤2 subject to Ai (Œ≤, Xi  + Œ≤0 )
2
 Ri
‚â• (1 ‚àí Œæi ), Œæi ‚â• 0,
Œæi < s,
œÄi
that is,
 Ri
1
min Œ≤2 + Œ∫
Œæi
2
œÄi
i=1
n

subject to Ai (Œ≤, Xi  + Œ≤0 )

estimated decision rule is determined by the support vectors
with Œ±ÃÇi > 0.
2.4 Nonlinear Decision Rule for Optimal ITR
The previous section targets a linear boundary of prognostic
variables. This may not be practically useful since the dimension
of the prognostic variables can be quite high and complicated
relationships may be involved between the desired treatments
and these variables. However, we can easily generalize the previous approach to obtain a nonlinear decision rule for obtaining
the optimal ITR.
We let k : X √ó X ‚Üí R, called a kernel function, be continuous, symmetric, and positive semidefinite. Given a real-valued
kernel function k, we can associate with it a reproducing kernel
Hilbert space (RKHS) Hk , which is the completion of the linear
span of all functions {k(¬∑, x), x ‚àà X }. The norm in Hk , denoted
by  ¬∑ k , is induced by the following inner product,
f, gk =

‚àí

n


for f (¬∑) = ni=1 Œ±i k(¬∑, xi ) and g(¬∑) = m
j =1 Œ≤j k(¬∑, xj ).
We note that our decision function f (x) is from Hk equipped
with norm  ¬∑ k . Thus, since any function in Hk takes the form
m
i=1 Œ±i k(¬∑, xi ), it can be shown that the optimal decision function is given by
n


n
 

 
Œ±i Ai XiT Œ≤ + Œ≤0 ‚àí (1 ‚àí Œæi ) ‚àí
¬µi Œæi ,

i=1

max
Œ±

n

i=1

1 
Œ±i Œ±j Ai Aj Xi , Xj 
2 i=1 j =1
n

Œ±i ‚àí

Œ±ÃÇi Ai k(X, Xi ) + Œ≤ÃÇ0 ,

i=1

where (Œ±ÃÇ1 , . . . , Œ±ÃÇn ) solves
max
Œ±

n

i=1

1 
Œ±i Œ±j Ai Aj k(Xi , Xj )
2 i=1 j =1
n

Œ±i ‚àí

n

subject to 0 ‚â§ Œ±i ‚â§ Œ∫Ri /œÄi , i = 1, . . . , n, and ni=1 Œ±i Ai = 0.
We note that if we choose k(x, y) = x, y, then the obtained
rule reduces to the previous linear rule.
3. THEORETICAL RESULTS

i=1

with Œ±i ‚â• 0, ¬µi ‚â• 0. Taking derivatives with respect to (Œ≤, Œ≤0 )
and Œæi , we have Œ≤ = ni=1 Œ±i Ai Xi , 0 = ni=1 Œ±i Ai and Œ±i =
Œ∫Ri /œÄi ‚àí ¬µi . Plugging these equations into the Lagrange function, we obtain the dual problem

Œ±i Œ≤j k(xi , xj ),

i=1 j =1

‚â• (1 ‚àí Œæi ), Œæi ‚â• 0,

where Œ∫ > 0 is a tuning parameter and Ri /œÄi is the weight for
the ith point. We observe that the main difference compared
to standard SVM is that we weigh each slack variable Œæi with
Ri /œÄi .
After introducing Lagrange multipliers, the Lagrange function becomes
n

Ri
1
Œ≤2 + Œ∫
Œæi
2
œÄi
i=1

n 
m


In this section, we establish consistency of the optimal ITR
estimated using OWL. We further obtain a risk bound for the
estimated ITR and show how the bound can be improved for
certain specific, realistic situations.

n

n
i=1

subject to 0 ‚â§ Œ±i ‚â§ Œ∫Ri /œÄi , i = 1, . . . , n, and
Œ±i Ai = 0.
Quadratic programming algorithms from many widely available software packages can be used to solve this dual problem.
Finally, we obtain that

Œ±ÃÇi Ai Xi ,
Œ≤ÃÇ =
Œ±ÃÇi >0

and Œ≤ÃÇ0 can be solved using the margin points (0 < Œ±ÃÇi , ŒæÀÜi =
0) subject to the Karush-Kuhn-Tucker conditions (Hastie,
Tibshirani, and Friedman 2009, p. 421). The decision rule is
given by sign{Œ≤ÃÇ, X + Œ≤ÃÇ0 }. Similar to the traditional SVM, the

3.1 Notation
For any ITR D(x) = sign(f (x)) associated with decision
function f (x), we define


R
I (A = sign(f (X)))
R( f ) = E
AœÄ + (1 ‚àí A)/2
and the minimal risk (called Bayes risk in the learning literature)
as R‚àó = inf f {R( f )|f : X ‚Üí R}. Thus, for the optimal ITR
D‚àó (x) = sign(f ‚àó (x)) (called the Bayes classifier in the learning
literature), R‚àó = R(f ‚àó ). In terms of the value function, we note
that V(D‚àó ) ‚àí V(D) = R( f ) ‚àí R(f ‚àó ).
In the OWL approach, we substitute 0-1 loss I (A = sign(f
(X))) by a surrogate loss, œÜ(Af (X)), where œÜ(t) = (1 ‚àí t)+ .

Zhao et al.: Estimating Individualized Treatment Rules Using Outcome Weighted Learning

3.4 Consistency and Risk Bounds

Thus, we define the œÜ-risk


R
RœÜ ( f ) = E
œÜ(Af (X)) ,
AœÄ + (1 ‚àí A)/2
and, similarly, the minimal œÜ-risk as R‚àóœÜ = inf f {RœÜ ( f )|f :
X ‚Üí R}.
Recall that the estimated optimal ITR is given by sign(fÀÜn (X)),
where
1  Ri
{1 ‚àí Ai f (Xi )}+ + Œªn f 2k .
fÀÜn = argmin
n i=1 œÄi
f ‚ààHk
n

(3.1)
3.2 Fisher Consistency
We establish Fisher consistency of the decision function based
on surrogate loss œÜ(t). Specifically, the following result holds:

The purpose of this section is to establish the consistency of fÀÜn , and, moreover, to derive the convergence rate of
R(fÀÜn ) ‚àí R‚àó .
First, the following theorem shows that the risk due to fÀÜn does
converge to R‚àó , and, equivalently, the value of fÀÜn converges
to the optimal value function. Results on consistency of the
SVM have been shown in current literature (e.g., Zhang 2004).
Here we apply the empirical process techniques to show that the
proposed OWL estimator is consistent. The proof of the theorem
is deferred to the Appendix.
Theorem 3.3. Assume that we choose a sequence Œªn > 0
such that Œªn ‚Üí 0 and Œªn n ‚Üí ‚àû. Then for all distributions P,
we have that in probability,


ÀÜ
lim RœÜ (fn ) ‚àí inf RœÜ ( f ) = 0,
n‚Üí‚àû

Proposition 3.1. For any measurable function f , if fÀú minimizes RœÜ ( f ), then D‚àó (x) = sign(fÀú(x)).
Proof. First, we note
‚àó

D (x) = sign {E[R|X = x, A = 1] ‚àí E[R|X = x, A = ‚àí1]} .
Next, for each x ‚àà X ,


œÜ(Af (X))
X=x
E R
AœÄ + (1 ‚àí A)/2
= E(R|A = 1, X = x)(1 ‚àí f (x))
+ E(R|A = ‚àí1, X = x)(1 + f (x))
= ((E(R|A = ‚àí1, X = x) ‚àí E(R|A = 1, X = x))f (x)
+ E(R|A = ‚àí1, X = x) + E(R|A = 1, X = x)).

Therefore, fÀú(x), which minimizes RœÜ ( f ), should be positive
if E(R|A = 1, X = x) > E(R|A = ‚àí1, X = x) and negative
if E(R|A = 1, X = x) < E(R|A = ‚àí1, X = x). That is, fÀú(x)

has the same sign as D‚àó (x). The result holds.
The proposition is analogous to results for SVM (e.g., Lin
2002). This theorem justifies the validity of using œÜ(t) as the
surrogate loss in OWL.
3.3 Excess Risk for R( f ) and RœÜ ( f )
The following result shows that for any decision function f ,
the excess risk of f under 0-1 loss is no larger than the excess
risk of f under the hinge loss. Thus, the loss of the value function
due to the ITR associated with f can be bounded by the excess
risk under the hinge loss. The proof of the theorem can be found
in the Appendix.
Theorem 3.2. For any measurable f : X ‚Üí R and any probability distribution for (X, A, R),
R( f ) ‚àí R‚àó ‚â§ RœÜ ( f ) ‚àí R‚àóœÜ .

1109

(3.2)

The proof follows the general arguments by Bartlett, Jordan,
and McAuliffe (2006), in which they bound the risk associated
with 0-1 loss in terms of the risk from surrogate loss, using a
convexified variational transform of the surrogate loss. In our
proof, we extend this concept to our setting by establishing the
validity of a weighted version of such a transformation.

f ‚ààHÃÑk

where HÃÑk denotes the closure of Hk . Thus, if f ‚àó belongs to the
closure of lim supn‚Üí‚àû Hk , where Hk can potentially depend on
n, we have limn‚Üí‚àû RœÜ (fÀÜn ) = R‚àóœÜ in probability. It then follows
that limn‚Üí‚àû R(fÀÜn ) = R‚àó in probability.
One special situation where f ‚àó belongs to the limit space of
Hk is when we choose Hk to be an RKHS with Gaussian kernel
and let the kernel bandwidth decrease to zero as n ‚Üí ‚àû. This
will be shown in Theorem 3.4 below.
We now wish to derive the convergence rate of R(fÀÜn ) ‚àí R‚àó
under certain regularity conditions on the distribution P. Specifically, we need the following ‚Äúgeometric noise‚Äù assumption for
P (Steinwart and Scovel 2007): Let
Œ∑(x) =

E[R|X = x, A = 1] ‚àí E[R|X = x, A = ‚àí1]
+ 1/2,
E[R|X = x, A = 1] + E[R|X = x, A = ‚àí1]
(3.3)

then 2Œ∑(x) ‚àí 1 is the decision boundary for the optimal ITR.
We further define X + = {x ‚àà X : 2Œ∑(x) ‚àí 1 > 0}, and X ‚àí =
{x ‚àà X : 2Œ∑(x) ‚àí 1 < 0}. A distance function to the boundary
between X + and X ‚àí is (x) = dÃÉ(x, X + ) if x ‚àà X ‚àí , (x) =
dÃÉ(x, X ‚àí ) if x ‚àà X + , and (x) = 0 otherwise, where dÃÉ(x, O)
denotes the distance of x to a set O with respect to the Euclidean
norm. Then the distribution P is said to have geometric noise
exponent 0 < q < ‚àû, if there exists a constant C > 0 such that



(X)2
|2Œ∑(X) ‚àí 1| ‚â§ Ct qd/2 , t > 0. (3.4)
E exp ‚àí
t
In some sense, this geometric noise exponent describes the behavior of the distribution in a neighborhood of the decision
boundary. It is affected by how fast the density of the distance (X) decays along the boundary. For example, assume
the boundary is linear, in which case (x) = |2Œ∑(x) ‚àí 1|. If for
the density of (X), defined as f (u), we have f (u) ‚àº up when
u is close to 0, then we can show q = (p + 2)/d. Larger p corresponds to a faster decaying rate of the density, resulting in
a larger q accordingly. Another example is distinctly separable
data, that is, when |2Œ∑(x) ‚àí 1| > Œ¥ > 0, for some constant Œ¥,
and Œ∑ is continuous, q can be arbitrarily large.
In addition to this specific assumption for P, we also restrict the choice of RKHS to the space associated with Gaussian

1110

Journal of the American Statistical Association, September 2012

Radial Basis Function (RBF) kernels, that is,


k(x, x ) = exp ‚àí œÉn2 x ‚àí x 2 , x, x ‚àà X ,
where œÉn > 0 is a parameter varying with n. The tuning parameter œÉn is related to approximation properties of Gaussian RBF
kernels. When œÉn goes large, only observations in the small
neighborhood contribute to the prediction, in which case we
obtain a nonlinear decision boundary or even nonparametric decision rule. If œÉn does not diverge, then points further away can
contribute to the prediction, resulting in a nearly linear boundary. One advantage of using the Gaussian kernel is that we can
determine the complexity of Hk in terms of capacity bounds
with respect to the empirical L2 -norm, defined as
 n
1/2
1
2
f ‚àí gL2 (Pn ) =
|f (Xi ) ‚àí g(Xi )|
.
n i=1
For any > 0, the covering number of functional class F with
respect to L2 (Pn ), N (F, , L2 (Pn )), is the smallest number of
L2 (Pn ) -balls needed to cover F, where an L2 (Pn ) -ball
around a function g ‚àà F is the set {f ‚àà F : f ‚àí gL2 (Pn ) < }.
Specifically, according to Theorem 2.1 in the article by
Steinwart and Scovel (2007), we have that for any > 0,
sup log N (BHk , , L2 (Pn )) ‚â§ cŒΩ,Œ¥,m œÉn(1‚àíŒΩ/2)(1+Œ¥)d

‚àíŒΩ

,

(3.5)

Pn

where BHk is the closed unit ball of Hk , and ŒΩ and Œ¥ are any
numbers satisfying 0 < ŒΩ ‚â§ 2 and Œ¥ > 0.
Under the above conditions, we obtain the following theorem:
Theorem 3.4. Let P be a distribution of (X, A, R) satisfying
condition (3.4) with noise exponent q > 0. Then for any Œ¥ >
0, 0 < ŒΩ < 2, there exists a constant C (depending on ŒΩ, Œ¥, d,
‚àí1/(q+1)d
,
and œÄ ) such that for all œÑ ‚â• 1 and œÉn = Œªn
P r ‚àó (R(fÀÜn ) ‚â§ R‚àó + ) ‚â• 1 ‚àí e‚àíœÑ ,
where P r ‚àó denotes the outer probability for possibly nonmeasurable sets, and


q
(2‚àíŒΩ)(1+Œ¥)
2
œÑ
2
q+1
‚àí 2+ŒΩ
+ (2+ŒΩ)(1+q)
‚àí 2+ŒΩ
.
n
+
+ Œªn
= C (Œªn )
nŒªn
The first two terms bound the stochastic error, which arises
from the variability inherent in a finite sample size and which
depends on the complexity of Hk in terms of covering numbers,
while the third term controls the approximation error due to
using Hk , which depends on both œÉn and the noise behavior
in the underlying distribution. We expect better approximation
properties when the RKHS is more complex, but, conversely,
we also expect larger stochastic variability. Using the above
expression, an optimal choice of Œªn that balances bias and
variance is given by
2(1+q)

Œªn = n‚àí (4+ŒΩ)q+2+(2‚àíŒΩ)(1+Œ¥) ,
so the optimal rate for the risk is


2q
R(fÀÜn ) ‚àí R‚àó = Op n‚àí (4+ŒΩ)q+2+(2‚àíŒΩ)(1+Œ¥) .
In particular, when data are well separated, q can be sufficiently
large and we can let (Œ¥, ŒΩ) be sufficiently small. Then the
convergence rate almost achieves the rate n‚àí1/2 . However,

if the marginal distribution of X has continuous density
along the boundary, it can be calculated that q = 2/d. In this
case, the convergence rate is approximately n‚àí2/(d+2) . Clearly,
the speed of convergence is slower with larger dimension of the
prognostic variable space.
To prove Theorem 3.4, we note that according to
Theorem 3.2, it suffices to prove the result for the excess œÜ
risk. We also use the fact that
RœÜ (fÀÜn ) ‚àí R‚àóœÜ = RœÜ (fÀÜn ) ‚àí inf RœÜ ( f ) + inf RœÜ ( f ) ‚àí R‚àóœÜ .
Hk

Hk

We will then bound the first difference on the right-hand side
using the empirical counterpart plus the stochastic variability
due to the finite sample approximation. The latter can be controlled using large deviation results from empirical processes
and some preliminary bound for fÀÜn k . The second difference
on the right-hand side will be bounded by using the approximation property of the RKHS and the geometric noise assumption
of the underlying distribution P. The proof is modified based on
the literature by Vert and Vert (2006) and Steinwart and Scovel
(2007), where the weights in the loss function are taken into
consideration. The details are provided in the Appendix.
3.5 Improved Rate with Data Completely Separated
In this section, we show that a faster convergence rate can be
obtained if the data are completely separated. We assume
(A1) ‚àÄx ‚àà X , |Œ∑(x) ‚àí 1/2| ‚â• Œ∑0 > 0, where Œ∑(x) is defined
in Equation (3.3), and Œ∑ is continuous.
(A2) ‚àÄx ‚àà X , min(Œ∑(x), 1 ‚àí Œ∑(x)) ‚â• Œ∑1 > 0.
Assumption (A1) can be referred as a ‚Äúlow noise‚Äù condition equivalent to |E(R|A = 1, X) ‚àí E(R|A = ‚àí1, X)| ‚â• Œ∑0 .
Thus, a jump of Œ∑(x) at the level of 1/2 requires a gap between
the rewards gained from treatment 1 and ‚àí1 on the same patient.
This assumption is an adaptation of the noise condition used in
classical SVM to obtain fast learning rates and it is essentially
equivalent to one of the conditions in the article by Blanchard,
Bousquet, and Massart (2008).
Theorem 3.5. Assume that (A1) and (A2) are satisfied. For
any ŒΩ ‚àà (0, 1) and q ‚àà (0, ‚àû), let Œªn = O(n‚àí1/(ŒΩ+1) ) and œÉn =
‚àí1/(q+1)d
. Then
Œªn


q
1
R(fÀÜn ) ‚àí R‚àó = Op n‚àí ŒΩ+1 q+1 .
We can let q go to ‚àû and ŒΩ go to zero, and this theorem shows that the convergence rate for R(fÀÜn ) ‚àí R(f ‚àó ) is almost n‚àí1 , a much faster rate compared to what was given in
Theorem 3.4. This result is similar to SVM results described in
the literature by Tsybakov (2004), Steinwart and Scovel (2007),
and Blanchard, Bousquet, and Massart (2008).
To prove Theorem 3.5, we can rewrite the minimization problem in Equation (3.1) as
1  Ri
{1 ‚àí Ai f (Xi )}+ + ŒªS 2 .
n i=1 œÄi
n

min+

S‚ààR

min

f :f k ‚â§S

Thus, the problem can be viewed in the model selection framework: a collection of models are balls in Hk , and for each model,
we solve the penalized empirical œÜ-risk minimization to obtain

Zhao et al.: Estimating Individualized Treatment Rules Using Outcome Weighted Learning

an estimator fÀÜn . We can use a result for model selection, presented in Theorem 4.3 in the article by Blanchard, Bousquet,
and Massart (2008), to choose the model that yields the minimal penalized empirical œÜ-risk among all the models. We need
to verify the conditions required for the theorem based on the
weighted hinge loss and the condition on the covering number
of functional class F with respect to L2 (Pn ), that is, condition
(3.5). Proof details are provided in the Appendix.

8
7
6
5

œÉn

4

4. SIMULATION STUDY
3

We have conducted extensive simulations to assess the smallsample performance of the proposed method. In these simulations, we generate 50-dimensional vectors of prognostic variables X1 , . . . , X50 , consisting of independent U [‚àí1, 1] variates.
The treatment A is generated from {‚àí1, 1} independently of X
with P (A = 1) = 1/2. The response R is normally distributed
with mean Q0 = 1 + 2X1 + X2 + 0.5X3 + T0 (X, A) and standard deviation 1, where T0 (X, A) reflects the interaction between treatment and prognostic variables and is chosen to vary
according to the following four different scenarios:
(1)
(2)
(3)
(4)

T0 (X, A) = 0.442(1 ‚àí X1 ‚àí X2)A.
T0 (X, A) = X2 ‚àí 0.25X12 ‚àí 1 A.

T0 (X, A) = 0.5 ‚àí X12 ‚àí X22 X12 + X22 ‚àí 0.3 A.
T0 (X, A) = 1 ‚àí X13 + exp(X32 + X5 + 0.6X6 ‚àí
(X7 + X8 )2 )A.

The decision boundaries in the first three scenarios are determined by X1 and X2 . Scenario 1 corresponds to a linear decision
boundary in truth, where the shape of the boundary in Scenario
2 is a parabola. The third is a ring example, where the patients
on the ring are assigned to one treatment, and another if inside
or outside the ring. The decision boundary in the fourth example
is fairly nonlinear in covariates, depending on covariates other
than X1 and X2 . For each scenario, we estimate the optimal ITR
by applying OWL. We use the Gaussian kernel in the weighted
SVM algorithm. There are two tuning parameters: Œªn , the
penalty parameter, and œÉn , the inverse bandwidth of the kernel.
Since Œªn plays a role in controlling the severity of the penalty on
the functions and œÉn determines the complexity of the function
class used, œÉn should be chosen adaptively from the data simultaneously with Œªn . To illustrate this, Figure 1 shows the contours of
the value function for the first scenario with different combinations of (Œªn , œÉn ) when n = 30. We can see that Œªn interacts with
œÉn , with larger Œªn generally coupled with smaller œÉn for equivalent value function levels. In our simulations, we apply a fivefold cross-validation procedure in which we search over a prespecified finite set of (Œªn , œÉn ) to select the pair maximizing the
average of the estimated values from the validation data. In case
of tied values for parameter pair choices, we first choose the set
of pairs with smallest Œªn and then select the one with largest œÉn .
Additionally, comparison is made among the following four
methods:
(1) The proposed OWL using Gaussian kernel (OWLGaussian).
(2) The proposed OWL using linear kernel (OWL-Linear).
(3) The l1 -PLS method developed by Qian and Murphy
(2011), which approximates E(R|X, A) using the ba-

1111

1.2

1.1

1.

1

2

2

1.1

1.2

1
1

1.1 1.2
1

2

1

3

1.1

4

Œªn

1.2
5

6

7

8

Figure 1. Contour plots of value function for Example 1 with Œªn ‚àà
(0, 10) and œÉn ‚àà (0, 10).

sis function set (1, X, A, XA) and applies the LASSO
method for variable selection.
(4) The ordinary least squares method (OLS), which estimates the conditional mean response using the same basis
function set as in Method 3 but without variable selection.
We consider the OWL with linear kernel (Method 2) mainly
to assess the impact of different kernels in the weighted SVM
algorithm. In this case, there is only one tuning parameter, Œªn ,
which can be chosen to maximize the value function in a crossvalidation procedure. The selection of the tuning parameters in
the l1 -PLS approach follows similarly. The last two approaches
estimate the optimal ITR using the sign of the difference
between the predicted E(R|X, A = 1) and the predicted
E(R|X, A = ‚àí1). In the comparisons, the performances of the
four methods are assessed by two criteria: the first criterion is
to evaluate the value function using the estimated optimal ITR
when applying to an independent and large validation data;
the second criterion is to evaluate the misclassification rates
of the estimated optimal ITR from the true optimal ITR using
the validation data. Specifically, a validation set with 10,000
observations is simulated to assess the performance of the
approaches. The estimated value function using any ITR D is
given by Pn‚àó [I (A = D(X))R/P (A)]/Pn‚àó [I (A = D(X))/P (A)]
(Murphy et al. 2001), where Pn‚àó denotes the empirical average
using the validation data and P (A) is the probability of being
assigned treatment A.
For each scenario, we vary sample sizes for training
datasets from 30 to 100, 200, 400, and 800, and repeat the
simulation 1000 times. The simulation results are presented in
Figures 2 and 3, where we report the mean square errors (MSE)
of both value functions and misclassification rates. Simulations
show there are no large differences in the performance if we
replace the Gaussian kernel with the linear kernel in the OWL.
However, there are examples presenting advantages of the Gaussian kernel, which suggests that under certain circumstances, it
is useful to have a flexible nonparametric estimation procedure

1112

Journal of the American Statistical Association, September 2012

Example 1
0.6
0.4
0.0

0.00

200

400

600

800

0

200

400

n

n

Example 3

Example 4

800

2.0

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

0.0

0.00

0.02

MSE

0.04

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

600

1.0

0

MSE

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

0.2

MSE

0.10

0.15

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

0.05

MSE

Example 2

0

200

400

600

800

0

200

n

400

600

800

n

Figure 2. MSE for value functions of individualized treatment rules.

200

400

600

0.15
0.10

800

0

200

400

n

n

Example 3

Example 4

800

0.4

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

0.0

0.0

0.1

MSE

0.2

0.3

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

600

0.2

0

MSE

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

0.00

0.2

MSE

0.4

OLS
l1‚àíPLS
OWL‚àíLinear
OWL‚àíGaussian

0.0

MSE

Example 2

0.05

0.6

Example 1

0

200

400

n

600

800

0

200

400

600

n

Figure 3. MSE for misclassification rates of individualized treatment rules.

800

Zhao et al.: Estimating Individualized Treatment Rules Using Outcome Weighted Learning

to identify the optimal ITR for the underlying nonparametric
structures. As demonstrated in Figures 2 and 3, the OWL with
either Gaussian kernel or linear kernel has better performance,
especially for small samples, than the other two methods, from
the points of view of producing larger value functions, smaller
misclassification rates, and lower variability of the value function estimates. Specifically, when the approximation models
used in the l1 -PLS and OLS are correct in the first scenario,
the competing methods perform well with large sample size;
however, the OWL still provides satisfactory results even if we
use a Gaussian kernel. When the optimal ITR is nonlinear in X
in the other scenarios, the OWL tends to give higher values and
smaller misclassification rates. OLS generally fails unless the
sample size is large enough since it encounters severe bias for
small sample sizes. This is because without variable selection
for OLS, there is insufficient data to fit an accurate model
with all 50 variables included. We also note that l1 -PLS has
comparatively larger MSE, resulting from high variance of the
method, which may be explained by the conflicting goals of
maximizing the value function and minimizing the prediction
error (Qian and Murphy 2011). Note that a richer class of basis
functions can be used for fitting the regression models. We have
tried a polynomial basis and a wavelet basis to see if they could
improve the performance. However, as a larger set of basis
functions enters the model, we need to take into account higher
dimensional interactions that do not necessarily yield better results. Also, we noted that higher variability is introduced with a
richer basis for the approximation space (results not shown).
Additional simulations are performed by generating binary
outcomes from a logit model. It turns out that the OWL procedures outperform a traditional logistic regression procedure
(results not shown). Finally, using empirical results, we also verify that the cross-validation procedure can indeed identify the
optimal pairs (Œªn , œÉn ) with the order desired by the theoretical
‚àí(q+1)d
. The numerical results indicate
results, that is, œÉn = Œªn
that log2 œÉn is linear in log2 Œªn and the ratio between the slopes
is close to the reciprocal ratio between the dimensions of the
covariate spaces.

5. DATA ANALYSIS
We apply the proposed method to analyze real data from
the Nefazodone-CBASP clinical trial (Keller et al. 2000).
The study randomized 681 outpatients with nonpsychotic
chronic major depressive disorder (MDD), in a 1:1:1 ratio to
either Nafazodone, Cognitive Behavioral-Analysis System of
Psychotherapy (CBASP), or the combination of Nefazodone
and CBASP. The score on the 24-item Hamilton Rating Scale
for Depression (HRSD) was the primary outcome, where higher
scores indicate more severe depression. After excluding some
patients with missing observations, we use a subset with 647
patients for analysis. Among them, 216, 220, and 211 patients
were assigned to Nafazodone, CBASP, and the combined
treatment group, respectively. Overall comparisons using t-tests
show that the combination treatment had significant advantages
over the other treatments with respect to HRSD scores obtained
at the end of the trial, while there are no significant differences
between the nefazodone group and the psychotherapy group.

1113

Table 1. Mean depression scores (the smaller, the better) from
cross-validation procedure with different methods

Nefazodone vs. CBASP
Combination vs. Nefazodone
Combination vs. CBASP

OLS

l1 -PLS

OWL

15.87
11.75
12.22

15.95
11.28
10.97

15.74
10.71
10.86

To estimate the optimal ITR, we perform pairwise comparisons between all combinations of two treatment arms, and, for
each two-arm comparison, we apply the OWL approach. We
only present the results from the Gaussian kernel, since the
analysis shows a similarity with that of the linear kernel. Rewards used in the analyses are reversed HRSD scores and the
prognostic variables X consist of 50 pretreatment variables. The
results based on OWL are compared to results obtained using
the l1 -PLS and OLS methods that use (1, X, A, XA) in their
regression models. For comparison between methods, we calculate the value function from a cross-validation type analysis.
Specifically, the data is partitioned into five roughly equal-sized
parts. We perform the analysis on four parts of the data, and
obtain the estimated optimal ITRs using different methods. We
then compute the estimated value functions using the remaining
fifth part. The value functions calculated this way should better
represent expected value functions for future subjects, as compared to calculating value functions based on the training data.
The averages of the cross-validation value functions from the
three methods are presented in Table 1.
From Table 1, we observe that OLS produces smaller value
functions (corresponding to larger HRSD in the table) than the
other two methods, possibly because of the high-dimensional
prognostic variable space. OWL performs similarly to l1 -PLS,
but gives a 5% larger value function than l1 -PLS when comparing the Combination arm to the Nefazodone arm. In fact, when
comparing combination treatment with nefazodone only, OWL
recommends the combination treatment to all the patients in the
validation data in each round of the cross-validation procedure;
the OLS assigns the combination treatment to around 70% of the
patients in each validation subset; while the l1 -PLS recommends
the combination to all the patients in three out of five validation
sets, and 7% and 28% to the patients for the other two, indicating a very large variability. If we need to select treatment
between combination and psychotherapy alone, the OWL approach recommends the combination treatment for all patients
in the validation process. In contrast, the l1 -PLS chooses psychotherapy for 10 out of 86 patients in one round of validation,
and recommends the combination for all patients in the other
rounds. The percentages of patients who are recommended the
combination treatment range from 66% to 85% across the five
validation datasets when applying OLS. When the two single
treatments are studied, there are only negligible differences in
the estimated value functions from the three methods and the selection results also indicate an insignificant difference between
them. Thus, OWL yields ITRs with not only the best clinical
outcomes, but also the lowest variability compared to the other
methods.

1114

Journal of the American Statistical Association, September 2012

6. DISCUSSION
The proposed OWL procedure appears to be more effective,
across a broad range of possible forms of the interaction between prognostic variables and treatment, compared to previous methods. A two-stage procedure is likely to overfit the
regression model, and thus cause troubles for value function
approximation. The OWL provides a nonparametric approach
that sidesteps the inversion of the predicted model required in
other methods and benefits from directly maximizing the value
function. The convergence rates for the OWL, aiming to identify the best ITR, nearly reach the optimal for the nonparametric
SVM with the same type of assumptions on the separations. The
rates, however, are not directly comparable to Qian and Murphy
(2011), because we allow for complex multivariate interactions
and formulate the problem in a nonparametric framework. The
proposed estimator will lead to consistency and fast rate results,
but is not necessarily the most efficient approach. In some cases
when we have knowledge of the specific parametric form, a
likelihood-based method may be more efficient and aid in the
improvement of the estimation. Other possible surrogate loss
functions, for example, the negative log-likelihood for logistic
regression, can also be useful for finding the desired optimal
ITRs.
Several improvements and extensions are important to
consider. An important extension we are currently pursuing is
to right-censored clinical outcomes. Another extension involves
alleviating potential challenges arising from high-dimensional
prognostic variables. Recall that the proposed OWL is based
on a weighted SVM that minimizes the weighted hinge loss
function subject to an l2 penalty. If the dimension of the
covariate space is sufficiently large, not all the variables would
be essential for optimal ITR construction. By eliminating
the unimportant variables from the rule, we could simplify
interpretations and reduce health care costs by only requiring
collection of a small number of significant prognostic variables.
For standard SVM, the l1 penalty has been shown to be effective
in selecting relevant variables via shrinking small coefficients
to zero (Bradley and Mangasarian 1998; Zhu et al. 2003). It
outperforms the l2 penalty when there are many noisy variables
and sparse models are preferred. Other forms of penalty have
been proposed such as the F‚àû norm (Zou and Yuan 2008) and
the adaptive lq penalty (Liu et al. 2007). In the future, we will
examine use of these sparse penalties in the OWL method.
In this article, we only considered binary options for treatment. When there are more than two treatment classes, although we could do a series of pairwise comparisons as done in
Section 5 above, this approach may not be optimal in terms of
identifying the best rule considering all treatments simultaneously. It would thus be worthwhile to extend the OWL approach
to settings involving three or more treatments. The case of multicategory SVM has been studied recently (Lee, Lin, and Wahba
2004; Wang and Shen 2006), and a similar generalization may
be possible for finding ITRs involving three or more treatments.
Another setting to consider is optimal ITR discovery for continuous treatments such as, for example, a continuous range
of dose levels. In this situation, we could potentially use ideas
underlying support vector regression (Vapnik 1995), where the
goal is to find a function that has at most deviation from the

response. Using a similar rationale as the proposed OWL, we
could develop corresponding procedures for continuous treatment spaces through weighing each subject by his/her clinical
outcome.
Obtaining inference for individualized treatment regimens
is also important and challenging. Due to high heterogeneities
among individuals, there may be large variations in the estimated
treatment rules across different training sets. Laber and Murphy
(2011) construct an adaptive confidence interval for the test
error under the nonregular framework. Confidence intervals for
value functions help us determine whether essential differences
exist among different decision rules. Thus, an important future
research topic is to derive the limiting distribution of V(DÃÇn ) ‚àí
V(D‚àó ) and to derive corresponding sample size formulas to aid
in design of personalized medicine clinical trials.
In some complex diseases, dynamic treatment regimes may be
more useful than the single-decision treatment rules studied in
this article. Dynamic treatment regimes are customized sequential decision rules for individual patients that can adapt over time
to an evolving illness. Recently, this research area has been of
great interest in long-term management of chronic disease (see,
e.g., Murphy et al. 2001; Thall, Sung, and Estey 2002; Murphy
2003; Robins 2004; Moodie, Richardson, and Stephens 2007;
Zhao et al. 2011). Extension of the proposed OWL approach to
the dynamic setting would be of great interest.
APPENDIX: PROOFS
Proof of Theorem 3.2
We consider the case where rewards are discrete. Arguments for the
continuous rewards setting follow similarly. Let Œ∑r (x) = p(A = 1|R =
r, X = x) and qr (x) = rp(R = r|X = x). We can write



I (A = sign(f (X)))
R = r, X
rp(R = r|X)E
R( f ) = E
AœÄ + (1 ‚àí A)/2
r

Œ∑r (X)
=E
I (sign(f (X)) = 1)
qr (X)
œÄ
r

1 ‚àí Œ∑r (X)
I (sign(f (X)) = ‚àí1)
+
1‚àíœÄ
= E[c0 (X)(Œ∑(X)I (sign(f (X)) = 1)
+ (1 ‚àí Œ∑(X))I (sign(f (X)) = ‚àí1))],
(A.1)
where c0 (x) = r qr (x)[Œ∑r (x)/œÄ + (1 ‚àí Œ∑r (x))/(1 ‚àí œÄ )], and Œ∑(x),
defined previously in Equation (3.3), is equal to r qr (x)Œ∑r (x)/œÄ c0 (x).
Similarly,
RœÜ ( f ) = E [c0 (X)(Œ∑(X)œÜ(f (X)) + (1 ‚àí Œ∑(X))œÜ(‚àíf (X)))] .
We define C(Œ∑, Œ±) = Œ∑œÜ(Œ±) + (1 ‚àí Œ∑)œÜ(‚àíŒ±). Then the optimal œÜ-risk
satisfies


R‚àóœÜ = E c0 (X) inf C(Œ∑(X), Œ±)
Œ±‚ààR

and



RœÜ ‚àí R‚àóœÜ = E c0 (X) C(Œ∑(X), f (X)) ‚àí inf C(Œ∑(X), Œ±) .
Œ±‚ààR

By a result in the article by Bartlett, Jordan, and McAuliffe (2006) for
a convexified transform of hinge loss, we have
2Œ∑ ‚àí 1 =

inf

Œ±:Œ±(2Œ∑‚àí1)‚â§0

C(Œ∑, Œ±) ‚àí inf C(Œ∑, Œ±).
Œ±‚ààR

(A.2)

Zhao et al.: Estimating Individualized Treatment Rules Using Outcome Weighted Learning

Thus, according to Equations (A.1) and (A.2), we have
R( f ) ‚àí R‚àó ‚â§ E(I (sign(f (X)) = sign[c0 (X)(Œ∑(X) ‚àí 1/2)])
√ó |c0 (X)(2Œ∑(X) ‚àí 1)|)

= E c0 (X)I (sign(f (X)) = sign[c0 (X)(Œ∑(X) ‚àí 1/2)])


C(Œ∑(X), Œ±) ‚àí inf C(Œ∑(X), Œ±)
√ó
inf
Œ±:Œ±(2Œ∑(X)‚àí1)‚â§0
Œ±‚ààR



‚â§ E c0 (X) C(Œ∑(X), f (X)) ‚àí inf C(Œ∑(X), Œ±)
= RœÜ ( f ) ‚àí

R‚àóœÜ .

1115

Now we proceed to obtain a bound for the first term on the righthand side of Equation (A.3). To do this, we need the useful Theorem
5.6 in the article by Steinwart and Scovel (2007) presented below:
Theorem 5.6. Steinwart and Scovel (2007). Let F be a convex set
of bounded measurable functions from Z to R and let L : F √ó Z ‚Üí
[0, ‚àû) be a convex and line-continuous loss function. For a probability
measure P on Z, we define
G := {L ‚ó¶ f ‚àí L ‚ó¶ fP ,F : f ‚àà F}.

Œ±‚ààR

The last inequality holds because we always have C(Œ∑(x),
f (x)) ‚â• inf Œ±‚ààR C(Œ∑(x), Œ±) on the set where sign(f (x)) = sign[c0 (x)
(Œ∑(x) ‚àí 1/2)] and C(Œ∑(x), f (x)) ‚â• inf Œ±:Œ±(2Œ∑(x)‚àí1)‚â§0 C(Œ∑(x), Œ±) when
sign(f (x)) = sign[c0 (x)(Œ∑(x) ‚àí 1/2)].

Suppose that there are constants c ‚â• 0, 0 < Œ± < 1, Œ¥ ‚â• 0, and B > 0
with EP g 2 ‚â§ c(EP g)Œ± + Œ¥ and g‚àû ‚â§ B for all g ‚àà G. Furthermore,
assume that G is separable with respect to  ¬∑ ‚àû and that there are
constants a ‚â• 1 and 0 < p < 2 with
sup log N (B ‚àí1 G, , L2 (T )) ‚â§ a

‚àíp

T ‚ààZ n

Proof of Theorem 3.3
Define LœÜ ( f ) = RœÜ(Af )/(AœÄ + (1 ‚àí A)/2). By the definition of
fÀÜn , we have for any f ‚àà Hk ,
Pn (LœÜ (fÀÜn )) ‚â§ Pn (LœÜ (fÀÜn ) + Œªn fÀÜn 2 ) ‚â§ Pn (LœÜ ( f ) + Œªn f 2 ),
where Pn denotes the empirical measure of the observed data. Thus,
lim supn Pn (LœÜ (fÀÜn )) ‚â§ P (LœÜ ( f )). It leads to lim supn Pn (LœÜ (fÀÜn )) ‚â§
inf f ‚ààHÃÑk P (LœÜ ( f )). Theorem 3.3 holds if we can show Pn (LœÜ (fÀÜn )) ‚àí
P (LœÜ (fÀÜn )) ‚Üí 0 in probability.
To this end, we first obtain a bound for fÀÜn 2k . Since Pn (LœÜ (fÀÜn )) +
Œªn fÀÜn 2 ‚â§ Pn (LœÜ (f )) + Œªn f 2k for any f ‚àà Hk , we can select f = 0
to obtain
E(R)
1 1  Ri
2
.
‚â§
œÜ(0) ‚â§
Œªn n
œÄi
Œªn min{œÄ, 1 ‚àí œÄ }
‚àö
ÀÜ
Let M = 2E(R)/min{œÄ,
1 ‚àí œÄ } so that ‚àö
the Hk norm
‚àön (X) is
‚àö
‚àö of Œªn f
{ Œªn f :  Œª‚àö
f

‚â§
M}
bounded by M. Note that the class ‚àö
n
k
‚àö is
contained in a Donsker class. Thus, { Œªn LœÜ ( f ),  Œªn f k ‚â§ M}
is also P-Donsker because (1 ‚àí Af (X))+ is Lipschitz continuous with
respect to f . Therefore,

 ‚àö
‚àö
R
n(Pn ‚àí P )LœÜ (fÀÜn ) = Œª‚àí1
n(Pn ‚àí P )
n
AœÄ + (1 ‚àí A)/2
 
+ 


= Op Œª‚àí1
.
Œªn ‚àí A Œªn fÀÜn (X)
√ó
n
fÀÜn 2k

Consequently, from nŒªn ‚Üí ‚àû, Pn (LœÜ (fÀÜn )) ‚àí P (LœÜ (fÀÜn )) ‚Üí 0 in probability.

for all > 0. Then there exists a constant cp > 0 depending only on p
such that for all n ‚â• 1 and all œÑ ‚â• 1 we have
Pr‚àó (T ‚àà Z n : RL,P (fT ,F ) > RL,P (fP ,F ) + cp (n, a, B, c, Œ¥, œÑ )) ‚â§ e‚àíœÑ,
where

 a 2/(4‚àí2Œ±+Œ±p)
(n, a, B, c, Œ¥, x) := B 2p/(4‚àí2Œ±+Œ±p) c(2‚àíp)/(4‚àí2Œ±+Œ±p)
n
 1/2
 a 2/(2+p)
p/2 (2‚àíp)/4 a
+B Œ¥
+B
n
n

Œ¥x  cœÑ 1/(2‚àíŒ±) BœÑ
+
+
+
.
n
n
n

In their article, fP ,F ‚àà F is a minimizer of RL,P ( f ) = E(L(f, z)),
and fT ,F is similarly defined when T is an empirical measure. To
use this theorem, we define F, Z, T , G, fT ,F , and fP ,F according to
our setting.
It suffices to consider the subspace
of Hk , denoted by
‚àö
‚àö
,
as
the
ball
of
H
M/Œª
of
radius
M/Œª
.
Specifically, we let
BHk
n
k
n
‚àö

M/Œªn and Z be X . The loss function we consider here
F be BHk
is LœÜ ( f ) + Œªn f 2k and G is the function class
‚àó
)
GœÜ,Œªn = {LœÜ ( f ) + Œªn f 2k ‚àí LœÜ (fœÜ,Œª
 n
‚àó
2
‚àí Œªn fœÜ,Œªn k : f ‚àà BHk ( M/Œªn )},
‚àó
= argminf ‚ààBH (‚àöM/Œªn ) (Œªn f 2k + RœÜ ( f )). fP ,F and fT ,F
where fœÜ,Œª
n
k
‚àó
correspond to fœÜ,Œª
and fÀÜn , respectively. Therefore, to apply this then
orem, we will show that there are constants c ‚â• 0 and B > 0, which
can possibly depend on n, such that E(g 2 ) ‚â§ cE(g) and g‚àû ‚â§ B,
‚àÄg ‚àà GœÜ,Œª . Moreover, there are constants cÃÉ and 0 < ŒΩ < 2 with

sup log N (B ‚àí1 GœÜ,Œªn , , L2 (Pn )) ‚â§ cÃÉ

Proof of Theorem 3.4
for all

First, we have

RœÜ (fÀÜn ) ‚àí R‚àóœÜ ‚â§ Œªn fÀÜn 2k + RœÜ (fÀÜn ) ‚àí R‚àóœÜ ‚â§ Œªn fÀÜn 2k + RœÜ (fÀÜn )
 

‚àí inf (Œªn f 2k + RœÜ ( f )) + inf (Œªn f 2k + RœÜ ( f ) ‚àí R‚àóœÜ ) .
f ‚ààHk

f ‚ààHk

(A.3)
We will bound each term on the right-hand side separately in the
following arguments.
For the second term on the right-hand side of Equation (A.3), we use
Theorem 2.7 in the article by Steinwart and Scovel (2007) to conclude
that




,
(A.4)
inf Œªn f 2k + RœÜ ( f ) ‚àí R‚àóœÜ = O Œªq/(q+1)
n
f ‚ààHk

when we set œÉn = Œªn‚àí1/(q+1)d .

‚àíŒΩ

,

Pn

> 0.

Let CL denote sup{R/ min(œÄ, 1 ‚àí œÄ )}, which is finite provided that
R is bounded. Since the weighted hinge loss is Lipschitz continuous
with respect to f , with Lipschitz constant CL , and since f ‚àû ‚â§ f k
given that k(x, x) ‚â§ 1, for any g ‚àà GœÜ,Œªn , we have
‚àó
‚àó
)| + Œªn |f 2k ‚àí fœÜ,Œª
2 |
|g| ‚â§ |LœÜ ( f ) ‚àí LœÜ (fœÜ,Œª
n
n k
‚àó
‚â§ CL |f (x) ‚àí fœÜ,Œªn (x)| + M
‚àö
‚â§ 2CL MŒªn‚àí1/2 + M.
‚àö
Therefore, we can set B = 2CL MŒªn‚àí1/2 + M.
For any g ‚àà GœÜ,Œªn , we have
‚àó
‚àó
)| + Œªn |f 2k ‚àí fœÜ,Œª
2 |
g( f ) ‚â§ |LœÜ ( f ) ‚àí LœÜ (fœÜ,Œª
n
n k
‚àó
‚àó
‚àó
‚â§ CL |f ‚àí fœÜ,Œªn | + Œªn f ‚àí fœÜ,Œªn k f + fœÜ,Œªn k

‚àó
= (CL + 2 MŒªn )f ‚àí fœÜ,Œª
.
n k

(A.5)

1116

Journal of the American Statistical Association, September 2012

where

Squaring both sides and taking expectations yields

‚àó
2 .
E(g 2 ) ‚â§ (CL + 2 MŒªn )2 f ‚àí fœÜ,Œª
n k

(A.6)

On the other hand, from the convexity of LœÜ , we have
1
‚àó
‚àó
(LœÜ ( f ) + Œªn f 2k + LœÜ (fœÜ,Œª
) + Œªn fœÜ,Œª
2 )
n
n k
2


‚àó
‚àó
f + fœÜ,Œª
f 2k + fœÜ,Œª
2
n
n k
‚â• LœÜ
+ Œªn
2
2






‚àó
 f + f ‚àó 2
 f ‚àí f ‚àó 2
f + fœÜ,Œª


œÜ,Œªn 
œÜ,Œªn 
n
= LœÜ
+ Œªn 
 + Œªn 





2
2
2
k
k
2

f ‚àí f‚àó 


œÜ,Œª
n
‚àó
‚àó
‚â• LœÜ (fœÜ,Œª
) + Œªn fœÜ,Œª
2 + Œªn 
.
n
n k


2

2

 cÃÉ  2+ŒΩ
œÑ
2ŒΩ
2‚àíŒΩ
(n, cÃÉ, B, c, œÑ ) = B + B 2+ŒΩ c 2+ŒΩ
+ (B + c) .
n
n

With B and c as defined in Equations (A.5) and (A.7), that is, cÃÉ =
c2 œÉn(1‚àíŒΩ/2)(1+Œ¥)d and œÉn = ‚àíŒªn1/(q+1)d , we obtain
2

(2‚àíŒΩ)(1+Œ¥)

(n, cÃÉ, B, c, œÑ ) = C1 (Œªn )‚àí 2+ŒΩ + (2+ŒΩ)(1+q)

1
n

2
 2+ŒΩ

+ C2

œÑ
, (A.9)
nŒªn

where C1 and C2 are constants depending on ŒΩ, Œ¥, d, M, and œÄ . We
complete the proof of Theorem 3.4 by plugging Equations (A.4) and
(A.9) into Equation (A.3).

k

‚àó
2 /2.
Taking expectations on both sides leads to E(g) ‚â• Œªn f ‚àí fœÜ,Œª
n k
2
Combining this with Equation (A.6), we conclude that E(g ) ‚â§ cE(g),
where

2
(CL + 2 MŒªn )2 .
(A.7)
c=
Œªn

To estimate the bound for N (B ‚àí1 GœÜ,Œªn , , L2 (Pn )), we first have
N (B ‚àí1 GœÜ,Œªn , , L2 (Pn ))


= N (B ‚àí1 {LœÜ ( f ) + Œªn f 2k : f ‚àà BHk ( M/Œªn )}, , L2 (Pn )).

From the subadditivity of the entropy,
log N (B ‚àí1 GœÜ,Œªn , 2 , L2 (Pn ))


‚â§ log N (B ‚àí1 {LœÜ ( f ) : f ‚àà BHk ( M/Œªn )}, , L2 (Pn ))

+ log N ({Œªn f 2k , f ‚àà BHk ( M/Œªn )}, , L2 (Pn )). (A.8)

Using the Lipschitz-continuity of the weighted
hinge loss, we now have
‚àö
‚àà B ‚àí1 {LœÜ ( f ) : f ‚àà BHk ( M/Œªn )} with corresponding
that if u, u ‚àö
f, f ‚àà BHk ( M/Œªn ), then u ‚àí u L2 (Pn ) ‚â§ B ‚àí1 CL f ‚àí f L2 (Pn ) ,
and therefore the first term on the right-hand side of Equation (A.8)
satisfies

log N (B ‚àí1 {LœÜ ( f ) : f ‚àà BHk ( M/Œªn )}, , L2 (Pn ))



B
‚â§ log N BHk ( M/Œªn ),
, L2 (Pn )
CL


B
‚â§ log N BHk ,
, L2 (Pn )
‚àö
CL M/Œªn
‚â§ log N (BHk , 2 , L2 (Pn )).

‚àö
The last inequality follows because B/CL M/Œªn ‚â• 2. It is trivial to
see that for the second term on the right-hand side of Equation (A.8),

M
).
log N ({Œªn f 2k , f ‚àà B( M/Œªn )}, , L2 (Pn )) ‚â§ log(
B
Thus,

M
log N (B ‚àí1 GœÜ,Œªn , 2 , L2 (Pn )) ‚â§ log N (BHk , 2 , L2 (Pn ))+ log
.
B
Using Equation (3.5) and a given choice for B, we obtain for all œÉn > 0,
0 < ŒΩ < 2, Œ¥ > 0, > 0,
sup log N (B ‚àí1 GœÜ,Œªn , , L2 (Pn )) ‚â§ c2 œÉn(1‚àíŒΩ/2)(1+Œ¥)d

‚àíŒΩ

,

Pn

where c2 depends on ŒΩ, Œ¥, and d.
Consequently, from Theorem 5.6 in the article by Steinwart and
Scovel (2007), there exists a constant cŒΩ > 0 depending only on ŒΩ such
that for all n ‚â• 1 and all œÑ ‚â• 1, we have the bound for the first term
P ‚àó (Œªn fÀÜn 2k + RœÜ (fÀÜn ) > inf (Œªn f 2k + RœÜ ( f ))
f ‚ààHk

+ cŒΩ (n, cÃÉ, B, c, œÑ )) ‚â§ e‚àíœÑ ,

Proof of Theorem 3.5
We apply Theorem 4.3 in the article by Blanchard, Bousquet, and
Massart (2008) on the scaled loss function LÃÉœÜ ( f ) = LœÜ ( f )/CL to
obtain the rates in Theorem 3.5. Without loss of generality, we can
assume that the Bayes classifier f ‚àó ‚àà Hk , since we can always find
g ‚àà Hk such that RœÜ (g) = RœÜ (f ‚àó ) = R‚àóœÜ , provided that Hk is dense
in C(X ). Let S be a countable and dense subset of R+ , and let BHk (S)
denote the ball of Hk of radius S. Then BHk (S), S ‚àà S is a countable
collection of classes of functions. We can then use Theorem 4.3 in the
article by Blanchard, Bousquet, and Massart (2008) after we verify the
following conditions (H1)‚Äì(H4):
(H1) ‚àÄS ‚àà S, ‚àÄf ‚àà BHk (S), LÃÉœÜ ( f )‚àû ‚â§ bS , bS = 1 + S;
(H2) ‚àÄf, f ‚àà Hk , var(LÃÉœÜ ( f ) ‚àí LÃÉœÜ (f )) ‚â§ d 2 (f, f ), d(f, f ) =
f ‚àí f L2 (P ) ;
(H3) ‚àÄS ‚àà S, ‚àÄf ‚àà BHk (S), d 2 (f, f ‚àó ) ‚â§ CS E(LÃÉœÜ ( f ) ‚àí
LÃÉœÜ (f ‚àó )), CS = 2(S/Œ∑0 + 1/Œ∑1 );
(H4) Let
 x

Œæ (x) =
log N (BHk , , L2 (Pn ))d .
0

We have

E

sup
f ‚àà BHk (S)
d 2 (f, f ) ‚â§ r


(P ‚àí Pn )(LÃÉœÜ ( f ) ‚àí LÃÉœÜ (f )) ‚â§ inf


12
12
√ó 4œë ‚àí ‚àö Œæ (œë) + ‚àö Œæ
n
n

œë>0

‚àö 
r
= œàS (r).
‚àö
2S

that is, œàS is
œàS , S ‚àà S, is a sequence of subroot functions,
‚àö
nonnegative, nondecreasing, and œàS (r)/ r is nonincreasing
for r > 0. Denote x‚àó as the solution of the equation Œæ (x) =
‚àö
nx 2 . If rS‚àó denotes the solution of œàS (r) = r/CS , then
‚àö
rS‚àó ‚â§ inf CS {4œë ‚àí 12Œæ (œë)/ n} + c2 CS2 x‚àó2 .
œë>0

Under these conditions, we define for n ‚àà N the following quantity:


12
Œ≥n = inf 4œë ‚àí ‚àö Œæ (œë) + x‚àó2 (n) .
œë>0
n
Given Hk is associated with the Gaussian kernel, we can show that
Œæ (x)  1‚àíŒΩ for any 0 < ŒΩ < 2. Thus, Œ≥n  max(n‚àí1/2ŒΩ , n‚àí1/(ŒΩ+1) ). By
the choice of Œªn = O(n‚àí1/(ŒΩ+1) ) for any ŒΩ ‚àà (0, 1), this satisfies

log(œÑ ‚àí1 log n) ‚à® 1
Œªn ‚â• c Œ≥n + Œ∑1‚àí1
.
n
Therefore, according to Theorem 4.3 in the article by Blanchard,
Bousquet, and Massart (2008), the following bound holds with

Zhao et al.: Estimating Individualized Treatment Rules Using Outcome Weighted Learning

probability at least 1 ‚àí œÑ , where œÑ > 0 is a fixed real number:

E(LÃÉœÜ (fÀÜn )) ‚àí E(LÃÉœÜ (f ‚àó )) ‚â§ 2 inf E(LÃÉœÜ ( f )) ‚àí E(LÃÉœÜ (f ‚àó ))
f ‚ààHk



2
+ 2Œªn f k + 4Œªn 8 + cŒ∑1 Œ∑0‚àí1 .
The result does not change after we scale back to the original loss
LœÜ ( f ). We have shown that inf f ‚ààHk [RœÜ (f ) ‚àí RœÜ (f ‚àó ) + 2Œªn f 2k ] =
) in the proof of Theorem 3.4. Thus,
O(Œªq/(q+1)
n




q
1
= Op n‚àí ŒΩ+1 q+1 .
R(fÀÜn ) ‚àí R‚àó = Op Œªq/(q+1)
n
The remainder of the proof is to verify conditions (H1)‚Äì(H4).
For condition (H1), LÃÉœÜ ( f )‚àû ‚â§ sup{R/(AœÄ + (1 ‚àí A)/2)}(1 +
S)/CL ‚â§ 1 + S, f k ‚â§ S.
For condition (H2), let d(f, f ) = f ‚àí f L2 (P ) . LœÜ ( f ) is a
Lipschitz function with respect to f with Lipschitz constant CL . Then
LÃÉœÜ ( f ) ‚àí LÃÉœÜ (f ) ‚â§ |f (x) ‚àí f (x)|. Hence, (H2) is easily satisfied.
For condition (H3), the proof is similar to Lemma 6.4 in the article by
Blanchard, Bousquet, and Massart (2008) with CS = 2(S/Œ∑1 + 1/Œ∑0 ),
where Œ∑0 and Œ∑1 are as defined in Assumptions (A1) and (A2) of
Section 3.5.
For condition (H4), we introduce the notation for Rademacher averages: let Œµ1 , . . . , Œµn be n iid Rademacher random variables, independent
of (Xi , Ai , Ri ), i = 1, . . . , n. For any measurable real-valued function
f , the Rademacher average is defined as Ln f = n‚àí1 ni=1 Œµi f (Xi ).
Also let Ln (F) be the empirical Rademacher complexity of function
class F, Ln F = supf ‚ààF Ln f .
First, we have from Lemma 6.7 in the article by Blanchard,
Bousquet, and Massart (2008) that for f ‚àà Hk ,


E sup (P ‚àí Pn )(LÃÉœÜ ( f ) ‚àí LÃÉœÜ (f )) ‚â§ 4E[Ln {f ‚àí f , f ‚àà Hk }].
f ‚ààHk

Thus, for the set {f ‚àà Hk : f k ‚â§ S, d 2 (f, f ) ‚â§ r} and f ‚àà BHk (S),


E sup (P ‚àí Pn )(LÃÉœÜ ( f ) ‚àí LÃÉœÜ (f ))
f ‚ààHk

‚â§ 4E[Ln {f ‚àí f , f ‚àà Hk : f k ‚â§ S, d 2 (f, f ) ‚â§ r}],
the right-hand side of which is equivalent to 4E[Ln {f, f ‚àà Hk :
f k ‚â§ 2S, f 2L2 (Pn ) ‚â§ 2r}]. Now we proceed to show that


ELn f ‚àà Hk : f k ‚â§ 2S, f 2L2 (Pn ) ‚â§ 2r ‚â§ inf
12
4œë + ‚àö
n

√ó



‚àö
‚àör
2S

œë>0



log N (BH , , L2 (Pn ))d

by slightly modifying the procedure in obtaining Dudley‚Äôs Entropy Integral for Rademacher complexity of sets of functions. For j ‚â• 0, let rj =
‚àö
2r2‚àíj and Tj be a rj -cover of BHk (2S) with respect to the L2 (Pn )norm. For each f ‚àà BHk (2S), we can find an fÀúj ‚àà Tj , such that f ‚àí
Àú
fÀúj L2 (Pn ) ‚â§ rj . For any N, we express f as f = f ‚àí fÀúN + N
j =1 (fj ‚àí
fÀúj ‚àí1 ), where fÀú0 = 0. Note fÀú0 = 0 is an r0 -approximation of f . Hence,


n
N

1
Œµi f (Xi )‚àí fÀúN (Xi )+ (fÀúj (Xi )‚àí fÀúj ‚àí1 (Xi ))
=E
sup
f ‚ààBHk (2S) n
i=1
j =1


‚â§E
sup ŒµL2 (Pn ) f ‚àí fÀúN L2 (Pn )
f ‚ààBHk (2S)


n
1 Àú
(fj (Xi ) ‚àí fÀúj ‚àí1 (Xi ))
f ‚ààBHk (2S) n i=1
j =1


N
n

1 Àú
E
sup
(fj (Xi ) ‚àí fÀúj ‚àí1 (Xi )) .
‚â§ rN +
f ‚ààBHk (2S) n
j =1
i=1
+

N




E

sup

Note that

2

fÀúj ‚àí fÀúj ‚àí1 2L2 (Pn ) ‚â§ fÀúj ‚àí f L2 (Pn ) + f ‚àí fÀúj ‚àí1 L2 (Pn )
‚â§ (rj + rj ‚àí1 )2 = 9rj2 .

We therefore have
N




2 log(|Tj ||Tj ‚àí1 |)
n
j =1

N

log N (BHk (2S), rj , L2 (Pn ))
‚â§ rN + 12
(rj ‚àírj +1 )
n
j =1
‚àö
‚àö

 r/ 2S
log N (BHk , , L2 (Pn ))
d .
‚â§ rN + 12
n
rN+1

Ln (BHk (2S)) ‚â§ rN +

3rj

For any œë > 0, we can choose N = sup{j : rj > 2œë}. Therefore,
œë < rN+1 < 2œë, and rN < 4œë. We therefore conclude that
 ‚àör/‚àö2S 
log N (BHk , , L2 (Pn ))
d
Ln (BHk (2S)) ‚â§ inf 4œë + 12
œë>0
n
œë
‚àö 

12
r
12
= inf 4œë ‚àí ‚àö Œæ (œë) + ‚àö Œæ ‚àö
= œàS (r).
œë>0
n
n
2S
The function œàS is subroot because log N (BHk , , L2 (Pn )) is a
decreasing function of .
 ‚àö
To show the upper bound of r ‚àó , let tS‚àó = c2 CS2 x‚àó2 . Then tS‚àó / 2S =
‚àö
 ‚àö
cCS x‚àó / 2S, CS /S ‚â• 1. Assuming that c ‚â• 2, we have tS‚àó / 2S ‚â•
x‚àó . Since x ‚àí1 Œæ (x) is a decreasing function, it follows that
 
‚àö
t‚àó
n ‚àó
CS
Œæ ‚àö S ‚â§ c ‚àö Œæ (x‚àó ) =
t .
cSCS S
2S
2S
Therefore, by selecting an appropriate constant c,


12
12 ‚àó
œàS (tS‚àó ) ‚â§ inf 4œë ‚àí ‚àö Œæ (œë) +
t
œë>0
cSCS S
n
‚àö
CS inf œë>0 {4œë ‚àí 12/ nŒæ (œë)} + tS‚àó
‚â§
.
CS
The desired result follows from the property of subroot functions,
which states that if œà : [0, ‚àû) ‚Üí [0, ‚àû) is a sub-root function, then
the unique positive solution of œà(r) = r, denoted by r ‚àó , exists, and
for all r > 0, r ‚â• œà(r) if and only if r ‚àó ‚â§ r (Bartlett, Bousquet, and
Mendelson 2005).

= œàS (r),

œë

Ln (BHk (2S))


1117

[Received October 2011. Revised April 2012.]

REFERENCES
Bartlett, P. L., Bousquet, O., and Mendelson, S. (2005), ‚ÄúLocal Rademacher
Complexities,‚Äù The Annals of Statistics, 33 (4), 1497‚Äì1537. [1117]
Bartlett, P. L., Jordan, M. I., and McAuliffe, J. D. (2006), ‚ÄúConvexity, Classification, and Risk Bounds,‚Äù Journal of American Statistical Association,
101 (473), 138‚Äì156. [1109,1114]
Blanchard, G., Bousquet, O., and Massart, P. (2008), ‚ÄúStatistical Performance
of Support Vector Machines,‚Äù The Annals of Statistics, 36, 489‚Äì531.
[1110,1116,1117]
Bradley, P. S., and Mangasarian, O. L. (1998), ‚ÄúFeature Selection via Concave
Minimization and Support Vector Machines,‚Äù in Proceedings of the 15th
International Conference on Machine Learning, San Francisco, CA: Morgan
Kaufmann, pp. 82‚Äì90. [1114]
Buzdar, A. U. (2009), ‚ÄúRole of Biologic Therapy and Chemotherapy in Hormone
Receptor and HER2-Positive Breast Cancer,‚Äù The Annals of Oncology, 20,
993‚Äì999. [1106]
Cai, T., Tian, L., Uno, H., and Solomon, S. D. (2010), ‚ÄúCalibrating Parametric
Subject-Specific Risk Estimation,‚Äù Biometrika, 97 (2), 389‚Äì404. [1106]
Cortes, C., and Vapnik, V. (1995), ‚ÄúSupport-Vector Networks,‚Äù Machine Learning, 20, 273‚Äì297. [1106,1107]

1118
Crits-Christoph, P., Siqueland, L., Blaine, J., Frank, A., Luborsky, L. S., Onken,
L. S., Muenz, L. R., Thase, M. E., Weiss, R. D., Gastfriend, D. R., Woody,
G. E., Barber, J. P., Butler, S. F., Daley, D., Salloum, I., Bishop, S., Najavits,
L. M., Lis, J., Mercer, D., Griffin, M. L., Moras, K., and Beck, A. T. (1999),
‚ÄúPsychosocial Treatments for Cocaine Dependence,‚Äù Archives of General
Psychiatry, 56, 493‚Äì502. [1106]
Eagle, K. A., Lim, M. J., Dabbous, O. H., Pieper, K. S., Goldberg, R. J., de
Werf, F. V., Goodman, S. G., Granger, C. B., Steg, P. G., Gore, J. M., Budaj,
A., Avezum, A., Flather, M. D., Fox, K. A. A., and GRACE Investigators,
(2004), ‚ÄúA Validated Prediction Model for All Forms of Acute Coronary
Syndrome: Estimating the Risk of 6-Month Postdischarge Death in an International Registry,‚Äù Journal of the American Medical Association, 291,
2727‚Äì2733. [1106]
Flume, P. A., O Sullivan, B. P., Goss, C. H., Mogayzel, P. J., Willey-Courand,
D. B., Bujan, J., Finder, J., Lester, M., Quittell, L., Rosenblatt, R., Vender,
R. L., Hazle, L., Sabadosa, K., and Marshall, B. (2007), ‚ÄúCystic Fibrosis Pulmonary Guidelines: Chronic Medications for Maintenance of Lung
Health,‚Äù American Journal of Respiratory and Critical Care Medicine,
176 (1), 957‚Äì969. [1106]
GruÃànwald, V., and Hidalgo, M. (2003), ‚ÄúDeveloping Inhibitors of the Epidermal
Growth Factor Receptor for Cancer Treatment,‚Äù Journal of the National
Cancer Institute, 95 (12), 851‚Äì867. [1106]
Hastie, T., Tibshirani, R., and Friedman, J. H. (2009), The Elements of Statistical
Learning (2nd ed.), New York: Springer-Verlag. [1108]
Insel, T. R. (2009), ‚ÄúTranslating Scientific Opportunity Into Public Health Impact: A Strategic Plan for Research on Mental Illness,‚Äù Archives of General
Psychiatry, 66 (2), 128‚Äì133. [1106]
Keller, M. B., Mccullough, J. P., Klein, D. N., Arnow, B., Dunner, D. L.,
Gelenberg, A. J., Markowitz, J. C., Nemeroff, C. B., Russell, J. M., Thase,
M. E., Trivedi, M. H., and Zajecka, J. (2000), ‚ÄúA Comparison of Nefazodone,
The Cognitive Behavioral-Analysis System of Psychotherapy, and Their
Combination for the Treatment of Chronic Depression,‚Äù The New England
Journal of Medicine, 342 (20), 1462‚Äì1470. [1107,1113]
Laber, E. B., and Murphy, S. A. (2011), ‚ÄúAdaptive Confidence Intervals for the
Test Error in Classification,‚Äù Journal of the American Statistical Association,
106, 904‚Äì913. [1114]
Lee, Y., Lin, Y., and Wahba, G. (2004), ‚ÄúMulticategory Support Vector Machines: Theory and Application to the Classification of Microarray Data and
Satellite Radiance Data,‚Äù Journal of the American Statistical Association,
99, 67‚Äì81. [1114]
Lin, Y. (2002), ‚ÄúSupport Vector Machines and the Bayes Rule in Classification,‚Äù
Data Mining and Knowledge Discovery, 6, 259‚Äì275. [1109]
Liu, Y., Zhang, H., Park, C., and Ahn, J. (2007), ‚ÄúSupport Vector Machines
With Adaptive Lq Penalty,‚Äù Computational Statistics & Data Analysis, 51
(12), 6380‚Äì6394. [1114]
Lugosi, G., and Vayatis, N. (2004), ‚ÄúOn the Bayes-Risk Consistency
of Regularized Boosting Methods,‚Äù The Annals of Statistics, 32, 30‚Äì
55. [1107]
Marlowe, D. B., Festinger, D. S., Dugosh, K. L., Lee, P. A., and Benasutti,
K. M. (2007), ‚ÄúAdapting Judicial Supervision to the Risk Level of Drug
Offenders: Discharge and 6-Month Outcomes From a Prospective Matching
Study,‚Äù Drug and Alcohol Dependence, 88 (2), S4‚ÄìS13. [1106]
Moodie, E. E. M., Platt, R. W., and Kramer, M. S. (2009), ‚ÄúEstimating ResponseMaximized Decision Rules With Applications to Breastfeeding,‚Äù Journal of
the American Statistical Association, 104 (485), 155‚Äì165. [1107]
Moodie, E. E. M., Richardson, T. S., and Stephens, D. A. (2007), ‚ÄúDemystifying
Optimal Dynamic Treatment Regimes,‚Äù Biometrics, 63 (2), 447‚Äì455. [1114]
Murphy, S. A. (2003), ‚ÄúOptimal Dynamic Treatment Regimes,‚Äù Journal of the
Royal Statistical Society, Series B, 65, 331‚Äì366. [1114]

Journal of the American Statistical Association, September 2012
Murphy, S. A., van der Laan, M. J., Robins, J. M., and CPPRG, (2001),
‚ÄúMarginal Mean Models for Dynamic Regimes,‚Äù Journal of the American
Statistical Association, 96, 1410‚Äì1423. [1111,1114]
Piper, W. E., Boroto, D. R., Joyce, A. S., McCallum, M., and Azim, H. F. A.
(1995), ‚ÄúPattern of Alliance and Outcome in Short-Term Individual Psychotherapy,‚Äù Psychotherapy, 32, 639‚Äì647. [1106]
Qian, M., and Murphy, S. A. (2011), ‚ÄúPerformance Guarantees for Individualized Treatment Rules,‚Äù The Annals of Statistics, 39, 1180‚Äì1210.
[1106,1107,1111,1114]
Robins, J. M. (2004), ‚ÄúOptimal Structural Nested Models for Optimal Sequential
Decisions,‚Äù in Proceedings of the Second Seattle Symposium on Biostatistics,
pp. 189‚Äì236. [1107]
Rosenwald, A., Wright, G., Chan, W. C., Connors, J. M., Campo, E., Fisher,
R. I., Gascoyne, R. D., Muller-Hermelink, H. K., Smeland, E. B., Giltnane,
J. M., Hurt, E. M., Zhao, H., Averett, L., Yang, L., Wilson, W. H., Jaffe, E. S.,
Simon, R., Klausner, R. D., Powell, J., Duffey, P. L., Longo, D. L., Greiner,
T. C., Weisenburger, D. D., Sanger, W. G., Dave, B. J., Lynch, J. C., Vose,
J., Armitage, J. O., Montserrat, E., LoÃÅpez-Guillermo, A., Grogan, T. M.,
Miller, T. P., LeBlanc, M., Ott, G., Kvaloy, S., Delabie, J., Holte, H., Krajci,
P., Stokke, T., Staudt, L. M., and Lymphoma/Leukemia Molecular Profiling
Project, (2002), ‚ÄúThe Use of Molecular Profiling to Predict Survival After
Chemotherapy for Diffuse Large B-Cell Lymphoma,‚Äù The New England
Journal of Medicine, 346, 1937‚Äì1947. [1106]
Sargent, D. J., Conley, B. A., Allegra, C., and Collette, L. (2005), ‚ÄúClinical
Trial Designs for Predictive Marker Validation in Cancer Treatment Trials,‚Äù
Journal of Clinical Oncology, 32, 2020‚Äì2027. [1106]
Steinwart, I. (2005), ‚ÄúConsistency of Support Vector Machines and Other Regularized Kernel Classifiers,‚Äù IEEE Transactions on Information Theory, 51,
128‚Äì142. [1107]
Steinwart, I., and Scovel, C. (2007), ‚ÄúFast Rates for Support Vector Machines Using Gaussian Kernels,‚Äù The Annals of Statistics, 35, 575‚Äì607.
[1109,1110,1115,1116]
Thall, P. F., Sung, H.-G., and Estey, E. H. (2002), ‚ÄúSelecting Therapeutic Strategies Based on Efficacy and Death in Multicourse Clinical Trials,‚Äù Journal
of the American Statistical Association, 97, 29‚Äì39. [1114]
Tsybakov, A. B. (2004), ‚ÄúOptimal Aggregation of Classifiers in Statistical
Learning,‚Äù The Annals of Statistics, 32, 135‚Äì166. [1110]
van‚Äôt Veer, L. J., and Bernards, R. (2008), ‚ÄúEnabling Personalized Cancer
Medicine Through Analysis of Gene-Expression Patterns,‚Äù Nature, 452,
564‚Äì570. [1106]
Vapnik, V. N. (1995), The Nature of Statistical Learning Theory, New York:
Springer-Verlag. [1114]
Vert, R., and Vert, J.-P. (2006), ‚ÄúConsistency and Convergence Rates of OneClass SVMs and Related Algorithms,‚Äù Journal of Machine Learning Research, 7, 817‚Äì854. [1110]
Wang, L., and Shen, X. (2006), ‚ÄúMulti-Category Support Vector Machines, Feature Selection, and Solution Path,‚Äù Statistica Sinica, 16,
617‚Äì633. [1114]
Zhang, T. (2004), ‚ÄúStatistical Behavior and Consistency of Classification Methods Based on Convex Risk Minimization,‚Äù The Annals of Statistics, 32 (1),
56‚Äì85. [1107,1109]
Zhao, Y., Zeng, D., Socinski, M. A., and Kosorok, M. R. (2011), ‚ÄúReinforcement
Learning Strategies for Clinical Trials in Nonsmall Cell Lung Cancer,‚Äù
Biometrics, 67, 1422‚Äì1433. [1114]
Zhu, J., Rosset, S., Hastie, T., and Tibshirani, R. (2003), ‚Äú1-Norm Support Vector Machines,‚Äù in Neural Information Processing Systems,
p. 16. [1114]
Zou, H., and Yuan, M. (2008), ‚ÄúThe F‚àû -Norm Support Vector Machine,‚Äù Statistica Sinica, 18, 379‚Äì398. [1114]

