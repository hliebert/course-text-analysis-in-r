Principal Stratification Approach to Broken Randomized Experiments: A Case Study of
School Choice Vouchers in New York City [with Comment]
Author(s): Richard A. Berk and Hongquan Xu
Source: Journal of the American Statistical Association, Vol. 98, No. 462 (Jun., 2003), pp.
318-320
Published by: Taylor & Francis, Ltd. on behalf of the American Statistical Association
Stable URL: https://www.jstor.org/stable/30045241
Accessed: 27-02-2019 21:30 UTC
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide
range of content in a trusted digital archive. We use information technology and tools to increase productivity and
facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at
https://about.jstor.org/terms

American Statistical Association, Taylor & Francis, Ltd. are collaborating with JSTOR to
digitize, preserve and extend access to Journal of the American Statistical Association

This content downloaded from 206.253.207.235 on Wed, 27 Feb 2019 21:30:49 UTC
All use subject to https://about.jstor.org/terms

318 Journal of the American Statistical Association, June 2003

the effect on math is significant
at question
the that
.10one
level
in in
year
1,
depends on the
is interested
answering.
Barnard et al. have found, and
almost
significant
year
3.
Because
most interest
in the experimentin
for policy
purposes
we conclude that the effect of
the
opportunity
to use
a priva
centers
on the
impact of offering vouchers
on achievement
school voucher on the composite
score for
the
comprehe
not on compelling
students
to usemost
vouchers-we
think the IT
sive sample of Black students estimates,
is insignificantly
different
which reflect inevitable
partial usage offrom
vouchers
although it is possible that there
initially
a 1998;
small
benefic
are mostwas
relevant
(see also Rouse
Angrist
et al. 2003

effect on the math score for Black students.

Moreover, New York had a higher voucher take-up rate than
In the final column we present results for the subsample of the experiments in Dayton and the District of Columbia, so
students originally enrolled in schools with average test scores one could argue that the New York experiment provides an
below the median score in New York City. In each case, the upper bound estimate of the effect of offering vouchers. O
results for this subsample are quite similar to those for the the other hand, if the goal is to use the experiment to estifull sample, and a formal test of the null hypothesis that stu- mate the effect of attending private school on achievement
dents from low- and high-achieving schools benefit equally then such methods as instrumental variables or those used b
from vouchers is never close to rejecting. It also appears veryBarnard et al. are necessary to estimate the parameter of inte
unlikely that the differences between the treatment effects for
est. We consider this of secondary interest in this case, how
applicants from low- and high-achieving schools in Barnard ever.
et al.'s Table 4 are statistically significant either.
ADDITIONAL REFERENCES
3. WHAT WAS BROKEN?
Angrist, J., Bettinger, E., Bloom, E., King, E., and Kremer, M. (2003),

ers for Private Schooling in Colombia: Evidence from a Randomized N
We agree with Barnard et al. that the experiment was broken

Experiment," American Economic Review, 92, 1535-1558.
in the sense that attrition and missing data were common. Previ-

Cochran, W., and Cox, G. (1957), Experimental Designs (2nd ed.), Ne

ous analyses were also strained, if not broken, for their neglect
Wiley.
of the cohort of students originally in kindergarten who were
inA., and Zhu, P. (2003), "Another Look at the New York City
Krueger,
School Voucher Experiment," American Behavioral Scientist, forthcoming.
third grade at the end of the experiment and whose follow-up
Also available from Industrial Relation Section, Princeton University, at

test scores were ignored. Including these students qualitatively
http://www.irs.princeton.edu.
alters the results for Black students. The experiment was
also
Peterson,
P., Myers, D., and Howell, W. (1998), "An Evaluation of the
New York City Scholarships Program: The First Year," Mathematica Policy
broken in the sense that years passed before correct baseline
Research, Inc., available at http://www.ksg.harvard.edu/pepg/pdf/nylrpt.pdf.
weights were computed.
Rouse, C. (1998), "Private School Vouchers And Student Achievement: An
We disagree, however, with the interpretation that the experiEvaluation Of The Milwaukee Parental Choice Program," The Quarterly
Journal
ment was broken because compliance was less than 100%.
Thisof Economics, 13, 553-602.

Comment
Richard A. BERK and Hongquan Xu

1. INTRODUCTION

concretely with reference to the phenomena being studied,

uated empirically whenever possible, and, at a minimum,
The article by Barnard, Frangakis, Hill, and Rubin (hereafter
jected to sensitivity tests.

BFHR) is a virtuoso performance. By applying the NeymanAs battle-tested academics, we can certainly quibble her
Rubin model of causal effects and building on a series
of about
im- some aspects of the article. For example, migh
there
portant works on the estimation and interpretation ofnot
casual
haveefmade sense to construct priors from the educator

fects (e.g., Angrist, Imbens, and Rubin 1996), BFHR manage
to who were responsible for designing the inter
economists

extract a reasonable set of findings for a "broken" randomized
tion? Moreover, might it not have made sense to interpret th

experiment. The article more generally underscores the
imporsults
using a yardstick of treatment effects that are large en
tant difference between estimating relationships in a to
consistent
matter in practical terms? Nonetheless, we doubt that

allobtainwe could have done as well as BFHR did. Moreover, m
manner and interpreting those estimates in causal terms;

ing consistent estimates is only part of the enterprise.
of Finally,
our concerns depend on features of the data that canno

the article emphasizes that assumptions made so that known
proper from
esa distance. We would have had to carefully e
timates may be obtained are not just technical moves
conineof
the
data ourselves. As a result, we focus on why a virt
venience. Rather, they are statements about how theperformance
empirical
was needed to begin with. Why was this trip
world is supposed to work. As such, they need to be essary?
examined

b 2003 American Statistical Association

Journal of the American Statistical Association
Richard A. Berk is Professor and Hongquan Xu is Assistant Professor,
Department of Statistics, University of California, Los Angeles, CA 90095
June 2003, Vol. 98, No. 462, Applications and Case Studies

DOI 10.1198/016214503000107

(E-mail: berk@ stat. ucla.edu).

This content downloaded from 206.253.207.235 on Wed, 27 Feb 2019 21:30:49 UTC
All use subject to https://about.jstor.org/terms

Berk

and

Xu:

Comment

319

4. DESIGN EFFICIENCY

2. NONCOMPLIANCE

A carefully
designed experiment not only provides a
The implementation of randomized field experiments,
as desis
for
statistical
inference, but also gives credible evid
sirable as they are, invites any number of well-known problems

causation.
(Berk 1990). One of these problems is that human subjects
of- The New York School Choice Scholarships P
(NYSCSP) was apparently the first good example of a
ten do not do what they are told, even when they say they will.
ized experiment to examine the potential benefits of v
There is recent scholarly literature on noncompliance (Metry
for private schools. Offering a scholarship (treatment) r
and Meyer 1999; Johnson 2000) and a citation trail leading back
through a lottery can (1) provide a socially acceptable
to evaluations of the social programs of the War on Poverty
ration scarce resources, (2) protect against undesirable
(Havemen 1977). Some noncompliance can be expected except

tion bias and (3) produce balance between the obser

when there is unusual control over the study subjects. Our reunobserved variables, which may affect the response. I
cent randomized trial of the inmate classification system
used
tion to
the randomization and blocking, NYSCSP impl
by the California Department of Corrections is onea example
PMPD (propensity matched pairs design) to choose a

(Berk, Ladd, Graziano, and Baek 2003).

group from a large candidate pool and to balance many
An obvious question follows: Why does it seem that
theexplicitly.
indiates
Table 2 of BFHR shows that various bac
viduals who designed this experiment were caught by
surprise?
variables were balanced properly between the treatmen

and the control group.
As best we can tell, little was done to reduce noncompliance,
But, might
it have been possible to do a bit better?
and, more important for the analyses of BFHR, apparently
alnot mention that the sample size of the applicant
most no data were collected on factors that might bedid
explicitly
not balanced, although winners from high and low
related to noncompliance (Hill, Rubin, and Thomas was
2000).
were balanced between the treatments and the controls. An

Without knowing far more about the design stages of the ex-

ideal design would have had equal winners from "bad" (o
low) and "good" (or high) public schools. In the NYSCSP

periment, we find it difficult to be very specific. But from the

literatures on compliance and school choice, the following are

85% of the winners were from bad schools and 15% were from

probably illustrative indicators relevant for parents who would
good schools, to achieve the social goals of the School Choice
not be inclined to use a school voucher; for other forms of nonScholarships Foundation (Hill et al. 2000, p. 158). Bad schools
compliance, other measures would be needed:
are defined as "those for which the average test scores were

below
the median test scores for the city" (Hill et al. 2000,
1. Whether the adults in the household are employed
outside
p.
158).
A direct consequence is that the estimates from the
the home during the day

good schools have much larger variation than that from the bad
2. Whether there is any child care at the private schools beschools, which was evident in BFHR's Tables 4-6. The confifore classes begin and after they end for children of emdence intervals for good schools are wider.
ployed parents

3. A household's ability to pay for private school beyond the

Instead of classifying schools into two classes (bad and

good), it might have been helpful to classify them into four
value of the voucher
classes: very bad, bad, good, and very good. To estimate the
4. Travel time to the nearest private schools
effect of applicant's school (assuming linear effects), an opti5. Availability of transportation to those schools
mal design would select half of the winners to the very bad
6. Religious preference of the household and religious affil-school, other half to the very good school, and none to the two
iation of the private school.
middle schools. Avoiding the middle schools enlarges the distance between bad and good schools and also reduces the source
From these examples, and others that individuals closer to
variation in the bad and good schools, and thus reduces the varithe study would know about, one can imagine a variety of meaation in the estimates. To be more consistent with the goals of
sures to reduce noncompliance. For instance, key problems for
the School Choice Scholarships Foundation, an alternative deany working parent are child care before and after school, and
sign might take 75% winners from very bad schools, 10% from
round-trip school transportation. These might be addressed dibad schools, 5% from good schools, and 10% from very good
rectly with supplemental support. If no such resources could be
schools. This design would have a higher design efficiency than
obtained, then the study design might be altered to screen out
the original design especially because the applicant's school
before random assignment households for whom compliancewas the most important design variable after family size (Hill
was likely to be problematic.
et al. 2000, p. 160). Of course, people on the ground at the
time may have considered these options and rejected them. Our
3. MISSING DATA
point is that with better planning, it might have been possible
to squeeze more efficiency out of the study design. Such an
No doubt, BFHR know more about the subtleties of the
miss- would have made the job undertaken by BFHR a bit
outcome
easier.
ing data than we do. Nevertheless, the same issues arise
for
missing data that arise for noncompliance. Surely, problems
with missing data could have been anticipated. Factors related

5. CONCLUSIONS

to nonresponse to particular items could have been explicitly
Scientific problems often provide a fertile ground for im
measured and prevention strategies perhaps could have tant
been statistical
dedevelopments. BFHR's article and the liter
on which they depend are excellent illustrations. However
ployed.

This content downloaded from 206.253.207.235 on Wed, 27 Feb 2019 21:30:49 UTC
All use subject to https://about.jstor.org/terms

320 Journal of the American Statistical Association, June 2003

Berk, R. A.
(1990), goal
"What Your
Mother
Never Told You evaluat
About Random
the perspective of public policy,
the
of
program
Field Experiments,"of
in Community-Based
Careimpacts
of People With AIDS
is to obtain usefully precise estimates
program
wh
veloping a Research Agenda, AHCPR Conference Proceedings, Washing
using the most robust meansDC:
of
analysis
available.
Simplicity
U.S. Department of Health and Human Services.
also important, both for data
who
must
do "A
the
w
Berk, analysts
R. A., Ladd, H., Graziano,
H., and
Baek, J. (2003),
Randomized
periment
Testing Inmate Classification
Systems," Journal
of Criminolog
and policy makers who must
interpret
the results.
It
follo
Public Policy, 2, 215-242.
that large investments at the front end of an evaluation-in
Havemen, R. H. (ed.) (1977), A Decade of Federal Antipoverty Progr
search design, measurement, Achievements,
and study
integrity-are
essent
Failures, and
Lessons, New York: Academic
Press.
J. L.,certainly
Rubin, D. B., and Thomas,
N. (2000),
"The Design
of the
Virtuoso statistical analyses Hill,
can
help
when
these
York School Choice
Scholarships
Research De
vestments are insufficient or when
they
fail,Program
but Evaluation,"
they in
must
n
Donald Campbell's Legacy (Vol. II), ed. L. Bickman, Thousand Oaks,
be seen as an inexpensive alternative
to
doing
the
study
wel
Sage.

begin with.

Johnson, S. B. (2000), "Compliance Behavior in Clinical Trials: Error or Op-

ADDITIONAL REFERENCES

portunity?," in Promoting Adherence to Medical Treatment in Chronic Child-

hood Illness: Concepts, Methods, and Interventions, ed. D. Drotar Mahwah,
NJ, Lawrence Erlbaum.
Angrist, J., Imbens, G. W., and Rubin, D. B. (1996), "Identification of Causal
Metry,
and Meyer, U. A. (eds.) (1999), Drug Regimen Compliance: Issues
Effects Using Instrumental Variables" (with discussion), Journal of the J.,
Amerin Clinical Trials and Patient Management, New York: Wiley.
ican Statistical Association, 91, 441-472.

Rejoinder
John BARNARD, Constantine E. FRANGAKIS, Jennifer L. HILL, and Donald B. RUBIN

cussants have raised many salient issues and offered useful ex-

Regarding the trade-offs between the joint latent ignorability and compound exclusion assumptions versus the joint assumptions of standard ignorability and the standard exclusion

tensions of our work. We use this rejoinder primarily to address

restriction, this topic is up for debate. We would like to point

We thank the editorial board and the thoughtful group of dis-

cussants that they arranged to comment on our article. The dis-

out, however, that these standard structural assumptions come

a few points of contention.

with their own level of arbitrariness. These issues have been

Muthen, Jo, and Brown
Muthen, Jo, and Brown (henceforth MJB) provide an enlight-

ening discussion of an alternate and potentially complementary
approach to treatment effect estimation. The growth models that

they discuss are for data more extensive than what we analyzed

and so are beyond the scope of our article. Nevertheless, MJB
propose an interesting idea for looking for interactions in longitudinal experimental data, and we look forward to future applications of the method to appropriate datasets.

Although models that incorporate both our compliance principal strata as well as latent growth trajectories are theoretically

possible (assuming multiple years of outcome data) and could
potentially yield an extremely rich description of the types of
treatment effects manifested, the more time points that exist,

the more complicated the compliance patterns can become (at
least without further assumptions), and it may be difficult to find

a dataset rich enough to support all of the interactions. Given a
choice, we feel that it is probably more beneficial to handle real
observed issues than to search for interactions with latent tra-

explored by Jo (2002) and Mealli and Rubin (2002, 2003).
We thank MJB for providing a thought-provoking discussio
of our model and assumptions, as well as ample fodder for additional directions that can be explored in this arena. Clearly th
general category of work has stimulated much new and excitin
modeling.

Krueger and Zhu
Krueger and Zhu (henceforth KZ) focus primarily on the underlying study and analyses that either we did not do or used
data we did not have. Clearly, they are interested in the substantive issues, which is admirable, but we cannot be responsible
for analyses that we neither did nor were consulted on, and are
not prepared to comment on what analyses we might have undertaken with data that we did not have.

KZ state that "there is no substitute for probing the definition and concepts that underlie that data." Although we are not
entirely sure what this refers to in particular, if it means that
good science is more important than fancy techniques, then we

certainly agree.
jectories, but certainly it would always be nice to be able to
Another comment by KZ is that "it is desirable to use the
do both. Of course, such a search for interactions in trajectomost recent, comprehensive data, for the widest sample possiries is more beneficial when there is enough prior knowledge
ble." We agree that it is desirable to have access to the most
about the scientific background to include additional structural
comprehensive data available, but it is not necessary to use all
assumptions that can support robust estimation.
of these data in any given analysis. Here we use only first-year
MJB make an interesting point about the exploration of podata, because these were the only data available to us at the
tential violations of exclusion for never-takers. Such analyses

have been done in past work by some of the authors (Hirano
et al. 2000; Frangakis, Rubin, and Zhou 2002), but was not pursued for our study, because the robustness of such methods is
still an issue in examples as complex as this one.

@ 2003 American Statistical Association
Journal of the American Statistical Association

June 2003, Vol. 98, No. 462, Applications and Case Studi

This content downloaded from 206.253.207.235 on Wed, 27 Feb 2019 21:30:49 UTC
All use subject to https://about.jstor.org/terms

DOI 10.1198/016214503000116

