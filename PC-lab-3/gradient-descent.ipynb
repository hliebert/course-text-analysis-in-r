{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC Session 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:**\n",
    "[Helge Liebert](https://hliebert.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random data in which y is a noisy function of x\n",
    "x1 <- runif(1000, -5, 5)\n",
    "x2 <- runif(1000, -15, 15)\n",
    "x3 <- runif(1000, -1, 7)\n",
    "intercept <- rep(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outcome and matrix of regressors plus intercept, univariate case\n",
    "y <- x1 + rnorm(1000) + 3\n",
    "X <- as.matrix(cbind(intercept, x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outcome and matrix of regressors plus intercept, multivariate case\n",
    "## y <- 3*x1 + 0.5*x2 + 15*x3  + rnorm(1000) + 3\n",
    "## X <- as.matrix(cbind(intercept, x1, x2, x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(y)\n",
    "dim(X)\n",
    "cbind(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways of computing linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression by solving normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using matrices to solve the system of equations, (X'X)^-1 X'y\n",
    "b.ols <- solve(t(X) %*% X) %*% t(X) %*% y\n",
    "b.ols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more idiomatic\n",
    "b.ols <- solve(crossprod(X), crossprod(X,y))\n",
    "b.ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression by QR-decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit a linear model, QR-decomposition/Gram-Schmidt orthogonalization\n",
    "b.qrd <- lm(y ~ X - 1)\n",
    "b.qrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doing qrd manually and solving\n",
    "qrdecomp <- qr(X)\n",
    "b.qrd <- as.matrix(backsolve(qrdecomp$qr, qr.qty(qrdecomp, y)))\n",
    "b.qrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression by SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdecomp <- svd(X)\n",
    "str(svdecomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computing A^{+}y, (X'X)^{-1}X' is Moore-Penrose Pseudoinverse, optained via SVD, \n",
    "b.svd <- svdecomp$v %*% solve(diag(svdecomp$d)) %*% t(svdecomp$u) %*% y\n",
    "b.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for Moore-Penrose Pseudoinverse\n",
    "b.svd <- MASS::ginv(X) %*% y\n",
    "b.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moore-penrose Pseudoinverse, computed via eigenvalue decomposition of x'x\n",
    "egd <- eigen(t(X) %*% X)\n",
    "xtx.inv <- egd$vectors %*% solve(diag(egd$values)) %*% t(egd$vectors)\n",
    "x.pseudo.inv <- xtx.inv %*% t(X)\n",
    "b.svd <- x.pseudo.inv %*% y\n",
    "b.svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## squared error cost function\n",
    "cost <- function(X, y, theta) {\n",
    "  sum((X %*% theta - y)^2) / (2 * length(y))\n",
    "}\n",
    "\n",
    "## euclidean norm\n",
    "eucnorm <- function(x) sqrt(sum(x^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch gradient descent\n",
    "\n",
    "Simple approach, fixed # of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize coefficients\n",
    "theta <- matrix(c(0, 0), nrow = 2) ## univariate\n",
    "## theta <- matrix(c(0, 0), nrow = 4) ## multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## learning rate and iteration limit\n",
    "alpha <- 0.01\n",
    "niter <- 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep history\n",
    "cost_history <- double(niter)\n",
    "theta_history <- list(niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute gradient and update\n",
    "set.seed(42)\n",
    "for (i in 1:niter) {\n",
    "  error <- (X %*% theta) - y\n",
    "  delta <- t(X) %*% error / length(y)\n",
    "  theta <- theta - alpha * delta\n",
    "  cost_history[i] <- cost(X, y, theta)\n",
    "  theta_history[[i]] <- theta\n",
    "  ## if ((i %% 100) == 0) print(theta)\n",
    "}\n",
    "print(theta)\n",
    "print(niter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch gradient descent\n",
    "\n",
    "With a stopping rule instead of a fixed number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize coefficients\n",
    "theta <- matrix(c(0, 0), nrow = 2) ## univariate\n",
    "## theta <- matrix(c(0, 0), nrow = 4) ## multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep history\n",
    "cost_history <- c()\n",
    "theta_history <- list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stopping threshold\n",
    "epsilon <- 10e-10\n",
    "delta <- Inf\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute gradient and update\n",
    "## threshold and first iteration values\n",
    "set.seed(42)\n",
    "while (eucnorm(delta) > epsilon) {\n",
    "  error <- (X %*% theta) - y\n",
    "  delta <- t(X) %*% error / length(y)\n",
    "  theta <- theta - alpha * delta\n",
    "  cost_history <- c(cost_history, cost(X, y, theta))\n",
    "  theta_history <- append(theta_history, list(theta))\n",
    "  ## if ((i %% 100) == 0) print(theta)\n",
    "  i <- i + 1\n",
    "}\n",
    "print(theta)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare estimates\n",
    "plot(x1, y, col = rgb(0.2, 0.4, 0.6, 0.4), \n",
    "     main = \"Linear regression (by QR-decomp, normal eq, SVD or gradient descent)\")\n",
    "abline(b.qrd[1:2], col = \"blue\")\n",
    "#abline(b.ols[1:2], col = \"green\")\n",
    "#abline(b.svd[1:2], col = \"red\")\n",
    "#abline(theta[1:2], col = \"pink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converging fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plot data and converging fit\n",
    "plot(x1, y, col = rgb(0.2, 0.4, 0.6, 0.4),\n",
    "     main = \"Linear regression by gradient descent\")\n",
    "for (i in c(1, 3, 6, 10, 14, seq(20, niter, by = 10))) {\n",
    "  abline(coef = theta_history[[i]], col = rgb(0.8, 0, 0, 0.3))\n",
    "}\n",
    "abline(coef = theta, col = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cost convergence\n",
    "plot(cost_history, type = \"l\", col = \"blue\", lwd = 2,\n",
    "     main = \"Cost function\", ylab = \"cost\", xlab = \"Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv <- as.data.frame(cbind(t(sapply(theta_history, function(x) x[, 1])), cost = cost_history))\n",
    "\n",
    "library(plot3D)\n",
    "scatter3D(\n",
    "  x = conv$intercept,\n",
    "  y = conv$x1,\n",
    "  z = conv$cost,\n",
    "  xlab = \"intercept\",\n",
    "  ylab = \"slope\",\n",
    "  zlab = \"cost (mse)\",\n",
    "  col = ramp.col(\n",
    "    col = sort(RColorBrewer::brewer.pal(9, \"Blues\"), decreasing = F),\n",
    "    n = length(unique(conv$cost))\n",
    "  ),\n",
    "  colkey = F,\n",
    "  phi = 10,\n",
    "  theta = 45,\n",
    "  main = \"Gradient Descent (3D View)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent, single obs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta <- matrix(c(0, 0), nrow = 2) ## univariate\n",
    "## theta <- matrix(c(0, 0), nrow = 4) ## multivariate\n",
    "cost_history <- c()\n",
    "theta_history <- list()\n",
    "set.seed(42)\n",
    "for (i in 1:niter) {\n",
    "  j <- sample(NROW(X), 1)\n",
    "  error <- (X[j, ] %*% theta) - y[j]\n",
    "  delta <- X[j, ] %*% error / length(y[j])\n",
    "  theta <- theta - alpha * delta\n",
    "  cost_history[i] <- cost(X[j, ], y[j], theta) ## cost function could be simplified\n",
    "  theta_history[[i]] <- theta\n",
    "}\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot data and converging fit\n",
    "plot(x1, y, col = rgb(0.2, 0.4, 0.6, 0.4),\n",
    "     main = \"Linear regression by stochastic gradient descent, single obs\")\n",
    "for (i in c(1, 3, 6, 10, 14, seq(20, niter, by = 10))) {\n",
    "  abline(coef = theta_history[[i]], col = rgb(0.8, 0, 0, 0.3))\n",
    "}\n",
    "abline(coef = theta, col = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cost convergence\n",
    "plot(cost_history, type = \"l\", col = \"blue\", lwd = 2,\n",
    "     main = \"Cost function\", ylab = \"cost\", xlab = \"Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv <- as.data.frame(cbind(t(sapply(theta_history, function(x) x[, 1])), cost = cost_history))\n",
    "\n",
    "library(plot3D)\n",
    "scatter3D(\n",
    "  x = conv$intercept,\n",
    "  y = conv$x1,\n",
    "  z = conv$cost,\n",
    "  xlab = \"intercept\",\n",
    "  ylab = \"slope\",\n",
    "  zlab = \"cost (mse)\",\n",
    "  col = ramp.col(\n",
    "    col = sort(RColorBrewer::brewer.pal(9, \"Blues\"), decreasing = F),\n",
    "    n = length(unique(conv$cost))\n",
    "  ),\n",
    "  colkey = F,\n",
    "  phi = 10,\n",
    "  theta = 45,\n",
    "  main = \"Gradient Descent (3D View)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent, single batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta <- matrix(c(0, 0), nrow = 2) ## univariate\n",
    "## theta <- matrix(c(0, 0), nrow = 4) ## multivariate\n",
    "cost_history <- c()\n",
    "theta_history <- list()\n",
    "set.seed(42)\n",
    "for (i in 1:niter) {\n",
    "  select <- sample(NROW(X), 32)\n",
    "  error <- (X[select, ] %*% theta) - y[select]\n",
    "  delta <- t(X[select, ]) %*% error / length(y[select])\n",
    "  theta <- theta - alpha * delta\n",
    "  cost_history[i] <- cost(X[select, ], y[select], theta)\n",
    "  theta_history[[i]] <- theta\n",
    "}\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot data and converging fit\n",
    "plot(x1, y, col = rgb(0.2, 0.4, 0.6, 0.4),\n",
    "     main = \"Linear regression by stochastic gradient descent, mini batch\")\n",
    "for (i in c(1, 3, 6, 10, 14, seq(20, niter, by = 10))) {\n",
    "  abline(coef = theta_history[[i]], col = rgb(0.8, 0, 0, 0.3))\n",
    "}\n",
    "abline(coef = theta, col = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cost convergence\n",
    "plot(cost_history, type = \"l\", col = \"blue\", lwd = 2,\n",
    "     main = \"Cost function\", ylab = \"cost\", xlab = \"Iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent, mini batch w/ multiple batches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
